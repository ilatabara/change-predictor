id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fossa~master~I384971732166fbeb123d572d3ccbcde6bad39dfc,openstack/ossa,master,I384971732166fbeb123d572d3ccbcde6bad39dfc,Use templates to generate rst documentation,MERGED,2014-12-10 22:29:20.000000000,2015-01-14 14:56:58.000000000,2015-01-14 14:56:58.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 5263}, {'_account_id': 7473}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-12-10 22:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/8bc57cc5555d933a78b74c5bcc68940b30073414', 'message': 'Add conversion utility for yaml to rst format\n\ntox should now be able to build the html documentation to\ncompletion.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 2, 'created': '2014-12-11 04:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/e84e844d10345d814613104843657c3ad18192fe', 'message': 'Add conversion utility for yaml to rst format\n\ntox should now be able to build the html documentation to\ncompletion.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 3, 'created': '2014-12-12 01:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/cd98f4df55103d6d51926d71d34311ccfe8d38c4', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents. Additional templates\ncould be added to generate emails using this approach.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 4, 'created': '2014-12-12 01:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/b8c839fa3dc364bc6602e7ebc8032e5dea234704', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents. Additional templates\ncould be added to generate emails using this approach.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 5, 'created': '2014-12-16 22:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/676fd96de67c06ed383e6a19bf8536ecd5086a17', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents. Additional templates\ncould be added to generate emails using this approach.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 6, 'created': '2014-12-18 21:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/cd837b64c7def9b5eeb30993f9ecd4bb62cc0d86', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 7, 'created': '2014-12-18 22:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/b4cdf5d3958b28605157b161f91299adaca7e6cf', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents. Additional templates\ncould be added to generate emails using this approach.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 8, 'created': '2015-01-05 19:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/095ea61328234270315f1473dea5df6d00f60696', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 9, 'created': '2015-01-05 19:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/2e50640d8bf6390ab9f12d2369aadf045c3e7c19', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 10, 'created': '2015-01-06 00:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/dc0b65fce659566487eccf72100b55984f584dd1', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 11, 'created': '2015-01-08 15:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/dd2fa571be93a5c493523ba367688cdb2ef081ff', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 12, 'created': '2015-01-08 15:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/1f5727002fe31900d3695c3ffc0d81bc2e8dd753', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 13, 'created': '2015-01-08 16:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/8de251861355aa8b89ec70e6893360bc284584ce', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}, {'number': 14, 'created': '2015-01-12 16:10:11.000000000', 'files': ['doc/source/_exts/vmt.py', 'doc/source/index.rst', '.gitignore', 'test-requirements.txt', 'doc/source/_exts/rst.jinja', 'doc/source/conf.py', 'tox.ini', 'ossa/index.rst'], 'web_link': 'https://opendev.org/openstack/ossa/commit/eb2776f71429b68b1900b8470e46af947c08f351', 'message': 'Use templates to generate rst documentation\n\nUsing Jinja2 to generate ReSTructured text documents via a Sphinx\nExtension.\n\nChange-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc\n'}]",9,140848,eb2776f71429b68b1900b8470e46af947c08f351,44,6,14,7473,,,0,"Use templates to generate rst documentation

Using Jinja2 to generate ReSTructured text documents via a Sphinx
Extension.

Change-Id: I384971732166fbeb123d572d3ccbcde6bad39dfc
",git fetch https://review.opendev.org/openstack/ossa refs/changes/48/140848/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'test-requirements.txt', 'yaml2rst.py', 'tox.ini']",4,8bc57cc5555d933a78b74c5bcc68940b30073414,gm_publish_ossa,deps = -r{toxinidir}/test-requirements.txt commands = python yaml2rst.py python setup.py build_sphinx,commands = python setup.py build_sphinx,111,2
openstack%2Ftempest~master~I9c0f64c2083258573182ee5a7eab10d60aa3c65b,openstack/tempest,master,I9c0f64c2083258573182ee5a7eab10d60aa3c65b,Test port update with new security group,MERGED,2014-12-17 10:30:46.000000000,2015-01-14 14:51:07.000000000,2015-01-14 14:51:05.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 12626}]","[{'number': 1, 'created': '2014-12-17 10:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/26629523f0f6ddd278b22d60dd11c69c1d73d04c', 'message': ' Test port update with new security group\n Verify the traffic on VM port with default security group\n Verify the traffic after updating port with new security group having appropriate rules\n\nChange-Id: I9c0f64c2083258573182ee5a7eab10d60aa3c65b\n'}, {'number': 2, 'created': '2014-12-19 12:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ddf123aeb36dbe3d3ec7085e5de517823513cd9a', 'message': ' Test port update with new security group\n\n Verify the traffic on VM port with default security group\n Verify the traffic after updating port\n        with new security group having appropriate rules\n\nChange-Id: I9c0f64c2083258573182ee5a7eab10d60aa3c65b\n'}, {'number': 3, 'created': '2015-01-07 14:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/842e4276e304c66c8fcffa99cc624e4ef6ffff0b', 'message': ' Test port update with new security group\n\n Verify the traffic on VM port with default security group\n Verify the traffic after updating port\n        with new security group having appropriate rules\n\nChange-Id: I9c0f64c2083258573182ee5a7eab10d60aa3c65b\n'}, {'number': 4, 'created': '2015-01-13 07:39:14.000000000', 'files': ['tempest/scenario/test_security_groups_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d9e964a1412d11b846fc49b3843759c378851868', 'message': ' Test port update with new security group\n\n Verify the traffic on VM port with default security group\n Verify the traffic after updating port\n        with new security group having appropriate rules\n\nChange-Id: I9c0f64c2083258573182ee5a7eab10d60aa3c65b\n'}]",11,142414,d9e964a1412d11b846fc49b3843759c378851868,28,8,4,12626,,,0," Test port update with new security group

 Verify the traffic on VM port with default security group
 Verify the traffic after updating port
        with new security group having appropriate rules

Change-Id: I9c0f64c2083258573182ee5a7eab10d60aa3c65b
",git fetch https://review.opendev.org/openstack/tempest refs/changes/14/142414/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_security_groups_basic_ops.py'],1,26629523f0f6ddd278b22d60dd11c69c1d73d04c,port-update-new-securitygroup," 7._test_port_update_newsecuritygroup: * test that traffic is blocked with default security froup * test that traffic is enabled after updating port with new security group having appropriate rule except Exception: for tenant in self.tenants.values(): self._log_console_output(servers=tenant.servers) raise @test.attr(type='smoke') @test.services('compute', 'network') def test_port_update_new_security_group(self): """""" This test verifies the traffic after updating the vm port with new security group having appropiate rule. """""" try: new_tenant = self.primary_tenant new_sg = self._create_empty_security_group( namestart='secgroup_new-', tenant_id=new_tenant.creds.tenant_id, client=new_tenant.manager.network_client) icmp_rule = dict( protocol='icmp', direction='ingress', ) self._create_security_group_rule( secgroup=new_sg, client=new_tenant.manager.network_client, **icmp_rule) new_tenant.security_groups.update(new_sg=new_sg) name = 'server-{tenant}-gen-1-'.format( tenant=new_tenant.creds.tenant_name ) name = data_utils.rand_name(name) server = self._create_server(name, new_tenant) # Check connectivity failure with default security groups access_point_ssh = self._connect_to_access_point(new_tenant) self._check_connectivity(access_point=access_point_ssh, ip=self._get_server_ip(server), should_succeed=False) server_id = server['id'] port_id = self._list_ports(device_id=server_id)[0]['id'] self.network_client.update_port(port_id, security_groups=[ new_tenant.security_groups['new_sg'].id]) self._check_connectivity( access_point=access_point_ssh, ip=self._get_server_ip(server))",,48,0
openstack%2Ffuel-library~master~I443284a786df41a096bf59dd6d913ec437c05977,openstack/fuel-library,master,I443284a786df41a096bf59dd6d913ec437c05977,Added new role for vcenter compute nodes,ABANDONED,2014-12-23 16:07:49.000000000,2015-01-14 14:49:28.000000000,,"[{'_account_id': 3}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 11427}, {'_account_id': 12139}]","[{'number': 1, 'created': '2014-12-23 16:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f80da1ee8558da06c85ced86cf24939acd476c1e', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter and cinder-vcenter roles and their processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint availability-zones\n'}, {'number': 2, 'created': '2014-12-24 13:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1218304247afde0376c67e988f794662f3ea4d75', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 3, 'created': '2014-12-24 13:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6dfbf6de692b06bba06d4e01e378a66582cc6ef5', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 4, 'created': '2014-12-24 13:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/65584659565aaa62ee7ddea5a19501d34cf5902d', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 5, 'created': '2014-12-24 13:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3706e3715fb23c13b19e77fc70b7a48403198b4e', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 6, 'created': '2014-12-24 13:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f0d91a9f104e37a295be1516ed7d96b4049c29d5', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 7, 'created': '2014-12-24 13:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1ae1ba6fa226bd0cf12d86414ed56ebd9a0e5505', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 8, 'created': '2014-12-29 12:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0f4cd2cf5f29e300da4837c89e40e320b133088c', 'message': 'Added new roles for vcenter nodes\n\nAdded compute-vcenter roles and it processing\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 9, 'created': '2014-12-30 14:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/86f27189fc902585fde9b393d5e586cd95d8c0ea', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 10, 'created': '2014-12-30 15:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd8511820430bb7db9d66c613748917025eefdb1', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 11, 'created': '2014-12-30 15:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f93bb5922fee28e0e072f2f0e6cfa3936508dd07', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 12, 'created': '2014-12-30 15:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/48034398182cc9c1bba2da9ccf09c25bfc4ecfa8', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 13, 'created': '2014-12-30 15:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2689a5bfe3b7297e0875dae3b60c4d2df01e6a70', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 14, 'created': '2014-12-30 15:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7ee47fdf1c0227fff646a1b22f661fcf414f9a26', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 15, 'created': '2014-12-30 15:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e6d144c6af41c3409d40465991b9b979c0e6ef8', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 16, 'created': '2015-01-12 11:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d8c499ecba7917712f2210ec1aca618f3d4d6f59', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 17, 'created': '2015-01-12 14:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f34c85fa6806d118a0354c7faec266d680e7ba03', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 18, 'created': '2015-01-12 15:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cc9d4a0afda4b595c72d53afaf82026625160f05', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 19, 'created': '2015-01-13 10:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/51c2935ba5f8152bab820a68a2012c312bc1481b', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 20, 'created': '2015-01-13 13:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dfe18954d9f8ebb27e183d73f61057a8993429f3', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 21, 'created': '2015-01-13 13:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e50bbc292d74a9d47f5f3dd70bdad6b322f0a0f', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 22, 'created': '2015-01-13 16:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/560149255d043c475860db48012990409c6f297c', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}, {'number': 23, 'created': '2015-01-13 16:50:48.000000000', 'files': ['deployment/puppet/vmware/manifests/ceilometer/ha.pp', 'deployment/puppet/vmware/manifests/compute/ha.pp', 'deployment/puppet/vmware/templates/nova-compute.conf.erb', 'deployment/puppet/vmware/manifests/controller.pp', 'deployment/puppet/vmware/manifests/compute/simple.pp', 'deployment/puppet/vmware/templates/ceilometer-compute.conf.erb', 'deployment/puppet/vmware/manifests/ceilometer/simple.pp', 'deployment/puppet/vmware/manifests/init.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_ha.pp', 'deployment/puppet/osnailyfacter/manifests/cluster_simple.pp', 'deployment/puppet/vmware/manifests/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/af9878bd648036199d20633ee8f87db619e10dcc', 'message': 'Added new role for vcenter compute nodes\n\n* Added compute-vcenter roles and it processing\n* Refactored vmware class for new roles and cases\n\nChange-Id: I443284a786df41a096bf59dd6d913ec437c05977\nImplements: blueprint vmware-dual-hypervisor\n'}]",37,143688,af9878bd648036199d20633ee8f87db619e10dcc,146,5,23,12139,,,0,"Added new role for vcenter compute nodes

* Added compute-vcenter roles and it processing
* Refactored vmware class for new roles and cases

Change-Id: I443284a786df41a096bf59dd6d913ec437c05977
Implements: blueprint vmware-dual-hypervisor
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/88/143688/7 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/cluster_simple.pp'],1,f80da1ee8558da06c85ced86cf24939acd476c1e,bp/vmware-dual-hypervisor," ""compute-vcenter"" : { class { 'vmware' : vcenter_user => $vcenter_hash['vc_user'], vcenter_password => $vcenter_hash['vc_password'], vcenter_host_ip => $vcenter_hash['host_ip'], vcenter_cluster => $vcenter_hash['cluster'], vcenter_datastore_regex => $vcenter_hash['datastore_regex'], vlan_interface => $vcenter_hash['vlan_interface'], vnc_address => $controller_node_public, use_quantum => $::use_neutron, ceilometer => $ceilometer_hash['enabled'], debug => $debug, } } # COMPUTE VCENTER ENDS",,14,0
openstack%2Fmagnum~master~I752cf7ad8dcc4c576b67f63ee2da5e56da6f6fee,openstack/magnum,master,I752cf7ad8dcc4c576b67f63ee2da5e56da6f6fee,Sync from oslo requirements,MERGED,2015-01-14 00:09:17.000000000,2015-01-14 14:42:54.000000000,2015-01-14 01:15:01.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-14 00:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/02f0b144861fe7d119437e05016edbce4791d3eb', 'message': 'Sync from oslo requirements\n\nit is needed to synch from requirements for future integration\nwith openstack requirements easily in kilo or later\n\nChange-Id: I752cf7ad8dcc4c576b67f63ee2da5e56da6f6fee\n'}, {'number': 2, 'created': '2015-01-14 00:43:27.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/2fd10c5fca8ea2aeb98ec25a884ea960c164d590', 'message': 'Sync from oslo requirements\n\nit is needed to synch from requirements for future integration\nwith openstack requirements easily in kilo or later\n\nrefer: https://github.com/openstack/requirements\n\nChange-Id: I752cf7ad8dcc4c576b67f63ee2da5e56da6f6fee\n'}]",4,147029,2fd10c5fca8ea2aeb98ec25a884ea960c164d590,12,5,2,7049,,,0,"Sync from oslo requirements

it is needed to synch from requirements for future integration
with openstack requirements easily in kilo or later

refer: https://github.com/openstack/requirements

Change-Id: I752cf7ad8dcc4c576b67f63ee2da5e56da6f6fee
",git fetch https://review.opendev.org/openstack/magnum refs/changes/29/147029/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,02f0b144861fe7d119437e05016edbce4791d3eb,update-requirement,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,16,8
openstack%2Fpuppet-ceilometer~master~Id59fd02af92c6d77d49195001fc4f983d66d29dd,openstack/puppet-ceilometer,master,Id59fd02af92c6d77d49195001fc4f983d66d29dd,Deprecate support for Fedora 18,MERGED,2014-12-19 12:07:26.000000000,2015-01-14 14:41:24.000000000,2015-01-14 14:41:24.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 7462}, {'_account_id': 8368}, {'_account_id': 8482}, {'_account_id': 9500}, {'_account_id': 11491}]","[{'number': 1, 'created': '2014-12-19 12:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/d24031bc406c5a9c11ab0276f10683f7109bdc3c', 'message': 'Deprecate support for Fedora 18\n\nAlso fixes error on Rawhide: Error: comparison of String with 18\n\nChange-Id: Id59fd02af92c6d77d49195001fc4f983d66d29dd\n'}, {'number': 2, 'created': '2015-01-05 10:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/e7e1c4a5098935fd5dc7b4fbfc2703e99fd3ebd0', 'message': 'Deprecate support for Fedora 18\n\nAlso fixes error on Rawhide: Error: comparison of String with 18\nhttps://fedoraproject.org/wiki/End_of_life\n\nChange-Id: Id59fd02af92c6d77d49195001fc4f983d66d29dd\n'}, {'number': 3, 'created': '2015-01-12 10:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/78031154d827d1ae25fcdba20ef1ea8418eefe77', 'message': 'Deprecate support for Fedora 18\n\nAlso fixes error on Rawhide: Error: comparison of String with 18.\nPackage python-sqlite2 is deprecated since F18. F19 is also EOL.\nhttps://fedoraproject.org/wiki/End_of_life\n\nChange-Id: Id59fd02af92c6d77d49195001fc4f983d66d29dd\n'}, {'number': 4, 'created': '2015-01-12 17:19:03.000000000', 'files': ['spec/classes/ceilometer_db_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a0b8d10f2628bd0212d3de54e7ebf7a05f0c8333', 'message': 'Deprecate support for Fedora 18\n\nAlso fixes error on Rawhide: Error: comparison of String with 18.\nPackage python-sqlite2 is deprecated since F18. F19 is also EOL.\nhttps://fedoraproject.org/wiki/End_of_life\n\nChange-Id: Id59fd02af92c6d77d49195001fc4f983d66d29dd\n'}]",1,143060,a0b8d10f2628bd0212d3de54e7ebf7a05f0c8333,22,8,4,11166,,,0,"Deprecate support for Fedora 18

Also fixes error on Rawhide: Error: comparison of String with 18.
Package python-sqlite2 is deprecated since F18. F19 is also EOL.
https://fedoraproject.org/wiki/End_of_life

Change-Id: Id59fd02af92c6d77d49195001fc4f983d66d29dd
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/60/143060/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_db_spec.rb', 'manifests/params.pp']",2,d24031bc406c5a9c11ab0276f10683f7109bdc3c,, $sqlite_package_name = 'python-sqlite2'," # db packages if $::operatingsystem == 'Fedora' and $::operatingsystemrelease >= 18 { # fallback to stdlib version, not provided on fedora $sqlite_package_name = undef } else { $sqlite_package_name = 'python-sqlite2' } ",2,11
openstack%2Fheat~master~I1bc0206e6b473afd26b4a7caa1f0fce038cfd395,openstack/heat,master,I1bc0206e6b473afd26b4a7caa1f0fce038cfd395,Allow multiple deployment signals,ABANDONED,2014-10-22 16:55:04.000000000,2015-01-14 14:40:28.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 8688}, {'_account_id': 10373}]","[{'number': 1, 'created': '2014-10-22 16:55:04.000000000', 'files': ['heat/engine/resources/software_config/software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a91b3f8a0009289b8593bcf8c1204c515cca489a', 'message': 'Allow multiple deployment signals\n\nOnce this change has merged, we can remove a lot of ""signal_transport:\nNO_SIGNAL"" from the templates. Each deployment will be individually\nsignalled, making it much easier to see exactly what\'s going on.\n\nThis should also mean we can remove the ""depends_on"" keys without Heat\nexiting before the stack is complete.\n\nChange-Id: I1bc0206e6b473afd26b4a7caa1f0fce038cfd395\nRelated-To: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab\n'}]",5,130279,a91b3f8a0009289b8593bcf8c1204c515cca489a,12,6,1,8688,,,0,"Allow multiple deployment signals

Once this change has merged, we can remove a lot of ""signal_transport:
NO_SIGNAL"" from the templates. Each deployment will be individually
signalled, making it much easier to see exactly what's going on.

This should also mean we can remove the ""depends_on"" keys without Heat
exiting before the stack is complete.

Change-Id: I1bc0206e6b473afd26b4a7caa1f0fce038cfd395
Related-To: I5e3429ec9f1935fcc6c3201412f8c57ec46408ab
",git fetch https://review.opendev.org/openstack/heat refs/changes/79/130279/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/software_config/software_deployment.py'],1,a91b3f8a0009289b8593bcf8c1204c515cca489a,," url = self._get_signed_url() for inp in inputs: if inp[scl.NAME] == self.DEPLOY_SIGNAL_ID: inp['value'].append(url) break else: inputs.append({ scl.NAME: self.DEPLOY_SIGNAL_ID, scl.DESCRIPTION: _('ID of signal to use for signalling ' 'output values'), scl.TYPE: 'List', 'value': url })"," inputs.append({ scl.NAME: self.DEPLOY_SIGNAL_ID, scl.DESCRIPTION: _('ID of signal to use for signalling ' 'output values'), scl.TYPE: 'String', 'value': self._get_signed_url() })",13,7
openstack%2Ffuel-library~master~I8df7e0d0a51e0f14bca0b483fd1cfb297fdea47d,openstack/fuel-library,master,I8df7e0d0a51e0f14bca0b483fd1cfb297fdea47d,Fix forgotten data_name variable,MERGED,2015-01-14 14:17:36.000000000,2015-01-14 14:38:36.000000000,2015-01-14 14:38:36.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 13343}]","[{'number': 1, 'created': '2015-01-14 14:17:36.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/hiera.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89f7c94d65f75ebff01898b40aa3931bd52a8a61', 'message': 'Fix forgotten data_name variable\n\nRelated blueprint: fuel-library-modularization\nFuel-CI: disable\n\nChange-Id: I8df7e0d0a51e0f14bca0b483fd1cfb297fdea47d\n'}]",0,147166,89f7c94d65f75ebff01898b40aa3931bd52a8a61,13,5,1,9037,,,0,"Fix forgotten data_name variable

Related blueprint: fuel-library-modularization
Fuel-CI: disable

Change-Id: I8df7e0d0a51e0f14bca0b483fd1cfb297fdea47d
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/66/147166/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/hiera.pp'],1,89f7c94d65f75ebff01898b40aa3931bd52a8a61,bp/fuel-library-modularization,"$hiera_data_file = ""${data_dir}/astute.yaml""","$hiera_data_file = ""${data_dir}/${data_name}.yaml""",1,1
openstack%2Frequirements~stable%2Ficehouse~I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697,openstack/requirements,stable/icehouse,I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697,Cap eventlet at <0.16.0,MERGED,2015-01-14 04:14:57.000000000,2015-01-14 14:30:51.000000000,2015-01-14 14:30:49.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2750}, {'_account_id': 4264}, {'_account_id': 8556}, {'_account_id': 9656}]","[{'number': 1, 'created': '2015-01-14 04:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/10a5647e0d56b4e6a9e90066e041b672e8d38b4a', 'message': 'Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util function in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nCloses-bug: #1410626\n(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697\n'}, {'number': 2, 'created': '2015-01-14 08:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/64902d4d564c9b6903c11c7703d21efaaf16d742', 'message': 'Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util module in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nCloses-bug: #1410626\n(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697\n'}, {'number': 3, 'created': '2015-01-14 12:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ce4d3b6579a1f97ad8e3daba184fb78c73aa5a29', 'message': ""Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util module in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nThis is done instead of backporting the nova fix because it is assumed that stable released environments won't randomly take an eventlet semver bump.\n\nCloses-bug: #1410626\n(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697""}, {'number': 4, 'created': '2015-01-14 12:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7550b628c2f467e40e8defa03f3ac929381c59ad', 'message': ""Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util module in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nThis is done instead of backporting the nova fix because it is assumed\nthat stable released environments won't randomly take an eventlet \nsemver bump.\n\nCloses-bug: #1410626\n(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697""}, {'number': 5, 'created': '2015-01-14 12:33:43.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6201bae3a114279bb2d2aa071ac83f86047c475a', 'message': ""Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util module in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nThis is done instead of backporting the nova fix because it is assumed\nthat stable released environments won't randomly take an eventlet\nsemver bump.\n\nCloses-bug: #1410626\n(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)\n\nConflicts:\n\tglobal-requirements.txt\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697\n""}]",0,147063,6201bae3a114279bb2d2aa071ac83f86047c475a,21,6,5,1420,,,0,"Cap eventlet at <0.16.0

Eventlet removed the deprecated eventlet.util module in 0.16.0.
This caps stable branches to versions previous to that.

This is done instead of backporting the nova fix because it is assumed
that stable released environments won't randomly take an eventlet
semver bump.

Closes-bug: #1410626
(cherry picked from commit a8b79c49ff359020f257e2a3cf038ef84b4ea0c7)

Conflicts:
	global-requirements.txt

Change-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697
",git fetch https://review.opendev.org/openstack/requirements refs/changes/63/147063/5 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,10a5647e0d56b4e6a9e90066e041b672e8d38b4a,,"eventlet>=0.13.0,<0.16.0",eventlet>=0.13.0,1,1
openstack%2Fmagnetodb~master~I35b3b073596dda5bdbddec7febee0b6b3e6ba257,openstack/magnetodb,master,I35b3b073596dda5bdbddec7febee0b6b3e6ba257,Fix memory leakage during cassandra reconnect,MERGED,2015-01-05 16:00:10.000000000,2015-01-14 14:23:13.000000000,2015-01-14 14:23:12.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2015-01-05 16:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/34c67e1461fafcf213bb1ac48b65feac53bd22e4', 'message': 'Fix memory leakage during cassandra reconnect\n\nCloses-bug: #1407717\n\nChange-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257\n'}, {'number': 2, 'created': '2015-01-06 14:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/ff1254e3089ef21249c7d5f93c90770729641d66', 'message': 'Fix memory leakage during cassandra reconnect\n\nCloses-bug: #1407717\n\nChange-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257\n'}, {'number': 3, 'created': '2015-01-08 12:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/24e6a0eaf157fadd127cf188e951e6791275abc4', 'message': 'Fix memory leakage during cassandra reconnect\n\nTo implement reconnection reconnection approach we are using monitoring of control_connection and if some problems - shutdown cluster object and connect again. But python driver add a few atexit handlers during conection. and it block removing old cluster with dependencies from the memory.\n\nThis patch unregister all atexit handlers after cluster connect gets executed\n\nCloses-bug: #1407717\n\nChange-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257\n'}, {'number': 4, 'created': '2015-01-08 12:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/1da1d16e3e95e34d6c71c69d313ca9fd0a957431', 'message': 'Fix memory leakage during cassandra reconnect\n\nTo implement reconnection reconnection approach we are using monitoring\nof control_connection and if some problems - shutdown cluster object and\nconnect again. But python driver add a few atexit handlers during\nconection. and it block removing old cluster with dependencies from the\nmemory.\n\nThis patch unregister all atexit handlers after cluster connect gets\nexecuted\n\nCloses-bug: #1407717\n\nChange-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257\n'}, {'number': 5, 'created': '2015-01-12 16:40:16.000000000', 'files': ['magnetodb/common/cassandra/cluster_handler.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/e9c92d902ae86946b76d4647b9c0852389613eff', 'message': 'Fix memory leakage during cassandra reconnect\n\nTo implement reconnection reconnection approach we are using monitoring\nof control_connection and if some problems - shutdown cluster object and\nconnect again. But python driver add a few atexit handlers during\nconection. and it block removing old cluster with dependencies from the\nmemory.\n\nThis patch unregister all atexit handlers after cluster connect gets\nexecuted\n\nCloses-bug: #1407717\n\nChange-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257\n'}]",2,145011,e9c92d902ae86946b76d4647b9c0852389613eff,22,5,5,8601,,,0,"Fix memory leakage during cassandra reconnect

To implement reconnection reconnection approach we are using monitoring
of control_connection and if some problems - shutdown cluster object and
connect again. But python driver add a few atexit handlers during
conection. and it block removing old cluster with dependencies from the
memory.

This patch unregister all atexit handlers after cluster connect gets
executed

Closes-bug: #1407717

Change-Id: I35b3b073596dda5bdbddec7febee0b6b3e6ba257
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/11/145011/3 && git format-patch -1 --stdout FETCH_HEAD,['magnetodb/common/cassandra/cluster_handler.py'],1,34c67e1461fafcf213bb1ac48b65feac53bd22e4,,import atexit count = len(atexit._exithandlers) try: cluster = cassandra_cluster.Cluster(**self.__cluster_params) session = cluster.connect() finally: while len(atexit._exithandlers) > count: atexit._exithandlers.pop() , cluster = cassandra_cluster.Cluster(**self.__cluster_params) session = cluster.connect(),11,2
openstack%2Fironic~master~I87104ffd227ae941a01dd1cf77164a7ef13023f2,openstack/ironic,master,I87104ffd227ae941a01dd1cf77164a7ef13023f2,Allow configuration of neutronclient retries,MERGED,2015-01-13 22:45:07.000000000,2015-01-14 14:11:31.000000000,2015-01-14 12:37:07.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 6896}, {'_account_id': 6969}, {'_account_id': 9315}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-13 22:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a1809a931757a88a70aa6f3f7d14088c7f97aede', 'message': 'Allow configuration of neutronclient retries\n\nNeutron updates from the conductor may fail for any number of reasons.\nThe neutronclient provide facilities for retrying failed requests. This\npatch exposes this as an Ironic config option and provides a sensible\ndefault.\n\nChange-Id: I87104ffd227ae941a01dd1cf77164a7ef13023f2\n'}, {'number': 2, 'created': '2015-01-13 22:57:58.000000000', 'files': ['etc/ironic/ironic.conf.sample', 'ironic/dhcp/neutron.py', 'ironic/tests/dhcp/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cf3127a0bfc907b4b7cae3b9a296d67935d9535f', 'message': 'Allow configuration of neutronclient retries\n\nNeutron updates from the conductor may fail for any number of reasons.\nThe neutronclient provide facilities for retrying failed requests. This\npatch exposes this as an Ironic config option and provides a sensible\ndefault.\n\nChange-Id: I87104ffd227ae941a01dd1cf77164a7ef13023f2\n'}]",2,147002,cf3127a0bfc907b4b7cae3b9a296d67935d9535f,18,7,2,1420,,,0,"Allow configuration of neutronclient retries

Neutron updates from the conductor may fail for any number of reasons.
The neutronclient provide facilities for retrying failed requests. This
patch exposes this as an Ironic config option and provides a sensible
default.

Change-Id: I87104ffd227ae941a01dd1cf77164a7ef13023f2
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/147002/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/dhcp/neutron.py', 'ironic/tests/dhcp/test_neutron.py']",2,a1809a931757a88a70aa6f3f7d14088c7f97aede,neutron_retries," retries=2, 'retries': 2, 'retries': 2, 'retries': 2,",,8,0
openstack%2Foctavia~master~I11b4d97393edb12519ac4f6616498ff40e0ef6a9,openstack/octavia,master,I11b4d97393edb12519ac4f6616498ff40e0ef6a9,Change back the amhora driver interface,MERGED,2015-01-12 23:02:53.000000000,2015-01-14 14:05:13.000000000,2015-01-14 14:05:12.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-12 23:02:53.000000000', 'files': ['octavia/amphorae/drivers/noop_driver/driver.py', 'octavia/tests/unit/amphorae/drivers/test_noop_amphoraloadbalancer_driver.py', 'octavia/amphorae/drivers/driver_base.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d14374ae866f0c7c7a13bc3b67d6bae1be09f1b9', 'message': ""Change back the amhora driver interface\n\nThis new driver interface has no taskflow, it is based on German's doc.\n\nChange-Id: I11b4d97393edb12519ac4f6616498ff40e0ef6a9\n""}]",0,146674,d14374ae866f0c7c7a13bc3b67d6bae1be09f1b9,9,5,1,10477,,,0,"Change back the amhora driver interface

This new driver interface has no taskflow, it is based on German's doc.

Change-Id: I11b4d97393edb12519ac4f6616498ff40e0ef6a9
",git fetch https://review.opendev.org/openstack/octavia refs/changes/74/146674/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/drivers/noop_driver/driver.py', 'octavia/tests/unit/amphorae/drivers/test_noop_amphoraloadbalancer_driver.py', 'octavia/amphorae/drivers/driver_base.py']",3,d14374ae866f0c7c7a13bc3b67d6bae1be09f1b9,amphora_diverinterface_rollback," def stop(self, listener, vip): """"""Stop the listener on the vip def start(self, listener, vip): """"""Start the listener on the vip """"""Delete the listener on the vip def get_info(self, amphora): @abc.abstractmethod def finalize_amphora(self, amphora): """"""It is called before listeners configured while amphora was built :param amphora: amphora object, need to use its id property :type amphora: object :returns: return a value list (amphora.id, status flag--'ge t_diagnostics') At this moment, we just build the basic structure for testing, will add more function along with the development, eventually, we want it run some expensive self tests to determine if the amphora and the lbs are healthy the idea is that those tests are triggered more infrequent than the health gathering """""" pass "," def disable(self, listener, vip): """"""Suspend the running amphora --optional def enable(self, listener, vip): """"""Start/enable the listener """"""Delete the listener from the amphora def info(self, amphora): def get_metrics(self, amphora): """"""Return ceilometer ready metrics Some amphora might choose to send them straight to ceilometer others might use the mixin support metrics to be compatible with Neutron LBaaS :param amphora: amphora object, need to use its id property :type amphora: object :returns: return a value list (amphora.id, status flag--'get_metrics') At this moment, we just build the basic structure for testing, will add more function along with the development, eventually, we want it to return information as: {""Rest Interface"": ""1.0"", ""Amphorae"": ""1.0"", ""packages"":{""ha proxy"":""1.5""}} some information might come from querying the amphora """""" pass @abc.abstractmethod def get_health(self, amphora): """"""Return ceilometer ready health :param amphora: amphora object, need to use its id property :type amphora: object :returns: return a value list (amphora.id, status flag--'get_health') At this moment, we just build the basic structure for testing, will add more function along with the development, eventually, we want it to return information as: returns map: {""amphora-status"":HEALTHY, loadbalancers: {""loadbalancer-id"": {""loadbalancer-status"": HEALTHY, ""listeners"":{""listener-id"":{""listener-status"":HEALTHY, ""nodes"":{""node-id"":HEALTHY, ...}}, ...}, ...}} """""" pass @abc.abstractmethod",71,106
openstack%2Fmagnetodb-specs~master~Ie54ced5957de6de8607db5d2541c80c750256d9a,openstack/magnetodb-specs,master,Ie54ced5957de6de8607db5d2541c80c750256d9a,Added specs for integration with StatsD,NEW,2014-12-25 13:16:01.000000000,2015-01-14 13:51:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8414}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-12-25 13:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/f087e8374edd0b562f88c8b2264e6fab7c88aa23', 'message': 'Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 2, 'created': '2014-12-25 13:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/f35bdbbd4d1c41eae1ab74851a2620169b8ee966', 'message': 'Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 3, 'created': '2014-12-25 13:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/6e3301889488df82136ef7c84594f409efa7ac29', 'message': 'Added specs for integration with StatsD (WIP)\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 4, 'created': '2014-12-25 14:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/62b727cd6858ced76f4fdbccbe665c14345bb468', 'message': '(WIP)Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 5, 'created': '2014-12-29 12:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/767fb1bf755d0549b75408b97a1037fbdf16546b', 'message': '(WIP) Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 6, 'created': '2014-12-29 15:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/8ac92cdd3269cf5691139cc6d43ecf8ee0637e93', 'message': '(WIP) Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 7, 'created': '2014-12-29 15:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/312519c016046ec774a3f7dda3850f65ebb9b3e2', 'message': '(WIP) Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 8, 'created': '2015-01-05 14:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/9e9ce45ac570b32c5c4cd12dc2117f7bfbcdb582', 'message': 'Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}, {'number': 9, 'created': '2015-01-05 14:35:13.000000000', 'files': ['specs/kilo/approved/table-metrics.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/b462aecc0aa852b61f2e193b27c48117aacc1a36', 'message': 'Added specs for integration with StatsD\n\nChange-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a\nImplements: blueprint statsd-tables-metrics\n'}]",4,143982,b462aecc0aa852b61f2e193b27c48117aacc1a36,16,4,9,8414,,,0,"Added specs for integration with StatsD

Change-Id: Ie54ced5957de6de8607db5d2541c80c750256d9a
Implements: blueprint statsd-tables-metrics
",git fetch https://review.opendev.org/openstack/magnetodb-specs refs/changes/82/143982/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/table-metrics.rst'],1,f087e8374edd0b562f88c8b2264e6fab7c88aa23,bp/statsd-tables-metrics,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================== MagnetoDB monitoring api ======================== Launchpad: monitoring-api_ .. _monitoring-api: https://blueprints.launchpad.net/magnetodb/+spec/monitoring-api The API for exposing usage statistic for users, external monitoring or billing tools. :: +--------------+ +-----------------+ | | | | | Ceilometer | | | | Horizon | HTTP/monitoring API | | | collectd, +---------------------> magnetodb+api | | statsd, | | | | nagios... | | | | | | | +--------------+ +-----------------+ Problem description =================== --------- Use Cases --------- As a magnetodb administrator I need to push table stats to external monitoring service(StatsD). Proposed change =============== 1. Introduce new task for async task executor. 2. Use MagnetoDB monitoring API for collecting table stats. 3. Push collected data to StatsD server. ------------ Alternatives ------------ Place interaction with StatsD in MagnetoDB source code. However integration with StatsD is special case so it's better don't add unnecessary dependences to MagnetoDB source code. ----------------- Data model impact ----------------- No data is stored or cached. --------------- REST API impact --------------- None --------------- Security impact --------------- * TBD -------------------- Notifications impact -------------------- None --------------------- Other end user impact --------------------- None ------------------ Performance Impact ------------------ None --------------------- Other deployer impact --------------------- None ---------------- Developer impact ---------------- None Implementation ============== None ----------- Assignee(s) ----------- Primary assignee: <achudnovets> ---------- Work Items ---------- 1. Write interface for StatsD. 2. Update documentation. Dependencies ============ https://blueprints.launchpad.net/magnetodb/+spec/monitoring-api-url-refactoring Testing ======= None Documentation Impact ==================== * StatsD integration section should be added to documentation_. .. _documentation: http://magnetodb.readthedocs.org/en/latest/api_reference.html References ========== None ",,158,0
openstack%2Foctavia~master~I25c62a9d7cf23c5f89073929d3a1f511f6281934,openstack/octavia,master,I25c62a9d7cf23c5f89073929d3a1f511f6281934,Common TLS utilies,MERGED,2015-01-05 23:45:15.000000000,2015-01-14 13:45:17.000000000,2015-01-14 08:02:52.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-05 23:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9069c28bf1692a7292aba54a1f039b1986ec73d8', 'message': 'Common TLS utilies\n\nChange-Id: I25c62a9d7cf23c5f89073929d3a1f511f6281934\n'}, {'number': 2, 'created': '2015-01-08 01:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6d4e2a0a1e6428e442c653a0cbf56cc14573e5f3', 'message': 'Common TLS utilies\n\nChange-Id: I25c62a9d7cf23c5f89073929d3a1f511f6281934\n'}, {'number': 3, 'created': '2015-01-08 01:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/daa1670aadafaf80fa60fbdf968a4c0c30bf1b3f', 'message': 'Common TLS utilies\n\nChange-Id: I25c62a9d7cf23c5f89073929d3a1f511f6281934\n'}, {'number': 4, 'created': '2015-01-13 18:20:30.000000000', 'files': ['requirements.txt', 'octavia/common/tls_utils/cert_parser.py', 'octavia/tests/unit/common/tls_utils/__init__.py', 'octavia/tests/unit/common/tls_utils/test_cert_parser.py', 'octavia/common/tls_utils/__init__.py', 'octavia/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6d53b86e4e17090fe7221923c1d04c56ab58f990', 'message': 'Common TLS utilies\n\nChange-Id: I25c62a9d7cf23c5f89073929d3a1f511f6281934\n'}]",6,145092,6d53b86e4e17090fe7221923c1d04c56ab58f990,21,6,4,7398,,,0,"Common TLS utilies

Change-Id: I25c62a9d7cf23c5f89073929d3a1f511f6281934
",git fetch https://review.opendev.org/openstack/octavia refs/changes/92/145092/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'octavia/common/tls_utils/cert_parser.py', 'octavia/tests/unit/common/tls_utils/__init__.py', 'octavia/tests/unit/common/tls_utils/test_cert_parser.py', 'octavia/common/exceptions.py', 'octavia/common/tls_utils/__init__.py']",6,9069c28bf1692a7292aba54a1f039b1986ec73d8,cert_parser,,,394,0
openstack%2Ffuel-ostf~master~If7366da29da17404af3564e031e47e7ab39ba826,openstack/fuel-ostf,master,If7366da29da17404af3564e031e47e7ab39ba826,Use regex to check if test belong to test set,MERGED,2015-01-13 13:58:13.000000000,2015-01-14 13:36:13.000000000,2015-01-14 13:36:13.000000000,"[{'_account_id': 3}, {'_account_id': 7428}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-01-13 13:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/52a51f7385d278af1ce6e5e2d16941c860b769d2', 'message': ""Use regex to check if test belong to test set\n\nWhen discovering available tests regular expression will\nbe used to check to which test set given test belongs.\nThis prevent situation when 'test_sanity_sahara' was\nassigned to 'ha' test set because of occurrence of this words in\n'sahara'\n\nChange-Id: If7366da29da17404af3564e031e47e7ab39ba826\nCloses-Bug: #1359728\n""}, {'number': 2, 'created': '2015-01-14 11:10:28.000000000', 'files': ['fuel_plugin/testing/tests/unit/test_nose_discovery.py', 'fuel_plugin/ostf_adapter/nose_plugin/nose_discovery.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/70ecf3b93c406d3c77bb73d8dcbda5faf8a7fbf0', 'message': ""Use regex to check if test belong to test set\n\nWhen discovering available tests regular expression will\nbe used to check to which test set given test belongs.\nThis prevent situation when 'test_sanity_sahara' was\nassigned to 'ha' test set because of occurrence of this words in\n'sahara'\n\nChange-Id: If7366da29da17404af3564e031e47e7ab39ba826\nCloses-Bug: #1359728\n""}]",2,146870,70ecf3b93c406d3c77bb73d8dcbda5faf8a7fbf0,21,8,2,12200,,,0,"Use regex to check if test belong to test set

When discovering available tests regular expression will
be used to check to which test set given test belongs.
This prevent situation when 'test_sanity_sahara' was
assigned to 'ha' test set because of occurrence of this words in
'sahara'

Change-Id: If7366da29da17404af3564e031e47e7ab39ba826
Closes-Bug: #1359728
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/70/146870/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin/testing/tests/unit/test_nose_discovery.py', 'fuel_plugin/ostf_adapter/nose_plugin/nose_discovery.py']",2,52a51f7385d278af1ce6e5e2d16941c860b769d2,bug/1359728,"import re _test_pattern = r'(\b|_){0}(\b|_)' @classmethod def test_belongs_to_testset(cls, test_id, test_set_id): """"""Checks by name if test belongs to given test set."""""" test_set_pattern = re.compile(cls._test_pattern.format(test_set_id)) return bool(test_set_pattern.search(test_id)) if self.test_belongs_to_testset(test_id, test_set_id):", if test_set_id in test_id:,35,1
openstack%2Frequirements~stable%2Fjuno~I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697,openstack/requirements,stable/juno,I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697,Cap eventlet at <0.16.0,MERGED,2015-01-14 04:09:49.000000000,2015-01-14 13:35:24.000000000,2015-01-14 13:35:23.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9656}, {'_account_id': 13252}]","[{'number': 1, 'created': '2015-01-14 04:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a8b79c49ff359020f257e2a3cf038ef84b4ea0c7', 'message': 'Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util function in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697\nCloses-bug: #1410626\n'}, {'number': 2, 'created': '2015-01-14 08:43:01.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/577a40863a92328d7666dcc620a2763cd6eff566', 'message': 'Cap eventlet at <0.16.0\n\nEventlet removed the deprecated eventlet.util module in 0.16.0.\nThis caps stable branches to versions previous to that.\n\nChange-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697\nCloses-bug: #1410626\n'}]",0,147062,577a40863a92328d7666dcc620a2763cd6eff566,17,8,2,1420,,,0,"Cap eventlet at <0.16.0

Eventlet removed the deprecated eventlet.util module in 0.16.0.
This caps stable branches to versions previous to that.

Change-Id: I4bbbeb5bf9c22ed36f5c9a74fec6b487d2c15697
Closes-bug: #1410626
",git fetch https://review.opendev.org/openstack/requirements refs/changes/62/147062/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,a8b79c49ff359020f257e2a3cf038ef84b4ea0c7,,"eventlet>=0.15.1,<0.16.0",eventlet>=0.15.1,1,1
openstack%2Fnova~master~I3a205cf5ac2b3660872e2b56a3d96a62b1ab93c5,openstack/nova,master,I3a205cf5ac2b3660872e2b56a3d96a62b1ab93c5,use -out for openssl encrypted blobs,ABANDONED,2015-01-13 17:08:42.000000000,2015-01-14 13:29:29.000000000,,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}]","[{'number': 1, 'created': '2015-01-13 17:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f7a273d9b550387f2684d18f0ef217a927eea39', 'message': ""use -out for openssl encrypted blobs\n\noslo.concurrency 0.4.0 execute assumes that stdout is text in some\nvalid encoding. A set of our crypto operations were opperating as\nopenssl raw commands that were dumping binary encrypted data to\nstdout.\n\nAs this is encrypted data, it's safe to instead pass the information\nvia '-out' to a file that's in the tempdir we've created. This\nbypasses the oslo.concurrency restriction, and ensures no other future\nchanges to utilities that might provide stray output would impact\nthis.\n\nChange-Id: I3a205cf5ac2b3660872e2b56a3d96a62b1ab93c5\nRelated-Bug: #1410348\n""}, {'number': 2, 'created': '2015-01-13 17:15:44.000000000', 'files': ['nova/crypto.py', 'nova/tests/unit/test_crypto.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5456e21fa0f92c731dd977ff4cda376e595327e6', 'message': ""use -out for openssl encrypted blobs\n\noslo.concurrency 0.4.0 execute assumes that stdout is text in some\nvalid encoding. A set of our crypto operations were opperating as\nopenssl raw commands that were dumping binary encrypted data to\nstdout.\n\nAs this is encrypted data, it's safe to instead pass the information\nvia '-out' to a file that's in the tempdir we've created. This\nbypasses the oslo.concurrency restriction, and ensures no other future\nchanges to utilities that might provide stray output would impact\nthis.\n\nChange-Id: I3a205cf5ac2b3660872e2b56a3d96a62b1ab93c5\nRelated-Bug: #1410348\n""}]",2,146929,5456e21fa0f92c731dd977ff4cda376e595327e6,17,10,2,2750,,,0,"use -out for openssl encrypted blobs

oslo.concurrency 0.4.0 execute assumes that stdout is text in some
valid encoding. A set of our crypto operations were opperating as
openssl raw commands that were dumping binary encrypted data to
stdout.

As this is encrypted data, it's safe to instead pass the information
via '-out' to a file that's in the tempdir we've created. This
bypasses the oslo.concurrency restriction, and ensures no other future
changes to utilities that might provide stray output would impact
this.

Change-Id: I3a205cf5ac2b3660872e2b56a3d96a62b1ab93c5
Related-Bug: #1410348
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/146929/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/crypto.py', 'nova/tests/unit/test_crypto.py']",2,2f7a273d9b550387f2684d18f0ef217a927eea39,unittest_fix," out_key = os.path.join(tmpdir, ""out.key"") utils.execute('openssl', 'rsautl', '-certin', '-encrypt', '-inkey', public_key, '-out', out_key, process_input=text) with open(out_key) as f: enc = f.read() inkey = os.path.abspath(os.path.join(tmpdir, 'in.key')) with open(inkey, 'w') as f: f.write(text) try: # use the outfile because stdout is assumed to be text # in oslo.utils dec, _ = utils.execute('openssl', 'rsautl', '-decrypt', '-inkey', sshkey, '-in', inkey)"," enc, _err = utils.execute('openssl', 'rsautl', '-certin', '-encrypt', '-inkey', '%s' % public_key, process_input=text) try: dec, _err = utils.execute('openssl', 'rsautl', '-decrypt', '-inkey', sshkey, process_input=text)",31,19
openstack%2Fpbr~master~I18df9dfa3205ec22d29901a5a6414bf736435895,openstack/pbr,master,I18df9dfa3205ec22d29901a5a6414bf736435895,"remove integration test, it now lives in requirements",ABANDONED,2015-01-13 21:24:57.000000000,2015-01-14 13:24:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-01-13 21:24:57.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/e842495739042f6e2bb720a164fcfccd23f9915f', 'message': 'remove integration test, it now lives in requirements\n\nDepends-On: I37b1510f3639c332a13bd7fc892b66f71b99b594\n\nand\n\nChange-Id: I18df9dfa3205ec22d29901a5a6414bf736435895\nDepends-On: Ia49d93031425ce70e7667972fdf9078143d0dd53\n'}]",0,146982,e842495739042f6e2bb720a164fcfccd23f9915f,4,2,1,2750,,,0,"remove integration test, it now lives in requirements

Depends-On: I37b1510f3639c332a13bd7fc892b66f71b99b594

and

Change-Id: I18df9dfa3205ec22d29901a5a6414bf736435895
Depends-On: Ia49d93031425ce70e7667972fdf9078143d0dd53
",git fetch https://review.opendev.org/openstack/pbr refs/changes/82/146982/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,e842495739042f6e2bb720a164fcfccd23f9915f,req_integration,,"#!/bin/bash -xe function mkvenv { venv=$1 rm -rf $venv virtualenv $venv $venv/bin/pip install -U pip wheel # If a change to PBR is being tested, preinstall the wheel for it if [ -n ""$PBR_CHANGE"" ] ; then $venv/bin/pip install $pbrsdistdir/dist/pbr-*.whl fi } # BASE should be a directory with a subdir called ""new"" and in that # dir, there should be a git repository for every entry in PROJECTS BASE=${BASE:-/opt/stack} REPODIR=${REPODIR:-$BASE/new} # TODO: Figure out how to get this on to the box properly sudo apt-get install -y --force-yes libvirt-dev libxml2-dev libxslt-dev libmysqlclient-dev libpq-dev libnspr4-dev pkg-config libsqlite3-dev libzmq-dev libffi-dev libldap2-dev libsasl2-dev ccache # FOR numpy / pyyaml sudo apt-get build-dep -y --force-yes python-numpy sudo apt-get build-dep -y --force-yes python-yaml # And use ccache explitly export PATH=/usr/lib/ccache:$PATH tmpdir=$(mktemp -d) # Set up a wheelhouse export WHEELHOUSE=${WHEELHOUSE:-$tmpdir/.wheelhouse} export PIP_WHEEL_DIR=${PIP_WHEEL_DIR:-$WHEELHOUSE} export PIP_FIND_LINKS=${PIP_FIND_LINKS:-file://$WHEELHOUSE} mkvenv $tmpdir/wheelhouse # Not all packages properly build wheels (httpretty for example). # Do our best but ignore errors when making wheels. set +e grep -v '^#' $REPODIR/requirements/global-requirements.txt | while read req do $tmpdir/wheelhouse/bin/pip wheel ""$req"" done set -e #BRANCH BRANCH=${OVERRIDE_ZUUL_BRANCH=:-master} # PROJECTS is a list of projects that we're testing PROJECTS=$* pbrsdistdir=$tmpdir/pbrsdist git clone $REPODIR/pbr $pbrsdistdir cd $pbrsdistdir # Prepare a wheel and flag whether a change to PBR is being tested if git fetch $ZUUL_URL/$ZUUL_PROJECT $ZUUL_REF ; then mkvenv wheel wheel/bin/python setup.py bdist_wheel PBR_CHANGE=1 fi eptest=$tmpdir/eptest mkdir $eptest cd $eptest cat <<EOF > setup.cfg [metadata] name = test_project [entry_points] console_scripts = test_cmd = test_project:main [global] setup-hooks = pbr.hooks.setup_hook EOF cat <<EOF > setup.py import setuptools try: from requests import Timeout except ImportError: from pip._vendor.requests import Timeout from socket import error as SocketError # Some environments have network issues that drop connections to pypi # when running integration tests, so we retry here so that hour-long # test runs are less likely to fail randomly. try: setuptools.setup( setup_requires=['pbr'], pbr=True) except (SocketError, Timeout): setuptools.setup( setup_requires=['pbr'], pbr=True) EOF mkdir test_project cat <<EOF > test_project/__init__.py def main(): print ""Test cmd"" EOF epvenv=$eptest/venv mkvenv $epvenv eppbrdir=$tmpdir/eppbrdir git clone $REPODIR/pbr $eppbrdir $epvenv/bin/pip install -e $eppbrdir PBR_VERSION=0.0 $epvenv/bin/python setup.py install cat $epvenv/bin/test_cmd grep 'PBR Generated' $epvenv/bin/test_cmd $epvenv/bin/test_cmd | grep 'Test cmd' projectdir=$tmpdir/projects mkdir -p $projectdir for PROJECT in $PROJECTS ; do SHORT_PROJECT=$(basename $PROJECT) if ! grep 'pbr' $REPODIR/$SHORT_PROJECT/setup.py >/dev/null 2>&1 then # project doesn't use pbr continue fi if [ $SHORT_PROJECT = 'pypi-mirror' ]; then # pypi-mirror doesn't consume the mirror continue fi if [ $SHORT_PROJECT = 'jeepyb' ]; then # pypi-mirror doesn't consume the mirror continue fi if [ $SHORT_PROJECT = 'tempest' ]; then # Tempest doesn't really install continue fi if [ $SHORT_PROJECT = 'requirements' ]; then # requirements doesn't really install continue fi # set up the project synced with the global requirements sudo chown -R $USER $REPODIR/$SHORT_PROJECT (cd $REPODIR/requirements && python update.py $REPODIR/$SHORT_PROJECT) pushd $REPODIR/$SHORT_PROJECT if ! git diff --quiet ; then git commit -a -m'Update requirements' fi popd # Clone from synced repo shortprojectdir=$projectdir/$SHORT_PROJECT git clone $REPODIR/$SHORT_PROJECT $shortprojectdir # Test that we can make a tarball from scratch sdistvenv=$tmpdir/sdist mkvenv $sdistvenv cd $shortprojectdir $sdistvenv/bin/python setup.py sdist cd $tmpdir # Test that the tarball installs tarballvenv=$tmpdir/tarball mkvenv $tarballvenv $tarballvenv/bin/pip install $shortprojectdir/dist/*tar.gz # Test pip installing pipvenv=$tmpdir/pip mkvenv $pipvenv $pipvenv/bin/pip install git+file://$shortprojectdir # Test python setup.py install installvenv=$tmpdir/install mkvenv $installvenv installprojectdir=$projectdir/install$SHORT_PROJECT git clone $shortprojectdir $installprojectdir cd $installprojectdir $installvenv/bin/python setup.py install # Ensure the install_package_data is doing the thing it should do if [ $SHORT_PROJECT = 'nova' ]; then find $installvenv | grep migrate.cfg fi done ",0,194
openstack%2Fhorizon~master~If9832250332490a1e582e6a6679667569681863b,openstack/horizon,master,If9832250332490a1e582e6a6679667569681863b,Fix joint evaluation of angular hooks and jquery handlers,ABANDONED,2014-12-29 13:59:05.000000000,2015-01-14 12:34:23.000000000,,"[{'_account_id': 3}, {'_account_id': 8040}, {'_account_id': 9576}, {'_account_id': 11902}]","[{'number': 1, 'created': '2014-12-29 13:59:05.000000000', 'files': ['horizon/static/horizon/js/horizon.forms.js', 'horizon/templates/horizon/_scripts.html', 'horizon/static/horizon/js/horizon.tabs.js', 'horizon/static/horizon/js/horizon.modals.js', 'horizon/static/horizon/js/horizon.tables.js', 'horizon/static/horizon/js/horizon.instances.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/618c7341446dc284c6a3a575fcc5fe7fa2e83cf3', 'message': ""Fix joint evaluation of angular hooks and jquery handlers\n\nOnce any horizon jquery handler references the value being assigned\ninside the angular hook (namely, module.run() callback), the whole\nfile with jquery handlers should use deferred evaluation the same way\nthe angular hook does - otherwise it won't be able to properly use\ndata initialized in angular hook.\n\nChange-Id: If9832250332490a1e582e6a6679667569681863b\nCloses-Bug: #1406275\n""}]",0,144302,618c7341446dc284c6a3a575fcc5fe7fa2e83cf3,8,4,1,8040,,,0,"Fix joint evaluation of angular hooks and jquery handlers

Once any horizon jquery handler references the value being assigned
inside the angular hook (namely, module.run() callback), the whole
file with jquery handlers should use deferred evaluation the same way
the angular hook does - otherwise it won't be able to properly use
data initialized in angular hook.

Change-Id: If9832250332490a1e582e6a6679667569681863b
Closes-Bug: #1406275
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/144302/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.forms.js', 'horizon/static/horizon/js/horizon.tabs.js', 'horizon/templates/horizon/_scripts.html', 'horizon/static/horizon/js/horizon.modals.js', 'horizon/static/horizon/js/horizon.tables.js', 'horizon/static/horizon/js/horizon.instances.js']",6,618c7341446dc284c6a3a575fcc5fe7fa2e83cf3,bug/1406275,"angular.module('hz').run(function() { horizon.instances = { user_decided_length: false, user_volume_size: false, networks_selected: [], networks_available: [], getConsoleLog: function (via_user_submit) { var form_element = $(""#tail_length""), data; if (!via_user_submit) { via_user_submit = false; } if (this.user_decided_length) { data = $(form_element).serialize(); } else { data = ""length=35""; } $.ajax({ url: $(form_element).attr('action'), data: data, method: 'get', success: function (response_body) { $('pre.logs').text(response_body); }, error: function (response) { if (via_user_submit) { horizon.clearErrorMessages(); horizon.alert('error', gettext('There was a problem communicating with the server, please try again.')); } } }); }, /* * Gets the html select element associated with a given * network id for network_id. **/ get_network_element: function (network_id) { return $('li > label[for^=""id_network_' + network_id + '""]'); }, /* * Initializes an associative array of lists of the current * networks. **/ init_network_list: function () { horizon.instances.networks_selected = []; horizon.instances.networks_available = []; $(this.get_network_element("""")).each(function () { var $this = $(this); var $input = $this.children(""input""); var name = horizon.escape_html($this.text().replace(/^\s+/, """")); var network_property = { ""name"": name, ""id"": $input.attr(""id""), ""value"": $input.attr(""value"") }; if ($input.is("":checked"")) { horizon.instances.networks_selected.push(network_property); } else { horizon.instances.networks_available.push(network_property); } }, /* * Generates the HTML structure for a network that will be displayed * as a list item in the network list. **/ generate_network_element: function (name, id, value) { var $li = $('<li>'); $li.attr('name', value).html(name + '<em class=""network_id"">(' + value + ')</em><a href=""#"" class=""btn btn-primary""></a>'); return $li; }, /* * Generates the HTML structure for the Network List. **/ generate_networklist_html: function () { var self = this; var updateForm = function () { var lists = $(""#networkListId li"").attr('data-index', 100); var active_networks = $(""#selected_network > li"").map(function () { return $(this).attr(""name""); }); $(""#networkListId input:checkbox"").removeAttr('checked'); active_networks.each(function (index, value) { $(""#networkListId input:checkbox[value="" + value + ""]"") .prop('checked', true) .parents(""li"").attr('data-index', index); }); $(""#networkListId ul"").html( lists.sort(function (a, b) { if ($(a).data(""index"") < $(b).data(""index"")) { return -1; } if ($(a).data(""index"") > $(b).data(""index"")) { return 1; } return 0; }) ); }; $(""#networkListSortContainer"").show(); $(""#networkListIdContainer"").hide(); self.init_network_list(); // Make sure we don't duplicate the networks in the list $(""#available_network"").empty(); $.each(self.networks_available, function (index, value) { $(""#available_network"").append(self.generate_network_element(value.name, value.id, value.value)); // Make sure we don't duplicate the networks in the list $(""#selected_network"").empty(); $.each(self.networks_selected, function (index, value) { $(""#selected_network"").append(self.generate_network_element(value.name, value.id, value.value)); }); // $("".networklist > li"").click(function(){ // $(this).toggleClass(""ui-selected""); // }); $("".networklist > li > a.btn"").click(function (e) { var $this = $(this); e.preventDefault(); e.stopPropagation(); if ($this.parents(""ul#available_network"").length > 0) { $this.parent().appendTo($(""#selected_network"")); } else if ($this.parents(""ul#selected_network"").length > 0) { $this.parent().appendTo($(""#available_network"")); } }); if ($(""#networkListId > div.form-group.error"").length > 0) { var errortext = $(""#networkListId > div.form-group.error"").find(""span.help-block"").text(); $(""#selected_network_label"").before($('<div class=""dynamic-error"">').html(errortext)); } $("".networklist"").sortable({ connectWith: ""ul.networklist"", placeholder: ""ui-state-highlight"", distance: 5, start: function (e, info) { $(""#selected_network"").addClass(""dragging""); }, stop: function (e, info) { $(""#selected_network"").removeClass(""dragging""); updateForm(); } }).disableSelection(); }, workflow_init: function (modal) { // Initialise the drag and drop network list horizon.instances.generate_networklist_html(); } horizon.addInitFunction(horizon.instances.init = function () { $(document).on('submit', '#tail_length', function (evt) { horizon.instances.user_decided_length = true; horizon.instances.getConsoleLog(true); }); /* Launch instance workflow */ // Handle field toggles for the Launch Instance source type field function update_launch_source_displayed_fields(field) { var $this = $(field), base_type = $this.val(); $this.closest("".form-group"").nextAll().hide(); switch (base_type) { case ""image_id"": $(""#id_image_id"").closest("".form-group"").show(); break; case ""instance_snapshot_id"": $(""#id_instance_snapshot_id"").closest("".form-group"").show(); break; case ""volume_id"": $(""#id_volume_id, #id_delete_on_terminate"").closest("".form-group"").show(); break; case ""volume_image_id"": $(""#id_image_id, #id_volume_size, #id_device_name, #id_delete_on_terminate"") .closest("".form-group"").show(); break; case ""volume_snapshot_id"": $(""#id_volume_snapshot_id, #id_device_name, #id_delete_on_terminate"") .closest("".form-group"").show(); break; } } $(document).on('change', '.workflow #id_source_type', function (evt) { update_launch_source_displayed_fields(this); }); $('.workflow #id_source_type').change(); horizon.modals.addModalInitFunction(function (modal) { $(modal).find(""#id_source_type"").change(); }); /* Update the device size value to reflect minimum allowed for selected image and flavor */ function update_device_size() { var volume_size = horizon.Quota.getSelectedFlavor().disk; var image = horizon.Quota.getSelectedImage(); var size_field = $(""#id_volume_size""); if (image !== undefined && image.min_disk > volume_size) { volume_size = image.min_disk; } // If the user has manually changed the volume size, do not override // unless user-defined value is too small. if (horizon.instances.user_volume_size) { var user_value = size_field.val(); if (user_value > volume_size) { volume_size = user_value; } } // Make sure the new value is >= the minimum allowed (1GB) if (volume_size < 1) { volume_size = 1; } size_field.val(volume_size); } $(document).on('change', '.workflow #id_flavor', function (evt) { update_device_size(); }); $(document).on('change', '.workflow #id_image_id', function (evt) { update_device_size(); }); $(document).on('input', '.workflow #id_volume_size', function (evt) { horizon.instances.user_volume_size = true; // We only need to listen for the first user input to this field, // so remove the listener after the first time it gets called. $(document).off('input', '.workflow #id_volume_size'); }); horizon.instances.decrypt_password = function (encrypted_password, private_key) { var crypt = new JSEncrypt(); crypt.setKey(private_key); return crypt.decrypt(encrypted_password); }; $(document).on('change', '#id_private_key_file', function (evt) { var file = evt.target.files[0]; var reader = new FileReader(); if (file) { reader.onloadend = function (event) { $(""#id_private_key"").val(event.target.result); }; reader.onerror = function (event) { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not read the file')); }; reader.readAsText(file); } else { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not decrypt the password')); } }); /* The font-family is changed because with the default policy the major I and minor the l cannot be distinguished. */ $(document).on('show.bs.modal', '#password_instance_modal', function (evt) { $(""#id_decrypted_password"").css(""font-family"", ""monospace""); $(""#id_decrypted_password"").css(""cursor"", ""text""); $(""#id_encrypted_password"").css(""cursor"", ""text""); $(""#id_keypair_name"").css(""cursor"", ""text""); }); $(document).on('click', '#decryptpassword_button', function (evt) { encrypted_password = $(""#id_encrypted_password"").val(); private_key = $('#id_private_key').val(); if (!private_key) { evt.preventDefault(); $(this).closest('.modal').modal('hide'); } else { if (private_key.length > 0) { evt.preventDefault(); decrypted_password = horizon.instances.decrypt_password(encrypted_password, private_key); if (decrypted_password === false || decrypted_password === null) { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not decrypt the password')); } else { $(""#id_decrypted_password"").val(decrypted_password); $(""#decryptpassword_button"").hide(); } } } });});","horizon.instances = { user_decided_length: false, user_volume_size: false, networks_selected: [], networks_available: [], getConsoleLog: function(via_user_submit) { var form_element = $(""#tail_length""), data; if (!via_user_submit) { via_user_submit = false; } if(this.user_decided_length) { data = $(form_element).serialize(); } else { data = ""length=35""; } $.ajax({ url: $(form_element).attr('action'), data: data, method: 'get', success: function(response_body) { $('pre.logs').text(response_body); }, error: function(response) { if(via_user_submit) { horizon.clearErrorMessages(); horizon.alert('error', gettext('There was a problem communicating with the server, please try again.')); } } }); }, /* * Gets the html select element associated with a given * network id for network_id. **/ get_network_element: function(network_id) { return $('li > label[for^=""id_network_' + network_id + '""]'); }, /* * Initializes an associative array of lists of the current * networks. **/ init_network_list: function () { horizon.instances.networks_selected = []; horizon.instances.networks_available = []; $(this.get_network_element("""")).each(function () { var $this = $(this); var $input = $this.children(""input""); var name = horizon.escape_html($this.text().replace(/^\s+/, """")); var network_property = { ""name"": name, ""id"": $input.attr(""id""), ""value"": $input.attr(""value"") }; if ($input.is("":checked"")) { horizon.instances.networks_selected.push(network_property); } else { horizon.instances.networks_available.push(network_property); } }); }, /* * Generates the HTML structure for a network that will be displayed * as a list item in the network list. **/ generate_network_element: function(name, id, value) { var $li = $('<li>'); $li.attr('name', value).html(name + '<em class=""network_id"">(' + value + ')</em><a href=""#"" class=""btn btn-primary""></a>'); return $li; }, /* * Generates the HTML structure for the Network List. **/ generate_networklist_html: function() { var self = this; var updateForm = function() { var lists = $(""#networkListId li"").attr('data-index',100); var active_networks = $(""#selected_network > li"").map(function(){ return $(this).attr(""name""); $(""#networkListId input:checkbox"").removeAttr('checked'); active_networks.each(function(index, value){ $(""#networkListId input:checkbox[value="" + value + ""]"") .prop('checked', true) .parents(""li"").attr('data-index',index); $(""#networkListId ul"").html( lists.sort(function(a,b){ if( $(a).data(""index"") < $(b).data(""index"")) { return -1; } if( $(a).data(""index"") > $(b).data(""index"")) { return 1; } return 0; }) ); }; $(""#networkListSortContainer"").show(); $(""#networkListIdContainer"").hide(); self.init_network_list(); // Make sure we don't duplicate the networks in the list $(""#available_network"").empty(); $.each(self.networks_available, function(index, value){ $(""#available_network"").append(self.generate_network_element(value.name, value.id, value.value)); }); // Make sure we don't duplicate the networks in the list $(""#selected_network"").empty(); $.each(self.networks_selected, function(index, value){ $(""#selected_network"").append(self.generate_network_element(value.name, value.id, value.value)); }); // $("".networklist > li"").click(function(){ // $(this).toggleClass(""ui-selected""); // }); $("".networklist > li > a.btn"").click(function(e){ var $this = $(this); e.preventDefault(); e.stopPropagation(); if($this.parents(""ul#available_network"").length > 0) { $this.parent().appendTo($(""#selected_network"")); } else if ($this.parents(""ul#selected_network"").length > 0) { $this.parent().appendTo($(""#available_network"")); } updateForm(); }); if ($(""#networkListId > div.form-group.error"").length > 0) { var errortext = $(""#networkListId > div.form-group.error"").find(""span.help-block"").text(); $(""#selected_network_label"").before($('<div class=""dynamic-error"">').html(errortext)); } $("".networklist"").sortable({ connectWith: ""ul.networklist"", placeholder: ""ui-state-highlight"", distance: 5, start:function(e,info){ $(""#selected_network"").addClass(""dragging""); }, stop:function(e,info){ $(""#selected_network"").removeClass(""dragging""); } }).disableSelection(); }, workflow_init: function(modal) { // Initialise the drag and drop network list horizon.instances.generate_networklist_html(); } }; horizon.addInitFunction(horizon.instances.init = function () { $(document).on('submit', '#tail_length', function (evt) { horizon.instances.user_decided_length = true; horizon.instances.getConsoleLog(true); evt.preventDefault(); }); /* Launch instance workflow */ // Handle field toggles for the Launch Instance source type field function update_launch_source_displayed_fields (field) { var $this = $(field), base_type = $this.val(); $this.closest("".form-group"").nextAll().hide(); switch(base_type) { case ""image_id"": $(""#id_image_id"").closest("".form-group"").show(); break; case ""instance_snapshot_id"": $(""#id_instance_snapshot_id"").closest("".form-group"").show(); break; case ""volume_id"": $(""#id_volume_id, #id_delete_on_terminate"").closest("".form-group"").show(); break; case ""volume_image_id"": $(""#id_image_id, #id_volume_size, #id_device_name, #id_delete_on_terminate"") .closest("".form-group"").show(); break; case ""volume_snapshot_id"": $(""#id_volume_snapshot_id, #id_device_name, #id_delete_on_terminate"") .closest("".form-group"").show(); break; } } $(document).on('change', '.workflow #id_source_type', function (evt) { update_launch_source_displayed_fields(this); }); $('.workflow #id_source_type').change(); horizon.modals.addModalInitFunction(function (modal) { $(modal).find(""#id_source_type"").change(); }); /* Update the device size value to reflect minimum allowed for selected image and flavor */ function update_device_size() { var volume_size = horizon.Quota.getSelectedFlavor().disk; var image = horizon.Quota.getSelectedImage(); var size_field = $(""#id_volume_size""); if (image !== undefined && image.min_disk > volume_size) { volume_size = image.min_disk; } // If the user has manually changed the volume size, do not override // unless user-defined value is too small. if (horizon.instances.user_volume_size) { var user_value = size_field.val(); if (user_value > volume_size) { volume_size = user_value; } } // Make sure the new value is >= the minimum allowed (1GB) if (volume_size < 1) { volume_size = 1; } size_field.val(volume_size); } $(document).on('change', '.workflow #id_flavor', function (evt) { update_device_size(); }); $(document).on('change', '.workflow #id_image_id', function (evt) { update_device_size(); }); $(document).on('input', '.workflow #id_volume_size', function (evt) { horizon.instances.user_volume_size = true; // We only need to listen for the first user input to this field, // so remove the listener after the first time it gets called. $(document).off('input', '.workflow #id_volume_size'); }); horizon.instances.decrypt_password = function(encrypted_password, private_key) { var crypt = new JSEncrypt(); crypt.setKey(private_key); return crypt.decrypt(encrypted_password); $(document).on('change', '#id_private_key_file', function (evt) { var file = evt.target.files[0]; var reader = new FileReader(); if (file) { reader.onloadend = function(event) { $(""#id_private_key"").val(event.target.result); }; reader.onerror = function(event) { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not read the file')); }; reader.readAsText(file); } else { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not decrypt the password')); } }); /* The font-family is changed because with the default policy the major I and minor the l cannot be distinguished. */ $(document).on('show.bs.modal', '#password_instance_modal', function (evt) { $(""#id_decrypted_password"").css(""font-family"",""monospace""); $(""#id_decrypted_password"").css(""cursor"",""text""); $(""#id_encrypted_password"").css(""cursor"",""text""); $(""#id_keypair_name"").css(""cursor"",""text""); }); $(document).on('click', '#decryptpassword_button', function (evt) { encrypted_password = $(""#id_encrypted_password"").val(); private_key = $('#id_private_key').val(); if (!private_key) { $(this).closest('.modal').modal('hide'); } else { if (private_key.length > 0) { evt.preventDefault(); decrypted_password = horizon.instances.decrypt_password(encrypted_password, private_key); if (decrypted_password === false || decrypted_password === null) { horizon.clearErrorMessages(); horizon.alert('error', gettext('Could not decrypt the password')); } else { $(""#id_decrypted_password"").val(decrypted_password); $(""#decryptpassword_button"").hide(); } } }}); ",1566,1547
openstack%2Ffuel-main~master~Ie2b06be981db6a3b729c8cf55d190ce5c64394e7,openstack/fuel-main,master,Ie2b06be981db6a3b729c8cf55d190ce5c64394e7,Replace several calls with foreach,MERGED,2014-12-31 20:56:35.000000000,2015-01-14 12:21:19.000000000,2015-01-14 12:21:18.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-31 20:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9d30f86a8ac75b29908391fda841ba875babab3a', 'message': 'Replace several calls with foreach one liner\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\n'}, {'number': 2, 'created': '2015-01-02 13:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c96efaaed76bfeeaed8e31095b6fceeb2165b5c6', 'message': 'Replace several calls with foreach one liner\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2015-01-02 15:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4f5ed5e12b5fd51644a83475482898687b88c2c2', 'message': ""Replace several calls with foreach\n\n* Replace several calls with foreach\n* Replace several sudo invocations with 'sudo sh -c' in cleanup function\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 4, 'created': '2015-01-05 11:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6ddde5f6d0af52a71975e9ead93a10c28b6b6d9a', 'message': ""Replace several calls with foreach\n\n* Replace several calls with foreach\n* Replace several sudo invocations with 'sudo sh -c' in cleanup function\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 5, 'created': '2015-01-05 11:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6784fde1020d59f75ac29f42986e5503516f4c26', 'message': 'Replace several calls with foreach\n\n* Replace several calls with foreach\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 6, 'created': '2015-01-14 12:18:22.000000000', 'files': ['docker/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/669bd080967048f1270b3d183603e05a6b70486e', 'message': 'Replace several calls with foreach\n\n* Replace several calls with foreach\n\nChange-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",3,144661,669bd080967048f1270b3d183603e05a6b70486e,33,6,6,11090,,,0,"Replace several calls with foreach

* Replace several calls with foreach

Change-Id: Ie2b06be981db6a3b729c8cf55d190ce5c64394e7
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/61/144661/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/module.mk'],1,9d30f86a8ac75b29908391fda841ba875babab3a,tune_container,"containers:=astute cobbler mcollective nailgun keystone nginx ostf rsync rabbitmq postgres $(foreach cnt,$(containers),$(eval $(call build_container,$(cnt))))","$(eval $(call build_container,astute)) $(eval $(call build_container,cobbler)) $(eval $(call build_container,mcollective)) $(eval $(call build_container,nailgun)) $(eval $(call build_container,keystone)) $(eval $(call build_container,nginx)) $(eval $(call build_container,ostf)) $(eval $(call build_container,rsync)) $(eval $(call build_container,rabbitmq)) $(eval $(call build_container,postgres)) $(eval $(call build_container,rsyslog))",2,11
openstack%2Ffuel-main~master~Ic7b791843fdb1ecce3268968e7052124a2daf029,openstack/fuel-main,master,Ic7b791843fdb1ecce3268968e7052124a2daf029,Refactor Docker cleanup,MERGED,2015-01-05 12:06:18.000000000,2015-01-14 12:19:57.000000000,2015-01-14 12:19:57.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-01-05 12:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a8e1692a9a087bc2c8371b5f9cf868043bcf50fe', 'message': ""Refactor Docker cleanup\n\n* Removed timeout\n* Replaced several sudo commands with one 'sudo sh -c'\n\nChange-Id: Ic7b791843fdb1ecce3268968e7052124a2daf029\nImplements: blueprint support-ubuntu-trusty\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}, {'number': 2, 'created': '2015-01-14 12:19:02.000000000', 'files': ['mirror/docker/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/59b10c0d543af17eb88af43360df0f31337db68b', 'message': ""Refactor Docker cleanup\n\n* Removed timeout\n* Replaced several sudo commands with one 'sudo sh -c'\n\nChange-Id: Ic7b791843fdb1ecce3268968e7052124a2daf029\nImplements: blueprint support-ubuntu-trusty\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n""}]",1,144969,59b10c0d543af17eb88af43360df0f31337db68b,15,7,2,11090,,,0,"Refactor Docker cleanup

* Removed timeout
* Replaced several sudo commands with one 'sudo sh -c'

Change-Id: Ic7b791843fdb1ecce3268968e7052124a2daf029
Implements: blueprint support-ubuntu-trusty
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/69/144969/1 && git format-patch -1 --stdout FETCH_HEAD,['mirror/docker/module.mk'],1,a8e1692a9a087bc2c8371b5f9cf868043bcf50fe,bp/support-ubuntu-trusty," sudo sh -c 'docker ps && docker rm -f `docker ps -a | awk ""/fuel/ {print $$1}""` 2>/dev/null || true' sudo sh -c 'docker images && docker rmi -f `docker images | awk ""/fuel/ { print $$3; }""` 2>/dev/null || true'", timeout -k5 4 sudo docker ps && sudo docker rm -f `sudo docker ps -a | awk '/fuel/ {print $$1}'` || true timeout -k5 4 sudo docker images && sudo docker rmi -f `sudo docker images | awk '/fuel/ { print $$3; }'` || true,2,2
openstack%2Fopenstack-manuals~master~I8e339de36a940ba47712aebe05d7f7d5ddf5abc9,openstack/openstack-manuals,master,I8e339de36a940ba47712aebe05d7f7d5ddf5abc9,made change to intro to fw in networking guide,MERGED,2015-01-12 18:26:43.000000000,2015-01-14 12:06:49.000000000,2015-01-14 12:06:48.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 12402}]","[{'number': 1, 'created': '2015-01-12 18:26:43.000000000', 'files': ['doc/networking-guide/section_intro-firewalls.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b8a1612334740ee308f841fd1d54ddd78df7cb70', 'message': 'made change to intro to fw in networking guide\n\nadded additional documentation on fw\nadded “on” in sentence - necessary\n\nChange-Id: I8e339de36a940ba47712aebe05d7f7d5ddf5abc9\n'}]",0,146595,b8a1612334740ee308f841fd1d54ddd78df7cb70,8,4,1,9382,,,0,"made change to intro to fw in networking guide

added additional documentation on fw
added “on” in sentence - necessary

Change-Id: I8e339de36a940ba47712aebe05d7f7d5ddf5abc9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/95/146595/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/section_intro-firewalls.xml'],1,b8a1612334740ee308f841fd1d54ddd78df7cb70,ch_intro_fw," network traffic using a set of rules. Firewalls can be implemented in both hardware and software, or a mix of the two. For example, a firewall might internal networks, where data is trusted, and on external networks"," network traffic using a set of rules. For example, a firewall might internal networks, where data is trusted, and external networks",2,2
openstack%2Ffuel-library~stable%2F6.0~I2ad06db2d3c876c86afac3255bcddb865e057115,openstack/fuel-library,stable/6.0,I2ad06db2d3c876c86afac3255bcddb865e057115,Specify static defaults rather than variable,ABANDONED,2015-01-14 11:09:11.000000000,2015-01-14 12:01:21.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-01-14 11:09:11.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/57d5b3beb45746fcb735582b5477bcb7f4d40434', 'message': 'Specify static defaults rather than variable\n\n* Specify static file name for ulimits rather than using OCF_OCF_RESKEY_binary\n  as it may be specified with full path\n\nChange-Id: I2ad06db2d3c876c86afac3255bcddb865e057115\nCloses-Bug: 1405657\n'}]",0,147115,57d5b3beb45746fcb735582b5477bcb7f4d40434,7,2,1,11090,,,0,"Specify static defaults rather than variable

* Specify static file name for ulimits rather than using OCF_OCF_RESKEY_binary
  as it may be specified with full path

Change-Id: I2ad06db2d3c876c86afac3255bcddb865e057115
Closes-Bug: 1405657
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/15/147115/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,57d5b3beb45746fcb735582b5477bcb7f4d40434,bug/1405657, [ -f /etc/default/rabbitmq-server ] && . /etc/default/rabbitmq-server, [ -f /etc/default/${OCF_RESKEY_binary} ] && . /etc/default/${OCF_RESKEY_binary},1,1
openstack%2Fcinder~master~Ibd4b8f98dc197907f6df6f909b46d6b73acb2577,openstack/cinder,master,Ibd4b8f98dc197907f6df6f909b46d6b73acb2577,Allow remote FS drivers to use extra-specs to select share location,ABANDONED,2014-12-15 17:17:47.000000000,2015-01-14 11:45:27.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 10058}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-15 17:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/331019dcaa285d95ce3612cb667a2e97a6491dfb', 'message': 'Allow remote FS drivers to use extra-specs to select share location\n\nRemoteFSDriver only allows custom drivers to select the volume location based\nin the size of the volume. Some drivers might want to use another criteria\n(e.g. volume metadata) to select the share used.\n\nCloses-Bug: #1402756\nChange-Id: Ibd4b8f98dc197907f6df6f909b46d6b73acb2577\n'}, {'number': 2, 'created': '2014-12-16 19:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f47726fc426d7ce66a370188e9a4418602bdaafc', 'message': ""Allow remote FS drivers to use extra-specs to select share location\n\nNFS drivers relies in a function (_find_share) provided by RemoteFSDriver to choose among the available file systems. It only allows custom drivers to select the volume location based in the size of the volume. The selection is based on the free space available.\n\nIf a NFS driver wants to implement pool aware scheduling where each export will be in a different pool, the driver will not be able to select the best pool only with volume['size'] information. Also with the pool awareness, the size based selection makes no sense once the scheduler will select the pool using cinder filters.\n\nThis change modify _find_share() so it now takes a 'volume' reference as parameter and let the driver use other criteria like the extra-specs to make pool selection.\n\nCloses-Bug: #1402756\nChange-Id: Ibd4b8f98dc197907f6df6f909b46d6b73acb2577\n""}, {'number': 3, 'created': '2014-12-16 19:43:02.000000000', 'files': ['cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_smbfs.py', 'cinder/tests/test_nfs.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8254102ab627c9ea9d684b7bc1df0eb09b823097', 'message': ""Allow remote FS drivers to use extra-specs to select share location\n\nNFS drivers relies in a function (_find_share) provided by RemoteFSDriver to\nchoose among the available file systems. It only allows custom drivers to\nselect the volume location based in the size of the volume. The selection is\nbased on the free space available.  If a NFS driver wants to implement pool\naware scheduling where each export will be in a different pool, the driver will\nnot be able to select the best pool only with volume['size'] information. Also\nwith the pool awareness, the size based selection makes no sense once the\nscheduler will select the pool using cinder filters.\n\nThis change modify _find_share() so it now takes a 'volume' reference as\nparameter and let the driver use other criteria like the extra-specs to make\npool selection.NFS drivers relies in a function (_find_share) provided by\nRemoteFSDriver to choose among the available file systems. It only allows\ncustom drivers to select the volume location based in the size of the volume.\nThe selection is based on the free space available.  If a NFS driver wants to\nimplement pool aware scheduling where each export will be in a different pool,\nthe driver will not be able to select the best pool only with volume['size']\ninformation. Also with the pool awareness, the size based selection makes no\nsense once the scheduler will select the pool using cinder filters.\n\nThis change modifies _find_share() so it now takes a 'volume' reference as\nparameter and let the driver use other criteria like the extra-specs to make\npool selection.\n\nCloses-Bug: #1402756\nChange-Id: Ibd4b8f98dc197907f6df6f909b46d6b73acb2577\n""}]",0,141850,8254102ab627c9ea9d684b7bc1df0eb09b823097,22,9,3,10058,,,0,"Allow remote FS drivers to use extra-specs to select share location

NFS drivers relies in a function (_find_share) provided by RemoteFSDriver to
choose among the available file systems. It only allows custom drivers to
select the volume location based in the size of the volume. The selection is
based on the free space available.  If a NFS driver wants to implement pool
aware scheduling where each export will be in a different pool, the driver will
not be able to select the best pool only with volume['size'] information. Also
with the pool awareness, the size based selection makes no sense once the
scheduler will select the pool using cinder filters.

This change modify _find_share() so it now takes a 'volume' reference as
parameter and let the driver use other criteria like the extra-specs to make
pool selection.NFS drivers relies in a function (_find_share) provided by
RemoteFSDriver to choose among the available file systems. It only allows
custom drivers to select the volume location based in the size of the volume.
The selection is based on the free space available.  If a NFS driver wants to
implement pool aware scheduling where each export will be in a different pool,
the driver will not be able to select the best pool only with volume['size']
information. Also with the pool awareness, the size based selection makes no
sense once the scheduler will select the pool using cinder filters.

This change modifies _find_share() so it now takes a 'volume' reference as
parameter and let the driver use other criteria like the extra-specs to make
pool selection.

Closes-Bug: #1402756
Change-Id: Ibd4b8f98dc197907f6df6f909b46d6b73acb2577
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/141850/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/smbfs.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/tests/test_smbfs.py', 'cinder/tests/test_nfs.py', 'cinder/volume/drivers/ibm/ibmnas.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/remotefs.py', 'cinder/tests/test_glusterfs.py']",8,331019dcaa285d95ce3612cb667a2e97a6491dfb,nfs-pool-fix, volume = {'size': self.TEST_SIZE_IN_GB} volume) volume = {'size': self.TEST_SIZE_IN_GB} drv._find_share(volume)) volume = {'size': self.TEST_SIZE_IN_GB} volume) drv._find_share(volume).AndReturn(self.TEST_EXPORT1) mox.ReplayAll() drv._find_share(new_volume).AndReturn(self.TEST_EXPORT1), self.TEST_SIZE_IN_GB) drv._find_share(self.TEST_SIZE_IN_GB)) self.TEST_SIZE_IN_GB) drv._find_share(self.TEST_SIZE_IN_GB).AndReturn(self.TEST_EXPORT1) mox.ReplayAll() drv._find_share(new_volume['size']).AndReturn(self.TEST_EXPORT1),37,25
openstack%2Fnova~master~If0a79ef31ea93d2d237538b3a2d6d3db957e1937,openstack/nova,master,If0a79ef31ea93d2d237538b3a2d6d3db957e1937,Updated from global requirements,MERGED,2015-01-13 00:11:32.000000000,2015-01-14 11:41:00.000000000,2015-01-14 02:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}]","[{'number': 1, 'created': '2015-01-13 00:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f45a8f3b253d5617d7d50f644b8519d24c6b3d16', 'message': 'Updated from global requirements\n\nChange-Id: If0a79ef31ea93d2d237538b3a2d6d3db957e1937\n'}, {'number': 2, 'created': '2015-01-14 00:10:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/f078f20daca9f1c21023388d9cba3bd46449d9a7', 'message': 'Updated from global requirements\n\nChange-Id: If0a79ef31ea93d2d237538b3a2d6d3db957e1937\n'}]",0,146700,f078f20daca9f1c21023388d9cba3bd46449d9a7,23,10,2,11131,,,0,"Updated from global requirements

Change-Id: If0a79ef31ea93d2d237538b3a2d6d3db957e1937
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/146700/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f45a8f3b253d5617d7d50f644b8519d24c6b3d16,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fbarbican~master~I49f3911170bc1780502ab83efb25517dbea34b98,openstack/barbican,master,I49f3911170bc1780502ab83efb25517dbea34b98,Adding a plugin to interact with HP Atalla ESKM,ABANDONED,2014-08-26 12:30:32.000000000,2015-01-14 11:30:37.000000000,,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 1528}, {'_account_id': 5046}, {'_account_id': 6783}, {'_account_id': 7063}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 10873}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-08-26 12:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d667d49382733448156494bee09b49b667358639', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 2, 'created': '2014-08-26 12:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/33cf803d74711fcb8450bbc5fc5fe1ae505ce617', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 3, 'created': '2014-08-26 12:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7c71135ecffa2c57394f17c8ad0b129f4d85c2e9', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 4, 'created': '2014-08-26 14:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f5113b4627a14cbf4fed912419ab473bb73b32c7', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 5, 'created': '2014-09-01 14:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c098bba6c17ed36ebdaa370d91f78b751022fe98', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 6, 'created': '2014-09-03 12:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/eb8cd3536317f3251940c7ac0e2dbe559edae1c0', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 7, 'created': '2014-09-04 13:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e64190fbfc0b21878a167f5b6676d621d50b5abc', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 8, 'created': '2014-09-04 14:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a71ea816fc8197349e2a38972bd56d814ad3441a', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 9, 'created': '2014-09-08 12:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/819597cce3c179d7e34fb03ad849e3d3569ac916', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 10, 'created': '2014-09-10 10:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/2222e9d2575e3fe8637dd0af4c0b31cd58c416e5', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 11, 'created': '2014-09-19 10:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f756dcd78542e812e5e297dad42226f57383187f', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 12, 'created': '2014-09-30 10:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0342e1318a30f326190649a1533c5d2b85808ff3', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 13, 'created': '2014-09-30 10:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/41dc538d61ae6ef9e3a98b282e93369209756f26', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 14, 'created': '2014-10-06 15:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/442a3726eda12bd295c8a7d2c33b8966a487b59b', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}, {'number': 15, 'created': '2014-10-31 14:50:42.000000000', 'files': ['etc/barbican/barbican-api.conf', 'requirements.txt', 'barbican/plugin/crypto/eskm_crypto.py', 'barbican/tests/plugin/crypto/test_eskm.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican/commit/7ebadc93d168d5a6d274dcc9f8b0de71c48e1bf8', 'message': 'Adding a plugin to interact with HP Atalla ESKM\n\nThis adds a new crypto plugin to use a HP Atalla ESKM appliance as\na HSM backend for Barbican.\n\nsec-impact\nimplements: blueprint hp-eskm-plugin\n\nChange-Id: I49f3911170bc1780502ab83efb25517dbea34b98\n'}]",73,116878,7ebadc93d168d5a6d274dcc9f8b0de71c48e1bf8,67,11,15,11716,,,0,"Adding a plugin to interact with HP Atalla ESKM

This adds a new crypto plugin to use a HP Atalla ESKM appliance as
a HSM backend for Barbican.

sec-impact
implements: blueprint hp-eskm-plugin

Change-Id: I49f3911170bc1780502ab83efb25517dbea34b98
",git fetch https://review.opendev.org/openstack/barbican refs/changes/78/116878/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'barbican/plugin/crypto/eskm_crypto.py', 'barbican/tests/plugin/crypto/test_eskm.py', 'setup.cfg']",4,d667d49382733448156494bee09b49b667358639,bp/hp-eskm-plugin, eskm_crypto = barbican.plugin.crypto.eskm_crypto:EskmCryptoPlugin,,839,0
openstack%2Ffuel-astute~master~I9c1ffb4211794f87e79816607776bd6534d83d42,openstack/fuel-astute,master,I9c1ffb4211794f87e79816607776bd6534d83d42,Idling nodes: strong detection,ABANDONED,2014-12-03 17:14:32.000000000,2015-01-14 11:25:42.000000000,,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-03 17:14:32.000000000', 'files': ['spec/unit/puppetd_spec.rb', 'mcagents/puppetd.rb', 'lib/astute/puppetd.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/1fdb8d8cef3f23bc9b907d27d529ca0c36d35f1b', 'message': ""Idling nodes: strong detection\n\nProblem with unexpecting hung 'idling' error\nhave such symptoms:\n- puppet status - 'stopped'\n- run 'runonce' command as usual;\n- unexpecting puppet status - 'stopped' with message\n  'Process not running but not empty lockfile is present'\n- Retrying to run puppet for following error nodes\n- puppet status 'idling';\n- Following nodes have puppet hung\n\nChanges for magent:\n- locked status now verify actual and expecting pid;\n- runonce operation in case of idling status now only\n  kill process (strong kill) and do not run it again.\n\nChanges for Astute:\n- runonce operation also will including 'idling' nodes;\n- but 'idling' nodes as 'running' will be check in cycle as before.\n\nChange-Id: I9c1ffb4211794f87e79816607776bd6534d83d42\nCloses-Bug: #1392779\n""}]",0,138790,1fdb8d8cef3f23bc9b907d27d529ca0c36d35f1b,6,4,1,8776,,,0,"Idling nodes: strong detection

Problem with unexpecting hung 'idling' error
have such symptoms:
- puppet status - 'stopped'
- run 'runonce' command as usual;
- unexpecting puppet status - 'stopped' with message
  'Process not running but not empty lockfile is present'
- Retrying to run puppet for following error nodes
- puppet status 'idling';
- Following nodes have puppet hung

Changes for magent:
- locked status now verify actual and expecting pid;
- runonce operation in case of idling status now only
  kill process (strong kill) and do not run it again.

Changes for Astute:
- runonce operation also will including 'idling' nodes;
- but 'idling' nodes as 'running' will be check in cycle as before.

Change-Id: I9c1ffb4211794f87e79816607776bd6534d83d42
Closes-Bug: #1392779
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/90/138790/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/puppetd_spec.rb', 'mcagents/puppetd.rb', 'lib/astute/puppetd.rb']",3,1fdb8d8cef3f23bc9b907d27d529ca0c36d35f1b,bug/1392779," summary_results = puppetd(uids).last_run_summary running_uids = summary_results.select { |x| ['running'].include?(x.results[:data][:status]) idling_uids = summary_results.select { |x| ['idling'].include?(x.results[:data][:status]) }.map { |n| n.results[:sender] } # Try to kill 'idling' process and run again by 'runonce' call break if running_uids.empty? && idling_uids.empty? # Nodes on idling_uids can have 2 status after runonce call: # 'stopped' or 'idling'. Stopped - good, idling - hung. uids = running_uids + idling_uids if running_uids.present? || idling_uids.present? Astute.logger.warn ""Following nodes have puppet hung: \n "" \ ""running - '#{running_uids.join(',')}' \n "" \ ""idling - #{idling_uids.join(',')}"" end running_uids + idling_uids puppetd.on_respond_timeout do |error_uids| nodes = error_uids.map do |uid|"," running_uids = puppetd(uids).last_run_summary.select { |x| ['running', 'idling'].include?(x.results[:data][:status]) break if running_uids.empty? uids = running_uids Astute.logger.warn ""Following nodes have puppet hung: '#{running_uids.join(',')}'"" if running_uids.present? running_uids puppetd.on_respond_timeout do |uids| nodes = uids.map do |uid|",74,25
openstack%2Fglance_store~master~I735dc99722b30376dac50beeb97bdafb01046187,openstack/glance_store,master,I735dc99722b30376dac50beeb97bdafb01046187,Remove deprecated options,MERGED,2014-12-02 09:26:45.000000000,2015-01-14 11:24:17.000000000,2015-01-14 11:24:16.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 6549}, {'_account_id': 11356}, {'_account_id': 11391}]","[{'number': 1, 'created': '2014-12-02 09:26:45.000000000', 'files': ['glance_store/backend.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/ad6d0b11a8cb21711faf3bf73357336c7faa3cae', 'message': 'Remove deprecated options\n\nThe patch removes the already deprecated store config parameters.\n\nChange-Id: I735dc99722b30376dac50beeb97bdafb01046187\n'}]",0,138289,ad6d0b11a8cb21711faf3bf73357336c7faa3cae,11,6,1,6159,,,0,"Remove deprecated options

The patch removes the already deprecated store config parameters.

Change-Id: I735dc99722b30376dac50beeb97bdafb01046187
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/89/138289/1 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/backend.py'],1,ad6d0b11a8cb21711faf3bf73357336c7faa3cae,," help=_('List of stores enabled')), ""defined by the 'stores' config option."")) driver_opts += driver_cls.OPTIONS","_DEPRECATED_STORE_OPTS = [ cfg.DeprecatedOpt('known_stores', group='DEFAULT'), cfg.DeprecatedOpt('default_store', group='DEFAULT') ] help=_('List of stores enabled'), deprecated_opts=[_DEPRECATED_STORE_OPTS[0]]), ""defined by the 'stores' config option.""), deprecated_opts=[_DEPRECATED_STORE_OPTS[1]]) # NOTE(flaper87): To be removed in k-2. This should # give deployers enough time to migrate their systems # and move configs under the new section. for opt in driver_cls.OPTIONS: opt.deprecated_opts = [cfg.DeprecatedOpt(opt.name, group='DEFAULT')] driver_opts.append(opt)",3,16
openstack%2Fgnocchi~master~If7abef5db97172f13cca1ac32e6d1d5d8e334d05,openstack/gnocchi,master,If7abef5db97172f13cca1ac32e6d1d5d8e334d05,Upgrade to hacking 0.10,MERGED,2015-01-13 13:01:17.000000000,2015-01-14 11:23:42.000000000,2015-01-14 11:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-01-13 13:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a4b24a189649090a47a095258add22a80a9d3e53', 'message': 'Upgrade to hacking 0.10\n\nChange-Id: If7abef5db97172f13cca1ac32e6d1d5d8e334d05\n'}, {'number': 2, 'created': '2015-01-14 10:31:27.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/archive_policy.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/78e50623c84ba87bbc1936b590414214de1c230b', 'message': 'Upgrade to hacking 0.10\n\nChange-Id: If7abef5db97172f13cca1ac32e6d1d5d8e334d05\n'}]",0,146846,78e50623c84ba87bbc1936b590414214de1c230b,13,3,2,1669,,,0,"Upgrade to hacking 0.10

Change-Id: If7abef5db97172f13cca1ac32e6d1d5d8e334d05
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/46/146846/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/archive_policy.py', 'test-requirements.txt', 'test-requirements-py3.txt', 'tox.ini']",5,a4b24a189649090a47a095258add22a80a9d3e53,jd/hacking,,"deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt hacking>=0.9.2,<0.10",2,7
openstack%2Fglance~master~Idf5c22d788317ab009936cc82923a40147910c28,openstack/glance,master,Idf5c22d788317ab009936cc82923a40147910c28,Reuse methods from netutils,ABANDONED,2014-12-23 08:43:14.000000000,2015-01-14 11:16:37.000000000,,"[{'_account_id': 3}, {'_account_id': 7491}, {'_account_id': 11864}, {'_account_id': 12000}, {'_account_id': 12299}, {'_account_id': 12952}]","[{'number': 1, 'created': '2014-12-23 08:43:14.000000000', 'files': ['glance/tests/unit/common/test_utils.py', 'glance/common/utils.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c4e894c6336f7668eb2c389d7e237661e5371eae', 'message': 'Reuse methods from netutils\n\nReplace usages of is_valid_ipv4, is_valid_ipv6 from Glance,\nby usages of this methods from oslo.utils and remove these\nmethods from Glance code.\n\nChange-Id: Idf5c22d788317ab009936cc82923a40147910c28\n'}]",0,143624,c4e894c6336f7668eb2c389d7e237661e5371eae,9,6,1,9796,,,0,"Reuse methods from netutils

Replace usages of is_valid_ipv4, is_valid_ipv6 from Glance,
by usages of this methods from oslo.utils and remove these
methods from Glance code.

Change-Id: Idf5c22d788317ab009936cc82923a40147910c28
",git fetch https://review.opendev.org/openstack/glance refs/changes/24/143624/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/common/test_utils.py', 'glance/common/utils.py']",2,c4e894c6336f7668eb2c389d7e237661e5371eae,use_netutils, if not (netutils.is_valid_ip(host) or is_valid_hostname(host) or is_valid_fqdn(host)):,"import netaddrdef is_valid_ipv4(address): """"""Verify that address represents a valid IPv4 address."""""" try: return netaddr.valid_ipv4(address) except Exception: return False def is_valid_ipv6(address): """"""Verify that address represents a valid IPv6 address."""""" try: return netaddr.valid_ipv6(address) except Exception: return False if not (is_valid_ipv6(host) or is_valid_ipv4(host) or is_valid_hostname(host) or is_valid_fqdn(host)):",2,70
openstack%2Fopenstack-ansible~juno~I335743fe253bd501401208baf6aa8e772ba641f0,openstack/openstack-ansible,juno,I335743fe253bd501401208baf6aa8e772ba641f0,Run horizon-manage.py script as {{ system_user }},MERGED,2015-01-09 15:23:59.000000000,2015-01-14 11:10:20.000000000,2015-01-14 11:10:20.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 7217}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-01-09 15:23:59.000000000', 'files': ['rpc_deployment/inventory/group_vars/horizon.yml', 'rpc_deployment/roles/horizon_common/tasks/main.yml', 'rpc_deployment/roles/horizon_setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/86dcfe4587b662207d756d1743f961451c48c6a5', 'message': 'Run horizon-manage.py script as {{ system_user }}\n\nCurrently, we seem to always have 1/3 horizon nodes where\n/var/lib/horizon/.secret_key_store is owned by root which breaks\nhorizon logins.  This appears to be a result of running\nhorizon-manage.py syncdb as root (which only happens on 1/3 nodes).\nThis change moves all horizon-manage.py commands to run as\n{{ system_user }}, which requires us to also pre-create some dirs\nowned by {{ system_user }} by adding them to container_directories so\nthat the horizon-manage.py commands will all complete successfully.\n\nLastly, we remove the creation of /etc/horizon and the chown of files\nin {{ install_lib_dir }}/static in heat_common role since those have\nbeen added to container_directories.\n\nChange-Id: I335743fe253bd501401208baf6aa8e772ba641f0\nCloses-Bug: #1399368\n(cherry picked from commit da560992ba208c79e642c8920f0b638220d49222)\n'}]",0,146114,86dcfe4587b662207d756d1743f961451c48c6a5,8,4,1,7307,,,0,"Run horizon-manage.py script as {{ system_user }}

Currently, we seem to always have 1/3 horizon nodes where
/var/lib/horizon/.secret_key_store is owned by root which breaks
horizon logins.  This appears to be a result of running
horizon-manage.py syncdb as root (which only happens on 1/3 nodes).
This change moves all horizon-manage.py commands to run as
{{ system_user }}, which requires us to also pre-create some dirs
owned by {{ system_user }} by adding them to container_directories so
that the horizon-manage.py commands will all complete successfully.

Lastly, we remove the creation of /etc/horizon and the chown of files
in {{ install_lib_dir }}/static in heat_common role since those have
been added to container_directories.

Change-Id: I335743fe253bd501401208baf6aa8e772ba641f0
Closes-Bug: #1399368
(cherry picked from commit da560992ba208c79e642c8920f0b638220d49222)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/14/146114/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/inventory/group_vars/horizon.yml', 'rpc_deployment/roles/horizon_common/tasks/main.yml', 'rpc_deployment/roles/horizon_setup/tasks/main.yml']",3,86dcfe4587b662207d756d1743f961451c48c6a5,bug/1399368,"# This will create /var/lib/horizon/.secret_key_store, which needs to be owned # by {{ system_user }}, otherwise horizon logins will fail sudo: yes sudo_user: ""{{ system_user }}""","# Unlike the 'db sync' command run in other projects, we do not run this under # horizon's {{ system_user }} as horizon is run through Apache and logs are # written to as root",8,21
openstack%2Fzaqar~master~Ie9f5636b4cdb91a81dcb9f3edf9b1e2f2965d4e4,openstack/zaqar,master,Ie9f5636b4cdb91a81dcb9f3edf9b1e2f2965d4e4,Invalid grave accents at the end of the mongodb installation URLs,MERGED,2015-01-12 02:01:24.000000000,2015-01-14 10:55:28.000000000,2015-01-14 10:55:27.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 14577}]","[{'number': 1, 'created': '2015-01-12 02:01:24.000000000', 'files': ['doc/source/development-environment.rst'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b5043ccac231edeba2ec23219f13f60f13042b04', 'message': 'Invalid grave accents at the end of the mongodb installation URLs\n\nChange-Id: Ie9f5636b4cdb91a81dcb9f3edf9b1e2f2965d4e4\n'}]",0,146364,b5043ccac231edeba2ec23219f13f60f13042b04,9,4,1,14577,,,0,"Invalid grave accents at the end of the mongodb installation URLs

Change-Id: Ie9f5636b4cdb91a81dcb9f3edf9b1e2f2965d4e4
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/64/146364/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/development-environment.rst'],1,b5043ccac231edeba2ec23219f13f60f13042b04,broken-url,".. _`MongoDB on Ubuntu installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/.. _`MongoDB on Red Hat Enterprise, CentOS, Fedora, or Amazon Linux installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-red-hat-centos-or-fedora-linux/.. _GerritWorkflow: http://docs.openstack.org/infra/manual/developers.html#development-workflow ",".. _`MongoDB on Ubuntu installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/`.. _`MongoDB on Red Hat Enterprise, CentOS, Fedora, or Amazon Linux installation guide`: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-red-hat-centos-or-fedora-linux/`... _GerritWorkflow: http://docs.openstack.org/infra/manual/developers.html#development-workflow",3,3
openstack%2Ffuel-ostf~master~Id73208c3b0a000c017ec44388e3cecc78d2228a5,openstack/fuel-ostf,master,Id73208c3b0a000c017ec44388e3cecc78d2228a5,Cleaned and made integration tests working,MERGED,2015-01-07 09:35:26.000000000,2015-01-14 10:53:57.000000000,2015-01-14 10:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-01-07 09:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/95503317f0f8977edabd0222f74fe575a842d303', 'message': 'Cleaned and made integration tests working\n\n * they can be run now by tox -epy26 -- fuel_plugin/testing/tests/\n * removed code that mimic nailgun\n * used requests_mock to mock http requests\n * added BaseIntegrationTest class that set ups DB\n\nChange-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5\nPartial-Bug: #1404892\n'}, {'number': 2, 'created': '2015-01-07 09:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/2c12cad29b86525471235131f514127c7e93750f', 'message': 'Cleaned and made integration tests working\n\n * can be run by tox -epy26 -- fuel_plugin/testing/tests/integration\n * removed code that mimic nailgun\n * used requests_mock to mock http requests\n * added BaseIntegrationTest class that set ups DB\n\nChange-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5\nPartial-Bug: #1404892\n'}, {'number': 3, 'created': '2015-01-08 08:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/62ed268f1fc74ffe04a6afc83c6e8bd444feea2a', 'message': 'Cleaned and made integration tests working\n\n * can be run by tox -epy26 -- fuel_plugin/testing/tests/integration\n * removed code that mimic nailgun\n * used requests_mock to mock http requests\n * added BaseIntegrationTest class that set ups DB\n\nChange-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5\nPartial-Bug: #1404892\n'}, {'number': 4, 'created': '2015-01-12 14:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e537d776567958f4ad2d37b5bb03c7fb07c21b75', 'message': 'Cleaned and made integration tests working\n\n * can be run by tox -epy26 -- fuel_plugin/testing/tests/integration\n * removed code that mimic nailgun\n * used requests_mock to mock http requests\n * added BaseIntegrationTest class that set ups DB\n * it is possible to pass own session when creating\n   Pecan app for OSTF\n * added WebTest as a requirement for tests\n\nChange-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5\nPartial-Bug: #1404892\n'}, {'number': 5, 'created': '2015-01-13 08:43:04.000000000', 'files': ['fuel_plugin/testing/tests/integration/test_wsgi_interface.py', 'fuel_plugin/testing/tests/functional/tests.py', 'test-requirements.txt', 'fuel_plugin/ostf_adapter/storage/engine.py', 'fuel_plugin/testing/tests/base.py', 'fuel_plugin/testing/tests/integration/tests_wsgi_interface.py', 'fuel_plugin/testing/test_utils/__init__.py', 'fuel_plugin/testing/test_utils/nailgun_mimic.py', 'fuel_plugin/testing/tests/integration/test_wsgi_controllers.py', 'fuel_plugin/ostf_adapter/wsgi/app.py', 'fuel_plugin/testing/test_utils/pylintrc', 'fuel_plugin/ostf_adapter/wsgi/hooks.py', 'fuel_plugin/testing/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/98d0287158dfb8e5994ac43bbb5d6d4f69df09c6', 'message': 'Cleaned and made integration tests working\n\n * can be run by tox -epy26 -- fuel_plugin/testing/tests/integration\n * removed code that mimic nailgun\n * used requests_mock to mock http requests\n * added BaseIntegrationTest class that set ups DB\n * it is possible to pass own session when creating\n   Pecan app for OSTF\n * added WebTest as a requirement for tests\n\nChange-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5\nPartial-Bug: #1404892\n'}]",5,145445,98d0287158dfb8e5994ac43bbb5d6d4f69df09c6,33,11,5,12200,,,0,"Cleaned and made integration tests working

 * can be run by tox -epy26 -- fuel_plugin/testing/tests/integration
 * removed code that mimic nailgun
 * used requests_mock to mock http requests
 * added BaseIntegrationTest class that set ups DB
 * it is possible to pass own session when creating
   Pecan app for OSTF
 * added WebTest as a requirement for tests

Change-Id: Id73208c3b0a000c017ec44388e3cecc78d2228a5
Partial-Bug: #1404892
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/45/145445/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin/testing/tests/integration/test_wsgi_interface.py', 'fuel_plugin/testing/tests/functional/tests.py', 'test-requirements.txt', 'fuel_plugin/testing/test_utils/pylintrc', 'fuel_plugin/testing/tests/base.py', 'fuel_plugin/testing/test_utils/__init__.py', 'fuel_plugin/testing/test_utils/nailgun_mimic.py', 'fuel_plugin/testing/tests/integration/test_wsgi_controllers.py', 'fuel_plugin/testing/tests/__init__.py']",9,95503317f0f8977edabd0222f74fe575a842d303,bug/1404892,,"# Copyright 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import signal import subprocess import time processes_pool = None def setup(): global processes_pool with open('/dev/null', 'w') as devnull: processes_pool = tuple( [ subprocess.Popen( [ 'python', 'fuel_plugin/testing/test_utils/nailgun_mimic.py' ], stdout=devnull, stderr=devnull ), subprocess.Popen( [ 'ostf-server', '--debug', ('--debug_tests=fuel_plugin/testing/' 'fixture/dummy_tests') ], stdout=devnull, stderr=devnull ) ] ) time.sleep(5) def teardown(): for process in processes_pool: process.send_signal(signal.SIGINT) process.wait() ",105,483
openstack%2Fzaqar~master~I4e69a89931995d081b1c636c24a62fad369e67bf,openstack/zaqar,master,I4e69a89931995d081b1c636c24a62fad369e67bf,Updated from global requirements,MERGED,2015-01-08 18:52:19.000000000,2015-01-14 10:49:43.000000000,2015-01-14 10:49:41.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-01-08 18:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/45ae9bd6fdd31380ed0d11a4e6ed357b937c2c39', 'message': 'Updated from global requirements\n\nChange-Id: I4e69a89931995d081b1c636c24a62fad369e67bf\n'}, {'number': 2, 'created': '2015-01-09 18:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7527cc0bff133ef9ab13fb39857964e7f8c69477', 'message': 'Updated from global requirements\n\nChange-Id: I4e69a89931995d081b1c636c24a62fad369e67bf\n'}, {'number': 3, 'created': '2015-01-13 00:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/473963b78fec69282312568ff3ad1ce4d612f7c7', 'message': 'Updated from global requirements\n\nChange-Id: I4e69a89931995d081b1c636c24a62fad369e67bf\n'}, {'number': 4, 'created': '2015-01-14 00:16:56.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/15426c6d920e526920283d0794387050f2f4d39d', 'message': 'Updated from global requirements\n\nChange-Id: I4e69a89931995d081b1c636c24a62fad369e67bf\n'}]",0,145903,15426c6d920e526920283d0794387050f2f4d39d,12,2,4,11131,,,0,"Updated from global requirements

Change-Id: I4e69a89931995d081b1c636c24a62fad369e67bf
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/03/145903/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,45ae9bd6fdd31380ed0d11a4e6ed357b937c2c39,openstack/requirements,oslo.config>=1.6.0 # Apache-2.0,oslo.config>=1.4.0 # Apache-2.0,2,2
openstack%2Fneutron~master~I46cf187bcad7ddd35cd2dc48ed6e7edcf3c498e8,openstack/neutron,master,I46cf187bcad7ddd35cd2dc48ed6e7edcf3c498e8,"Revert ""IpsetManager refactoring""",ABANDONED,2015-01-14 03:41:01.000000000,2015-01-14 10:44:41.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-01-14 03:41:01.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py', 'neutron/tests/functional/agent/linux/test_ipset.py', 'neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/tests/unit/test_iptables_firewall.py', 'neutron/agent/linux/ipset_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2768e7696b31482789debb6fc4602c67613a5f4b', 'message': 'Revert ""IpsetManager refactoring""\n\nThis reverts commit dcd4a11258d2cebbb2f08bd6386e2c8dac0039b2 just\nto see if it\'s related to the DHCP failures.\n\nChange-Id: I46cf187bcad7ddd35cd2dc48ed6e7edcf3c498e8\n'}]",0,147059,2768e7696b31482789debb6fc4602c67613a5f4b,24,17,1,7787,,,0,"Revert ""IpsetManager refactoring""

This reverts commit dcd4a11258d2cebbb2f08bd6386e2c8dac0039b2 just
to see if it's related to the DHCP failures.

Change-Id: I46cf187bcad7ddd35cd2dc48ed6e7edcf3c498e8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/147059/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/iptables_firewall.py', 'neutron/tests/functional/agent/linux/test_ipset.py', 'neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/tests/unit/test_iptables_firewall.py', 'neutron/agent/linux/ipset_manager.py']",5,2768e7696b31482789debb6fc4602c67613a5f4b,revertcheck," """"""Wrapper for ipset."""""" def create_ipset_chain(self, chain_name, ethertype): cmd = ['ipset', 'create', '-exist', chain_name, 'hash:ip', 'family', self._get_ipset_chain_type(ethertype)] @utils.synchronized('ipset', external=True) def add_member_to_ipset_chain(self, chain_name, member_ip): cmd = ['ipset', 'add', '-exist', chain_name, member_ip] self._apply(cmd) @utils.synchronized('ipset', external=True) def refresh_ipset_chain_by_name(self, chain_name, member_ips, ethertype): new_chain_name = chain_name + '-new' chain_type = self._get_ipset_chain_type(ethertype) process_input = [""create %s hash:ip family %s"" % (new_chain_name, chain_type)] for ip in member_ips: process_input.append(""add %s %s"" % (new_chain_name, ip)) self._restore_ipset_chains(process_input) self._swap_ipset_chains(new_chain_name, chain_name) self._destroy_ipset_chain(new_chain_name) @utils.synchronized('ipset', external=True) def del_ipset_chain_member(self, chain_name, member_ip): cmd = ['ipset', 'del', chain_name, member_ip] @utils.synchronized('ipset', external=True) def destroy_ipset_chain_by_name(self, chain_name): self._destroy_ipset_chain(chain_name) def _get_ipset_chain_type(self, ethertype): def _restore_ipset_chains(self, process_input): def _swap_ipset_chains(self, src_chain, dest_chain): cmd = ['ipset', 'swap', src_chain, dest_chain] def _destroy_ipset_chain(self, chain_name): cmd = ['ipset', 'destroy', chain_name] self._apply(cmd)","IPSET_ADD_BULK_THRESHOLD = 5 SWAP_SUFFIX = '-new' IPSET_NAME_MAX_LENGTH = 31 - len(SWAP_SUFFIX) """"""Smart wrapper for ipset. Keeps track of ip addresses per set, using bulk or single ip add/remove for smaller changes. """""" self.ipset_sets = {} @staticmethod def get_name(id, ethertype): """"""Returns the given ipset name for an id+ethertype pair. This reference can be used from iptables. """""" name = ethertype + id return name[:IPSET_NAME_MAX_LENGTH] def set_exists(self, id, ethertype): """"""Returns true if the id+ethertype pair is known to the manager."""""" set_name = self.get_name(id, ethertype) return set_name in self.ipset_sets def set_members(self, id, ethertype, member_ips): """"""Create or update a specific set by name and ethertype. It will make sure that a set is created, updated to add / remove new members, or swapped atomically if that's faster. """""" set_name = self.get_name(id, ethertype) if not self.set_exists(id, ethertype): # The initial creation is handled with create/refresh to # avoid any downtime for existing sets (i.e. avoiding # a flush/restore), as the restore operation of ipset is # additive to the existing set. self._create_set(set_name, ethertype) self._refresh_set(set_name, member_ips, ethertype) # TODO(majopela,shihanzhang,haleyb): Optimize this by # gathering the system ipsets at start. So we can determine # if a normal restore is enough for initial creation. # That should speed up agent boot up time. else: add_ips = self._get_new_set_ips(set_name, member_ips) del_ips = self._get_deleted_set_ips(set_name, member_ips) if (len(add_ips) + len(del_ips) < IPSET_ADD_BULK_THRESHOLD): self._add_members_to_set(set_name, add_ips) self._del_members_from_set(set_name, del_ips) else: self._refresh_set(set_name, member_ips, ethertype) @utils.synchronized('ipset', external=True) def destroy(self, id, ethertype, forced=False): set_name = self.get_name(id, ethertype) self._destroy(set_name, forced) def _add_member_to_set(self, set_name, member_ip): cmd = ['ipset', 'add', '-exist', set_name, member_ip] self.ipset_sets[set_name].append(member_ip) def _refresh_set(self, set_name, member_ips, ethertype): new_set_name = set_name + SWAP_SUFFIX set_type = self._get_ipset_set_type(ethertype) process_input = [""create %s hash:ip family %s"" % (new_set_name, set_type)] for ip in member_ips: process_input.append(""add %s %s"" % (new_set_name, ip)) self._restore_sets(process_input) self._swap_sets(new_set_name, set_name) self._destroy(new_set_name, True) self.ipset_sets[set_name] = member_ips def _del_member_from_set(self, set_name, member_ip): cmd = ['ipset', 'del', set_name, member_ip] self.ipset_sets[set_name].remove(member_ip) def _create_set(self, set_name, ethertype): cmd = ['ipset', 'create', '-exist', set_name, 'hash:ip', 'family', self._get_ipset_set_type(ethertype)] self._apply(cmd) self.ipset_sets[set_name] = [] def _get_new_set_ips(self, set_name, expected_ips): new_member_ips = (set(expected_ips) - set(self.ipset_sets.get(set_name, []))) return list(new_member_ips) def _get_deleted_set_ips(self, set_name, expected_ips): deleted_member_ips = (set(self.ipset_sets.get(set_name, [])) - set(expected_ips)) return list(deleted_member_ips) def _add_members_to_set(self, set_name, add_ips): for ip in add_ips: if ip not in self.ipset_sets[set_name]: self._add_member_to_set(set_name, ip) def _del_members_from_set(self, set_name, del_ips): for ip in del_ips: if ip in self.ipset_sets[set_name]: self._del_member_from_set(set_name, ip) def _get_ipset_set_type(self, ethertype): def _restore_sets(self, process_input): def _swap_sets(self, src_set, dest_set): cmd = ['ipset', 'swap', src_set, dest_set] def _destroy(self, set_name, forced=False): if set_name in self.ipset_sets or forced: cmd = ['ipset', 'destroy', set_name] self._apply(cmd) self.ipset_sets.pop(set_name, None)",204,305
openstack%2Fcinder~stable%2Ficehouse~I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3,openstack/cinder,stable/icehouse,I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3,Mock calls to rpm and dpkg from NetApp unit tests,ABANDONED,2015-01-05 14:36:07.000000000,2015-01-14 10:44:06.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11600}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12780}, {'_account_id': 14428}]","[{'number': 1, 'created': '2015-01-05 14:36:07.000000000', 'files': ['cinder/volume/drivers/netapp/utils.py', 'cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/tests/test_netapp.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/274ba175087e492eacb0d63257c798ac8da52a24', 'message': ""Mock calls to rpm and dpkg from NetApp unit tests\n\nThis patch fixes an issue wherein several NetApp unit tests ran\nOS rpm or dpkg commands because the callouts to these commands\nwere not mocked out during driver initialization.\n\nIt also replaces 'rpm -qa' with 'rpm -q' when that command is\ninvoked since the latter also works and is faster.\n\nCloses-Bug: 1393545\nChange-Id: I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3\n(cherry picked from commit d555ca100aeb176bc021b8179d2a5cdfe10e168e)\n""}]",0,144992,274ba175087e492eacb0d63257c798ac8da52a24,15,12,1,9003,,,0,"Mock calls to rpm and dpkg from NetApp unit tests

This patch fixes an issue wherein several NetApp unit tests ran
OS rpm or dpkg commands because the callouts to these commands
were not mocked out during driver initialization.

It also replaces 'rpm -qa' with 'rpm -q' when that command is
invoked since the latter also works and is faster.

Closes-Bug: 1393545
Change-Id: I3d5cfeb2ee39ecb6af5b312dfa6c2a585cf8e0e3
(cherry picked from commit d555ca100aeb176bc021b8179d2a5cdfe10e168e)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/144992/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/tests/test_netapp.py']",4,274ba175087e492eacb0d63257c798ac8da52a24,bug/1393545,"from cinder.volume.drivers.netapp import utils self.mock_object(utils.OpenStackInfo, '_update_info_from_rpm') self.mock_object(utils.OpenStackInfo, '_update_info_from_dpkg') self.mock_object(utils, 'provide_ems') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils, 'OpenStackInfo') self.mock_object(utils.OpenStackInfo, '_update_info_from_rpm') self.mock_object(utils.OpenStackInfo, '_update_info_from_dpkg') self.mock_object(utils, 'provide_ems') self.mock_object(utils.OpenStackInfo, '_update_info_from_rpm') self.mock_object(utils.OpenStackInfo, '_update_info_from_dpkg') self.mock_object(utils, 'provide_ems')",,19,1
openstack%2Foslo-incubator~master~I18c13d4e10224cd880e19649a3c56aea6f4bdbca,openstack/oslo-incubator,master,I18c13d4e10224cd880e19649a3c56aea6f4bdbca,Ignore errors uninstalling lib in run_cross_test.sh,MERGED,2015-01-13 23:22:12.000000000,2015-01-14 10:32:16.000000000,2015-01-14 10:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-13 23:22:12.000000000', 'files': ['tools/run_cross_tests.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/1b808503889a0de8f459099ee594f16aefefa203', 'message': ""Ignore errors uninstalling lib in run_cross_test.sh\n\nIf we can't remove the library, it might not be a dependency yet so just\nignore the error.\n\nChange-Id: I18c13d4e10224cd880e19649a3c56aea6f4bdbca\n""}]",0,147016,1b808503889a0de8f459099ee594f16aefefa203,7,3,1,2472,,,0,"Ignore errors uninstalling lib in run_cross_test.sh

If we can't remove the library, it might not be a dependency yet so just
ignore the error.

Change-Id: I18c13d4e10224cd880e19649a3c56aea6f4bdbca
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/16/147016/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/run_cross_tests.sh'],1,1b808503889a0de8f459099ee594f16aefefa203,cross-test-arguments," $tox_envbin/pip uninstall -y $our_name || echo ""Ignoring error""", $tox_envbin/pip uninstall -y $our_name,1,1
openstack%2Foslo-incubator~master~I60605fa51e93a230389170e9c1dc366a5e016b76,openstack/oslo-incubator,master,I60605fa51e93a230389170e9c1dc366a5e016b76,Update run_cross_test.sh to pass extra args to tox,MERGED,2015-01-13 22:56:37.000000000,2015-01-14 10:28:38.000000000,2015-01-14 10:28:37.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-13 22:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9d25d4e9aa2ac8ae67d6c1f5db837763d7883ef9', 'message': 'Update run_cross_test.sh to pass extra args to tox\n\nIf the caller provides positional arguments, such as a test pattern,\npass them through to tox.\n\nChange-Id: I60605fa51e93a230389170e9c1dc366a5e016b76\n'}, {'number': 2, 'created': '2015-01-13 23:22:12.000000000', 'files': ['tools/run_cross_tests.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b486e3e9073e7d7050131a0be244448c0dc49541', 'message': 'Update run_cross_test.sh to pass extra args to tox\n\nIf the caller provides positional arguments, such as a test pattern,\npass them through to tox.\n\nChange-Id: I60605fa51e93a230389170e9c1dc366a5e016b76\n'}]",0,147009,b486e3e9073e7d7050131a0be244448c0dc49541,10,4,2,2472,,,0,"Update run_cross_test.sh to pass extra args to tox

If the caller provides positional arguments, such as a test pattern,
pass them through to tox.

Change-Id: I60605fa51e93a230389170e9c1dc366a5e016b76
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/09/147009/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/run_cross_tests.sh'],1,9d25d4e9aa2ac8ae67d6c1f5db837763d7883ef9,cross-test-arguments,"shift venv=""$1"" shift posargs=""$*""(cd $project_dir && tox -e $venv -- $posargs)","venv=""$2""(cd $project_dir && tox -e $venv)",5,2
openstack%2Fgovernance~master~I24da839c291ab08dfb531735b0a3b585b0ed2bd6,openstack/governance,master,I24da839c291ab08dfb531735b0a3b585b0ed2bd6,Add debtcollector library for oslo project/program,MERGED,2015-01-09 23:27:50.000000000,2015-01-14 10:16:57.000000000,2015-01-14 10:16:53.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-01-09 23:27:50.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/ad20df3b4aa7d73eb3c83acb54abb46f4f9c8f97', 'message': 'Add debtcollector library for oslo project/program\n\nPart of blueprint adopt-debtcollector\n\nChange-Id: I24da839c291ab08dfb531735b0a3b585b0ed2bd6\n'}]",0,146224,ad20df3b4aa7d73eb3c83acb54abb46f4f9c8f97,12,7,1,1297,,,0,"Add debtcollector library for oslo project/program

Part of blueprint adopt-debtcollector

Change-Id: I24da839c291ab08dfb531735b0a3b585b0ed2bd6
",git fetch https://review.opendev.org/openstack/governance refs/changes/24/146224/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,ad20df3b4aa7d73eb3c83acb54abb46f4f9c8f97,bp/adopt-debtcollector, - repo: openstack/debtcollector,,1,0
openstack%2Fgovernance~master~I9f51a4315972d4ecb8edcfd5fc97242409a6e461,openstack/governance,master,I9f51a4315972d4ecb8edcfd5fc97242409a6e461,oslo.policy promotion,MERGED,2014-12-18 15:09:28.000000000,2015-01-14 10:16:42.000000000,2015-01-14 10:16:42.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 67}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2218}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2889}, {'_account_id': 2903}, {'_account_id': 5538}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6928}, {'_account_id': 9107}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-12-18 15:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a53d650e089b30dbdaacd73f2888bfe51f139d77', 'message': 'oslo.policy promotion\n\nPromote policy to a top level library.\n\nChange-Id: I9f51a4315972d4ecb8edcfd5fc97242409a6e461\nImplements: blueprint graduate-policy\n'}, {'number': 2, 'created': '2014-12-18 15:20:31.000000000', 'files': ['reference/programs.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/a41e37306fa53b14ac72e89b9161a7bf4eab433d', 'message': 'oslo.policy promotion\n\nPromote policy to a top level library.\n\nImplements: blueprint graduate-policy\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/graduate-policy\n\nChange-Id: I9f51a4315972d4ecb8edcfd5fc97242409a6e461\n'}]",0,142813,a41e37306fa53b14ac72e89b9161a7bf4eab433d,18,21,2,2218,,,0,"oslo.policy promotion

Promote policy to a top level library.

Implements: blueprint graduate-policy
https://blueprints.launchpad.net/oslo-incubator/+spec/graduate-policy

Change-Id: I9f51a4315972d4ecb8edcfd5fc97242409a6e461
",git fetch https://review.opendev.org/openstack/governance refs/changes/13/142813/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/programs.yaml'],1,a53d650e089b30dbdaacd73f2888bfe51f139d77,bp/graduate-policy, - repo: openstack/oslo.policy,,1,0
openstack%2Fpython-heatclient~master~Ie37952f28568cfb91799352e83bb68289ec3ee13,openstack/python-heatclient,master,Ie37952f28568cfb91799352e83bb68289ec3ee13,Updated from global requirements,MERGED,2015-01-09 18:35:36.000000000,2015-01-14 10:07:12.000000000,2015-01-14 10:07:07.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-09 18:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/9c8c81e142de8f54ce4f249cf992d8056aaf0017', 'message': 'Updated from global requirements\n\nChange-Id: Ie37952f28568cfb91799352e83bb68289ec3ee13\n'}, {'number': 2, 'created': '2015-01-13 00:15:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2e6e4f80ac334ae9b69a00d222cdda9f37c52c47', 'message': 'Updated from global requirements\n\nChange-Id: Ie37952f28568cfb91799352e83bb68289ec3ee13\n'}]",0,146165,2e6e4f80ac334ae9b69a00d222cdda9f37c52c47,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ie37952f28568cfb91799352e83bb68289ec3ee13
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/65/146165/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9c8c81e142de8f54ce4f249cf992d8056aaf0017,openstack/requirements,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Ffuel-main~master~Ibcdd480c1dc3d9cd35521813e937306670ea913b,openstack/fuel-main,master,Ibcdd480c1dc3d9cd35521813e937306670ea913b,Add test on repeatable provision after cluster deletion,MERGED,2014-11-18 15:05:06.000000000,2015-01-14 09:42:10.000000000,2015-01-12 10:33:34.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2014-11-18 15:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8bb9b413520bef9a9ed65e8a5960003312ddea6c', 'message': 'Add test on repeatable provision after cluster deletion\n\n- Add test that deploy cluster, delete it, create new cluster,\nsnapshot env and then 10 times tries to provision new cluster\n\nImplement blueprint image-provisioning-in-system-tests\n\nChange-Id: Ibcdd480c1dc3d9cd35521813e937306670ea913b\n'}, {'number': 2, 'created': '2015-01-08 08:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3c16ffa6abc9424e4ad9478ba041b75acdeebae7', 'message': ""Add test on repeatable provision after cluster deletion\n\n- Add test that deploy cluster, delete it, create new cluster,\nsnapshot env and then 10 times tries to provision new cluster\n- Changed image-based tag to image_based in tests cause hyphen\nisn't recognized by google docs in our system tests report\n\nImplement blueprint image-provisioning-in-system-tests\n\nChange-Id: Ibcdd480c1dc3d9cd35521813e937306670ea913b\n""}, {'number': 3, 'created': '2015-01-09 10:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/77706d393adb401a3450e9f779b74367f4399b18', 'message': ""Add test on repeatable provision after cluster deletion\n\n- Add test that deploy cluster, delete it, create new cluster,\nsnapshot env and then 10 times tries to provision new cluster\n- Changed image-based tag to image_based in tests cause hyphen\nisn't recognized by google docs in our system tests report\n\nImplement blueprint image-provisioning-in-system-tests\n\nChange-Id: Ibcdd480c1dc3d9cd35521813e937306670ea913b\n""}, {'number': 4, 'created': '2015-01-09 10:35:23.000000000', 'files': ['fuelweb_test/tests/test_ha.py', 'fuelweb_test/tests/test_neutron.py', 'fuelweb_test/tests/test_ceph.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/tests/test_environment_action.py', 'fuelweb_test/tests/tests_strength/test_image_based.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/af3c65591858fa3f1b4cc16829b64794177cc1c2', 'message': ""Add test on repeatable provision after cluster deletion\n\n- Add test that deploy cluster, delete it, create new cluster,\nsnapshot env and then 10 times tries to provision new cluster\n- Changed image-based tag to image_based in tests cause hyphen\nisn't recognized by google docs in our system tests report\n\nImplement blueprint image-provisioning-in-system-tests\n\nChange-Id: Ibcdd480c1dc3d9cd35521813e937306670ea913b\n""}]",17,135318,af3c65591858fa3f1b4cc16829b64794177cc1c2,29,8,4,10136,,,0,"Add test on repeatable provision after cluster deletion

- Add test that deploy cluster, delete it, create new cluster,
snapshot env and then 10 times tries to provision new cluster
- Changed image-based tag to image_based in tests cause hyphen
isn't recognized by google docs in our system tests report

Implement blueprint image-provisioning-in-system-tests

Change-Id: Ibcdd480c1dc3d9cd35521813e937306670ea913b
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/18/135318/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_restart.py'],1,8bb9b413520bef9a9ed65e8a5960003312ddea6c,bp/image-provisioning-in-system-tests,"from fuelweb_test.settings import DEPLOYMENT_MODE_HA @test(groups=[""repeatable_image_based""]) class RepeatableImageBased(TestBasic): @test(depends_on=[SetupEnvironment.prepare_slaves_5], groups=[""repeatable_image_based""]) @log_snapshot_on_error def repeatable_image_based(self): """"""Deploy cluster after deletion many times Scenario: 1. Create HA cluster 2. Add 3 controllers and 2 computes 3. Deploy the cluster 4. Delete cluster 5. Create another HA cluster 6. Create snapshot of environment 7. Revert snapshot and try provision cluster 10 times """""" segment_type = 'gre' cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=DEPLOYMENT_MODE_HA, settings={ ""net_provider"": 'neutron', ""net_segment_type"": segment_type, 'tenant': 'haGre', 'user': 'haGre', 'password': 'haGre' } ) self.fuel_web.update_nodes( cluster_id, { 'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller'], 'slave-04': ['compute'], 'slave-05': ['compute'] } ) self.fuel_web.deploy_cluster_wait(cluster_id) self.fuel_web.client.delete_cluster(cluster_id) for node in self.fuel_web.client.list_nodes(): wait(lambda: self.fuel_web.is_node_discovered(node), timeout=10 * 60, interval=15) segment_type = 'vlan' cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=DEPLOYMENT_MODE_HA, settings={ ""net_provider"": 'neutron', ""net_segment_type"": segment_type } ) self.fuel_web.update_nodes( cluster_id, { 'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller'], 'slave-04': ['compute'], 'slave-05': ['compute'] } ) self.env.make_snapshot(""deploy_after_delete"", is_make=True) for i in range(0, 10): self.env.revert_snapshot(""deploy_after_delete"") cluster_id = self.fuel_web.get_last_created_cluster() self.fuel_web.provisioning_cluster_wait(cluster_id)",,76,0
openstack%2Ffuel-main~master~I21b015dec730eeca737524b04661aa435f7e5097,openstack/fuel-main,master,I21b015dec730eeca737524b04661aa435f7e5097,Add neutron failover tests,MERGED,2015-01-02 08:14:07.000000000,2015-01-14 09:39:44.000000000,2015-01-13 09:22:48.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2015-01-02 08:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/29cdf2c3b5e9167b8eed81affc9ae973b894a7d5', 'message': 'Add neutron failover tests\n\n- Add test on l3 agent rescheduling after non-primary controller reset\nand after non-primary controller shutdown\n\nImplement blueprint ha-test-improvements\n\nChange-Id: I21b015dec730eeca737524b04661aa435f7e5097\n'}, {'number': 2, 'created': '2015-01-05 08:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7534ac83bee780c9f87a57d4d9eb95b756a95614', 'message': 'Add neutron failover tests\n\n- Add test on l3 agent rescheduling after non-primary controller reset\nand after non-primary controller shutdown\n\nImplement blueprint ha-test-improvements\n\nChange-Id: I21b015dec730eeca737524b04661aa435f7e5097\n'}, {'number': 3, 'created': '2015-01-05 08:25:02.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c9479102c97d700547d8b9d1753f642a1d032ed9', 'message': 'Add neutron failover tests\n\n- Add test on l3 agent rescheduling after non-primary controller reset\nand after non-primary controller shutdown\n\nImplement blueprint ha-test-improvements\n\nChange-Id: I21b015dec730eeca737524b04661aa435f7e5097\n'}]",0,144720,c9479102c97d700547d8b9d1753f642a1d032ed9,21,8,3,10136,,,0,"Add neutron failover tests

- Add test on l3 agent rescheduling after non-primary controller reset
and after non-primary controller shutdown

Implement blueprint ha-test-improvements

Change-Id: I21b015dec730eeca737524b04661aa435f7e5097
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/20/144720/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_neutron.py'],1,29cdf2c3b5e9167b8eed81affc9ae973b894a7d5,bp/ha-test-improvements,"from proboscis import SkipTest @classmethod def get_node_with_dhcp(cls, self, os_conn, net_id): node = os_conn.get_node_with_dhcp_for_network(net_id)[0] node_fqdn = self.fuel_web.get_fqdn_by_hostname(node) logger.debug('node name with dhcp is {0}'.format(node)) devops_node = self.fuel_web.find_devops_node_by_nailgun_fqdn( node_fqdn, self.env.nodes().slaves[0:6]) return devops_node @classmethod def get_node_with_l3(cls, self, node_with_l3): node_with_l3_fqdn = self.fuel_web.get_fqdn_by_hostname(node_with_l3) logger.debug(""new node with l3 is {0}"".format(node_with_l3)) devops_node = self.fuel_web.find_devops_node_by_nailgun_fqdn( node_with_l3_fqdn, self.env.nodes().slaves[0:6]) return devops_node @classmethod def create_instance_with_keypair(cls, os_conn, remote): remote.execute( '. openrc;' ' nova keypair-add instancekey > /root/.ssh/webserver_rsa') remote.execute('chmod 400 /root/.ssh/webserver_rsa') instance = os_conn.create_server_for_migration( neutron=True, key_name='instancekey') return instance @classmethod def reshedule_router_manually(cls, os_conn, router_id): l3_agent_id = os_conn.get_l3_agent_ids(router_id)[0] logger.debug(""l3 agent id is {0}"".format(l3_agent_id)) another_l3_agent = os_conn.get_available_l3_agents_ids( l3_agent_id)[0] logger.debug(""another l3 agent is {0}"".format(another_l3_agent)) os_conn.remove_l3_from_router(l3_agent_id, router_id) os_conn.add_l3_to_router(another_l3_agent, router_id) wait(lambda: os_conn.get_l3_agent_ids(router_id), timeout=60 * 5) @classmethod def check_instance_connectivity(cls, remote, dhcp_namespace, instance_ip): cmd = "". openrc; ip netns exec {0} ssh -i /root/.ssh/webserver_rsa"" \ "" -o 'StrictHostKeyChecking no'"" \ "" cirros@{1} \""ping -c 1 8.8.8.8\"""".format(dhcp_namespace, instance_ip) wait(lambda: remote.execute(cmd)['exit_code'] == 0, timeout=2 * 60) res = remote.execute(cmd) assert_equal(0, res['exit_code'], 'instance has no connectivity, exit code {0}'.format( res['exit_code'])) """"""Deploy cluster in HA mode, Neutron with GRE segmentation try: self.check_run('deploy_ha_neutron') except SkipTest: return self.env.make_snapshot(""deploy_ha_neutron"", is_make=True) @test(depends_on=[deploy_ha_neutron], groups=[""neutron_l3_migration""]) @log_snapshot_on_error def neutron_l3_migration(self): """"""Check l3-agent rescheduling after l3-agent dies Scenario: 1. Revert snapshot with neutron cluster 2. Manually reschedule router from primary controller to another one 3. Stop l3-agent on new node with pcs 4. Check l3-agent was rescheduled 5. Check network connectivity from instance via dhcp namespace 6. Run OSTF Snapshot deploy_ha_neutron """""" self.env.revert_snapshot(""deploy_ha_neutron"") cluster_id = self.fuel_web.get_last_created_cluster() devops_node = self.get_node_with_dhcp(self, os_conn, net_id) instance_ip = \ self.create_instance_with_keypair( os_conn, remote).addresses['net04'][0]['addr'] self.reshedule_router_manually(os_conn, router_id) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) new_devops = self.get_node_with_l3(self, node_with_l3) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) @test(depends_on=[deploy_ha_neutron], groups=[""neutron_l3_migration_after_reset""]) @log_snapshot_on_error def neutron_l3_migration_after_reset(self): """"""Check l3-agent rescheduling after reset non-primary controller Scenario: 1. Revert snapshot with neutron cluster 2. Manually reschedule router from primary controller to another one 3. Reset controller with l3-agent 4. Check l3-agent was rescheduled 5. Check network connectivity from instance via dhcp namespace 6. Run OSTF Snapshot deploy_ha_neutron """""" self.env.revert_snapshot(""deploy_ha_neutron"") cluster_id = self.fuel_web.get_last_created_cluster() os_conn = os_actions.OpenStackActions( self.fuel_web.get_public_vip(cluster_id)) net_id = os_conn.get_network('net04')['id'] devops_node = self.get_node_with_dhcp(self, os_conn, net_id) remote = self.env.get_ssh_to_remote_by_name(devops_node.name) dhcp_namespace = ''.join(remote.execute('ip netns | grep {0}'.format( net_id))['stdout']).rstrip() logger.debug('dhcp namespace is {0}'.format(dhcp_namespace)) instance_ip = \ self.create_instance_with_keypair( os_conn, remote).addresses['net04'][0]['addr'] logger.debug('instance internal ip is {0}'.format(instance_ip)) router_id = os_conn.get_routers_ids()[0] self.reshedule_router_manually(os_conn, router_id) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) node_with_l3 = os_conn.get_l3_agent_hosts(router_id)[0] new_devops = self.get_node_with_l3(self, node_with_l3) self.fuel_web.warm_restart_nodes([new_devops]) try: wait(lambda: not node_with_l3 == os_conn.get_l3_agent_hosts( router_id)[0], timeout=60 * 3) except TimeoutError: raise TimeoutError( ""l3 agent wasn't rescheduled, it is still {0}"".format( os_conn.get_l3_agent_hosts(router_id)[0])) wait(lambda: os_conn.get_l3_agent_ids(router_id), timeout=60) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity']) @test(depends_on=[deploy_ha_neutron], groups=[""neutron_l3_migration_after_destroy""]) @log_snapshot_on_error def neutron_l3_migration_after_destroy(self): """"""Check l3-agent rescheduling after destroy non-primary controller Scenario: 1. Revert snapshot with neutron cluster 2. Manually reschedule router from primary controller to another one 3. Destroy controller with l3-agent 4. Check l3-agent was rescheduled 5. Check network connectivity from instance via dhcp namespace 6. Run OSTF Snapshot deploy_ha_neutron """""" self.env.revert_snapshot(""deploy_ha_neutron"") cluster_id = self.fuel_web.get_last_created_cluster() os_conn = os_actions.OpenStackActions( self.fuel_web.get_public_vip(cluster_id)) net_id = os_conn.get_network('net04')['id'] devops_node = self.get_node_with_dhcp(self, os_conn, net_id) remote = self.env.get_ssh_to_remote_by_name(devops_node.name) dhcp_namespace = ''.join(remote.execute('ip netns | grep {0}'.format( net_id))['stdout']).rstrip() logger.debug('dhcp namespace is {0}'.format(dhcp_namespace)) instance_ip = \ self.create_instance_with_keypair( os_conn, remote).addresses['net04'][0]['addr'] logger.debug('instance internal ip is {0}'.format(instance_ip)) router_id = os_conn.get_routers_ids()[0] self.reshedule_router_manually(os_conn, router_id) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) node_with_l3 = os_conn.get_l3_agent_hosts(router_id)[0] new_devops = self.get_node_with_l3(self, node_with_l3) new_devops.destroy() wait(lambda: not self.fuel_web.get_nailgun_node_by_devops_node( new_devops)['online'], timeout=60 * 10) self.fuel_web.wait_mysql_galera_is_up( [n.name for n in set(self.env.nodes().slaves[:3]) - {new_devops}]) try: wait(lambda: not node_with_l3 == os_conn.get_l3_agent_hosts( router_id)[0], timeout=60 * 3) except TimeoutError: raise TimeoutError( ""l3 agent wasn't rescheduled, it is still {0}"".format( os_conn.get_l3_agent_hosts(router_id)[0])) wait(lambda: os_conn.get_l3_agent_ids(router_id), timeout=60) self.check_instance_connectivity(remote, dhcp_namespace, instance_ip) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'], should_fail=1, failed_test_name=['Check that required services are running'])"," """"""Check l3-agent rescheduling after l3-agent dies 6. Manually reschedule router from primary controller to another one 7. Stop l3-agent on new node with pcs 8. Check l3-agent was rescheduled 9. Check network connectivity from instance via dhcp namespace 10. Run OSTF node = os_conn.get_node_with_dhcp_for_network(net_id)[0] node_fqdn = self.fuel_web.get_fqdn_by_hostname(node) logger.debug('node name with dhcp is {0}'.format(node)) devops_node = self.fuel_web.find_devops_node_by_nailgun_fqdn( node_fqdn, self.env.nodes().slaves[0:6]) remote.execute( '. openrc;' ' nova keypair-add instancekey > /root/.ssh/webserver_rsa') remote.execute('chmod 400 /root/.ssh/webserver_rsa') instance = os_conn.create_server_for_migration( neutron=True, key_name='instancekey') instance_ip = instance.addresses['net04'][0]['addr'] l3_agent_id = os_conn.get_l3_agent_ids(router_id)[0] logger.debug(""l3 agent id is {0}"".format(l3_agent_id)) another_l3_agent = os_conn.get_available_l3_agents_ids( l3_agent_id)[0] logger.debug(""another l3 agent is {0}"".format(another_l3_agent)) os_conn.remove_l3_from_router(l3_agent_id, router_id) os_conn.add_l3_to_router(another_l3_agent, router_id) wait(lambda: os_conn.get_l3_agent_ids(router_id), timeout=60 * 5) cmd = "". openrc; ip netns exec {0} ssh -i /root/.ssh/webserver_rsa"" \ "" -o 'StrictHostKeyChecking no'"" \ "" cirros@{1} \""ping -c 1 8.8.8.8\"""".format(dhcp_namespace, instance_ip) wait(lambda: remote.execute(cmd)['exit_code'] == 0, timeout=60) res = remote.execute(cmd) assert_equal(0, res['exit_code'], 'instance has no connectivity, exit code {0}'.format( res['exit_code'])) node_with_l3_fqdn = self.fuel_web.get_fqdn_by_hostname(node_with_l3) logger.debug(""new node with l3 is {0}"".format(node_with_l3)) new_devops = self.fuel_web.find_devops_node_by_nailgun_fqdn( node_with_l3_fqdn, self.env.nodes().slaves[0:6]) wait(lambda: remote.execute(cmd)['exit_code'] == 0, timeout=120) res = remote.execute(cmd) assert_equal(0, res['exit_code'], 'instance has no connectivity, exit code is {0}'.format( res['exit_code']))",215,53
openstack%2Ffuel-library~master~I3eb3a07cb8145c6a509806aaffd3e1a84823c800,openstack/fuel-library,master,I3eb3a07cb8145c6a509806aaffd3e1a84823c800,Update globalls.pp,MERGED,2015-01-13 11:43:43.000000000,2015-01-14 09:30:29.000000000,2015-01-14 09:30:24.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2015-01-13 11:43:43.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/globals.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ff61e9af2fb991ba70fc2b9a62bafde8a49102d3', 'message': 'Update globalls.pp\n\n* add the primary_controller variable\n* add the use_ceilometer variable\n* change the ceilometer_hash\n\nRelated blueprint fuel-library-modularization\nFuel-CI: disable\n\nChange-Id: I3eb3a07cb8145c6a509806aaffd3e1a84823c800\n'}]",2,146830,ff61e9af2fb991ba70fc2b9a62bafde8a49102d3,15,6,1,13343,,,0,"Update globalls.pp

* add the primary_controller variable
* add the use_ceilometer variable
* change the ceilometer_hash

Related blueprint fuel-library-modularization
Fuel-CI: disable

Change-Id: I3eb3a07cb8145c6a509806aaffd3e1a84823c800
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/30/146830/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/globals.pp'],1,ff61e9af2fb991ba70fc2b9a62bafde8a49102d3,bp/fuel-library-modularization,"$ceilometer_hash = hiera('ceilometer',{})$use_ceilometer = $ceilometer_hash['enabled'] $primary_controller = $role ? { 'primary-controller' => true, default =>false }","$default_ceilometer_hash = hiera('default_ceilometer_hash', { 'enabled' => false, 'db_password' => 'ceilometer', 'user_password' => 'ceilometer', 'metering_secret' => 'ceilometer', } ) $ceilometer_hash = hiera('ceilometer', $default_ceilometer_hash) ",3,11
openstack%2Fkeystone~master~I6bc7fa5edd6295a1245844fc9d710f4745778269,openstack/keystone,master,I6bc7fa5edd6295a1245844fc9d710f4745778269,Add information regarding HTTPS for SSL enabled endpoints,ABANDONED,2014-05-26 15:12:53.000000000,2015-01-14 09:12:10.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 167}, {'_account_id': 220}, {'_account_id': 1057}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8533}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 9263}, {'_account_id': 9751}, {'_account_id': 11194}, {'_account_id': 11333}, {'_account_id': 11717}]","[{'number': 1, 'created': '2014-05-26 15:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/33eb64ccdc84a6e9139d64fa42929746b91a6bbc', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 2, 'created': '2014-05-27 07:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b5db7cd5fd11fe67686a4c00a52be58a943000bb', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 3, 'created': '2014-05-29 07:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b54901dcb156ed98df356dc3135b816c0ffa8145', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 4, 'created': '2014-06-02 08:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5e8dda08778724bc2d975727860fee39748d5abc', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 5, 'created': '2014-06-03 05:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d521962a4a2c52ea500ff2b4c4d3988899d0891', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 6, 'created': '2014-06-05 05:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1fe761147b9b290d20d7de2157505ddd5065a460', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 7, 'created': '2014-07-16 07:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/37ffd295d0240e7d8ffd2a704eb2ee35e4b0fc49', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 8, 'created': '2014-07-16 08:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/97c507ccf9f8f6753791a732fdc8ca51f0d58ab5', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 9, 'created': '2014-07-16 10:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d0a256609a0f0521ad8e70c995c11bfe7cb412e8', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 10, 'created': '2014-08-06 12:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0855fc45e97cf1d15c5273de256ed53e76cedd28', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\nAlso:\n- The Domain-specific Drivers functionality will be new in Juno.\n- Keystone does not support moving the contents of a domain.\n- Changed tenant_whatever names attribute to project_whatever names.\n- Some typos have been fixed.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 11, 'created': '2014-08-22 11:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/467046b743e897e10de72e1e6bf18b611f7f826f', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\nAlso:\n- The Domain-specific Drivers functionality will be new in Juno.\n- Keystone does not support moving the contents of a domain.\n- Changed tenant_whatever names attribute to project_whatever names.\n- Some typos have been fixed.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 12, 'created': '2014-08-27 07:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/24c784893c6dd11fbd32c4c268329ac03f93b54d', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\nAlso:\n- The Domain-specific Drivers functionality will be new in Juno.\n- Keystone does not support moving the contents of a domain.\n- Changed tenant_whatever names attribute to project_whatever names.\n- Some typos have been fixed.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}, {'number': 13, 'created': '2014-08-29 11:44:57.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3bcf0fb50a453c066d3a92eb074bb7e0e328703b', 'message': 'Add information regarding HTTPS for SSL enabled endpoints\n\nWhen using SSL the endpoint should be configured to listen on HTTPS\ninstead of HTTP. So the corresponding documentation has been enhanced.\nAlso:\n- The Domain-specific Drivers functionality will be new in Juno.\n- Keystone does not support moving the contents of a domain.\n- Changed tenant_whatever names attribute to project_whatever names.\n- Some typos have been fixed.\n\nChange-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269\nCloses-Bug: #1317815\n'}]",50,95545,3bcf0fb50a453c066d3a92eb074bb7e0e328703b,92,18,13,1057,,,0,"Add information regarding HTTPS for SSL enabled endpoints

When using SSL the endpoint should be configured to listen on HTTPS
instead of HTTP. So the corresponding documentation has been enhanced.
Also:
- The Domain-specific Drivers functionality will be new in Juno.
- Keystone does not support moving the contents of a domain.
- Changed tenant_whatever names attribute to project_whatever names.
- Some typos have been fixed.

Change-Id: I6bc7fa5edd6295a1245844fc9d710f4745778269
Closes-Bug: #1317815
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/95545/10 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,33eb64ccdc84a6e9139d64fa42929746b91a6bbc,master,under the [ssl] section and remember to configure the endpoint to listen on the corresponding secure port e.g. HTTPS instead HTTP. SSL configuration example using the included sample certificates:: to change the provided command accordingly. If you configured SSL then use HTTPS instead of HTTP. # remember to use HTTPS instead of HTTP when using SSL,under the [ssl] section. SSL configuration example using the included sample certificates:: to change the provided command accordingly.,6,3
openstack%2Fneutron~master~I79bfee9ec4fd2ffb44bd9d57a211d0bd95d10877,openstack/neutron,master,I79bfee9ec4fd2ffb44bd9d57a211d0bd95d10877,Fix misc-sanity-checks.sh to be multi-platform,ABANDONED,2014-12-25 09:47:29.000000000,2015-01-14 08:55:52.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-25 09:47:29.000000000', 'files': ['tools/misc-sanity-checks.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/077211f972228785dfe587de0e82914af7c640ba', 'message': ""Fix misc-sanity-checks.sh to be multi-platform\n\nPatch 143539 introduces the script to allow easier and cleaner sanity\nchecks to 'tox -e pep8'. The script uses '/bin/mktemp' to create a\ntemporary directory, but on OS X the file is placed in a different\ndirectory (/usr/bin/mktemp), and in an earlier version of the program.\n\nThis patch changes the call to mktemp in a way that works on all (known)\nplatforms.\n\nCloses-bug: #1405584\nChange-Id: I79bfee9ec4fd2ffb44bd9d57a211d0bd95d10877\n""}]",0,143947,077211f972228785dfe587de0e82914af7c640ba,17,17,1,12444,,,0,"Fix misc-sanity-checks.sh to be multi-platform

Patch 143539 introduces the script to allow easier and cleaner sanity
checks to 'tox -e pep8'. The script uses '/bin/mktemp' to create a
temporary directory, but on OS X the file is placed in a different
directory (/usr/bin/mktemp), and in an earlier version of the program.

This patch changes the call to mktemp in a way that works on all (known)
platforms.

Closes-bug: #1405584
Change-Id: I79bfee9ec4fd2ffb44bd9d57a211d0bd95d10877
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/143947/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/misc-sanity-checks.sh'],1,077211f972228785dfe587de0e82914af7c640ba,bug/1405584,export TMPDIR=`mktemp -d /tmp/tmp.XXXXXXXX`,export TMPDIR=`/bin/mktemp -d`,1,1
openstack%2Foslo.messaging~master~I7aa697ccc23dc90463d7dcbf5dfd6875df73eeab,openstack/oslo.messaging,master,I7aa697ccc23dc90463d7dcbf5dfd6875df73eeab,Deprecates the localcontext API,ABANDONED,2015-01-14 08:14:38.000000000,2015-01-14 08:20:30.000000000,,[],"[{'number': 1, 'created': '2015-01-14 08:14:38.000000000', 'files': ['oslo_messaging/openstack/common/_i18n.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/openstack/common/log.py', 'oslo_messaging/rpc/dispatcher.py', 'openstack-common.conf', 'oslo_messaging/openstack/common/versionutils.py', 'oslo_messaging/openstack/common/local.py', 'oslo_messaging/localcontext.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3f28c1f644a53eb0e630a959cf5bfd1115997578', 'message': 'Deprecates the localcontext API\n\nWe deprecate the localcontext API in favor of the\noslo.context one.\n\nRelated bug: #1288878\n\nChange-Id: I7aa697ccc23dc90463d7dcbf5dfd6875df73eeab\n'}]",0,147086,3f28c1f644a53eb0e630a959cf5bfd1115997578,2,0,1,2813,,,0,"Deprecates the localcontext API

We deprecate the localcontext API in favor of the
oslo.context one.

Related bug: #1288878

Change-Id: I7aa697ccc23dc90463d7dcbf5dfd6875df73eeab
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/86/147086/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/openstack/common/_i18n.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/openstack/common/log.py', 'oslo_messaging/rpc/dispatcher.py', 'openstack-common.conf', 'oslo_messaging/openstack/common/local.py', 'oslo_messaging/openstack/common/versionutils.py', 'oslo_messaging/localcontext.py', 'tox.ini']",9,3f28c1f644a53eb0e630a959cf5bfd1115997578,bug/1288878, oslo_messaging.openstack.common._i18n,,1033,4
openstack%2Fpython-manilaclient~master~I5f7ac638403bfc23b855219f6e11469e23481fbc,openstack/python-manilaclient,master,I5f7ac638403bfc23b855219f6e11469e23481fbc,Use print_list and print_dict functions from common code,MERGED,2015-01-09 05:29:55.000000000,2015-01-14 08:20:22.000000000,2015-01-14 08:20:21.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 13634}]","[{'number': 1, 'created': '2015-01-09 05:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/61f816ec2641c313fda67f722dffaca0bd6628bf', 'message': ""Use print_list and print_dict function from common code\n\nRemove 'print_list' and 'print_dict' functions from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc\n""}, {'number': 2, 'created': '2015-01-09 05:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/73a615af7efbf09a3e2268061e3a36a6b80a328e', 'message': ""Use print_list and print_dict functions from common code\n\nRemove 'print_list' and 'print_dict' functions from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc\n""}, {'number': 3, 'created': '2015-01-09 17:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/90391b99bbbfa32156fc5dfa3ea5a244c6febcd9', 'message': ""Use print_list and print_dict functions from common code\n\nRemove 'print_list' and 'print_dict' functions from\nmanilaclient.utils and use same functions from cliutils instead.\n\nIn the meanwhile, sync the newest cliutil code from oslo\nincubator for the py3 compatibility,.\n\ncommit c8d143bf942c34fc15678a61f5bcd5f460b280ac\nMerge: 103ebd5 80c4751\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Tue Jan 6 01:37:41 2015 +0000\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc\n""}, {'number': 4, 'created': '2015-01-12 02:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/52dece277543cb57c998b70e6ec1534f70c40a1e', 'message': ""Use print_list and print_dict functions from common code\n\nRemove 'print_list' and 'print_dict' functions from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc\n""}, {'number': 5, 'created': '2015-01-14 02:20:44.000000000', 'files': ['manilaclient/tests/unit/v1/test_shell.py', 'manilaclient/v1/contrib/list_extensions.py', 'manilaclient/v1/shell.py', 'manilaclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/2f8a58acf404ed2ee01284be0f0e408244711b1c', 'message': ""Use print_list and print_dict functions from common code\n\nRemove 'print_list' and 'print_dict' functions from\nmanilaclient.utils and use same functions from cliutils instead.\n\nPartially implements: blueprint use-common-code\n\nChange-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc\n""}]",0,146017,2f8a58acf404ed2ee01284be0f0e408244711b1c,22,5,5,13634,,,0,"Use print_list and print_dict functions from common code

Remove 'print_list' and 'print_dict' functions from
manilaclient.utils and use same functions from cliutils instead.

Partially implements: blueprint use-common-code

Change-Id: I5f7ac638403bfc23b855219f6e11469e23481fbc
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/17/146017/2 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/tests/unit/v1/test_shell.py', 'manilaclient/v1/contrib/list_extensions.py', 'manilaclient/utils.py', 'manilaclient/v1/shell.py']",4,61f816ec2641c313fda67f722dffaca0bd6628bf,bp/use-common-code," cliutils.print_dict(info) cliutils.print_dict(info) cliutils.print_dict(e['endpoints'][0], e['name']) cliutils.print_dict(catalog['access']['user'], ""User Credentials"") cliutils.print_dict(catalog['access']['token'], ""Token"") cliutils.print_dict(quota_dict) cliutils.print_list(limits, columns) cliutils.print_list(limits, columns) cliutils.print_dict(metadata, 'Metadata-property') cliutils.print_dict(metadata, 'Metadata-property') cliutils.print_dict(access) cliutils.print_list(access_list, ['id', 'access type', 'access to', 'state']) cliutils.print_list(shares, list_of_keys) cliutils.print_list(snapshots, list_of_keys) cliutils.print_dict(info) cliutils.print_dict(info) cliutils.print_dict(info) cliutils.print_list(share_networks, fields=fields) cliutils.print_list(security_services, fields=fields) cliutils.print_dict(info) cliutils.print_dict(security_service._info) cliutils.print_dict(info) cliutils.print_list(security_services, fields=fields) cliutils.print_list(share_servers, fields=fields) cliutils.print_dict(share_server._info) cliutils.print_dict(details._info) cliutils.print_list(services, fields=fields) cliutils.print_list(vtypes, ['ID', 'Name']) cliutils.print_list(vtypes, ['ID', 'Name', 'extra_specs'], formatters)","from manilaclient import utils utils.print_dict(info) utils.print_dict(info) utils.print_dict(e['endpoints'][0], e['name']) utils.print_dict(catalog['access']['user'], ""User Credentials"") utils.print_dict(catalog['access']['token'], ""Token"") utils.print_dict(quota_dict) utils.print_list(limits, columns) utils.print_list(limits, columns) utils.print_dict(metadata, 'Metadata-property') utils.print_dict(metadata, 'Metadata-property') utils.print_dict(access) utils.print_list(access_list, ['id', 'access type', 'access to', 'state']) utils.print_list(shares, list_of_keys) utils.print_list(snapshots, list_of_keys) utils.print_dict(info) utils.print_dict(info) utils.print_dict(info) utils.print_list(share_networks, fields=fields) utils.print_list(security_services, fields=fields) utils.print_dict(info) utils.print_dict(security_service._info) utils.print_dict(info) utils.print_list(security_services, fields=fields) utils.print_list(share_servers, fields=fields) utils.print_dict(share_server._info) utils.print_dict(details._info) utils.print_list(services, fields=fields) utils.print_list(vtypes, ['ID', 'Name']) utils.print_list(vtypes, ['ID', 'Name', 'extra_specs'], formatters)",68,99
openstack%2Fceilometer~master~I3c53797198a1c890bc8d4a0e48833b75dd8a312a,openstack/ceilometer,master,I3c53797198a1c890bc8d4a0e48833b75dd8a312a,Allows to share engine between drivers,ABANDONED,2014-06-04 16:21:46.000000000,2015-01-14 08:17:40.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6676}, {'_account_id': 6983}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-04 16:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7501d8ec75f271bc776acbe5db9e11fe97487d85', 'message': 'Allows to share engine between both sql driver\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}, {'number': 2, 'created': '2014-06-05 08:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f5c8f8a477f19c0828adb82868cb47cf8f46cd5c', 'message': 'Allows to share engine between both sql driver\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}, {'number': 3, 'created': '2014-07-21 14:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/06e791a2aba64437aa2aacff58f9577e47ba4ae2', 'message': 'Allows to share engine between both sql driver\n\nThis change allows to use only one database connection when the same database\nis used for alarming and metering.\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}, {'number': 4, 'created': '2014-07-21 14:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/52768e4c3e897213f5b71b1fb465e261f6ff56ff', 'message': 'Allows to share engine between drivers\n\nThis change allows to use only one database connection when the same database\nis used for alarming and metering.\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}, {'number': 5, 'created': '2014-07-23 15:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bc94dba2789bdf73c4886149059d73850876b3fa', 'message': 'Allows to share engine between drivers\n\nThis change allows to use only one database connection when the same database\nis used for alarming and metering.\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}, {'number': 6, 'created': '2014-07-25 14:35:46.000000000', 'files': ['ceilometer/alarm/storage/impl_mongodb.py', 'ceilometer/storage/base.py', 'ceilometer/tests/storage/test_impl_log.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/api/app.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/storage/__init__.py', 'ceilometer/alarm/storage/base.py', 'ceilometer/alarm/storage/impl_db2.py', 'ceilometer/alarm/storage/impl_hbase.py', 'ceilometer/tests/db.py', 'ceilometer/tests/storage/test_impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04ebb50277c153205bb0481e92011dd55c1d0f04', 'message': 'Allows to share engine between drivers\n\nThis change allows to use only one database connection when the same database\nis used for alarming and metering.\n\nChange-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a\n'}]",3,97847,04ebb50277c153205bb0481e92011dd55c1d0f04,35,9,6,2813,,,0,"Allows to share engine between drivers

This change allows to use only one database connection when the same database
is used for alarming and metering.

Change-Id: I3c53797198a1c890bc8d4a0e48833b75dd8a312a
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/47/97847/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/storage/impl_mongodb.py', 'ceilometer/storage/base.py', 'ceilometer/tests/storage/test_impl_log.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/api/app.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/storage/__init__.py', 'ceilometer/alarm/storage/base.py', 'ceilometer/alarm/storage/impl_db2.py', 'ceilometer/alarm/storage/impl_hbase.py', 'ceilometer/tests/db.py', 'ceilometer/tests/storage/test_impl_hbase.py']",16,7501d8ec75f271bc776acbe5db9e11fe97487d85,bp/dedicated-alarm-database," conn = hbase.Connection(self.db_manager.connection, {}) conn = hbase.Connection('hbase://test_hbase:9090', {})", conn = hbase.Connection(self.db_manager.connection) conn = hbase.Connection('hbase://test_hbase:9090'),50,36
openstack%2Fneutron~master~I29583afd8b5c84df41acb1065edc794596b407be,openstack/neutron,master,I29583afd8b5c84df41acb1065edc794596b407be,See if both rename/changes get shown by Gerrit,ABANDONED,2015-01-13 22:51:13.000000000,2015-01-14 08:09:54.000000000,,"[{'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-13 22:51:13.000000000', 'files': ['neutron/agent/dhcp/__init__.py', 'neutron/agent/dhcp/agent.py', 'doc/source/devref/rpc_api.rst', 'neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_dhcp_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e1f6758b40bbaca589fd9cf7b22992f8e0d7fed', 'message': 'See if both rename/changes get shown by Gerrit\n\nWIP\n\nChange-Id: I29583afd8b5c84df41acb1065edc794596b407be\n'}]",0,147004,6e1f6758b40bbaca589fd9cf7b22992f8e0d7fed,13,11,1,748,,,0,"See if both rename/changes get shown by Gerrit

WIP

Change-Id: I29583afd8b5c84df41acb1065edc794596b407be
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/147004/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/__init__.py', 'neutron/agent/dhcp/agent.py', 'doc/source/devref/rpc_api.rst', 'neutron/agent/dhcp_agent.py', 'neutron/tests/unit/test_dhcp_agent.py']",5,6e1f6758b40bbaca589fd9cf7b22992f8e0d7fed,prelimar-dhcp-rename, self.cache_p = mock.patch('neutron.agent.dhcp.agent.NetworkCache'), self.cache_p = mock.patch('neutron.agent.dhcp_agent.NetworkCache'),659,633
openstack%2Foctavia~master~Iadd4915740ad864408e9b7e495ca0ff99d1ebec9,openstack/octavia,master,Iadd4915740ad864408e9b7e495ca0ff99d1ebec9,Removes flows from the amphora-driver-interface,MERGED,2015-01-12 18:38:51.000000000,2015-01-14 08:08:56.000000000,2015-01-14 08:08:54.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-12 18:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/730c3e528abbd0e67dce3e642d6d519582220ba2', 'message': 'Removes flows from the amphora-driver-interface\n\n* Remove reference to flows\n* Added new finalize_amphora_call as taled about in midcycle\n\nChange-Id: Iadd4915740ad864408e9b7e495ca0ff99d1ebec9\n'}, {'number': 2, 'created': '2015-01-13 17:16:47.000000000', 'files': ['specs/version0.5/amphora-driver-interface.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d1601c535cd59ddacbd5690f8ae8d509880ef08d', 'message': 'Removes flows from the amphora-driver-interface\n\n* Remove reference to flows\n* Added new finalize_amphora_call as taled about in midcycle\n* fixed spelling\n\nChange-Id: Iadd4915740ad864408e9b7e495ca0ff99d1ebec9\n'}]",5,146602,d1601c535cd59ddacbd5690f8ae8d509880ef08d,13,4,2,10850,,,0,"Removes flows from the amphora-driver-interface

* Remove reference to flows
* Added new finalize_amphora_call as taled about in midcycle
* fixed spelling

Change-Id: Iadd4915740ad864408e9b7e495ca0ff99d1ebec9
",git fetch https://review.opendev.org/openstack/octavia refs/changes/02/146602/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/version0.5/amphora-driver-interface.rst'],1,730c3e528abbd0e67dce3e642d6d519582220ba2,,"The controller will heavily utilize taskflow [2] to accomplish its goals so it is highly encouraged for drivers to use taskflow to organize their work, too. def update(self, listener, vip): updates the amphora with a new configuration for the listener on the vip. def stop(self, listener. vip): stops the listener on the vip. def start(self, listener. vip): starts the listener on the vip. def delete(self, listener, vip): deletes the listener on the vip. def finalize_amphora(self, amphora): """""" OPTIONAL - this method is called once an amphora has been build but before any listeners are configured. This is a hook for drivers who need to do additional work before am amphora becomes ready to accept listeners. Please keep in mind that amphora might be kept in am offline pool after this call. """""" pass ","The system will heavily utilize taskflow [2] to accomplish its goals so it is expected that drivers will implement there functions as tasks. def get_update_flow(self): returns a task flow which updates the amphora with a new configuration for the listener on the vip. The system will place both listener and vip into the task flow engine (or as a result of previous tasks) def get_stop_flow(self): returns a task flow which stops the listener on the vip. Both ""listener"" and ""vip"" become defined inputs for the flow. def get_start_flow(self): returns a task flow which starts the listener on the vip. Both ""listener"" and ""vip"" become defined inputs for the flow. def get_delete_flow(self): returns a task flow which deletes the listener on the vip. Both ""listener"" and ""vip"" become defined inputs for the flow. def get_config_network_flow(self, amphora): """""" returns a task flow which returns the network configuration to be inspected by the controller and creates missing network interfaces, etc. ""amphora"" becomes a defined inputs for the flow and the flow will return a list of network interface cards in the format {""eth0"":{""ip"":""123.123.123.123"", ""netmask"":""..."", ""mac"":"",,,"")) """""" raise NotImplementedErr ",22,29
openstack%2Foctavia~master~I1facdbc8d2059fb4dac4f3e9d195a884758ad16d,openstack/octavia,master,I1facdbc8d2059fb4dac4f3e9d195a884758ad16d,Updates the controller spec to clarify API Manager,MERGED,2015-01-12 17:53:37.000000000,2015-01-14 08:03:02.000000000,2015-01-14 08:02:58.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-12 17:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7d11c23ceac05002a68531821b820c17cdee7d73', 'message': 'Updates the controller spec to clarify API Manager\n\nClarifying the role the API Manager will play in the Octavia\nversion 0.5 controller.\n\nChange-Id: I1facdbc8d2059fb4dac4f3e9d195a884758ad16d\n'}, {'number': 2, 'created': '2015-01-12 23:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f30a81e2b6e1fb889c7af5c83f30002580d4bc3a', 'message': 'Updates the controller spec to clarify API Manager\n\nClarifying the role the API Manager will play in the Octavia\nversion 0.5 controller.\n\nChange-Id: I1facdbc8d2059fb4dac4f3e9d195a884758ad16d\n'}, {'number': 3, 'created': '2015-01-13 00:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f6f4e8665a340cb4e87684818f271d1f91438146', 'message': 'Updates the controller spec to clarify API Manager\n\nClarifying the role the API Manager will play in the Octavia\nversion 0.5 controller.\n\nChange-Id: I1facdbc8d2059fb4dac4f3e9d195a884758ad16d\n'}, {'number': 4, 'created': '2015-01-13 18:30:31.000000000', 'files': ['specs/version0.5/controller.rst', 'specs/version0.5/controller.dot'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e1fd87ae4c403cb6410901df14bba837165384ef', 'message': 'Updates the controller spec to clarify API Manager\n\nClarifying the role the API Manager will play in the Octavia\nversion 0.5 controller.\n\nChange-Id: I1facdbc8d2059fb4dac4f3e9d195a884758ad16d\n'}]",6,146583,e1fd87ae4c403cb6410901df14bba837165384ef,20,5,4,11628,,,0,"Updates the controller spec to clarify API Manager

Clarifying the role the API Manager will play in the Octavia
version 0.5 controller.

Change-Id: I1facdbc8d2059fb4dac4f3e9d195a884758ad16d
",git fetch https://review.opendev.org/openstack/octavia refs/changes/83/146583/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/version0.5/controller.dot'],1,7d11c23ceac05002a68531821b820c17cdee7d73,bp/controller," deploy -> apim [dir=""both""];",,1,0
openstack%2Fmistral~master~I23386e1dcb310d38939e96158a5d8f8fdb31cc15,openstack/mistral,master,I23386e1dcb310d38939e96158a5d8f8fdb31cc15,Small: remove polluting debug log.,MERGED,2015-01-10 02:59:40.000000000,2015-01-14 07:40:03.000000000,2015-01-14 07:39:53.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 11863}]","[{'number': 1, 'created': '2015-01-10 02:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ecb14843aaa7826276e8f9ccc7649ce8d0f02908', 'message': 'Small: remove polluting debug log.\n\nFix a complain that with --debug the logs are polluted grow\nwithout bounds.\n\nChange-Id: I23386e1dcb310d38939e96158a5d8f8fdb31cc15\n'}, {'number': 2, 'created': '2015-01-13 22:16:54.000000000', 'files': ['mistral/services/scheduler.py', 'mistral/services/periodic.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3cc54a0a09e4b4f56cd22e8c12c60b3d700e7f82', 'message': 'Small: remove polluting debug log.\n\nFix a complain that with --debug the logs are polluted grow\nwithout bounds.\n\nChange-Id: I23386e1dcb310d38939e96158a5d8f8fdb31cc15'}]",0,146255,3cc54a0a09e4b4f56cd22e8c12c60b3d700e7f82,16,7,2,9432,,,0,"Small: remove polluting debug log.

Fix a complain that with --debug the logs are polluted grow
without bounds.

Change-Id: I23386e1dcb310d38939e96158a5d8f8fdb31cc15",git fetch https://review.opendev.org/openstack/mistral refs/changes/55/146255/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/services/scheduler.py'],1,ecb14843aaa7826276e8f9ccc7649ce8d0f02908,small-fixes," LOG.debug('Processing next delayed call: %s', call)", LOG.debug('Processing next delayed calls.'),1,1
openstack%2Fopenstack-manuals~master~I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2,openstack/openstack-manuals,master,I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2,Add a small section to the hot-guide composition doc,MERGED,2015-01-12 12:50:44.000000000,2015-01-14 07:12:29.000000000,2015-01-14 07:12:28.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6547}, {'_account_id': 7193}, {'_account_id': 7923}, {'_account_id': 8246}, {'_account_id': 8804}, {'_account_id': 12402}, {'_account_id': 14046}]","[{'number': 1, 'created': '2015-01-12 12:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8258d8b24f5aca6b18aac2b08e5957985908acc3', 'message': 'Add a small section to the hot-guide composition doc\n\nThis completes a two way sync of the contents with the in-tree\ncomposition docs.\n\nChange-Id: I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2\n'}, {'number': 2, 'created': '2015-01-12 23:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fdb9ed443ae2517e51257bc6879814b20767ca03', 'message': 'Add a small section to the hot-guide composition doc\n\nThis completes a two way sync of the contents with the in-tree\ncomposition docs.\nAlso set the template version in the examples to the latest\ntemplate version (we should be encouraging the latest template\nversion).\n\nChange-Id: I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2\n'}, {'number': 3, 'created': '2015-01-13 19:49:24.000000000', 'files': ['doc/hot-guide/source/composition.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3410fc1f1158e1c29ad0ddd493f01512e29153de', 'message': 'Add a small section to the hot-guide composition doc\n\nThis completes a two way sync of the contents with the in-tree\ncomposition docs.\nAlso set the template version in the examples to the latest\ntemplate version (we should be encouraging the latest template\nversion).\n\nChange-Id: I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2\n'}]",2,146454,3410fc1f1158e1c29ad0ddd493f01512e29153de,23,10,3,4715,,,0,"Add a small section to the hot-guide composition doc

This completes a two way sync of the contents with the in-tree
composition docs.
Also set the template version in the examples to the latest
template version (we should be encouraging the latest template
version).

Change-Id: I0c9767835614ea8e44d6b0ec3ca28c50bdc0b1d2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/54/146454/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/hot-guide/source/composition.rst'],1,8258d8b24f5aca6b18aac2b08e5957985908acc3,146454," Get access to nested attributes =============================== There are implicit attributes of a template resource. These are accessable as follows: .. code-block:: yaml heat_template_version: 2013-05-23 resources: my_server: type: my_nova.yaml outputs: test_out: value: {get_attr: my_server, resource.server, first_address} ",,18,0
openstack%2Fapi-site~master~I68675defd87728c75a98fb41b39eb37d44e4c6cd,openstack/api-site,master,I68675defd87728c75a98fb41b39eb37d44e4c6cd,Imported Translations from Transifex,MERGED,2015-01-14 06:05:13.000000000,2015-01-14 07:10:10.000000000,2015-01-14 07:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-14 06:05:13.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-quick-start/locale/it.po', 'api-ref/locale/fr.po', 'api-quick-start/locale/ja.po', 'api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po', 'api-quick-start/locale/ca.po', 'api-quick-start/locale/api-quick-start.pot', 'api-quick-start/locale/es.po', 'api-quick-start/locale/fr.po', 'api-quick-start/locale/zh_CN.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/9b8d3bbf6a4116eb3d9a121a60c8e623796e4dc5', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I68675defd87728c75a98fb41b39eb37d44e4c6cd\n'}]",0,147069,9b8d3bbf6a4116eb3d9a121a60c8e623796e4dc5,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I68675defd87728c75a98fb41b39eb37d44e4c6cd
",git fetch https://review.opendev.org/openstack/api-site refs/changes/69/147069/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-quick-start/locale/it.po', 'api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-quick-start/locale/ja.po', 'api-quick-start/locale/ko_KR.po', 'api-quick-start/locale/de.po', 'api-quick-start/locale/ca.po', 'api-quick-start/locale/api-quick-start.pot', 'api-quick-start/locale/es.po', 'api-quick-start/locale/fr.po', 'api-quick-start/locale/zh_CN.po']",11,9b8d3bbf6a4116eb3d9a121a60c8e623796e4dc5,transifex/translations,"""POT-Creation-Date: 2015-01-13 14:24+0000\n"" ""PO-Revision-Date: 2015-01-13 14:24+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""username (required)"" msgstr """"msgid ""password (required)"" msgstr """"#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml76(errorcode)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml77(errorname)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml84(td)""server responds with a <placeholder-3/><placeholder-4/>. If you do not know "" ""the tenantId, you can send a request with \""\"" for the tenantId and get the "" ""ID returned to you in the response."" msgstr """" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml83(td)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml85(td)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml91(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml95(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml103(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml108(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml117(title)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml118(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml126(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml132(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml136(para)""request with an empty tenantName, as follows:"" msgstr """" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml147(title)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml148(para)""This section shows how to make some basic Compute API calls. For a complete "" ""list of Compute API calls, see <link href=\""http://developer.openstack.org"" ""/api-ref-compute-v2.html\"">Compute APIs and Extensions</link>."" msgstr """" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml153(para) msgid ""Use the Compute API to list flavors, as follows:"" msgstr """" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml155(replaceable)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml164(replaceable)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml156(replaceable) #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml161(replaceable) #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml164(replaceable)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml158(para) msgid ""Use the Compute API to list images, as follows:"" msgstr """" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml163(para) msgid ""Use the Compute API to list servers, as follows:"" msgstr ""使用计算服务API来得到虚拟机列表，如下所示:"" ","""POT-Creation-Date: 2014-06-29 01:37+0000\n"" ""PO-Revision-Date: 2014-06-30 08:51+0000\n"" ""Last-Translator: Ying Chun Guo <daisy.ycguo@gmail.com>\n""msgid ""username (Optional)"" msgstr ""用户名(可选的)""msgid ""password (Optional)"" msgstr ""密码(可选的)""#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml77(errorcode)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml78(errorname)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml82(td)""server responds with a <placeholder-3/><placeholder-4/>."" msgstr ""租户ID。<placeholder-1/> 和 <placeholder-2/>都是可选的，但不能被同时具体指定。如果这两个属性值都被指定了，服务将会返回<placeholder-3/><placeholder-4/>。"" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml81(td)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml83(td)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml89(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml93(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml101(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml106(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml115(title)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml116(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml120(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml126(para)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml135(para)""request with an empty tenant, as follows:"" msgstr ""如果你不知道租户名称或者ID，可以发送不携带租户信息的认证请求，具体如下:"" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml142(title)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml143(para)""This section shows how to make some Identity API and Compute API calls. For "" ""a complete list of Identity API calls, see <link "" ""href=\""http://developer.openstack.org/api-ref-identity-v3.html\"">Identity "" ""APIs</link>. For a complete list of Compute API calls, see <link "" ""href=\""http://developer.openstack.org/api-ref-compute-v2.html\"">Compute APIs"" "" and Extensions</link>."" msgstr ""本部分内容展示了如何使用认证API和计算服务API调用。 如果需要认证服务完整API介绍，请参见<link href=\""http://developer.openstack.org/api-ref-identity-v3.html\"">Identity APIs</link>. 如果需要计算服务完整API介绍信息，请参见<link href=\""http://developer.openstack.org/api-ref-compute-v2.html\"">Compute APIs and Extensions</link>."" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml151(para) msgid ""Use the Identity API to request a list of tenants, as follows:"" msgstr ""使用认证API可以请求一些租户，如下所示："" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml153(replaceable) #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml157(replaceable)#: ./api-quick-start/src/docbkx/api-quick-start-intro.xml155(para) msgid ""Use the Identity API to request a list of endpoints, as follows:"" msgstr ""使用认证API来请求一些服务接入点，如下所示："" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml159(para) msgid ""Use the Compute API to list servers, as follows:"" msgstr ""使用计算服务API来得到虚拟机列表，如下所示:"" #: ./api-quick-start/src/docbkx/api-quick-start-intro.xml160(replaceable)",449,441
openstack%2Foctavia~master~I6c45dae5dbdd39515f9db02e8765d68871da2762,openstack/octavia,master,I6c45dae5dbdd39515f9db02e8765d68871da2762,Nova driver implementation,MERGED,2014-11-06 19:02:56.000000000,2015-01-14 06:56:46.000000000,2015-01-14 06:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 10806}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 12403}]","[{'number': 1, 'created': '2014-11-06 19:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2208f22e51ba76d3af2ff6168b2144e2f5b10fcd', 'message': 'Nova virtual machine driver implementation\n\nAdded virtual_machine_driver for virtual machine creation through nova\nAdded amphora types list and an entry for Virtual Machine type\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 2, 'created': '2014-11-06 19:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0a1b7263c59c95a0f3fffe0f6d776d6a92cf67ad', 'message': 'Nova virtual machine driver implementation\n\nAdded virtual_machine_driver for virtual machine creation through nova\nAdded amphora types list and an entry for Virtual Machine type\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 3, 'created': '2014-11-06 21:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0763ea817f751b020d60dc8f47783db49ae6c97f', 'message': 'Nova virtual machine driver implementation\n\nAdded virtual_machine_driver for virtual machine creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available version to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 4, 'created': '2014-11-07 20:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/832b91f95edfc7ff28ff86ee1b2820ed88081442', 'message': 'Nova virtual machine driver implementation\n\nAdded virtual_machine_driver for virtual machine creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available version to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 5, 'created': '2014-11-10 20:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6b3a6d723d5d9416aaa40689969dff8d5a6671db', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 6, 'created': '2014-11-10 21:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c4bd8d1349366a7632b4c93f5dce612607eaa79b', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 7, 'created': '2014-11-10 21:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c9e2d0d8b04e91205f0ef4ae8906ccff945b814f', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 8, 'created': '2014-11-10 22:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cc69ebcae09b4acce563804d521f2588ff933cd6', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 9, 'created': '2014-11-11 22:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8d397e211f3bf4d1f58dbd6496584ee0e8724219', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 10, 'created': '2014-11-12 17:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/19c3896ad2e77f7e27248f6411b680006de64c92', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 11, 'created': '2014-11-12 19:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c554d377c67dbf0b7965f28f5d428c86a3394392', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 12, 'created': '2014-11-13 20:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ff0b731acce4fc5c7e33511e47b42238cfb7157e', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 13, 'created': '2014-11-14 00:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/524204848189319374faa5fd14834a174bd66fcb', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 14, 'created': '2014-11-14 22:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fc5c816220f84dd3c825b1644d1c33f695683199', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 15, 'created': '2014-11-17 21:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/675e5ac9faa73cb4c19fa9a05fff0b1ae2588434', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 16, 'created': '2014-11-19 21:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6507f665b1f873b5550a328869a8b0d556a04bae', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 17, 'created': '2014-12-05 21:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1ace69e4db466bf33e0e98367385808c5730a0a7', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 18, 'created': '2014-12-11 20:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9da5956a10ed215462201b605d46f7bdbdbfecd3', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 19, 'created': '2014-12-12 21:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ec92b6f3b4172b2e2362d77a4f4b930b5cacb705', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 20, 'created': '2014-12-15 17:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a90715100a83185f6c709eb0360bf37beeb1e8d4', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 21, 'created': '2015-01-13 18:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3f05a541c522fa1fea5ac87374f8a60395c619f5', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 22, 'created': '2015-01-13 22:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/951d950cf0761ed975fd45da355bd950b40fa7c1', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}, {'number': 23, 'created': '2015-01-13 22:43:54.000000000', 'files': ['octavia/common/config.py', 'octavia/compute/compute_base.py', 'octavia/compute/drivers/__init__.py', 'octavia/db/models.py', 'octavia/db/migration/alembic_migrations/versions/256852d5ff7c_add_lb_network_ip_to_amphora.py', 'octavia/tests/unit/amphorae/drivers/test_nova_driver.py', 'octavia/compute/drivers/nova_driver.py', 'octavia/db/migration/alembic_migrations/versions/14892634e228_update_vip.py', 'etc/octavia.conf', 'octavia/tests/functional/db/test_repositories.py', 'octavia/api/v1/types/load_balancer.py', 'octavia/common/data_models.py', 'requirements.txt', 'octavia/common/constants.py', 'octavia/tests/functional/db/test_models.py', 'octavia/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/0053509489ebce571bd98238f8370158619e38fc', 'message': 'Nova driver implementation\n\nAdded nova_driver for amphora creation through nova\nAdded amphora types list and an entry for Virtual Machine type to constants\nAdded nova version list and available versions to constants\nAdded amphora status list and UP/DOWN statuses to constants\nAdded to amphora data_model for reuse in response from nova_driver\nAdded testing for nova_driver\n\nChange-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762\nPartially-Implements: blueprint nova-compute-driver\n'}]",70,133108,0053509489ebce571bd98238f8370158619e38fc,104,11,23,10806,,,0,"Nova driver implementation

Added nova_driver for amphora creation through nova
Added amphora types list and an entry for Virtual Machine type to constants
Added nova version list and available versions to constants
Added amphora status list and UP/DOWN statuses to constants
Added to amphora data_model for reuse in response from nova_driver
Added testing for nova_driver

Change-Id: I6c45dae5dbdd39515f9db02e8765d68871da2762
Partially-Implements: blueprint nova-compute-driver
",git fetch https://review.opendev.org/openstack/octavia refs/changes/08/133108/20 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/constants.py', 'octavia/amphorae/drivers/compute/virtual_machine_driver.py', 'octavia/amphorae/drivers/compute/__init__.py']",3,2208f22e51ba76d3af2ff6168b2144e2f5b10fcd,bp/nova-compute-driver,,,55,0
openstack%2Ftempest~master~I82ed7d3a9e20168d074d3a0c16b8edea6b56f092,openstack/tempest,master,I82ed7d3a9e20168d074d3a0c16b8edea6b56f092,"Revert ""Remove network debug""",ABANDONED,2015-01-10 03:42:40.000000000,2015-01-14 06:40:59.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5803}, {'_account_id': 6072}, {'_account_id': 9656}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-10 03:42:40.000000000', 'files': ['tempest/tests/common/test_debug.py', 'tempest/scenario/manager.py', 'tempest/common/commands.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/common/debug.py', 'tempest/config.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/tests/test_commands.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a5ae3d67a7c60e88befc7ddd5c612a169658b9d3', 'message': 'Revert ""Remove network debug""\n\nTroubleshooting bug: #1403291\n\nThis reverts commit 53483137c70dfeebff3c53c6f841ea55f9cca679.\n\nChange-Id: I82ed7d3a9e20168d074d3a0c16b8edea6b56f092\n'}]",0,146256,a5ae3d67a7c60e88befc7ddd5c612a169658b9d3,43,6,1,748,,,0,"Revert ""Remove network debug""

Troubleshooting bug: #1403291

This reverts commit 53483137c70dfeebff3c53c6f841ea55f9cca679.

Change-Id: I82ed7d3a9e20168d074d3a0c16b8edea6b56f092
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/146256/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/common/test_debug.py', 'tempest/common/commands.py', 'tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/common/debug.py', 'tempest/config.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/tests/test_commands.py']",9,a5ae3d67a7c60e88befc7ddd5c612a169658b9d3,bug/1403291,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import subprocess import mock from tempest.common import commands from tempest.tests import base class TestCommands(base.TestCase): def setUp(self): super(TestCommands, self).setUp() self.subprocess_args = {'stdout': subprocess.PIPE, 'stderr': subprocess.STDOUT} @mock.patch('subprocess.Popen') def test_ip_addr_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'a'] commands.ip_addr_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_route_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'r'] commands.ip_route_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'list'] commands.ip_ns_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_iptables_raw(self, mock): table = 'filter' expected = ['/usr/bin/sudo', '-n', 'iptables', '--line-numbers', '-L', '-nv', '-t', '%s' % table] commands.iptables_raw(table) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_list(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'list'] commands.ip_ns_list() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_addr(self, mock): ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'ip', 'a'] commands.ip_ns_addr(ns) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_route(self, mock): ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'ip', 'r'] commands.ip_ns_route(ns) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_iptables_ns(self, mock): table = 'filter' ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'iptables', '-v', '-S', '-t', table] commands.iptables_ns(ns, table) mock.assert_called_once_with(expected, **self.subprocess_args) ",,344,3
openstack%2Fpython-mistralclient~master~Id33e35ede760f1e4748d6e858b8a93d01e39aaba,openstack/python-mistralclient,master,Id33e35ede760f1e4748d6e858b8a93d01e39aaba,Implement commands for execution environment,MERGED,2015-01-06 21:02:25.000000000,2015-01-14 06:34:47.000000000,2015-01-14 06:34:47.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 14272}]","[{'number': 1, 'created': '2015-01-06 21:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/8f233376176c63926ad97f894d8d81f8155d6c37', 'message': 'Implement commands for execution environment\n\nImplement create, update, list, get, and delete commands for\nexecution environment. Create and update commands takes JSON\nor YAML files as input.\n\nChange-Id: Id33e35ede760f1e4748d6e858b8a93d01e39aaba\nImplements: blueprint mistral-execution-environment\n'}, {'number': 2, 'created': '2015-01-07 02:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/ceaca87bdfc56319f306f2500a544b834a05aaf5', 'message': 'Implement commands for execution environment\n\nImplement create, update, list, get, and delete commands for\nexecution environment. Create and update commands takes JSON\nor YAML files as input.\n\nChange-Id: Id33e35ede760f1e4748d6e858b8a93d01e39aaba\nImplements: blueprint mistral-execution-environment\n'}, {'number': 3, 'created': '2015-01-14 02:09:51.000000000', 'files': ['mistralclient/shell.py', 'requirements.txt', 'mistralclient/commands/v2/environments.py', 'mistralclient/tests/unit/v2/test_cli_environments.py', 'mistralclient/tests/unit/v2/base.py', 'mistralclient/api/v2/client.py', 'mistralclient/api/v2/environments.py', 'mistralclient/tests/unit/v2/test_environments.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/90b56a9f45ba41a90f4bf10402ce465c49cbee62', 'message': 'Implement commands for execution environment\n\nImplement create, update, list, get, and delete commands for\nexecution environment. Create and update commands takes JSON\nor YAML files as input.\n\nChange-Id: Id33e35ede760f1e4748d6e858b8a93d01e39aaba\nImplements: blueprint mistral-execution-environment\n'}]",9,145339,90b56a9f45ba41a90f4bf10402ce465c49cbee62,22,7,3,5558,,,0,"Implement commands for execution environment

Implement create, update, list, get, and delete commands for
execution environment. Create and update commands takes JSON
or YAML files as input.

Change-Id: Id33e35ede760f1e4748d6e858b8a93d01e39aaba
Implements: blueprint mistral-execution-environment
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/39/145339/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/shell.py', 'requirements.txt', 'mistralclient/commands/v2/environments.py', 'mistralclient/tests/unit/v2/test_cli_environments.py', 'mistralclient/tests/unit/v2/base.py', 'mistralclient/api/v2/client.py', 'mistralclient/api/v2/environments.py', 'mistralclient/tests/unit/v2/test_environments.py']",8,8f233376176c63926ad97f894d8d81f8155d6c37,bp/mistral-execution-environment,"# -*- coding: utf-8 -*- # # Copyright 2015 - StackStorm, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import copy import json from mistralclient.api.v2 import environments from mistralclient.tests.unit.v2 import base ENVIRONMENT = { 'name': 'env1', 'description': 'Test Environment #1', 'scope': 'private', 'variables': { 'server': 'localhost', 'database': 'test', 'timeout': 600, 'verbose': True } } URL_TEMPLATE = '/environments' URL_TEMPLATE_NAME = '/environments/%s' class TestEnvironmentsV2(base.BaseClientV2Test): def test_create(self): data = copy.deepcopy(ENVIRONMENT) mock = self.mock_http_post(content=data) env = self.environments.create(**data) self.assertIsNotNone(env) mock.assert_called_once_with(URL_TEMPLATE, json.dumps(data)) def test_update(self): data = copy.deepcopy(ENVIRONMENT) mock = self.mock_http_put(content=data) env = self.environments.update(**data) self.assertIsNotNone(env) mock.assert_called_once_with(URL_TEMPLATE_NAME % data['name'], json.dumps(data)) def test_list(self): mock = self.mock_http_get(content={'environments': [ENVIRONMENT]}) environment_list = self.environments.list() self.assertEqual(1, len(environment_list)) env = environment_list[0] self.assertDictEqual( environments.Environment(self.environments, ENVIRONMENT).__dict__, env.__dict__ ) mock.assert_called_once_with(URL_TEMPLATE) def test_get(self): mock = self.mock_http_get(content=ENVIRONMENT) env = self.environments.get('env') self.assertIsNotNone(env) self.assertDictEqual( environments.Environment(self.environments, ENVIRONMENT).__dict__, env.__dict__ ) mock.assert_called_once_with(URL_TEMPLATE_NAME % 'env') def test_delete(self): mock = self.mock_http_delete(status_code=204) self.environments.delete('env') mock.assert_called_once_with(URL_TEMPLATE_NAME % 'env') ",,480,3
openstack%2Fkeystone-specs~master~I114bd4786282424d33a2494b85c0801e9004dc28,openstack/keystone-specs,master,I114bd4786282424d33a2494b85c0801e9004dc28,Service Provider for K2K,MERGED,2014-11-19 13:53:38.000000000,2015-01-14 06:09:37.000000000,2015-01-14 06:09:35.000000000,"[{'_account_id': 3}, {'_account_id': 1228}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 8978}, {'_account_id': 10335}, {'_account_id': 11022}]","[{'number': 1, 'created': '2014-11-19 13:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/dc7867c142c6db66c9bbba0ff80539e33c697e29', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: bp/k2k-service-providers\n'}, {'number': 2, 'created': '2014-11-20 08:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/96c94dcb6b0254d3d60c15af6f827bb206245c29', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: bp/k2k-service-providers\n'}, {'number': 3, 'created': '2014-11-20 08:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e305d3ee9a040c6cd0f821914a55d14a6f2d430a', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: bp/k2k-service-providers\n'}, {'number': 4, 'created': '2014-11-20 17:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/d5cd1e81f0b5a8405a9515e7809dff98bc10aa79', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: bp/k2k-service-providers\n'}, {'number': 5, 'created': '2014-11-24 10:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/10560be624155be42e1f79e5ff2d3855dfaa55b8', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: bp/k2k-service-providers\n'}, {'number': 6, 'created': '2014-11-24 19:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/a088ac51374ffe1dd62552f2f419f0fae9663e91', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 7, 'created': '2014-12-11 10:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/087c8c18d40465a465e508d1b4a03d49c84f5e60', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 8, 'created': '2014-12-11 14:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/fb89db9d8277c894be62e6d9d1cda81e540f0738', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 9, 'created': '2014-12-11 14:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e8b5d430e62e7c60c2d4408cebcba8d3ce24cdf3', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 10, 'created': '2014-12-15 15:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/45f0b0fe12fb6ea00f970fd0fc889ec25163d4a8', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 11, 'created': '2015-01-08 10:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/03c411602cbd75b816bf3f48246ac50ff99a25df', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 12, 'created': '2015-01-12 08:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/ee4bda8901bc923eb45d4518c34db668344d9b86', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 13, 'created': '2015-01-13 09:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/f35a5afc30dac1f725f0e11aabf4b6dee82a3469', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 14, 'created': '2015-01-13 10:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/acb17de995e3f76ed320f7c8376fbd8ea3cda51f', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}, {'number': 15, 'created': '2015-01-13 17:40:59.000000000', 'files': ['api/v3/identity-api-v3-os-federation-ext.rst', 'specs/kilo/k2k-service-providers.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/47dde37e7c48b99af858b814c745f4a8011bf056', 'message': 'Service Provider for K2K\n\nKeystone2Keystone needs ``Service Provider`` objects to be added to the\nexisting suite so the user experience is more transparent.\nAlso, users planning to burst into remote clouds should use new Service\nCatalog entry instead of regions.\n\nChange-Id: I114bd4786282424d33a2494b85c0801e9004dc28\nImplements: blueprint k2k-service-providers\n'}]",97,135604,47dde37e7c48b99af858b814c745f4a8011bf056,87,9,15,8978,,,0,"Service Provider for K2K

Keystone2Keystone needs ``Service Provider`` objects to be added to the
existing suite so the user experience is more transparent.
Also, users planning to burst into remote clouds should use new Service
Catalog entry instead of regions.

Change-Id: I114bd4786282424d33a2494b85c0801e9004dc28
Implements: blueprint k2k-service-providers
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/04/135604/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/k2k-service-providers.rst'],1,dc7867c142c6db66c9bbba0ff80539e33c697e29,service_providers,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Federated Service Providers in Keystone ========================================== `bp example <https://blueprints.launchpad.net/keystone/+spec/k2k-service-providers`_ This specification describes main steps required for reworking Keystone2Keystone federation shipped in Juno release so the user experience is even better and the whole design doesn't break core Keystone architecture. Problem Description =================== Keystone2Keystone federation delivered in Juno is currently marked as ``experimental`` and happens to miss few important points. It also utilizes regions while not being a discoverable service at the same time. Therefore there is a need for rearchitecturing few aspects: * ``regions`` should not be used for indicating remote service a client can burst into. * client should get all the information about the federation protocol that will be used for bursing into remote clouds (all the URLs etc.). * a client should be able to fetch all required information needed for bursting into remote clouds (for instance ``authURL`` as well federated protocol specific urls) Proposed Change =============== Keystone should be enhanced with new set of objects called ``Service Provider`` (``/v3/OS-FEDERATION/service_providers/``) where a trusted Service Providers are being configured. Information stored within such object should include information like: * ``authURL`` - an url where client can get his token once he has authenticated via the federated protocol * protocol specific url - usually a dedicated url where assertions are being sent * a federation protocol that will be used for bursting into remote clouds Each ``Service Provider`` should be identified by a user specified system unique name, alike ``Identity Providers`` already existing within Keystone ecosystem. ``Identity API`` should be enhanced with 5 new ``Service Provider`` operations: * Create * Delete * Get * List * Update Apart from that, Service Catalog should be extended with a new entry - ``service_providers``. Users willing to burst into remote clouds would query that entry in the Service Catalog. Optinally a proper filtering of the ``Service Providers`` allowed for a certain user could be added (e.g. ``userA`` can burst into ``cloud1`` and ``cloud2`` whereas ``userB`` can burst into ``cloud2`` and ``cloud3``. Those constraints should be reflected in service catalog proposed for each of users) Alternatives ------------ One alternative is to keep using regions as remote endpoint where users can burst into, however this would presume users know apriori at least ``authURL`` of the remote services as well federated protocol to be used. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? It changes a Service Catalog but changes the structure not the set of data exposed. * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? No. * Does this change involve cryptography or hashing? No. * Does this change require the use of sudo or any elevated privileges? No. * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. No. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. No. Notifications Impact -------------------- Please specify any changes to notifications. Be that an extra notification, changes to an existing notification, or removing a notification. No. Other End User Impact --------------------- python-keystoneclient would need to be enhanced with operations for managing ``Service Catalog`` objects, correctly interpret new structure of the ``Service Catalog`` , list all the remote clouds/services a user can burst into and reuse existing federated authentication plugins for the authentication process. Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other Deployer Impact --------------------- No additional config options, new features would be enabled only after the ``federation`` extension is enabled. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Marek Denis <marek.denis> Other contributors: None Work Items ---------- * Add ``Service Provider`` objects along with relevant APIs * Add ``service_providers`` object to the Service Catalog Dependencies ============ * Include specific references to specs and/or blueprints in keystone, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Keystone (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Documentation Impact ==================== All the changes must be documented: * New set of APIs * New structure of the Service Catalog References ========== Etherpad site: https://etherpad.openstack.org/p/keystone2keystone ",,197,0
openstack%2Fpython-neutronclient~master~I971e04e06cfc95c08ead595f9d9552796ca19842,openstack/python-neutronclient,master,I971e04e06cfc95c08ead595f9d9552796ca19842,Allow to specify IP address of floating ip,ABANDONED,2015-01-09 02:39:55.000000000,2015-01-14 05:53:32.000000000,,"[{'_account_id': 3}, {'_account_id': 5948}]","[{'number': 1, 'created': '2015-01-09 02:39:55.000000000', 'files': ['neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/neutron/v2_0/floatingip.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/37a5daa532dfd458eca0b120513843be682e5c4c', 'message': ""Allow to specify IP address of floating ip\n\nSince neutron now support specify IP address of floating ip[1],\nwe need to add option 'floating_ip_address' for creating floating\nip.\n\nCloses-bug: #1408854\nChange-Id: I971e04e06cfc95c08ead595f9d9552796ca19842\n""}]",0,145999,37a5daa532dfd458eca0b120513843be682e5c4c,4,2,1,4428,,,0,"Allow to specify IP address of floating ip

Since neutron now support specify IP address of floating ip[1],
we need to add option 'floating_ip_address' for creating floating
ip.

Closes-bug: #1408854
Change-Id: I971e04e06cfc95c08ead595f9d9552796ca19842
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/99/145999/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/neutron/v2_0/floatingip.py']",2,37a5daa532dfd458eca0b120513843be682e5c4c,specify-floating-ip," parser.add_argument( '--floating-ip-address', help=_('IP address of floating ip.')) parser.add_argument( '--floating_ip_address', help=argparse.SUPPRESS) if parsed_args.floating_ip_address: body[self.resource].update({'floating_ip_address': parsed_args.floating_ip_address})",,27,0
openstack%2Fsolum~master~If0668fc16bec6833c1d2bec02e50154c818927af,openstack/solum,master,If0668fc16bec6833c1d2bec02e50154c818927af,Fix worker cannot find build script on gate,MERGED,2015-01-12 18:43:49.000000000,2015-01-14 05:50:45.000000000,2015-01-14 05:50:20.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 14554}]","[{'number': 1, 'created': '2015-01-12 18:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e21c3a6a6d8c015d8fb96a5b1bb97775fcb00e31', 'message': 'Fix worker cannot find build script on gate\n\n1. Change devstack/lib/solum to use the correct proj_dir on gate;\n2. Change the conductor handler to make sure image.description is\nalways of str type.\n\nChange-Id: If0668fc16bec6833c1d2bec02e50154c818927af\nCloses-bug: #1408124\nCloses-bug: #1408125\n'}, {'number': 2, 'created': '2015-01-12 19:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d6bdf5a47fb2f6be72a217bfb48ad39822b80280', 'message': 'Fix worker cannot find build script on gate\n\n1. Change devstack/lib/solum to use the correct proj_dir on gate;\n2. Change the conductor handler to make sure image.description is\nalways of str type.\n\nChange-Id: If0668fc16bec6833c1d2bec02e50154c818927af\nCloses-bug: #1408124\nCloses-bug: #1408125\n'}, {'number': 3, 'created': '2015-01-13 03:24:31.000000000', 'files': ['contrib/devstack/lib/solum', 'solum/worker/handlers/shell.py', 'solum/conductor/handlers/default.py', 'functionaltests/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/solum/commit/ed323debdeae08ca7069a0fda4e397e11b79da80', 'message': 'Fix worker cannot find build script on gate\n\n1. Change devstack/lib/solum to use the correct proj_dir on gate;\n2. Change the conductor handler to make sure image.description is\nalways of str type.\n\nChange-Id: If0668fc16bec6833c1d2bec02e50154c818927af\nCloses-bug: #1408124\nCloses-bug: #1408125\n'}]",0,146605,ed323debdeae08ca7069a0fda4e397e11b79da80,21,5,3,6662,,,0,"Fix worker cannot find build script on gate

1. Change devstack/lib/solum to use the correct proj_dir on gate;
2. Change the conductor handler to make sure image.description is
always of str type.

Change-Id: If0668fc16bec6833c1d2bec02e50154c818927af
Closes-bug: #1408124
Closes-bug: #1408125
",git fetch https://review.opendev.org/openstack/solum refs/changes/05/146605/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/lib/solum', 'solum/worker/handlers/shell.py', 'solum/conductor/handlers/default.py', 'functionaltests/gate_hook.sh']",4,e21c3a6a6d8c015d8fb96a5b1bb97775fcb00e31,bug/1408124,export SOLUM_PROJ_DIR=/opt/stack/new/solum,,6,3
openstack%2Ffuel-main~master~I66acf1d7b1af7216296e5c2364e7d787906826bb,openstack/fuel-main,master,I66acf1d7b1af7216296e5c2364e7d787906826bb,DRAFT: Test for OS Patching,ABANDONED,2014-06-16 10:26:49.000000000,2015-01-14 05:39:58.000000000,,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-06-16 10:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c4b68bd0501a02ff9620dff344a0520088312218', 'message': 'DRAFT: Test for OS Patching\n\nChange-Id: I66acf1d7b1af7216296e5c2364e7d787906826bb\n'}, {'number': 2, 'created': '2014-06-16 10:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/558b56078d9369683b414255f6533e0f5b65d685', 'message': 'DRAFT: Test for OS Patching\n\nChange-Id: I66acf1d7b1af7216296e5c2364e7d787906826bb\n'}, {'number': 3, 'created': '2014-06-16 11:53:14.000000000', 'files': ['fuelweb_test/tests/os_patching/mirantis.key', 'fuelweb_test/tests/os_patching/prepare_update_tests.sh', 'fuelweb_test/tests/os_patching/update_test.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aa7f1adf0e28431a629d43a63a96bf7ebed3acfc', 'message': 'DRAFT: Test for OS Patching\n\nChange-Id: I66acf1d7b1af7216296e5c2364e7d787906826bb\n'}]",0,100212,aa7f1adf0e28431a629d43a63a96bf7ebed3acfc,16,5,3,8882,,,0,"DRAFT: Test for OS Patching

Change-Id: I66acf1d7b1af7216296e5c2364e7d787906826bb
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/12/100212/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/os_pathching/prepare_update_tests.sh'],1,c4b68bd0501a02ff9620dff344a0520088312218,test-os-patching,"#!/bin/sh centos_repo_archive=""centos-fuel-5.1-update.tgz"" ubuntu_repo_archive=""ubuntu-fuel-5.1-update.tgz"" repos_dir=""/var/www/nailgun"" puppet_releases=""/etc/puppet/releases"" puppet_modules=""/etc/puppet/modules"" puppet_manifests=""/etc/puppet/manifests"" modules_versions='5.0 5.1' ### functions ### upload_from_stdin() { dockerctl shell ""${1}"" ""tee ${2}"" > /dev/null } prepare_versioned_puppet() { cat <<EOF | upload_from_stdin rsync puppet_modules_update.sh modules_versions='${modules_versions}' if ! [ -d ""${puppet_modules}"" ]; then exit 1 fi if ! [ -d ""${puppet_manifests}"" ]; then exit 1 fi for version in ${modules_versions}; do mkdir -p ""${puppet_releases}/\${version}/modules"" mkdir -p ""${puppet_releases}/\${version}/manifests"" rsync -ca --delete ""${puppet_modules}/"" ""${puppet_releases}/\${version}/modules/"" rsync -ca --delete ""${puppet_manifests}/"" ""${puppet_releases}/\${version}/manifests/"" done EOF dockerctl shell rsync ""sh puppet_modules_update.sh"" } create_versions_files() { cat <<EOF | upload_from_stdin rsync ""${puppet_releases}/5.0/manifests/centos-versions.yaml"" --- openstack-glance: ""2014.1.fuel5.0-mira3"" EOF cat <<EOF | upload_from_stdin rsync ""${puppet_releases}/5.1/manifests/centos-versions.yaml"" --- openstack-glance: ""2014.1.fuel5.0-mira999"" EOF cat <<EOF | upload_from_stdin rsync ""${puppet_releases}/5.0/manifests/ubuntu-versions.yaml"" --- glance-api: 1:2014.1.fuel5.0~mira5 EOF cat <<EOF | upload_from_stdin rsync ""${puppet_releases}/5.1/manifests/ubuntu-versions.yaml"" --- glance-api: 1:2014.1.fuel5.0~mira999 EOF } untar_repos() { cat ""${centos_repo_archive}"" | upload_from_stdin nginx ""${centos_repo_archive}"" cat ""${ubuntu_repo_archive}"" | upload_from_stdin nginx ""${ubuntu_repo_archive}"" dockerctl shell nginx ""yum install -y -q tar"" dockerctl shell nginx ""tar -C ${repos_dir} -xf ${centos_repo_archive}"" dockerctl shell nginx ""tar -C ${repos_dir} -xf ${ubuntu_repo_archive}"" } cd_home() { DIR=$(dirname ""${0}"") cd ""${DIR}"" if [ $? -gt 0 ]; then echo ""Could not cd to ${DIR}!"" exit 1 fi } ## MAIN ## cd_home prepare_versioned_puppet create_versions_files untar_repos ",,88,0
openstack%2Ffuel-main~master~I53988018be6fd5cd13968d0b0c8ca82d193d0424,openstack/fuel-main,master,I53988018be6fd5cd13968d0b0c8ca82d193d0424,Change release name to lower case,MERGED,2015-01-12 15:00:33.000000000,2015-01-14 05:39:04.000000000,2015-01-14 05:39:02.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10136}]","[{'number': 1, 'created': '2015-01-12 15:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5d55370035d0c3cd28299718e443672d60b5de08', 'message': 'Change release name to lower case\n\nFor jjb compatibility we have to use lower case in OpenStack release name.\nCloses-Bug: #1409741\n\nChange-Id: I53988018be6fd5cd13968d0b0c8ca82d193d0424\n'}, {'number': 2, 'created': '2015-01-12 16:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c3cc10fc755abd91e2b6850a7444aea6801102b2', 'message': 'Change release name to lower case\n\nFor jjb compatibility we have to use lower case in OpenStack release name.\nCloses-Bug: #1409741\n\nChange-Id: I53988018be6fd5cd13968d0b0c8ca82d193d0424\n'}, {'number': 3, 'created': '2015-01-13 13:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4a0b7cfcbcf2e8f9bd2203196b068114dfb583f9', 'message': 'Change release name to lower case\n\nFor jjb compatibility we have to use lower case in OpenStack release name.\nCloses-Bug: #1409741\n\nChange-Id: I53988018be6fd5cd13968d0b0c8ca82d193d0424\n'}, {'number': 4, 'created': '2015-01-13 14:28:26.000000000', 'files': ['fuelweb_test/models/nailgun_client.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/88e7094a89f36cd44f5200e9cfba676ab103941a', 'message': 'Change release name to lower case\n\nFor jjb compatibility we have to use lower case in OpenStack release name.\nCloses-Bug: #1409741\n\nChange-Id: I53988018be6fd5cd13968d0b0c8ca82d193d0424\n'}]",0,146482,88e7094a89f36cd44f5200e9cfba676ab103941a,24,6,4,8882,,,0,"Change release name to lower case

For jjb compatibility we have to use lower case in OpenStack release name.
Closes-Bug: #1409741

Change-Id: I53988018be6fd5cd13968d0b0c8ca82d193d0424
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/82/146482/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/nailgun_client.py'],1,5d55370035d0c3cd28299718e443672d60b5de08,(detached," if release[""name""].lower().find(release_name.lower()) != -1:"," if release[""name""].find(release_name) != -1:",1,1
openstack%2Fnova~master~I7c428d47d89ee74453ab3b9171571208f2d71a67,openstack/nova,master,I7c428d47d89ee74453ab3b9171571208f2d71a67,Add unit tests for microversion and validation,ABANDONED,2014-12-09 11:20:31.000000000,2015-01-14 05:37:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 13663}]","[{'number': 1, 'created': '2014-12-09 11:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7148b6e81302b44dfbeb81d6f148b239e27a8971', 'message': ""Add unit tests for microversion and validation\n\nFor microversioning, we need to create API methods with @api_version()\nand @validation.schema() for strong REST APIs. However, we don't test\nthe combination in the unit tests. This patch adds them.\n\nPartially implements blueprint api-microversions\n\nChange-Id: I7c428d47d89ee74453ab3b9171571208f2d71a67\n""}, {'number': 2, 'created': '2014-12-18 04:24:07.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c432b31bb8b0f911ab2bca4fa2b1ec54dfa3e5d9', 'message': ""Add unit tests for microversion and validation\n\nFor microversioning, we need to create API methods with @api_version()\nand @validation.schema() for strong REST APIs. However, we don't test\nthe combination in the unit tests. This patch adds them.\n\nPartially implements blueprint api-microversions\n\nChange-Id: I7c428d47d89ee74453ab3b9171571208f2d71a67\n""}]",6,140300,c432b31bb8b0f911ab2bca4fa2b1ec54dfa3e5d9,29,12,2,6167,,,0,"Add unit tests for microversion and validation

For microversioning, we need to create API methods with @api_version()
and @validation.schema() for strong REST APIs. However, we don't test
the combination in the unit tests. This patch adds them.

Partially implements blueprint api-microversions

Change-Id: I7c428d47d89ee74453ab3b9171571208f2d71a67
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/140300/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/api/openstack/compute/test_plugins/microversions.py']",2,7148b6e81302b44dfbeb81d6f148b239e27a8971,bp/api-microversions,"from nova.api import validation test_schema = { 'type': 'object', 'properties': { 'foo': { 'type': 'string' } }, 'required': ['foo'], 'additionalProperties': False } @wsgi.Controller.api_version(""2.1"") @validation.schema(test_schema) def create(self, req, body): data = {'param': 'create_val'} return data @wsgi.Controller.api_version(""2.2"") # noqa @validation.schema(test_schema) def create(self, req, body): data = {'param': 'create_val2'} return data ",,75,2
openstack%2Fnova~master~I195bdcba7e1522b86279369bf10fa1743c363f15,openstack/nova,master,I195bdcba7e1522b86279369bf10fa1743c363f15,Do not decode binary data from crypt commands,ABANDONED,2015-01-13 17:31:56.000000000,2015-01-14 05:27:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}]","[{'number': 1, 'created': '2015-01-13 17:31:56.000000000', 'files': ['nova/crypto.py', 'nova/tests/unit/test_crypto.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b3e763f07562943b4b17d9e448e984d00bde9f9c', 'message': 'Do not decode binary data from crypt commands\n\nExplicitly disable decoding of output from commands that\nproduce binary output.\n\nThis change depends on https://review.openstack.org/146932\nin oslo.concurrency.\n\nCloses-Bug: #1410348\nChange-Id: I195bdcba7e1522b86279369bf10fa1743c363f15\n'}]",0,146937,b3e763f07562943b4b17d9e448e984d00bde9f9c,9,7,1,2472,,,0,"Do not decode binary data from crypt commands

Explicitly disable decoding of output from commands that
produce binary output.

This change depends on https://review.openstack.org/146932
in oslo.concurrency.

Closes-Bug: #1410348
Change-Id: I195bdcba7e1522b86279369bf10fa1743c363f15
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/146937/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/crypto.py', 'nova/tests/unit/test_crypto.py']",2,b3e763f07562943b4b17d9e448e984d00bde9f9c,bug/1410348," process_input=text, encoding=None)", process_input=text),4,2
openstack%2Fcongress~master~I671665436deacff449c5c578e57ed62e454ca37e,openstack/congress,master,I671665436deacff449c5c578e57ed62e454ca37e,Set all_tenants=True to populate all floating ips,MERGED,2015-01-13 08:45:15.000000000,2015-01-14 05:22:04.000000000,2015-01-14 05:22:02.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-13 08:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/a858469db3e29bf1029e4d21a88aab0857e182c1', 'message': 'Set all_tenants=True but it relies on Nova bug\nhttps://bugs.launchpad.net/nova/+bug/1402514 to export all\nfloating ips.\n\nChange-Id: I671665436deacff449c5c578e57ed62e454ca37e\nCloses-Bug: #1376462\n'}, {'number': 2, 'created': '2015-01-14 02:56:19.000000000', 'files': ['congress/datasources/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/edc09cdbeec1807970a2644cf873f86758580582', 'message': 'Set all_tenants=True to populate all floating ips\n\nThis patch still relies on Nova bug #1402514 to expose all\nfloating ips.\n\nChange-Id: I671665436deacff449c5c578e57ed62e454ca37e\nCloses-Bug: #1376462\n'}]",2,146799,edc09cdbeec1807970a2644cf873f86758580582,12,3,2,13790,,,0,"Set all_tenants=True to populate all floating ips

This patch still relies on Nova bug #1402514 to expose all
floating ips.

Change-Id: I671665436deacff449c5c578e57ed62e454ca37e
Closes-Bug: #1376462
",git fetch https://review.opendev.org/openstack/congress refs/changes/99/146799/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/datasources/nova_driver.py'],1,a858469db3e29bf1029e4d21a88aab0857e182c1,bug/1376462, self._translate_floating_ips(self.nova_client.floating_ips.list(all_tenants=True)), self._translate_floating_ips(self.nova_client.floating_ips.list()),1,1
openstack%2Fmistral~master~Id61ecaba661ce1ba608527b0c8e6a9dcd88c9eb9,openstack/mistral,master,Id61ecaba661ce1ba608527b0c8e6a9dcd88c9eb9,Update README file with devstack installation instruction,MERGED,2015-01-13 13:16:40.000000000,2015-01-14 05:14:10.000000000,2015-01-14 05:14:09.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-01-13 13:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/de65fffec3c5345f51c9094074186aecb4ae11de', 'message': 'Update README file with devstack installation instraction\n\nChange-Id: Id61ecaba661ce1ba608527b0c8e6a9dcd88c9eb9\n'}, {'number': 2, 'created': '2015-01-13 13:32:14.000000000', 'files': ['contrib/devstack/README.rst'], 'web_link': 'https://opendev.org/openstack/mistral/commit/5d503138439a0fb66836f8ffa52b106c008dce93', 'message': 'Update README file with devstack installation instruction\n\nChange-Id: Id61ecaba661ce1ba608527b0c8e6a9dcd88c9eb9\n'}]",0,146853,5d503138439a0fb66836f8ffa52b106c008dce93,10,4,2,8592,,,0,"Update README file with devstack installation instruction

Change-Id: Id61ecaba661ce1ba608527b0c8e6a9dcd88c9eb9
",git fetch https://review.opendev.org/openstack/mistral refs/changes/53/146853/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/README.rst'],1,de65fffec3c5345f51c9094074186aecb4ae11de,(detached,"1. Clone Mistral source code::1. Copy Mistral integration scripts to Devstack::1. Create/modify a ``localrc`` file as input to devstack::1. The Mistral service is not enabled by default, so it must be enabled in ``localrc``1. Deploy your OpenStack Cloud with Mistral::1. Python-mistralclient also will be automatically cloned and installed.","2. Clone Mistral source code::2. Copy Mistral integration scripts to Devstack::3. Create/modify a ``localrc`` file as input to devstack.4. The Mistral service is not enabled by default, so it must be enabled in ``localrc`` # Use Keystone Identity API v3 (override 2.0 default) IDENTITY_API_VERSION=3 5. Deploy your OpenStack Cloud with Mistral::2. Python-mistralclient also will be automatically cloned and installed.",6,9
openstack%2Fmagnum~master~I52e82c3b50854f80c86b6553e99d256962a38497,openstack/magnum,master,I52e82c3b50854f80c86b6553e99d256962a38497,Implement bay deletion on api,MERGED,2015-01-14 04:39:02.000000000,2015-01-14 05:09:23.000000000,2015-01-14 05:09:22.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}]","[{'number': 1, 'created': '2015-01-14 04:39:02.000000000', 'files': ['magnum/tests/api/controllers/v1/test_bay.py', 'magnum/api/controllers/v1/bay.py', 'magnum/conductor/handlers/bay_k8s_heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/f8ae58f2a27db4efe890553952df37fe2f0da7a3', 'message': 'Implement bay deletion on api\n\nHeat stack was not deleted when bay deleted. This fixes it.\n\nChange-Id: I52e82c3b50854f80c86b6553e99d256962a38497\nCloses-bug: #1410507\n'}]",0,147064,f8ae58f2a27db4efe890553952df37fe2f0da7a3,7,3,1,12385,,,0,"Implement bay deletion on api

Heat stack was not deleted when bay deleted. This fixes it.

Change-Id: I52e82c3b50854f80c86b6553e99d256962a38497
Closes-bug: #1410507
",git fetch https://review.opendev.org/openstack/magnum refs/changes/64/147064/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/api/controllers/v1/test_bay.py', 'magnum/api/controllers/v1/bay.py', 'magnum/conductor/handlers/bay_k8s_heat.py']",3,f8ae58f2a27db4efe890553952df37fe2f0da7a3,bug/1410507, # TODO(yuanying): handle stack status DELETE_IN_PROGRESS # TODO(yuanying): bay.destroy will be triggered by stack status change.,,10,3
openstack%2Fkeystonemiddleware~master~I7b249fc71894caafaf847bcfbb0c02907a740e6e,openstack/keystonemiddleware,master,I7b249fc71894caafaf847bcfbb0c02907a740e6e,support micro version if sent,MERGED,2014-10-25 02:14:06.000000000,2015-01-14 04:55:23.000000000,2015-01-14 04:55:21.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8871}, {'_account_id': 9101}, {'_account_id': 9142}, {'_account_id': 10873}, {'_account_id': 11022}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-10-25 02:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/94fa3e9488a6f9da86db61aca11470d9bff4139c', 'message': ""support micro version if sent\n\nDon't hard coded to check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 2, 'created': '2014-10-29 09:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/0b987a756ea3f4db19210291aaea2605a84d18bc', 'message': ""support micro version if sent\n\nDon't hard coded to check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 3, 'created': '2014-12-09 09:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8f8d2568d2a6338d64121d59733049592b236f06', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 4, 'created': '2014-12-10 02:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/871a215cfdb1942fe4a965a810aa2cfce799a2d9', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 5, 'created': '2014-12-12 02:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c7d4e0bd7438e757c40671bcd3fb35713f402bfc', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 6, 'created': '2014-12-17 08:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/75bbc21d0112e982b36404b953fdd87cb74d28fc', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 7, 'created': '2014-12-22 09:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e4de086b4cda1ef37834914d0afbe6eb098be419', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 8, 'created': '2014-12-23 01:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c6458db3bd91416e89e9abe1cce464b7dab0a302', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 9, 'created': '2014-12-29 03:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4077f6b7933813f547b1caef812055edc46f12a8', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}, {'number': 10, 'created': '2015-01-07 07:56:46.000000000', 'files': ['keystonemiddleware/auth_token.py', 'keystonemiddleware/tests/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4e20760a6f55e4360dd2616c5738abec2774a198', 'message': ""support micro version if sent\n\nDon't hard code the check for version 3.0, support micro version such\nas v3.1, v3.1.1, v3.2 etc...\n\nChange-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e\nCloses-Bug: #1383853\n""}]",23,130916,4e20760a6f55e4360dd2616c5738abec2774a198,71,11,10,9101,,,0,"support micro version if sent

Don't hard code the check for version 3.0, support micro version such
as v3.1, v3.1.1, v3.2 etc...

Change-Id: I7b249fc71894caafaf847bcfbb0c02907a740e6e
Closes-Bug: #1383853
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/16/130916/5 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,94fa3e9488a6f9da86db61aca11470d9bff4139c,bug/1383853, if self._auth_version.startswith('v3'): if self._auth_version.startswith('v3'):, if self._auth_version == 'v3.0': if self._auth_version == 'v3.0':,2,2
openstack%2Fmistral~master~I165b567a3cece658885a0ee60f87f2cd0fd0fbbd,openstack/mistral,master,I165b567a3cece658885a0ee60f87f2cd0fd0fbbd,Updating YAQL dependency to version 0.2.4,MERGED,2015-01-13 14:10:11.000000000,2015-01-14 04:53:50.000000000,2015-01-14 04:53:49.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-01-13 14:10:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e60bc1c24130ffefb2c991b6672e95e1954f7843', 'message': ""Updating YAQL dependency to version 0.2.4\n\n* In yaql-0.2.3 there was bug that caused wrong evaluation of\n  functions applied to empty collections. It's fixed in yaql-0.2.4.\n\nChange-Id: I165b567a3cece658885a0ee60f87f2cd0fd0fbbd\n""}]",0,146875,e60bc1c24130ffefb2c991b6672e95e1954f7843,9,5,1,8731,,,0,"Updating YAQL dependency to version 0.2.4

* In yaql-0.2.3 there was bug that caused wrong evaluation of
  functions applied to empty collections. It's fixed in yaql-0.2.4.

Change-Id: I165b567a3cece658885a0ee60f87f2cd0fd0fbbd
",git fetch https://review.opendev.org/openstack/mistral refs/changes/75/146875/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e60bc1c24130ffefb2c991b6672e95e1954f7843,update_yaql_version,"yaql>=0.2.4,<0.3 # This is not in global requirements",yaql==0.2.3 # This is not in global requirements,1,1
openstack%2Fmagnum~master~I041ee8a4e111d6c900ff6d654eeb23d61fff28ff,openstack/magnum,master,I041ee8a4e111d6c900ff6d654eeb23d61fff28ff,Add rc_data support for magnum replication controller,MERGED,2015-01-13 23:54:14.000000000,2015-01-14 04:51:41.000000000,2015-01-14 04:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 23:54:14.000000000', 'files': ['magnum/tests/conductor/handlers/test_kube.py', 'magnum/objects/replicationcontroller.py', 'magnum/api/controllers/v1/replicationcontroller.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9c68323035269e79ebc2e418d126a834f5c5ae5c', 'message': 'Add rc_data support for magnum replication controller\n\nChange-Id: I041ee8a4e111d6c900ff6d654eeb23d61fff28ff\n'}]",0,147020,9c68323035269e79ebc2e418d126a834f5c5ae5c,8,4,1,7494,,,0,"Add rc_data support for magnum replication controller

Change-Id: I041ee8a4e111d6c900ff6d654eeb23d61fff28ff
",git fetch https://review.opendev.org/openstack/magnum refs/changes/20/147020/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/conductor/handlers/test_kube.py', 'magnum/objects/replicationcontroller.py', 'magnum/api/controllers/v1/replicationcontroller.py', 'magnum/conductor/handlers/kube.py']",4,9c68323035269e79ebc2e418d126a834f5c5ae5c,master," k8s_master_url = _retrive_k8s_master_url(ctxt, rc) status = self.kube_cli.rc_create(k8s_master_url, rc)", status = self.kube_cli.rc_create(rc),31,2
openstack%2Foctavia~master~Ib88570e06e6d99e14482dfe2a8b1853b5da83b16,openstack/octavia,master,Ib88570e06e6d99e14482dfe2a8b1853b5da83b16,Fixed my alembic version fail,MERGED,2015-01-13 22:22:10.000000000,2015-01-14 04:50:51.000000000,2015-01-14 04:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 6951}]","[{'number': 1, 'created': '2015-01-13 22:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6f4a9f3f32fd2411e6017e3835d9f289c43bc770', 'message': 'Fixed my alembic version fail\n\nop.batch_alter_table needs alembic 0.7.  Also antoher review\nmerged before the one that added the update_vip migration\nso it needed to be relinked.\n\nChange-Id: Ib88570e06e6d99e14482dfe2a8b1853b5da83b16\n'}, {'number': 2, 'created': '2015-01-13 22:30:19.000000000', 'files': ['requirements.txt', 'octavia/db/migration/alembic_migrations/versions/14892634e228_update_vip.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e7cad32fb98d93ced5673441478ec33e99a71677', 'message': 'Fixed my alembic version fail\n\nop.batch_alter_table needs alembic 0.7. Also antoher review\nmerged before the one that added the update_vip migration\nso it needed to be relinked.\n\nChange-Id: Ib88570e06e6d99e14482dfe2a8b1853b5da83b16\n'}]",0,146996,e7cad32fb98d93ced5673441478ec33e99a71677,8,2,2,6951,,,0,"Fixed my alembic version fail

op.batch_alter_table needs alembic 0.7. Also antoher review
merged before the one that added the update_vip migration
so it needed to be relinked.

Change-Id: Ib88570e06e6d99e14482dfe2a8b1853b5da83b16
",git fetch https://review.opendev.org/openstack/octavia refs/changes/96/146996/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'octavia/db/migration/alembic_migrations/versions/14892634e228_update_vip.py']",2,6f4a9f3f32fd2411e6017e3835d9f289c43bc770,bug/alembic-version,Revises: 3a1e1cdb7b27down_revision = '3a1e1cdb7b27',Revises: 13500e2e978ddown_revision = '13500e2e978d',3,3
openstack%2Fbarbican~master~I957d3814ce8b398afad92825969bad16c70529cf,openstack/barbican,master,I957d3814ce8b398afad92825969bad16c70529cf,Updated from global requirements,MERGED,2015-01-13 23:59:52.000000000,2015-01-14 03:53:09.000000000,2015-01-14 03:53:08.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}]","[{'number': 1, 'created': '2015-01-13 23:59:52.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/5ad9232ef04f46846630a7e6b5a6eb42ca678e1e', 'message': 'Updated from global requirements\n\nChange-Id: I957d3814ce8b398afad92825969bad16c70529cf\n'}]",0,147023,5ad9232ef04f46846630a7e6b5a6eb42ca678e1e,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I957d3814ce8b398afad92825969bad16c70529cf
",git fetch https://review.opendev.org/openstack/barbican refs/changes/23/147023/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5ad9232ef04f46846630a7e6b5a6eb42ca678e1e,openstack/requirements,"oslo.concurrency>=0.3.0,!=0.4.0 # Apache-2.0",oslo.concurrency>=0.3.0 # Apache-2.0,1,1
openstack%2Ftripleo-image-elements~master~Ibd7b88b50727fe8780c9fb9f01b9eb9115570b15,openstack/tripleo-image-elements,master,Ibd7b88b50727fe8780c9fb9f01b9eb9115570b15,Enable Bulk requests middleware in swift proxy pipeline,MERGED,2014-11-28 10:14:49.000000000,2015-01-14 03:14:51.000000000,2015-01-14 03:14:50.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 860}, {'_account_id': 1872}, {'_account_id': 6928}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-11-28 10:14:49.000000000', 'files': ['elements/swift-proxy/os-apply-config/etc/swift/proxy-server.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/d7c17b249df67b84cada9c792f3db83d762de330', 'message': 'Enable Bulk requests middleware in swift proxy pipeline\n\nThe bulk requests middleware was introduced into swift in the\ngrizzly release. It allows swift to perform many operations\nas a result of a single API request\n  - Extract Archive: Uploaded archive will automatically expand and\n    store the individual files into swift.\n  - Bulk Delete: Delete multiple objects or containers from their\n    account with a single request\n\nChange-Id: Ibd7b88b50727fe8780c9fb9f01b9eb9115570b15\n'}]",0,137752,d7c17b249df67b84cada9c792f3db83d762de330,11,6,1,1253,,,0,"Enable Bulk requests middleware in swift proxy pipeline

The bulk requests middleware was introduced into swift in the
grizzly release. It allows swift to perform many operations
as a result of a single API request
  - Extract Archive: Uploaded archive will automatically expand and
    store the individual files into swift.
  - Bulk Delete: Delete multiple objects or containers from their
    account with a single request

Change-Id: Ibd7b88b50727fe8780c9fb9f01b9eb9115570b15
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/52/137752/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift-proxy/os-apply-config/etc/swift/proxy-server.conf'],1,d7c17b249df67b84cada9c792f3db83d762de330,add-bulk-to-pipeline,pipeline = catch_errors healthcheck proxy-logging cache bulk crossdomain tempurl formpost authtoken keystoneauth staticweb container-quotas account-quotas slo proxy-logging proxy-server[filter:bulk] use = egg:swift#bulk ,pipeline = catch_errors healthcheck proxy-logging cache crossdomain tempurl formpost authtoken keystoneauth staticweb container-quotas account-quotas slo proxy-logging proxy-server,4,1
openstack%2Ftripleo-image-elements~master~I969dc6753224aed7165ba264d3fddf6f6fa1542b,openstack/tripleo-image-elements,master,I969dc6753224aed7165ba264d3fddf6f6fa1542b,Swift proxy memcache authtoken additions,MERGED,2014-12-04 16:39:33.000000000,2015-01-14 03:06:15.000000000,2015-01-14 03:06:14.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1253}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-12-04 16:39:33.000000000', 'files': ['elements/swift-proxy/os-apply-config/etc/swift/proxy-server.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/2d1f4cc934920c0758a22ed359cc5ea10030ef3c', 'message': 'Swift proxy memcache authtoken additions\n\nNow that memcache is enabled on Swift proxies, we want to make use\nof it for caching of Keystone authtokens.  There are two parts to\nthis.  First of all, when Swift memcache is enabled - as confirmed\nby the existence of swift.proxy-memcache metadata - we want to\nuse this cache for authtokens by setting\n   cache = swift.cache\nin the [filter:authtoken] stanza.  Secondly, many Swift deployments\nwill want to encrypt these cached tokens for security reasons.  To\nenable this, we set the swift.encrypt-authtoken metadata to\nsomething other than null.  Furthermore, we need to provide an\nencryption key which will need to be unique to each deployment.\nWe use the value of swift.hash for this key.\n\nChange-Id: I969dc6753224aed7165ba264d3fddf6f6fa1542b\n'}]",0,139107,2d1f4cc934920c0758a22ed359cc5ea10030ef3c,9,4,1,1005,,,0,"Swift proxy memcache authtoken additions

Now that memcache is enabled on Swift proxies, we want to make use
of it for caching of Keystone authtokens.  There are two parts to
this.  First of all, when Swift memcache is enabled - as confirmed
by the existence of swift.proxy-memcache metadata - we want to
use this cache for authtokens by setting
   cache = swift.cache
in the [filter:authtoken] stanza.  Secondly, many Swift deployments
will want to encrypt these cached tokens for security reasons.  To
enable this, we set the swift.encrypt-authtoken metadata to
something other than null.  Furthermore, we need to provide an
encryption key which will need to be unique to each deployment.
We use the value of swift.hash for this key.

Change-Id: I969dc6753224aed7165ba264d3fddf6f6fa1542b
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/07/139107/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/swift-proxy/os-apply-config/etc/swift/proxy-server.conf'],1,2d1f4cc934920c0758a22ed359cc5ea10030ef3c,swift-authtoken-memcache,{{#swift.proxy-memcache}} cache = swift.cache {{#swift.encrypt-authtoken}} memcache_security_strategy = ENCRYPT memcache_secret_key = {{swift.hash}} {{/swift.encrypt-authtoken}} {{/swift.proxy-memcache}},,7,0
openstack%2Fcinder~master~I011888f676ebc170e7285048b7e5a638a5a8c9a9,openstack/cinder,master,I011888f676ebc170e7285048b7e5a638a5a8c9a9,Use lockutils.set_defaults to set lock_path in test,MERGED,2015-01-13 22:30:27.000000000,2015-01-14 03:05:12.000000000,2015-01-14 01:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6043}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 14259}]","[{'number': 1, 'created': '2015-01-13 22:30:27.000000000', 'files': ['cinder/test.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b2ce8b2ef648b9c00dee53b84ca00b2a05ae3e2', 'message': ""Use lockutils.set_defaults to set lock_path in test\n\nCommit 9dd6d212f0d8fd74c29077a786fb6d770a2a0bba for oslo.concurrency's\nlockutils appears to have broken our unit tests.\n\nTwelve of the the storwize_svc unit tests started failing with the\ncomplaint that the required configuration option 'lock_path' was not set.\n\nThis change updates cinder/test.py to not only set up a temporary\nlock_path location that will be automatically cleaned up, but to also\nregister that temporary lock_path location using lockutils.set_defaults()\nto correct the problem.\n\nChange-Id: I011888f676ebc170e7285048b7e5a638a5a8c9a9\nCloses-bug: 1410485\n""}]",0,146997,1b2ce8b2ef648b9c00dee53b84ca00b2a05ae3e2,16,12,1,7198,,,0,"Use lockutils.set_defaults to set lock_path in test

Commit 9dd6d212f0d8fd74c29077a786fb6d770a2a0bba for oslo.concurrency's
lockutils appears to have broken our unit tests.

Twelve of the the storwize_svc unit tests started failing with the
complaint that the required configuration option 'lock_path' was not set.

This change updates cinder/test.py to not only set up a temporary
lock_path location that will be automatically cleaned up, but to also
register that temporary lock_path location using lockutils.set_defaults()
to correct the problem.

Change-Id: I011888f676ebc170e7285048b7e5a638a5a8c9a9
Closes-bug: 1410485
",git fetch https://review.opendev.org/openstack/cinder refs/changes/97/146997/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/test.py'],1,1b2ce8b2ef648b9c00dee53b84ca00b2a05ae3e2,bug/1410485, lockutils.set_defaults(lock_path),,1,0
openstack%2Fnova~master~I8379471eea4ea7b114c2a235224f6fe61f8f981f,openstack/nova,master,I8379471eea4ea7b114c2a235224f6fe61f8f981f,Removing the headroom calculation from db layer,MERGED,2014-09-16 09:20:48.000000000,2015-01-14 03:01:35.000000000,2014-12-02 02:55:15.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 4428}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9545}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-09-16 09:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f5bc722a8faeb95b7868382c341793c1a12f4c3', 'message': ""Removing the headroom calculation from db layer\n\nIt's odd that this is happening in the DB API because it's dealing\nwith instance quotas but maybe I'm not doing anything with instance\nquotas, maybe I'm doing things with security group or fixed IP quotas.\n\nThis patch moves the headroom calculation from db layer to the\ncalling side.\n\nChange-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f\nCloses-bug: #1369696\n""}, {'number': 2, 'created': '2014-09-16 13:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6b994baf521c35fe507ee763d573f44094428c2', 'message': ""Removing the headroom calculation from db layer\n\nIt's odd that this is happening in the DB API because it's dealing\nwith instance quotas but maybe I'm not doing anything with instance\nquotas, maybe I'm doing things with security group or fixed IP quotas.\n\nThis patch moves the headroom calculation from db layer to the\ncalling side.\n\nChange-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f\nCloses-bug: #1369696\n""}, {'number': 3, 'created': '2014-11-18 00:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc67648903e399ede1744242808033556d62d585', 'message': ""Removing the headroom calculation from db layer\n\nIt's odd that this is happening in the DB API because it's dealing\nwith instance quotas but maybe I'm not doing anything with instance\nquotas, maybe I'm doing things with security group or fixed IP quotas.\n\nThis patch moves the headroom calculation from db layer to the\ncalling side.\n\nChange-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f\nCloses-bug: #1369696\n""}, {'number': 4, 'created': '2014-11-24 07:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6af7057e77b92c9723231122bbed24930e4d9f44', 'message': ""Removing the headroom calculation from db layer\n\nIt's odd that this is happening in the DB API because it's dealing\nwith instance quotas but maybe I'm not doing anything with instance\nquotas, maybe I'm doing things with security group or fixed IP quotas.\n\nThis patch moves the headroom calculation from db layer to the\ncalling side.\n\nChange-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f\nCloses-bug: #1369696\n""}, {'number': 5, 'created': '2014-11-28 05:00:38.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/test_quota.py', 'nova/tests/unit/api/openstack/fakes.py', 'nova/compute/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0045f7d50cad345c26ae02394ad57716b270d268', 'message': ""Removing the headroom calculation from db layer\n\nIt's odd that this is happening in the DB API because it's dealing\nwith instance quotas but maybe I'm not doing anything with instance\nquotas, maybe I'm doing things with security group or fixed IP quotas.\n\nThis patch moves the headroom calculation from db layer to the\ncalling side.\n\nChange-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f\nCloses-bug: #1369696\n""}]",2,121786,0045f7d50cad345c26ae02394ad57716b270d268,68,17,5,4428,,,0,"Removing the headroom calculation from db layer

It's odd that this is happening in the DB API because it's dealing
with instance quotas but maybe I'm not doing anything with instance
quotas, maybe I'm doing things with security group or fixed IP quotas.

This patch moves the headroom calculation from db layer to the
calling side.

Change-Id: I8379471eea4ea7b114c2a235224f6fe61f8f981f
Closes-bug: #1369696
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/121786/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/api/openstack/fakes.py', 'nova/tests/compute/test_compute_api.py', 'nova/compute/api.py', 'nova/db/sqlalchemy/api.py']",4,3f5bc722a8faeb95b7868382c341793c1a12f4c3,move-headroom, usages=usages)," headroom = dict((res, user_quotas[res] - (usages[res]['in_use'] + usages[res]['reserved'])) for res in user_quotas.keys()) # If quota_cores is unlimited [-1]: # - set cores headroom based on instances headroom: if user_quotas.get('cores') == -1: if deltas['cores']: hc = headroom['instances'] * deltas['cores'] headroom['cores'] = hc / deltas['instances'] else: headroom['cores'] = headroom['instances'] # If quota_ram is unlimited [-1]: # - set ram headroom based on instances headroom: if user_quotas.get('ram') == -1: if deltas['ram']: hr = headroom['instances'] * deltas['ram'] headroom['ram'] = hr / deltas['instances'] else: headroom['ram'] = headroom['instances'] usages=usages, headroom=headroom)",34,37
openstack%2Ftripleo-image-elements~master~I86feca5b31be9b323931e5344046e683f0fcee75,openstack/tripleo-image-elements,master,I86feca5b31be9b323931e5344046e683f0fcee75,Give ceilometer.conf rabbit_port a default,MERGED,2015-01-09 18:45:00.000000000,2015-01-14 02:59:24.000000000,2015-01-14 02:59:23.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6671}, {'_account_id': 8449}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-01-09 18:45:00.000000000', 'files': ['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/71d0fea4c7eeb66a7ea6ad0284d40660993f771a', 'message': ""Give ceilometer.conf rabbit_port a default\n\nThe undercloud heat template doesn't supply a rabbit_port parameter,\nand at this time there's no particular reason it should.  Instead of\nadding an unnecessary configuration option to the heat template, let's\njust provide a sane default in the conf file template.\n\nChange-Id: I86feca5b31be9b323931e5344046e683f0fcee75\nRelated: I16825f5bb9e4fc00f686ce11d6caf87155c4580a\n""}]",0,146175,71d0fea4c7eeb66a7ea6ad0284d40660993f771a,10,5,1,6928,,,0,"Give ceilometer.conf rabbit_port a default

The undercloud heat template doesn't supply a rabbit_port parameter,
and at this time there's no particular reason it should.  Instead of
adding an unnecessary configuration option to the heat template, let's
just provide a sane default in the conf file template.

Change-Id: I86feca5b31be9b323931e5344046e683f0fcee75
Related: I16825f5bb9e4fc00f686ce11d6caf87155c4580a
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/75/146175/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ceilometer/os-apply-config/etc/ceilometer/ceilometer.conf'],1,71d0fea4c7eeb66a7ea6ad0284d40660993f771a,rabbit-port,{{#rabbit_port}} rabbit_port={{.}} {{/rabbit_port}} {{^rabbit_port}} rabbit_port=5672 {{/rabbit_port}},rabbit_port={{rabbit.rabbit_port}},6,1
openstack%2Fpuppet-nova~stable%2Ficehouse~I711aa640726cba76a0cb64ae685b9c3e282f8395,openstack/puppet-nova,stable/icehouse,I711aa640726cba76a0cb64ae685b9c3e282f8395,Correct section for cell_type nova.conf parameter,MERGED,2015-01-13 00:13:24.000000000,2015-01-14 02:30:35.000000000,2015-01-14 02:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 7155}, {'_account_id': 9060}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-01-13 00:13:24.000000000', 'files': ['spec/classes/nova_cells_spec.rb', 'manifests/cells.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8c1f2f65c321855dafdb3d4832c2eb2e09891216', 'message': 'Correct section for cell_type nova.conf parameter\n\nMove the cell_type parameter to the [cells] section, from the\n[DEFAULT] section.\n\nChange-Id: I711aa640726cba76a0cb64ae685b9c3e282f8395\nCloses-bug: 1403174\n(cherry picked from commit a744554e4a7b33e714969eef2db886ac060ed58d)\n'}]",0,146702,8c1f2f65c321855dafdb3d4832c2eb2e09891216,7,5,1,7156,,,0,"Correct section for cell_type nova.conf parameter

Move the cell_type parameter to the [cells] section, from the
[DEFAULT] section.

Change-Id: I711aa640726cba76a0cb64ae685b9c3e282f8395
Closes-bug: 1403174
(cherry picked from commit a744554e4a7b33e714969eef2db886ac060ed58d)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/02/146702/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_cells_spec.rb', 'manifests/cells.pp']",2,8c1f2f65c321855dafdb3d4832c2eb2e09891216,, nova_config { 'cells/cell_type': value => 'api' } nova_config { 'cells/cell_type': value => 'compute' }, nova_config { 'DEFAULT/cell_type': value => 'api' } nova_config { 'DEFAULT/cell_type': value => 'compute' },4,2
openstack%2Ftricircle~master~I1fee40f147d92631c38cef6dd0822cc6a7340a23,openstack/tricircle,master,I1fee40f147d92631c38cef6dd0822cc6a7340a23,modify l2-proxy to process unauthorized exception when query port,MERGED,2015-01-14 02:22:28.000000000,2015-01-14 02:28:19.000000000,2015-01-14 02:28:19.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2015-01-14 02:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/551ffdbef0ca1e2ff879d7f526f8872147e92fb1', 'message': 'modify l2-proxy to process unauthorized exception when query port\n\nChange-Id: I1fee40f147d92631c38cef6dd0822cc6a7340a23\n'}, {'number': 2, 'created': '2015-01-14 02:26:49.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/236e2167b0077063d48bf7fa90c5ba3bb0287475', 'message': 'modify l2-proxy to process unauthorized exception when query port\n\nChange-Id: I1fee40f147d92631c38cef6dd0822cc6a7340a23\n'}]",0,147053,236e2167b0077063d48bf7fa90c5ba3bb0287475,8,2,2,9778,,,0,"modify l2-proxy to process unauthorized exception when query port

Change-Id: I1fee40f147d92631c38cef6dd0822cc6a7340a23
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/53/147053/2 && git format-patch -1 --stdout FETCH_HEAD,['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'],1,551ffdbef0ca1e2ff879d7f526f8872147e92fb1,, with excutils.save_and_reraise_exception(): LOG.error(_('ERR: Unauthorized to list ports!')) return None skipped_devices.appand(device)," QueryPortsInfoInterface.cascaded_neutron_client = \ self._get_cascaded_neutron_client() return self._list_ports(since_time, pagination_limit, pagination_marker) skipped_devices.add(device)",4,6
openstack%2Fneutron~stable%2Fjuno~I9ef5c1a7cf564651b11b983185bd8d6b625a04dd,openstack/neutron,stable/juno,I9ef5c1a7cf564651b11b983185bd8d6b625a04dd,Issue warning when running DHCP agent with dnsmasq < 2.67,MERGED,2015-01-08 14:01:47.000000000,2015-01-14 02:00:57.000000000,2015-01-13 21:49:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 642}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 7787}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12524}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-08 14:01:47.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/097607aa8bdf1dd73b83257b439a78a7dec0fb88', 'message': 'Issue warning when running DHCP agent with dnsmasq < 2.67\n\ndnsmasq < 2.67 does not support hwaddr matching for IPv6 clients, meaning IPv6\nstateful subnets fail to provide IP addresses to instances.\n\nQuoting dnsmasq CHANGELOG:\n\n""\nversion 2.67\n[...]\n    Support identification of clients by MAC address in\n    DHCPv6. When using a relay, the relay must support RFC\n    6939 for this to work. It always works for directly\n    connected clients. Thanks to Vladislav Grishenko\n    for prompting this feature.\n""\n\nWe cannot just exit as we do for dnsmasq < 2.63 since that would potentially\nbreak DHCP agent startup for users that fetch the fix from git without bumping\ndnsmasq version.\n\nAppropriate release note will be added to notify operators about\nincompatibility issue.\n\nChange-Id: I9ef5c1a7cf564651b11b983185bd8d6b625a04dd\nCloses-Bug: #1408297\n'}]",2,145784,097607aa8bdf1dd73b83257b439a78a7dec0fb88,35,24,1,9656,,,0,"Issue warning when running DHCP agent with dnsmasq < 2.67

dnsmasq < 2.67 does not support hwaddr matching for IPv6 clients, meaning IPv6
stateful subnets fail to provide IP addresses to instances.

Quoting dnsmasq CHANGELOG:

""
version 2.67
[...]
    Support identification of clients by MAC address in
    DHCPv6. When using a relay, the relay must support RFC
    6939 for this to work. It always works for directly
    connected clients. Thanks to Vladislav Grishenko
    for prompting this feature.
""

We cannot just exit as we do for dnsmasq < 2.63 since that would potentially
break DHCP agent startup for users that fetch the fix from git without bumping
dnsmasq version.

Appropriate release note will be added to notify operators about
incompatibility issue.

Change-Id: I9ef5c1a7cf564651b11b983185bd8d6b625a04dd
Closes-Bug: #1408297
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/145784/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,097607aa8bdf1dd73b83257b439a78a7dec0fb88,bug/1408297," def test_check_version_ipv6_succeed(self): with mock.patch('neutron.agent.linux.dhcp.LOG.warning') as warning: self._check_version('Dnsmasq version 2.69 Copyright (c)...', float(2.69)) self.assertFalse(warning.called) def test_check_version_ipv6_fail(self): with mock.patch('neutron.agent.linux.dhcp.LOG.warning') as warning: self._check_version('Dnsmasq version 2.66 Copyright (c)...', float(2.66)) self.assertTrue(warning.called) ",,20,0
openstack%2Fkeystoneauth-saml2~master~Iefd1295ca17a1b4de81504c38e647141711f56cf,openstack/keystoneauth-saml2,master,Iefd1295ca17a1b4de81504c38e647141711f56cf,Updated from global requirements,MERGED,2015-01-02 18:21:19.000000000,2015-01-14 01:49:53.000000000,2015-01-14 01:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-01-02 18:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/7a44bfbd32dd41915e779cdace745b06643a038f', 'message': 'Updated from global requirements\n\nChange-Id: Iefd1295ca17a1b4de81504c38e647141711f56cf\n'}, {'number': 2, 'created': '2015-01-14 00:15:00.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/9dc2af8cccf86789f646893a0762ecfdc8b75e29', 'message': 'Updated from global requirements\n\nChange-Id: Iefd1295ca17a1b4de81504c38e647141711f56cf\n'}]",0,144785,9dc2af8cccf86789f646893a0762ecfdc8b75e29,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: Iefd1295ca17a1b4de81504c38e647141711f56cf
",git fetch https://review.opendev.org/openstack/keystoneauth-saml2 refs/changes/85/144785/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7a44bfbd32dd41915e779cdace745b06643a038f,openstack/requirements,"sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3 oslosphinx>=2.2.0 # Apache-2.0 oslotest>=1.2.0 # Apache-2.0testtools>=0.9.36,!=1.2.0","sphinx>=1.1.2,!=1.2.0,<1.3 oslosphinx>=2.2.0.0a2 oslotest>=1.1.0.0a2testtools>=0.9.34",4,4
openstack%2Fkeystone~master~I305abd8446fee57af18aebf7873e3c67a1b83c92,openstack/keystone,master,I305abd8446fee57af18aebf7873e3c67a1b83c92,Always return the service name in the catalog,MERGED,2014-11-20 01:33:31.000000000,2015-01-14 01:44:21.000000000,2015-01-14 01:44:16.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7244}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 8978}, {'_account_id': 11022}, {'_account_id': 11333}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-20 01:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d30ca4a3ff8d561aa42a3685a631a50d906552ae', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, so that\nit won't blow up if there is no service name.\n\nThe name attribute of the service will now always be included\nin the service catalog. The value will be defaulted to empty\nstring if no service name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 2, 'created': '2014-11-20 10:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0b361bf8bb58b8220b04de21a217493f82a33e6a', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, so that\nit won't blow up if there is no service name.\n\nThe name attribute of the service will now always be included\nin the service catalog. The value will be defaulted to empty\nstring if no service name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 3, 'created': '2014-11-20 17:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/58cc72bcdb13d4286b5c0ef1f9bea51bf931b352', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, so that\nit won't blow up if there is no service name.\n\nThe name attribute of the service will now always be included\nin the service catalog. The value will be defaulted to empty\nstring if no service name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 4, 'created': '2014-11-21 02:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b092fb8983cc2f149cc0b6bfbf2d8304936bbca5', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from sql.DictBase\nparent class of Service. Instead the service name have to be directly read\nfrom the 'extra' attribute of the service object using\nservice.extra.get('name', '').\n\nThe name attribute of the service will now always be included\nin the service catalog. The value will be defaulted to empty\nstring if no service name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 5, 'created': '2014-11-21 02:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c8bc01551a0329a68e3e65a3ecc70fd6883a1428', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from\nsql.DictBase parent class of Service. Instead the service name have to\nbe directly read from the 'extra' attribute of the service object using\nservice.extra.get('name', '').\n\nThe name attribute of the service will now always be included in the\nservice catalog. The value will be defaulted to empty string if no\nservice name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 6, 'created': '2014-11-21 14:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cbae37b5732cf2b6d701d7456c9bb235b5ff8232', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from\nsql.DictBase parent class of Service. Instead the service name have to\nbe directly read from the 'extra' attribute of the service object using\nservice.extra.get('name', '').\n\nThe name attribute of the service will now always be included in the\nservice catalog. The value will be defaulted to empty string if no\nservice name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 7, 'created': '2014-11-23 15:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9fa76d279557f33a525d5c5118f51e73bfc98e2c', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from\nsql.DictBase parent class of Service. Instead the service name have to\nbe directly read from the 'extra' attribute of the service object using\nservice.extra.get('name', '').\n\nThe name attribute of the service will now always be included in the\nservice catalog. The value will be defaulted to empty string if no\nservice name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 8, 'created': '2014-11-24 11:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0a3d0c6c0f84dd9f1478d8ec8f0c714dc150e1b0', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from\nsql.DictBase parent class of Service. Instead the service name have to\nbe directly read from the 'extra' attribute of the service object using\nservice.extra.get('name', '').\nThe name attribute of the service will now always be included in the\nservice catalog. The value will be defaulted to empty string if no\nservice name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}, {'number': 9, 'created': '2014-12-18 05:40:49.000000000', 'files': ['keystone/tests/test_catalog.py', 'keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ca3df19da46e330cd9ce1de77224452177f06071', 'message': ""Always return the service name in the catalog\n\nFix implemention of service catalog creation in v2, to handle the case\nwhen the service name is not available. Using service.get('name', '')\ndoes not work because that doesn't invoke the __getitem__() from\nsql.DictBase parent class of Service. Instead the service name have to\nbe directly read from the 'extra' attribute of the service object using\nservice.extra.get('name', '').\nThe name attribute of the service will now always be included in the\nservice catalog. The value will be defaulted to empty string if no\nservice name is available.\n\nChange-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92\nCloses-Bug: #1393518\n""}]",27,135808,ca3df19da46e330cd9ce1de77224452177f06071,59,14,9,1941,,,0,"Always return the service name in the catalog

Fix implemention of service catalog creation in v2, to handle the case
when the service name is not available. Using service.get('name', '')
does not work because that doesn't invoke the __getitem__() from
sql.DictBase parent class of Service. Instead the service name have to
be directly read from the 'extra' attribute of the service object using
service.extra.get('name', '').
The name attribute of the service will now always be included in the
service catalog. The value will be defaulted to empty string if no
service name is available.

Change-Id: I305abd8446fee57af18aebf7873e3c67a1b83c92
Closes-Bug: #1393518
",git fetch https://review.opendev.org/openstack/keystone refs/changes/08/135808/9 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_catalog.py', 'keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/sql.py']",3,d30ca4a3ff8d561aa42a3685a631a50d906552ae,bug/1393518," 'name': endpoint.service.get('name', ''), service['name'] = svc.extra.get('name', '')"," 'name': endpoint.service['name'], name = svc.extra.get('name') if name: service['name'] = name",40,5
openstack%2Fhorizon~master~If302385d7d0f8b84512e710fbd70cdbd5bcdffea,openstack/horizon,master,If302385d7d0f8b84512e710fbd70cdbd5bcdffea,Add TabbedFormRegion to Integration tests,MERGED,2014-10-07 07:01:48.000000000,2015-01-14 01:40:00.000000000,2015-01-14 01:39:58.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 10684}, {'_account_id': 11473}, {'_account_id': 12355}, {'_account_id': 12721}, {'_account_id': 12954}, {'_account_id': 13049}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-10-07 07:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/971ac1a9be5fad9755383d19496cc240b7a01e35', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 2, 'created': '2014-10-07 07:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a5ebb5e8275820730460fdde19371c89242e57f4', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 3, 'created': '2014-10-14 06:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6562f444028e3565481566985fe012b25bbcb730', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 4, 'created': '2014-10-30 16:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4743c9343782ca0604d2edbcde98b599584817ef', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 5, 'created': '2014-10-30 19:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c7dfc0003e070e23aa25ed977a96e6899455bf9b', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 6, 'created': '2014-11-06 11:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e82de4bbdd27fe16d636080dc2b1e4f13970ad4', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 7, 'created': '2014-11-06 14:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/160502e5d6b81c8a01a3e07a348ee674f2c57cda', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 8, 'created': '2014-11-11 16:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3b29550a8f32bf0ab6c79dcc8a3823f54e1b4170', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 9, 'created': '2014-11-21 14:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3304314dae8f490ef69cb821eac79e53aeb37527', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 10, 'created': '2014-11-25 14:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13eb9bf20481809c127bc4cbe28bd770c6d8266a', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 11, 'created': '2014-11-27 21:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/eec0a4877c3b01b4fefa5ba20e62c262aee341c4', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 12, 'created': '2014-12-09 20:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a7622095887ae6e55c6343ebe3838c97c3cc4a1', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 13, 'created': '2014-12-13 20:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/25d1b3bd5699f54136bd741630c64ddd3f12494d', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 14, 'created': '2014-12-15 09:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1c8d8bd5714819ef4fc681759aa39297e0234d5', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 15, 'created': '2014-12-16 20:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bcf0b13887c1d3d2665ceb6a1a9a1bdbf75d7e72', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 16, 'created': '2014-12-17 09:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/52e99ecc7cfc101f4e76f9048dd281cdbeb030e6', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 17, 'created': '2014-12-21 15:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aa5a19d4eb50f25c00e994236c0d4f4232add54d', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as witch the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certaion forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}, {'number': 18, 'created': '2014-12-27 10:33:21.000000000', 'files': ['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/test/integration_tests/regions/menus.py', 'openstack_dashboard/test/integration_tests/regions/baseregion.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e3e25a6e8bebae8f6a1986b6e8de97478cfa7a25', 'message': 'Add TabbedFormRegion to Integration tests\n\n* TabbedFormRegion - that should be used for forms that are divided into tabs,\n  the manipulation with the form is then the same as with the regular Form\n  region, tabs are switched automatically\n\n* TabbedMenuRegion - support for another type of menu, that is for\n  example located in certain forms or under the Project/Compute/access\n  & security page\n\n* Also _default_src_locator is added to BaseRegion class, that makes it\n  possible for every component to have its own default locator, so it is\n  not necessary to specify region source element all over again\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea\n'}]",11,126478,e3e25a6e8bebae8f6a1986b6e8de97478cfa7a25,88,12,18,11473,,,0,"Add TabbedFormRegion to Integration tests

* TabbedFormRegion - that should be used for forms that are divided into tabs,
  the manipulation with the form is then the same as with the regular Form
  region, tabs are switched automatically

* TabbedMenuRegion - support for another type of menu, that is for
  example located in certain forms or under the Project/Compute/access
  & security page

* Also _default_src_locator is added to BaseRegion class, that makes it
  possible for every component to have its own default locator, so it is
  not necessary to specify region source element all over again

Partially implements blueprint: selenium-integration-testing

Change-Id: If302385d7d0f8b84512e710fbd70cdbd5bcdffea
",git fetch https://review.opendev.org/openstack/horizon refs/changes/78/126478/16 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/test/integration_tests/regions/menus.py', 'openstack_dashboard/test/integration_tests/regions/baseregion.py']",3,971ac1a9be5fad9755383d19496cc240b7a01e35,bp/selenium-integration-testing," """""" _default_src_locator = None if src_elem is None and self._default_src_locator: # fake self.src_elem must be set up in # order self._get_element work self.src_elem = driver src_elem = self._get_element(*self._default_src_locator) "," """"""",73,13
openstack%2Ftelemetry-specs~master~If9e33615fbb47f1e48b8caaeac80687551eca976,openstack/telemetry-specs,master,If9e33615fbb47f1e48b8caaeac80687551eca976,Add alarm severity,ABANDONED,2014-06-18 03:18:30.000000000,2015-01-14 01:36:12.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 8290}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-18 03:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/78f867496c6003b08e454bfce1c589e41d142046', 'message': 'Specs for add-alarm-severity\n\nThis blueprint aims to add alarm severity to alarm.\n\nImplements blueprint add-alarm-severity\n\nChange-Id: If9e33615fbb47f1e48b8caaeac80687551eca976\n'}, {'number': 2, 'created': '2014-07-04 07:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/a02f0fa433548bc449801c1eded7e13fb836d0bf', 'message': 'Add alarm severity\n\nThis blueprint aims to add alarm severity to alarm.\n\nChange-Id: If9e33615fbb47f1e48b8caaeac80687551eca976\n'}, {'number': 3, 'created': '2014-07-21 09:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/04e0c1e998d6427fb3b84a99ee3bf263fe19fe9e', 'message': 'Add alarm severity\n\nThis blueprint aims to add alarm severity to alarm.\n\nChange-Id: If9e33615fbb47f1e48b8caaeac80687551eca976\n'}, {'number': 4, 'created': '2014-12-09 01:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/dd29bdeee37226e323703a0c66fc40d7f3acabae', 'message': 'Add alarm severity\n\nThis spec aims to add alarm severity to alarm.\n\nChange-Id: If9e33615fbb47f1e48b8caaeac80687551eca976\n'}, {'number': 5, 'created': '2014-12-09 06:21:16.000000000', 'files': ['specs/kilo/add-alarm-severity.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/7cf34ed7791db5917078131425461153887b9e51', 'message': 'Add alarm severity\n\nThis spec aims to add alarm severity to alarm.\n\nblueprint add-alarm-severity\nChange-Id: If9e33615fbb47f1e48b8caaeac80687551eca976\n'}]",17,100752,7cf34ed7791db5917078131425461153887b9e51,45,9,5,8290,,,0,"Add alarm severity

This spec aims to add alarm severity to alarm.

blueprint add-alarm-severity
Change-Id: If9e33615fbb47f1e48b8caaeac80687551eca976
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/52/100752/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/add-alarm-severity.rst'],1,78f867496c6003b08e454bfce1c589e41d142046,bp/add-alarm-severity,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Add severity attribute to alarm =============================== https://blueprints.launchpad.net/ceilometer/+spec/add-alarm-severity Currently, alarm in ceilometer has no concept of severity, which is important in operation scenarios, this blueprint proposes to add severity attribute to alarm, that can provide a basic support for other component doing different alarm action according the alarm severity, or just for providing a hierarchical alarm presentation to user in dashboard. Problem description =================== There are several use case about adding severity to alarm: - To create alarms with alarm severity specified representing different level of the alarm. - To get alarms filtered by alarm severity. - To show alarm history with alarm severity, use different color/icon to identify different severity level alarm, this is clear to user. - Different alarm notifying action for different severity of alarm. For example, e.g. SMS for high severity, email for others. - Limiting actions by conditions against alarm severity - Send alarm notify with alarm severity attribute which allow 3th part alarm consumer doing different action with different level alarm. Proposed change =============== * Define 3 alarm severity as options: low, medium, high. * Implement storage model for adding alarm severity. * Implement alarm severity in alarm creating API. * Implement alarm_severity filter in alarm listing API. Alternatives ------------ Allow user to define the alarm severity options instead the hard-coding severity definitions Data model impact ----------------- Add a alarm_severity item to alarm model. REST API impact --------------- * For alarm creating API, support specifying alarm_severity. * For listing alarm API, support alarm_severity as query filter. Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: liusheng<liusheng@huawei.com> Work Items ---------- 1. Add alarm severity as an alarm attribute to alarm model definition. 2. Implement the alarm db table updating or db version migration for different storage backend. 3. Implement the API of alarm creating with alarm severity. 4. Implement the query filter of listing alarm API. 5. Add the alarm severity to of alarm notify information. Future lifecycle ================ None Dependencies ============ None Testing ======= This code will be tested in unit tests for alarm severity. The API will be tested by adding tempest. Documentation Impact ==================== The API document will need updating if this blueprint merged. References ========== None",,148,0
openstack%2Ftelemetry-specs~master~I8f3a829d1d4a01f9ef11f8e89f63b63aa3de8a6f,openstack/telemetry-specs,master,I8f3a829d1d4a01f9ef11f8e89f63b63aa3de8a6f,Spec to Expose level in alarm notifications,MERGED,2014-12-18 18:21:52.000000000,2015-01-14 01:36:00.000000000,2015-01-13 14:37:43.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-12-18 18:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/ff0851d93d84301299ba3dd59b061f8bfbc6a81f', 'message': 'Spec to Expose level in alarm notifications\n\nChange-Id: I8f3a829d1d4a01f9ef11f8e89f63b63aa3de8a6f\nImplements: blueprint ceilometer-alarm-level\n'}, {'number': 2, 'created': '2014-12-22 17:33:47.000000000', 'files': ['specs/kilo/ceilometer-alarm-level.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/9b121f8358332dea06466bdb96d2d9db10cf1613', 'message': 'Spec to Expose level in alarm notifications\n\nChange-Id: I8f3a829d1d4a01f9ef11f8e89f63b63aa3de8a6f\nImplements: blueprint ceilometer-alarm-level\n'}]",2,142867,9b121f8358332dea06466bdb96d2d9db10cf1613,16,6,2,6924,,,0,"Spec to Expose level in alarm notifications

Change-Id: I8f3a829d1d4a01f9ef11f8e89f63b63aa3de8a6f
Implements: blueprint ceilometer-alarm-level
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/67/142867/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ceilometer-alarm-level.rst'],1,ff0851d93d84301299ba3dd59b061f8bfbc6a81f,bp/ceilometer-alarm-level,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================================== Add Support to include Alarm level as part of notifications =========================================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-alarm-level The goal of this blueprint is to expose an alarm priority field that can be used to set the alarm importance level. Problem description =================== A detailed description of the problem: * Alarms in ceilometer have no way to identify the criticality of an alarm. All we know today is if alarm has been triggered or insufficient data. This might be ok in general. * But from auditing point of view, cloud administrators would like to know if an alarm is triggered and if so how critical is it. A hardware failure would be a critical alarm vs an occasional spike in cpu level could be medium or low. Differentiating this level would be very useful for audit. Proposed change =============== Expose a new field called alarm_priority as part of the alarm base object. This will be exposed via the alarm notifications so the alarms can be filtered by priority. Alternatives ------------ None Data model impact ----------------- Need to update the Alarm model to include a new field called priority REST API impact --------------- We will probably want to expose requests to get alarms by priority. Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: pkilambi Ongoing maintainer: pkilambi Work Items ---------- The specific work items include: * Update the model layer to include the necessary fields * Update the notifier module to expose the priority field * Update the rpc and service modules under alarm * Update unit tests. Future lifecycle ================ NOne Dependencies ============ None Testing ======= Unit and integration Tests will be added/updated to cover the necessary scenarios for alarms Documentation Impact ==================== We might need to update the example json in alarm api docs. References ========== Initial implementation is here https://review.openstack.org/#/c/142849/ ",,136,0
openstack%2Fdesignate~master~Ia201b6700cc3431200a161d945c42a80750a8202,openstack/designate,master,Ia201b6700cc3431200a161d945c42a80750a8202,Add doc/html/* to .gitignore,ABANDONED,2015-01-09 03:00:03.000000000,2015-01-14 01:31:09.000000000,,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 4894}]","[{'number': 1, 'created': '2015-01-09 03:00:03.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/designate/commit/1fce2ca92a53598b22fad0b36e6bfac22ca2b73e', 'message': 'Add doc/html/* to .gitignore\n\nChange-Id: Ia201b6700cc3431200a161d945c42a80750a8202\n'}]",0,146000,1fce2ca92a53598b22fad0b36e6bfac22ca2b73e,8,3,1,4894,,,0,"Add doc/html/* to .gitignore

Change-Id: Ia201b6700cc3431200a161d945c42a80750a8202
",git fetch https://review.opendev.org/openstack/designate refs/changes/00/146000/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,1fce2ca92a53598b22fad0b36e6bfac22ca2b73e,,doc/html/*,,1,0
openstack%2Ftempest~master~I8e440b91fee8aa4c7284a49603f9ad99c221182d,openstack/tempest,master,I8e440b91fee8aa4c7284a49603f9ad99c221182d,Remove imports of http module,MERGED,2015-01-08 08:44:57.000000000,2015-01-14 01:12:07.000000000,2015-01-14 01:12:05.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-08 08:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/175353e8c2176fcb6b79a4aef5d182213df15d07', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 2, 'created': '2015-01-08 09:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7c46ac5e8e1ce829cd2e743901844c12bd62e5b', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 3, 'created': '2015-01-09 01:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d53dd22a2b77d3c955083fb306a56b00b4d81089', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 4, 'created': '2015-01-09 04:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fdd60cfa7518e0bfd0500916f71d86257189d1a5', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 5, 'created': '2015-01-09 05:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9de178db52479fb62517140a034f5262de644001', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 6, 'created': '2015-01-12 23:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/17333add9b210ca6c1ac2a9b407838fdbd513e59', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}, {'number': 7, 'created': '2015-01-13 00:42:25.000000000', 'files': ['tempest/tests/test_auth.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/tests/common/test_accounts.py', 'tempest/tests/test_credentials.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/03010dca40990b593e010bb7e6c8428f7f1a368f', 'message': 'Remove imports of http module\n\nhttp module will be moved to tempest-lib, and it will be used only\nfor rest-client module as an internal module.\nThis patch replaces imports of http module for doing the above.\n\nChange-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d\n'}]",0,145720,03010dca40990b593e010bb7e6c8428f7f1a368f,35,7,7,6167,,,0,"Remove imports of http module

http module will be moved to tempest-lib, and it will be used only
for rest-client module as an internal module.
This patch replaces imports of http module for doing the above.

Change-Id: I8e440b91fee8aa4c7284a49603f9ad99c221182d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/20/145720/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/test_auth.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/tests/common/test_accounts.py', 'tempest/tests/test_credentials.py']",4,175353e8c2176fcb6b79a4aef5d182213df15d07,rest-client,"from tempest.services.identity.json import identity_client as v2_client from tempest.services.identity.v3.json import identity_client as v3_client tokenclient_class = v2_client.TokenClientJSON self.stubs.Set(self.tokenclient_class, 'raw_request', self.identity_response) tokenclient_class = v3_client.V3TokenClientJSON","from tempest.common import http self.stubs.Set(http.ClosingHttp, 'request', self.identity_response)",13,10
openstack%2Fironic~master~I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc,openstack/ironic,master,I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc,Enable async callbacks from task.process_event(),MERGED,2014-12-10 23:40:38.000000000,2015-01-14 00:59:45.000000000,2015-01-14 00:59:45.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-10 23:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c9f61a9ba48e78a8fdc32e969505d1a3529948dd', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parametes to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\n** NOTE **\nThis patch needs additional unit testing for process_event\n** NOTE **\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 2, 'created': '2014-12-11 00:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ce381a76595a58687878c7c9bf72c1ea70a120f5', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parametes to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\n** NOTE **\nThis patch needs additional unit testing for process_event\n** NOTE **\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 3, 'created': '2014-12-11 01:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/083618cd75532ba1e9725a87e1c02860a59d174f', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parametes to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\n** NOTE **\nThis patch needs additional unit testing for process_event\n** NOTE **\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 4, 'created': '2014-12-11 20:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c1fd7edabaf64af3183ce79179d737ad738cd15', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parametes to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\n** NOTE **\nThis patch needs additional unit testing for process_event\n** NOTE **\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 5, 'created': '2014-12-15 20:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc7f6bea9c0344a3682613708291b3d54f99099a', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parametes to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\n** NOTE **\nThis patch needs additional unit testing for process_event\n** NOTE **\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 6, 'created': '2014-12-19 03:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bac5720330a8fac87766637767685260077563a2', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 7, 'created': '2015-01-06 23:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b39bc342e678035beb1cbb8d456b10994b1ccfc9', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 8, 'created': '2015-01-07 01:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c5ce1f7a1974f2aaa1ff137b0e31c7909e9884a', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies the some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 9, 'created': '2015-01-07 17:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/93e90dfa3c455254189589baf428c1b7ab2106f6', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 10, 'created': '2015-01-07 18:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c02bec61ff33fc211a89ec8a0e6121e220b1a517', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 11, 'created': '2015-01-08 20:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4b9686ceb47bb1a961da0f640aacccb7a4872743', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 12, 'created': '2015-01-09 22:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d4a2c035398d2a22374fce646e75eddec7c6e90c', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 13, 'created': '2015-01-09 23:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/103ebb096ed79d28a4c1f4d8c92d2291eeee601d', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 14, 'created': '2015-01-13 17:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b28c8864acf7470a279df90651532669200c1ad4', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}, {'number': 15, 'created': '2015-01-13 19:00:26.000000000', 'files': ['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py', 'ironic/tests/conductor/test_task_manager.py', 'ironic/conductor/task_manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/42bb13046b0af439eb0f38e83d114552ffc209ab', 'message': 'Enable async callbacks from task.process_event()\n\nAdd optional parameters to task.process_event such that it can register\nasync callbacks. This simplifies some of the code in\nConductorManager.\n\nUpdate do_node_deploy and do_node_teardown to use this approach.\n\nAdds unit tests for the new code paths in task.process_event\n\nChange-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc\nRelated-to: blueprint new-ironic-state-machine\n'}]",53,140868,42bb13046b0af439eb0f38e83d114552ffc209ab,97,9,15,2889,,,0,"Enable async callbacks from task.process_event()

Add optional parameters to task.process_event such that it can register
async callbacks. This simplifies some of the code in
ConductorManager.

Update do_node_deploy and do_node_teardown to use this approach.

Adds unit tests for the new code paths in task.process_event

Change-Id: I6371dd51f3e0dfa4a35f30f61d0ee928943dd4dc
Related-to: blueprint new-ironic-state-machine
",git fetch https://review.opendev.org/openstack/ironic refs/changes/68/140868/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/conductor/test_manager.py', 'ironic/conductor/manager.py', 'ironic/conductor/task_manager.py']",3,c9f61a9ba48e78a8fdc32e969505d1a3529948dd,bp/new-ironic-state-machine," def process_event(self, event, callback=None, call_args=None, call_kwargs=None, err_handler=None): """"""Process an event by advancing the state machine. :param event: the name of the event to process :param callback: optional callback to invoke upon event transition :param call_args: optional *args to pass to the callback method :param call_kwargs: optional **kwargs to pass to to the callback method :param err_handler: optional error handler to invoke if the callback fails, eg. because there are no workers available """""" # advance the state machine into -ING state # this may raise InvalidState, but does not change node states directly # stash current states in the error handler, # in case we fail to get a worker from the pool if err_handler: self.set_spawn_error_hook(err_handler, self.node, self.node.provision_state, self.node.target_provision_state) # set up the async worker if callback: if call_args is None: call_args = [] if call_kwargs is None: call_kwargs = {} self.spawn_after(callback, *call_args, **call_kwargs) # publish the state transition by saving the Node self.node.last_error = None self.node.save()"," def process_event(self, event): """"""Process an event by advancing the state machine.""""""",44,32
openstack%2Fironic~master~Ic18e74945f6e7a087632088e8feca8b0f0c98dfb,openstack/ironic,master,Ic18e74945f6e7a087632088e8feca8b0f0c98dfb,Add requests to requirements.txt,MERGED,2015-01-13 19:52:15.000000000,2015-01-14 00:59:33.000000000,2015-01-14 00:59:31.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 8106}, {'_account_id': 10342}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-13 19:52:15.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/52722212cb7662fa763221765a11befdc6aaf0cd', 'message': 'Add requests to requirements.txt\n\nThis is used in code but not specified as a dependency.\n\nChange-Id: Ic18e74945f6e7a087632088e8feca8b0f0c98dfb\nCloses-Bug: #1410468\n'}]",0,146971,52722212cb7662fa763221765a11befdc6aaf0cd,12,6,1,10343,,,0,"Add requests to requirements.txt

This is used in code but not specified as a dependency.

Change-Id: Ic18e74945f6e7a087632088e8feca8b0f0c98dfb
Closes-Bug: #1410468
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/146971/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,52722212cb7662fa763221765a11befdc6aaf0cd,bug/1410468,"requests>=2.2.0,!=2.4.0",,1,0
openstack%2Fhorizon~master~I140ca0d57e89b792b7f1ac989ef78f13766639f6,openstack/horizon,master,I140ca0d57e89b792b7f1ac989ef78f13766639f6,Remove unused method get_stats,MERGED,2015-01-13 21:12:14.000000000,2015-01-14 00:59:20.000000000,2015-01-14 00:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2015-01-13 21:12:14.000000000', 'files': ['openstack_dashboard/dashboards/admin/info/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ac8d8fa1e9fc81e4b1dde9e9dfba79455f6cb14d', 'message': 'Remove unused method get_stats\n\nIt looks like the method get_stats in dashboards.info.tables is not\nused anywhere in Horizon. The referenced file ""_stats.html"" is also\nnot available in the Horizon repository.\n\nCloses-Bug: #1410524\n\nChange-Id: I140ca0d57e89b792b7f1ac989ef78f13766639f6\n'}]",0,146978,ac8d8fa1e9fc81e4b1dde9e9dfba79455f6cb14d,8,4,1,167,,,0,"Remove unused method get_stats

It looks like the method get_stats in dashboards.info.tables is not
used anywhere in Horizon. The referenced file ""_stats.html"" is also
not available in the Horizon repository.

Closes-Bug: #1410524

Change-Id: I140ca0d57e89b792b7f1ac989ef78f13766639f6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/78/146978/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/info/tables.py'],1,ac8d8fa1e9fc81e4b1dde9e9dfba79455f6cb14d,bug/1410524,,"def get_stats(service): return template.loader.render_to_string('admin/services/_stats.html', {'service': service}) ",0,5
openstack%2Fmonasca-api~master~Idbda71dcb55c769af408797323683cc7c75dd7bf,openstack/monasca-api,master,Idbda71dcb55c769af408797323683cc7c75dd7bf,Fix bug where metric name regex matches prefixes,MERGED,2015-01-13 22:53:12.000000000,2015-01-14 00:58:04.000000000,2015-01-14 00:58:04.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 14273}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-01-13 22:53:12.000000000', 'files': ['monasca/common/repositories/influxdb/metrics_repository.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/65d0e5ff5d8593aac24edaf49527494d3c7e3447', 'message': 'Fix bug where metric name regex matches prefixes\n\nChange-Id: Idbda71dcb55c769af408797323683cc7c75dd7bf\n'}]",0,147006,65d0e5ff5d8593aac24edaf49527494d3c7e3447,7,6,1,12512,,,0,"Fix bug where metric name regex matches prefixes

Change-Id: Idbda71dcb55c769af408797323683cc7c75dd7bf
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/06/147006/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca/common/repositories/influxdb/metrics_repository.py'],1,65d0e5ff5d8593aac24edaf49527494d3c7e3447,, from_clause += '(&|$)' from_clause += '(.*&)*' from_clause += '(&|$)', from_clause += '.*&',3,1
openstack%2Fpython-magnumclient~master~If315873a02bc896129e2ba41eb2a3d6fdd10b5ed,openstack/python-magnumclient,master,If315873a02bc896129e2ba41eb2a3d6fdd10b5ed,Make replication controller client works,MERGED,2015-01-13 22:54:31.000000000,2015-01-14 00:51:59.000000000,2015-01-14 00:51:59.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 22:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/82d0a1605c54f262dbbbd53ee9a7d766e0f209f0', 'message': 'Make replication controller client works\n\n1) Rename replicationcontroller.py to replicationcontrollers.py\n2) Add pod_data support in client (backend will be updated later)\n\nChange-Id: If315873a02bc896129e2ba41eb2a3d6fdd10b5ed\nCloses-Bug: #1410447\n'}, {'number': 2, 'created': '2015-01-13 23:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/70cd84f2f50d1f37c793a3ebb93cdca27cb855ec', 'message': 'Make replication controller client works\n\n1) Rename replicationcontroller.py to replicationcontrollers.py\n2) Add pod_data support in client (backend will be updated later)\n\nChange-Id: If315873a02bc896129e2ba41eb2a3d6fdd10b5ed\nCloses-Bug: #1410447\n'}, {'number': 3, 'created': '2015-01-13 23:17:40.000000000', 'files': ['magnumclient/v1/replicationcontrollers.py', 'magnumclient/v1/client.py', 'magnumclient/v1/shell.py', 'magnumclient/tests/v1/test_replicationcontrollers.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/0b1c535729f34cbf779b8377c6318f616c68169d', 'message': 'Make replication controller client works\n\n1) Rename replicationcontroller.py to replicationcontrollers.py\n2) Add pod_data support in client (backend will be updated later)\n\nChange-Id: If315873a02bc896129e2ba41eb2a3d6fdd10b5ed\nCloses-Bug: #1410447\n'}]",0,147007,0b1c535729f34cbf779b8377c6318f616c68169d,10,4,3,7494,,,0,"Make replication controller client works

1) Rename replicationcontroller.py to replicationcontrollers.py
2) Add pod_data support in client (backend will be updated later)

Change-Id: If315873a02bc896129e2ba41eb2a3d6fdd10b5ed
Closes-Bug: #1410447
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/07/147007/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/tests/v1/test_replicationcontroller.py', 'magnumclient/v1/replicationcontrollers.py', 'magnumclient/v1/client.py', 'magnumclient/v1/shell.py']",4,82d0a1605c54f262dbbbd53ee9a7d766e0f209f0,master,"@utils.arg('--rc-url', metavar='<rc_url>',@utils.arg('--rc-file', metavar='<rc_file>', help='File path of the replication controller file to use for ' 'creating replication controllers.') @utils.arg('--bay-id', required=True, metavar='<bay_id>', help='The bay ID.') opts['rc_definition_url'] = args.rc_url opts['bay_uuid'] = args.bay_id if args.rc_file is not None and os.path.isfile(args.rc_file): with open(args.rc_file, 'r') as f: opts['rc_data'] = f.read()","@utils.arg('--rc-file', metavar='<rc-file>', opts['rc_definition_url'] = args.rc_file",21,8
openstack%2Fpython-magnumclient~master~Ic2c0c0c17bb5e25ab727a3e6469ebee802c1683f,openstack/python-magnumclient,master,Ic2c0c0c17bb5e25ab727a3e6469ebee802c1683f,Remove 'desc' from docker creation attribute,MERGED,2015-01-13 14:50:06.000000000,2015-01-14 00:47:54.000000000,2015-01-14 00:47:54.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 14:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/74c199a0eeb336e6321e7c49b0d94b473052173e', 'message': ""Remove 'desc' from docker creation attribute\n\nChange-Id: Ic2c0c0c17bb5e25ab727a3e6469ebee802c1683f\n""}, {'number': 2, 'created': '2015-01-13 21:56:59.000000000', 'files': ['magnumclient/v1/containers.py', 'magnumclient/tests/v1/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/4e0a68ccaed52429d8a1315eae144aa9fd90b6ba', 'message': 'Remove \'desc\' from docker creation attribute\n\n""Docker run"" API do not support adding description for\na container, so we can remove \'desc\' from docker creation\nattribute.\n\nChange-Id: Ic2c0c0c17bb5e25ab727a3e6469ebee802c1683f\n'}]",0,146888,4e0a68ccaed52429d8a1315eae144aa9fd90b6ba,11,4,2,7494,,,0,"Remove 'desc' from docker creation attribute

""Docker run"" API do not support adding description for
a container, so we can remove 'desc' from docker creation
attribute.

Change-Id: Ic2c0c0c17bb5e25ab727a3e6469ebee802c1683f
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/88/146888/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/v1/containers.py', 'magnumclient/tests/v1/test_shell.py']",2,74c199a0eeb336e6321e7c49b0d94b473052173e,master," ""image_id"": ""image_id"""," ""desc"": ""container description.""",3,3
openstack%2Foslo.concurrency~master~I33fa9b4e6099f521e0de3cb4585016fd694c4548,openstack/oslo.concurrency,master,I33fa9b4e6099f521e0de3cb4585016fd694c4548,"Revert ""Port processutils to Python 3""",MERGED,2015-01-13 17:37:59.000000000,2015-01-14 00:43:38.000000000,2015-01-14 00:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-13 17:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/ad6d69175b820e81a9458bd9a0ff4d751df27eda', 'message': 'Revert ""Port processutils to Python 3""\n\nThis reverts commit 7c7493feb53429577efca2c4b0380af03ddc149b.\n\nThis change breaks the API of execute() and breaks nova\'s tests.\n\nChange-Id: I33fa9b4e6099f521e0de3cb4585016fd694c4548\n'}, {'number': 2, 'created': '2015-01-13 17:54:43.000000000', 'files': ['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py', 'tests/test_processutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/acb55ef279cd5ae0f489f6b5298258d5ff1a437e', 'message': 'Revert ""Port processutils to Python 3""\n\nThis reverts commit 7c7493feb53429577efca2c4b0380af03ddc149b.\n\nThis change breaks the API of execute() and breaks nova\'s tests.\n\nCloses-Bug: #1410348\nChange-Id: I33fa9b4e6099f521e0de3cb4585016fd694c4548\n'}]",1,146940,acb55ef279cd5ae0f489f6b5298258d5ff1a437e,12,5,2,2472,,,0,"Revert ""Port processutils to Python 3""

This reverts commit 7c7493feb53429577efca2c4b0380af03ddc149b.

This change breaks the API of execute() and breaks nova's tests.

Closes-Bug: #1410348
Change-Id: I33fa9b4e6099f521e0de3cb4585016fd694c4548
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/40/146940/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py', 'tests/test_processutils.py']",3,ad6d69175b820e81a9458bd9a0ff4d751df27eda,py3," self.assertIn(b'SUPER_UNIQUE_VAR=The answer is 42', out)class FakeSshStream(six.StringIO): stdout = FakeSshStream('stdout') return (six.StringIO(), six.StringIO('stderr')) fake_stdin = six.StringIO() fake_stdout.read.return_value = 'password=""secret""' fake_stderr = six.StringIO('password=""foobar""')"," self.assertIn('SUPER_UNIQUE_VAR=The answer is 42', out)class FakeSshStream(six.BytesIO): stdout = FakeSshStream(b'stdout') return (six.BytesIO(), six.BytesIO(b'stderr')) fake_stdin = six.BytesIO() fake_stdout.read.return_value = b'password=""secret""' fake_stderr = six.BytesIO(b'password=""foobar""')",17,36
openstack%2Fneutron-vpnaas~master~I264cdcde76606b7e639c8fa561c70bac32a868f6,openstack/neutron-vpnaas,master,I264cdcde76606b7e639c8fa561c70bac32a868f6,VPNaaS: Remove unneeded metaclass decorator,MERGED,2015-01-08 00:19:28.000000000,2015-01-14 00:39:40.000000000,2015-01-14 00:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-08 00:19:28.000000000', 'files': ['neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/a7af633dcc4633a85658da11066043e26c48495f', 'message': 'VPNaaS: Remove unneeded metaclass decorator\n\nThe metaclass decorator was added to replace the older\n__metaclass__ line, but for the Cisco device driver, the class\nis not an ABC, and there are no child classes, unlike the\nreference implementation, which has a single abstract method.\n\nChange-Id: I264cdcde76606b7e639c8fa561c70bac32a868f6\nCloses-Bug: 1408404\n'}]",0,145641,a7af633dcc4633a85658da11066043e26c48495f,8,4,1,6659,,,0,"VPNaaS: Remove unneeded metaclass decorator

The metaclass decorator was added to replace the older
__metaclass__ line, but for the Cisco device driver, the class
is not an ABC, and there are no child classes, unlike the
reference implementation, which has a single abstract method.

Change-Id: I264cdcde76606b7e639c8fa561c70bac32a868f6
Closes-Bug: 1408404
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/41/145641/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py'],1,a7af633dcc4633a85658da11066043e26c48495f,bug/1408404,,import abcimport six@six.add_metaclass(abc.ABCMeta),0,3
openstack%2Fneutron~master~Ic2d681f1515aaa541c6d137ce981622f2fff90e5,openstack/neutron,master,Ic2d681f1515aaa541c6d137ce981622f2fff90e5,Allow IptablesManager to manage mangle table,MERGED,2014-11-18 09:57:19.000000000,2015-01-14 00:38:29.000000000,2015-01-14 00:38:28.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1131}, {'_account_id': 2035}, {'_account_id': 4149}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9360}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-11-18 09:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de622bad8df11560aa6740ca9b33281077ee128e', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to managle mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 2, 'created': '2014-11-18 10:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dcc2a8c635610469e3cbc0d6004c92620afd4154', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to managle mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 3, 'created': '2014-11-21 22:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a198eb8d6f731e4a7d6ea4a8e4dbe94fcea262d6', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to managle mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 4, 'created': '2014-11-21 22:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de25b1f7e82c0d5ed55dfb5119f447064da54313', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 5, 'created': '2014-11-23 14:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41ca2d9eed9bccf7df7b67228de0e132328b41c7', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 6, 'created': '2014-11-23 15:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cef1c6c4e1594a1eb292376cacdbdb72e541ebc3', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 7, 'created': '2014-11-25 10:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/488dd4d99c8eea7e16ace80b76e87ee450f2beef', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 8, 'created': '2014-12-01 16:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e09c81e76b32242f5644e9259a1337eaaf0050a', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 9, 'created': '2014-12-01 23:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8cc385cce351f3b566db843431937c23b8133b7', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 10, 'created': '2014-12-10 13:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0d2833896989819548fc22289f428eb206a8c1d', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 11, 'created': '2014-12-11 12:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb062e5445f527cca1d5b5bbea8863be443dcd7b', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 12, 'created': '2014-12-12 20:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/372702d0adf78b659761638b0d2c593f815db764', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 13, 'created': '2014-12-13 12:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/72a94d087d9f9260436a941e6349908e2ef08370', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 14, 'created': '2014-12-16 23:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/944557e14a88ff857c6ba627cbf6fd3eb625ac6e', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 15, 'created': '2014-12-18 21:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/967e8cd1cd1e2051d40dc2e123889e978901f9d3', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 16, 'created': '2014-12-18 23:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/34aff1687b798b5bfbbe3126d2e9895c3f6c6bce', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 17, 'created': '2014-12-22 09:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efae558c798d99fc7dd2c738be00aa9e37979cb4', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 18, 'created': '2014-12-22 11:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1574cdaf26c034c08634dc453b03a7a2d596693e', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 19, 'created': '2015-01-07 21:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d4edd8625779d72f7f0db1a805a0c25773d6e19', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}, {'number': 20, 'created': '2015-01-12 09:45:01.000000000', 'files': ['neutron/tests/functional/agent/linux/base.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/tests/functional/agent/linux/test_iptables.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7e533c3679a1f4a612f3b53354cb7cb5bc1ba12', 'message': 'Allow IptablesManager to manage mangle table\n\nThis change enables the IptablesManager to manage mangle table (used\nby daughter change).\n\nPartial-Bug: #1187102\nChange-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5\n'}]",8,135203,c7e533c3679a1f4a612f3b53354cb7cb5bc1ba12,361,40,20,8124,,,0,"Allow IptablesManager to manage mangle table

This change enables the IptablesManager to manage mangle table (used
by daughter change).

Partial-Bug: #1187102
Change-Id: Ic2d681f1515aaa541c6d137ce981622f2fff90e5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/135203/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py']",3,de622bad8df11560aa6740ca9b33281077ee128e,mangle," {'mangle': IptablesTable(binary_name=self.wrap_name)}) builtin_chains[4].update( {'mangle': ['PREROUTING', 'INPUT', 'FORWARD', 'OUTPUT', 'POSTROUTING']}) self.ipv4.update(",,161,19
openstack%2Foslo-incubator~master~I65c99d0841b4aacecc15a7f3ea06aa0124de8ae1,openstack/oslo-incubator,master,I65c99d0841b4aacecc15a7f3ea06aa0124de8ae1,processutils: execute(): fix option incompatibility,ABANDONED,2014-10-18 23:09:40.000000000,2015-01-14 00:30:59.000000000,,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 9664}]","[{'number': 1, 'created': '2014-10-18 23:09:40.000000000', 'files': ['openstack/common/processutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/694cf712b9feb174282d5f364edd7fed7afd54b9', 'message': ""processutils: execute(): fix option incompatibility\n\nIssue: simultaneous usage of 'shell' and 'run_as_root' options led\nto error.\n\nCause: it's actually a concealed TypeError: in 'shell'\nmode the command argument is assumed to be a string, elsewhere\na list/tuple.\n\nFix: the command editing implied by 'run_as_root' is performed\nwith care taken of above tacit type assumption.\n\nChange-Id: I65c99d0841b4aacecc15a7f3ea06aa0124de8ae1\nCloses-Bug: #1382873\n""}]",2,129447,694cf712b9feb174282d5f364edd7fed7afd54b9,12,6,1,9521,,,0,"processutils: execute(): fix option incompatibility

Issue: simultaneous usage of 'shell' and 'run_as_root' options led
to error.

Cause: it's actually a concealed TypeError: in 'shell'
mode the command argument is assumed to be a string, elsewhere
a list/tuple.

Fix: the command editing implied by 'run_as_root' is performed
with care taken of above tacit type assumption.

Change-Id: I65c99d0841b4aacecc15a7f3ea06aa0124de8ae1
Closes-Bug: #1382873
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/47/129447/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/processutils.py'],1,694cf712b9feb174282d5f364edd7fed7afd54b9,bug/1382873," if shell: # root helper has to be injected into the command string cmd = [' '.join((root_helper, cmd[0]))] + list(cmd[1:]) else: # root helper has to be tokenized into argument list cmd = shlex.split(root_helper) + list(cmd)", cmd = shlex.split(root_helper) + list(cmd),6,1
openstack%2Fkeystone~master~Ie3d8e1f16ee0b65b4886ae8e7866deb558238702,openstack/keystone,master,Ie3d8e1f16ee0b65b4886ae8e7866deb558238702,Update Inherited Role Assignment Extension section,MERGED,2015-01-10 04:18:20.000000000,2015-01-14 00:24:34.000000000,2015-01-14 00:24:33.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 9142}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-10 04:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/120be91ac3af8b0b74f19e3169e856f0e934a4a6', 'message': 'Update Inherited Role Assignment Extension section\n\nThis patch updates the section which explains\ninherited role assignments in order to include\ninformation about role inheritance in a project\nhierarchy.\n\nCloses-Bug: #1409205\nChange-Id: Ie3d8e1f16ee0b65b4886ae8e7866deb558238702\n'}, {'number': 2, 'created': '2015-01-13 19:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c53d85f1cd5a0a6e364f98bdb02b17189e474587', 'message': 'Update Inherited Role Assignment Extension section\n\nThis patch updates the section which explains\ninherited role assignments in order to include\ninformation about role inheritance in a project\nhierarchy.\n\nCloses-Bug: #1409205\nChange-Id: Ie3d8e1f16ee0b65b4886ae8e7866deb558238702\n'}, {'number': 3, 'created': '2015-01-13 19:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/01df370fcb9025f334e6497dc9321ed88c848bba', 'message': 'Update Inherited Role Assignment Extension section\n\nThis patch updates the section which explains\ninherited role assignments in order to include\ninformation about role inheritance in a project\nhierarchy.\n\nCloses-Bug: #1409205\nChange-Id: Ie3d8e1f16ee0b65b4886ae8e7866deb558238702\n'}, {'number': 4, 'created': '2015-01-13 20:13:33.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/984fdbc38e1655a9462068c5bf16d7c257088054', 'message': 'Update Inherited Role Assignment Extension section\n\nThis patch updates the section which explains\ninherited role assignments in order to include\ninformation about role inheritance in a project\nhierarchy.\n\nCloses-Bug: #1409205\nChange-Id: Ie3d8e1f16ee0b65b4886ae8e7866deb558238702\n'}]",1,146261,984fdbc38e1655a9462068c5bf16d7c257088054,16,5,4,9142,,,0,"Update Inherited Role Assignment Extension section

This patch updates the section which explains
inherited role assignments in order to include
information about role inheritance in a project
hierarchy.

Closes-Bug: #1409205
Change-Id: Ie3d8e1f16ee0b65b4886ae8e7866deb558238702
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/146261/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,120be91ac3af8b0b74f19e3169e856f0e934a4a6,doc/4,"roles on a project or domain that, rather than affect the project or domain itself, are instead inherited to the project subtree or to all projects owned by that domain. This extension is disabled by default, but can be enabled by including the following in ``keystone.conf``:","roles to a domain that, rather than affect the domain itself, are instead inherited to all projects owned by that domain. This extension is disabled by default, but can be enabled by including the following in ``keystone.conf``:",4,3
openstack%2Fkeystone~master~I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac,openstack/keystone,master,I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac,Limit lines length on configuration doc,MERGED,2015-01-10 04:18:20.000000000,2015-01-14 00:24:25.000000000,2015-01-14 00:24:24.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-10 04:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/66b22bf5886cff8dc325730dba7b181a1889850f', 'message': 'Limit lines length on configuration doc\n\nFor a better documentation organization, this\npatch limits all lines to a maximum of 79\ncharacters in configuration.rst. In addition,\nit ensures that maximum length is always used.\nCode blocks and links are exceptions.\n\nPartial-Bug: #1409203\nChange-Id: I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac\n'}, {'number': 2, 'created': '2015-01-13 19:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/13b32173621451f51f0623656f1524f3a5659bad', 'message': 'Limit lines length on configuration doc\n\nFor a better documentation organization, this\npatch limits all lines to a maximum of 79\ncharacters in configuration.rst. In addition,\nit ensures that maximum length is always used.\nCode blocks and links are exceptions.\n\nPartial-Bug: #1409203\nChange-Id: I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac\n'}, {'number': 3, 'created': '2015-01-13 19:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eeec81350e992e8536dc4438d918cea231a02504', 'message': 'Limit lines length on configuration doc\n\nFor a better documentation organization, this\npatch limits all lines to a maximum of 79\ncharacters in configuration.rst. In addition,\nit ensures that maximum length is always used.\nCode blocks and links are exceptions.\n\nPartial-Bug: #1409203\nChange-Id: I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac\n'}, {'number': 4, 'created': '2015-01-13 20:13:33.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aae31e088d26632e629a3e14c09dfab6c8617451', 'message': 'Limit lines length on configuration doc\n\nFor a better documentation organization, this\npatch limits all lines to a maximum of 79\ncharacters in configuration.rst. In addition,\nit ensures that maximum length is always used.\nCode blocks and links are exceptions.\n\nPartial-Bug: #1409203\nChange-Id: I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac\n'}]",0,146260,aae31e088d26632e629a3e14c09dfab6c8617451,14,4,4,9142,,,0,"Limit lines length on configuration doc

For a better documentation organization, this
patch limits all lines to a maximum of 79
characters in configuration.rst. In addition,
it ensures that maximum length is always used.
Code blocks and links are exceptions.

Partial-Bug: #1409203
Change-Id: I99ccd56a8dcc0cd35cb1a3823a1f3803acdf00ac
",git fetch https://review.opendev.org/openstack/keystone refs/changes/60/146260/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,66b22bf5886cff8dc325730dba7b181a1889850f,doc/4,"common system used to configure Python WSGI based applications. The PasteDeploy configuration entries (WSGI pipeline definitions) can be provided in a separate ``keystone-paste.ini`` file, while general and driver-specific configuration parameters are in the primary configuration file ``keystone.conf``. The primary configuration file is organized into the following sections:The Keystone primary configuration file is expected to be named ``keystone.conf``. When starting Keystone, you can specify a different configuration file to use with ``--config-file``. If you do **not** specify a configuration file, Keystone will look in the following directories for a configuration file, in order: Keystone does not support moving the contents of a domain (i.e. ""its"" users and groups) from one backend to another, nor group membership across To delete a domain that uses a domain specific backend, it's necessary to first disable it, remove its specific configuration file (i.e. its configuration files, it currently only supports one SQL backend. This could be either the default driver or a single domain-specific backend, perhaps for storing service users in a predominantly LDAP installation.when it first encounters the entity. If the local ID of the entity is from a backend that does not guarantee to generate UUIDs, a hash algorithm willremoving entries when entities are deleted via the Keystone, for those entities in backends that are managed outside of Keystone (e.g. a Read Only LDAP), Keystone will not know if entities have been deleted and hence will continue to carry stale identity mappings in its table. While benign, Keystone provides an ability for operators to purge the mapping table of such stale entries using the keystone-manage command, for example:A typical usage would be for an operator to obtain a list of those entries in an external backend that had been deleted out-of-band to Keystone, and thenlocal-id. The type of the entity (i.e. user or group) may also be specified if this is needed to uniquely identify the mapping.will purge all the mappings for DOMAINA. The entire mapping table can be purged with the following command:Keystone supports authentication plugins and they are specified in the ``[auth]`` section of the configuration file. However, an authentication plugin may also have its own section in the configuration file. It is up to the plugin to register its own configuration options.Keystone provides three authentication methods by default. ``password`` handles password authentication and ``token`` handles token authentication. ``external`` is used in conjunction with authentication performed by a container web server that sets the ``REMOTE_USER`` environment variable. For more details, refer to :doc:`External Authentication <external-auth>`.``authenticate()`` method. The ``authenticate()`` method expects the following parameters.in ``auth_context`` and return ``None``. ``method_name`` is used to convey any additional authentication methods in case authentication is for re-scoping. For example, if the authentication is for re-scoping, a plugin must append the previous method names into ``method_names``. Also, a plugin may add any additional information into ``extras``. Anything in ``extras`` will be conveyed in the token's ``extras`` field.class configuration in the ``[auth]`` sections of the configuration file to deploy it.invoked, all plugins must succeed in order to for the entire authentication to be successful. Furthermore, all the plugins invoked must agree on the ``user_id`` in the ``auth_context``. The ``REMOTE_USER`` environment variable is only set from a containing webserver. However, to ensure that a user must go through other authentication mechanisms, even if this variable is set, remove ``external`` from the list of plugins specified in ``methods``. This effectively disables external authentication. For more details, refer to :doc:`ExternalAuthentication <external-auth>`.Keystone supports customizable token persistence drivers. These can be specified in the ``[token]`` section of the configuration file. Keystone provides three non-test persistence backends. These can be set with the ``[token]\driver`` configuration option.* ``keystone.token.persistence.backends.memcache_pool.Token`` - The pooled memcached token persistence engine. This backend supports the concept of pooled memcache client object (allowing for the re-use of the client objects). This backend has a number of extra tunable options in the ``[memcache]`` section of the config. token persistence backend. This backend relies on ``dogpile.cache`` and stores the token data in a set of memcached servers. The servers URLs are specified in the ``[memcache]\servers`` configuration option in the Keystone config. It is recommended you use the ``keystone.token.persistence.backends.memcache_pool.Token`` backend instead of ``keystone.token.persistence.backends.memcache.Token`` as the token Apache + mod_wsgi. This recommendation is due to known issues with the use of ``thread.local`` under eventlet that can allow the leaking of memcache client objects and consumption of extra sockets. Both UUID and PKI-based tokens are bearer tokens, meaning that they must be protected from unnecessary disclosure to prevent unauthorized access.Keystone supports a caching layer that is above the configurable subsystems (e.g. ``token``, ``identity``, etc). Keystone uses the `dogpile.cache`_ library which allows for flexible cache backends. The majority of the caching configuration options are set in the ``[cache]`` section. However, each section that has the capability to be cached usually has a ``caching`` boolean value that will toggle caching for that specific section. The current default behavior is that subsystem caching is enabled, but the global toggle is set to disabled.* ``debug_cache_backend`` - enables more in-depth logging from the cache backend (get, set, delete, etc) * ``backend`` - the caching backend module to use e.g. ``dogpile.cache.memcached`` (``keystone.common.cache.noop``). If caching is desired a different backend will need to be specified. Current functional backends are: * ``dogpile.cache.memcached`` - Memcached backend using the standard `python-memcached`_ library * ``dogpile.cache.pylibmc`` - Memcached backend using the `pylibmc`_ library * ``dogpile.cache.bmemcached`` - Memcached using `python-binary-memcached`_ library. * ``keystone.cache.memcache_pool`` - An eventlet safe implementation of ``dogpile.cache.memcached``. This implementation also provides client connection re-use. ``dogpile.cache.memory`` is not suitable for use outside of unit testing as it does not cleanup its internal cache on cache expiration, does not provide isolation to the cached data (values in the store can be inadvertently changed without extra layers of data protection added), and does not share cache between processes. This means that caching and cache invalidation will not be consistent or reliable when using ``Keystone`` and the ``dogpile.cache.memory`` backend under any real workload. Keystone under eventlet. There are known issues with the use of ``thread.local`` under eventlet that can allow the leaking of memcache client objects and consumption of extra sockets. * ``expiration_time`` - int, the default length of time to cache a specific value. A value of ``0`` indicates to not cache anything. It is recommended that the ``enabled`` option be used to disable cache instead of setting this to ``0``. ``backend_argument`` should be specified once per argument to be passed to the backend and in the format of ``<argument name>:<argument value>``. e.g.: ``backend_argument = host:localhost`` * ``proxies`` - comma delimited list of `ProxyBackends`_ e.g. ``my.example.Proxy, my.example.Proxy2`` The token system has a separate ``cache_time`` configuration option, that can be set to a value above or below the global ``expiration_time`` default, allowing for different caching behavior from the other systems in ``Keystone``. This option is set in the ``[token]`` section of the configuration file. The Token Revocation List cache time is handled by the configuration option ``revocation_cache_time`` in the ``[token]`` section. The revocation list is refreshed whenever a token is revoked. It typically sees significantly more requests than specific token retrievals or token validation calls. The assignment system has a separate ``cache_time`` configuration option, that can be set to a value above or below the global ``expiration_time`` default, allowing for different caching behavior from the other systems in ``Keystone``. This option is set in the ``[assignment]`` section of the configuration file. Currently ``assignment`` has caching for ``project``, ``domain``, and ``role`` specific requests (primarily around the CRUD actions). Caching is currently not implemented on grants. The list (``list_projects``, ``list_domains``, etc) methods are not subject to caching. Be aware that if a read-only ``assignment`` backend is in use, the cache will not immediately reflect changes on the backend. Any given change may take up to the ``cache_time`` (if set in the ``[assignment]`` section of the configuration) or the global ``expiration_time`` (set in the ``[cache]`` section of the configuration) before it is reflected. If this type of delay (when using a read-only ``assignment`` backend) is an issue, it is recommended that caching be disabled on ``assignment``. To disable caching specifically on ``assignment``, in the ``[assignment]``The basic workflow for using a signing certificate issued by an external CA involves:format. Also, make sure your trusted CA certificate chain is also in PEM format.``/etc/keystone/ssl/certs``, make sure it is reflected in the ``[signing]`` section of the configuration file.secret key should generally be kept apart from the token signing secret keys so that a compromise of a node does not lead to an attacker being able to generate valid signed Keystone tokens. This is a low probability attack vector, as compromise of a Keystone service machine's filesystem security almost certainly means the attacker will be able to gain direct access to the token backend.``template_file``. Choose this option only if you know that your service catalog will not change very much over time. Attempting to change your service catalog against this driver will result in ``HTTP 501 Not Implemented`` errors. This is the expected behavior. If you want to use these commands, you must instead use the SQL-based ServiceLogging is configured externally to the rest of Keystone. Configure the path to your logging configuration file using the ``[DEFAULT] log_config`` option ofKeystone may be configured to support SSL and 2-way SSL out-of-the-box. The X509 certificates used by Keystone can be generated by keystone-manage orsection. Here is the description of each of them and their purpose:* ``middleware.pem``: Public and private certificate for Keystone middleware/client.Note that you may choose whatever names you want for these certificates, or combine the public/private keys in the same file if you wish. These certificates are just provided as an example.* ``keyfile``: Path to Keystone private certificate file. If the private key is included in the certfile, the keyfile maybe omitted.* ``valid_days``: How long the certificate is valid for. Defaults to 3650 (10 years). * ``ca_key``: The private key for the CA. Defaults to ``/etc/keystone/ssl/certs/cakey.pem``. * ``cert_subject``: The subject to set in the certificate. Defaults to /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost. When setting the subject it is important to set CN to be the address of the server so client validation will succeed. This generally means having the subject be at least /CN=<keystone ip>user_crud_extension filter, insert it after the ``*_body`` middleware and before the ``public_service`` app in the public_api WSGI pipeline inmeans that if a token is stolen it will not be usable without also providing the external authentication.``keystone.conf``, with no limit set by default. Individual driver sections may override this global value with a specific limit, for example:Like most OpenStack projects, Keystone supports the protection of its APIs by defining policy rules based on an RBAC approach. These are stored in a JSON policy file, the name and location of which is set in the main KeystoneEach Keystone v3 API has a line in the policy file which dictates what level of protection is applied to it, where each line is of the form::provided by the caller of the API and the parameters or target entities of the API call in question. For example:create. In other words, you must have the admin role on the domain in which you are creating the user, and the token you are using must be scoped to that* Attributes related to API call: Any parameters that are passed into the API call are available, along with any filters specified in the query string. Attributes of objects passed can be referenced using an object.attribute syntax (e.g. user.domain_id). The target objects of an API are also available using a target.object.attribute syntax. For instance:Every target object has an `id` and a `name` available as `target.<object>.id` and `target.<object>.name`. Other attributes are retrieved from the database and vary between object types. Moreover, some database fields are filtered out (e.g. user passwords).The default policy.json file supplied provides a somewhat basic example of API protection, and does not assume any particular use of domains. For multi-domain configuration installations where, for example, a cloud provider wishes to allow administration of the contents of a domain to be delegated, it is recommended that the supplied policy.v3cloudsample.json is used as a basis for creating a suitable production policy file. This example policy file also shows the use of an admin_domain to allow a cloud provider to enable cloud administrators to have wider access across the APIs. A clean installation would need to perhaps start with the standard policy file, to allow creation of the admin_domain with the first users within it. The domain_id of the admin domain would then be obtained and could be pasted into a modified version of policy.v3cloudsample.json which could then be enabled as the main policy file.You may also want to configure your ``[database]`` settings to better reflect your environment: We're providing the default OS_TOKEN and OS_URL values from ``keystone.conf`` to connect to the Keystone service. If you changed those values, or deployed Keystone to a different endpoint, you will need to change the provided command accordingly.``roles``. See section `Keystone API protection with Role Based Access Control (RBAC)`_ for more details on policy files. As of the Juno release, it is recommended to use ``python-openstackclient``, as it supports both v2.0 and v3 APIs. For the purpose of backwards compatibility, the CLI packaged in ``python-keystoneclient`` is not being removed.Instead of ``python-openstackclient``, if using ``python-keystoneclient``, set the following:* ``--os-service-token OS_SERVICE_TOKEN``: equivalent to ``--os-token OS_TOKEN``To authenticate with Keystone using a password and ``python-openstackclient``, set the following flags, note that the following user referenced below should* ``--os-tenant-name OS_TENANT_NAME``: equivalent to ``--os-project-name OS_PROJECT_NAME``For additional examples using ``python-keystoneclient`` refer to `python-keystoneclient examples`_, likewise, for additional examples using ``python-openstackclient``, refer to `python-openstackclient examples`_.The memcache backend automatically discards expired tokens and so flushing is unnecessary and if attempted will fail with a NotImplemented error.directory server to provide the Identity service. An example Schema for OpenStack would look like this::reflect the common standard objects according to the LDAP RFCs. However, in a live deployment, the correct attributes can be overridden to support aobjectClass posixAccount from RFC2307 is very common. If this is the underlying objectclass, then the *uid* field should probably be *uidNumber* and *username* field either *uid* or *cn*. To change these two fields, the corresponding entries in the Keystone configuration file are:There is a set of allowed actions per object type that you can modify depending on your specific deployment. For example, the users are managed by another tool and you have only read access, in such case the configuration is:There are some configuration options for filtering users, tenants and roles, if the backend is providing too much output, in such case the configuration will look like:boolean for the user, there is several configuration parameters that can be used to extract the value from an integer attribute like in Active Directory:In this case the attribute is an integer and the enabled attribute is listed in bit 1, so the if the mask configured *user_enabled_mask* is different from 0,operation with the value indicated on *user_enabled_mask* and if the value matches the mask then the account is disabled.*enabled_nomask*. This is needed in order to set it back in case that we need to change it to enable/disable a user because it contains more information than the status like password expiration. Last setting *user_enabled_mask* is needed in order to create a default value on the integer attribute (512 = NORMAL ACCOUNT on AD)This field is a bit mask (integer), and the possible flags are documented in the OpenLDAP manpages. Commonly used values include 255 and 4095, with 4095 being more verbose.Some directory servers do not provide any enabled attribute. For these servers, the ``user_enabled_emulation`` and ``project_enabled_emulation`` attributes have been created. They are enabled by setting their respective flags to True. Then the attributes ``user_enabled_emulation_dn`` and``groupOfNames`` and adding whichever users or projects (tenants) that you want enabled to the respective group. For example, this will mark any user who is a member of ``enabled_users`` as enabled:If you are using a directory server to provide the Identity service, it is strongly recommended that you utilize a secure connection from Keystone to the directory server. In addition to supporting LDAP, Keystone also provides Transport Layer Security (TLS) support. There are some basic configuration options for enabling TLS, identifying a single file or directory that contains certificates for all the Certificate Authorities that the Keystone LDAP client will recognize, and declaring what checks the client should perform on server certificates. This functionality can easily be configured as follows:tls_cacertfile and tls_cacertdir are set then tls_cacertfile will be used and tls_cacertdir is ignored. Furthermore, valid options for tls_req_cert are demand, never, and allow. These correspond to the standard options permitted by the TLS_REQCERT TLS option.Keystone now provides an option whereby these read-only directories can be easily integrated as it now enables its identity entities (which comprises users, groups, and group memberships) to be served out of directories while assignments (which comprises projects, roles, role assignments, and domains) are to be served from a different Keystone backend (i.e. SQL). To enable this option, you must have the following ``keystone.conf`` options set:information such users, groups, and group membership from the directory, while assignment related information will be provided by the SQL backend. Also note that if there is an LDAP Identity, and no assignment backend is specified, the assignment backend will default to LDAP. Although this may seem counterintuitive, it is provided for backwards compatibility. Nonetheless, the explicit option will always override the implicit option, so specifying the options as shown above will always be correct. Finally, it is also worth noting that whether or not the LDAP accessible directory is to be considered read only is still configured as described in a previous section above by setting values such as the following in the ``[ldap]`` configuration section:configuraton in enterprise setup. Re-using of connectors from a connection pool drastically reduces overhead of initiating a new connection for every LDAP operation.quickly so a separate pool is provided for those end user auth bind calls. If a deployment does not want to use pool for those binds, then it can disable pooling selectively by ``use_auth_pool`` as false. If a deployment wants to use pool for those auth binds, then ``use_auth_pool`` needs to be true. For auth pool, a different pool size (``auth_pool_size``) and connection lifetime","common system used to configure Python WSGI based applications. The PasteDeploy configuration entries (WSGI pipeline definitions) can be provided in a separate ``keystone-paste.ini`` file, while general and driver-specific configuration parameters are in the primary configuration file ``keystone.conf``. The primary configuration file is organized into the following sections:The Keystone primary configuration file is expected to be named ``keystone.conf``. When starting Keystone, you can specify a different configuration file to use with ``--config-file``. If you do **not** specify a configuration file, Keystone will look in the following directories for a configuration file, in order: Keystone does not support moving the contents of a domain (i.e. ""its"" users and groups) from one backend to another, nor group membership across To delete a domain that uses a domain specific backend, it's necessary to first disable it, remove its specific configuration file (i.e. its configuration files, it currently only supports one SQL backend. This could be either the default driver or a single domain-specific backend, perhaps for storing service users in a predominantly LDAP installation.when it first encounters the entity. If the local ID of the entity is from a backend that does not guarantee to generate UUIDs, a hash algorithm willremoving entries when entities are deleted via the Keystone, for those entities in backends that are managed outside of Keystone (e.g. a Read Only LDAP), Keystone will not know if entities have been deleted and hence will continue to carry stale identity mappings in its table. While benign, Keystone provides an ability for operators to purge the mapping table of such stale entries using the keystone-manage command, for example:A typical usage would be for an operator to obtain a list of those entries in an external backend that had been deleted out-of-band to Keystone, and thenlocal-id. The type of the entity (i.e. user or group) may also be specified if this is needed to uniquely identify the mapping.will purge all the mappings for DOMAINA. The entire mapping table can be purged with the following command:Keystone supports authentication plugins and they are specified in the ``[auth]`` section of the configuration file. However, an authentication plugin may also have its own section in the configuration file. It is up to the plugin to register its own configuration options.Keystone provides three authentication methods by default. ``password`` handles password authentication and ``token`` handles token authentication. ``external`` is used in conjunction with authentication performed by a container web server that sets the ``REMOTE_USER`` environment variable. For more details, refer to :doc:`External Authentication <external-auth>`.``authenticate()`` method. The ``authenticate()`` method expects the following parameters.in ``auth_context`` and return ``None``. ``method_name`` is used to convey any additional authentication methods in case authentication is for re-scoping. For example, if the authentication is for re-scoping, a plugin must append the previous method names into ``method_names``. Also, a plugin may add any additional information into ``extras``. Anything in ``extras`` will be conveyed in the token's ``extras`` field.class configuration in the ``[auth]`` sections of the configuration file to deploy it.invoked, all plugins must succeed in order to for the entire authentication to be successful. Furthermore, all the plugins invoked must agree on the ``user_id`` in the ``auth_context``. The ``REMOTE_USER`` environment variable is only set from a containing webserver. However, to ensure that a user must go through other authentication mechanisms, even if this variable is set, remove ``external`` from the list of plugins specified in ``methods``. This effectively disables external authentication. For more details, refer to :doc:`ExternalAuthentication <external-auth>`.Keystone supports customizable token persistence drivers. These can be specified in the ``[token]`` section of the configuration file. Keystone provides three non-test persistence backends. These can be set with the ``[token]\driver`` configuration option.* ``keystone.token.persistence.backends.memcache_pool.Token`` - The pooled memcached token persistence engine. This backend supports the concept of pooled memcache client object (allowing for the re-use of the client objects). This backend has a number of extra tunable options in the ``[memcache]`` section of the config. token persistence backend. This backend relies on ``dogpile.cache`` and stores the token data in a set of memcached servers. The servers URLs are specified in the ``[memcache]\servers`` configuration option in the Keystone config. It is recommended you use the ``keystone.token.persistence.backends.memcache_pool.Token`` backend instead of ``keystone.token.persistence.backends.memcache.Token`` as the token Apache + mod_wsgi. This recommendation is due to known issues with the use of ``thread.local`` under eventlet that can allow the leaking of memcache client objects and consumption of extra sockets. Both UUID and PKI-based tokens are bearer tokens, meaning that they must be protected from unnecessary disclosure to prevent unauthorized access.Keystone supports a caching layer that is above the configurable subsystems (e.g. ``token``, ``identity``, etc). Keystone uses the `dogpile.cache`_ library which allows for flexible cache backends. The majority of the caching configuration options are set in the ``[cache]`` section. However, each section that has the capability to be cached usually has a ``caching`` boolean value that will toggle caching for that specific section. The current default behavior is that subsystem caching is enabled, but the global toggle is set to disabled.* ``debug_cache_backend`` - enables more in-depth logging from the cache backend (get, set, delete, etc) * ``backend`` - the caching backend module to use e.g. ``dogpile.cache.memcached`` (``keystone.common.cache.noop``). If caching is desired a different backend will need to be specified. Current functional backends are: * ``dogpile.cache.memcached`` - Memcached backend using the standard `python-memcached`_ library * ``dogpile.cache.pylibmc`` - Memcached backend using the `pylibmc`_ library * ``dogpile.cache.bmemcached`` - Memcached using `python-binary-memcached`_ library. * ``keystone.cache.memcache_pool`` - An eventlet safe implementation of ``dogpile.cache.memcached``. This implementation also provides client connection re-use. ``dogpile.cache.memory`` is not suitable for use outside of unit testing as it does not cleanup its internal cache on cache expiration, does not provide isolation to the cached data (values in the store can be inadvertently changed without extra layers of data protection added), and does not share cache between processes. This means that caching and cache invalidation will not be consistent or reliable when using ``Keystone`` and the ``dogpile.cache.memory`` backend under any real workload. Keystone under eventlet. There are known issues with the use of ``thread.local`` under eventlet that can allow the leaking of memcache client objects and consumption of extra sockets. * ``expiration_time`` - int, the default length of time to cache a specific value. A value of ``0`` indicates to not cache anything. It is recommended that the ``enabled`` option be used to disable cache instead of setting this to ``0``. ``backend_argument`` should be specified once per argument to be passed to the backend and in the format of ``<argument name>:<argument value>``. e.g.: ``backend_argument = host:localhost`` * ``proxies`` - comma delimited list of `ProxyBackends`_ e.g. ``my.example.Proxy, my.example.Proxy2`` The token system has a separate ``cache_time`` configuration option, that can be set to a value above or below the global ``expiration_time`` default, allowing for different caching behavior from the other systems in ``Keystone``. This option is set in the ``[token]`` section of the configuration file. The Token Revocation List cache time is handled by the configuration option ``revocation_cache_time`` in the ``[token]`` section. The revocation list is refreshed whenever a token is revoked. It typically sees significantly more requests than specific token retrievals or token validation calls. The assignment system has a separate ``cache_time`` configuration option, that can be set to a value above or below the global ``expiration_time`` default, allowing for different caching behavior from the other systems in ``Keystone``. This option is set in the ``[assignment]`` section of the configuration file. Currently ``assignment`` has caching for ``project``, ``domain``, and ``role`` specific requests (primarily around the CRUD actions). Caching is currently not implemented on grants. The list (``list_projects``, ``list_domains``, etc) methods are not subject to caching. Be aware that if a read-only ``assignment`` backend is in use, the cache will not immediately reflect changes on the backend. Any given change may take up to the ``cache_time`` (if set in the ``[assignment]`` section of the configuration) or the global ``expiration_time`` (set in the ``[cache]`` section of the configuration) before it is reflected. If this type of delay (when using a read-only ``assignment`` backend) is an issue, it is recommended that caching be disabled on ``assignment``. To disable caching specifically on ``assignment``, in the ``[assignment]``The basic workflow for using a signing certificate issued by an external CA involves:format. Also, make sure your trusted CA certificate chain is also in PEM format.``/etc/keystone/ssl/certs``, make sure it is reflected in the ``[signing]`` section of the configuration file.secret key should generally be kept apart from the token signing secret keys so that a compromise of a node does not lead to an attacker being able to generate valid signed Keystone tokens. This is a low probability attack vector, as compromise of a Keystone service machine's filesystem security almost certainly means the attacker will be able to gain direct access to the token backend.``template_file``. Choose this option only if you know that your service catalog will not change very much over time. Attempting to change your service catalog against this driver will result in ``HTTP 501 Not Implemented`` errors. This is the expected behavior. If you want to use these commands, you must instead use the SQL-based ServiceLogging is configured externally to the rest of Keystone. Configure the path to your logging configuration file using the ``[DEFAULT] log_config`` option ofKeystone may be configured to support SSL and 2-way SSL out-of-the-box. The X509 certificates used by Keystone can be generated by keystone-manage orsection. Here is the description of each of them and their purpose:* ``middleware.pem``: Public and private certificate for Keystone middleware/client.Note that you may choose whatever names you want for these certificates, or combine the public/private keys in the same file if you wish. These certificates are just provided as an example.* ``keyfile``: Path to Keystone private certificate file. If the private key is included in the certfile, the keyfile maybe omitted.* ``valid_days``: How long the certificate is valid for. Defaults to 3650 (10 years). * ``ca_key``: The private key for the CA. Defaults to ``/etc/keystone/ssl/certs/cakey.pem``. * ``cert_subject``: The subject to set in the certificate. Defaults to /C=US/ST=Unset/L=Unset/O=Unset/CN=localhost. When setting the subject it is important to set CN to be the address of the server so client validation will succeed. This generally means having the subject be at least /CN=<keystone ip>user_crud_extension filter, insert it after the ``*_body`` middleware and before the ``public_service`` app in the public_api WSGI pipeline inmeans that if a token is stolen it will not be usable without also providing the external authentication.``keystone.conf``, with no limit set by default. Individual driver sections may override this global value with a specific limit, for example:Like most OpenStack projects, Keystone supports the protection of its APIs by defining policy rules based on an RBAC approach. These are stored in a JSON policy file, the name and location of which is set in the main KeystoneEach Keystone v3 API has a line in the policy file which dictates what level of protection is applied to it, where each line is of the form::provided by the caller of the API and the parameters or target entities of the API call in question. For example:create. In other words, you must have the admin role on the domain in which you are creating the user, and the token you are using must be scoped to that* Attributes related to API call: Any parameters that are passed into the API call are available, along with any filters specified in the query string. Attributes of objects passed can be referenced using an object.attribute syntax (e.g. user.domain_id). The target objects of an API are also available using a target.object.attribute syntax. For instance:Every target object has an `id` and a `name` available as `target.<object>.id` and `target.<object>.name`. Other attributes are retrieved from the database and vary between object types. Moreover, some database fields are filtered out (e.g. user passwords).The default policy.json file supplied provides a somewhat basic example of API protection, and does not assume any particular use of domains. For multi-domain configuration installations where, for example, a cloud provider wishes to allow administration of the contents of a domain to be delegated, it is recommended that the supplied policy.v3cloudsample.json is used as a basis for creating a suitable production policy file. This example policy file also shows the use of an admin_domain to allow a cloud provider to enable cloud administrators to have wider access across the APIs. A clean installation would need to perhaps start with the standard policy file, to allow creation of the admin_domain with the first users within it. The domain_id of the admin domain would then be obtained and could be pasted into a modified version of policy.v3cloudsample.json which could then be enabled as the main policy file.You may also want to configure your ``[database]`` settings to better reflect your environment: We're providing the default OS_TOKEN and OS_URL values from ``keystone.conf`` to connect to the Keystone service. If you changed those values, or deployed Keystone to a different endpoint, you will need to change the provided command accordingly.``roles``. See section `Keystone API protection with Role Based Access Control (RBAC)`_ for more details on policy files. As of the Juno release, it is recommended to use ``python-openstackclient``, as it supports both v2.0 and v3 APIs. For the purpose of backwards compatibility, the CLI packaged in ``python-keystoneclient`` is not being removed.Instead of ``python-openstackclient``, if using ``python-keystoneclient``, set the following:* ``--os-service-token OS_SERVICE_TOKEN``: equivalent to ``--os-token OS_TOKEN``To authenticate with Keystone using a password and ``python-openstackclient``, set the following flags, note that the following user referenced below should* ``--os-tenant-name OS_TENANT_NAME``: equivalent to ``--os-project-name OS_PROJECT_NAME``For additional examples using ``python-keystoneclient`` refer to `python-keystoneclient examples`_, likewise, for additional examples using ``python-openstackclient``, refer to `python-openstackclient examples`_.The memcache backend automatically discards expired tokens and so flushing is unnecessary and if attempted will fail with a NotImplemented error.directory server to provide the Identity service. An example Schema for OpenStack would look like this::reflect the common standard objects according to the LDAP RFCs. However, in a live deployment, the correct attributes can be overridden to support aobjectClass posixAccount from RFC2307 is very common. If this is the underlying objectclass, then the *uid* field should probably be *uidNumber* and *username* field either *uid* or *cn*. To change these two fields, the corresponding entries in the Keystone configuration file are:There is a set of allowed actions per object type that you can modify depending on your specific deployment. For example, the users are managed by another tool and you have only read access, in such case the configuration is:There are some configuration options for filtering users, tenants and roles, if the backend is providing too much output, in such case the configuration will look like:boolean for the user, there is several configuration parameters that can be used to extract the value from an integer attribute like in Active Directory:In this case the attribute is an integer and the enabled attribute is listed in bit 1, so the if the mask configured *user_enabled_mask* is different from 0,operation with the value indicated on *user_enabled_mask* and if the value matches the mask then the account is disabled.*enabled_nomask*. This is needed in order to set it back in case that we need to change it to enable/disable a user because it contains more information than the status like password expiration. Last setting *user_enabled_mask* is needed in order to create a default value on the integer attribute (512 = NORMAL ACCOUNT on AD)This field is a bit mask (integer), and the possible flags are documented in the OpenLDAP manpages. Commonly used values include 255 and 4095, with 4095 being more verbose.Some directory servers do not provide any enabled attribute. For these servers, the ``user_enabled_emulation`` and ``project_enabled_emulation`` attributes have been created. They are enabled by setting their respective flags to True. Then the attributes ``user_enabled_emulation_dn`` and``groupOfNames`` and adding whichever users or projects (tenants) that you want enabled to the respective group. For example, this will mark any user who is a member of ``enabled_users`` as enabled:If you are using a directory server to provide the Identity service, it is strongly recommended that you utilize a secure connection from Keystone to the directory server. In addition to supporting LDAP, Keystone also provides Transport Layer Security (TLS) support. There are some basic configuration options for enabling TLS, identifying a single file or directory that contains certificates for all the Certificate Authorities that the Keystone LDAP client will recognize, and declaring what checks the client should perform on server certificates. This functionality can easily be configured as follows:tls_cacertfile and tls_cacertdir are set then tls_cacertfile will be used and tls_cacertdir is ignored. Furthermore, valid options for tls_req_cert are demand, never, and allow. These correspond to the standard options permitted by the TLS_REQCERT TLS option.Keystone now provides an option whereby these read-only directories can be easily integrated as it now enables its identity entities (which comprises users, groups, and group memberships) to be served out of directories while assignments (which comprises projects, roles, role assignments, and domains) are to be served from a different Keystone backend (i.e. SQL). To enable this option, you must have the following ``keystone.conf`` options set:information such users, groups, and group membership from the directory, while assignment related information will be provided by the SQL backend. Also note that if there is an LDAP Identity, and no assignment backend is specified, the assignment backend will default to LDAP. Although this may seem counterintuitive, it is provided for backwards compatibility. Nonetheless, the explicit option will always override the implicit option, so specifying the options as shown above will always be correct. Finally, it is also worth noting that whether or not the LDAP accessible directory is to be considered read only is still configured as described in a previous section above by setting values such as the following in the ``[ldap]`` configuration section:configuraton in enterprise setup. Re-using of connectors from a connection pool drastically reduces overhead of initiating a new connection for every LDAP operation.quickly so a separate pool is provided for those end user auth bind calls. If a deployment does not want to use pool for those binds, then it can disable pooling selectively by ``use_auth_pool`` as false. If a deployment wants to use pool for those auth binds, then ``use_auth_pool`` needs to be true. For auth pool, a different pool size (``auth_pool_size``) and connection lifetime",322,298
openstack%2Fkeystone~master~I6a79058bf14594c435521048e1abdddb2dcfbf24,openstack/keystone,master,I6a79058bf14594c435521048e1abdddb2dcfbf24,Fixes spacing in sentences on configuration doc,MERGED,2015-01-10 04:18:20.000000000,2015-01-14 00:24:14.000000000,2015-01-14 00:24:13.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-10 04:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/231994f89834cecd0e791c97e7847949ce7cf638', 'message': 'Fixes spacing in sentences on configuration doc\n\nThis patch fixes several sentences that contain\ndouble-spacing, where just one space is needed.\n\nPartial-Bug: #1409203\nChange-Id: I6a79058bf14594c435521048e1abdddb2dcfbf24\n'}, {'number': 2, 'created': '2015-01-13 19:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c6964e5531d99d8b202e0fda6aad435054eeff89', 'message': 'Fixes spacing in sentences on configuration doc\n\nThis patch fixes several sentences that contain\ndouble-spacing, where just one space is needed.\n\nPartial-Bug: #1409203\nChange-Id: I6a79058bf14594c435521048e1abdddb2dcfbf24\n'}, {'number': 3, 'created': '2015-01-13 19:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/93b37bdcd5fa7ca78d86c9ab90b502ff6d9bd4a7', 'message': 'Fixes spacing in sentences on configuration doc\n\nThis patch fixes several sentences that contain\ndouble-spacing, where just one space is needed.\n\nPartial-Bug: #1409203\nChange-Id: I6a79058bf14594c435521048e1abdddb2dcfbf24\n'}, {'number': 4, 'created': '2015-01-13 20:13:33.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3fbbd1d2d7a4505e7de325b67591366045813ee0', 'message': 'Fixes spacing in sentences on configuration doc\n\nThis patch fixes several sentences that contain\ndouble-spacing, where just one space is needed.\n\nPartial-Bug: #1409203\nChange-Id: I6a79058bf14594c435521048e1abdddb2dcfbf24\n'}]",0,146259,3fbbd1d2d7a4505e7de325b67591366045813ee0,14,4,4,9142,,,0,"Fixes spacing in sentences on configuration doc

This patch fixes several sentences that contain
double-spacing, where just one space is needed.

Partial-Bug: #1409203
Change-Id: I6a79058bf14594c435521048e1abdddb2dcfbf24
",git fetch https://review.opendev.org/openstack/keystone refs/changes/59/146259/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,231994f89834cecd0e791c97e7847949ce7cf638,doc/4,"when it first encounters the entity. If the local ID of the entity is fromthen the same public ID will be created. This is useful if you are runningcontinue to carry stale identity mappings in its table. While benign, Keystonelocal-id. The type of the entity (i.e. user or group) may also be specifiedcircumstances, the security of the public ID. The maximum length of public IDthis full capability. Since the public ID is what is exposed externally byauthentication and ``token`` handles token authentication. ``external`` is used in conjunction``identity``, etc). Keystone uses the `dogpile.cache`_ library which allows for flexibleboolean value that will toggle caching for that specific section. The current default can be used. The default backend is the ``Keystone`` no-op backend need to be specified. Current functional backends are: and does not share cache between processes. This means that caching indicates to not cache anything. It is recommended that the ``enabled`` option be used to disable ``revocation_cache_time`` in the ``[token]`` section. The revocation ``Keystone``. This option is set in the ``[assignment]`` section of the specific requests (primarily around the CRUD actions). Caching is currently not implemented on grants. The list (``list_projects``, ``list_domains``, etc) will not immediately reflect changes on the backend. Any given changePKI stands for Public Key Infrastructure. Tokens are documents, cryptographically signed using the X509 standard. In order to work correctly token generation requires a public/private key pair. The public key must beavailable as Certificate Authority (CA) certificate. These files can be either``[signing]`` section of the configuration file. The configuration values are: * ``certfile`` - Location of certificate used to verify tokens. Default is* ``keyfile`` - Location of private key used to sign tokens. Default isthe public/private keys in the same file if you wish. These certificates are justunder the [ssl] section. SSL configuration example using the included sample* ``enable``: True enables SSL. Defaults to False. * ``certfile``: Path to Keystone public certificate file. * ``keyfile``: Path to Keystone private certificate file. If the private key is included in the certfile, the keyfile maybe omitted. * ``ca_certs``: Path to CA trust chain. * ``cert_required``: Requires client certificate. Defaults to False. $ curl -X PATCH http://localhost:5000/v2.0/OS-KSCRUD/users/<userid> -H ""Content-type: application/json"" \inherited to all projects owned by that domain. This extension is disabled by``keystone.conf``, with no limit set by default. Individual driver sectionsby defining policy rules based on an RBAC approach. These are stored in acreate. In other words, you must have the admin role on the domain in which API are also available using a target.object.attribute syntax. For instance:The private key used for token signing can only be read by its owner. Thispackaged in `python-openstackclient`_ supports both v2.0 and v3 APIs.directory server to provide the Identity service. An example SchemaThe default object classes and attributes are intentionally simplistic. They reflect the common standard objects according to the LDAP RFCs. However, in a live deployment, the correct attributes can be overridden to support a preexisting, more complex schema. For example, in the user object, the objectClass posixAccount from RFC2307 is very common. If this is the*username* field either *uid* or *cn*. To change these two fields, theand projects (tenants) are selected. These attributes work by using aKeystone to the directory server. In addition to supporting LDAP, Keystonewhat checks the client should perform on server certificates. ThisA few points worth mentioning regarding the above options. If bothused and tls_cacertdir is ignored. Furthermore, valid options for tls_req_cert are demand, never, and allow. These correspond to thethe options as shown above will always be correct. Finally, it is also # Connection lifetime in seconds. (integer value)","when it first encounters the entity. If the local ID of the entity is fromthen the same public ID will be created. This is useful if you are runningcontinue to carry stale identity mappings in its table. While benign, Keystonelocal-id. The type of the entity (i.e. user or group) may also be specifiedcircumstances, the security of the public ID. The maximum length of public IDthis full capability. Since the public ID is what is exposed externally byauthentication and ``token`` handles token authentication. ``external`` is used in conjunction``identity``, etc). Keystone uses the `dogpile.cache`_ library which allows for flexibleboolean value that will toggle caching for that specific section. The current default can be used. The default backend is the ``Keystone`` no-op backend need to be specified. Current functional backends are: and does not share cache between processes. This means that caching indicates to not cache anything. It is recommended that the ``enabled`` option be used to disable ``revocation_cache_time`` in the ``[token]`` section. The revocation ``Keystone``. This option is set in the ``[assignment]`` section of the specific requests (primarily around the CRUD actions). Caching is currently not implemented on grants. The list (``list_projects``, ``list_domains``, etc) will not immediately reflect changes on the backend. Any given changePKI stands for Public Key Infrastructure. Tokens are documents, cryptographically signed using the X509 standard. In order to work correctly token generation requires a public/private key pair. The public key must beavailable as Certificate Authority (CA) certificate. These files can be either``[signing]`` section of the configuration file. The configuration values are: * ``certfile`` - Location of certificate used to verify tokens. Default is* ``keyfile`` - Location of private key used to sign tokens. Default isthe public/private keys in the same file if you wish. These certificates are justunder the [ssl] section. SSL configuration example using the included sample* ``enable``: True enables SSL. Defaults to False. * ``certfile``: Path to Keystone public certificate file. * ``keyfile``: Path to Keystone private certificate file. If the private key is included in the certfile, the keyfile maybe omitted. * ``ca_certs``: Path to CA trust chain. * ``cert_required``: Requires client certificate. Defaults to False. $ curl -X PATCH http://localhost:5000/v2.0/OS-KSCRUD/users/<userid> -H ""Content-type: application/json"" \inherited to all projects owned by that domain. This extension is disabled by``keystone.conf``, with no limit set by default. Individual driver sectionsby defining policy rules based on an RBAC approach. These are stored in acreate. In other words, you must have the admin role on the domain in which API are also available using a target.object.attribute syntax. For instance:The private key used for token signing can only be read by its owner. Thispackaged in `python-openstackclient`_ supports both v2.0 and v3 APIs.directory server to provide the Identity service. An example SchemaThe default object classes and attributes are intentionally simplistic. They reflect the common standard objects according to the LDAP RFCs. However, in a live deployment, the correct attributes can be overridden to support a preexisting, more complex schema. For example, in the user object, the objectClass posixAccount from RFC2307 is very common. If this is the*username* field either *uid* or *cn*. To change these two fields, theand projects (tenants) are selected. These attributes work by using aKeystone to the directory server. In addition to supporting LDAP, Keystonewhat checks the client should perform on server certificates. ThisA few points worth mentioning regarding the above options. If bothused and tls_cacertdir is ignored. Furthermore, valid options for tls_req_cert are demand, never, and allow. These correspond to thethe options as shown above will always be correct. Finally, it is also # Connection lifetime in seconds. (integer value)",55,55
openstack%2Fsolum~master~I984d745494b629f2ebab92b68c222f74ddab3b63,openstack/solum,master,I984d745494b629f2ebab92b68c222f74ddab3b63,Add accept json/yaml for GET /plans,MERGED,2014-08-20 15:40:26.000000000,2015-01-14 00:19:47.000000000,2015-01-14 00:19:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 9095}, {'_account_id': 9548}, {'_account_id': 11813}, {'_account_id': 14554}]","[{'number': 1, 'created': '2014-08-20 15:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7039792c5f93233c18545974681a261d31a389f7', 'message': 'Add accept yaml/json for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}, {'number': 2, 'created': '2014-08-27 12:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/597865d02fb8105b20187c70b454d5b5e0c65600', 'message': 'Add accept yaml/json for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}, {'number': 3, 'created': '2014-09-15 14:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f99d640ef9e900f94b544c4591001eb9d243239e', 'message': 'Add accept yaml/json for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}, {'number': 4, 'created': '2014-10-21 20:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/74b911d43c5c45ad0dedbe88f8793b8a223a4bc2', 'message': 'Add accept yaml/json for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}, {'number': 5, 'created': '2014-12-17 13:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f5d6bc2447e6291c294734d7c2a88be77bc8b611', 'message': 'Add accept json/yaml for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}, {'number': 6, 'created': '2014-12-18 11:26:08.000000000', 'files': ['solum/api/controllers/v1/datamodel/plan.py', 'solum/tests/api/controllers/v1/test_plan.py', 'functionaltests/api/v1/test_plan.py', 'solum/tests/fakes.py', 'solum/api/controllers/v1/plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/db9e67a319b8cf68ae6114925c74a4b6c472d56e', 'message': 'Add accept json/yaml for GET /plans\n\nChange-Id: I984d745494b629f2ebab92b68c222f74ddab3b63\nPartially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support\nRelated-Bug: #1331093\n'}]",1,115685,db9e67a319b8cf68ae6114925c74a4b6c472d56e,38,9,6,9548,,,0,"Add accept json/yaml for GET /plans

Change-Id: I984d745494b629f2ebab92b68c222f74ddab3b63
Partially Implements: blueprint spec/plan-improvements-versionning-and-yaml-support
Related-Bug: #1331093
",git fetch https://review.opendev.org/openstack/solum refs/changes/85/115685/5 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/api/controllers/v1/test_plan.py', 'solum/api/controllers/v1/plan.py']",2,7039792c5f93233c18545974681a261d31a389f7,bug/1331093,"from wsme import types as wsme_types @pecan.expose() @pecan.expose() if pecan.request.accept is not None and 'yaml' in pecan.request.accept: plan_tpl = yamlutils.dump([yaml_content(obj) for obj in handler.get_all() if obj and obj.raw_content]) else: plan_tpl = wsme_json.encode_result( [plan.Plan.from_db_model(obj, pecan.request.host_url) for obj in handler.get_all()], wsme_types.ArrayType(plan.Plan)) return plan_tpl", @pecan.expose(content_type='application/x-yaml') @pecan.expose(content_type='application/x-yaml') plan_yml = yamlutils.dump([yaml_content(obj) for obj in handler.get_all() if obj and obj.raw_content]) return plan_yml,27,7
openstack%2Fkeystone~master~I8abc2385a4d9543e5028276843c7c13d176ce1df,openstack/keystone,master,I8abc2385a4d9543e5028276843c7c13d176ce1df,Fixes several typos on configuration doc,MERGED,2015-01-10 04:18:20.000000000,2015-01-14 00:13:44.000000000,2015-01-14 00:13:42.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 9142}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-10 04:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3e34e4dd5e47b57e7b25030b7c810224ed4f1040', 'message': 'Fixes several typos on configuration doc\n\nThis patch fixes several typos in\nconfiguration.rst, such as ""it\'s"", where it\nshould be the possessive pronoun ""its"".\n\nPartial-Bug: #1409201\nChange-Id: I8abc2385a4d9543e5028276843c7c13d176ce1df\n'}, {'number': 2, 'created': '2015-01-13 19:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/248f2519d5595a790abe78270fb714eb2473f51e', 'message': 'Fixes several typos on configuration doc\n\nThis patch fixes several typos in\nconfiguration.rst, such as ""it\'s"", where it\nshould be the possessive pronoun ""its"".\n\nPartial-Bug: #1409201\nChange-Id: I8abc2385a4d9543e5028276843c7c13d176ce1df\n'}, {'number': 3, 'created': '2015-01-13 20:13:33.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/27d9d958f37f143652e3777a43cc9bf62870ec2a', 'message': 'Fixes several typos on configuration doc\n\nThis patch fixes several typos in\nconfiguration.rst, such as ""it\'s"", where it\nshould be the possessive pronoun ""its"".\n\nPartial-Bug: #1409201\nChange-Id: I8abc2385a4d9543e5028276843c7c13d176ce1df\n'}]",3,146258,27d9d958f37f143652e3777a43cc9bf62870ec2a,15,5,3,9142,,,0,"Fixes several typos on configuration doc

This patch fixes several typos in
configuration.rst, such as ""it's"", where it
should be the possessive pronoun ""its"".

Partial-Bug: #1409201
Change-Id: I8abc2385a4d9543e5028276843c7c13d176ce1df
",git fetch https://review.opendev.org/openstack/keystone refs/changes/58/146258/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,3e34e4dd5e47b57e7b25030b7c810224ed4f1040,doc/4," Keystone does not support moving the contents of a domain (i.e. ""its"" to first disable it, remove its specific configuration file (i.e. itsSince public IDs are regenerable **with the correct generator implementation**, if the details of those entries that have been deleted are not available, then it is safe to simply bulk purge identity mappings periodically, for example:If the plugin requires additional configurations, it may register its own section in the configuration file. as it does not cleanup its internal cache on cache expiration, does backend and in the format of ``<argument name>:<argument value>``. will not immediately reflect changes on the backend. Any given changeKeystone to the directory server. In addition to supporting LDAP, Keystone"," Keystone does not support moving the contents of a domain (i.e. ""it's"" to first disable it, remove its specific configuration file (i.e. it'sSince public IDs are be regeneratable **with the correct generator implementation**, then, if the details of those entries that have been deleted are not available, then it is safe to simply bulk purge identity mappings periodically, for example:If the plugin require addition configurations, it may register its own section in the configuration file. as it does not cleanup it's internal cache on cache expiration, does back end and in the format of ``<argument name>:<argument value>``. will not immediately reflect changes on the back end. Any given changeKeystone to the directory server. In addition to supporting ldaps, Keystone",11,12
openstack%2Fironic-specs~master~I28b989c33ef822cee11e9055bb5c53aa47645fc9,openstack/ironic-specs,master,I28b989c33ef822cee11e9055bb5c53aa47645fc9,Update VirtualBox spec,MERGED,2015-01-08 14:53:38.000000000,2015-01-14 00:07:52.000000000,2015-01-14 00:07:50.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 10343}]","[{'number': 1, 'created': '2015-01-08 14:53:38.000000000', 'files': ['specs/kilo/ironic-virtualbox-webservice-support.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/df5225f70bd2d64120f12a0879bd31bdaa38aeab', 'message': 'Update VirtualBox spec\n\nThis commit addresses the pending nits/comments in\nVirtualBox spec when it was merged.\n\nChange-Id: I28b989c33ef822cee11e9055bb5c53aa47645fc9\n'}]",0,145800,df5225f70bd2d64120f12a0879bd31bdaa38aeab,9,5,1,9315,,,0,"Update VirtualBox spec

This commit addresses the pending nits/comments in
VirtualBox spec when it was merged.

Change-Id: I28b989c33ef822cee11e9055bb5c53aa47645fc9
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/00/145800/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ironic-virtualbox-webservice-support.rst'],1,df5225f70bd2d64120f12a0879bd31bdaa38aeab,vbox_power," available separately in GitHub and PyPI. Currently it is hosted in `GitHub`_. named ``VirtualBoxPower`` and ``VirtualBoxManagement``* This can also be used by users running VirtualBox on other operating systems where it is supported (other than Windows). They may also use SSHPower and SSHManagement if VirtualBox is running on linux machines. The advantage of this module over ssh ones is that, it will be faster (because ssh modules first ssh to system and then run VBoxManage command which does the same thing, so time for doing ssh is extra). The disadvantage is that VirtualBox webservice should be running all the time (which is not required for ssh ones). will be available in GitHub and PyPI for developers to install on their.. _`GitHub`: https://github.com/rameshg87/pyremotevbox", available separately in Github and PyPI. Currently it is hosted in `Github`_. named ``VirtualBoxPowerInterface`` and ``VirtualBoxManagementInterface`` will be available in Github and PyPI for developers to install on their.. _`Github`: https://github.com/rameshg87/pyremotevbox,13,4
openstack%2Ftooz~master~I77f50a1a4a5b08bd71d549e62fd471ef445b4bd7,openstack/tooz,master,I77f50a1a4a5b08bd71d549e62fd471ef445b4bd7,Upgrade to hacking 0.10,MERGED,2015-01-13 15:12:00.000000000,2015-01-14 00:06:03.000000000,2015-01-14 00:06:03.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}]","[{'number': 1, 'created': '2015-01-13 15:12:00.000000000', 'files': ['tooz/drivers/_retry.py', 'tooz/drivers/mysql.py', 'tooz/tests/drivers/test_retry.py', 'tooz/drivers/ipc.py', 'tooz/drivers/pgsql.py', 'tooz/drivers/memcached.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tooz/commit/26c39acd31725aaa8ac0bbc0b35cede70cd7133f', 'message': 'Upgrade to hacking 0.10\n\nChange-Id: I77f50a1a4a5b08bd71d549e62fd471ef445b4bd7\n'}]",0,146893,26c39acd31725aaa8ac0bbc0b35cede70cd7133f,11,3,1,1669,,,0,"Upgrade to hacking 0.10

Change-Id: I77f50a1a4a5b08bd71d549e62fd471ef445b4bd7
",git fetch https://review.opendev.org/openstack/tooz refs/changes/93/146893/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/_retry.py', 'tooz/drivers/mysql.py', 'tooz/tests/drivers/test_retry.py', 'tooz/drivers/ipc.py', 'tooz/drivers/memcached.py', 'tooz/drivers/pgsql.py', 'tox.ini']",7,26c39acd31725aaa8ac0bbc0b35cede70cd7133f,jd/hacking,"deps = hacking>=0.10.0,<0.11","deps = hacking>=0.9.2,<0.10",1,13
openstack%2Fheat~master~I06cee893c9aa16c1131cb625ca23c96154de33b3,openstack/heat,master,I06cee893c9aa16c1131cb625ca23c96154de33b3,Correct protocol allowed values for firewall rule,MERGED,2014-12-29 08:01:43.000000000,2015-01-14 00:02:34.000000000,2015-01-14 00:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-29 08:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/50d0dd0616824f2caefff4ec4d1ea8b7cfcfb798', 'message': ""Correct protocol allowed values for firewall rule\n\nChange protocol allowed values from None to 'any' since\nneutron not allow the string 'None' protocol.\n\nChange-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3\nCloses-Bug: #1406197\n""}, {'number': 2, 'created': '2014-12-30 01:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e4ffa1c6c5d4fd90d1dd2df03fab238477efd83e', 'message': ""Correct protocol allowed values for firewall rule\n\nChange protocol allowed values from None to 'any' since\nneutron not allow the string 'None' protocol.\n\nChange-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3\nCloses-Bug: #1406197\n""}, {'number': 3, 'created': '2015-01-08 01:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6111dddaf12a4f399e3a82f497e76f6ebe9ae5d', 'message': ""Correct protocol allowed values for firewall rule\n\nChange protocol allowed values from None to 'any' since\nneutron not allow the string 'None' protocol.\n\nChange-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3\nCloses-Bug: #1406197\n""}, {'number': 4, 'created': '2015-01-10 07:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9a1acac8635927771590b5bad816cb439697e3dc', 'message': ""Correct protocol allowed values for firewall rule\n\nChange protocol allowed values from None to 'any' since\nneutron not allow the string 'None' protocol.\n\nChange-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3\nCloses-Bug: #1406197\n""}, {'number': 5, 'created': '2015-01-13 14:52:21.000000000', 'files': ['heat/tests/test_neutron_firewall.py', 'heat/engine/resources/neutron/firewall.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c99d3631e013ea518a2b8271f8ccff3e22023aa9', 'message': ""Correct protocol allowed values for firewall rule\n\nChange protocol allowed values from None to 'any' since\nneutron not allow the string 'None' protocol.\n\nChange-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3\nCloses-Bug: #1406197\n""}]",1,144264,c99d3631e013ea518a2b8271f8ccff3e22023aa9,55,11,5,8289,,,0,"Correct protocol allowed values for firewall rule

Change protocol allowed values from None to 'any' since
neutron not allow the string 'None' protocol.

Change-Id: I06cee893c9aa16c1131cb625ca23c96154de33b3
Closes-Bug: #1406197
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/144264/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/firewall.py', 'heat/tests/test_neutron_firewall.py']",2,50d0dd0616824f2caefff4ec4d1ea8b7cfcfb798,bug/1406197," def test_validate_failed_with_string_None_protocol(self): snippet = template_format.parse(firewall_rule_template) stack = utils.parse_stack(snippet) rsrc = stack['firewall_rule'] rsrc.t['Properties']['protocol'] = 'None' self.assertRaises(exception.StackValidationFailed, rsrc.validate) def test_create_with_protocol_any(self): neutronclient.Client.create_firewall_rule({ 'firewall_rule': { 'name': 'test-firewall-rule', 'shared': True, 'action': 'allow', 'protocol': None, 'enabled': True, 'ip_version': ""4""}} ).AndReturn({'firewall_rule': {'id': '5678'}}) self.m.ReplayAll() snippet = template_format.parse(firewall_rule_template) stack = utils.parse_stack(snippet) rsrc = stack['firewall_rule'] rsrc.t['Properties']['protocol'] = 'any' scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() def test_update_protocol_to_any(self): rsrc = self.create_firewall_rule() neutronclient.Client.update_firewall_rule( '5678', {'firewall_rule': {'protocol': None}}) self.m.ReplayAll() scheduler.TaskRunner(rsrc.create)() # update to 'any' protocol update_template = copy.deepcopy(rsrc.t) update_template['Properties']['protocol'] = 'any' scheduler.TaskRunner(rsrc.update, update_template)() self.m.VerifyAll()",,42,1
openstack%2Fironic~master~Ie0e5b7c20e2ba701d75ed2853190b318c63c0413,openstack/ironic,master,Ie0e5b7c20e2ba701d75ed2853190b318c63c0413,Document dependency on `fuser` for pxe driver,MERGED,2015-01-13 18:45:08.000000000,2015-01-13 23:59:36.000000000,2015-01-13 23:59:35.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-13 18:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d4df116d48264fb8c738ab7be0ead9fc9c20d2a8', 'message': 'Document dependency on `fuser` for unit tests\n\nThis is provided by the package `psmisc` on all three documented\ndistributions.\n\nChange-Id: Ie0e5b7c20e2ba701d75ed2853190b318c63c0413\nCloses-bug: 1358820\n'}, {'number': 2, 'created': '2015-01-13 18:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0f0811376c0bb86f7e0d1b76c9d7e8f4ec8ee311', 'message': 'Document dependency on `fuser` for pxe driver\n\nThis is provided by the package `psmisc` on all three documented\ndistributions.\n\nChange-Id: Ie0e5b7c20e2ba701d75ed2853190b318c63c0413\nCloses-bug: 1358820\n'}, {'number': 3, 'created': '2015-01-13 18:55:27.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d1f772a8c57b303c2300a22d08361f1006078abf', 'message': 'Document dependency on `fuser` for pxe driver\n\nThis is provided by the package `psmisc` on all three documented\ndistributions.\n\nChange-Id: Ie0e5b7c20e2ba701d75ed2853190b318c63c0413\nCloses-bug: 1358820\n'}]",1,146948,d1f772a8c57b303c2300a22d08361f1006078abf,15,4,3,10342,,,0,"Document dependency on `fuser` for pxe driver

This is provided by the package `psmisc` on all three documented
distributions.

Change-Id: Ie0e5b7c20e2ba701d75ed2853190b318c63c0413
Closes-bug: 1358820
",git fetch https://review.opendev.org/openstack/ironic refs/changes/48/146948/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,d4df116d48264fb8c738ab7be0ead9fc9c20d2a8,bug/1358820, sudo apt-get install python-dev libssl-dev python-pip libmysqlclient-dev libxml2-dev libxslt-dev libpq-dev git git-review libffi-dev gettext psmisc sudo yum install python-devel openssl-devel python-pip mysql-devel libxml2-devel libxslt-devel postgresql-devel git git-review libffi-devel gettext ipmitool psmisc sudo zypper install git git-review libffi-devel libmysqlclient-devel libopenssl-devel libxml2-devel libxslt-devel postgresql-devel python-devel python-nose python-pip gettext-runtime psmisc, sudo apt-get install python-dev libssl-dev python-pip libmysqlclient-dev libxml2-dev libxslt-dev libpq-dev git git-review libffi-dev gettext sudo yum install python-devel openssl-devel python-pip mysql-devel libxml2-devel libxslt-devel postgresql-devel git git-review libffi-devel gettext ipmitool sudo zypper install git git-review libffi-devel libmysqlclient-devel libopenssl-devel libxml2-devel libxslt-devel postgresql-devel python-devel python-nose python-pip gettext-runtime,3,3
openstack%2Frequirements~master~Iae7c55861adc6cf09869c76ec2a1b4ef3f6955df,openstack/requirements,master,Iae7c55861adc6cf09869c76ec2a1b4ef3f6955df,Block oslo.concurrency 0.4.0,MERGED,2015-01-13 17:49:35.000000000,2015-01-13 23:59:19.000000000,2015-01-13 23:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 7166}]","[{'number': 1, 'created': '2015-01-13 17:49:35.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/53c356d695df23a21cdd639f0dd3c837db045a29', 'message': ""Block oslo.concurrency 0.4.0\n\nThe 0.4.0 release has a change 7c7493feb which\nbreaks nova unit tests on python 2*, the change\nis being reverted and a 0.4.1 release will fix\nthat, but we can't use the 0.4.0 version in nova\nwithout a workaround change.\n\nChange-Id: Iae7c55861adc6cf09869c76ec2a1b4ef3f6955df\nRelated-Bug: #1410348\n""}]",0,146942,53c356d695df23a21cdd639f0dd3c837db045a29,12,7,1,6873,,,0,"Block oslo.concurrency 0.4.0

The 0.4.0 release has a change 7c7493feb which
breaks nova unit tests on python 2*, the change
is being reverted and a 0.4.1 release will fix
that, but we can't use the 0.4.0 version in nova
without a workaround change.

Change-Id: Iae7c55861adc6cf09869c76ec2a1b4ef3f6955df
Related-Bug: #1410348
",git fetch https://review.opendev.org/openstack/requirements refs/changes/42/146942/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,53c356d695df23a21cdd639f0dd3c837db045a29,bug/1410348,"oslo.concurrency>=0.3.0,!=0.4.0 # Apache-2.0",oslo.concurrency>=0.3.0 # Apache-2.0,1,1
openstack%2Fkeystonemiddleware~master~Id6d3bc1767e264d3f07c4e14758d67e10223f02f,openstack/keystonemiddleware,master,Id6d3bc1767e264d3f07c4e14758d67e10223f02f,Correct failures for check H703,MERGED,2015-01-12 00:35:33.000000000,2015-01-13 23:52:07.000000000,2015-01-13 23:52:06.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-01-12 00:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5d006f49ba8a17925a43c9bd1aeebd67f18810a8', 'message': 'Correct failures for check H703\n\nThe H703 ""Multiple positional placeholders"" rule was failing and\nignored. Now it\'s enforced.\n\nChange-Id: Id6d3bc1767e264d3f07c4e14758d67e10223f02f\n'}, {'number': 2, 'created': '2015-01-13 20:42:11.000000000', 'files': ['keystonemiddleware/auth_token.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/a31ed5ca4faace4afe30942a155e210a3334edd3', 'message': 'Correct failures for check H703\n\nThe H703 ""Multiple positional placeholders"" rule was failing and\nignored. Now it\'s enforced.\n\nChange-Id: Id6d3bc1767e264d3f07c4e14758d67e10223f02f\n'}]",0,146358,a31ed5ca4faace4afe30942a155e210a3334edd3,15,5,2,6486,,,0,"Correct failures for check H703

The H703 ""Multiple positional placeholders"" rule was failing and
ignored. Now it's enforced.

Change-Id: Id6d3bc1767e264d3f07c4e14758d67e10223f02f
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/58/146358/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/auth_token.py', 'tox.ini']",2,5d006f49ba8a17925a43c9bd1aeebd67f18810a8,hacking,"ignore = E122,F821,H238,H304,H405","# H703: Multiple positional placeholders ignore = E122,F821,H238,H304,H405,H703",3,4
openstack%2Fdevstack-gate~master~I76c78bcf1fe49903df7d0bcecbb4c81ea0d73ca2,openstack/devstack-gate,master,I76c78bcf1fe49903df7d0bcecbb4c81ea0d73ca2,Copy tempest.log from verify-tempest-config,MERGED,2014-12-19 17:25:50.000000000,2015-01-13 23:47:52.000000000,2015-01-13 23:47:51.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-12-19 17:25:50.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/80c8c91e0b03ebaf7f8c520c35ce58a797939185', 'message': ""Copy tempest.log from verify-tempest-config\n\nAs part of the current devstack runs verify-tempest-config is run to\ngenerate a complete extension list which is only used when a disable\nextension option is provided. While this is not the best method for\ndoing this, since it exposes the risk of silently skipping tests if\nthere is an api bug it is currently how devstack supports doing this.\nHowever, calling verify-tempest-config has one side-effect that it\ngenerates a separate log file where it's run (at least using the\ndefault oslo logging configuration) This commit adds a check if the\nlog file exists and copies it along with the other artifacts. So that\npeople will be able to debug failures in the verify-tempest-config\ntool when they occur.\n\nChange-Id: I76c78bcf1fe49903df7d0bcecbb4c81ea0d73ca2\n""}]",0,143142,80c8c91e0b03ebaf7f8c520c35ce58a797939185,10,4,1,5196,,,0,"Copy tempest.log from verify-tempest-config

As part of the current devstack runs verify-tempest-config is run to
generate a complete extension list which is only used when a disable
extension option is provided. While this is not the best method for
doing this, since it exposes the risk of silently skipping tests if
there is an api bug it is currently how devstack supports doing this.
However, calling verify-tempest-config has one side-effect that it
generates a separate log file where it's run (at least using the
default oslo logging configuration) This commit adds a check if the
log file exists and copies it along with the other artifacts. So that
people will be able to debug failures in the verify-tempest-config
tool when they occur.

Change-Id: I76c78bcf1fe49903df7d0bcecbb4c81ea0d73ca2
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/42/143142/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,80c8c91e0b03ebaf7f8c520c35ce58a797939185,, if -f [ $BASE/old/devstack/tempest.log ] ; then sudo cp $BASE/old/devstack/tempest.log $BASE/logs/old/verify_tempest_conf.log fi if [ -f $BASE/new/devstack/tempest.log ]; then sudo cp $BASE/new/devstack/tempest.log $NEWLOGTARGET/verify_tempest_conf.log fi,,6,0
openstack%2Fpython-novaclient~master~I4ef6142676022b2e2f3178e7bfa24ed985fcae2c,openstack/python-novaclient,master,I4ef6142676022b2e2f3178e7bfa24ed985fcae2c,Directly using base64 encoding for injected files,MERGED,2015-01-07 18:32:31.000000000,2015-01-13 23:30:48.000000000,2015-01-13 23:30:46.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 4690}, {'_account_id': 7135}]","[{'number': 1, 'created': '2015-01-07 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/7ff27eb5a733f80f6ac7c7d32c03ece64eb3507d', 'message': 'Directly using base64 encoding for injected files\n\nBinary files cannot be treated as utf-8 byte streams and converted\nto plain. Change this back to just using base64 encoding as it was\nbefore commit 8b264fc61d21fe4d0c7405914fb084f898956888.\n\nChange-Id: I4ef6142676022b2e2f3178e7bfa24ed985fcae2c\nCloses-Bug: #1408088\n'}, {'number': 2, 'created': '2015-01-07 20:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/84659f9a7396edf20f94fa35069cc5badc167df3', 'message': 'Directly using base64 encoding for injected files\n\nBinary files cannot be treated as utf-8 byte streams and converted\nto plain. Change this back to just using base64 encoding as it was\nbefore commit 8b264fc61d21fe4d0c7405914fb084f898956888.\n\nChange-Id: I4ef6142676022b2e2f3178e7bfa24ed985fcae2c\nCloses-Bug: #1408088\n'}, {'number': 3, 'created': '2015-01-07 20:27:57.000000000', 'files': ['novaclient/v1_1/servers.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f75ea86a2a4ee0bed076ee9e4ea5021eb0643e16', 'message': 'Directly using base64 encoding for injected files\n\nBinary files cannot be treated as utf-8 byte streams and converted\nto plain. Change this back to just using base64 encoding as it was\nbefore commit 8b264fc61d21fe4d0c7405914fb084f898956888.\n\nChange-Id: I4ef6142676022b2e2f3178e7bfa24ed985fcae2c\nCloses-Bug: #1408088\n'}]",9,145554,f75ea86a2a4ee0bed076ee9e4ea5021eb0643e16,26,5,3,7135,,,0,"Directly using base64 encoding for injected files

Binary files cannot be treated as utf-8 byte streams and converted
to plain. Change this back to just using base64 encoding as it was
before commit 8b264fc61d21fe4d0c7405914fb084f898956888.

Change-Id: I4ef6142676022b2e2f3178e7bfa24ed985fcae2c
Closes-Bug: #1408088
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/54/145554/2 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v1_1/servers.py'],1,7ff27eb5a733f80f6ac7c7d32c03ece64eb3507d,bug/1408088, cont = base64.b64encode(data).decode('utf-8'), cont = base64.b64encode(data.encode('utf-8')).decode('utf-8'),1,1
openstack%2Foslo.concurrency~master~Ia478bca795909d5a038bcfc522c4b57766781eed,openstack/oslo.concurrency,master,Ia478bca795909d5a038bcfc522c4b57766781eed,Allow callers to disable encoding for execute(),ABANDONED,2015-01-13 17:18:47.000000000,2015-01-13 23:23:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 6928}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-01-13 17:18:47.000000000', 'files': ['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/9767fe7bd7243826f4820e3a4b4d1de4d77772e0', 'message': 'Allow callers to disable encoding for execute()\n\nNot all of the commands run will produce text output that needs to be\ndecoded. Allow the caller to pass None to bypass output decoding.\n\nChange-Id: Ia478bca795909d5a038bcfc522c4b57766781eed\nCloses-Bug: #1410348\n'}]",2,146932,9767fe7bd7243826f4820e3a4b4d1de4d77772e0,7,5,1,2472,,,0,"Allow callers to disable encoding for execute()

Not all of the commands run will produce text output that needs to be
decoded. Allow the caller to pass None to bypass output decoding.

Change-Id: Ia478bca795909d5a038bcfc522c4b57766781eed
Closes-Bug: #1410348
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/32/146932/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py']",2,9767fe7bd7243826f4820e3a4b4d1de4d77772e0,bug/1410348,"import codecs class OutputEncodingTest(test_base.BaseTestCase): def test_no_encoding(self): if six.PY3: out, err = processutils.execute( 'python3', '-c', 'import codecs, sys; sys.stdout.buffer.write(codecs.BOM_UTF16_BE)', encoding=None, ) self.assertEqual(out, codecs.BOM_UTF16_BE) self.assertEqual(err, b'') else: out, err = processutils.execute( 'python', '-c', 'import codecs; print(codecs.BOM_UTF16_BE)', encoding=None, ) self.assertEqual(out, codecs.BOM_UTF16_BE + '\n') self.assertEqual(err, '') def test_default_encoding(self): if six.PY3: out, err = processutils.execute( 'python3', '-c', 'print(""\U0001f603"")', ) self.assertEqual(out, '\U0001f603\n') else: out, err = processutils.execute( 'python', '-c', 'import six; print(u""\U0001f603"".encode(""utf-8""))', ) self.assertEqual(out, u'\U0001f603\n') self.assertEqual(err, '')",,40,3
openstack%2Ftempest~master~Id41e94e100d283fc94059ac2f202625ea6a2ae0e,openstack/tempest,master,Id41e94e100d283fc94059ac2f202625ea6a2ae0e,Updated from global requirements,MERGED,2015-01-08 18:51:55.000000000,2015-01-13 23:15:59.000000000,2015-01-13 23:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 9656}, {'_account_id': 10385}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-01-08 18:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c406c98057507d98d8451f27cc5b972ff9926651', 'message': 'Updated from global requirements\n\nChange-Id: Id41e94e100d283fc94059ac2f202625ea6a2ae0e\n'}, {'number': 2, 'created': '2015-01-09 14:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1be7482c970f067d07c76f844567273308f9684f', 'message': 'Updated from global requirements\n\nChange-Id: Id41e94e100d283fc94059ac2f202625ea6a2ae0e\n'}, {'number': 3, 'created': '2015-01-13 00:16:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/928a6caed9276bd7057f99cd8f85e8a4401f0cbd', 'message': 'Updated from global requirements\n\nChange-Id: Id41e94e100d283fc94059ac2f202625ea6a2ae0e\n'}]",0,145901,928a6caed9276bd7057f99cd8f85e8a4401f0cbd,19,6,3,11131,,,0,"Updated from global requirements

Change-Id: Id41e94e100d283fc94059ac2f202625ea6a2ae0e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/01/145901/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c406c98057507d98d8451f27cc5b972ff9926651,openstack/requirements,oslo.config>=1.6.0 # Apache-2.0,oslo.config>=1.4.0 # Apache-2.0,1,1
openstack%2Fneutron~master~Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e,openstack/neutron,master,Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e,VMWare NSXv DB model bugfix,MERGED,2015-01-11 09:54:40.000000000,2015-01-13 23:14:16.000000000,2015-01-13 18:19:28.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13438}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-11 09:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd088cdb619b272eedf937cc19704924d546f4b6', 'message': 'VMWare NSXv DB model bugfix\n\nDB Model and migration for VMWare NSXv had two issues:\nIn DB migration, nsxv_security_group_section_mappings table is not dropped on downgrade.\nIn nsxv_models.py, tz_network_bindings_binding_type enum name should be\nnsxv_tz_network_bindings_binding_type to match migration code.\n\nChange-Id: Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e\nCloses-bug: #1409411\n'}, {'number': 2, 'created': '2015-01-11 14:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/db70d5f8ef264d142af55baee29eeb8e6c0c58c8', 'message': 'VMWare NSXv DB model bugfix\n\nDB Model and migration for VMWare NSXv had two issues:\nIn DB migration, nsxv_security_group_section_mappings table is not dropped on downgrade.\nIn nsxv_models.py, tz_network_bindings_binding_type enum name should be\nnsxv_tz_network_bindings_binding_type to match migration code.\n\nChange-Id: Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e\nCloses-bug: #1409411\n'}, {'number': 3, 'created': '2015-01-12 09:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7159720acedb4721e5884596ceabbba2fc28ba76', 'message': 'VMWare NSXv DB model bugfix\n\nDB Model and migration for VMWare NSXv had two issues:\nIn DB migration, nsxv_security_group_section_mappings table is not dropped on downgrade.\nIn nsxv_models.py, tz_network_bindings_binding_type enum name should be\nnsxv_tz_network_bindings_binding_type to match migration code.\n\nChange-Id: Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e\nCloses-bug: #1409411\n'}, {'number': 4, 'created': '2015-01-13 08:26:12.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/4dbe243cd84d_nsxv.py', 'neutron/plugins/vmware/dbexts/nsxv_models.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/681ac331765892cfc8885907f87d2b3168a66012', 'message': 'VMWare NSXv DB model bugfix\n\nDB Model and migration for VMWare NSXv had two issues:\nIn DB migration, nsxv_security_group_section_mappings table is not dropped on downgrade.\nIn nsxv_models.py, tz_network_bindings_binding_type enum name should be\nnsxv_tz_network_bindings_binding_type to match migration code.\n\nChange-Id: Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e\nCloses-bug: #1409411\n'}]",0,146306,681ac331765892cfc8885907f87d2b3168a66012,96,27,4,13438,,,0,"VMWare NSXv DB model bugfix

DB Model and migration for VMWare NSXv had two issues:
In DB migration, nsxv_security_group_section_mappings table is not dropped on downgrade.
In nsxv_models.py, tz_network_bindings_binding_type enum name should be
nsxv_tz_network_bindings_binding_type to match migration code.

Change-Id: Ib5e8a2078d9c86da6375c7b6a39f48d5bba4e06e
Closes-bug: #1409411
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/146306/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/4dbe243cd84d_nsxv.py', 'neutron/plugins/vmware/dbexts/nsxv_models.py']",2,dd088cdb619b272eedf937cc19704924d546f4b6,nsxv_db_fix," binding_type = sa.Column( sa.Enum('flat', 'vlan', 'portgroup', name='nsxv_tz_network_bindings_binding_type'), nullable=False, primary_key=True)"," binding_type = sa.Column(sa.Enum('flat', 'vlan', 'portgroup', name='tz_network_bindings_binding_type'), nullable=False, primary_key=True)",6,5
openstack%2Fdevstack~master~I8b203ffc6d9cf588462d0d65a9703a9941d8fa71,openstack/devstack,master,I8b203ffc6d9cf588462d0d65a9703a9941d8fa71,Depreciated pip option PIP_DOWNLOAD_CACHE removal,MERGED,2014-12-28 01:11:23.000000000,2015-01-13 23:05:48.000000000,2015-01-13 23:05:46.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 7118}, {'_account_id': 10215}, {'_account_id': 10385}, {'_account_id': 11444}]","[{'number': 1, 'created': '2014-12-28 01:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/975b24d6a85f90563131b4682c26b720c05101e1', 'message': 'Fix the way how pip uses own cache\n\nFix warning:\nDEPRECATION: --download-cache has been deprecated and will be removed in the\nfuture. Pip now automatically uses and configures its cache.\n\n1. Since version 6.0 (2014-12-22) pip has deprecated PIP_DOWNLOAD_CACHE\n   and now automatically uses and configures its cache.\n   Default new location is $HOME/.cache/pip.\n2. If pip version<6, stack.sh still uses PIP_DOWNLOAD_CACHE.\n3. Fix old behaviour when default cache directory /var/cache/pip was missing,\n   has never been created.\n\nChange-Id: I8b203ffc6d9cf588462d0d65a9703a9941d8fa71\n'}, {'number': 2, 'created': '2015-01-12 23:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e19b8c93595cafa92b5fe895b742d8b6e2c6ce9a', 'message': 'Depreciated pip option PIP_DOWNLOAD_CACHE removal\n\nFix warning:\nDEPRECATION: --download-cache has been deprecated and will be removed in the\nfuture. Pip now automatically uses and configures its cache.\n\n1. Since version 6.0 (2014-12-22) pip has deprecated PIP_DOWNLOAD_CACHE\n   and now automatically uses and configures its cache.\n   Default new location is $HOME/.cache/pip.\n2. pip gets upgraded to the latest version in tools/install_pip.sh\n   but if pip version<6, exit with error: ""Currently installed pip version\n   ${pip_version} does not meet meet minimum requirements""\n\nChange-Id: I8b203ffc6d9cf588462d0d65a9703a9941d8fa71\n'}, {'number': 3, 'created': '2015-01-13 06:30:57.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6ce071b796d7bbf851df225ca7097d2de26b3456', 'message': 'Depreciated pip option PIP_DOWNLOAD_CACHE removal\n\nFix warning:\nDEPRECATION: --download-cache has been deprecated and will be removed in the\nfuture. Pip now automatically uses and configures its cache.\n\n1. Since version 6.0 (2014-12-22) pip has deprecated PIP_DOWNLOAD_CACHE\n   and now automatically uses and configures its cache.\n   Default new location is $HOME/.cache/pip.\n2. pip gets upgraded to the latest version in tools/install_pip.sh\n   but if pip version<6, exit with error: ""Currently installed pip version\n   ${pip_version} does not meet meet minimum requirements""\n\nChange-Id: I8b203ffc6d9cf588462d0d65a9703a9941d8fa71\n'}]",4,144218,6ce071b796d7bbf851df225ca7097d2de26b3456,27,8,3,11444,,,0,"Depreciated pip option PIP_DOWNLOAD_CACHE removal

Fix warning:
DEPRECATION: --download-cache has been deprecated and will be removed in the
future. Pip now automatically uses and configures its cache.

1. Since version 6.0 (2014-12-22) pip has deprecated PIP_DOWNLOAD_CACHE
   and now automatically uses and configures its cache.
   Default new location is $HOME/.cache/pip.
2. pip gets upgraded to the latest version in tools/install_pip.sh
   but if pip version<6, exit with error: ""Currently installed pip version
   ${pip_version} does not meet meet minimum requirements""

Change-Id: I8b203ffc6d9cf588462d0d65a9703a9941d8fa71
",git fetch https://review.opendev.org/openstack/devstack refs/changes/18/144218/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,975b24d6a85f90563131b4682c26b720c05101e1,pip_cache,"# Uses globals ``OFFLINE``, ``TRACK_DEPENDS``, ``*_proxy`` pip_version=$(python -c ""import pip; print(pip.__version__.strip('.')[0])"") if (( pip_version>=6 )); then # PIP_DOWNLOAD_CACHE has been deprecated, pip now automatically uses # and configures its own cache, new default is $HOME/.cache/pip pip_cache='' else test -d /var/cache/pip || mkdir /var/cache/pip pip_cache='PIP_DOWNLOAD_CACHE=/var/cache/pip' fi $sudo_pip $pip_cache \ $sudo_pip $pip_cache \","# - ``PIP_DOWNLOAD_CACHE``# Uses globals ``OFFLINE``, ``PIP_DOWNLOAD_CACHE``, # ``TRACK_DEPENDS``, ``*_proxy`` $sudo_pip PIP_DOWNLOAD_CACHE=${PIP_DOWNLOAD_CACHE:-/var/cache/pip} \ $sudo_pip PIP_DOWNLOAD_CACHE=${PIP_DOWNLOAD_CACHE:-/var/cache/pip} \",13,5
openstack%2Ftrove-integration~master~Ida186454d247d827312fd004d84efba13f780b0c,openstack/trove-integration,master,Ida186454d247d827312fd004d84efba13f780b0c,Fix malformed pip-install lines,MERGED,2015-01-09 17:45:58.000000000,2015-01-13 23:05:38.000000000,2015-01-13 23:05:38.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 6413}, {'_account_id': 8214}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9746}, {'_account_id': 9750}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10725}]","[{'number': 1, 'created': '2015-01-09 17:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/d19c7bd4a7a1888c110167ee8b283fe6798dad16', 'message': 'Fix malformed pip-install lines\n\nThe pip install command attempted to provide version hint requirements\non the command line but failed to quote the individual package\nnames. This resulted in the creation of files in the ""/"" directory of\nthe guest with names corresponding to the versions specified. The\ncorrect way to specify version restrictions is to quote the package\nnames.\n\nChange-Id: Ida186454d247d827312fd004d84efba13f780b0c\nCloses-Bug: #1406581\n'}, {'number': 2, 'created': '2015-01-09 21:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/96bce24e536bce34f7c33c7bc4907adfe7b43939', 'message': 'Fix malformed pip-install lines\n\nThe pip install command attempted to provide version hint requirements\non the command line but failed to quote the individual package\nnames. This resulted in the creation of files in the ""/"" directory of\nthe guest with names corresponding to the versions specified. The\ncorrect way to specify version restrictions is to quote the package\nnames.\n\nChange-Id: Ida186454d247d827312fd004d84efba13f780b0c\nCloses-Bug: #1406581\nCloses-Bug: #1409053\n'}, {'number': 3, 'created': '2015-01-10 01:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/6a25efa7707afdc6c166bf99d7e5b4c03333bffb', 'message': 'Fix malformed pip-install lines\n\nThe pip install command attempted to provide version hint requirements\non the command line but failed to quote the individual package\nnames. This resulted in the creation of files in the ""/"" directory of\nthe guest with names corresponding to the versions specified. To make\nit easier to maintain in the future, a requirements.txt file for\nubuntu and fedora and a extra-data.d step which will copy this from\nthe source tree into the guest image (extra-data.d/15-reddwarf-dep)\nhave been added, and the 15-reddwarf-dep step in install.d can\nreference the requirements.txt file.\n\nrequirements.txt has been updated to reflect the versions of packages\nthat trove has in its requirements.txt. Finally the dependency issue\nwith testtools and unittest2 have been addressed by adding them to the\nrequirements.txt file and adding the --upgrade option to pip install.\n\nChange-Id: Ida186454d247d827312fd004d84efba13f780b0c\nCloses-Bug: #1406581\nCloses-Bug: #1409053\n'}, {'number': 4, 'created': '2015-01-13 01:43:20.000000000', 'files': ['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/extra-data.d/15-reddwarf-dep', 'scripts/files/requirements/ubuntu-requirements.txt', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep', 'scripts/files/requirements/fedora-requirements.txt', 'scripts/files/elements/fedora-guest/extra-data.d/15-reddwarf-dep'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/9f764e4aea018ba87c9e6904c2eca5babee119f2', 'message': 'Fix malformed pip-install lines\n\nThe pip install command attempted to provide version hint requirements\non the command line but failed to quote the individual package\nnames. This resulted in the creation of files in the ""/"" directory of\nthe guest with names corresponding to the versions specified. To make\nit easier to maintain in the future, a requirements.txt file for\nubuntu and fedora and a extra-data.d step which will copy this from\nthe source tree into the guest image (extra-data.d/15-reddwarf-dep)\nhave been added, and the 15-reddwarf-dep step in install.d can\nreference the requirements.txt file.\n\nrequirements.txt has been updated to reflect the versions of packages\nthat trove has in its requirements.txt. Finally the dependency issue\nwith testtools and unittest2 have been addressed by adding them to the\nrequirements.txt file and adding the --upgrade option to pip install.\n\nChange-Id: Ida186454d247d827312fd004d84efba13f780b0c\nCloses-Bug: #1406581\nCloses-Bug: #1409053\n'}]",3,146147,9f764e4aea018ba87c9e6904c2eca5babee119f2,32,11,4,9664,,,0,"Fix malformed pip-install lines

The pip install command attempted to provide version hint requirements
on the command line but failed to quote the individual package
names. This resulted in the creation of files in the ""/"" directory of
the guest with names corresponding to the versions specified. To make
it easier to maintain in the future, a requirements.txt file for
ubuntu and fedora and a extra-data.d step which will copy this from
the source tree into the guest image (extra-data.d/15-reddwarf-dep)
have been added, and the 15-reddwarf-dep step in install.d can
reference the requirements.txt file.

requirements.txt has been updated to reflect the versions of packages
that trove has in its requirements.txt. Finally the dependency issue
with testtools and unittest2 have been addressed by adding them to the
requirements.txt file and adding the --upgrade option to pip install.

Change-Id: Ida186454d247d827312fd004d84efba13f780b0c
Closes-Bug: #1406581
Closes-Bug: #1409053
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/47/146147/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-guest/install.d/15-reddwarf-dep', 'scripts/files/elements/ubuntu-guest/install.d/15-reddwarf-dep']",2,d19c7bd4a7a1888c110167ee8b283fe6798dad16,bugs/bug-1406581,"apt-get -y install python-dev libxml2-dev libxslt1-dev python-setuptools \ python-pip python-sqlalchemy python-lxml \ python-routes python-eventlet python-webob \ python-pastedeploy python-paste python-netaddr \pip install -q extras python-novaclient python-swiftclient python-cinderclient \ ""kombu>2.4.7"" six babel python-heatclient passlib jinja2 python-neutronclient netifaces \ ""oslo.config>=1.2.0"" ""oslo.messaging>=1.4.0"" ""oslo.i18n>=1.0.0"" ""oslo.serialization>=1.0.0"" \ ""oslo.utils>=1.0.0"" ""osprofiler>=0.3.0"" ""oslo.concurrency>=0.3.0""",apt-get -y install python-dev libxml2-dev libxslt1-dev python-setuptools python-pip python-sqlalchemy python-lxml \ python-routes python-eventlet python-webob python-pastedeploy python-paste python-netaddr \pip install extras python-novaclient python-swiftclient python-cinderclient \ kombu>2.4.7 six babel python-heatclient passlib jinja2 python-neutronclient netifaces \ oslo.config>=1.2.0 oslo.messaging>=1.4.0 oslo.i18n>=1.0.0 oslo.serialization>=1.0.0 oslo.utils>=1.0.0 \ osprofiler>=0.3.0 oslo.concurrency>=0.3.0,18,13
openstack%2Fmagnum~master~Ifbd10246682dda32bb28bbc1d640ff365d53495d,openstack/magnum,master,Ifbd10246682dda32bb28bbc1d640ff365d53495d,Implement service deletion,MERGED,2015-01-13 06:46:31.000000000,2015-01-13 23:05:32.000000000,2015-01-13 23:05:32.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7494}]","[{'number': 1, 'created': '2015-01-13 06:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2041aae9d5a91b818feb2c2cdade7f5d4af557e6', 'message': 'Implement service deletion\n\nService deletion is working from magnum api.\n\nChange-Id: Ifbd10246682dda32bb28bbc1d640ff365d53495d\n'}, {'number': 2, 'created': '2015-01-13 14:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d921052c85a8033f6d47c9f783da17feb46bd455', 'message': 'Implement service deletion\n\nService deletion is working from magnum api.\n\nChange-Id: Ifbd10246682dda32bb28bbc1d640ff365d53495d\n'}, {'number': 3, 'created': '2015-01-13 22:09:33.000000000', 'files': ['magnum/conductor/handlers/common/kube_utils.py', 'magnum/conductor/api.py', 'magnum/tests/api/controllers/v1/test_service.py', 'magnum/tests/conductor/test_rpcapi.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/444a202859dbd3079292f5d64464c02f68401b42', 'message': 'Implement service deletion\n\nService deletion is working from magnum api.\n\nChange-Id: Ifbd10246682dda32bb28bbc1d640ff365d53495d\n'}]",0,146774,444a202859dbd3079292f5d64464c02f68401b42,14,3,3,12385,,,0,"Implement service deletion

Service deletion is working from magnum api.

Change-Id: Ifbd10246682dda32bb28bbc1d640ff365d53495d
",git fetch https://review.opendev.org/openstack/magnum refs/changes/74/146774/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/common/kube_utils.py', 'magnum/conductor/api.py', 'magnum/tests/api/controllers/v1/test_service.py', 'magnum/tests/conductor/test_rpcapi.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py']",6,2041aae9d5a91b818feb2c2cdade7f5d4af557e6,impl-k8s-backend," def service_delete(self, ctxt, uuid): service = objects.Service.get_by_uuid(ctxt, uuid) k8s_master_url = _retrive_k8s_master_url(ctxt, service) status = self.kube_cli.service_delete(k8s_master_url, service.name)"," def service_delete(self, ctxt, service): status = self.kube_cli.service_delete(service.uuid)",16,15
openstack%2Fmagnum~master~I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86,openstack/magnum,master,I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86,Set service name from service manifest,MERGED,2015-01-13 06:46:31.000000000,2015-01-13 23:05:26.000000000,2015-01-13 23:05:26.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 06:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cb4f1dcf3a81e2a208da99b7d6a3d6a32b48b20b', 'message': 'Set service name from service manifest\n\nOnly service manifest knows about service name, so this patch retrieve service\nname from service manifest.\n\nChange-Id: I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86\n'}, {'number': 2, 'created': '2015-01-13 14:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2937af2a911038ae74d1db8e7e4a8459d4dfe993', 'message': 'Set service name from service manifest\n\nOnly service manifest knows about service name, so this patch retrieve service\nname from service manifest.\n\nChange-Id: I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86\n'}, {'number': 3, 'created': '2015-01-13 22:09:33.000000000', 'files': ['magnum/objects/service.py', 'magnum/tests/api/controllers/v1/test_service.py', 'magnum/api/controllers/v1/service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b982600545fad1c105cd034da44475fbbdebf3a0', 'message': 'Set service name from service manifest\n\nOnly service manifest knows about service name, so this patch retrieve service\nname from service manifest.\n\nChange-Id: I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86\n'}]",5,146773,b982600545fad1c105cd034da44475fbbdebf3a0,18,6,3,12385,,,0,"Set service name from service manifest

Only service manifest knows about service name, so this patch retrieve service
name from service manifest.

Change-Id: I1eb0f7dd7227875e1d10e5bd1d22f7e989e15f86
",git fetch https://review.opendev.org/openstack/magnum refs/changes/73/146773/3 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/objects/service.py', 'magnum/tests/api/controllers/v1/test_service.py', 'magnum/api/controllers/v1/service.py']",3,cb4f1dcf3a81e2a208da99b7d6a3d6a32b48b20b,impl-k8s-backend,"from magnum.common import k8s_manifest name = wsme.wsattr(wtypes.text, readonly=True) labels = wsme.wsattr({wtypes.text: wtypes.text}, readonly=True) selector = wsme.wsattr({wtypes.text: wtypes.text}, readonly=True) def parse_manifest(self): # Set service name and port from its manifest # TODO(yuanying): retrive service name from definition_url if (hasattr(self, ""service_data"") and self.service_data is not None): manifest = k8s_manifest.parse(self.service_data) self.name = manifest[""id""] if ""port"" in manifest: self.port = manifest[""port""] if ""selector"" in manifest: self.selector = manifest[""selector""] if ""labels"" in manifest: self.labels = manifest[""labels""] service.parse_manifest()"," name = wsme.wsattr(wtypes.text, mandatory=True) labels = {wtypes.text: wtypes.text} selector = {wtypes.text: wtypes.text}",38,11
openstack%2Fcookbook-openstack-network~master~If875bdbecf9867a20afd5264a2fdb814a7729896,openstack/cookbook-openstack-network,master,If875bdbecf9867a20afd5264a2fdb814a7729896,Fix user_group configuration in lbaas_agent.ini.erb,MERGED,2015-01-09 10:50:47.000000000,2015-01-13 23:01:12.000000000,2015-01-13 23:01:10.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 7515}, {'_account_id': 8112}, {'_account_id': 8172}, {'_account_id': 12588}]","[{'number': 1, 'created': '2015-01-09 10:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/204fb34336ddbd0e0e078fb6a373a2a0d4d71fa2', 'message': 'Fix user_group configuration in lbaas_agent.ini.erb\n\nwhen using haproxy, user_group should be nobody on rhel,fedora and suse, and nogroup on debian\n\nChange-Id: If875bdbecf9867a20afd5264a2fdb814a7729896\nCloses-Bug:#1406224\n'}, {'number': 2, 'created': '2015-01-13 02:32:27.000000000', 'files': ['templates/default/lbaas_agent.ini.erb', 'spec/balancer-redhat_spec.rb', 'spec/balancer_spec.rb', 'CHANGELOG.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/31f6606586cc94660f4150e0781db4e75c29eec9', 'message': 'Fix user_group configuration in lbaas_agent.ini.erb\n\nwhen using haproxy, user_group should be nobody on rhel,fedora and suse, and nogroup on debian\n\nChange-Id: If875bdbecf9867a20afd5264a2fdb814a7729896\nCloses-Bug:#1406224\n'}]",8,146052,31f6606586cc94660f4150e0781db4e75c29eec9,12,6,2,7515,,,0,"Fix user_group configuration in lbaas_agent.ini.erb

when using haproxy, user_group should be nobody on rhel,fedora and suse, and nogroup on debian

Change-Id: If875bdbecf9867a20afd5264a2fdb814a7729896
Closes-Bug:#1406224
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/52/146052/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/default/lbaas_agent.ini.erb', 'spec/balancer-redhat_spec.rb', 'spec/balancer_spec.rb', 'CHANGELOG.md']",4,204fb34336ddbd0e0e078fb6a373a2a0d4d71fa2,bug/1406224,* Fix user_group configuration in lbaas_agent.ini.erb,,26,1
openstack%2Fnova-specs~master~I38960514e4cd914cb8acc3a2250c213b1d485e17,openstack/nova-specs,master,I38960514e4cd914cb8acc3a2250c213b1d485e17,Add the StorPool volume attach/detach proposal.,MERGED,2014-08-20 17:26:34.000000000,2015-01-13 23:00:06.000000000,2015-01-13 22:43:38.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 7730}, {'_account_id': 12988}]","[{'number': 1, 'created': '2014-08-20 17:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bf5911b5106de8d3ff07e5d422ea4baae845ecbd', 'message': 'Add the StorPool volume attach/detach proposal.\n\nChange-Id: I38960514e4cd914cb8acc3a2250c213b1d485e17\n'}, {'number': 2, 'created': '2014-11-04 01:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e652fb2fa5fb31697070810017ca2328a8e8411a', 'message': 'Add the StorPool volume attach/detach proposal.\n\nChange-Id: I38960514e4cd914cb8acc3a2250c213b1d485e17\n'}, {'number': 3, 'created': '2014-11-29 01:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/060d767578a59a7907d9638e682c5244e34788b0', 'message': 'Add the StorPool volume attach/detach proposal.\n\nChange-Id: I38960514e4cd914cb8acc3a2250c213b1d485e17\n'}, {'number': 4, 'created': '2015-01-13 22:04:15.000000000', 'files': ['specs/kilo/approved/libvirt-storpool-volume-attach.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3e08183550ada9633d8bc12d905a6d3b6c0c0378', 'message': 'Add the StorPool volume attach/detach proposal.\n\nChange-Id: I38960514e4cd914cb8acc3a2250c213b1d485e17\n'}]",5,115716,3e08183550ada9633d8bc12d905a6d3b6c0c0378,27,8,4,12988,,,0,"Add the StorPool volume attach/detach proposal.

Change-Id: I38960514e4cd914cb8acc3a2250c213b1d485e17
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/16/115716/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/libvirt-storpool-volume-attach.rst'],1,bf5911b5106de8d3ff07e5d422ea4baae845ecbd,bp/libvirt-storpool-volume-attach,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== StorPool Volume Attachment ========================================== https://blueprints.launchpad.net/nova/+spec/libvirt-storpool-volume-attach There are various Nova volume drivers providing access to Cinder volumes using specific types of storage, such as LVM, RBD, etc. The purpose of this blueprint is to add a driver supporting the volumes defined in a StorPool cluster. Problem description =================== StorPool is distributed data storage software running on standard x86 servers. StorPool aggregates the performance and capacity of all drives into a shared pool of storage distributed among the servers. Within this storage pool the user creates thin-provisioned volumes that are exposed to the clients as block devices. StorPool consists of two parts wrapped in one package - a server and a client. The StorPool server allows a hypervisor to act as a storage node, while the StorPool client allows a hypervisor node to access the storage pool and act as a compute node. In OpenStack terms the StorPool solution allows each hypervisor node to be both a storage and a compute node simultaneously. Proposed change =============== The proposed driver will make use of the StorPool API (based on JSON over HTTP) to attach and detach volumes defined in the StorPool cluster and already known to Cinder. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ The requests to attach or detach a volume will be passed on to the StorPool JSON-over-HTTP API. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Peter Penchev <openstack-dev@storpool.com> Other contributors: None Work Items ---------- * Write the nova.virt.libvirt.storpool driver to attach and detach volumes. * Write tests for the StorPool driver. * Provide a CI setup for the StorPool driver. Dependencies ============ The StorPool driver for Cinder for handling StorPool volumes: https://blueprints.launchpad.net/cinder/+spec/storpool-block-driver Testing ======= Since the test setup requires an operational StorPool cluster, the unit tests will mostly use mocking to simulate the operations. A separate continuous integration environment will be set up by StorPool and access to it will be provided for running automated CI tests. Documentation Impact ==================== Using the StorPool driver will be documented. References ========== The StorPool distributed storage software: http://storpool.com/ ",,128,0
openstack%2Fpython-keystoneclient~master~I7a19c0d83d88a3efd102e3054d5f2081496b105a,openstack/python-keystoneclient,master,I7a19c0d83d88a3efd102e3054d5f2081496b105a,Correct failures for check H904,ABANDONED,2015-01-11 18:55:04.000000000,2015-01-13 22:44:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2015-01-11 18:55:04.000000000', 'files': ['tox.ini', 'keystoneclient/common/cms.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/6bfe78e396ed8e1fdf6063d451b2b23a669b2971', 'message': 'Correct failures for check H904\n\nThe H904 ""Wrap long lines in parentheses instead of a backslash"" rule\nwas failing and ignored. Now it\'s enforced.\n\nChange-Id: I7a19c0d83d88a3efd102e3054d5f2081496b105a\n'}]",0,146343,6bfe78e396ed8e1fdf6063d451b2b23a669b2971,8,3,1,6486,,,0,"Correct failures for check H904

The H904 ""Wrap long lines in parentheses instead of a backslash"" rule
was failing and ignored. Now it's enforced.

Change-Id: I7a19c0d83d88a3efd102e3054d5f2081496b105a
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/43/146343/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'keystoneclient/common/cms.py']",2,6bfe78e396ed8e1fdf6063d451b2b23a669b2971,hacking, # $ openssl cms -verify -certfile not_exist_file -CAfile \ # noqa # not_exist_file -inform PEM -nosmimecap -nodetach \ # noqa, # $ openssl cms -verify -certfile not_exist_file -CAfile \ # not_exist_file -inform PEM -nosmimecap -nodetach \,3,4
openstack%2Fnova~master~I742f25dd643a7886a5fd5f66eee899ae5b17b439,openstack/nova,master,I742f25dd643a7886a5fd5f66eee899ae5b17b439,Log sqlalchemy exception message in migration.py,MERGED,2014-11-06 10:28:10.000000000,2015-01-13 22:40:57.000000000,2015-01-13 12:31:09.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 8574}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-06 10:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d15e46a0f73515b46e743358d549bda628f910db', 'message': 'Log sqlalchemy exception message in migration.py\n\nThe current code in migration.py suppress underlying exception message.\nIf Nova sql db configuation (eg. user, or permission) is incorrect, or\nthe query result is not as expected, nova-manage command will display\na confusing message, which may not help user to address the problem.\nNeed to log the exception message and stack trace, in order to improve\nservicability.\n\nChange-Id: I742f25dd643a7886a5fd5f66eee899ae5b17b439\n'}, {'number': 2, 'created': '2014-11-06 10:30:52.000000000', 'files': ['nova/db/sqlalchemy/migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ea4baade40fda88b01d9b00cc2a8d9bc91a6444a', 'message': 'Log sqlalchemy exception message in migration.py\n\nThe current code in migration.py suppress underlying exception message.\nIf Nova sql db configuration (eg. user, or permission) is incorrect, or\nthe query result is not as expected, nova-manage command will display\na confusing message, which may not help user to address the problem.\nNeed to log the exception message and stack trace, in order to improve\nservicability.\n\nChange-Id: I742f25dd643a7886a5fd5f66eee899ae5b17b439\n'}]",2,132990,ea4baade40fda88b01d9b00cc2a8d9bc91a6444a,24,11,2,8574,,,0,"Log sqlalchemy exception message in migration.py

The current code in migration.py suppress underlying exception message.
If Nova sql db configuration (eg. user, or permission) is incorrect, or
the query result is not as expected, nova-manage command will display
a confusing message, which may not help user to address the problem.
Need to log the exception message and stack trace, in order to improve
servicability.

Change-Id: I742f25dd643a7886a5fd5f66eee899ae5b17b439
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/132990/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/migration.py'],1,d15e46a0f73515b46e743358d549bda628f910db,nova-manage,from nova.openstack.common import log as loggingLOG = logging.getLogger(__name__) except versioning_exceptions.DatabaseNotControlledError as exc: LOG.exception(exc), except versioning_exceptions.DatabaseNotControlledError:,5,1
openstack%2Fpython-openstackclient~master~I9839f6be139d6a6a3f6bbf79957e218dd8e03fe3,openstack/python-openstackclient,master,I9839f6be139d6a6a3f6bbf79957e218dd8e03fe3,Rework role list v2 for --user and --project,MERGED,2015-01-10 00:59:29.000000000,2015-01-13 22:35:21.000000000,2015-01-13 22:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-10 00:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0959f812f9a659413a7a7044c9c3d6b11754b29f', 'message': ""Rework role list v2 for --user and --project\n\n`os user role list` does the same as v3's `os role list`.\nWe should rework v2's `role list` to basically call `os user role list`\nunder the covers.\n\nChange-Id: I9839f6be139d6a6a3f6bbf79957e218dd8e03fe3\n""}, {'number': 2, 'created': '2015-01-10 01:02:33.000000000', 'files': ['openstackclient/identity/v2_0/role.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ffb783215986318aded3eef0d97b603062f7c7ee', 'message': ""Rework role list v2 for --user and --project\n\n`os user role list` does the same as v3's `os role list`.\nWe should rework v2's `role list` to basically call `os user role list`\nunder the covers.\n\nCloses-Bug: #1409179\nChange-Id: I9839f6be139d6a6a3f6bbf79957e218dd8e03fe3\n""}]",4,146241,ffb783215986318aded3eef0d97b603062f7c7ee,19,5,2,6482,,,0,"Rework role list v2 for --user and --project

`os user role list` does the same as v3's `os role list`.
We should rework v2's `role list` to basically call `os user role list`
under the covers.

Closes-Bug: #1409179
Change-Id: I9839f6be139d6a6a3f6bbf79957e218dd8e03fe3
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/41/146241/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v2_0/role.py'],1,0959f812f9a659413a7a7044c9c3d6b11754b29f,consolidate_user_role_list," def get_parser(self, prog_name): parser = super(ListRole, self).get_parser(prog_name) parser.add_argument( '--project', metavar='<project>', help='Filter roles by <project> (name or ID)', ) parser.add_argument( '--user', metavar='<user>', help='Filter roles by <user> (name or ID)', ) return parser identity_client = self.app.client_manager.identity auth_ref = self.app.client_manager.auth_ref # No user or project specified, list all roles in the system if not parsed_args.user and not parsed_args.project: columns = ('ID', 'Name') data = identity_client.roles.list() elif parsed_args.user and parsed_args.project: user = utils.find_resource( identity_client.users, parsed_args.user, ) project = utils.find_resource( identity_client.projects, parsed_args.project, ) data = identity_client.roles.roles_for_user(user.id, project.id) elif parsed_args.user: user = utils.find_resource( identity_client.users, parsed_args.user, ) if self.app.client_manager.auth_ref: project = utils.find_resource( identity_client.projects, auth_ref.project_id ) else: msg = _(""Project must be specified"") raise exceptions.CommandError(msg) data = identity_client.roles.roles_for_user(user.id, project.id) elif parsed_args.project: project = utils.find_resource( identity_client.projects, parsed_args.project, ) if self.app.client_manager.auth_ref: user = utils.find_resource( identity_client.users, auth_ref.user_id ) else: msg = _(""User must be specified"") raise exceptions.CommandError(msg) data = identity_client.roles.roles_for_user(user.id, project.id) if parsed_args.user or parsed_args.project: columns = ('ID', 'Name', 'Project', 'User') for user_role in data: user_role.user = user.name user_role.project = project.name "," columns = ('ID', 'Name') data = self.app.client_manager.identity.roles.list()",67,2
openstack%2Fpython-solumclient~master~I11a37da3c5023284a5b4e9ece003cab7ed507790,openstack/python-solumclient,master,I11a37da3c5023284a5b4e9ece003cab7ed507790,Rename 'app' to 'plan' in CLI,MERGED,2014-11-21 23:01:55.000000000,2015-01-13 22:34:49.000000000,2015-01-13 22:34:48.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}]","[{'number': 1, 'created': '2014-11-21 23:01:55.000000000', 'files': ['solumclient/tests/test_solum.py', 'solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/d2dc8fbf9d876794ae472178b0bb4b089373165a', 'message': ""Rename 'app' to 'plan' in CLI\n\nThe use of the name 'app' to refer to a Solum plan resource\nexists not entirely in the cli in this client; not even the\nclient code uses the name.\n\nThis is entirely a cosmetic change to solum.py and of its\ncorresponding test_solum.py.\n\nChange-Id: I11a37da3c5023284a5b4e9ece003cab7ed507790\n""}]",1,136518,d2dc8fbf9d876794ae472178b0bb4b089373165a,8,4,1,1375,,,0,"Rename 'app' to 'plan' in CLI

The use of the name 'app' to refer to a Solum plan resource
exists not entirely in the cli in this client; not even the
client code uses the name.

This is entirely a cosmetic change to solum.py and of its
corresponding test_solum.py.

Change-Id: I11a37da3c5023284a5b4e9ece003cab7ed507790
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/18/136518/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/tests/test_solum.py', 'solumclient/solum.py']",2,d2dc8fbf9d876794ae472178b0bb4b089373165a,rename-app-to-plan,"* plan create --repo=""repo_url"" [--build=no] plan_name * plan delete plan_name * plan list * plan show plan_idclass PlanCommands(cli_utils.CommandsBase): """"""Plan targets."""""" """"""Create a plan."""""" help=""A yaml file that defines a plan,"" """"""Delete a plan."""""" """"""Show a plan's resource."""""" """"""List all plans."""""" 'plan': PlanCommands,","* app create --repo=""repo_url"" [--build=no] plan_name * app delete plan_name * app list * app show plan_idclass AppCommands(cli_utils.CommandsBase): """"""Application targets."""""" """"""Create an application."""""" help=""A yaml file that defines an app,"" """"""Delete an application."""""" """"""Show an application's resource."""""" """"""List all applications."""""" 'app': AppCommands,",50,49
openstack%2Fdevstack~master~I2a0b09c34fac5f63a5cdbbe05761a0857f243465,openstack/devstack,master,I2a0b09c34fac5f63a5cdbbe05761a0857f243465,Change default nova service name in cinder.conf,MERGED,2015-01-08 17:47:47.000000000,2015-01-13 22:29:32.000000000,2015-01-13 22:29:31.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 970}, {'_account_id': 2243}, {'_account_id': 7118}, {'_account_id': 7219}, {'_account_id': 7715}, {'_account_id': 8074}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-08 17:47:47.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/afc1423e70074762e5c8d74b7295b9e55f91a44c', 'message': 'Change default nova service name in cinder.conf\n\nIn cinder the config options nova_catalog_info and\nnova_catalog_admin_info define values to be matched when searching for\nthe correct compute service in the catalog.\n\nThe commit 5ad15c040fdc115bca9efb1c952279988a2a48b3 in the cinder\nproject has changed these defaults.\n\nThis commit sets the options in cinder.conf to the values set by\ndevstack.\n\nChange-Id: I2a0b09c34fac5f63a5cdbbe05761a0857f243465\nCloses-Bug: #1408734\n'}]",4,145858,afc1423e70074762e5c8d74b7295b9e55f91a44c,19,9,1,7219,,,0,"Change default nova service name in cinder.conf

In cinder the config options nova_catalog_info and
nova_catalog_admin_info define values to be matched when searching for
the correct compute service in the catalog.

The commit 5ad15c040fdc115bca9efb1c952279988a2a48b3 in the cinder
project has changed these defaults.

This commit sets the options in cinder.conf to the values set by
devstack.

Change-Id: I2a0b09c34fac5f63a5cdbbe05761a0857f243465
Closes-Bug: #1408734
",git fetch https://review.opendev.org/openstack/devstack refs/changes/58/145858/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,afc1423e70074762e5c8d74b7295b9e55f91a44c,bug/1408734,# Change the default nova_catalog_info and nova_catalog_admin_info values in # cinder so that the service name cinder is searching for matches that set for # nova in keystone. CINDER_NOVA_CATALOG_INFO=${CINDER_NOVA_CATALOG_INFO:-compute:nova:publicURL} CINDER_NOVA_CATALOG_ADMIN_INFO=${CINDER_NOVA_CATALOG_ADMIN_INFO:-compute:nova:adminURL} iniset $CINDER_CONF DEFAULT nova_catalog_info $CINDER_NOVA_CATALOG_INFO iniset $CINDER_CONF DEFAULT nova_catalog_admin_info $CINDER_NOVA_CATALOG_ADMIN_INFO ,,9,0
openstack%2Fdesignate~master~I7e93ab53966cf71d7c8ced38fce55f76aec12e71,openstack/designate,master,I7e93ab53966cf71d7c8ced38fce55f76aec12e71,Migrate Server table,MERGED,2014-11-21 17:59:17.000000000,2015-01-13 22:24:20.000000000,2015-01-13 22:24:19.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-11-21 17:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bee56a3031cb61bfa82211e3e37eab652f8aa136', 'message': '  # Pool Server Storage - WIP\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n'}, {'number': 2, 'created': '2014-12-04 21:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d3d88f68a915c2283aaece0f1f95587cc5149054', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 3, 'created': '2014-12-08 19:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/68d92ff8cd821ce5901197cf054e53274d64a1ad', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 4, 'created': '2014-12-09 17:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/570df43268779654c84cfb4cf6635f2b5f5c3c1a', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 5, 'created': '2014-12-10 15:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/46ab546838886129ca4ed611f3af993cb0e48f6c', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 6, 'created': '2014-12-17 04:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4bb50c84d94a68b36039ee52e9609e81a26402b5', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 7, 'created': '2014-12-17 19:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ee29d7a16fa8b544df692c48a32e2e76551ac4da', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 8, 'created': '2015-01-02 18:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8d1b17c1df490fbfa7a875659f3633ce7988916e', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 9, 'created': '2015-01-06 15:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b79b72213d22c1127d1884a13df77957e17653aa', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}, {'number': 10, 'created': '2015-01-08 14:34:47.000000000', 'files': ['designate/tests/__init__.py', 'designate/resources/schemas/v2/pool.json', 'designate/api/v2/views/pools.py', 'designate/tests/test_storage/__init__.py', 'designate/central/service.py', 'designate/api/v1/domains.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/storage/base.py', 'designate/tests/test_central/test_service.py', 'designate/tests/test_api/test_v2/test_nameservers.py', 'designate/storage/impl_sqlalchemy/migrate_repo/versions/049_migrate_servers.py', 'designate/storage/impl_sqlalchemy/__init__.py', 'designate/tests/test_api/test_v2/test_zones.py', 'designate/api/v1/servers.py', 'designate/api/v2/views/nameservers.py', 'designate/tests/test_api/test_v1/test_domains.py', 'designate/backend/impl_ipa/__init__.py', 'designate/tests/test_api/test_v2/test_floatingips.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/3ab3853c2fd5715a4e2fc4ea61c4bd1d5351450a', 'message': ""  Migrate Server table\n\n  This migrates the data in the server table to\n  the pool_attributes table. In addition, this\n  makes all the changes for the code to use the\n  nameserver pool_attribute in the default pool\n  instead of a server.\n\n  Paritally-implements: blueprint server-pools-storage\n\n  What's left to do:\n  - Remove the old server table and rest of the\n    server api code\n\nChange-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71\n""}]",74,136440,3ab3853c2fd5715a4e2fc4ea61c4bd1d5351450a,47,6,10,8130,,,0,"  Migrate Server table

  This migrates the data in the server table to
  the pool_attributes table. In addition, this
  makes all the changes for the code to use the
  nameserver pool_attribute in the default pool
  instead of a server.

  Paritally-implements: blueprint server-pools-storage

  What's left to do:
  - Remove the old server table and rest of the
    server api code

Change-Id: I7e93ab53966cf71d7c8ced38fce55f76aec12e71
",git fetch https://review.opendev.org/openstack/designate refs/changes/40/136440/3 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/__init__.py', 'designate/storage/impl_sqlalchemy/migrate_repo/versions/049_migrate_servers.py', 'designate/central/service.py', 'designate/api/v1/servers.py', 'designate/tests/test_api/test_v1/test_servers.py', 'designate/storage/base.py', 'designate/tests/test_central/test_service.py']",7,bee56a3031cb61bfa82211e3e37eab652f8aa136,bp/server-pools-storage," pool_attribute = self.create_pool_attribute(fixture=1) LOG.debug(""The pool_id is %r "" % pool_attribute.pool_id) def test_delete_last_nameserver(self): # Create a pool_attribute that is a nameserver pool_attribute1 = self.create_nameserver(fixture=0) # Create a second one pool_attribute2 = self.create_nameserver(fixture=1) # Delete the first nameserver self.central_service.delete_pool_attribute(self.admin_context, pool_attribute1['id']) # Try to fetch the blacklist to verify an exception is raised with testtools.ExpectedException(exceptions.PoolAttributeNotFound): self.central_service.get_pool_attribute(self.admin_context, pool_attribute1['id']) # Verify that we cannot delete the last remaining nameserver with testtools.ExpectedException( exceptions.LastServerDeleteNotAllowed): self.central_service.delete_pool_attribute(self.admin_context, pool_attribute2['id'])", pool_attribute = self.create_pool_attribute(),317,46
openstack%2Fpython-ceilometerclient~master~I70ac868c35b2e8f07917657a05e0cd1141e687ab,openstack/python-ceilometerclient,master,I70ac868c35b2e8f07917657a05e0cd1141e687ab,Update hacking to global requirements,MERGED,2015-01-12 10:56:18.000000000,2015-01-13 22:18:12.000000000,2015-01-13 22:18:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-12 10:56:18.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/6ae01277636c941e2782f8c4d6c90cdc66356c45', 'message': 'Update hacking to global requirements\n\nChange-Id: I70ac868c35b2e8f07917657a05e0cd1141e687ab\n'}]",0,146415,6ae01277636c941e2782f8c4d6c90cdc66356c45,19,9,1,3012,,,0,"Update hacking to global requirements

Change-Id: I70ac868c35b2e8f07917657a05e0cd1141e687ab
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/15/146415/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,6ae01277636c941e2782f8c4d6c90cdc66356c45,fix-pep8-issues,"# H105 Don't use author tags ignore = H405,H904,H105","ignore = H405,H904",3,2
openstack%2Fglance~master~I75fdc1c5c6b4c5d38abc8caf79db7669d3661899,openstack/glance,master,I75fdc1c5c6b4c5d38abc8caf79db7669d3661899,Fix SQL comments. Use valid SQL when commenting,ABANDONED,2015-01-13 22:03:01.000000000,2015-01-13 22:04:17.000000000,,[{'_account_id': 12000}],"[{'number': 1, 'created': '2015-01-13 22:03:01.000000000', 'files': ['glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/037_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql'], 'web_link': 'https://opendev.org/openstack/glance/commit/9a372359015fbe70814c9a262f79c2c46cdf4e60', 'message': 'Fix SQL comments. Use valid SQL when commenting\n\nChange-Id: I75fdc1c5c6b4c5d38abc8caf79db7669d3661899\n'}]",0,146991,9a372359015fbe70814c9a262f79c2c46cdf4e60,3,1,1,12000,,,0,"Fix SQL comments. Use valid SQL when commenting

Change-Id: I75fdc1c5c6b4c5d38abc8caf79db7669d3661899
",git fetch https://review.opendev.org/openstack/glance refs/changes/91/146991/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/037_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql', 'glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql']",8,9a372359015fbe70814c9a262f79c2c46cdf4e60,fix-sql-migrations,-- Move type column from base images table -- to be records in image_properties table-- Make changes to the base images table,/* Move type column from base images table * to be records in image_properties table *//* Make changes to the base images table */,19,29
openstack%2Fdesignate~master~Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79,openstack/designate,master,Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79,Imported Translations from Transifex,MERGED,2015-01-10 06:09:22.000000000,2015-01-13 22:02:17.000000000,2015-01-13 22:02:15.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2015-01-10 06:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/baf2a25dd649b8641c45e987bc01b1621d32bad3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79\n'}, {'number': 2, 'created': '2015-01-11 06:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4ddc54a3ed8e46eee585b9d9ddb4e3edfd6aab7d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79\n'}, {'number': 3, 'created': '2015-01-12 06:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/edf57eb1d3c0846637509d1aaa92ee7f777727b1', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79\n'}, {'number': 4, 'created': '2015-01-13 06:09:14.000000000', 'files': ['designate/locale/designate-log-warning.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-warning.po', 'designate/locale/designate-log-info.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-info.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/22da4fb102d04c4a7419609e5705a7a212b8c19f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79\n'}]",0,146267,22da4fb102d04c4a7419609e5705a7a212b8c19f,15,3,4,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ifc9e7d21e0f0f562fb84a69332a795a7f4110c79
",git fetch https://review.opendev.org/openstack/designate refs/changes/67/146267/4 && git format-patch -1 --stdout FETCH_HEAD,"['designate/locale/designate-log-warning.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-warning.po', 'designate/locale/designate-log-info.pot', 'designate/locale/fr/LC_MESSAGES/designate-log-info.po']",4,baf2a25dd649b8641c45e987bc01b1621d32bad3,transifex/translations,"# Copyright (C) 2015 ORGANIZATION""POT-Creation-Date: 2015-01-10 06:09+0000\n"" ""PO-Revision-Date: 2015-01-09 19:02+0000\n""#: designate/central/rpcapi.py:74#: designate/central/rpcapi.py:81#: designate/central/rpcapi.py:86#: designate/central/rpcapi.py:92#: designate/central/rpcapi.py:98#: designate/central/rpcapi.py:104#: designate/central/rpcapi.py:110#: designate/central/rpcapi.py:117#: designate/central/rpcapi.py:122#: designate/central/rpcapi.py:127#: designate/central/rpcapi.py:133#: designate/central/rpcapi.py:138#: designate/central/rpcapi.py:144#: designate/central/rpcapi.py:148#: designate/central/rpcapi.py:152#: designate/central/rpcapi.py:158#: designate/central/rpcapi.py:162#: designate/central/rpcapi.py:166#: designate/central/rpcapi.py:171#: designate/central/rpcapi.py:175#: designate/central/rpcapi.py:179#: designate/central/rpcapi.py:186#: designate/central/rpcapi.py:192#: designate/central/rpcapi.py:196#: designate/central/rpcapi.py:201#: designate/central/rpcapi.py:205#: designate/central/rpcapi.py:209#: designate/central/rpcapi.py:214#: designate/central/rpcapi.py:219#: designate/central/rpcapi.py:225#: designate/central/rpcapi.py:229#: designate/central/rpcapi.py:233#: designate/central/rpcapi.py:238#: designate/central/rpcapi.py:243#: designate/central/rpcapi.py:249#: designate/central/rpcapi.py:256#: designate/central/rpcapi.py:260#: designate/central/rpcapi.py:267#: designate/central/rpcapi.py:274#: designate/central/rpcapi.py:281#: designate/central/rpcapi.py:289#: designate/central/rpcapi.py:297#: designate/central/rpcapi.py:303#: designate/central/rpcapi.py:307#: designate/central/rpcapi.py:314#: designate/central/rpcapi.py:322#: designate/central/rpcapi.py:327#: designate/central/rpcapi.py:332#: designate/central/rpcapi.py:336#: designate/central/rpcapi.py:340#: designate/central/rpcapi.py:347#: designate/central/rpcapi.py:351#: designate/central/rpcapi.py:356#: designate/central/rpcapi.py:363#: designate/central/rpcapi.py:368#: designate/central/rpcapi.py:374#: designate/central/rpcapi.py:380#: designate/central/rpcapi.py:384#: designate/central/rpcapi.py:389#: designate/central/rpcapi.py:395#: designate/central/rpcapi.py:401#: designate/central/rpcapi.py:408#: designate/central/rpcapi.py:413#: designate/central/rpcapi.py:418#: designate/central/rpcapi.py:423#: designate/central/rpcapi.py:429#: designate/central/rpcapi.py:436#: designate/central/rpcapi.py:445#: designate/central/rpcapi.py:455#: designate/central/rpcapi.py:464#: designate/central/rpcapi.py:472#: designate/central/rpcapi.py:480#: designate/central/rpcapi.py:489#: designate/central/rpcapi.py:497#: designate/central/rpcapi.py:507#: designate/central/rpcapi.py:515#: designate/central/rpcapi.py:523#: designate/central/rpcapi.py:531#: designate/central/service.py:1774#: designate/central/service.py:2120#: designate/mdns/notify.py:175#, python-format msgid ""create_domain: Calling pool manager's create_domain for %(domain)s""#: designate/pool_manager/rpcapi.py:68 #, python-format msgid ""delete_domain: Calling pool manager's delete_domain for %(domain)s""#: designate/pool_manager/rpcapi.py:74 #, python-format msgid ""update_domain: Calling pool manager's update_domain for %(domain)s""#: designate/pool_manager/rpcapi.py:81 #, python-format msgid ""update_status: Calling pool manager's update_status for %(domain)s"" msgstr """" #: designate/pool_manager/service.py:61 #, python-format msgid ""Domain %(domain)s is managed by this pool. Executing."" msgstr """" #: designate/pool_manager/service.py:66 #, python-format msgid ""Domain %(domain)s is not managed by this pool. Skipping."" msgstr """" #: designate/pool_manager/service.py:130 msgid ""Starting periodic recovery timer."" msgstr """" #: designate/pool_manager/service.py:135 msgid ""Starting periodic sync timer."" msgstr """" #: designate/pool_manager/service.py:145 msgid ""Stopping periodic sync timer."" msgstr """" #: designate/pool_manager/service.py:146 msgid ""Stopping periodic recovery timer."" msgstr """" #: designate/pool_manager/service.py:178 designate/pool_manager/service.py:348 #, python-format msgid ""Created domain %(domain)s on server %(server)s."" msgstr """" #: designate/pool_manager/service.py:221 designate/pool_manager/service.py:379 #, python-format msgid ""Deleted domain %(domain)s from server %(server)s."" msgstr """" #: designate/pool_manager/service.py:237 #, python-format msgid ""Consensus reached for deleting domain %(domain)s"" msgstr """" #: designate/pool_manager/service.py:282 #, python-format msgid """" ""For domain %(domain)s on server %(server)s the consensus serial is "" ""%(consensus_serial)s.""","# Copyright (C) 2014 ORGANIZATION""POT-Creation-Date: 2014-12-16 06:16+0000\n"" ""PO-Revision-Date: 2014-12-16 00:40+0000\n""#: designate/central/rpcapi.py:75#: designate/central/rpcapi.py:82#: designate/central/rpcapi.py:87#: designate/central/rpcapi.py:93#: designate/central/rpcapi.py:99#: designate/central/rpcapi.py:105#: designate/central/rpcapi.py:111#: designate/central/rpcapi.py:118#: designate/central/rpcapi.py:123#: designate/central/rpcapi.py:128#: designate/central/rpcapi.py:134#: designate/central/rpcapi.py:139#: designate/central/rpcapi.py:145#: designate/central/rpcapi.py:149#: designate/central/rpcapi.py:153#: designate/central/rpcapi.py:159#: designate/central/rpcapi.py:163#: designate/central/rpcapi.py:167#: designate/central/rpcapi.py:172#: designate/central/rpcapi.py:176#: designate/central/rpcapi.py:180#: designate/central/rpcapi.py:187#: designate/central/rpcapi.py:193#: designate/central/rpcapi.py:197#: designate/central/rpcapi.py:202#: designate/central/rpcapi.py:206#: designate/central/rpcapi.py:210#: designate/central/rpcapi.py:215#: designate/central/rpcapi.py:220#: designate/central/rpcapi.py:226#: designate/central/rpcapi.py:230#: designate/central/rpcapi.py:234#: designate/central/rpcapi.py:239#: designate/central/rpcapi.py:244#: designate/central/rpcapi.py:250#: designate/central/rpcapi.py:257#: designate/central/rpcapi.py:261#: designate/central/rpcapi.py:268#: designate/central/rpcapi.py:275#: designate/central/rpcapi.py:282#: designate/central/rpcapi.py:290#: designate/central/rpcapi.py:298#: designate/central/rpcapi.py:304#: designate/central/rpcapi.py:308#: designate/central/rpcapi.py:315#: designate/central/rpcapi.py:323#: designate/central/rpcapi.py:328#: designate/central/rpcapi.py:333#: designate/central/rpcapi.py:337#: designate/central/rpcapi.py:341#: designate/central/rpcapi.py:348#: designate/central/rpcapi.py:352#: designate/central/rpcapi.py:357#: designate/central/rpcapi.py:364#: designate/central/rpcapi.py:369#: designate/central/rpcapi.py:375#: designate/central/rpcapi.py:381#: designate/central/rpcapi.py:385#: designate/central/rpcapi.py:390#: designate/central/rpcapi.py:396#: designate/central/rpcapi.py:402#: designate/central/rpcapi.py:409#: designate/central/rpcapi.py:414#: designate/central/rpcapi.py:419#: designate/central/rpcapi.py:424#: designate/central/rpcapi.py:430#: designate/central/rpcapi.py:437#: designate/central/rpcapi.py:446#: designate/central/rpcapi.py:456#: designate/central/rpcapi.py:465#: designate/central/rpcapi.py:473#: designate/central/rpcapi.py:481#: designate/central/rpcapi.py:490#: designate/central/rpcapi.py:498#: designate/central/rpcapi.py:508#: designate/central/rpcapi.py:516#: designate/central/rpcapi.py:524#: designate/central/rpcapi.py:532#: designate/central/service.py:1775#: designate/central/service.py:2121#: designate/mdns/notify.py:184msgid ""create_domain: Calling pool manager's create_domain.""#: designate/pool_manager/rpcapi.py:67 msgid ""delete_domain: Calling pool manager's delete_domain.""#: designate/pool_manager/rpcapi.py:72 msgid ""update_domain: Calling pool manager's update_domain.""#: designate/pool_manager/rpcapi.py:78 msgid ""update_status: Calling pool manager's update_status.""",336,198
openstack%2Fdevstack-gate~master~Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881,openstack/devstack-gate,master,Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881,testr last requires sudo,MERGED,2015-01-12 22:36:46.000000000,2015-01-13 21:51:42.000000000,2015-01-13 21:51:40.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-01-12 22:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/1b29c0399000d56c317d6cd29915f2084eb871fd', 'message': 'testr last requires sudo\n\n736d1c987be90fd97ec55f15b6b7560e1f295c29 breaks testrepository.subunit.gz\n and testr_results.html.gz\n\nBasic testing shows that running the command with sudo resolves the issue.\n\nChange-Id: Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881\n'}, {'number': 2, 'created': '2015-01-12 22:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/42e5f41aa4d23cf0a523d1a5001b4d169efa6814', 'message': 'testr last requires sudo\n\n736d1c987be90fd97ec55f15b6b7560e1f295c29 breaks testrepository.subunit.gz\n and testr_results.html.gz\n\nBasic testing shows that running the command with sudo resolves the issue.\nWithout sudo, this is the error message run using jenkins user:\n""local variable \'run_subunit_content\' referenced before assignment""\n\nChange-Id: Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881\n'}, {'number': 3, 'created': '2015-01-12 23:46:04.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/80fe49c3238cb8ddb274b984ddf4936294475cf4', 'message': 'testr last requires sudo\n\n736d1c987be90fd97ec55f15b6b7560e1f295c29 breaks testrepository.subunit.gz\n and testr_results.html.gz\n\nBasic testing shows that running the command with sudo resolves the issue.\nWithout sudo, this is the error message run using jenkins user:\n""local variable \'run_subunit_content\' referenced before assignment""\n\nChange-Id: Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881\n'}]",1,146666,80fe49c3238cb8ddb274b984ddf4936294475cf4,13,4,3,9624,,,0,"testr last requires sudo

736d1c987be90fd97ec55f15b6b7560e1f295c29 breaks testrepository.subunit.gz
 and testr_results.html.gz

Basic testing shows that running the command with sudo resolves the issue.
Without sudo, this is the error message run using jenkins user:
""local variable 'run_subunit_content' referenced before assignment""

Change-Id: Ia2f10cb2d09aa5db3957e30f9a7c25cc40c54881
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/66/146666/2 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,1b29c0399000d56c317d6cd29915f2084eb871fd,fixTestr, sudo testr last --subunit > $WORKSPACE/testrepository.subunit sudo testr last --subunit > $WORKSPACE/testrepository.subunit, testr last --subunit > $WORKSPACE/testrepository.subunit testr last --subunit > $WORKSPACE/testrepository.subunit,2,2
openstack%2Fdevstack~master~Ic5304893f4c97c50e7a2f29ad5cd77dba3d5a9dd,openstack/devstack,master,Ic5304893f4c97c50e7a2f29ad5cd77dba3d5a9dd,wget less verbose,MERGED,2015-01-13 13:03:55.000000000,2015-01-13 21:49:13.000000000,2015-01-13 21:49:11.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-13 13:03:55.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/devstack/commit/057d6ae2255f8895baada8d00767ffa71c8615ac', 'message': 'wget less verbose\n\nwget is too verbose in devstack logs [1] on image download.\n\nChanging the progress bar style to giga, in order\nto be less verbose.\n\nhttp://logs.openstack.org/73/146573/2/check/\ncheck-tempest-dsvm-full-juno/41ba988/logs/devstacklog.txt.gz#_2015-01-13_11_34_15_330\n\nChange-Id: Ic5304893f4c97c50e7a2f29ad5cd77dba3d5a9dd\n'}]",0,146848,057d6ae2255f8895baada8d00767ffa71c8615ac,9,5,1,5803,,,0,"wget less verbose

wget is too verbose in devstack logs [1] on image download.

Changing the progress bar style to giga, in order
to be less verbose.

http://logs.openstack.org/73/146573/2/check/
check-tempest-dsvm-full-juno/41ba988/logs/devstacklog.txt.gz#_2015-01-13_11_34_15_330

Change-Id: Ic5304893f4c97c50e7a2f29ad5cd77dba3d5a9dd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/48/146848/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,057d6ae2255f8895baada8d00767ffa71c8615ac,wget-verbose, wget --progress=dot:giga -c $image_url -O $FILES/$image_fname wget --progress=dot:giga -c $flat_url -O $FILES/$flat_fname, wget -c $image_url -O $FILES/$image_fname wget -c $flat_url -O $FILES/$flat_fname,2,2
openstack%2Fpython-solumclient~master~I5ad5ae108dd39888ced908110af1171607155656,openstack/python-solumclient,master,I5ad5ae108dd39888ced908110af1171607155656,Rename 'app' to 'plan' in CLI,MERGED,2015-01-12 18:51:22.000000000,2015-01-13 21:31:26.000000000,2015-01-13 21:31:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 6662}, {'_account_id': 9095}]","[{'number': 1, 'created': '2015-01-12 18:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/bf0548dc59b037c2ca9185dd796d13e8f9ebb220', 'message': ""Rename 'app' to 'plan' in CLI\n\nThe use of the name 'app' to refer to a Solum plan resource\nexists not entirely in the cli in this client; not even the\nclient code uses the name.\n\nThis is entirely a cosmetic change to solum.py and of its\ncorresponding test_solum.py.\n\nChange-Id: I5ad5ae108dd39888ced908110af1171607155656\n""}, {'number': 2, 'created': '2015-01-12 18:52:37.000000000', 'files': ['solumclient/tests/test_solum.py', 'solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/a9a0bd53a80a7f6c97025365f7f10fab8b217cba', 'message': ""Rename 'app' to 'plan' in CLI\n\nThe use of the name 'app' to refer to a Solum plan resource\nexists now entirely in the cli in this client; not even the\nclient code uses the name.\n\nThis is entirely a cosmetic change to solum.py and of its\ncorresponding test_solum.py.\n\nChange-Id: I5ad5ae108dd39888ced908110af1171607155656\n""}]",0,146607,a9a0bd53a80a7f6c97025365f7f10fab8b217cba,10,5,2,1375,,,0,"Rename 'app' to 'plan' in CLI

The use of the name 'app' to refer to a Solum plan resource
exists now entirely in the cli in this client; not even the
client code uses the name.

This is entirely a cosmetic change to solum.py and of its
corresponding test_solum.py.

Change-Id: I5ad5ae108dd39888ced908110af1171607155656
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/07/146607/2 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/tests/test_solum.py', 'solumclient/solum.py']",2,bf0548dc59b037c2ca9185dd796d13e8f9ebb220,rename-app-to-plan,"* plan create --repo=""repo_url"" [--build=no] plan_name * plan delete plan_name * plan list * plan show plan_idclass PlanCommands(cli_utils.CommandsBase): """"""Plan targets."""""" """"""Create a plan."""""" help=""A yaml file that defines a plan,"" """"""Delete a plan."""""" """"""Show a plan's resource."""""" """"""List all plans."""""" 'plan': PlanCommands,","* app create --repo=""repo_url"" [--build=no] plan_name * app delete plan_name * app list * app show plan_idclass AppCommands(cli_utils.CommandsBase): """"""Application targets."""""" """"""Create an application."""""" help=""A yaml file that defines an app,"" """"""Delete an application."""""" """"""Show an application's resource."""""" """"""List all applications."""""" 'app': AppCommands,",50,49
openstack%2Fironic~master~Ide764f3936444449f82deec29d88b7087eb426cb,openstack/ironic,master,Ide764f3936444449f82deec29d88b7087eb426cb,Updated from global requirements,MERGED,2015-01-13 00:03:45.000000000,2015-01-13 21:30:33.000000000,2015-01-13 21:30:31.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-13 00:03:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f5b29d276b79ee96054bc15b4026c9a2af25ad04', 'message': 'Updated from global requirements\n\nChange-Id: Ide764f3936444449f82deec29d88b7087eb426cb\n'}]",0,146692,f5b29d276b79ee96054bc15b4026c9a2af25ad04,11,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ide764f3936444449f82deec29d88b7087eb426cb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/92/146692/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f5b29d276b79ee96054bc15b4026c9a2af25ad04,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Ftelemetry-specs~master~I5ec378741bc2fff9cfe65eeef255333f45ca9211,openstack/telemetry-specs,master,I5ec378741bc2fff9cfe65eeef255333f45ca9211,Repackage the ceilometer and the ceilometerclient packages,ABANDONED,2014-08-29 10:58:23.000000000,2015-01-13 21:30:27.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 11564}, {'_account_id': 12193}]","[{'number': 1, 'created': '2014-08-29 10:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/38417d2ad894c78007b883d410b1ad6948c5795b', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis blueprint can solve this problem and realize pure client\ninstallations for ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}, {'number': 2, 'created': '2014-08-29 11:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/a9a9af66a4bd2f249aee32dd78c7b08405a6bd02', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis specification can solve this problem and realize pure client installations\nfor ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}, {'number': 3, 'created': '2014-08-29 11:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/c51b5baa3d6b2dd3b460ec299205173ae0d89f7b', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis specification can solve this problem and realize pure client\ninstallations for ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}, {'number': 4, 'created': '2014-08-29 11:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/e4bf9965f0cad1b24a286d50e2b5c5a471c62d1f', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis specification can solve this problem and realize pure client\ninstallations for ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}, {'number': 5, 'created': '2014-09-09 09:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/5fd41292b73c7a5f942251fed591809c42a67a5d', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis specification can solve this problem and realize pure client\ninstallations for ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}, {'number': 6, 'created': '2014-09-26 04:57:15.000000000', 'files': ['specs/juno/repackaging-ceilometerclient.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/744626b84845ea7334a58e5fbe5b76af2b4bb989', 'message': 'Repackage the ceilometer and the ceilometerclient packages\n\nThe swift middleware (swift_middleware.py) is included the ceilometer\npackage so Cloud Deployers for the swift middleware need to install\nthe package on Proxy Nodes of swift in addition to the ceilometerclient\npackage.\nThis specification can solve this problem and realize pure client\ninstallations for ceilometerclient.\n\nChange-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211\nImplements: blueprint repackaging-ceilometerclient\n'}]",4,117745,744626b84845ea7334a58e5fbe5b76af2b4bb989,28,5,6,12193,,,0,"Repackage the ceilometer and the ceilometerclient packages

The swift middleware (swift_middleware.py) is included the ceilometer
package so Cloud Deployers for the swift middleware need to install
the package on Proxy Nodes of swift in addition to the ceilometerclient
package.
This specification can solve this problem and realize pure client
installations for ceilometerclient.

Change-Id: I5ec378741bc2fff9cfe65eeef255333f45ca9211
Implements: blueprint repackaging-ceilometerclient
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/45/117745/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/repackaging-ceilometerclient.rst'],1,38417d2ad894c78007b883d410b1ad6948c5795b,bp/repackaging-ceilometerclient,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Repackage Ceilometer and Ceilometer Client ========================================== https://blueprints.launchpad.net/ceilometer/+spec/repackaging-ceilometerclient Repackage the ceilometer and the ceilometerclient packages so that pure client installations for ceilometerclient can be realized. Problem description =================== The swift middleware (swift_middleware.py) is included the ceilometer package so Cloud Deployers for the swift middleware need to install the package on Proxy Nodes of swift in addition to the ceilometerclient package. And the ceilometer package has dependencies with the following client packages of OpenStack components. For half part of the above packages are not necessary to install on Proxy Nodes. - python-ceilometerclient - python-glanceclient - python-keystoneclient - python-neutronclient - python-novaclient - python-swiftclient This problem leads to increasing operational costs on the Proxy Nodes because Cloud Operators must check and apply security patches for unused packages. Proposed change =============== Repackage the ceilometer and the ceilometerclient packages based on the following steps. (1) Move the swift middleware from the ceilometer package to the ceilometerclient package. (2) Remove the following dependencies which the swift middleware has. (a) ceilometer.openstack.common.context (b) ceilometer.openstack.common.log (c) ceilometer.openstack.common.timeutils (d) ceilometer.pipeline (e) ceilometer.sample (f) ceilometer.service As for the (d), (e) and (f), rewrite the swift middleware using oslo.messaging notifications so that the dependencies can be removed. The dependencies for (a), (b) and (c) should be removed after the rewriting. (3) Get the transport information of the swift middleware from proxy-server.conf instead of ceilometer.conf. Alternatives ------------ As discussed in the mail thread, it's better to move the swift middleware to an own repository in order to realize pure client installations. I think this is a trade-off problem b/w the concept and conveniences of Cloud Deployers so difficult to decide it. Therefore I split the trade-off problem from this spec. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Pipeline impact --------------- None. Other end user impact --------------------- None. Performance/Scalability Impacts ------------------------------- None. Other deployer impact --------------------- All Cloud Deployers don't need to install the ceilometer package on the Proxy Nodes of swift. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: osanai-hisashi Other contributors: None. Ongoing maintainer: None. Work Items ---------- * Implement the swift middleware using oslo.messaging notification * Repackage the ceilometer and the ceilometerclient * Add Unit/Integration test coverage * Update related documents Future lifecycle ================ This repackaging will be done b/w the ceilometer package and the ceilometerclient package so the ceilometer team will be responsible for this. Dependencies ============ * oslo.messaging notifications * a configuration sample in proxy-server.conf-sample in swift Testing ======= In addition to unit tests, Tempest tests which confirm that ceilometer consumes notifications produced by the swift middleware would be useful. And also some performance measurements with swift are necessary to check whether changing to oslo.messaging has a bad influence for performance. Documentation Impact ==================== The installation procedure should be changed. Create new procedure only for object store statistics in addition to the current procedure. New procedure will be created based on step 3-7 and As for the step 4 and 5, install the ceilometerclient package instead of the ceilometer package. http://docs.openstack.org/developer/ceilometer/install/manual.html#installing-the-notification-agent References ========== This topic was discussed with the following mail thread. https://www.mail-archive.com/openstack-dev%40lists.openstack.org/msg32793.html ",,178,0
openstack%2Fkeystone~master~Id33dd4fefd79b39c1410c511c9700b53507245bc,openstack/keystone,master,Id33dd4fefd79b39c1410c511c9700b53507245bc,Bump hacking to be at least 0.9.4,ABANDONED,2014-12-02 19:21:19.000000000,2015-01-13 21:25:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6676}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-12-02 19:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/37dcc2649ac05d6cef5347c0a2f63e406aa15023', 'message': 'Bump hacking to be atleast 0.9.4\n\nH302 recently broke using hacking 0.9.2 on oslo.concurrency. Hacking 0.9.4\ncontains the following fix:\n\n  https://review.openstack.org/#/c/138462/2\n\nWe should at least use 0.9.4 so that we can continue to check for H302.\n\nChange-Id: Id33dd4fefd79b39c1410c511c9700b53507245bc\nRelated-Bug: #1398472\n'}, {'number': 2, 'created': '2014-12-02 19:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f3bdc45cc8431a1ebc3f99a9d7de948a935c166', 'message': 'Bump hacking to be at least 0.9.4\n\nH302 recently broke using hacking 0.9.2 on oslo.concurrency. Hacking 0.9.4\ncontains the following fix:\n\n  https://review.openstack.org/#/c/138462/2\n\nWe should at least use 0.9.4 so that we can continue to check for H302.\n\nChange-Id: Id33dd4fefd79b39c1410c511c9700b53507245bc\nRelated-Bug: #1398472\n'}, {'number': 3, 'created': '2014-12-03 16:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7db1561d1111a4eb7dddeeaa8e5f9288d693ace2', 'message': 'Bump hacking to be at least 0.9.4\n\nH302 recently broke using hacking 0.9.2 on oslo.concurrency. Hacking 0.9.4\ncontains the following fix:\n\n  https://review.openstack.org/#/c/138462/2\n\nWe should at least use 0.9.4 so that we can continue to check for H302.\n\nChange-Id: Id33dd4fefd79b39c1410c511c9700b53507245bc\nRelated-Bug: #1398472\n'}, {'number': 4, 'created': '2014-12-19 15:31:54.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2860fd1b4f041a32dd434911b763fb8a301e5334', 'message': 'Bump hacking to be at least 0.9.4\n\nH302 recently broke using hacking 0.9.2 on oslo.concurrency. Hacking 0.9.4\ncontains the following fix:\n\n  https://review.openstack.org/#/c/138462/2\n\nWe should at least use 0.9.4 so that we can continue to check for H302.\n\nChange-Id: Id33dd4fefd79b39c1410c511c9700b53507245bc\nRelated-Bug: #1398472\n'}]",0,138497,2860fd1b4f041a32dd434911b763fb8a301e5334,28,6,4,5046,,,0,"Bump hacking to be at least 0.9.4

H302 recently broke using hacking 0.9.2 on oslo.concurrency. Hacking 0.9.4
contains the following fix:

  https://review.openstack.org/#/c/138462/2

We should at least use 0.9.4 so that we can continue to check for H302.

Change-Id: Id33dd4fefd79b39c1410c511c9700b53507245bc
Related-Bug: #1398472
",git fetch https://review.opendev.org/openstack/keystone refs/changes/97/138497/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,37dcc2649ac05d6cef5347c0a2f63e406aa15023,bug/1398472,"hacking>=0.9.4,<0.10","hacking>=0.9.2,<0.10",1,1
openstack%2Fpython-muranoclient~master~I7471d33a8dfeefc208102c35009d7db9ff959029,openstack/python-muranoclient,master,I7471d33a8dfeefc208102c35009d7db9ff959029,Add opportunity to create public packages via shell,MERGED,2014-12-30 08:27:19.000000000,2015-01-13 21:19:27.000000000,2015-01-13 21:19:27.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}]","[{'number': 1, 'created': '2014-12-30 08:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/d9c2c3f0d9094e96323b58cc6e3b1d70e965c057', 'message': 'Add oportinity to create public packages via shell\n\nChange-Id: I7471d33a8dfeefc208102c35009d7db9ff959029\nCloses-Bug: #1385146\n'}, {'number': 2, 'created': '2014-12-30 08:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/d976d61df1dfacdb28dda439c1a7aa4aeaa94791', 'message': 'Add opportunity to create public packages via shell\n\nChange-Id: I7471d33a8dfeefc208102c35009d7db9ff959029\nCloses-Bug: #1385146\n'}, {'number': 3, 'created': '2014-12-30 08:37:24.000000000', 'files': ['muranoclient/tests/test_shell.py', 'muranoclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/08e447ea8a0f9d963df988a93c750a6511c14958', 'message': ""Add opportunity to create public packages via shell\n\n'is_public' parameter is False by default.\nNow, user can set --is-public during package import to\nmake package avaliable for other tenants.\nAlso, unit-tests were updated.\n\nChange-Id: I7471d33a8dfeefc208102c35009d7db9ff959029\nCloses-Bug: #1385146\n""}]",0,144418,08e447ea8a0f9d963df988a93c750a6511c14958,9,3,3,7549,,,0,"Add opportunity to create public packages via shell

'is_public' parameter is False by default.
Now, user can set --is-public during package import to
make package avaliable for other tenants.
Also, unit-tests were updated.

Change-Id: I7471d33a8dfeefc208102c35009d7db9ff959029
Closes-Bug: #1385146
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/18/144418/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/shell.py'],1,d9c2c3f0d9094e96323b58cc6e3b1d70e965c057,bug/1385146,"@utils.arg('--is-public', action='store_true', default=False, help='Make package available for user from other tenants') data = {""is_public"": args.is_public} if args.categories: data[""categories""] = args.categories "," data = None if args.categories: data = {""categories"": args.categories}",6,2
openstack%2Fneutron~master~I369203a23ad4af1d307166aae84aee817572370b,openstack/neutron,master,I369203a23ad4af1d307166aae84aee817572370b,Remove redundant tunnel ids from ovs agent,MERGED,2015-01-08 11:37:55.000000000,2015-01-13 21:10:09.000000000,2015-01-13 21:10:03.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6502}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-08 11:37:55.000000000', 'files': ['neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e8a592b5700750fa91a7a6b17c30ff7d6038e09', 'message': 'Remove redundant tunnel ids from ovs agent\n\ntunnel ids were specific to the OVS plugin which was removed in Juno.\n\nChange-Id: I369203a23ad4af1d307166aae84aee817572370b\n'}]",0,145750,5e8a592b5700750fa91a7a6b17c30ff7d6038e09,20,16,1,2733,,,0,"Remove redundant tunnel ids from ovs agent

tunnel ids were specific to the OVS plugin which was removed in Juno.

Change-Id: I369203a23ad4af1d307166aae84aee817572370b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/145750/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py']",3,5e8a592b5700750fa91a7a6b17c30ff7d6038e09,remove-tunnel-id," mock.call.add_tunnel_port('gre-0a000a01', '10.0.10.1', '10.0.0.1', mock.sentinel.ctx, tunnel_ip='10.0.10.1', mock.sentinel.ctx, tunnel_ip='10.0.0.1')"," mock.call.add_tunnel_port('gre-1', '10.0.10.1', '10.0.0.1', mock.sentinel.ctx, tunnel_id='1', tunnel_ip='10.0.10.1', mock.sentinel.ctx, tunnel_id='1', tunnel_ip='10.0.0.1')",8,27
openstack%2Fhorizon~master~Ie5eec615f09b6b2b20a73e372db2371ab1bf2819,openstack/horizon,master,Ie5eec615f09b6b2b20a73e372db2371ab1bf2819,Decorator for skipping tests hitting known bugs,MERGED,2015-01-01 15:58:45.000000000,2015-01-13 21:09:52.000000000,2015-01-13 21:09:51.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 8090}, {'_account_id': 8533}, {'_account_id': 8577}, {'_account_id': 9317}, {'_account_id': 10442}, {'_account_id': 12355}, {'_account_id': 12954}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-01-01 15:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/12c7735db1b8a2d499f2b43eec4bc66b3bab29aa', 'message': 'Decorator for skipping tests hitting known bugs\n\nAdding skip_because decorator that can be used for decorating test\nclasses as well as test methods.\nDecorator expects to recieve the bug number causing the test to skip.\n\nPartially implements blueprint: selenium-integration-testing\nCloses-Bug: #1406950\n\nChange-Id: Ie5eec615f09b6b2b20a73e372db2371ab1bf2819\n'}, {'number': 2, 'created': '2015-01-07 22:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bdca0c95ba4165bb2b5b12a3516228597beb2593', 'message': 'Decorator for skipping tests hitting known bugs\n\nAdding skip_because decorator that can be used for decorating test\nclasses as well as test methods.\nDecorator expects to recieve the bug numbers causing the test to skip.\n\nPartially implements blueprint: selenium-integration-testing\nCloses-Bug: #1406950\n\nChange-Id: Ie5eec615f09b6b2b20a73e372db2371ab1bf2819\n'}, {'number': 3, 'created': '2015-01-13 10:48:12.000000000', 'files': ['openstack_dashboard/test/integration_tests/tests/decorators.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5b56140650969505f34a02f51f3b480d4609b7af', 'message': 'Decorator for skipping tests hitting known bugs\n\nAdding skip_because decorator that can be used for decorating test\nclasses as well as test methods.\nDecorator expects to recieve the bug numbers causing the test to skip.\n\nPartially implements blueprint: selenium-integration-testing\nCloses-Bug: #1406950\n\nChange-Id: Ie5eec615f09b6b2b20a73e372db2371ab1bf2819\n'}]",4,144695,5b56140650969505f34a02f51f3b480d4609b7af,24,10,3,8577,,,0,"Decorator for skipping tests hitting known bugs

Adding skip_because decorator that can be used for decorating test
classes as well as test methods.
Decorator expects to recieve the bug numbers causing the test to skip.

Partially implements blueprint: selenium-integration-testing
Closes-Bug: #1406950

Change-Id: Ie5eec615f09b6b2b20a73e372db2371ab1bf2819
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/144695/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/tests/decorators.py'],1,12c7735db1b8a2d499f2b43eec4bc66b3bab29aa,bp/selenium-integration-testing," def skip_because(**kwargs): """"""Decorator for skipping tests hitting known bugs Usage: from openstack_dashboard.test.integration_tests.tests import decorators class TestDashboardHelp(helpers.TestCase): @decorators.skip_because(bug=""1234567"") def test_dashboard_help_redirection(self): . . . """""" def actual_decoration(obj): if inspect.isclass(obj): if not _is_test_cls(obj): raise ValueError(NOT_TEST_OBJECT_ERROR_MSG) skip_method = _mark_class_skipped else: if not _is_test_method_name(obj.func_name): raise ValueError(NOT_TEST_OBJECT_ERROR_MSG) skip_method = _mark_method_skipped if ""bug"" in kwargs: if not kwargs['bug'].isdigit(): raise ValueError('bug must be a valid bug number') obj = skip_method(obj, ""Skipped until Bug: %s is resolved."" % kwargs[""bug""]) return obj return actual_decoration",,32,0
openstack%2Ftempest~master~I240b12139fd91747cf4ed96e0294a0bf082bcf93,openstack/tempest,master,I240b12139fd91747cf4ed96e0294a0bf082bcf93,Add raw_request() to RestClient,MERGED,2015-01-08 08:03:18.000000000,2015-01-13 21:09:11.000000000,2015-01-13 21:09:10.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-08 08:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6d365f5cc8ac52efd64954c9f05eca812b94a807', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 2, 'created': '2015-01-08 09:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c54c9bbbf0568d6d7ee0046653d81f6f32572bde', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 3, 'created': '2015-01-09 01:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c04e0a8e700846c0df3c4e214f9588b6e37eb838', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 4, 'created': '2015-01-09 04:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7e4e502f97a970922cfdb2c590d986ca7ce67ea', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 5, 'created': '2015-01-09 05:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6de10a796ffdf2e522aee9083853943425582ff6', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 6, 'created': '2015-01-12 23:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2f926ad318198e0193c2582c1f2dc8ed1d11ed8e', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}, {'number': 7, 'created': '2015-01-13 00:42:25.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/34f34728d513572c350d3f39e93944555298abd2', 'message': 'Add raw_request() to RestClient\n\nTokenClientJSON and V3TokenClientJSON call self.http_obj.request()\ndirectly for skipping an authentication request. However, the method\nis internal in RestClient and we need to avoid the call for moving\nRestClient to tempest-lib.\nThis patch adds raw_request() to RestClient for avoiding it.\n\nChange-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93\n'}]",0,145713,34f34728d513572c350d3f39e93944555298abd2,34,7,7,6167,,,0,"Add raw_request() to RestClient

TokenClientJSON and V3TokenClientJSON call self.http_obj.request()
directly for skipping an authentication request. However, the method
is internal in RestClient and we need to avoid the call for moving
RestClient to tempest-lib.
This patch adds raw_request() to RestClient for avoiding it.

Change-Id: I240b12139fd91747cf4ed96e0294a0bf082bcf93
",git fetch https://review.opendev.org/openstack/tempest refs/changes/13/145713/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/rest_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py']",3,6d365f5cc8ac52efd64954c9f05eca812b94a807,rest-client," resp, resp_body = self.raw_request(url, method, headers=headers, body=body)"," resp, resp_body = self.http_obj.request(url, method, headers=headers, body=body)",9,5
openstack%2Fneutron-fwaas~master~I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05,openstack/neutron-fwaas,master,I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05,Adjust fwaas unit tests to work with quotas enabled,MERGED,2014-12-11 14:55:44.000000000,2015-01-13 21:09:04.000000000,2015-01-13 21:09:04.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 2062}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-11 14:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/2689a17b754818ac887d1fd465e8fef6cffca652', 'message': 'Adjust fwaas unit tests to work with quotas enabled\n\nTo allow unit tests that create multiple firewalls succeeding even after\nbug#1399280 (FWaaS doesn\'t register it\'s quota resources) is fixed we\ncreate the firewalls in separate tenants.\nThe default per-tenant quota for firewalls is ""1"". Additionally the plugin\ncurrently has a hardcoded limit of one firewall per tenant so there is no point\nin increasing the default quota.\n\nChange-Id: I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05\nRelated-Bug: #1399280\n'}, {'number': 2, 'created': '2015-01-09 11:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/ce2d153daf934e6b479d1ed2d66b649ef2502c2e', 'message': 'Adjust fwaas unit tests to work with quotas enabled\n\nTo allow unit tests that create multiple firewalls succeeding even after\nbug#1399280 (FWaaS doesn\'t register it\'s quota resources) is fixed we\ncreate the firewalls in separate tenants.\nThe default per-tenant quota for firewalls is ""1"". Additionally the\nplugin currently has a hardcoded limit of one firewall per tenant so\nthere is no point in increasing the default quota.\n\nChange-Id: I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05\nRelated-Bug: #1399280\n'}, {'number': 3, 'created': '2015-01-13 09:23:32.000000000', 'files': ['neutron_fwaas/tests/unit/db/firewall/test_db_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/b823b339d5089dd3db329b7f89a431d7a3dc94d2', 'message': 'Adjust fwaas unit tests to work with quotas enabled\n\nTo allow unit tests that create multiple firewalls succeeding even after\nbug#1399280 (FWaaS doesn\'t register it\'s quota resources) is fixed we\ncreate the firewalls in separate tenants.\nThe default per-tenant quota for firewalls is ""1"". Additionally the\nplugin currently has a hardcoded limit of one firewall per tenant so\nthere is no point in increasing the default quota.\n\nChange-Id: I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05\nRelated-Bug: #1399280\n'}]",0,141064,b823b339d5089dd3db329b7f89a431d7a3dc94d2,18,4,3,2062,,,0,"Adjust fwaas unit tests to work with quotas enabled

To allow unit tests that create multiple firewalls succeeding even after
bug#1399280 (FWaaS doesn't register it's quota resources) is fixed we
create the firewalls in separate tenants.
The default per-tenant quota for firewalls is ""1"". Additionally the
plugin currently has a hardcoded limit of one firewall per tenant so
there is no point in increasing the default quota.

Change-Id: I7933d3bc6cf2465fe28604ea3dba9d38cf2e0a05
Related-Bug: #1399280
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/64/141064/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/tests.skip/unit/db/firewall/test_db_firewall.py'],1,2689a17b754818ac887d1fd465e8fef6cffca652,bug/1399280," tenant_id='tenant1', tenant_id='tenant2', tenant_id='tenant3',",,3,0
openstack%2Fneutron-vpnaas~master~I1134742a38847f8b8ee7520568d8e94b8b05212f,openstack/neutron-vpnaas,master,I1134742a38847f8b8ee7520568d8e94b8b05212f,Updated from global requirements,MERGED,2015-01-13 00:06:11.000000000,2015-01-13 21:09:02.000000000,2015-01-13 21:09:02.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-13 00:06:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/998ee539554bf8771b8e314edcbc8e9f78093995', 'message': 'Updated from global requirements\n\nChange-Id: I1134742a38847f8b8ee7520568d8e94b8b05212f\n'}]",0,146699,998ee539554bf8771b8e314edcbc8e9f78093995,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1134742a38847f8b8ee7520568d8e94b8b05212f
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/99/146699/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,998ee539554bf8771b8e314edcbc8e9f78093995,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fneutron-vpnaas~master~I6d990a564df6a312bd09b2a152315bbdba732082,openstack/neutron-vpnaas,master,I6d990a564df6a312bd09b2a152315bbdba732082,Update hacking to 0.10,MERGED,2015-01-12 16:44:18.000000000,2015-01-13 21:08:55.000000000,2015-01-13 21:08:54.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-12 16:44:18.000000000', 'files': ['test-requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'tox.ini', 'neutron_vpnaas/db/migration/alembic_migrations/env.py', 'neutron_vpnaas/db/vpn/vpn_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/f9d6675c88ea44c2c0467a7f93eed4ceff5e1147', 'message': 'Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Minor fixes to pass new W292 (no newline at the end of file) and H238\n  (old style classes) rules.\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n'}]",0,146565,f9d6675c88ea44c2c0467a7f93eed4ceff5e1147,7,3,1,9656,,,0,"Update hacking to 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

* Remove references in tox.ini to removed rules.
* Minor fixes to pass new W292 (no newline at the end of file) and H238
  (old style classes) rules.

Change-Id: I6d990a564df6a312bd09b2a152315bbdba732082
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/65/146565/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'tox.ini', 'neutron_vpnaas/db/migration/alembic_migrations/env.py', 'neutron_vpnaas/db/vpn/vpn_db.py']",5,f9d6675c88ea44c2c0467a7f93eed4ceff5e1147,,class VPNPluginRpcDbMixin(object):,class VPNPluginRpcDbMixin():,5,8
openstack%2Fneutron-lbaas~master~Icc8880e309b6bcd31999cd6cd0cc1cfd668e0273,openstack/neutron-lbaas,master,Icc8880e309b6bcd31999cd6cd0cc1cfd668e0273,Updated from global requirements,MERGED,2015-01-13 00:05:48.000000000,2015-01-13 21:08:49.000000000,2015-01-13 21:08:47.000000000,"[{'_account_id': 3}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2015-01-13 00:05:48.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/3fe3a1a60dc59281a5d5e1b8e824386dfe6f2ed2', 'message': 'Updated from global requirements\n\nChange-Id: Icc8880e309b6bcd31999cd6cd0cc1cfd668e0273\n'}]",0,146698,3fe3a1a60dc59281a5d5e1b8e824386dfe6f2ed2,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: Icc8880e309b6bcd31999cd6cd0cc1cfd668e0273
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/98/146698/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3fe3a1a60dc59281a5d5e1b8e824386dfe6f2ed2,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fheat~master~I52d7b1123fed75f2f9bcd7a66ee7a104fc9cb1b2,openstack/heat,master,I52d7b1123fed75f2f9bcd7a66ee7a104fc9cb1b2,LB: Separate out the validation tests,MERGED,2015-01-09 07:28:47.000000000,2015-01-13 21:08:36.000000000,2015-01-13 21:08:35.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-09 07:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/666b27054d4c29edf46e0d6a2b53d5ed8013ac09', 'message': 'LB: Separate out the validation tests\n\nPart of blueprint decouple-nested\nChange-Id: I52d7b1123fed75f2f9bcd7a66ee7a104fc9cb1b2\n'}, {'number': 2, 'created': '2015-01-13 02:20:03.000000000', 'files': ['heat/tests/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d819d9946882ce860dbed664639546c1d57daa18', 'message': 'LB: Separate out the validation tests\n\nPart of blueprint decouple-nested\nChange-Id: I52d7b1123fed75f2f9bcd7a66ee7a104fc9cb1b2\n'}]",0,146032,d819d9946882ce860dbed664639546c1d57daa18,21,6,2,4715,,,0,"LB: Separate out the validation tests

Part of blueprint decouple-nested
Change-Id: I52d7b1123fed75f2f9bcd7a66ee7a104fc9cb1b2
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/146032/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_loadbalancer.py'],1,666b27054d4c29edf46e0d6a2b53d5ed8013ac09,bp/decouple-nested," def test_loadbalancer_validate_hchk_good(self): rsrc = self.setup_loadbalancer() rsrc._parse_nested_stack = mock.Mock() hc = { 'Target': 'HTTP:80/', 'HealthyThreshold': '3', 'UnhealthyThreshold': '5', 'Interval': '30', 'Timeout': '5'} rsrc.t['Properties']['HealthCheck'] = hc self.assertIsNone(rsrc.validate()) def test_loadbalancer_validate_hchk_int_gt_tmo(self): rsrc = self.setup_loadbalancer() rsrc._parse_nested_stack = mock.Mock() hc = { 'Target': 'HTTP:80/', 'HealthyThreshold': '3', 'UnhealthyThreshold': '5', 'Interval': '30', 'Timeout': '35'} rsrc.t['Properties']['HealthCheck'] = hc self.assertEqual( {'Error': 'Interval must be larger than Timeout'}, rsrc.validate()) rsrc = self.setup_loadbalancer()"," hc = { 'Target': 'HTTP:80/', 'HealthyThreshold': '3', 'UnhealthyThreshold': '5', 'Interval': '30', 'Timeout': '5'} rsrc.t['Properties']['HealthCheck'] = hc self.assertIsNone(rsrc.validate()) hc['Timeout'] = 35 self.assertEqual( {'Error': 'Interval must be larger than Timeout'}, rsrc.validate()) hc['Timeout'] = 5 t = template_format.parse(lb_template) s = utils.parse_stack(t) s.store() resource_defns = s.t.resource_definitions(s) rsrc = lb.LoadBalancer('LoadBalancer', resource_defns['LoadBalancer'], s)",27,24
openstack%2Fneutron-fwaas~master~Iafc4a82a73d8a467a39472d92052501843119d24,openstack/neutron-fwaas,master,Iafc4a82a73d8a467a39472d92052501843119d24,Updated from global requirements,MERGED,2015-01-13 00:05:27.000000000,2015-01-13 21:08:28.000000000,2015-01-13 21:08:26.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 7448}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-13 00:05:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/11425d5a093214927172d8f7c7a8176f001a4da6', 'message': 'Updated from global requirements\n\nChange-Id: Iafc4a82a73d8a467a39472d92052501843119d24\n'}]",0,146697,11425d5a093214927172d8f7c7a8176f001a4da6,7,9,1,11131,,,0,"Updated from global requirements

Change-Id: Iafc4a82a73d8a467a39472d92052501843119d24
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/97/146697/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,11425d5a093214927172d8f7c7a8176f001a4da6,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fnova-specs~master~Ie89c87032831594efe9755cc6ac994510ec3d27c,openstack/nova-specs,master,Ie89c87032831594efe9755cc6ac994510ec3d27c,Fix wrong BP URL: Support iSCSI live migration for different iSCSI target,MERGED,2015-01-13 19:39:02.000000000,2015-01-13 21:01:24.000000000,2015-01-13 21:01:24.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-01-13 19:39:02.000000000', 'files': ['specs/kilo/approved/iscsi-live-migration-different-target.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0dcb54a4df683e9f0ff0d685e16b47e9406bf2d9', 'message': 'Fix wrong BP URL: Support iSCSI live migration for different iSCSI target\n\nThis patch just fixes wrong blueprint URL for already merged nova-spec.\nSPEC: https://review.openstack.org/#/c/132323/\nBP: https://blueprints.launchpad.net/nova/+spec/iscsi-live-migration-different-target\n\nChange-Id: Ie89c87032831594efe9755cc6ac994510ec3d27c\nBlueprint iscsi-live-migration-different-target\n'}]",0,146963,0dcb54a4df683e9f0ff0d685e16b47e9406bf2d9,6,3,1,10115,,,0,"Fix wrong BP URL: Support iSCSI live migration for different iSCSI target

This patch just fixes wrong blueprint URL for already merged nova-spec.
SPEC: https://review.openstack.org/#/c/132323/
BP: https://blueprints.launchpad.net/nova/+spec/iscsi-live-migration-different-target

Change-Id: Ie89c87032831594efe9755cc6ac994510ec3d27c
Blueprint iscsi-live-migration-different-target
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/63/146963/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/iscsi-live-migration-different-target.rst'],1,0dcb54a4df683e9f0ff0d685e16b47e9406bf2d9,bp/URL,https://blueprints.launchpad.net/nova/+spec/iscsi-live-migration-different-target,https://blueprints.launchpad.net/cinder/+spec/iscsi-live-migration-for-different-target,1,1
openstack%2Fmagnum~master~I6b6ccc9d95bddc42a98450cebac15bfd7aceab37,openstack/magnum,master,I6b6ccc9d95bddc42a98450cebac15bfd7aceab37,Implement pod deletion,MERGED,2015-01-13 03:38:38.000000000,2015-01-13 21:00:41.000000000,2015-01-13 21:00:40.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7494}, {'_account_id': 11536}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 03:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9f18acf90c56322eadaeb5fdf53c324d36f9bbbe', 'message': 'Implement pod deletion\n\nPod deletion is working from magnum api.\n\nChange-Id: I6b6ccc9d95bddc42a98450cebac15bfd7aceab37\n'}, {'number': 2, 'created': '2015-01-13 05:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/718f8056c3657315debc2f6c5397001ec31cb3ec', 'message': 'Implement pod deletion\n\nPod deletion is working from magnum api.\n\nChange-Id: I6b6ccc9d95bddc42a98450cebac15bfd7aceab37\n'}, {'number': 3, 'created': '2015-01-13 06:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b1936b76eb2d55cba2ebcee12031fbdf55ceb1a9', 'message': 'Implement pod deletion\n\nPod deletion is working from magnum api.\n\nChange-Id: I6b6ccc9d95bddc42a98450cebac15bfd7aceab37\n'}, {'number': 4, 'created': '2015-01-13 14:39:41.000000000', 'files': ['magnum/conductor/handlers/common/kube_utils.py', 'magnum/conductor/api.py', 'magnum/tests/api/controllers/v1/test_pod.py', 'magnum/api/controllers/v1/pod.py', 'magnum/tests/conductor/test_rpcapi.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b30b4f1f25c3b481671503bd288812a9ff7c9cfc', 'message': 'Implement pod deletion\n\nPod deletion is working from magnum api.\n\nChange-Id: I6b6ccc9d95bddc42a98450cebac15bfd7aceab37\n'}]",2,146751,b30b4f1f25c3b481671503bd288812a9ff7c9cfc,17,5,4,12385,,,0,"Implement pod deletion

Pod deletion is working from magnum api.

Change-Id: I6b6ccc9d95bddc42a98450cebac15bfd7aceab37
",git fetch https://review.opendev.org/openstack/magnum refs/changes/51/146751/4 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/common/kube_utils.py', 'magnum/conductor/api.py', 'magnum/tests/api/controllers/v1/test_pod.py', 'magnum/api/controllers/v1/pod.py', 'magnum/tests/conductor/test_rpcapi.py', 'magnum/conductor/handlers/kube.py']",6,9f18acf90c56322eadaeb5fdf53c324d36f9bbbe,impl-k8s-backend," def pod_delete(self, ctxt, uuid): pod = objects.Pod.get_by_uuid(ctxt, uuid) k8s_master_url = _retrive_k8s_master_url(ctxt, pod) status = self.kube_cli.pod_delete(k8s_master_url, pod.name)"," def pod_delete(self, ctxt, pod): status = self.kube_cli.pod_delete(pod.uuid)",16,13
openstack%2Fmagnum~master~I7ad53e1ddcef76a644c8da7b7369423705c72a2c,openstack/magnum,master,I7ad53e1ddcef76a644c8da7b7369423705c72a2c,Set pod name from pod manifest,MERGED,2015-01-13 03:38:38.000000000,2015-01-13 21:00:32.000000000,2015-01-13 21:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 03:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/986dc2293dbdaa90347ad6b6a5be5c7433056b4f', 'message': 'Set pod name from pod manifest\n\nOnly pod manifest knows about pod name, so this patch retrieve pod name from\npod manifest.\n\nChange-Id: I7ad53e1ddcef76a644c8da7b7369423705c72a2c\n'}, {'number': 2, 'created': '2015-01-13 05:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/caf3fbfab6b94bbe2ff1279cbfcaaa8dc9da931c', 'message': 'Set pod name from pod manifest\n\nOnly pod manifest knows about pod name, so this patch retrieve pod name from\npod manifest.\n\nChange-Id: I7ad53e1ddcef76a644c8da7b7369423705c72a2c\n'}, {'number': 3, 'created': '2015-01-13 06:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/661fe5837d30ca416dd6f49ee169e06f948c7b4b', 'message': 'Set pod name from pod manifest\n\nOnly pod manifest knows about pod name, so this patch retrieve pod name from\npod manifest.\n\nChange-Id: I7ad53e1ddcef76a644c8da7b7369423705c72a2c\n'}, {'number': 4, 'created': '2015-01-13 14:39:41.000000000', 'files': ['magnum/tests/api/controllers/v1/test_pod.py', 'magnum/api/controllers/v1/pod.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/5fe240f50eb27a855eae95cace30d761a84e82e0', 'message': 'Set pod name from pod manifest\n\nOnly pod manifest knows about pod name, so this patch retrieve pod name from\npod manifest.\n\nChange-Id: I7ad53e1ddcef76a644c8da7b7369423705c72a2c\n'}]",3,146750,5fe240f50eb27a855eae95cace30d761a84e82e0,16,6,4,12385,,,0,"Set pod name from pod manifest

Only pod manifest knows about pod name, so this patch retrieve pod name from
pod manifest.

Change-Id: I7ad53e1ddcef76a644c8da7b7369423705c72a2c
",git fetch https://review.opendev.org/openstack/magnum refs/changes/50/146750/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/api/controllers/v1/pod.py', 'magnum/common/k8s_manifest.py']",2,986dc2293dbdaa90347ad6b6a5be5c7433056b4f,impl-k8s-backend, import six,import itertoolsimport re import six from oslo.config import cfg,9,4
openstack%2Fmagnum~master~I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a,openstack/magnum,master,I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a,Add parser for k8s manifest,MERGED,2015-01-13 03:38:38.000000000,2015-01-13 21:00:26.000000000,2015-01-13 21:00:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 03:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/12b7049e306048efecf46b9b5f043941eb4c93e0', 'message': 'Add parser for k8s manifest\n\nWhen creating a service/pod, Magnum needs its name and more additional\ninformation to store database.\nThis parser allows it.\n\nChange-Id: I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a\n'}, {'number': 2, 'created': '2015-01-13 05:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d48ca3a835c03c398de87fd9577779253e260ed3', 'message': 'Add parser for k8s manifest\n\nWhen creating a service/pod, Magnum needs its name and more additional\ninformation to store database.\nThis parser allows it.\n\nChange-Id: I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a\n'}, {'number': 3, 'created': '2015-01-13 14:39:41.000000000', 'files': ['magnum/tests/common/test_k8s_manifest.py', 'magnum/common/k8s_manifest.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1db6c60d3acc2702c5e88ce5abe3450b4f31e985', 'message': 'Add parser for k8s manifest\n\nWhen creating a service/pod, Magnum needs its name and more additional\ninformation to store database.\nThis parser allows it.\n\nChange-Id: I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a\n'}]",7,146749,1db6c60d3acc2702c5e88ce5abe3450b4f31e985,15,6,3,12385,,,0,"Add parser for k8s manifest

When creating a service/pod, Magnum needs its name and more additional
information to store database.
This parser allows it.

Change-Id: I6e2a028f0caa7dbbd3a6de20aa3c982fb870c24a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/49/146749/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/common/test_k8s_manifest.py', 'magnum/common/k8s_manifest.py']",2,12b7049e306048efecf46b9b5f043941eb4c93e0,impl-k8s-backend,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import itertools import json import re import six from oslo.config import cfg import yaml from magnum.openstack.common._i18n import _ if hasattr(yaml, 'CSafeLoader'): yaml_loader = yaml.CSafeLoader else: yaml_loader = yaml.SafeLoader if hasattr(yaml, 'CSafeDumper'): yaml_dumper = yaml.CSafeDumper else: yaml_dumper = yaml.SafeDumper def _construct_yaml_str(self, node): # Override the default string handling function # to always return unicode objects return self.construct_scalar(node) yaml_loader.add_constructor(u'tag:yaml.org,2002:str', _construct_yaml_str) # Unquoted dates like 2013-05-23 in yaml files get loaded as objects of type # datetime.data which causes problems in API layer when being processed by # openstack.common.jsonutils. Therefore, make unicode string out of timestamps # until jsonutils can handle dates. yaml_loader.add_constructor(u'tag:yaml.org,2002:timestamp', _construct_yaml_str) def simple_parse(tmpl_str): try: tpl = json.loads(tmpl_str) except ValueError: try: tpl = yaml.load(tmpl_str, Loader=yaml_loader) except yaml.YAMLError as yea: yea = six.text_type(yea) msg = _('Error parsing manifest: %s') % yea raise ValueError(msg) else: if tpl is None: tpl = {} if not isinstance(tpl, dict): raise ValueError(_('The manifest is not a JSON object ' 'or YAML mapping.')) return tpl def parse(tmpl_str): """"""Takes a string and returns a dict containing the parsed structure. This includes determination of whether the string is using the JSON or YAML format. """""" # if len(tmpl_str) > cfg.CONF.max_template_size: # msg = (_('Template exceeds maximum allowed size (%s bytes)') % # cfg.CONF.max_template_size) # raise exception.RequestLimitExceeded(message=msg) tpl = simple_parse(tmpl_str) return tpl",,140,0
openstack%2Fneutron-fwaas~master~I6d990a564df6a312bd09b2a152315bbdba732082,openstack/neutron-fwaas,master,I6d990a564df6a312bd09b2a152315bbdba732082,Update hacking to 0.10,MERGED,2015-01-12 16:34:55.000000000,2015-01-13 21:00:05.000000000,2015-01-13 21:00:05.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}]","[{'number': 1, 'created': '2015-01-12 16:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/3a23d3bbcd1f4b142bb452e464c18e8ea8099a9b', 'message': 'Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Minor fix to pass new W292 rule (no newline at the end of file).\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n'}, {'number': 2, 'created': '2015-01-12 22:48:54.000000000', 'files': ['test-requirements.txt', 'neutron_fwaas/db/migration/alembic_migrations/env.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c3b7aaece65c48b8d196fd31d09b9ea4d7ca0b7a', 'message': 'Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Minor fix to pass new W292 rule (no newline at the end of file).\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n'}]",0,146555,c3b7aaece65c48b8d196fd31d09b9ea4d7ca0b7a,9,3,2,9656,,,0,"Update hacking to 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

* Remove references in tox.ini to removed rules.
* Minor fix to pass new W292 rule (no newline at the end of file).

Change-Id: I6d990a564df6a312bd09b2a152315bbdba732082
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/55/146555/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'neutron_fwaas/db/migration/alembic_migrations/env.py', 'tox.ini']",3,3a23d3bbcd1f4b142bb452e464c18e8ea8099a9b,hacking,"ignore = E125,E126,E128,E129,E265,H305,H404,H405","# H307 like imports should be grouped together # H402 one line docstring needs punctuation# H904 Wrap long lines in parentheses instead of a backslashignore = E125,E126,E128,E129,E265,H305,H307,H402,H404,H405,H904",3,6
openstack%2Fneutron-lbaas~master~I6d990a564df6a312bd09b2a152315bbdba732082,openstack/neutron-lbaas,master,I6d990a564df6a312bd09b2a152315bbdba732082,Update hacking to 0.10,MERGED,2015-01-12 16:48:55.000000000,2015-01-13 20:59:31.000000000,2015-01-13 20:59:30.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 6951}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2015-01-12 16:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/fd598f0f267c7f4defc8a702515bba80e23b4675', 'message': 'Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Minor fixes to pass new W292 (no newline at the end of file) and H238\n  (old style classes) rules.\n* Fix single false positive for H501 (Do not use self.__dict__ for string\n  formatting) by adding another level of indirection.\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n'}, {'number': 2, 'created': '2015-01-12 22:52:05.000000000', 'files': ['neutron_lbaas/services/loadbalancer/drivers/embrane/constants.py', 'test-requirements.txt', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py', 'tox.ini', 'neutron_lbaas/services/loadbalancer/drivers/radware/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/bfcd20693e4792eb454450d78b93da584b10f56b', 'message': 'Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Minor fixes to pass new W292 (no newline at the end of file) and H238\n  (old style classes) rules.\n* Fix single false positive for H501 (Do not use self.__dict__ for string\n  formatting) by adding another level of indirection.\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n'}]",0,146568,bfcd20693e4792eb454450d78b93da584b10f56b,16,6,2,9656,,,0,"Update hacking to 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

* Remove references in tox.ini to removed rules.
* Minor fixes to pass new W292 (no newline at the end of file) and H238
  (old style classes) rules.
* Fix single false positive for H501 (Do not use self.__dict__ for string
  formatting) by adding another level of indirection.

Change-Id: I6d990a564df6a312bd09b2a152315bbdba732082
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/68/146568/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/drivers/embrane/constants.py', 'test-requirements.txt', 'tox.ini', 'neutron_lbaas/services/loadbalancer/drivers/radware/driver.py']",4,fd598f0f267c7f4defc8a702515bba80e23b4675,,"class vDirectRESTClient(object):class OperationAttributes(object): attrs = self.__dict__ items = (""%s = %r"" % (k, v) for k, v in attrs.items())","class vDirectRESTClient:class OperationAttributes: items = (""%s = %r"" % (k, v) for k, v in self.__dict__.items())",8,10
openstack%2Fhorizon~master~I8ff9ce6856e5053515d1675a27729b415d33145b,openstack/horizon,master,I8ff9ce6856e5053515d1675a27729b415d33145b,Refactoring main_content css,MERGED,2014-09-12 23:40:38.000000000,2015-01-13 20:59:20.000000000,2015-01-13 20:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6638}, {'_account_id': 6763}, {'_account_id': 6825}, {'_account_id': 8040}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10295}, {'_account_id': 11473}, {'_account_id': 11881}, {'_account_id': 13325}, {'_account_id': 13785}]","[{'number': 1, 'created': '2014-09-12 23:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/15c647333251bd988487b5054b32583027dc740a', 'message': 'Refactoring main_content from ID to class\n\nChange-Id: I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983\n'}, {'number': 2, 'created': '2014-09-12 23:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/75bfe0a76bbe522e514037333c5e94e218200b44', 'message': 'Refactoring main_content from ID to class\n\nAlso refactored content_body and scss.\n\nChange-Id: I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 3, 'created': '2014-09-12 23:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3e124cddae57b64259fe486236f139673627b491', 'message': 'Refactoring main_content from ID to class\n\nAlso refactored content_body and scss.\n\nChange-Id: I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 4, 'created': '2014-09-15 16:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d4352d1d67faa752d73d547342aa51febb2c7068', 'message': 'Refactoring main_content from ID to class\n\nAlso refactored content_body and scss.\n\nChange-Id: I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 5, 'created': '2014-10-23 02:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8bb460af3818a5bb4fc15b4cf91a49ebf2ae464c', 'message': 'Refactoring main_content from ID to class\n\nWe should avoid the use of id for styling and instead use classes for more\nreusability. Also refactored content_body and combined scss.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 6, 'created': '2014-10-23 17:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/148ac85e7824db97f57a94e411565bfa49b0a188', 'message': 'Refactoring main_content from ID to class\n\nWe should avoid the use of id for styling and instead use classes for more\nreusability. Also refactored content_body and combined scss.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 7, 'created': '2014-10-24 02:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bafa1dcd36f81c90dd3b4647632991ed50357b2c', 'message': 'Refactoring main_content css\n\nWe are primarily using main_content ID for styling. This patch\nrefactor some of the styling so that it takes advantage of SCSS nesting.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983\n'}, {'number': 8, 'created': '2014-10-27 18:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3e1b6d6c8a291211f28a9b430ffa4c6f1e119238', 'message': 'Refactoring main_content css\n\nWe are primarily using main_content ID for styling. This patch\nrefactor some of the styling so that it takes advantage of SCSS nesting.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 9, 'created': '2015-01-12 17:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9329f4df404eb4e66e325ea56e8fedf0460b06b2', 'message': 'Refactoring main_content css\n\nThis patch refactor some of the styling to take advantage of SCSS nesting.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}, {'number': 10, 'created': '2015-01-12 18:00:26.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/812c1f079b8972b9e3d004753a0fea5c58101820', 'message': 'Refactoring main_content css\n\nThis patch refactor some of the styling to take advantage of SCSS nesting.\n\nChange-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b\nCloses-Bug: #1368983'}]",6,121268,812c1f079b8972b9e3d004753a0fea5c58101820,42,13,10,9576,,,0,"Refactoring main_content css

This patch refactor some of the styling to take advantage of SCSS nesting.

Change-Id:  I8ff9ce6856e5053515d1675a27729b415d33145b
Closes-Bug: #1368983",git fetch https://review.opendev.org/openstack/horizon refs/changes/68/121268/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/qunit.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/job_executions.html', 'horizon/static/horizon/js/horizon.messages.js', 'horizon/templates/horizon/jasmine/jasmine.html', 'openstack_dashboard/test/integration_tests/pages/basepage.py', 'horizon/static/horizon/tests/messages.js', 'horizon/templates/base.html']",8,15c647333251bd988487b5054b32583027dc740a,bug/refactor-main-content-css, <div class='main_content'>, <div id='main_content'>,44,42
openstack%2Fnova~master~I6196e8059e71730cc567d4dd211264cdd2272c40,openstack/nova,master,I6196e8059e71730cc567d4dd211264cdd2272c40,Enable W292,MERGED,2015-01-07 23:01:12.000000000,2015-01-13 20:55:53.000000000,2015-01-13 06:56:13.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 23:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/480a4d6f8018ff88a17aeed930fe8862e9a3981a', 'message': 'Enable W292\n\nW292 no newline at end of file\n\nW292 started failing with hacking 0.10.0, fix all cases and gate on the\nrule.\n\nChange-Id: I6196e8059e71730cc567d4dd211264cdd2272c40\n'}, {'number': 2, 'created': '2015-01-10 22:40:40.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_cloudpipe.py', 'nova/api/openstack/compute/contrib/flavorextradata.py', 'nova/tests/unit/api/openstack/compute/contrib/test_createserverext.py', 'nova/tests/unit/api/openstack/compute/contrib/test_block_device_mapping_v1.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_swap.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_diagnostics.py', 'nova/tests/unit/api/openstack/compute/contrib/test_virtual_interfaces.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips_mac.py', 'nova/tests/unit/api/openstack/compute/contrib/test_certificates.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/contrib/flavor_swap.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_rxtx.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_disabled.py', 'nova/tests/unit/api/openstack/compute/contrib/test_snapshots.py', 'nova/api/openstack/compute/contrib/server_usage.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_availability_zone.py', 'nova/tests/unit/api/openstack/compute/contrib/test_instance_actions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_migrations.py', 'nova/tests/unit/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/unit/api/openstack/compute/contrib/test_used_limits.py', 'nova/api/openstack/compute/contrib/extended_availability_zone.py', 'nova/tests/unit/api/openstack/compute/test_images.py', 'nova/api/openstack/compute/contrib/extended_ips_mac.py', 'nova/api/openstack/compute/contrib/flavor_disabled.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hide_server_addresses.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_usage.py', 'nova/tests/unit/api/openstack/compute/contrib/test_image_size.py', 'nova/api/openstack/compute/contrib/extended_status.py', 'nova/api/openstack/compute/contrib/extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/contrib/test_quota_classes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_groups.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_status.py', 'nova/api/openstack/compute/contrib/extended_ips.py', 'nova/api/openstack/compute/contrib/flavor_rxtx.py', 'nova/tests/unit/virt/test_images.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_server_attributes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ip_pools.py', 'nova/tests/unit/api/openstack/test_faults.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_virtual_interfaces_net.py', 'nova/api/openstack/compute/contrib/extended_server_attributes.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/0150222387c4ad545017d37169df9c17d50fbb16', 'message': 'Enable W292\n\nW292 no newline at end of file\n\nW292 started failing with hacking 0.10.0, fix all cases and gate on the\nrule.\n\nChange-Id: I6196e8059e71730cc567d4dd211264cdd2272c40\n'}]",0,145620,0150222387c4ad545017d37169df9c17d50fbb16,26,9,2,1849,,,0,"Enable W292

W292 no newline at end of file

W292 started failing with hacking 0.10.0, fix all cases and gate on the
rule.

Change-Id: I6196e8059e71730cc567d4dd211264cdd2272c40
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/145620/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_cloudpipe.py', 'nova/api/openstack/compute/contrib/flavorextradata.py', 'nova/tests/unit/api/openstack/compute/contrib/test_createserverext.py', 'nova/tests/unit/api/openstack/compute/contrib/test_block_device_mapping_v1.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_swap.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_diagnostics.py', 'nova/tests/unit/api/openstack/compute/contrib/test_virtual_interfaces.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips_mac.py', 'nova/tests/unit/api/openstack/compute/contrib/test_certificates.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/contrib/flavor_swap.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_rxtx.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavor_disabled.py', 'nova/tests/unit/api/openstack/compute/contrib/test_snapshots.py', 'nova/api/openstack/compute/contrib/server_usage.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_availability_zone.py', 'nova/tests/unit/api/openstack/compute/contrib/test_instance_actions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_migrations.py', 'nova/tests/unit/api/openstack/compute/contrib/test_security_groups.py', 'nova/tests/unit/api/openstack/compute/contrib/test_used_limits.py', 'nova/api/openstack/compute/contrib/extended_availability_zone.py', 'nova/tests/unit/api/openstack/compute/test_images.py', 'nova/api/openstack/compute/contrib/extended_ips_mac.py', 'nova/api/openstack/compute/contrib/flavor_disabled.py', 'nova/tests/unit/api/openstack/compute/contrib/test_hide_server_addresses.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_usage.py', 'nova/tests/unit/api/openstack/compute/contrib/test_image_size.py', 'nova/api/openstack/compute/contrib/extended_status.py', 'nova/api/openstack/compute/contrib/extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_volumes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_flavors_extra_specs.py', 'nova/tests/unit/api/openstack/compute/test_consoles.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_ips.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ip_dns.py', 'nova/tests/unit/api/openstack/compute/contrib/test_quota_classes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_server_groups.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_status.py', 'nova/api/openstack/compute/contrib/extended_ips.py', 'nova/api/openstack/compute/contrib/flavor_rxtx.py', 'nova/tests/unit/virt/test_images.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_server_attributes.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ip_pools.py', 'nova/tests/unit/api/openstack/test_faults.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extended_virtual_interfaces_net.py', 'nova/api/openstack/compute/contrib/extended_server_attributes.py', 'tox.ini']",46,480a4d6f8018ff88a17aeed930fe8862e9a3981a,hacking," ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H238","# Temporarily skip W292 (new in hacking 0.10) ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H238,W292",46,47
openstack%2Fkeystone~master~Ib684bd870a995e482d7c1a91f0acb5f4bfd96a57,openstack/keystone,master,Ib684bd870a995e482d7c1a91f0acb5f4bfd96a57,add missing parent_id parameter check in project schema,MERGED,2015-01-13 08:26:14.000000000,2015-01-13 20:54:21.000000000,2015-01-13 20:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-01-13 08:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c2f443cfec7104b3346d16c0153bc06f12b3c98b', 'message': 'add missing parent_id parameter check in project schema\n\nChange-Id: Ib684bd870a995e482d7c1a91f0acb5f4bfd96a57\n'}, {'number': 2, 'created': '2015-01-13 10:36:55.000000000', 'files': ['keystone/tests/test_validation.py', 'keystone/assignment/schema.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cd4d7fdca0216bbdebf753fb1a0feb27f386f5c7', 'message': 'add missing parent_id parameter check in project schema\n\nCloses-Bug: #1410182\nChange-Id: Ib684bd870a995e482d7c1a91f0acb5f4bfd96a57\n'}]",1,146796,cd4d7fdca0216bbdebf753fb1a0feb27f386f5c7,10,3,2,9101,,,0,"add missing parent_id parameter check in project schema

Closes-Bug: #1410182
Change-Id: Ib684bd870a995e482d7c1a91f0acb5f4bfd96a57
",git fetch https://review.opendev.org/openstack/keystone refs/changes/96/146796/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_validation.py', 'keystone/assignment/schema.py']",2,c2f443cfec7104b3346d16c0153bc06f12b3c98b,project_parent_id," 'parent_id': validation.nullable(parameter_types.id_string),",,20,0
openstack%2Fhorizon~master~I544d1b28b2397731f7e2e9058388edc0c45cd15a,openstack/horizon,master,I544d1b28b2397731f7e2e9058388edc0c45cd15a,"Change ""Add..."" to ""Add Users"" in Group Management",MERGED,2015-01-12 06:39:57.000000000,2015-01-13 20:51:45.000000000,2015-01-13 20:51:44.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4428}, {'_account_id': 7012}, {'_account_id': 8533}, {'_account_id': 9317}, {'_account_id': 9622}, {'_account_id': 10068}, {'_account_id': 12355}, {'_account_id': 12651}, {'_account_id': 14082}, {'_account_id': 14606}]","[{'number': 1, 'created': '2015-01-12 06:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d2adb76348ea596efa297f06ea80afad4bd5c988', 'message': 'This change addresses the UX improvement suggested in bug#1396326.  The button when adding new users to a group will change from ""Add..."" to ""Add Members"".\n\nBug Information can be found at: https://bugs.launchpad.net/horizon/+bug/1396326\nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}, {'number': 2, 'created': '2015-01-12 23:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0657d4be4bbfddd747bca9a3dca70f27f53088c6', 'message': 'This change addresses the UX improvement suggested in bug#1396326.  The button when adding new users to a group will change from ""Add..."" to ""Add Members"".\n\nBug Information can be found at: https://bugs.launchpad.net/horizon/+bug/1396326\nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}, {'number': 3, 'created': '2015-01-12 23:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aa531d14690baf07ce7e1efc1b7b69527c5af33b', 'message': 'Change ""Add"" to ""Add Members"" on button to Add Users to Group \n\nThe button being changed can be found under Horizon -> Identity -> Groups -> Manage Members (when Identity API v3 is enabled in local_settings.py).  The change was requested for UX enhancement.\n\n \nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}, {'number': 4, 'created': '2015-01-12 23:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3fb30fce7657db62335c3e491980537ae83170f2', 'message': 'Change ""Add"" to ""Add Members"" in Identity->Groups\n\nThe button being changed can be found under Horizon -> Identity ->\nGroups -> Manage Members (when Identity API v3 is enabled in\nlocal_settings.py).  The change was requested for UX enhancement.\n\n \nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}, {'number': 5, 'created': '2015-01-13 00:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/21a3d972a90fae52ff2cd2af8b378c3a5f8fc9dc', 'message': 'Change ""Add..."" to ""Add Users"" in Group Management\n\nThe button being changed can be found under Horizon -> Identity\n->\t9 Groups -> Manage Members (when Identity API v3 is enabled\nin\t10 local_settings.py).  The change was requested for UX\nenhancement.\n\nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}, {'number': 6, 'created': '2015-01-13 00:13:01.000000000', 'files': ['openstack_dashboard/dashboards/identity/groups/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e676c8dc72fcd44d7e8a56d3db59f7319e74d9e8', 'message': 'Change ""Add..."" to ""Add Users"" in Group Management\n\nThe button being changed can be found under Horizon -> Identity\n-> Groups -> Manage Members (when Identity API v3 is enabled\nin local_settings.py).  The change was requested for UX enhancement.\nCloses-Bug: 1396326\n\nChange-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a\n'}]",5,146383,e676c8dc72fcd44d7e8a56d3db59f7319e74d9e8,29,12,6,12651,,,0,"Change ""Add..."" to ""Add Users"" in Group Management

The button being changed can be found under Horizon -> Identity
-> Groups -> Manage Members (when Identity API v3 is enabled
in local_settings.py).  The change was requested for UX enhancement.
Closes-Bug: 1396326

Change-Id: I544d1b28b2397731f7e2e9058388edc0c45cd15a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/83/146383/6 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/identity/groups/tables.py'],1,d2adb76348ea596efa297f06ea80afad4bd5c988,bug/1396326," verbose_name = _(""Add Members"")"," verbose_name = _(""Add..."")",1,1
openstack%2Fkeystone~master~I6616812343f4477808a298b1449358dba75c5516,openstack/keystone,master,I6616812343f4477808a298b1449358dba75c5516,Updated from global requirements,MERGED,2015-01-13 00:03:59.000000000,2015-01-13 20:50:04.000000000,2015-01-13 20:50:03.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-01-13 00:03:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ff5256b8756fcb457e2b2b8d36b0532d994df7e8', 'message': 'Updated from global requirements\n\nChange-Id: I6616812343f4477808a298b1449358dba75c5516\n'}]",0,146694,ff5256b8756fcb457e2b2b8d36b0532d994df7e8,9,3,1,11131,,,0,"Updated from global requirements

Change-Id: I6616812343f4477808a298b1449358dba75c5516
",git fetch https://review.opendev.org/openstack/keystone refs/changes/94/146694/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ff5256b8756fcb457e2b2b8d36b0532d994df7e8,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fkeystone~master~I9f616d74e4777640cc9441e96f2bd8c1873aaaca,openstack/keystone,master,I9f616d74e4777640cc9441e96f2bd8c1873aaaca,Correct failures for H238,MERGED,2015-01-11 18:10:49.000000000,2015-01-13 20:49:54.000000000,2015-01-13 20:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6676}, {'_account_id': 7491}, {'_account_id': 7725}, {'_account_id': 9142}, {'_account_id': 13055}]","[{'number': 1, 'created': '2015-01-11 18:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dc4bf560e797867cddf1d354c24fb6f4c7fe4e46', 'message': 'Correct failures for H238\n\nThe new H238 ""old style class declaration, use new style (inherit\nfrom `object`)"" rule was failing and ignored. Now it\'s enforced.\n\nChange-Id: I9f616d74e4777640cc9441e96f2bd8c1873aaaca\n'}, {'number': 2, 'created': '2015-01-11 23:33:47.000000000', 'files': ['keystone/tests/core.py', 'keystone/assignment/backends/sql.py', 'keystone/identity/mapping_backends/mapping.py', 'keystone/tests/unit/common/test_notifications.py', 'keystone/controllers.py', 'keystone/tests/test_v3.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/02ec2dbb2f46fff75fe9fceebaf1c7db289f2f7d', 'message': 'Correct failures for H238\n\nThe new H238 ""old style class declaration, use new style (inherit\nfrom `object`)"" rule was failing and ignored. Now it\'s enforced.\n\nChange-Id: I9f616d74e4777640cc9441e96f2bd8c1873aaaca\n'}]",0,146335,02ec2dbb2f46fff75fe9fceebaf1c7db289f2f7d,15,8,2,6486,,,0,"Correct failures for H238

The new H238 ""old style class declaration, use new style (inherit
from `object`)"" rule was failing and ignored. Now it's enforced.

Change-Id: I9f616d74e4777640cc9441e96f2bd8c1873aaaca
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/146335/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/core.py', 'keystone/assignment/backends/sql.py', 'keystone/identity/mapping_backends/mapping.py', 'keystone/tests/unit/common/test_notifications.py', 'keystone/controllers.py', 'keystone/tests/test_v3.py', 'tox.ini']",7,dc4bf560e797867cddf1d354c24fb6f4c7fe4e46,hacking,"ignore = H405,H803","# New from hacking 0.10: H238 ignore = H238,H405,H803",9,10
openstack%2Fheat~master~I4f0e71e5c3d15c9510f060d3f7eadf58d6334309,openstack/heat,master,I4f0e71e5c3d15c9510f060d3f7eadf58d6334309,Add 'distributed' property for OS::Neutron::Router,MERGED,2014-12-25 02:45:13.000000000,2015-01-13 20:49:44.000000000,2015-01-13 20:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9453}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-25 02:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/887d4679773b49c5d32d314257570f0e89c7fbb8', 'message': ""Add 'distributed' property for OS::Neutron::Router\n\nImplement 'distributed' property for OS::Neutron::Router\nresource, to allow to create a distributed router.\n\nChange-Id: I4f0e71e5c3d15c9510f060d3f7eadf58d6334309\nCloses-Bug: #1405365\n""}, {'number': 2, 'created': '2014-12-29 09:43:36.000000000', 'files': ['heat/engine/resources/neutron/router.py', 'heat/tests/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/814a328af1255160941718d7a9e32c00b507b817', 'message': ""Add 'distributed' property for OS::Neutron::Router\n\nImplement 'distributed' property for OS::Neutron::Router\nresource, to allow to create a distributed router.\n\nChange-Id: I4f0e71e5c3d15c9510f060d3f7eadf58d6334309\nCloses-Bug: #1405365\n""}]",0,143921,814a328af1255160941718d7a9e32c00b507b817,17,9,2,8289,,,0,"Add 'distributed' property for OS::Neutron::Router

Implement 'distributed' property for OS::Neutron::Router
resource, to allow to create a distributed router.

Change-Id: I4f0e71e5c3d15c9510f060d3f7eadf58d6334309
Closes-Bug: #1405365
",git fetch https://review.opendev.org/openstack/heat refs/changes/21/143921/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/neutron/router.py', 'heat/tests/test_neutron.py']",2,887d4679773b49c5d32d314257570f0e89c7fbb8,bug/1405365," def test_router_validate(self): t = template_format.parse(neutron_template) props = t['Resources']['router']['Properties'] props['distributed'] = True stack = utils.parse_stack(t) rsrc = stack['router'] self.assertRaises(exception.ResourcePropertyConflict, rsrc.validate) 'distributed': False, ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8"", ""distributed"": False, ""distributed"": False, ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8"", ""distributed"": False, ""distributed"": False, ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8"", ""distributed"": False"," ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8"" ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8"" ""id"": ""3e46229d-8fce-4733-819a-b5fe630550f8""",37,5
openstack%2Fheat~master~Ied0099f545b0af484aefc50f3d5932111ca3fd0b,openstack/heat,master,Ied0099f545b0af484aefc50f3d5932111ca3fd0b,Deal with misconfigured cloud_backend,MERGED,2015-01-05 14:19:15.000000000,2015-01-13 20:48:23.000000000,2015-01-13 20:48:19.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7253}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-05 14:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7a6f8e85238aa2db08d02d7930ee7fbc7b3fcb1a', 'message': ""Tolerate misconfigured cloud_backend\n\nIn some rare cases, users may misconfigure 'cloud_backend' in heat.conf.\nThe result is that Heat cannot properly import the configured\nmodule/object.  This patch attempts to make Heat tolerate such kinds of\nerror configurations.\n\nAnother option is to throw an exception and stop, but I'm not sure if\nthat is the right solution here.\n\nCloses-Bug: 1279058\nChange-Id: Ied0099f545b0af484aefc50f3d5932111ca3fd0b\n""}, {'number': 2, 'created': '2015-01-07 03:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c7cf6e759103d8a65b097745cc7b089f7501ced', 'message': ""Deal with misconfigured cloud_backend\n\nIn some rare cases, users may misconfigure 'cloud_backend' in heat.conf.\nThe result is that Heat cannot properly import the configured\nmodule/object.  This patch attempts to make Heat throw exceptions that\ntells users what was wrong.\n\nCloses-Bug: 1279058\nChange-Id: Ied0099f545b0af484aefc50f3d5932111ca3fd0b\n""}, {'number': 3, 'created': '2015-01-09 04:58:53.000000000', 'files': ['heat/tests/test_clients.py', 'heat/engine/clients/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/28d9ba7de4cd90857eb647d88183b5e626ed7280', 'message': ""Deal with misconfigured cloud_backend\n\nIn some rare cases, users may misconfigure 'cloud_backend' in heat.conf.\nThe result is that Heat cannot properly import the configured\nmodule/object.  This patch makes Heat throw exceptions that inform users\nof correct error messages and also log errors for operators.\n\nCloses-Bug: 1279058\nChange-Id: Ied0099f545b0af484aefc50f3d5932111ca3fd0b\n""}]",1,144989,28d9ba7de4cd90857eb647d88183b5e626ed7280,19,9,3,8246,,,0,"Deal with misconfigured cloud_backend

In some rare cases, users may misconfigure 'cloud_backend' in heat.conf.
The result is that Heat cannot properly import the configured
module/object.  This patch makes Heat throw exceptions that inform users
of correct error messages and also log errors for operators.

Closes-Bug: 1279058
Change-Id: Ied0099f545b0af484aefc50f3d5932111ca3fd0b
",git fetch https://review.opendev.org/openstack/heat refs/changes/89/144989/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_clients.py', 'heat/engine/clients/__init__.py']",2,7a6f8e85238aa2db08d02d7930ee7fbc7b3fcb1a,bug/1279058,"import six try: return importutils.import_object(cfg.CONF.cloud_backend, context) except ImportError as err: LOG.warn(_LW('Invalid cloud_backend in heat.conf detected (' '%s), falling back to default backend.' ), six.text_type(err)) return OpenStackClients(context)"," return importutils.import_object( cfg.CONF.cloud_backend, context )",18,4
openstack%2Fkeystone~master~Ifaf62839a4b6da62a3b380396158b463c1381026,openstack/keystone,master,Ifaf62839a4b6da62a3b380396158b463c1381026,Move to hacking 0.10,MERGED,2015-01-11 17:55:32.000000000,2015-01-13 20:47:19.000000000,2015-01-13 20:47:14.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6676}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-01-11 17:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8c754ea5b1b3edbe20913060a8030f3776f77700', 'message': 'Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\nChange-Id: Ifaf62839a4b6da62a3b380396158b463c1381026\n'}, {'number': 2, 'created': '2015-01-11 23:30:49.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/12b6538fcc3ebb1d6b1c0c39f05c9f51a7889bbb', 'message': 'Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\nPer the release notes, H803 has been removed.\n\nChange-Id: Ifaf62839a4b6da62a3b380396158b463c1381026\n'}]",0,146334,12b6538fcc3ebb1d6b1c0c39f05c9f51a7889bbb,14,6,2,6486,,,0,"Move to hacking 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

Per the release notes, H803 has been removed.

Change-Id: Ifaf62839a4b6da62a3b380396158b463c1381026
",git fetch https://review.opendev.org/openstack/keystone refs/changes/34/146334/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,8c754ea5b1b3edbe20913060a8030f3776f77700,hacking,"# New from hacking 0.10: H238 ignore = H238,H405,H803","ignore = H405,H803",3,2
openstack%2Fbarbican~master~Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab,openstack/barbican,master,Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab,Make default action return 405 in the controllers,MERGED,2015-01-02 12:49:38.000000000,2015-01-13 20:44:02.000000000,2015-01-13 20:44:01.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-01-02 12:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/992754bfd0d8de7225aef7975d94d9bd694df4a8', 'message': ""Make default action return 405 in the controllers\n\nNow the default action that controllers will take is HTTP 405 (Not\nAllowed) as stated in the pecan's recommended approach. This means\nthat there is now a separate method in the controllers that\nspecifically handles HTTP GET.\n\nChange-Id: Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab\nCloses-bug: #1334872\n""}, {'number': 2, 'created': '2015-01-05 14:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/880e992dd4341463439edbff4f3a5a7ddf3639c8', 'message': ""Make default action return 405 in the controllers\n\nNow the default action that controllers will take is HTTP 405 (Not\nAllowed) as stated in the pecan's recommended approach. This means\nthat there is now a separate method in the controllers that\nspecifically handles HTTP GET.\n\nChange-Id: Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab\nCloses-bug: #1334872\n""}, {'number': 3, 'created': '2015-01-07 15:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4b610ede44a52520a622afa9bccbcd5a055ee558', 'message': ""Make default action return 405 in the controllers\n\nNow the default action that controllers will take is HTTP 405 (Not\nAllowed) as stated in the pecan's recommended approach. This means\nthat there is now a separate method in the controllers that\nspecifically handles HTTP GET.\n\nChange-Id: Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab\nCloses-bug: #1334872\n""}, {'number': 4, 'created': '2015-01-09 11:32:09.000000000', 'files': ['barbican/api/controllers/orders.py', 'barbican/api/controllers/transportkeys.py', 'barbican/api/controllers/secrets.py', 'barbican/tests/api/test_resources_policy.py', 'barbican/api/controllers/versions.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/d0949ae360f71002bd06045c64218572df41ec02', 'message': ""Make default action return 405 in the controllers\n\nNow the default action that controllers will take is HTTP 405 (Not\nAllowed) as stated in the pecan's recommended approach. This means\nthat there is now a separate method in the controllers that\nspecifically handles HTTP GET.\n\nChange-Id: Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab\nCloses-bug: #1334872\n""}]",2,144743,d0949ae360f71002bd06045c64218572df41ec02,21,13,4,10873,,,0,"Make default action return 405 in the controllers

Now the default action that controllers will take is HTTP 405 (Not
Allowed) as stated in the pecan's recommended approach. This means
that there is now a separate method in the controllers that
specifically handles HTTP GET.

Change-Id: Ib9291d4d4216f577e3f7af0fda5fa6dfe2f53cab
Closes-bug: #1334872
",git fetch https://review.opendev.org/openstack/barbican refs/changes/43/144743/4 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/controllers/orders.py', 'barbican/api/controllers/transportkeys.py', 'barbican/api/controllers/secrets.py', 'barbican/tests/api/test_resources_policy.py', 'barbican/api/controllers/versions.py', 'barbican/api/controllers/consumers.py', 'barbican/api/controllers/containers.py']",7,992754bfd0d8de7225aef7975d94d9bd694df4a8,bug/1334872," @pecan.expose(generic=True) def index(self, keystone_id, **kwargs): pecan.abort(405) # HTTP 405 Method Not Allowed as defalt @index.when(method='GET', template='json') def on_get(self, keystone_id): @pecan.expose(generic=True) def index(self, keystone_id, **kwargs): pecan.abort(405) # HTTP 405 Method Not Allowed as defalt @index.when(method='GET', template='json') def on_get(self, project_id, **kw):"," @pecan.expose(generic=True, template='json') def index(self, keystone_id): @pecan.expose(generic=True, template='json') def index(self, project_id, **kw):",66,22
openstack%2Fbarbican~master~I32c958ec70d963d79c287d4720b67120b9f3d8d6,openstack/barbican,master,I32c958ec70d963d79c287d4720b67120b9f3d8d6,Adding client certificates to connection credentials,MERGED,2014-11-18 10:36:10.000000000,2015-01-13 20:43:22.000000000,2015-01-13 20:43:17.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 6783}, {'_account_id': 6802}, {'_account_id': 7063}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7764}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-11-18 10:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/952ddc0de3b810de3edb990ee18b964d7b0f7099', 'message': 'Adding client certificates to connection credentials.\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 2, 'created': '2014-11-18 11:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/bcb1905a2b0b870a79aceee9abb0b2940827d8c7', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 3, 'created': '2014-11-19 12:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3c0002d0500839d6945302a9e6285f0ddaae77d2', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 4, 'created': '2014-11-24 11:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/da404ebc76bfde626c01f883701eeb9208356c64', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 5, 'created': '2014-11-24 12:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a63f25c8d8ef42f2649e4930a7fd86b842197c0b', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 6, 'created': '2014-11-24 14:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6287ca53f6a3c06a138c88253cf35749a4995639', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 7, 'created': '2014-12-05 15:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/389a3960ab802d83f05da3f5a4f61eb91370653f', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 8, 'created': '2014-12-08 12:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/55850cba211a4143353a5ab2e1c4882ac5dfba84', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 9, 'created': '2014-12-09 14:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b38b28880c06e665c3c4765e7ee9170d8e116714', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 10, 'created': '2014-12-09 15:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/883298020f46bbe0105b1e4a3006c3e3f6eee3cc', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\n'}, {'number': 11, 'created': '2014-12-09 16:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/dcf2cebae59f67aa246c8b98225611ff91154641', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 12, 'created': '2014-12-16 12:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4bef0a4edff9e9ef6b5c2b9de63e4c8c1dc4ef18', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 13, 'created': '2014-12-18 12:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ef367822657146a145f524ad01cfdf0e5ecd0b1c', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 14, 'created': '2015-01-13 13:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/da04ec014247d87c171f510ec77fe11c6bbf9789', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 15, 'created': '2015-01-13 14:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5b004dbf94d9e1b0a486f98fac6456265183a53c', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 16, 'created': '2015-01-13 15:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fab35f7ac298627589fd109dcc8a1ca015a74be2', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 17, 'created': '2015-01-13 15:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ed5b2a1827dfb4254d0e295b4ba434fbbaabd9b4', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}, {'number': 18, 'created': '2015-01-13 15:51:00.000000000', 'files': ['barbican/tests/plugin/test_kmip.py', 'etc/barbican/barbican-api.conf', 'barbican/plugin/kmip_secret_store.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican/commit/ac161fc45661c30cf8f8049d93105e001e986551', 'message': 'Adding client certificates to connection credentials\n\n- this changes requires PyKMIP 0.2.0\n\nChange-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6\nAlso-By: Robert Clark <robert.clark@hp.com>\n'}]",41,135217,ac161fc45661c30cf8f8049d93105e001e986551,90,14,18,11716,,,0,"Adding client certificates to connection credentials

- this changes requires PyKMIP 0.2.0

Change-Id: I32c958ec70d963d79c287d4720b67120b9f3d8d6
Also-By: Robert Clark <robert.clark@hp.com>
",git fetch https://review.opendev.org/openstack/barbican refs/changes/17/135217/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/barbican-api.conf', 'barbican/plugin/kmip_secret_store.py']",2,952ddc0de3b810de3edb990ee18b964d7b0f7099,kmip-certs," ), cfg.StrOpt('cert_file', default=None, help=u._('File path to local client certificate'), ), cfg.StrOpt('key_file', default=None, help=u._('File path to local client certificate keyfile'), ca_certs=conf.kmip_plugin.ca_certs, certfile=conf.kmip_plugin.cert_file, keyfile=conf.kmip_plugin.key_file, username=conf.kmip_plugin.username, password=conf.kmip_plugin.password)", ca_certs=conf.kmip_plugin.ca_certs),17,1
openstack%2Fqa-specs~master~Iede4e99ee047cd7c1c969aecc07ae4976f1f9767,openstack/qa-specs,master,Iede4e99ee047cd7c1c969aecc07ae4976f1f9767,Add DevStack Logging and Service Names spec,MERGED,2014-12-10 21:58:12.000000000,2015-01-13 20:42:53.000000000,2015-01-13 20:42:52.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 21:58:12.000000000', 'files': ['doc/source/index.rst', 'specs/devstack/devstack-logging-and-service-names.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/35ab7532305ae23a59226563d53b20d913c16039', 'message': 'Add DevStack Logging and Service Names spec\n\nChange-Id: Iede4e99ee047cd7c1c969aecc07ae4976f1f9767\n'}]",3,140843,35ab7532305ae23a59226563d53b20d913c16039,11,5,1,970,,,0,"Add DevStack Logging and Service Names spec

Change-Id: Iede4e99ee047cd7c1c969aecc07ae4976f1f9767
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/43/140843/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/devstack/devstack-logging-and-service-names.rst']",2,35ab7532305ae23a59226563d53b20d913c16039,ds-log,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/tempest/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html =================================== DevStack Logging and Service Names =================================== `NOTE: This spec is still a work in progress, it is being posted to get some early feedback on scope and ordering of steps.` https://blueprints.launchpad.net/tempest/+spec/devstack-logging-and-service-names DevStack is in need of updates to its log file handling and service naming, both of which were appropriate for the originalscreen-based installs with a handful of services. This spec contains both the log file reform as well as the service name updates as they are a bit intertwined so some steps will address them both as necessary. Problem description =================== DevStack's logging configuration was initially based on saving ``screen`` logs, as part of the development of not using ``screen`` the logging was kept compatible and it became obvious that the original special case was not required. Historically DevStack has used abbreviated service names for identifying services to enable, naming log files and as window names in screen. OpenStack has grown to the point that the abbreviated names are too confusing and non-obvious, especially for the not-so-recently renamed Neutron. These topics were covered at the Paris summit, notes in the `OpenStack Etherpad`_. .. _`OpenStack Etherpad`: https://etherpad.openstack.org/p/kilo-summit-devstack-grenade Proposed change =============== Logging ------- Update DevStack's logging configuration to set a logging directory rather than parsing that out of a filename. Ultimately eliminate the use of ``SCREEN_LOGDIR``. * Use ``LOGDIR`` as the primary setting in local.conf for log locations, default to ``${DEST}/logs`` if ``LOGFILENAME`` is not set. * Continue to use ``LOGFILENAME`` if set, if ``LOGFILE`` is not set continue to set it to $(dirname ``$LOGFILENAME``). * Deprecate ``SCREEN_LOGDIR`` and use ``LOGDIR`` instead. For a compatibility period leave symlinks in the old screen log locations. * Remove ``screen-`` from the beginning of the service log filenames * Service log files will implicitly be renamed as the service names change (see above) Grenade should work seamlessly as it lets both DevStack runs do their thing and ``devstack-gate`` contains all of the specifics that need updating fro Grenade jobs. Service Names ------------- Use fully-formed names for service names (like ceilometer does today): ``nova-compute``, ``glance-registry``, etc. The names will use the project name, as used in ``devstack/lib/*`` followed by '-' and a descriptive name of the service. Also allow multiple instances of service names, as in running the fake hypervisor has a number of ``nova-cpu`` instances. Append an instance counter to the name similar to how ``n-cpu-N`` is currently handled. Optionally use a ':' as the separator between the service name and instance number. This will be used in the log file name so it must be shell-safe. * There needs to be a mapping of the old abbreviated names to the full names to handle backward compatibility. * This will make ``ENABLED_SERVICES`` very long by default and harder to scan visually. Is this a real concern? With the recent forced update to using Bash 4 we could use an associative array to do the mapping and the enabled list in a single shot. (Note: We just started doing something in Grenade to handle mapping abbreviated service names-> processes (https://review.openstack.org/#/c/113405/5/check-sanity) This would help move that logic into DevStack and also help provide other mappings (ie, service name -> database name)) * Log filenames will change, but there is more on that front (see below). * Grenade will need to be updated before the backward compatibility can be removed. Implementation ============== Assignee(s) ----------- Primary assignee: dtroyer Work Items ---------- 1. Logging: change the log file names in ``SCREEN_LOGDIR`` so the actual files with the timestamp in the names end with the timestamp:: screen-c-sch.2014-12-10-193405.log becomes screen-c-sch.log.2014-12-10-193405 2. Logging: change ``devstack-gate`` to look for ``*.log`` rather than symlinks to select the log files it copies out of ``screen-logs``. 3. Logging: switch from ``SCREEN_LOGDIR`` to ``LOGDIR`` for log tests. This will move the log files out of ``SCREEN_LOGDIR`` so leave backward-compatibility symlinks in the old locations. (This is the reason for #2 as ``devstack-gate`` selects the files top copy by the symlink attribute.) 4. Logging: follow up in ``devstack-gate`` to use LOGDIR directly and copy log files from there. 5. Logging: after a time, remove the symlinks from ``SCREEN_LOGDIR``. 6. Services: change how multiple instances of services are handled, currently in ``lib/nova start_nova_compute()`` and ``stop_nova_compute()``. If the separator is changed the config filenames will also change, reconsider if parsing is necessary. 7. Services: build the new service naming structures and compatibility. 8. Services and Logging: switch logging to use the new service names and ensure nothing gets lost in ``devstack-gate`` copies. Dependencies ============ The only dependencies are in the order of changes required in multiple projects. ",,148,1
openstack%2Fopenstack-specs~master~I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256,openstack/openstack-specs,master,I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256,Log Guidelines,MERGED,2014-11-03 12:13:24.000000000,2015-01-13 20:42:07.000000000,2015-01-13 20:42:06.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 170}, {'_account_id': 308}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 1207}, {'_account_id': 1921}, {'_account_id': 2243}, {'_account_id': 2271}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2537}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 2903}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 5174}, {'_account_id': 6172}, {'_account_id': 6486}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 6794}, {'_account_id': 6816}, {'_account_id': 6926}, {'_account_id': 6928}, {'_account_id': 7198}, {'_account_id': 7567}, {'_account_id': 7849}, {'_account_id': 8434}, {'_account_id': 8688}, {'_account_id': 10342}, {'_account_id': 11351}, {'_account_id': 11904}, {'_account_id': 12000}, {'_account_id': 12321}, {'_account_id': 12807}, {'_account_id': 12826}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-11-03 12:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/fc746846012dd88514b99bccc46a292d9ecdc52e', 'message': 'Log Guidelines\n\nDraft logging guidelines for OpenStack. This evolved originally in the\nnova-specs repo at: I674966988ed501dee323a106b84b5b6602d846b1 but is\nnow moved over to cross project specs repo.\n\nPart of bp:log-guidelines\n\nChange-Id: I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256\n'}, {'number': 2, 'created': '2014-11-24 13:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/bfa870b937f7bcc36d88d09c44f59f9889e00050', 'message': 'Log Guidelines\n\nDraft logging guidelines for OpenStack. This evolved originally in the\nnova-specs repo at: I674966988ed501dee323a106b84b5b6602d846b1 but is\nnow moved over to cross project specs repo.\n\nPart of bp:log-guidelines\n\nChange-Id: I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256\n'}, {'number': 3, 'created': '2015-01-06 14:30:22.000000000', 'files': ['specs/log-guidelines.rst'], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/f699e8623847ead07d11ed03425b11915057c45c', 'message': 'Log Guidelines\n\nProposed final draft.\n\nThis attempts to integrate much of the existing feedback, including\nclarity around the points that were confusing people regarding the\n""unit of work"" and when stacktraces are appropriate.\n\nIn addition the Security logging section was dropped, because\nrealistically it was a poor fit for this original document. The wiki\npage on it remains. My expectation is that security for logging should\nbe proposed as a follow on patch by someone that wants to make that\ninfo fit well with this document.\n\nAll the open questions are now removed. Hopefully this ends up very\nclose to an agreed point.\n\nNote: This evolved originally in the nova-specs repo at:\nI674966988ed501dee323a106b84b5b6602d846b1 but is now moved over to\ncross project specs repo. Some deep history can be seen at the\noriginal draft.\n\nPart of bp:log-guidelines\n\nChange-Id: I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256\n'}]",90,132552,f699e8623847ead07d11ed03425b11915057c45c,74,41,3,2750,,,0,"Log Guidelines

Proposed final draft.

This attempts to integrate much of the existing feedback, including
clarity around the points that were confusing people regarding the
""unit of work"" and when stacktraces are appropriate.

In addition the Security logging section was dropped, because
realistically it was a poor fit for this original document. The wiki
page on it remains. My expectation is that security for logging should
be proposed as a follow on patch by someone that wants to make that
info fit well with this document.

All the open questions are now removed. Hopefully this ends up very
close to an agreed point.

Note: This evolved originally in the nova-specs repo at:
I674966988ed501dee323a106b84b5b6602d846b1 but is now moved over to
cross project specs repo. Some deep history can be seen at the
original draft.

Part of bp:log-guidelines

Change-Id: I3a8d0ac570e05eb11ccc70ad4eb9da277aaac256
",git fetch https://review.opendev.org/openstack/openstack-specs refs/changes/52/132552/1 && git format-patch -1 --stdout FETCH_HEAD,['kilo/log-guidelines.rst'],1,fc746846012dd88514b99bccc46a292d9ecdc52e,bp/log-guidelines,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Logging Guidelines ========================================== https://blueprints.launchpad.net/nova/+spec/log-guidelines Problem description =================== The current state of logging both within, and between OpenStack components is inconsistent to the point of being somewhat harmful by obscuring the current state, function, and real cause of errors in an OpenStack cloud. In order to make OpenStack clouds possible for non super powered enabled humans to debug, which should make this better. Before we can address this in OpenStack, we first need to come up with a set of guidelines that we can get broad agreement on. This is expected to happen in waves, and this is the first iteration to gather agreement on. Proposed change =============== Definition of Log Levels ------------------------ http://stackoverflow.com/a/2031209 This is a nice writeup about when to use each log level. Here is a brief description: - Debug: Shows everything and is likely not suitable for normal production operation due to the sheer size of logs generated - Info: Usually indicates successful service start/stop, versions and such non-error related data. This should include largely positive units of work that are accomplished (such as starting a compute, creating a user, deleting a volume, etc.) - Audit: REMOVE - (all previous Audit messages should be put as INFO) - Warning: Indicates that there might be a systemic issue; potential predictive failure notice - Error: An error has occurred and an administrator should research the event - Critical: An error has occurred and the system might be unstable; immediately get administrator assistance We can think of this from an operator perspective the following ways (Note: we are not specifying operator policy here, just trying to set tone for developers that aren't familiar with how these messages will be interpretted): - Critical : ZOMG! Cluster on FIRE! Call all pagers, wake up everyone. This is an unrecoverable error with a service that has or probably will lead to service death or massive degredation. - Error: Serious issue with cloud, administrator should be notified immediately via email/pager. On call people expected to respond. - Warning: Something is not right, should get looked into during the next work week. Administrators should be working through eliminating warnings as part of normal work. - Info: normal status messages showing measureable units of positive work passing through under normal functioning of the system. Should not be so verbose as to overwhelm real signal with noise. Should not be continuous ""I'm alive!"" messages. Proposed Changes From Status Quo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - Deprecate and remove AUDIT level Rationale, AUDIT is confusing, and people use it for entirely the wrong purposes. The origin of AUDIT was a NASA specific requirement which is not longer really relevant to the current code. Information that was previously being emitted at AUDIT should instead be sent as notifications to a notification queue. *Note: Notification formats and frequency are beyond the scope of this spec.* Open Question: Logger Name Standardization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In OpenStack code today, most loggers are created via: :: LOG = logging.getLogger(__name__) While this is useful for DEBUG levels, it's actually quite confusing for INFO and above levels and leads to output like: :: 2014-04-25 18:49:21.546 INFO nova.virt.libvirt.firewall [req-87280286-8964-46f3-9e8d-d55d7ecf6ebd ServersAdminTestXML-1606495100 ServersAdminTestXML-1617692500] [instance: 6e51a557-cde5-43e5-9e0f-5321158bee2a] Ensuring static filters 2014-04-25 18:49:22.217 INFO nova.virt.libvirt.driver [req-b20fe944-28f4-4076-8394-0a8e33554e14 ServersAdminTestJSON-492015978 ServersAdminTestJSON-253173963] [instance: b3efe38b-82fd-4798-b36f-b1a0c302a00d] Creating image 2014-04-25 18:49:22.400 INFO nova.virt.libvirt.driver [req-b20fe944-28f4-4076-8394-0a8e33554e14 ServersAdminTestJSON-492015978 ServersAdminTestJSON-253173963] [instance: b3efe38b-82fd-4798-b36f-b1a0c302a00d] Using config drive 2014-04-25 18:49:22.409 INFO nova.compute.manager [req-c234703f-60ac-4233-8d5b-0ee297288900 FixedIPsTestJson-1879416564 FixedIPsTestJson-1390666706] [instance: ae31b4f6-18d2-46b6-94d9-2f116d825db0] Terminating instance Where the code implementation details on what module is used leak through to the operator. This may or may not be considered useful. This remains an open question about whether python module implementations should be in the logs vs. service names (i.e. nova-compute, nova-sched, nova-os-api, nova-ec2-api). Overall Logging Rules --------------------- The following principles should apply to all messages Log messages should be a unit of work ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack services are typically multiworker so the immediate lines above and below a log message may not be related at all to the message that was printed. As such all messages should be a complete unit of work with enough context to know what happened with just that message. DEBUG messages may be more trace oriented, however they still need to provide enough context that their operation can be determined from a single log message. In a real environment there may be tens, hundreds, or even thousands of workers all processing content at the same time to the same log stores, and without fully contained message context piecing the flows back together may be very difficult. **Good** :: 2014-01-26 15:36:10.597 28297 INFO nova.virt.libvirt.driver [-] [instance: b1b8e5c7-12f0-4092-84f6-297fe7642070] Instance spawned successfully. 2014-01-26 15:36:14.307 28297 INFO nova.virt.libvirt.driver [-] [instance: b1b8e5c7-12f0-4092-84f6-297fe7642070] Instance destroyed successfully. **Bad** :: 2014-01-26 15:36:11.198 INFO nova.virt.libvirt.driver [req-ded67509-1e5d-4fb2-a0e2-92932bba9271 FixedIPsNegativeTestXml-1426989627 FixedIPsNegativeTestXml-38506689] [instance: fd027464-6e15-4f5d-8b1f-c389bdb8772a] Creating image 2014-01-26 15:36:11.525 INFO nova.virt.libvirt.driver [req-ded67509-1e5d-4fb2-a0e2-92932bba9271 FixedIPsNegativeTestXml-1426989627 FixedIPsNegativeTestXml-38506689] [instance: fd027464-6e15-4f5d-8b1f-c389bdb8772a] Using config drive 2014-01-26 15:36:12.326 AUDIT nova.compute.manager [req-714315e2-6318-4005-8f8f-05d7796ff45d FixedIPsTestXml-911165017 FixedIPsTestXml-1315774890] [instance: b1b8e5c7-12f0-4092-84f6-297fe7642070] Terminating instance 2014-01-26 15:36:12.570 INFO nova.virt.libvirt.driver [req-ded67509-1e5d-4fb2-a0e2-92932bba9271 FixedIPsNegativeTestXml-1426989627 FixedIPsNegativeTestXml-38506689] [instance: fd027464-6e15-4f5d-8b1f-c389bdb8772a] Creating config drive at /opt/stack/data/nova/instances/fd027464-6e15-4f5d-8b1f -c389bdb8772a/disk.config This is mostly an overshare issue. At Info these are stages that don't really need to be fully communicated. Messages shouldn't need a secret decoder ring ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ **Bad** :: 2014-01-26 15:36:14.256 28297 INFO nova.compute.manager [-] Lifecycle event 1 on VM b1b8e5c7-12f0-4092-84f6-297fe7642070 General rule, when using constants or enums ensure they are translated back to user strings prior to being sent to the user. Specific Event Types -------------------- Inbound WSGI requests ~~~~~~~~~~~~~~~~~~~~~ Should be: - Logged at **INFO** level - Logged exactly once per request - Include enough information to know what the request was Operator Deprecation Warnings ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Should be: - Logged at **WARN** level - Logged exactly once per service start (not on every request through code) - Include directions on what to do to migrate from the deprecated state REST API Deprecation Warnings ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Should be: - **Not** logged any higher than DEBUG (these are not operator facing messages) - Logged no more than once per REST API usage / tenant. Definitely not on *every* REST API call. Stacktraces in Logs ~~~~~~~~~~~~~~~~~~~ Stacktraces in logs should be an exceptional event for a completely unforeseeable circumstance that is not yet recoverable by the system. As such during normal behavior there should be no stack traces in the system. Any that arise should be filed as high priority bugs and be fixed as soon as possible. Logging by non-OpenStack Components ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack uses a ton of libraries, which have their own definitions of logging. This causes a lot of extraneous information in normal logs by wildly different definitions of those libraries. As such, all 3rd party libraries should have their logging levels adjusted so only real errors are logged. Currently proposed settings for 3rd party libraries: - amqp=WARN - boto=WARN - qpid=WARN - sqlalchemy=WARN - suds=INFO - iso8601=WARN - requests.packages.urllib3.connectionpool=WARN Security Guidelines ~~~~~~~~~~~~~~~~~~~ Logs should have a format that enables grouping of confidential data especially when logging data such as: - Passwords: Never log plain text passwords - Private Keys: Never log plain text private keys If the log message will also be used in an end user response (via a REST response of some sort, or logged in a database where the end user will have access to it), then additional measures should be taken, such as: - Exceptions: Unless the developer is sure that an exception will never contain confidential information, exceptions should be identified as confidential. This has historically been especially problematic with database exceptions which may contain real field data. - Recommend parsing the specific exception or error and providing an abstracted/safe version back to the user - PII: Minimize Personally Identifiable Information (PII) logging where possible - Tenant/Project ID Checking: If a user identifier (tenant/project ID) is not present in the log record or does not match the current authenticated user, do not show this log data to the user - Log Insecure Configurations: If a configuration option causes the system to enter a potentially less secure state, log a message to this effect for operators to see OpenStack's Oslo Log is capable of creating formatted logs with a section for confidential data. The following example contains two pieces of variable data: key_name which is not confidential data (and will equal 'ssh') and key_value which is a confidential key that should not be visible to anyone but admins/operators. Note: This is a contrived example for simplicity. If the key_value is a public ssh key, it probably isn't critical to hide it in the logs from the authorized user that it belongs to. If the key_value is a private ssh key, it shouldn't be logged to begin with. Bad Example: :: LOG.debug(""User set %s key to value %s"" % [key_name, key_value]) Revised/Good Example: :: LOG.debug(""User set %s key"" % [key_name], extra={private={value=key_value}}) Note that the extra->private structure is used to hold all confidential data within logs so that it may be filtered out later before a user views logs. In this example, the key value is moved to a 'private' dictionary which makes filtering out confidential data from logs easier as there will be a single keyword to locate in log entries if these guidelines are followed. An authenticated user may see that an ssh key has been changed but an operator may see the actual ssh key value in the logs. Alternatives ------------ Continue to have terribly confusing logs Data model impact ----------------- NA REST API impact --------------- NA Security impact --------------- NA Notifications impact -------------------- NA Other end user impact --------------------- NA Performance Impact ------------------ NA Other deployer impact --------------------- Should provide a much more standard way to determine what's going on in the system. Developer impact ---------------- Developers will need to be cognizant of these guidelines in creating new code or reviewing code. Implementation ============== Assignee(s) ----------- Assignee is for moving these guidelines through the review process to something that we all agree on. The expectation is that these become review criteria that we can reference and are implemented by a large number of people. Once approved, will also drive collecting volunteers to help fix in multiple projects. Primary assignee: Sean Dague <sean@dague.net> Work Items ---------- Using this section to highlight things we need to decide that aren't settled as of yet. Proposed changes with general consensus - Drop AUDIT log level, move AUDIT message to INFO - Begin adjusting log levels within projects to match the severity guidelines. Proposed changes *without* general consensus - Logger naming. There just wasn't much feedback yet. Dependencies ============ NA Testing ======= See tests provided by https://blueprints.launchpad.net/nova/+spec/clean-logs Documentation Impact ==================== Once agreed upon this should form a more permanent document on logging specifications. References ========== - Security Log Guidelines - https://wiki.openstack.org/wiki/Security/Guidelines/logging_guidelines - Wiki page for basic logging standards proposal developed early in Icehouse - https://wiki.openstack.org/wiki/LoggingStandards ",,415,0
openstack%2Fneutron~master~I65909040a16b022108e481344064d375050d731c,openstack/neutron,master,I65909040a16b022108e481344064d375050d731c,Validate legacy router services before migration,MERGED,2014-09-22 22:44:15.000000000,2015-01-13 20:26:44.000000000,2015-01-13 09:24:06.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 2031}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6995}, {'_account_id': 7016}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10354}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-22 22:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/767bf11f73109778328853fa49fb23b1a4564afb', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 2, 'created': '2014-09-23 17:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9db0e56248c021498ebddef01f21c414bf82c03c', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 3, 'created': '2014-09-24 18:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a73be3c533266560aae2bc9a530d179c615d6a8', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 4, 'created': '2014-09-24 19:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/152ef86262172e38a34e9a704d17123a0dee146d', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 5, 'created': '2014-09-24 22:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d4970465cdc0c51b454c9473bb7f9f635556e2b', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 6, 'created': '2014-09-25 00:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5807407671f46e7cd8dcdbace9051668d625787f', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 7, 'created': '2014-09-25 17:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63b48c6a14a18947e4ffea8b588519544585ac5d', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 8, 'created': '2014-11-25 23:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04659825d787539d4a3a983deb66d19c16cbca75', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 9, 'created': '2014-12-05 20:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad714bf51006e14b657895c959f32c3375992e82', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 10, 'created': '2014-12-05 20:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b902adfa9484b2c4b961035f43d4f03e769e138', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 11, 'created': '2014-12-17 22:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfc802d21603eceff3d94d20742e5eebe657dd5f', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 12, 'created': '2015-01-05 21:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fab7afd282c92a209ee4071ccdb8441c397de57d', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nDocImpact\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}, {'number': 13, 'created': '2015-01-09 00:28:53.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c41f4a397dc32efa39a0fcce2131caa46692cb03', 'message': 'Validate legacy router services before migration\n\nWhen legacy routers are migrated to distributed\nrouters, we need to make sure that there are no\nAdvanced services associated with the router.\n\nIf Advanced services such as FWaaS or VPNaaS is\nassociated with the router, we raise an exception\nand stop the migration.\n\nPartial-bug: #1348309\n\nDocImpact\n\nChange-Id: I65909040a16b022108e481344064d375050d731c\n'}]",46,123273,c41f4a397dc32efa39a0fcce2131caa46692cb03,381,42,13,7016,,,0,"Validate legacy router services before migration

When legacy routers are migrated to distributed
routers, we need to make sure that there are no
Advanced services associated with the router.

If Advanced services such as FWaaS or VPNaaS is
associated with the router, we raise an exception
and stop the migration.

Partial-bug: #1348309

DocImpact

Change-Id: I65909040a16b022108e481344064d375050d731c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/123273/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/db/l3_dvr_db.py']",2,767bf11f73109778328853fa49fb23b1a4564afb,bug/current-service-validation-migration,"from neutron.extensions import firewallfrom neutron.extensions import vpnaas def _validate_router_migration(self, context, router_db, router_res): # This check below ensures that the legacy routers with # associated VPNaaS or FWaaS services are not allowed to # migrate. if (self.check_if_router_has_vpnaas(context, router_db) and self.check_if_router_has_firewall(context, router_db)): router_db['status'] = ( l3_const.ROUTER_STATUS_LEGACY_TO_DVR) def check_if_router_has_firewall(self, context, router_db): """"""Check if FWaaS is associated with the legacy router."""""" fwaas_service = manager.NeutronManager.get_service_plugins().get( constants.FIREWALL) if fwaas_service: fw_count = fwaas_service.get_firewalls_count( context, filters={'tenant_id': [router_db['tenant_id']]}) if fw_count: raise firewall.FirewallInUse(firewall_id=router_db['id']) else: return True else: return True def check_if_router_has_vpnaas(self, context, router_db): """"""Check if VPNaaS is associated with the legacy router."""""" vpn_plugin = manager.NeutronManager.get_service_plugins().get( constants.VPN) if vpn_plugin: vpnservices = vpn_plugin.get_vpnservices( context, filters={'router_id': [router_db['id']]}) if vpnservices: raise vpnaas.RouterInUseByVPNService( router_id=router_db['id'], vpnservice_id=vpnservices[0]['id']) else: return True self._validate_router_migration(context, router_db, data)"," def _validate_router_migration(self, router_db, router_res): router_db['status'] = ( l3_const.ROUTER_STATUS_LEGACY_TO_DVR) self._validate_router_migration(router_db, data)",139,10
openstack%2Fmagnum~master~I8a061d97757d5284c277675c46c416a88b64d895,openstack/magnum,master,I8a061d97757d5284c277675c46c416a88b64d895,Enable kube.py get k8s api server port from baymodel,MERGED,2015-01-13 13:35:36.000000000,2015-01-13 20:17:33.000000000,2015-01-13 20:17:32.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2834}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 13:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d6ba72a8f6865db940f486a56bf413f12bc323df', 'message': 'Remove k8s_port from kube.py\n\nEnable kube.py get k8s api server port from baymodel.\n\nImplements part of bp override-native-rest-port\n\nChange-Id: I8a061d97757d5284c277675c46c416a88b64d895\n'}, {'number': 2, 'created': '2015-01-13 13:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6005616332eeb3dd4587fa602074dfcf66b85913', 'message': 'Remove k8s_port from kube.py\n\nEnable kube.py get k8s api server port from baymodel.\n\nImplements part of bp override-native-rest-port\n\nChange-Id: I8a061d97757d5284c277675c46c416a88b64d895\n'}, {'number': 3, 'created': '2015-01-13 15:19:17.000000000', 'files': ['magnum/tests/conductor/handlers/test_kube.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1c5361304d952d311b23bcc80c6a1d994414cae6', 'message': 'Enable kube.py get k8s api server port from baymodel\n\nImplements part of bp override-native-rest-port\n\nChange-Id: I8a061d97757d5284c277675c46c416a88b64d895\n'}]",7,146859,1c5361304d952d311b23bcc80c6a1d994414cae6,12,5,3,7494,,,0,"Enable kube.py get k8s api server port from baymodel

Implements part of bp override-native-rest-port

Change-Id: I8a061d97757d5284c277675c46c416a88b64d895
",git fetch https://review.opendev.org/openstack/magnum refs/changes/59/146859/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/conductor/handlers/test_kube.py', 'magnum/conductor/handlers/kube.py']",2,d6ba72a8f6865db940f486a56bf413f12bc323df,bp/override-native-rest-port,"def _retrive_baymodel(ctxt, obj): return objects.BayModel.get_by_uuid(ctxt, obj.baymodel_id) def _retrive_k8s_master_url(ctxt, obj): apiserver_port = 8080 if obj: baymodel = _retrive_baymodel(ctxt, obj) apiserver_port = baymodel.apiserver_port 'k8s_port': apiserver_port,"," cfg.IntOpt('k8s_port', default=8080, help=_('Default port of the k8s master endpoint.')),def _retrive_k8s_master_url(ctxt, obj): 'k8s_port': cfg.CONF.kubernetes.k8s_port,",22,5
openstack%2Fpuppet-cinder~master~Idef1c7722bbee198e6d87e3c06217275de5469ad,openstack/puppet-cinder,master,Idef1c7722bbee198e6d87e3c06217275de5469ad,Automates generation of NFS config file,MERGED,2014-12-04 23:03:08.000000000,2015-01-13 20:17:15.000000000,2015-01-13 20:17:13.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 9186}, {'_account_id': 9410}, {'_account_id': 9500}, {'_account_id': 10540}, {'_account_id': 13084}]","[{'number': 1, 'created': '2014-12-04 23:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/7d55aa909830d171007c355388a34e705111b103', 'message': 'Automates generation of NFS config file\n\nChange-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad\n'}, {'number': 2, 'created': '2014-12-04 23:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/f5caf3d205c4a94c65c85076a7048ba38113856e', 'message': 'Automates generation of NFS config file\n\nCurrently, a user must have a file already created that contains the\nNFS shares that they want to use. This change allows a user to specify\na list of NFS shares and have Puppet write them to a new file. If the\nnfs_shares option is blank, then the manifest will function as it does\ncurrently.\n\nChange-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad\n'}, {'number': 3, 'created': '2015-01-01 22:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/4d6236713e6cfc94a865bee0896f091dc96238ca', 'message': 'Automates generation of NFS config file\n\nCurrently, a user must have a file already created that contains the\nNFS shares that they want to use. This change allows a user to specify\na list of NFS shares and have Puppet write them to a new file. If the\nnfs_shares option is blank, then the manifest will function as it does\ncurrently.\n\nChange-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad\n'}, {'number': 4, 'created': '2015-01-06 19:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/551925aa3e7f52f1857522cc303a540e37f5ff7b', 'message': 'Automates generation of NFS config file\n\nCurrently, a user must have a file already created that contains the\nNFS shares that they want to use. This change allows a user to specify\na list of NFS shares and have Puppet write them to a new file. If the\nnfs_shares option is blank, then the manifest will function as it does\ncurrently.\n\nChange-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad\n'}, {'number': 5, 'created': '2015-01-12 22:30:42.000000000', 'files': ['spec/classes/cinder_volume_netapp_spec.rb', 'manifests/volume/netapp.pp', 'manifests/backend/netapp.pp', 'spec/defines/cinder_backend_netapp_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/8f639695c26715de035230e9627501f3d3a2e997', 'message': 'Automates generation of NFS config file\n\nCurrently, a user must have a file already created that contains the\nNFS shares that they want to use. This change allows a user to specify\na list of NFS shares and have Puppet write them to a new file. If the\nnfs_shares option is blank, then the manifest will function as it does\ncurrently.\n\nChange-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad\n'}]",9,139254,8f639695c26715de035230e9627501f3d3a2e997,30,9,5,13084,,,0,"Automates generation of NFS config file

Currently, a user must have a file already created that contains the
NFS shares that they want to use. This change allows a user to specify
a list of NFS shares and have Puppet write them to a new file. If the
nfs_shares option is blank, then the manifest will function as it does
currently.

Change-Id: Idef1c7722bbee198e6d87e3c06217275de5469ad
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/54/139254/5 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_volume_netapp_spec.rb', 'manifests/volume/netapp.pp', 'manifests/backend/netapp.pp', 'spec/defines/cinder_backend_netapp_spec.rb']",4,7d55aa909830d171007c355388a34e705111b103,139254," :nfs_shares_config => '/etc/cinder/shares.conf', context 'with NFS shares provided' do let (:req_params) { params.merge!({ :nfs_shares => ['10.0.0.1:/test1', '10.0.0.2:/test2'], }) } it 'writes NFS shares to file' do should contain_file(""#{default_params[:nfs_shares_config]}"") end end"," :nfs_shares_config => '',",49,6
openstack%2Fkeystone~master~I38e72aed25c7e0151b1bd5c169b84c0db6fd90c8,openstack/keystone,master,I38e72aed25c7e0151b1bd5c169b84c0db6fd90c8,Fixes Keystone name on configuration doc,ABANDONED,2015-01-10 04:18:19.000000000,2015-01-13 19:51:44.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-10 04:18:19.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aab02966361e0a5f93417181a3433ed6486af7e9', 'message': 'Fixes Keystone name on configuration doc\n\nThis patch fixes several sentences in\nconfiguration.rst, where Keystone system name was\nwritten starting with lowercase letter.\n\nPartial-Bug: #1409201\nChange-Id: I38e72aed25c7e0151b1bd5c169b84c0db6fd90c8\n'}]",0,146257,aab02966361e0a5f93417181a3433ed6486af7e9,11,6,1,9142,,,0,"Fixes Keystone name on configuration doc

This patch fixes several sentences in
configuration.rst, where Keystone system name was
written starting with lowercase letter.

Partial-Bug: #1409201
Change-Id: I38e72aed25c7e0151b1bd5c169b84c0db6fd90c8
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/146257/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,aab02966361e0a5f93417181a3433ed6486af7e9,bug/1409201,"multiple Keystone servers and want to ensure the same ID would be generated whichever server you hit.continue to carry stale identity mappings in its table. While benign, Keystoneverified offline using Keystone's public signing key. The only reason for them* ``enabled`` - enables/disables caching across all of Keystoneused to encrypt communications with Keystone. In the event that a Certificate","multiple keystones and want to ensure the same ID would be generated whichever server you hit.continue to carry stale identity mappings in its table. While benign, keystoneverified offline using keystone's public signing key. The only reason for them* ``enabled`` - enables/disables caching across all of keystoneused to encrypt communications with keystone. In the event that a Certificate",6,6
openstack%2Fnova~master~I16db4600107b1f8f54b9f46a8552331612859346,openstack/nova,master,I16db4600107b1f8f54b9f46a8552331612859346,Fix and re-gate on H306,MERGED,2015-01-07 20:22:34.000000000,2015-01-13 19:51:11.000000000,2015-01-13 06:48:19.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 20:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98217e60669de060aedebd617d4428c34757bf1d', 'message': 'Fix and re-gate on H306\n\nH306, alphabetical imports, was mistakenly skipped in\nf96ec4411ce89606cf52211061003c14306dcfa1\n\nChange-Id: I16db4600107b1f8f54b9f46a8552331612859346\n'}, {'number': 2, 'created': '2015-01-07 23:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b784ca38d022b31b91f088b595aa8073b2c0f179', 'message': 'Fix and re-gate on H306\n\nH306, alphabetical imports, was mistakenly skipped in\nf96ec4411ce89606cf52211061003c14306dcfa1\n\nChange-Id: I16db4600107b1f8f54b9f46a8552331612859346\n'}, {'number': 3, 'created': '2015-01-10 22:40:40.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_server_password.py', 'nova/db/sqlalchemy/types.py', 'nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/3aaefad0d274e3bc5499789f1fe298d8dbe43b02', 'message': 'Fix and re-gate on H306\n\nH306, alphabetical imports, was mistakenly skipped in\nf96ec4411ce89606cf52211061003c14306dcfa1\n\nChange-Id: I16db4600107b1f8f54b9f46a8552331612859346\n'}]",2,145571,3aaefad0d274e3bc5499789f1fe298d8dbe43b02,34,11,3,1849,,,0,"Fix and re-gate on H306

H306, alphabetical imports, was mistakenly skipped in
f96ec4411ce89606cf52211061003c14306dcfa1

Change-Id: I16db4600107b1f8f54b9f46a8552331612859346
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/145571/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_server_password.py', 'nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py', 'tox.ini']",5,98217e60669de060aedebd617d4428c34757bf1d,hacking," ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H238","# H306 was mistakenly ignored, TODO to re-add ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H238,H306",6,6
openstack%2Fnova~master~I38bf2ff5247817d58723f28e87607f16f3d9c374,openstack/nova,master,I38bf2ff5247817d58723f28e87607f16f3d9c374,Replace Hacking N315 with H105,MERGED,2015-01-07 23:12:14.000000000,2015-01-13 19:44:16.000000000,2015-01-13 06:59:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 23:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a43d7c2a55d8f5d3ae20dc881639fdd5c26fb255', 'message': ""Replace Hacking N315 with H105\n\nDon't use author tags is H105 in hacking 0.10, so drop local rule N315\nin favor of H105.\n\nChange-Id: I38bf2ff5247817d58723f28e87607f16f3d9c374\n""}, {'number': 2, 'created': '2015-01-10 22:40:40.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/571893ab42ee45bc48422b0ddf099612fd99c439', 'message': ""Replace Hacking N315 with H105\n\nDon't use author tags is H105 in hacking 0.10, so drop local rule N315\nin favor of H105.\n\nChange-Id: I38bf2ff5247817d58723f28e87607f16f3d9c374\n""}]",0,145625,571893ab42ee45bc48422b0ddf099612fd99c439,26,9,2,1849,,,0,"Replace Hacking N315 with H105

Don't use author tags is H105 in hacking 0.10, so drop local rule N315
in favor of H105.

Change-Id: I38bf2ff5247817d58723f28e87607f16f3d9c374
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/145625/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst']",3,a43d7c2a55d8f5d3ae20dc881639fdd5c26fb255,hacking,,- [N315] We do not use @authors tags in source files. We have git to track authorship.,0,25
openstack%2Fproject-config~master~I99bf07443298c4ab80702bda5b276c85e07a24e2,openstack/project-config,master,I99bf07443298c4ab80702bda5b276c85e07a24e2,Move devstack f20 jobs to f21,MERGED,2015-01-13 04:49:37.000000000,2015-01-13 19:43:17.000000000,2015-01-13 19:43:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1106}, {'_account_id': 2750}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-13 04:49:37.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/70c46ce5bbae68700aee946f797e4f96710ec35e', 'message': 'Move devstack f20 jobs to f21\n\nF21 nodes are up and running in both hp and rackspace, and\nexperimental runs of this test show it works.\n\nChange-Id: I99bf07443298c4ab80702bda5b276c85e07a24e2\n'}]",0,146760,70c46ce5bbae68700aee946f797e4f96710ec35e,8,5,1,7118,,,0,"Move devstack f20 jobs to f21

F21 nodes are up and running in both hp and rackspace, and
experimental runs of this test show it works.

Change-Id: I99bf07443298c4ab80702bda5b276c85e07a24e2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/146760/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,70c46ce5bbae68700aee946f797e4f96710ec35e,devstack-f20-to-f21, - check-tempest-dsvm-f21 - check-tempest-dsvm-f21, - check-tempest-dsvm-f20 - check-tempest-dsvm-f21 - check-tempest-dsvm-f20,2,3
openstack%2Ftripleo-incubator~master~Ie282b3f0563a9006f84f533c6901835bdb11e517,openstack/tripleo-incubator,master,Ie282b3f0563a9006f84f533c6901835bdb11e517,add --uri flag for remote hypervisor,MERGED,2015-01-06 16:42:52.000000000,2015-01-13 19:41:32.000000000,2015-01-13 19:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 1706}, {'_account_id': 8449}, {'_account_id': 9453}, {'_account_id': 10035}, {'_account_id': 14123}]","[{'number': 1, 'created': '2015-01-06 16:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/44ae5065b7ea5816ecd46e132262f2f1ca48ca7a', 'message': 'CORE-2335 add --uri flag for remote hypervisor\n\nAdd --uri flag for remote hypervisor which will enable\nvirtual machines on remote hypervisors. This is 100%\nbackwards compatible.\n\nChange-Id: Ie282b3f0563a9006f84f533c6901835bdb11e517\n'}, {'number': 2, 'created': '2015-01-07 18:35:32.000000000', 'files': ['scripts/configure-vm'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/afa9c08d20cd81b31f43ab9b97f8f54d370c1771', 'message': 'add --uri flag for remote hypervisor\n\nCurrently its not possible to launch VMs on any hypervisor\nexcept qemu:///system (ie the local one). This may not\nalways be possible.\nAdd --uri flag for remote hypervisor which will enable\nvirtual machines on remote hypervisors. This is 100%\nbackwards compatible.\n\nChange-Id: Ie282b3f0563a9006f84f533c6901835bdb11e517\n'}]",4,145263,afa9c08d20cd81b31f43ab9b97f8f54d370c1771,21,6,2,1706,,,0,"add --uri flag for remote hypervisor

Currently its not possible to launch VMs on any hypervisor
except qemu:///system (ie the local one). This may not
always be possible.
Add --uri flag for remote hypervisor which will enable
virtual machines on remote hypervisors. This is 100%
backwards compatible.

Change-Id: Ie282b3f0563a9006f84f533c6901835bdb11e517
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/63/145263/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/configure-vm'],1,44ae5065b7ea5816ecd46e132262f2f1ca48ca7a,os_add_uri," parser.add_argument('--uri', default='qemu:///system', help='The server uri with which to connect.') conn=libvirt.open(args.uri)"," conn=libvirt.open(""qemu:///system"")",3,1
openstack%2Fcookbook-openstack-object-storage~master~I556ebc28834630c96c686d18a0250241068c095a,openstack/cookbook-openstack-object-storage,master,I556ebc28834630c96c686d18a0250241068c095a,Use Common bind endpoint,MERGED,2014-11-20 21:43:57.000000000,2015-01-13 18:28:03.000000000,2015-01-13 18:28:03.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 12213}, {'_account_id': 12323}, {'_account_id': 12588}, {'_account_id': 13252}]","[{'number': 1, 'created': '2014-11-20 21:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/17af29e0bda85e38db49104b2c595df450fd9a51', 'message': 'Use Common bind endpoint\n\nMore cleanup\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}, {'number': 2, 'created': '2014-11-21 15:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/83bf9c28594a65af2171c2eac44de22be4bc359e', 'message': 'Use Common bind endpoint\n\nMore cleanup and work to use the Common support.\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}, {'number': 3, 'created': '2014-11-26 18:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/ac77c2a6d07acfcfe2d87b2e3da3eee8cf5f3d1f', 'message': 'Use Common bind endpoint\n\nMore cleanup and work to use the Common support.\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}, {'number': 4, 'created': '2014-12-03 17:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/e762497f4bbba3bf58a943bab06a840d571a2a31', 'message': 'Use Common bind endpoint\n\nMore cleanup and work to use the Common support.\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n* beefed up spec tests a bit\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}, {'number': 5, 'created': '2014-12-03 18:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/d0646997dfcc4800a79791d90596ddec9f355265', 'message': 'Use Common bind endpoint\n\nMore cleanup and work to use the Common support.\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n* beefed up spec tests a bit\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}, {'number': 6, 'created': '2014-12-27 16:09:12.000000000', 'files': ['templates/default/object-server.conf.erb', 'CHANGELOG.md', 'spec/account_spec.rb', 'recipes/proxy-server.rb', 'spec/proxy_spec.rb', 'templates/default/container-server.conf.erb', 'spec/spec_helper.rb', 'attributes/default.rb', 'spec/object_spec.rb', 'templates/default/proxy-server.conf.erb', 'spec/container_spec.rb', 'recipes/common.rb', 'templates/default/account-server.conf.erb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/ff934f0f4f5c59302a0cc62ada4b949161685e69', 'message': 'Use Common bind endpoint\n\nMore cleanup and work to use the Common support.\n* use the common defined object storage api bind endpoint\n* allow workers for each server\n* adjust cidr to reflect common network defaults\n* cleanup out of date comments from templates\n* beefed up spec tests a bit\n\nChange-Id: I556ebc28834630c96c686d18a0250241068c095a\n'}]",4,136134,ff934f0f4f5c59302a0cc62ada4b949161685e69,32,6,6,7128,,,0,"Use Common bind endpoint

More cleanup and work to use the Common support.
* use the common defined object storage api bind endpoint
* allow workers for each server
* adjust cidr to reflect common network defaults
* cleanup out of date comments from templates
* beefed up spec tests a bit

Change-Id: I556ebc28834630c96c686d18a0250241068c095a
",git fetch https://review.opendev.org/openstack/cookbook-openstack-object-storage refs/changes/34/136134/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/account_spec.rb', 'recipes/proxy-server.rb', 'spec/proxy_spec.rb', 'templates/default/container-server.conf.erb', 'attributes/default.rb', 'spec/object_spec.rb', 'templates/default/object-server.conf.erb', 'templates/default/proxy-server.conf.erb', 'spec/container_spec.rb', 'recipes/common.rb', 'templates/default/account-server.conf.erb']",11,17af29e0bda85e38db49104b2c595df450fd9a51,common_bind_endpoint,workers = <%= node['openstack']['object-storage']['account-server']['workers'] %>,workers = 10,41,60
openstack%2Fceilometer~master~I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e,openstack/ceilometer,master,I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e,Remove unnecessary import_opt|group,MERGED,2014-11-20 18:13:14.000000000,2015-01-13 18:21:03.000000000,2015-01-13 18:21:01.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 6763}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-11-20 18:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e45356ba0284157da9317ca4cf2c02d4042d3753', 'message': ""Remove unnecessary import_opt|group\n\nUsually, we should import an option before we use it, otherwise,\nNoSuchOpt exception will be raised.\n\nWhen we import a module, the options in that module are registered,\n(or imported), so we don't need to explicitly import them again.\nHowever, it is a bit hard for developers, reviewers and maintainers\nto track between files just to check if a specific option is imported\nor not. So it is good (not required) whenever we use an option, we import\nit explicitly, such kind of redundant is acceptable. But not the case that\nwe already import a module A, then import_opt|group registered or imported\nin that module again, this is obviously unnecessary and should be avoid.\n\nChange-Id: I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e\nCloses-Bug: #1389229\n""}, {'number': 2, 'created': '2014-11-21 10:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/80c2473e07f7ab2e5096c6402db8912c7ecf9b86', 'message': ""Remove unnecessary import_opt|group\n\nUsually, we should import an option before we use it, otherwise,\nNoSuchOpt exception will be raised.\n\nWhen we import a module, the options in that module are registered,\n(or imported), so we don't need to explicitly import them again.\nHowever, it is a bit hard for developers, reviewers and maintainers\nto track between files just to check if a specific option is imported\nor not. So it is good (not required) whenever we use an option, we import\nit explicitly, such kind of redundant is acceptable. But not the case that\nwe already import a module A, then import_opt|group registered or imported\nin that module again, this is obviously unnecessary and should be avoid.\n\nChange-Id: I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e\nCloses-Bug: #1389229\n""}, {'number': 3, 'created': '2014-11-29 04:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/da1f394934f1ec1fa371ecb6cf38517d086835ba', 'message': ""Remove unnecessary import_opt|group\n\nUsually, we should import an option before we use it, otherwise,\nNoSuchOpt exception will be raised.\n\nWhen we import a module, the options in that module are registered,\n(or imported), so we don't need to explicitly import them again.\nHowever, it is a bit hard for developers, reviewers and maintainers\nto track between files just to check if a specific option is imported\nor not. So it is good (not required) whenever we use an option, we import\nit explicitly, such kind of redundant is acceptable. But not the case that\nwe already import a module A, then import_opt|group registered or imported\nin that module again, this is obviously unnecessary and should be avoid.\n\nChange-Id: I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e\nCloses-Bug: #1389229\n""}, {'number': 4, 'created': '2014-12-26 10:54:41.000000000', 'files': ['ceilometer/alarm/storage/impl_mongodb.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/network/services/discovery.py', 'ceilometer/network/floatingip.py', 'ceilometer/alarm/service.py', 'ceilometer/cmd/storage.py', 'ceilometer/api/app.py', 'ceilometer/storage/__init__.py', 'ceilometer/service.py', 'ceilometer/agent/base.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d288a28589d3791bc71eee626d1ed0b7ac7bcd23', 'message': ""Remove unnecessary import_opt|group\n\nUsually, we should import an option before we use it, otherwise,\nNoSuchOpt exception will be raised.\n\nWhen we import a module, the options in that module are registered,\n(or imported), so we don't need to explicitly import them again.\nHowever, it is a bit hard for developers, reviewers and maintainers\nto track between files just to check if a specific option is imported\nor not. So it is good (not required) whenever we use an option, we import\nit explicitly, such kind of redundant is acceptable. But not the case that\nwe already import a module A, then import_opt|group registered or imported\nin that module again, this is obviously unnecessary and should be avoid.\n\nChange-Id: I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e\nCloses-Bug: #1389229\n""}]",4,136081,d288a28589d3791bc71eee626d1ed0b7ac7bcd23,35,10,4,6676,,,0,"Remove unnecessary import_opt|group

Usually, we should import an option before we use it, otherwise,
NoSuchOpt exception will be raised.

When we import a module, the options in that module are registered,
(or imported), so we don't need to explicitly import them again.
However, it is a bit hard for developers, reviewers and maintainers
to track between files just to check if a specific option is imported
or not. So it is good (not required) whenever we use an option, we import
it explicitly, such kind of redundant is acceptable. But not the case that
we already import a module A, then import_opt|group registered or imported
in that module again, this is obviously unnecessary and should be avoid.

Change-Id: I8672d9f12d862f9a622e5557d9c8dc2fe6717f5e
Closes-Bug: #1389229
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/81/136081/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/storage/impl_mongodb.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/network/services/discovery.py', 'ceilometer/network/floatingip.py', 'ceilometer/alarm/service.py', 'ceilometer/cmd/storage.py', 'ceilometer/agent.py', 'ceilometer/api/app.py', 'ceilometer/storage/__init__.py', 'ceilometer/service.py']",10,e45356ba0284157da9317ca4cf2c02d4042d3753,bug/1389229,,"cfg.CONF.import_opt('default_log_levels', 'ceilometer.openstack.common.log') ",0,28
openstack%2Fceilometer~master~I653c637ba18c7f0e9f5c4d64e3a4864467af83b8,openstack/ceilometer,master,I653c637ba18c7f0e9f5c4d64e3a4864467af83b8,notification agent missing CONF option,MERGED,2015-01-12 22:38:29.000000000,2015-01-13 18:17:18.000000000,2015-01-13 18:17:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-01-12 22:38:29.000000000', 'files': ['ceilometer/notification.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4485e3709bd247037c04d3f8d40a50d04ee27531', 'message': ""notification agent missing CONF option\n\nimport metering_driver option to ensure it's properly set before\nbeing used.\n\nChange-Id: I653c637ba18c7f0e9f5c4d64e3a4864467af83b8\n""}]",0,146667,4485e3709bd247037c04d3f8d40a50d04ee27531,12,6,1,6537,,,0,"notification agent missing CONF option

import metering_driver option to ensure it's properly set before
being used.

Change-Id: I653c637ba18c7f0e9f5c4d64e3a4864467af83b8
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/67/146667/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/notification.py'],1,4485e3709bd247037c04d3f8d40a50d04ee27531,missing-opt,"cfg.CONF.import_opt('metering_driver', 'ceilometer.publisher.messaging', group='publisher_notifier')",,2,0
openstack%2Fdevstack~master~I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7,openstack/devstack,master,I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7,Ability to use a remote Ceph cluster,MERGED,2014-12-04 17:33:58.000000000,2015-01-13 18:16:04.000000000,2015-01-13 18:16:02.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1107}, {'_account_id': 2750}, {'_account_id': 4523}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 9236}, {'_account_id': 10385}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-04 17:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c2cf2d61f5cf2fb489e0a2dd229d3a0f9b48a8dc', 'message': ""Ability to use a remote Ceph cluster\n\nSometimes we want to run some benchmarks on virtual machines that will be\nbacked by a Ceph cluster. The first idea that comes in our mind is to\nuse devstack to quickly get an OpenStack up and running but what about\nthe configuration of Devstack with this remote cluster?\n\nThanks to this commit it's now possible to use an already existing Ceph\ncluster. In this case Devstack just needs two things:\n\n* the location of the Ceph config file (by default devstack will look\nfor /etc/ceph/ceph.conf\n* the admin key of the remote ceph cluster (by default devstack will\nlook for /etc/ceph/ceph.client.admin.keyring)\n\nDevstack will then create the necessary pools, users, keys and will\nconnect the OpenStack environment as usual. During the unstack phase\nevery pools, users and keys will be deleted on the remote cluster while\nlocal files and ceph-common package will be removed from the current\nDevstack host.\n\nTo enable this mode simply add REMOTE_CEPH=True to your localrc file.\n\nChange-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7\nSigned-off-by: Sébastien Han <sebastien.han@enovance.com>\n""}, {'number': 2, 'created': '2014-12-08 15:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/612d74ff71ebca7670fbdec6a3efd27cee50a48d', 'message': ""Ability to use a remote Ceph cluster\n\nSometimes we want to run some benchmarks on virtual machines that will be\nbacked by a Ceph cluster. The first idea that comes in our mind is to\nuse devstack to quickly get an OpenStack up and running but what about\nthe configuration of Devstack with this remote cluster?\n\nThanks to this commit it's now possible to use an already existing Ceph\ncluster. In this case Devstack just needs two things:\n\n* the location of the Ceph config file (by default devstack will look\nfor /etc/ceph/ceph.conf\n* the admin key of the remote ceph cluster (by default devstack will\nlook for /etc/ceph/ceph.client.admin.keyring)\n\nDevstack will then create the necessary pools, users, keys and will\nconnect the OpenStack environment as usual. During the unstack phase\nevery pools, users and keys will be deleted on the remote cluster while\nlocal files and ceph-common package will be removed from the current\nDevstack host.\n\nTo enable this mode simply add REMOTE_CEPH=True to your localrc file.\n\nChange-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7\nSigned-off-by: Sébastien Han <sebastien.han@enovance.com>\n""}, {'number': 3, 'created': '2014-12-08 22:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/389df9aae1b84232ce93aebd347f1955f826bbb8', 'message': ""Ability to use a remote Ceph cluster\n\nSometimes we want to run some benchmarks on virtual machines that will be\nbacked by a Ceph cluster. The first idea that comes in our mind is to\nuse devstack to quickly get an OpenStack up and running but what about\nthe configuration of Devstack with this remote cluster?\n\nThanks to this commit it's now possible to use an already existing Ceph\ncluster. In this case Devstack just needs two things:\n\n* the location of the Ceph config file (by default devstack will look\nfor /etc/ceph/ceph.conf\n* the admin key of the remote ceph cluster (by default devstack will\nlook for /etc/ceph/ceph.client.admin.keyring)\n\nDevstack will then create the necessary pools, users, keys and will\nconnect the OpenStack environment as usual. During the unstack phase\nevery pools, users and keys will be deleted on the remote cluster while\nlocal files and ceph-common package will be removed from the current\nDevstack host.\n\nTo enable this mode simply add REMOTE_CEPH=True to your localrc file.\n\nChange-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7\nSigned-off-by: Sébastien Han <sebastien.han@enovance.com>\n""}, {'number': 4, 'created': '2015-01-05 10:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/feac918d29338894d7e127408b5308ece807dc97', 'message': ""Ability to use a remote Ceph cluster\n\nSometimes we want to run some benchmarks on virtual machines that will be\nbacked by a Ceph cluster. The first idea that comes in our mind is to\nuse devstack to quickly get an OpenStack up and running but what about\nthe configuration of Devstack with this remote cluster?\n\nThanks to this commit it's now possible to use an already existing Ceph\ncluster. In this case Devstack just needs two things:\n\n* the location of the Ceph config file (by default devstack will look\nfor /etc/ceph/ceph.conf\n* the admin key of the remote ceph cluster (by default devstack will\nlook for /etc/ceph/ceph.client.admin.keyring)\n\nDevstack will then create the necessary pools, users, keys and will\nconnect the OpenStack environment as usual. During the unstack phase\nevery pools, users and keys will be deleted on the remote cluster while\nlocal files and ceph-common package will be removed from the current\nDevstack host.\n\nTo enable this mode simply add REMOTE_CEPH=True to your localrc file.\n\nChange-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7\nSigned-off-by: Sébastien Han <sebastien.han@enovance.com>\n""}, {'number': 5, 'created': '2015-01-13 08:50:28.000000000', 'files': ['extras.d/60-ceph.sh', 'lib/cinder_backends/ceph', 'lib/ceph'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4eb04a5f9e378fa67175056ab94b5803db2be875', 'message': ""Ability to use a remote Ceph cluster\n\nSometimes we want to run some benchmarks on virtual machines that will be\nbacked by a Ceph cluster. The first idea that comes in our mind is to\nuse devstack to quickly get an OpenStack up and running but what about\nthe configuration of Devstack with this remote cluster?\n\nThanks to this commit it's now possible to use an already existing Ceph\ncluster. In this case Devstack just needs two things:\n\n* the location of the Ceph config file (by default devstack will look\nfor /etc/ceph/ceph.conf\n* the admin key of the remote ceph cluster (by default devstack will\nlook for /etc/ceph/ceph.client.admin.keyring)\n\nDevstack will then create the necessary pools, users, keys and will\nconnect the OpenStack environment as usual. During the unstack phase\nevery pools, users and keys will be deleted on the remote cluster while\nlocal files and ceph-common package will be removed from the current\nDevstack host.\n\nTo enable this mode simply add REMOTE_CEPH=True to your localrc file.\n\nChange-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7\nSigned-off-by: Sébastien Han <sebastien.han@enovance.com>\n""}]",1,139125,4eb04a5f9e378fa67175056ab94b5803db2be875,24,11,5,6984,,,0,"Ability to use a remote Ceph cluster

Sometimes we want to run some benchmarks on virtual machines that will be
backed by a Ceph cluster. The first idea that comes in our mind is to
use devstack to quickly get an OpenStack up and running but what about
the configuration of Devstack with this remote cluster?

Thanks to this commit it's now possible to use an already existing Ceph
cluster. In this case Devstack just needs two things:

* the location of the Ceph config file (by default devstack will look
for /etc/ceph/ceph.conf
* the admin key of the remote ceph cluster (by default devstack will
look for /etc/ceph/ceph.client.admin.keyring)

Devstack will then create the necessary pools, users, keys and will
connect the OpenStack environment as usual. During the unstack phase
every pools, users and keys will be deleted on the remote cluster while
local files and ceph-common package will be removed from the current
Devstack host.

To enable this mode simply add REMOTE_CEPH=True to your localrc file.

Change-Id: I1a4b6fd676d50b6a41a09e7beba9b11f8d1478f7
Signed-off-by: Sébastien Han <sebastien.han@enovance.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/25/139125/2 && git format-patch -1 --stdout FETCH_HEAD,"['extras.d/60-ceph.sh', 'lib/cinder_backends/ceph', 'lib/ceph']",3,c2cf2d61f5cf2fb489e0a2dd229d3a0f9b48a8dc,ceph-use-remote-cluster,"# Connect to an existing Ceph cluster REMOTE_CEPH=$(trueorfalse False $REMOTE_CEPH) REMOTE_CEPH_ADMIN_KEY_PATH=${REMOTE_CEPH_ADMIN_KEY_PATH:-$CEPH_CONF_DIR/ceph.client.admin.keyring} # do a proper cleanup from here to avoid leftover on the remote Ceph cluster if is_service_enabled glance; then sudo ceph osd pool delete $GLANCE_CEPH_POOL $GLANCE_CEPH_POOL --yes-i-really-really-mean-it > /dev/null sudo ceph auth del client.$GLANCE_CEPH_USER > /dev/null fi if is_service_enabled cinder; then sudo ceph osd pool delete $CINDER_CEPH_POOL $CINDER_CEPH_POOL --yes-i-really-really-mean-it > /dev/null sudo ceph auth del client.$CINDER_CEPH_USER > /dev/null fi if is_service_enabled c-bak; then sudo ceph osd pool delete $CINDER_BAK_CEPH_POOL $CINDER_BAK_CEPH_POOL --yes-i-really-really-mean-it > /dev/null sudo ceph auth del client.$CINDER_BAK_CEPH_USER > /dev/null fi sudo ceph osd pool delete $NOVA_CEPH_POOL $NOVA_CEPH_POOL --yes-i-really-really-mean-it > /dev/null sudo ceph auth del client.$NOVA_CEPH_USER > /dev/null fi # purge ceph config file and keys sudo rm -rf ${CEPH_CONF_DIR}/* if [ ""$REMOTE_CEPH"" = ""False"" ]; then sudo pkill -f ceph-mon sudo pkill -f ceph-osd sudo rm -rf ${CEPH_DATA_DIR}/*/* if egrep -q ${CEPH_DATA_DIR} /proc/mounts; then sudo umount ${CEPH_DATA_DIR} fi if [[ -e ${CEPH_DISK_IMAGE} ]]; then sudo rm -f ${CEPH_DISK_IMAGE} fi uninstall_package ceph ceph-common python-ceph libcephfs1 > /dev/null 2>&1 if [ ""$REMOTE_CEPH"" = ""False"" ]; then # configure Glance service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${GLANCE_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${GLANCE_CEPH_POOL} crush_ruleset ${RULE_ID} fi if [ ""$REMOTE_CEPH"" = ""False"" ]; then # configure Nova service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${NOVA_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo -c ${CEPH_CONF_FILE} ceph osd pool set ${NOVA_CEPH_POOL} crush_ruleset ${RULE_ID} fi if [ ""$REMOTE_CEPH"" = ""False"" ]; then # Configure Cinder service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${CINDER_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${CINDER_CEPH_POOL} crush_ruleset ${RULE_ID} fi if [ ""$REMOTE_CEPH"" = ""True"" ]; then install_package ceph-common else install_package ceph fi"," sudo pkill -f ceph-mon sudo pkill -f ceph-osd sudo rm -rf ${CEPH_DATA_DIR}/*/* sudo rm -rf ${CEPH_CONF_DIR}/* if egrep -q ${CEPH_DATA_DIR} /proc/mounts; then sudo umount ${CEPH_DATA_DIR} fi if [[ -e ${CEPH_DISK_IMAGE} ]]; then sudo rm -f ${CEPH_DISK_IMAGE} fi uninstall_package ceph ceph-common python-ceph libcephfs1 > /dev/null 2>&1 # configure Glance service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${GLANCE_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${GLANCE_CEPH_POOL} crush_ruleset ${RULE_ID} # configure Nova service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${NOVA_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo -c ${CEPH_CONF_FILE} ceph osd pool set ${NOVA_CEPH_POOL} crush_ruleset ${RULE_ID} # Configure Cinder service options, ceph pool, ceph user and ceph key sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${CINDER_CEPH_POOL} size ${CEPH_REPLICAS} if [[ $CEPH_REPLICAS -ne 1 ]]; then sudo ceph -c ${CEPH_CONF_FILE} osd pool set ${CINDER_CEPH_POOL} crush_ruleset ${RULE_ID} install_package ceph",79,36
openstack%2Fcookbook-openstack-compute~master~I4965927c66118aad46a736ea84e437de9b60fee4,openstack/cookbook-openstack-compute,master,I4965927c66118aad46a736ea84e437de9b60fee4,Update deprecated neutron_*/glance_*/cinder_* options in nova.conf,MERGED,2014-12-09 08:04:20.000000000,2015-01-13 18:15:52.000000000,2015-01-13 18:15:51.000000000,"[{'_account_id': 3}, {'_account_id': 1298}, {'_account_id': 2589}, {'_account_id': 7128}, {'_account_id': 9488}, {'_account_id': 9492}, {'_account_id': 12588}]","[{'number': 1, 'created': '2014-12-09 08:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/b857a4da22dca9baa0d7f4d5e1f08b4dd7598bab', 'message': ""Update deprecated neutron_*, glance_* options in nova.conf\n\nIn openstack juno release, neutron_* and glance_* configurations in\n[DEFAULT] section have been deprecated by a new section\n[neutron]/[glance]\nhttps://review.openstack.org/#/c/97461/\nhttps://review.openstack.org/#/c/102212/\nhttps://review.openstack.org/#/c/100567/\n\nIn Kilo, these deprecated options have been completely removed\nhttps://review.openstack.org/#/c/132885/\nhttps://review.openstack.org/#/c/132900/\n\nIf early Kilo adopters use openstack-compute cookbook for deployment,\nnova-compute won't work any more.\n\nIn order to provide support for early Kilo adopters update the nova.conf\ntemplate in Juno to reflect these changes.\n\nChange-Id: I4965927c66118aad46a736ea84e437de9b60fee4\nCloses-Bug: #1339695\n""}, {'number': 2, 'created': '2014-12-15 03:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/4887170cee17fa99302f66bec5799bff4d20cec6', 'message': ""Update deprecated neutron_*, glance_* options in nova.conf\n\nIn openstack juno release, neutron_* and glance_* configurations in\n[DEFAULT] section have been deprecated by a new section\n[neutron]/[glance]\nhttps://review.openstack.org/#/c/97461/\nhttps://review.openstack.org/#/c/102212/\nhttps://review.openstack.org/#/c/100567/\n\nIn Kilo, these deprecated options have been completely removed\nhttps://review.openstack.org/#/c/132885/\nhttps://review.openstack.org/#/c/132900/\n\nIf early Kilo adopters use openstack-compute cookbook for deployment,\nnova-compute won't work any more.\n\nIn order to provide support for early Kilo adopters update the nova.conf\ntemplate in Juno to reflect these changes.\n\nChange-Id: I4965927c66118aad46a736ea84e437de9b60fee4\nCloses-Bug: #1339695\n""}, {'number': 3, 'created': '2014-12-15 04:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/c54f7ba0735616357f359865a4da77b228a7fe23', 'message': ""Update deprecated neutron_*, glance_* options in nova.conf\n\nIn openstack juno release, neutron_* and glance_* configurations in\n[DEFAULT] section have been deprecated by a new section\n[neutron]/[glance]\nhttps://review.openstack.org/#/c/97461/\nhttps://review.openstack.org/#/c/102212/\nhttps://review.openstack.org/#/c/100567/\n\nIn Kilo, these deprecated options have been completely removed\nhttps://review.openstack.org/#/c/132885/\nhttps://review.openstack.org/#/c/132900/\n\nIf early Kilo adopters use openstack-compute cookbook for deployment,\nnova-compute won't work any more.\n\nIn order to provide support for early Kilo adopters update the nova.conf\ntemplate in Juno to reflect these changes.\n\nChange-Id: I4965927c66118aad46a736ea84e437de9b60fee4\nCloses-Bug: #1339695\n""}, {'number': 4, 'created': '2015-01-09 03:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/6ee7e5f43bc3c0e869b44be170b991bed5b879a0', 'message': ""Update deprecated neutron_*/glance_*/cinder_* options in nova.conf\n\nIn openstack juno release, neutron_*, glance_* and cinder_*\nconfigurations in\n[DEFAULT] section have been deprecated by a new section\n[neutron]/[glance]/[cinder]\nhttps://review.openstack.org/#/c/97461/\nhttps://review.openstack.org/#/c/102212/\nhttps://review.openstack.org/#/c/100567/\nhttps://review.openstack.org/#/c/100800/\n\nIn Kilo, these deprecated options have been completely removed\nhttps://review.openstack.org/#/c/132885/\nhttps://review.openstack.org/#/c/132900/\nhttps://review.openstack.org/#/c/132887/\n\nIf early Kilo adopters use openstack-compute cookbook for deployment,\nnova-compute won't work any more.\n\nIn order to provide support for early Kilo adopters update the nova.conf\ntemplate in Juno to reflect these changes.\n\nChange-Id: I4965927c66118aad46a736ea84e437de9b60fee4\nCloses-Bug: #1339695\n""}, {'number': 5, 'created': '2015-01-10 04:50:20.000000000', 'files': ['spec/nova-common_spec.rb', 'CHANGELOG.md', 'templates/default/nova.conf.erb', 'spec/network_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/f3952ed4e4c9f17f8e2d1c327de0e228f463b555', 'message': ""Update deprecated neutron_*/glance_*/cinder_* options in nova.conf\n\nIn openstack juno release, neutron_*, glance_* and cinder_*\nconfigurations in\n[DEFAULT] section have been deprecated by a new section\n[neutron]/[glance]/[cinder]\nhttps://review.openstack.org/#/c/97461/\nhttps://review.openstack.org/#/c/102212/\nhttps://review.openstack.org/#/c/100567/\nhttps://review.openstack.org/#/c/100800/\n\nIn Kilo, these deprecated options have been completely removed\nhttps://review.openstack.org/#/c/132885/\nhttps://review.openstack.org/#/c/132900/\nhttps://review.openstack.org/#/c/132887/\n\nIf early Kilo adopters use openstack-compute cookbook for deployment,\nnova-compute won't work any more.\n\nIn order to provide support for early Kilo adopters update the nova.conf\ntemplate in Juno to reflect these changes.\n\nChange-Id: I4965927c66118aad46a736ea84e437de9b60fee4\nCloses-Bug: #1339695\n""}]",4,140262,f3952ed4e4c9f17f8e2d1c327de0e228f463b555,24,7,5,9492,,,0,"Update deprecated neutron_*/glance_*/cinder_* options in nova.conf

In openstack juno release, neutron_*, glance_* and cinder_*
configurations in
[DEFAULT] section have been deprecated by a new section
[neutron]/[glance]/[cinder]
https://review.openstack.org/#/c/97461/
https://review.openstack.org/#/c/102212/
https://review.openstack.org/#/c/100567/
https://review.openstack.org/#/c/100800/

In Kilo, these deprecated options have been completely removed
https://review.openstack.org/#/c/132885/
https://review.openstack.org/#/c/132900/
https://review.openstack.org/#/c/132887/

If early Kilo adopters use openstack-compute cookbook for deployment,
nova-compute won't work any more.

In order to provide support for early Kilo adopters update the nova.conf
template in Juno to reflect these changes.

Change-Id: I4965927c66118aad46a736ea84e437de9b60fee4
Closes-Bug: #1339695
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/62/140262/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/nova-common_spec.rb', 'templates/default/nova.conf.erb', 'spec/network_spec.rb']",3,b857a4da22dca9baa0d7f4d5e1f08b4dd7598bab,deprecated-nova," /^\[neutron\]$/, %r{^url=http://127.0.0.1:9696$}, /^auth_strategy=keystone$/, /^admin_tenant_name=service$/, /^admin_username=neutron$/, /^admin_password=neutron-pass$/, %r{^admin_auth_url=http://127.0.0.1:5000/v2.0$}, /^url_timeout=30$/, /^region_name=$/, /^ovs_bridge=br-int$/, /^extension_sync_interval=600$/, /^ca_certificates_file=$/, /^service_metadata_proxy=true$/, /^metadata_proxy_shared_secret=metadata-secret$/,"," %r{^neutron_url=http://127.0.0.1:9696$}, /^neutron_auth_strategy=keystone$/, /^neutron_admin_tenant_name=service$/, /^neutron_admin_username=neutron$/, /^neutron_admin_password=neutron-pass$/, %r{^neutron_admin_auth_url=http://127.0.0.1:5000/v2.0$}, /^neutron_url_timeout=30$/, /^neutron_region_name=$/, /^neutron_ovs_bridge=br-int$/, /^neutron_extension_sync_interval=600$/, /^neutron_ca_certificates_file=$/, /^service_neutron_metadata_proxy=true$/, /^neutron_metadata_proxy_shared_secret=metadata-secret$/,",57,44
openstack%2Fneutron~master~Ia4d5c6cae82c579928129d0728cb03091d2869a7,openstack/neutron,master,Ia4d5c6cae82c579928129d0728cb03091d2869a7,QoS API and DB models,ABANDONED,2014-04-28 20:01:23.000000000,2015-01-13 18:10:33.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 333}, {'_account_id': 385}, {'_account_id': 490}, {'_account_id': 642}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2031}, {'_account_id': 2166}, {'_account_id': 2888}, {'_account_id': 4149}, {'_account_id': 4395}, {'_account_id': 4428}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 7823}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 12171}]","[{'number': 28, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20e63381cac7c428f5ea0c18bcbbb3a91d79f1bb', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 29, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/07b47013d4990722f73a9b100dab2e12f3e98a99', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 30, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/357815c3bffbcd3c63cbc4328d722da96a857881', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 31, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4b564470890714a273ac6e83727055fbc51148d', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 24, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28673dd0537ca6c90fcc5311f1cbdaea82140db7', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 25, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93bb1d9b7f05dc030e5f4e67511c8bebe09375fa', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 26, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3517bc5c4d9b93809d4bdf73771c6f345c47928', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 27, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/afe78b139c0bd825fe599d2cec447edb95ee12d9', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 20, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b93e9d065cf69bb27006905371aa43a225bfcb6', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type and policy.\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t\t* The policy field will store either the DSCP mark\n\t\tthat will be applied (as a string), or the bandwith\n\t\tvalue in kbps (as a string).\n\n* A concrete implementation will be written for the OpenVSwitch plugin,\nto support QoS via DSCP marking, as well as bandwidth limiting.\n\n* Other plugins can extend the database model with more columns if\nrequired\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 21, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f2c1383617d8fe7a366fa60646645164505febb', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type and policy.\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t\t* The policy field will store either the DSCP mark\n\t\tthat will be applied (as a string), or the bandwith\n\t\tvalue in kbps (as a string).\n\n* A concrete implementation will be written for the OpenVSwitch plugin,\nto support QoS via DSCP marking, as well as bandwidth limiting.\n\n* Other plugins can extend the database model with more columns if\nrequired\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 22, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c33420a25ddb7b6482949198017c0f3d2362c162', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type and policy.\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t\t* The policy field will store either the DSCP mark\n\t\tthat will be applied (as a string), or the bandwith\n\t\tvalue in kbps (as a string).\n\n* A concrete implementation will be written for the OpenVSwitch plugin,\nto support QoS via DSCP marking, as well as bandwidth limiting.\n\n* Other plugins can extend the database model with more columns if\nrequired\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 23, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40d7af92980bb0622b5631a178c9127918c28a04', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 16, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/430fe6814f931ca0789e502d7113702eddc4481d', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 17, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d725440ee2bd06d68b46a1acfa74c6513a92dd7', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 18, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/919257bdbd48af7d3cbc7d4e4ba82311a5e4a07c', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 19, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d3926ca9d61c969e3c81fee9430aa5019cc6aee', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type and policy.\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or network based on a bandwidth value\n\t\t* The policy field will store either the DSCP mark\n\t\tthat will be applied (as a string), or the bandwith\n\t\tvalue in kbps (as a string).\n\n* A concrete implementation will be written for the OpenVSwitch plugin,\nto support QoS via DSCP marking, as well as bandwidth limiting.\n\n* Other plugins can extend the database model with more columns if\nrequired\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 12, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6f7ad4eae493d39226661b28d932692b9df8cdf', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 13, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3dcbcc6e5d377417e4b860362ce283e9ed97b230', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 14, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cac3c3e72fb66d3df32f66690761c5fc8785edb7', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs more unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 15, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2be7494b0499660054c06a95281b6bfb2fc53f32', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs more unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 8, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/805a45e6a55009a5aa59933702702564a7535151', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 9, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2a14eb069263d62d6051b3b4061950eac0b8430', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 10, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa5ec59d79b5d206c718b752134c91e3d77da6b5', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 11, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eac9277775e34b0cb46b9b221a8a4ffb66c6bb69', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb450caa4d941d9a53b037751905749322a174ee', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/681157c7a56e198ddf9b43c3a50f0cdfa559ca6c', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fe5d0140783d2398f8f6c57347257778c30233a', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 7, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32d9e3dd8d2aea12d539d0539ffda637cfdcb65e', 'message': 'QoS API and DB models\n\n* Contains a skeleton for the REST API - Sean still needs\nto learn about how to use the RESOURCE_ATTRIBUTE_MAP.\n\n* Implements a vendor neutral database model centered around a QoS\nobject, that has a policy field that can store arbitrary JSON.\n\n* QoS objects can be linked to Networks, Subnets, or Ports.\n\n* QoS mappings to a port overrides a subnet policy, subnet\npolicy overrides a network policy. If no policy is specified,\nthe policy is inherited from the parent object.\n\n* Needs unit tests\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42ff021d68d134cea3832e3cea5433f2d9ff61d4', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7b2a8d7e1a6b1eeeb053bb042f0652e3542ab92', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a90eddbcde88008f7e3621db186a18108893aaf', 'message': 'QoS DB models\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 48, 'created': '2014-04-28 20:01:23.000000000', 'files': ['neutron/common/constants.py', 'neutron/db/qos_db.py', 'neutron/tests/unit/test_extension_qos.py', 'neutron/db/migration/alembic_migrations/versions/562fa8b1d4b5_qos.py', 'neutron/extensions/qos.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb3ba01b99a6a390f810e5039a0d8b887308a981', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 44, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eca4d9bdc7f6a8311c92813d06b9ce2a7d1044c1', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 45, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88d4e7cfe3e715435e02ca64ae7afa84339c310a', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nImplements: Blueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 46, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dfd5c6b61a14a2d4098fba20ad6f0a16e4ba012a', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 47, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4a8dec1ab2f49be7578fb5fcc19b984d34f6dea', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 40, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e19cd118f1438d85bd1b6fa438637a1cfa678586', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 41, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e6d88fd7833b4089b3bb320c7e4f4023b7e5c2ec', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 42, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63ab7c8d640a5704d2d724fa2b4dcf0a43b18c2a', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 43, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/46bba000f857777fab548747fa480e23eaf99b2e', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 36, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11d7f8823576ac0ca7e230fe677b2cffd8da3111', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 37, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f2a3f969c2e7065a3b16b2d02ce67cf19e4f7b6', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 38, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fac7c2b2825df5efba95f3884b5141537b2f7d96', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 39, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/85fda24fe763c979c319567f5f35aa0103c7bc02', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 32, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eedd4a787984a94efac061eeecb1f6f0e5beae45', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 33, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8a0cac996530df817ca00d723ca79bf6dce4171', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 34, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9181cfe377f38595ebca7d41ac90109399d27f16', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}, {'number': 35, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b1671682fc9c447aad55ed4b5606d7932ca5942', 'message': 'QoS API and DB models\n\n* Implements a vendor neutral database model centered around a QoS\nobject.\n\t* QoS objects have a type\n\t\t* Type is an Enum, with two current choices: ""DSCP"" for\n\t\tmarking packets with a DSCP mark, and ""ratelimit"" which will\n\t\tthrottle a port or all ports attached to a network based on a bandwidth value\n\t* QoS objects have policy key-value pairs for implementation specific behaviors\n\n* QoS objects can be linked to Networks or Ports\n\n* QoS mappings to a port overrides a network policy. If no policy is\nspecified, the policy for a port is inherited from the network.\n\nBlueprint quantum-qos-api-db\n\nChange-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7\n'}]",186,28313,eb3ba01b99a6a390f810e5039a0d8b887308a981,337,37,48,4656,,,0,"QoS API and DB models

* Implements a vendor neutral database model centered around a QoS
object.
	* QoS objects have a type
		* Type is an Enum, with two current choices: ""DSCP"" for
		marking packets with a DSCP mark, and ""ratelimit"" which will
		throttle a port or all ports attached to a network based on a bandwidth value
	* QoS objects have policy key-value pairs for implementation specific behaviors

* QoS objects can be linked to Networks or Ports

* QoS mappings to a port overrides a network policy. If no policy is
specified, the policy for a port is inherited from the network.

Blueprint quantum-qos-api-db

Change-Id: Ia4d5c6cae82c579928129d0728cb03091d2869a7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/28313/28 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/db/qos_db.py', 'neutron/tests/unit/test_extension_qos.py', 'neutron/db/migration/alembic_migrations/versions/562fa8b1d4b5_qos.py', 'neutron/extensions/qos.py']",5,20e63381cac7c428f5ea0c18bcbbb3a91d79f1bb,bp/ml2-qos,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2013 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Sean M. Collins, sean@coreitpro.com, Comcast # import abc from neutron.api import extensions from neutron.api.v2 import attributes as attr from neutron.api.v2 import base from neutron.common import constants from neutron.common import exceptions as qexception from neutron import manager RESOURCE_ATTRIBUTE_MAP = { 'qos': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'policies': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:dict': None}}, 'type': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:values': [constants.TYPE_QOS_DSCP, constants.TYPE_QOS_RATELIMIT]}}, 'description': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': '', 'validate': {'type:string': None}}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, }, } QOS = ""qos"" EXTENDED_ATTRIBUTES_2_0 = { 'ports': {QOS: {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': attr.ATTR_NOT_SPECIFIED, 'validate': {'type:uuid': None}}}, 'networks': {QOS: {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': attr.ATTR_NOT_SPECIFIED, 'validate': {'type:uuid': None}}}, } class QoSValidationError(qexception.InvalidInput): message = _(""Invalid QoS Policy"") class Qos(extensions.ExtensionDescriptor): """"""Quality of Service extension."""""" @classmethod def get_name(cls): return ""quality-of-service"" @classmethod def get_alias(cls): return ""quality-of-service"" @classmethod def get_description(cls): return ""The quality of service extension"" @classmethod def get_namespace(cls): #TODO(scollins) pass def get_updated(cls): #TODO(scollins) pass @classmethod def get_resources(cls): #TODO(scollins) my_plurals = [(key + 'es', key) for key in RESOURCE_ATTRIBUTE_MAP.keys()] attr.PLURALS.update(dict(my_plurals)) exts = [] plugin = manager.NeutronManager.get_plugin() params = RESOURCE_ATTRIBUTE_MAP.get(""qos"", dict()) controller = base.create_resource(""qoses"", ""qos"", plugin, params, allow_bulk=True, allow_pagination=True, allow_sorting=True) ex = extensions.ResourceExtension(""qoses"", controller, attr_map=params) exts.append(ex) return exts def get_extended_resources(self, version): if version == ""2.0"": return dict(EXTENDED_ATTRIBUTES_2_0.items() + RESOURCE_ATTRIBUTE_MAP.items()) else: return {} class QoSPluginBase(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def get_qoses(self, context, filters=None, fields=None, sorts=None, limit=None, marker=None, page_reverse=False): pass @abc.abstractmethod def create_qos(self, context, qos): pass @abc.abstractmethod def delete_qos(self, context, id): pass @abc.abstractmethod def update_qos(self, context, id, qos): pass @abc.abstractmethod def create_qos_for_network(self, context, qos_id, network_id): pass @abc.abstractmethod def delete_qos_for_network(self, context, network_id): pass @abc.abstractmethod def create_qos_for_port(self, context, qos_id, port_id): pass @abc.abstractmethod def delete_qos_for_port(self, context, port_id): pass @abc.abstractmethod def validate_qos(self, context, qos): pass ",,834,0
openstack%2Fcongress~master~If931c45aaff3e11fc99e0808c10f7bd13d9d105f,openstack/congress,master,If931c45aaff3e11fc99e0808c10f7bd13d9d105f,Updated from global requirements,MERGED,2015-01-08 02:37:13.000000000,2015-01-13 17:47:51.000000000,2015-01-13 17:47:51.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-08 02:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6c8c1b959c6e965c19b653144748c06180f62202', 'message': 'Updated from global requirements\n\nChange-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f\n'}, {'number': 2, 'created': '2015-01-08 18:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d1d9d50ce9000af27a085e089f168463ee82b1cb', 'message': 'Updated from global requirements\n\nChange-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f\n'}, {'number': 3, 'created': '2015-01-09 00:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/75b0bf3c3523fee176bdd0b64065b244d5c8f1c2', 'message': 'Updated from global requirements\n\nChange-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f\n'}, {'number': 4, 'created': '2015-01-10 22:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/62d0043a8bf03b2ca950c6ce5dfe0a0ddad44afd', 'message': 'Updated from global requirements\n\nChange-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f\n'}, {'number': 5, 'created': '2015-01-13 00:17:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/ba91555b542c018fa162cba936740e31116d0f65', 'message': 'Updated from global requirements\n\nChange-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f\n'}]",0,145675,ba91555b542c018fa162cba936740e31116d0f65,20,3,5,11131,,,0,"Updated from global requirements

Change-Id: If931c45aaff3e11fc99e0808c10f7bd13d9d105f
",git fetch https://review.opendev.org/openstack/congress refs/changes/75/145675/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6c8c1b959c6e965c19b653144748c06180f62202,openstack/requirements,oslo.db>=1.3.0 # Apache-2.0,oslo.db>=1.1.0 # Apache-2.0,1,1
openstack%2Fironic-python-agent~master~I7cb2fc56792f7516222baf75f76b50509deefcf5,openstack/ironic-python-agent,master,I7cb2fc56792f7516222baf75f76b50509deefcf5,Error classes invoke their parent's __init__(),MERGED,2015-01-12 21:17:09.000000000,2015-01-13 17:43:40.000000000,2015-01-13 17:43:38.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 10342}]","[{'number': 1, 'created': '2015-01-12 21:17:09.000000000', 'files': ['ironic_python_agent/errors.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f09359760c870e934c2a22461299f507e6233935', 'message': ""Error classes invoke their parent's __init__()\n\nThis fixes some Error classes so that they are correcting invoking\ntheir parent's __init__() method instead of some other ancestor's\nmethod.\n\nChange-Id: I7cb2fc56792f7516222baf75f76b50509deefcf5\nCloses-Bug: 1408813\n""}]",0,146643,f09359760c870e934c2a22461299f507e6233935,7,3,1,6618,,,0,"Error classes invoke their parent's __init__()

This fixes some Error classes so that they are correcting invoking
their parent's __init__() method instead of some other ancestor's
method.

Change-Id: I7cb2fc56792f7516222baf75f76b50509deefcf5
Closes-Bug: 1408813
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/43/146643/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/errors.py'],1,f09359760c870e934c2a22461299f507e6233935,bug/1408813," super(LookupAgentIPError, self).__init__(details) super(LookupAgentInterfaceError, self).__init__(details) super(VirtualMediaBootError, self).__init__(details)"," super(IronicAPIError, self).__init__(details) super(IronicAPIError, self).__init__(details) super(RESTError, self).__init__(details)",3,3
openstack%2Fnova~master~I1a130bbbad16cbef2e974b1ba66a8586a11b666a,openstack/nova,master,I1a130bbbad16cbef2e974b1ba66a8586a11b666a,libvirt: Allow setting maxdowntime for live migrations,ABANDONED,2014-12-15 15:41:38.000000000,2015-01-13 17:38:52.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 8247}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11748}]","[{'number': 1, 'created': '2014-12-15 15:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a125622c867b4f3469da980a76c724941dfa2ec1', 'message': 'libvirt: Allow setting maxdowntime for live migrations\n\nThis permits setting the maximum downtime for libvirt live migrations,\nwhich is necessary to migrate VMs with very high rates of memory churn\nrelative to the network link speed.\n\nCloses-Bug: 1378514\nImplements: blueprint set-live-migration-max-downtime\nChange-Id: I1a130bbbad16cbef2e974b1ba66a8586a11b666a\n'}, {'number': 2, 'created': '2014-12-17 16:24:32.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b117c4e957362006887763e0e8d1ae5d3ef63de9', 'message': 'libvirt: Allow setting maxdowntime for live migrations\n\nThis permits setting the maximum downtime for libvirt live migrations,\nwhich is necessary to migrate VMs with very high rates of memory churn\nrelative to the network link speed.\n\nCloses-Bug: 1378514\nImplements: blueprint set-live-migration-max-downtime\nChange-Id: I1a130bbbad16cbef2e974b1ba66a8586a11b666a\n'}]",4,141826,b117c4e957362006887763e0e8d1ae5d3ef63de9,16,8,2,11748,,,0,"libvirt: Allow setting maxdowntime for live migrations

This permits setting the maximum downtime for libvirt live migrations,
which is necessary to migrate VMs with very high rates of memory churn
relative to the network link speed.

Closes-Bug: 1378514
Implements: blueprint set-live-migration-max-downtime
Change-Id: I1a130bbbad16cbef2e974b1ba66a8586a11b666a
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/141826/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,a125622c867b4f3469da980a76c724941dfa2ec1,bug/1378514," @mock.patch.object(libvirt, 'VIR_DOMAIN_XML_MIGRATABLE', None, create=True) def test_live_migration_set_max_downtime(self): # Tests setting max live migration downtime self.flags(migration_maxdowntime=1000, group='libvirt') self.compute = importutils.import_object(CONF.compute_manager) instance_dict = dict(self.test_instance) instance_dict.update({'host': 'fake', 'power_state': power_state.RUNNING, 'vm_state': vm_states.ACTIVE}) instance_ref = objects.Instance(**instance_dict) # Preparing mocks vdmock = self.mox.CreateMock(libvirt.virDomain) self.mox.StubOutWithMock(vdmock, ""migrateToURI"") _bandwidth = CONF.libvirt.live_migration_bandwidth vdmock.migrateToURI(CONF.libvirt.live_migration_uri % 'dest', mox.IgnoreArg(), None, _bandwidth) self.mox.StubOutWithMock(vdmock, ""migrateSetMaxDowntime"") vdmock.migrateSetMaxDowntime(1000, 0) self.stubs.Set(self.conn, ""getLibVersion"", lambda: 1002009) def fake_get_info(instance): raise exception.InstanceNotFound( instance_id=self.test_instance['id']) def fake_lookup(instance_name): if instance_name == instance_ref['name']: return vdmock self.create_fake_libvirt_mock(lookupByName=fake_lookup) # start test migrate_data = {'pre_live_migration_result': {'graphics_listen_addrs': {'vnc': '0.0.0.0', 'spice': '0.0.0.0'}}} self.mox.ReplayAll() conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) self.stubs.Set(conn, 'get_info', fake_get_info) conn._live_migration( self.context, instance_ref, 'dest', post_method=lambda *args: None, recover_method=self.compute._rollback_live_migration, migrate_data=migrate_data) ",,69,1
openstack%2Foslo.concurrency~master~I655d5abf932c9a104e3ab487e23c372377f7096a,openstack/oslo.concurrency,master,I655d5abf932c9a104e3ab487e23c372377f7096a,Port processutils to Python 3,MERGED,2014-12-11 23:10:35.000000000,2015-01-13 17:37:59.000000000,2014-12-12 13:16:59.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-12-11 23:10:35.000000000', 'files': ['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py', 'tests/test_processutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/7c7493feb53429577efca2c4b0380af03ddc149b', 'message': 'Port processutils to Python 3\n\nAdd encoding and errors parameters to execute() and ssh_execute(). By\ndefault, use the locale encoding in strict mode on Python 2, or the\nlocale encoding with the \'surrogateescape\' error handler on Python 3.\n\nFix also unit tests to use bytes strings for stdin, stdout and stderr.\n\nWithout this change, tests are failing with Python 3 when run with:\nPYTHON=""python -bb"" testr run\n\nUsing -bb, Python 3 raises a TypeError when a bytes string is casted\nto a text string, which occurred in many places.\n\nChange-Id: I655d5abf932c9a104e3ab487e23c372377f7096a\n'}]",0,141206,7c7493feb53429577efca2c4b0380af03ddc149b,8,5,1,9107,,,0,"Port processutils to Python 3

Add encoding and errors parameters to execute() and ssh_execute(). By
default, use the locale encoding in strict mode on Python 2, or the
locale encoding with the 'surrogateescape' error handler on Python 3.

Fix also unit tests to use bytes strings for stdin, stdout and stderr.

Without this change, tests are failing with Python 3 when run with:
PYTHON=""python -bb"" testr run

Using -bb, Python 3 raises a TypeError when a bytes string is casted
to a text string, which occurred in many places.

Change-Id: I655d5abf932c9a104e3ab487e23c372377f7096a
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/06/141206/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_concurrency/processutils.py', 'oslo_concurrency/tests/unit/test_processutils.py', 'tests/test_processutils.py']",3,7c7493feb53429577efca2c4b0380af03ddc149b,py3," self.assertIn('SUPER_UNIQUE_VAR=The answer is 42', out)class FakeSshStream(six.BytesIO): stdout = FakeSshStream(b'stdout') return (six.BytesIO(), six.BytesIO(b'stderr')) fake_stdin = six.BytesIO() fake_stdout.read.return_value = b'password=""secret""' fake_stderr = six.BytesIO(b'password=""foobar""')"," self.assertIn(b'SUPER_UNIQUE_VAR=The answer is 42', out)class FakeSshStream(six.StringIO): stdout = FakeSshStream('stdout') return (six.StringIO(), six.StringIO('stderr')) fake_stdin = six.StringIO() fake_stdout.read.return_value = 'password=""secret""' fake_stderr = six.StringIO('password=""foobar""')",36,17
openstack%2Ffuel-main~stable%2F6.0~I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda,openstack/fuel-main,stable/6.0,I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda,Check started/restarted services only during last puppet run,MERGED,2014-12-22 20:07:35.000000000,2015-01-13 17:26:47.000000000,2015-01-13 17:26:47.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-22 20:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f3c8686fba09d2d17ac075889309571138df7b09', 'message': 'Check started/restarted services only during last puppet run\n\n- get count of lines between last two ""Finished catalog run""\noccurrences in the /var/log/puppet using awk, or between 0 and\nthe an occurrence,\n- get the part of the log that refers to the last puppet run\nusing \'tail -n\' and obtained count of lines,\n- search the pattern within the obtained part of the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 2, 'created': '2015-01-12 07:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fb7e02899fe26cc663db29cd1aed81260448115b', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 3, 'created': '2015-01-13 11:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fc3638770418d02fa98f0a83f642237fa46e47d2', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 4, 'created': '2015-01-13 11:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d673b19425a282c1e1bfa24da5fc644f2cf4f40c', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 5, 'created': '2015-01-13 12:01:40.000000000', 'files': ['fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/tests_os_patching/test_os_patching.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4935a7680cc18fbb24df0493d761e17fba072e21', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}]",0,143521,4935a7680cc18fbb24df0493d761e17fba072e21,31,7,5,11969,,,0,"Check started/restarted services only during last puppet run

- get the part of the log that refers to the last puppet run
by count the number of lines in the log before upgrade, and
scan for pattern only the next lines in the log.

Change-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda
Closes-Bug: #1404950
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/21/143521/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/utils.py'],1,f3c8686fba09d2d17ac075889309571138df7b09,," cmd = (""LAST=`grep 'Finished catalog run' --line-number {0} |"" ""cut -f1 -d: | awk 'BEGIN{{A=0;B=0;}}{{A=B;B=$1;}}"" ""END{{print B-A}}'`; tail -n $LAST {0} |"" ""grep -E '/sbin/(re)?start' {0} | awk -F' ' '{{print $11}}'"" .format('/var/log/puppet.log')) cmd = (""LAST=`grep 'Finished catalog run' --line-number {0} |"" ""cut -f1 -d: | awk 'BEGIN{{A=0;B=0;}}{{A=B;B=$1;}}"" ""END{{print B-A}}'`; tail -n $LAST {0} |"" ""grep '/sbin/service openstack-%s' {0} |"" ""awk -F' ' '{{print $11}}' "".format('/var/log/puppet.log')) for service in services_list: res = node_ssh.execute(cmd % service)['stdout']"," cmd = (""grep '/sbin/restart' /var/log/puppet.log"" "" | awk -F' ' '{print $11}' "") cmd_template = (""grep '/sbin/service openstack-%s'"" "" /var/log/puppet.log| awk -F' ' '{print $11}' "") for service in services_list: res = node_ssh.execute(cmd_template % service)['stdout']",11,5
openstack%2Fneutron~stable%2Fjuno~Ic2ab3f0179b0c192e63af0bc4268d92aa26bdabe,openstack/neutron,stable/juno,Ic2ab3f0179b0c192e63af0bc4268d92aa26bdabe,Reset policies after RESOURCE_ATTRIBUTE_MAP is populated,MERGED,2015-01-12 16:56:56.000000000,2015-01-13 17:17:25.000000000,2015-01-13 17:17:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-12 16:56:56.000000000', 'files': ['neutron/api/extensions.py', 'neutron/tests/functional/api/test_policies.py', 'neutron/tests/functional/api/__init__.py', 'neutron/api/v2/router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/175e86977d6905e1e11766ca47e30b89c88d8827', 'message': 'Reset policies after RESOURCE_ATTRIBUTE_MAP is populated\n\nThe REST API relies on neutron-specific policy checking logic that is\nonly available after the extensions are loaded and the\nRESOURCE_ATTRIBUTE_MAP is populated. This patch resets the policies\nimmediately after these steps are done. This ensures that in the event\nthe policies are prematurely loaded for any reason, the on-demand\nloading of the policies will reload the policies and properly configure\nthe neutron specific checks on the next policy check.\n\nChange-Id: Ic2ab3f0179b0c192e63af0bc4268d92aa26bdabe\nCloses-Bug: #1398566\nRelated-Bug: #1254555\n(cherry picked from commit eeff5d06b2099ed9813091926dd8cef58680ad8f)\n'}]",0,146572,175e86977d6905e1e11766ca47e30b89c88d8827,16,12,1,6681,,,0,"Reset policies after RESOURCE_ATTRIBUTE_MAP is populated

The REST API relies on neutron-specific policy checking logic that is
only available after the extensions are loaded and the
RESOURCE_ATTRIBUTE_MAP is populated. This patch resets the policies
immediately after these steps are done. This ensures that in the event
the policies are prematurely loaded for any reason, the on-demand
loading of the policies will reload the policies and properly configure
the neutron specific checks on the next policy check.

Change-Id: Ic2ab3f0179b0c192e63af0bc4268d92aa26bdabe
Closes-Bug: #1398566
Related-Bug: #1254555
(cherry picked from commit eeff5d06b2099ed9813091926dd8cef58680ad8f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/146572/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/extensions.py', 'neutron/tests/functional/api/test_policies.py', 'neutron/api/v2/router.py', 'neutron/tests/functional/api/__init__.py']",4,175e86977d6905e1e11766ca47e30b89c88d8827,bug/1398566,,,109,2
openstack%2Ffuel-astute~master~Ie4af6904a8297d9acbc4e96425903e9e57450286,openstack/fuel-astute,master,Ie4af6904a8297d9acbc4e96425903e9e57450286,Fix rebooting of the bootstrap nodes,MERGED,2015-01-13 06:52:19.000000000,2015-01-13 17:09:22.000000000,2015-01-13 17:09:22.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-01-13 06:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/ad67e090dbfc9fbb47c5553baae8b3bdd4dce485', 'message': ""Stop corrupting the provisioned nodes' filesystems.\n\nAs of now astute abruptly reboots the nodes which have been just provisioned.\n(basically it sends SysRq-b via ssh). Fortunately this command does not reach\nmost of the nodes: before shooting a node with SysRq-b astute tries to reboot\nit gracefully via cobbler. Thus most of the time the ssh connection which\ntries to send SysRq-b gets rejected. However if a node reboots fast enough\nthe `control reboot' hits such a node (which is being configured by cloud-init\nat that time). An abrupt reboot causes a major filesystem corruption and\nmakes the deployment fail. All in all the control reboot thing causes much\nworse problem than the one it tries to resolve. Disable the control reboot\nfor now.\n\nRelated-bug: #1394599\nRelated-bug: #1407634\nChange-Id: Ie4af6904a8297d9acbc4e96425903e9e57450286\n""}, {'number': 2, 'created': '2015-01-13 14:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9570a5ddc1b3bba71c08629b4d61eabf07930ce2', 'message': 'Fix rebooting of the bootstrap nodes\n\nSkip the hard reboot for the image based provisioning since the reboot\ncommand might hit a node which has booted into the provisioned OS (which\ncauses the filesystem corruption and interrupts the deployment).\nFix the condition which selects the bootstrap nodes, that is, use\nSshHardReboot instead of SshRebootNotProvisioning (the latter reboots\nthe locally booted nodes instead the bootstrap ones due to the inverted\ncondition).\n\nRelated-bug: #1394599\nRelated-bug: #1407634\nChange-Id: Ie4af6904a8297d9acbc4e96425903e9e57450286\n'}, {'number': 3, 'created': '2015-01-13 14:24:52.000000000', 'files': ['lib/astute/ssh_actions/ssh_reboot_not_provisioning.rb', 'lib/astute.rb', 'lib/astute/orchestrator.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/2e9d2733a2ddd1ea3ff583d0a9f81792e2569dba', 'message': 'Fix rebooting of the bootstrap nodes\n\nSkip the hard reboot for the image based provisioning since the reboot\ncommand might hit a node which has booted into the provisioned OS (which\ncauses the filesystem corruption and interrupts the deployment).\nFix the condition which selects the bootstrap nodes, that is, use\nSshHardReboot instead of SshRebootNotProvisioning (the latter reboots\nthe locally booted nodes instead the bootstrap ones due to the inverted\ncondition).\n\nRelated-bug: #1394599\nRelated-bug: #1407634\nChange-Id: Ie4af6904a8297d9acbc4e96425903e9e57450286\n'}]",0,146776,2e9d2733a2ddd1ea3ff583d0a9f81792e2569dba,20,7,3,13194,,,0,"Fix rebooting of the bootstrap nodes

Skip the hard reboot for the image based provisioning since the reboot
command might hit a node which has booted into the provisioned OS (which
causes the filesystem corruption and interrupts the deployment).
Fix the condition which selects the bootstrap nodes, that is, use
SshHardReboot instead of SshRebootNotProvisioning (the latter reboots
the locally booted nodes instead the bootstrap ones due to the inverted
condition).

Related-bug: #1394599
Related-bug: #1407634
Change-Id: Ie4af6904a8297d9acbc4e96425903e9e57450286
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/76/146776/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/astute/orchestrator.rb'],1,ad67e090dbfc9fbb47c5553baae8b3bdd4dce485,support-ubuntu-trusty," # control_reboot_using_ssh(reporter, task_id, nodes)"," control_reboot_using_ssh(reporter, task_id, nodes)",1,1
openstack%2Fmagnetodb~master~Ic29a46a1b955efa567748f6897fb17604ada91a4,openstack/magnetodb,master,Ic29a46a1b955efa567748f6897fb17604ada91a4,Pins tempest commit on devstack installation,MERGED,2015-01-12 13:04:20.000000000,2015-01-13 17:08:55.000000000,2015-01-13 17:08:54.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2015-01-12 13:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/c709e7f415a815dd3c52d5ec832804c8f2dfd3e8', 'message': ""Fixes tempest commit on devstack installation\n\nWhen devstack is installing, tempest will be checked out\nto fix commit to improve stability of devstack job.\nVariable 'TEMPEST_FIXED_COMMIT' in 'contrib/devstack/lib/magnetodb'\nshould be updated periodically.\n\nImplements: bp fix-tempest-commit\nChange-Id: Ic29a46a1b955efa567748f6897fb17604ada91a4\n""}, {'number': 2, 'created': '2015-01-12 13:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/41ea56bda8d9cb76a8fa30a56591325c83b02761', 'message': ""Fixes tempest commit on devstack installation\n\nWhen devstack is installing, tempest will be checked out\nto fix commit to improve stability of devstack job.\nVariable 'TEMPEST_FIXED_COMMIT' in 'contrib/devstack/lib/magnetodb'\nshould be updated periodically.\n\nImplements: bp fix-tempest-commit\nChange-Id: Ic29a46a1b955efa567748f6897fb17604ada91a4\n""}, {'number': 3, 'created': '2015-01-12 16:10:01.000000000', 'files': ['contrib/devstack/lib/magnetodb'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/ed4ad9a1474794abbd045278f0b2c67fbf17b143', 'message': ""Pins tempest commit on devstack installation\n\nWhen devstack is installing, tempest will be checked out\nto fix commit to improve stability of devstack job.\nVariable 'TEMPEST_REVISION' in 'contrib/devstack/lib/magnetodb'\nshould be updated periodically.\n\nImplements: bp fix-tempest-commit\nChange-Id: Ic29a46a1b955efa567748f6897fb17604ada91a4\n""}]",2,146456,ed4ad9a1474794abbd045278f0b2c67fbf17b143,13,6,3,8863,,,0,"Pins tempest commit on devstack installation

When devstack is installing, tempest will be checked out
to fix commit to improve stability of devstack job.
Variable 'TEMPEST_REVISION' in 'contrib/devstack/lib/magnetodb'
should be updated periodically.

Implements: bp fix-tempest-commit
Change-Id: Ic29a46a1b955efa567748f6897fb17604ada91a4
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/56/146456/3 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/magnetodb'],1,c709e7f415a815dd3c52d5ec832804c8f2dfd3e8,bp/fix-tempest-commit,TEMPEST_FIXED_COMMIT='b8df55e3db1c' git checkout $TEMPEST_FIXED_COMMIT,,2,0
openstack%2Foslo.i18n~master~I4db750fb2356ebf44a8fccf7c422b474fefec0ee,openstack/oslo.i18n,master,I4db750fb2356ebf44a8fccf7c422b474fefec0ee,Make setup.cfg packages include oslo.i18n,MERGED,2015-01-13 02:13:40.000000000,2015-01-13 17:07:31.000000000,2015-01-13 17:07:29.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1955}, {'_account_id': 2472}, {'_account_id': 6601}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-13 02:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/196a24c47ed4453dfb539934892bed550a90e193', 'message': 'Set setup.cfg packages = oslo.i18n\n\nThis properly deploys the oslo.i18n package and resolves\nsphinx build errors for projects which have not yet\nupgraded to oslo_i18n.\n\nChange-Id: I4db750fb2356ebf44a8fccf7c422b474fefec0ee\nCloses-bug: #1409998\n'}, {'number': 2, 'created': '2015-01-13 02:20:46.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/e9340090fa106447a41fbf382e641276a7c3883c', 'message': 'Make setup.cfg packages include oslo.i18n\n\nThis properly deploys the oslo.i18n package and resolves\nsphinx build errors for projects which have not yet\nupgraded to oslo_i18n.\n\nChange-Id: I4db750fb2356ebf44a8fccf7c422b474fefec0ee\nCloses-bug: #1409998'}]",0,146733,e9340090fa106447a41fbf382e641276a7c3883c,10,6,2,360,,,0,"Make setup.cfg packages include oslo.i18n

This properly deploys the oslo.i18n package and resolves
sphinx build errors for projects which have not yet
upgraded to oslo_i18n.

Change-Id: I4db750fb2356ebf44a8fccf7c422b474fefec0ee
Closes-bug: #1409998",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/33/146733/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,196a24c47ed4453dfb539934892bed550a90e193,setup_cfg_fix, oslo.i18n,,1,0
openstack%2Fpython-novaclient~master~If65b0060e6f64a456b4869ef4129ad15aef107fb,openstack/python-novaclient,master,If65b0060e6f64a456b4869ef4129ad15aef107fb,Move to hacking 0.10,MERGED,2015-01-11 01:34:36.000000000,2015-01-13 17:07:08.000000000,2015-01-13 17:07:05.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2015-01-11 01:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/3b0888e824a57ba7723a65708432c8a09f517fd5', 'message': 'Move to hacking 0.10\n\nRelease notes: http://lists.openstack.org/pipermail/openstack-dev/2015-January/054165.html\n\nExplicitly move everything to new style classes (H238).\nhttp://python3porting.com/preparing.html#use-new-style-classes\n\nChange-Id: If65b0060e6f64a456b4869ef4129ad15aef107fb\n'}, {'number': 2, 'created': '2015-01-11 20:41:57.000000000', 'files': ['test-requirements.txt', 'novaclient/v1_1/shell.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0eb2e72d38ff4aee9dac9ec909282ecb5c4fd0d0', 'message': 'Move to hacking 0.10\n\nRelease notes: http://lists.openstack.org/pipermail/openstack-dev/2015-January/054165.html\n\nExplicitly move everything to new style classes (H238).\nhttp://python3porting.com/preparing.html#use-new-style-classes\n\nRemove deleted hacking rules from tox.ini\n\nChange-Id: If65b0060e6f64a456b4869ef4129ad15aef107fb\n'}]",0,146291,0eb2e72d38ff4aee9dac9ec909282ecb5c4fd0d0,10,4,2,1849,,,0,"Move to hacking 0.10

Release notes: http://lists.openstack.org/pipermail/openstack-dev/2015-January/054165.html

Explicitly move everything to new style classes (H238).
http://python3porting.com/preparing.html#use-new-style-classes

Remove deleted hacking rules from tox.ini

Change-Id: If65b0060e6f64a456b4869ef4129ad15aef107fb
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/91/146291/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'novaclient/v1_1/shell.py']",2,3b0888e824a57ba7723a65708432c8a09f517fd5,hacking, class VNCConsole(object): class SPICEConsole(object): class RDPConsole(object): class SerialConsole(object): class FormattedRule(object):, class VNCConsole: class SPICEConsole: class RDPConsole: class SerialConsole: class FormattedRule:,6,6
openstack%2Fpython-ceilometerclient~master~I594234648a37d283559a0365969a7fe3609079f8,openstack/python-ceilometerclient,master,I594234648a37d283559a0365969a7fe3609079f8,Remove redundant parentheses (except openstack.common),MERGED,2014-12-10 10:18:14.000000000,2015-01-13 17:04:38.000000000,2015-01-13 17:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-10 10:18:14.000000000', 'files': ['ceilometerclient/v1/meters.py', 'ceilometerclient/v2/options.py', 'ceilometerclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/5df9d3c3c4e0ba18ae5050464bf991776edd16ad', 'message': 'Remove redundant parentheses (except openstack.common)\n\nChange-Id: I594234648a37d283559a0365969a7fe3609079f8\n'}]",0,140630,5df9d3c3c4e0ba18ae5050464bf991776edd16ad,15,11,1,3012,,,0,"Remove redundant parentheses (except openstack.common)

Change-Id: I594234648a37d283559a0365969a7fe3609079f8
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/30/140630/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/v1/meters.py', 'ceilometerclient/v2/options.py', 'ceilometerclient/client.py']",3,5df9d3c3c4e0ba18ae5050464bf991776edd16ad,code-style-fixes," return v2_auth_url, v3_auth_url"," return (v2_auth_url, v3_auth_url)",9,9
openstack%2Fpython-ceilometerclient~master~I524b05ed5ff9db34430afd722991d02545c263cb,openstack/python-ceilometerclient,master,I524b05ed5ff9db34430afd722991d02545c263cb,"event-list should sort by timestamp, not id",MERGED,2015-01-13 04:15:27.000000000,2015-01-13 17:04:31.000000000,2015-01-13 17:04:30.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-01-13 04:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/04f75535e27c3d7d733a1de9f9878615fe347ce2', 'message': ""event-list should sort by timestamp, not id\n\nCurrently, event-list output will be sorted by message id, that is\nbecause table field 0 is the default sort field. But sort by id makes\nno sense, and REST API returns events by timestamp order, so let's\nkeep consistent with upstream.\n\nChange-Id: I524b05ed5ff9db34430afd722991d02545c263cb\nCloses-Bug: #1406622\n""}, {'number': 2, 'created': '2015-01-13 12:16:57.000000000', 'files': ['ceilometerclient/v2/shell.py', 'ceilometerclient/tests/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/97a200d51dca2108c414a0f36dbfc99c44d71226', 'message': ""event-list should sort by timestamp, not id\n\nCurrently, event-list output will be sorted by message id, that is\nbecause table field 0 is the default sort field. But sort by id makes\nno sense, and REST API returns events by timestamp order, so let's\nkeep consistent with upstream.\n\nChange-Id: I524b05ed5ff9db34430afd722991d02545c263cb\nCloses-Bug: #1406622\n""}]",2,146754,97a200d51dca2108c414a0f36dbfc99c44d71226,12,5,2,6676,,,0,"event-list should sort by timestamp, not id

Currently, event-list output will be sorted by message id, that is
because table field 0 is the default sort field. But sort by id makes
no sense, and REST API returns events by timestamp order, so let's
keep consistent with upstream.

Change-Id: I524b05ed5ff9db34430afd722991d02545c263cb
Closes-Bug: #1406622
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/54/146754/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/v2/shell.py', 'ceilometerclient/tests/v2/test_shell.py']",2,04f75535e27c3d7d733a1de9f9878615fe347ce2,bug/1406622,"from ceilometerclient.v2 import events class ShellEventListCommandTest(utils.BaseTestCase): EVENTS = [ { ""traits"": [], ""generated"": ""2015-01-12T04:03:25.741471"", ""message_id"": ""fb2bef58-88af-4380-8698-e0f18fcf452d"", ""event_type"": ""compute.instance.create.start"", }, { ""traits"": [], ""generated"": ""2015-01-12T04:03:28.452495"", ""message_id"": ""9b20509a-576b-4995-acfa-1a24ee5cf49f"", ""event_type"": ""compute.instance.create.end"", }, ] def setUp(self): super(ShellEventListCommandTest, self).setUp() self.cc = mock.Mock() self.args = mock.Mock() self.args.query = None @mock.patch('sys.stdout', new=six.StringIO()) def test_event_list(self): ret_events = [events.Event(mock.Mock(), event) for event in self.EVENTS] self.cc.events.list.return_value = ret_events ceilometer_shell.do_event_list(self.cc, self.args) self.assertEqual('''\ +--------------------------------------+-------------------------------\ +----------------------------+--------+ | Message ID | Event Type \ | Generated | Traits | +--------------------------------------+-------------------------------\ +----------------------------+--------+ | fb2bef58-88af-4380-8698-e0f18fcf452d | compute.instance.create.start \ | 2015-01-12T04:03:25.741471 | | | 9b20509a-576b-4995-acfa-1a24ee5cf49f | compute.instance.create.end \ | 2015-01-12T04:03:28.452495 | | +--------------------------------------+-------------------------------\ +----------------------------+--------+ ''', sys.stdout.getvalue())",,48,1
openstack%2Foctavia~master~Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af,openstack/octavia,master,Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af,Adding network driver interface,MERGED,2015-01-10 07:56:56.000000000,2015-01-13 17:03:50.000000000,2015-01-13 17:03:49.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-10 07:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7827f8c490a17ef10227ec0e7aadd7168121f9a9', 'message': 'Adding network driver interface\n\nDefinition of network driver interface.  Also removed\nthe floating_ip attributes of VIP because they are not\nneeded at this point.  Also renamed net_port_id to just\nport_id and subnet_id to network_id just to be a little\nbit more generically clear.\n\nChange-Id: Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af\nImplements: bp/network-driver-interface\n'}, {'number': 2, 'created': '2015-01-11 06:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/322b1e14ba7a19276683cca77bff2fe5c43ccfb4', 'message': 'Adding network driver interface\n\nDefinition of network driver interface.  Also removed\nthe floating_ip attributes of VIP because they are not\nneeded at this point.  Also renamed net_port_id to just\nport_id and subnet_id to network_id just to be a little\nbit more generically clear.\n\nChange-Id: Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af\nImplements: bp/network-driver-interface\n'}, {'number': 3, 'created': '2015-01-13 04:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bb3023e507297300efca59a671acebc429facc8b', 'message': 'Adding network driver interface\n\nDefinition of network driver interface.  Also removed\nthe floating_ip attributes of VIP because they are not\nneeded at this point.  Also renamed net_port_id to just\nport_id and subnet_id to network_id just to be a little\nbit more generically clear.\n\nChange-Id: Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af\nImplements: bp/network-driver-interface\n'}, {'number': 4, 'created': '2015-01-13 04:40:46.000000000', 'files': ['doc/source/main/octaviaapi.rst', 'octavia/tests/functional/db/test_repositories.py', 'octavia/api/v1/types/load_balancer.py', 'octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_load_balancer.py', 'octavia/db/models.py', 'octavia/network/base.py', 'octavia/network/data_models.py', 'octavia/db/migration/alembic_migrations/versions/14892634e228_update_vip.py', 'octavia/tests/unit/api/v1/types/test_load_balancers.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/9b989e2f8ade76a12d90b99dba0ff29c1838d113', 'message': 'Adding network driver interface\n\nDefinition of network driver interface.  Also removed\nthe floating_ip attributes of VIP because they are not\nneeded at this point.  Also renamed net_port_id to just\nport_id and subnet_id to network_id just to be a little\nbit more generically clear.\n\nChange-Id: Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af\nImplements: bp/network-driver-interface\n'}]",7,146271,9b989e2f8ade76a12d90b99dba0ff29c1838d113,23,6,4,6951,,,0,"Adding network driver interface

Definition of network driver interface.  Also removed
the floating_ip attributes of VIP because they are not
needed at this point.  Also renamed net_port_id to just
port_id and subnet_id to network_id just to be a little
bit more generically clear.

Change-Id: Ic82cb2ab25fbba7dc8caa875552f4caeafb0e4af
Implements: bp/network-driver-interface
",git fetch https://review.opendev.org/openstack/octavia refs/changes/71/146271/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/functional/db/test_repositories.py', 'octavia/api/v1/types/load_balancer.py', 'octavia/common/data_models.py', 'octavia/tests/functional/api/v1/test_load_balancer.py', 'octavia/db/models.py', 'octavia/network/base.py', 'octavia/network/data_models.py', 'octavia/db/migration/alembic_migrations/versions/14892634e228_update_vip.py', 'octavia/tests/unit/api/v1/types/test_load_balancers.py']",9,7827f8c490a17ef10227ec0e7aadd7168121f9a9,135495," ""port_id"": uuidutils.generate_uuid(), ""network_id"": uuidutils.generate_uuid()}} def test_invalid_port_id(self): body = {""port_id"": ""invalid_uuid""} def test_invalid_network_id(self): body = {""network_id"": ""invalid_uuid""}"," ""net_port_id"": uuidutils.generate_uuid(), ""subnet_id"": uuidutils.generate_uuid(), ""floating_ip_id"": uuidutils.generate_uuid(), ""floating_ip_network_id"": uuidutils.generate_uuid()}} def test_invalid_net_port_id(self): body = {""net_port_id"": ""invalid_uuid""} def test_invalid_subnet_id(self): body = {""subnet_id"": ""invalid_uuid""} def test_invalid_floating_ip_id(self): body = {""floating_ip_id"": ""invalid_uuid""} self.assertRaises(exc.InvalidInput, wsme_json.fromjson, self._type, body) def test_invalid_floating_network_ip_id(self): body = {""floating_ip_network_id"": ""invalid_uuid""} self.assertRaises(exc.InvalidInput, wsme_json.fromjson, self._type, body)",236,53
openstack%2Fkeystonemiddleware~master~I56e59bbde0c0ccf3328ffef3f599abf6a8940616,openstack/keystonemiddleware,master,I56e59bbde0c0ccf3328ffef3f599abf6a8940616,Correct failures for check H238,MERGED,2015-01-12 00:28:21.000000000,2015-01-13 17:00:45.000000000,2015-01-13 17:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-01-12 00:28:21.000000000', 'files': ['keystonemiddleware/auth_token.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e55f8e7802bc6b40381284052754e3a3cb386d0d', 'message': 'Correct failures for check H238\n\nThe H238 ""old style class declaration, use new style"" rule was failing\nand ignored. Now it\'s enforced.\n\nChange-Id: I56e59bbde0c0ccf3328ffef3f599abf6a8940616\n'}]",0,146357,e55f8e7802bc6b40381284052754e3a3cb386d0d,8,4,1,6486,,,0,"Correct failures for check H238

The H238 ""old style class declaration, use new style"" rule was failing
and ignored. Now it's enforced.

Change-Id: I56e59bbde0c0ccf3328ffef3f599abf6a8940616
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/57/146357/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/auth_token.py', 'tox.ini']",2,e55f8e7802bc6b40381284052754e3a3cb386d0d,hacking,"ignore = E122,F821,H304,H405,H703","# H238: old style class declaration, use new style (inherit from `object`)ignore = E122,F821,H238,H304,H405,H703",2,3
openstack%2Fkeystonemiddleware~master~Ifaf62839a4b6da62a3b380396158b463c1381026,openstack/keystonemiddleware,master,Ifaf62839a4b6da62a3b380396158b463c1381026,Move to hacking 0.10,MERGED,2015-01-12 00:18:06.000000000,2015-01-13 16:52:28.000000000,2015-01-13 16:52:26.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 9142}]","[{'number': 1, 'created': '2015-01-12 00:18:06.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d88401d6f171c7a1001015ceecf725e53932a07b', 'message': 'Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\nH803 is no longer enforced by hacking so the ignore is removed.\n\nChange-Id: Ifaf62839a4b6da62a3b380396158b463c1381026\n'}]",0,146353,d88401d6f171c7a1001015ceecf725e53932a07b,9,4,1,6486,,,0,"Move to hacking 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

H803 is no longer enforced by hacking so the ignore is removed.

Change-Id: Ifaf62839a4b6da62a3b380396158b463c1381026
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/53/146353/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,d88401d6f171c7a1001015ceecf725e53932a07b,hacking,"# E122: continuation line missing indentation or outdented# H238: old style class declaration, use new style (inherit from `object`)# H405: multi line docstring summary not separated with an empty line # H703: Multiple positional placeholders ignore = E122,F821,H238,H304,H405,H703","# H803 Commit message should not end with a period (do not remove per list discussion) ignore = F821,H304,H803",7,3
openstack%2Foslo.messaging~master~I516c580faef04f55fcc095d22adbfabcfa001da7,openstack/oslo.messaging,master,I516c580faef04f55fcc095d22adbfabcfa001da7,fix qpid test issue with eventlet monkey patching,MERGED,2015-01-12 17:00:50.000000000,2015-01-13 16:49:13.000000000,2015-01-13 16:49:12.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6928}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-01-12 17:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7d12a2f893363acd1dd6fdc8612ef58f82e4b094', 'message': 'fix qpid test issue with eventlet monkey patching\n\nTests now ensure that eventlet monkey patching is enabled before loading\nthe qpid module, otherwise qpid will hang.\n\nCurrently, qpid randomly hangs, depending on the order of the Python\nmodule import, which probably depends on the local file modification\ntime.\n\nChange-Id: I516c580faef04f55fcc095d22adbfabcfa001da7\n'}, {'number': 2, 'created': '2015-01-12 20:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/edfd5a6fbcdd329e7589375f143ab44c36fd651e', 'message': 'fix qpid test issue with eventlet monkey patching\n\nTests now ensure that eventlet monkey patching is enabled before\nimporting the qpid module, otherwise qpid will hang.\n\nCurrently, qpid randomly hangs, depending on the order of the Python\nmodule import, which probably depends on the local file modification\ntime.\n\nCloses-Bug: #1409899\nChange-Id: I516c580faef04f55fcc095d22adbfabcfa001da7\n'}, {'number': 3, 'created': '2015-01-13 10:35:39.000000000', 'files': ['tests/drivers/test_impl_zmq.py', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bc8675afb067c517cbe5ee1129aad080282bd7c4', 'message': 'fix qpid test issue with eventlet monkey patching\n\nTests now ensure that eventlet monkey patching is enabled before\nimporting the qpid module, otherwise qpid will hang.\n\nCurrently, qpid randomly hangs, depending on the order of the Python\nmodule import, which probably depends on the local file modification\ntime.\n\nCloses-Bug: #1409899\nChange-Id: I516c580faef04f55fcc095d22adbfabcfa001da7\n'}]",1,146574,bc8675afb067c517cbe5ee1129aad080282bd7c4,18,4,3,9107,,,0,"fix qpid test issue with eventlet monkey patching

Tests now ensure that eventlet monkey patching is enabled before
importing the qpid module, otherwise qpid will hang.

Currently, qpid randomly hangs, depending on the order of the Python
module import, which probably depends on the local file modification
time.

Closes-Bug: #1409899
Change-Id: I516c580faef04f55fcc095d22adbfabcfa001da7
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/74/146574/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/__init__.py'],1,7d12a2f893363acd1dd6fdc8612ef58f82e4b094,bug/1409899,"try: import eventlet except ImportError: pass else: # Ensure that eventlet monkey patching is enabled before loading the qpid # module, otherwise qpid will hang eventlet.monkey_patch()",,8,1
openstack%2Foslo.utils~master~I4db750fb2356ebf44a8fccf7c422b474fefec0ee,openstack/oslo.utils,master,I4db750fb2356ebf44a8fccf7c422b474fefec0ee,Make setup.cfg packages include oslo.utils,MERGED,2015-01-13 02:20:27.000000000,2015-01-13 16:48:17.000000000,2015-01-13 16:48:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-13 02:20:27.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/942cf060a1ece4999234191da19aea48e005f740', 'message': 'Make setup.cfg packages include oslo.utils\n\nThis properly deploys the oslo.utils package may resolve\nsphinx build errors for projects which have not yet\nupgraded to oslo_utils.\n\nChange-Id: I4db750fb2356ebf44a8fccf7c422b474fefec0ee\n'}]",0,146735,942cf060a1ece4999234191da19aea48e005f740,7,3,1,360,,,0,"Make setup.cfg packages include oslo.utils

This properly deploys the oslo.utils package may resolve
sphinx build errors for projects which have not yet
upgraded to oslo_utils.

Change-Id: I4db750fb2356ebf44a8fccf7c422b474fefec0ee
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/35/146735/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,942cf060a1ece4999234191da19aea48e005f740,setup_cfg_fix, oslo.utils,,1,0
openstack%2Fgnocchi~master~I199b955c1f204f88512249e0d3f07b69dfae9497,openstack/gnocchi,master,I199b955c1f204f88512249e0d3f07b69dfae9497,Fix ceilometer dispacher to conform to the new name,MERGED,2015-01-12 10:09:31.000000000,2015-01-13 16:30:06.000000000,2015-01-13 16:30:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 10987}, {'_account_id': 12119}]","[{'number': 1, 'created': '2015-01-12 10:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/554506d8af032592b7189a12ea562735d7568088', 'message': 'Fix ceilometer dispacher to conform to the new name\n\nfrom `archive_policy` to `archive_policy_name`\n\nChange-Id: I199b955c1f204f88512249e0d3f07b69dfae9497\n'}, {'number': 2, 'created': '2015-01-13 01:06:22.000000000', 'files': ['gnocchi/ceilometer/dispatcher.py', 'gnocchi/tests/test_ceilometer_dispatcher.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/3a580e486ba1e18aec1b27ebebe206be42087998', 'message': 'Fix ceilometer dispacher to conform to the new name\n\nfrom `archive_policy` to `archive_policy_name`\n\nChange-Id: I199b955c1f204f88512249e0d3f07b69dfae9497\n'}]",2,146406,3a580e486ba1e18aec1b27ebebe206be42087998,16,4,2,12119,,,0,"Fix ceilometer dispacher to conform to the new name

from `archive_policy` to `archive_policy_name`

Change-Id: I199b955c1f204f88512249e0d3f07b69dfae9497
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/06/146406/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/ceilometer/dispatcher.py'],1,554506d8af032592b7189a12ea562735d7568088,, 'archive_policy_name':, 'archive_policy':,1,1
openstack%2Fpython-neutronclient~master~I0f2ec22da7ba36f79197acb41d0621fc726cc0f3,openstack/python-neutronclient,master,I0f2ec22da7ba36f79197acb41d0621fc726cc0f3,Correct the bash completion of CLI,MERGED,2014-07-16 03:18:57.000000000,2015-01-13 16:26:58.000000000,2015-01-13 16:26:55.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 7787}, {'_account_id': 8290}, {'_account_id': 8976}, {'_account_id': 12376}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-07-16 03:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/6fef52bcd88e12383eceb273a07cf4c4917ddb9b', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI dosen\'t expose the\n""bash-completion"" command to user, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will print a wrong\nresult. This patch add the ""bash-completion"" command to commands list of\nneutron CLI and remove the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 2, 'created': '2014-07-16 04:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9189e1c62b713775a9b4998c69fb937ab5b415ae', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI dosen\'t expose the\n""bash-completion"" command to user, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will print a wrong\nresult. This patch add the ""bash-completion"" command to commands list of\nneutron CLI and remove the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 3, 'created': '2014-07-17 02:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b7aec96999fad983b1983f3e168745fb61a52fd7', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI dosen\'t exposes the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 4, 'created': '2014-07-18 01:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8e8b1443c434e7e0f816e01ef6ae5fae1c78fc01', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI doesn\'t expose the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 5, 'created': '2014-09-04 07:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/68941472d688a8e32e8d22d7e54fc95722392a47', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI doesn\'t expose the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 6, 'created': '2014-09-05 06:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/425078d49396d2b441971a80fdb4e8ce5e4925da', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI doesn\'t expose the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 7, 'created': '2014-12-11 04:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/864911daba548f237a5354eb742b6c207fb5b2ab', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI doesn\'t expose the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}, {'number': 8, 'created': '2014-12-11 06:15:13.000000000', 'files': ['neutronclient/tests/unit/test_shell.py', 'neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/187c36c19b0e43740df3c46c6f34d3d0ad76a510', 'message': 'Correct the bash completion of CLI\n\nCurrently, the ""neutron help"" command in CLI doesn\'t expose the\n""bash-completion"" command to users, but actually, the ""neutron\nbash-completion"" command is available. Additionally, there is a ""complete""\ncommand in outputs of ""neutron help"", but this command will prints a wrong\nresult. This patch adds the ""bash-completion"" command to commands list of\nneutron CLI and removes the ""complete"" command.\n\nChange-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3\nCloses-Bug: #1340647\n'}]",31,107226,187c36c19b0e43740df3c46c6f34d3d0ad76a510,51,9,8,8290,,,0,"Correct the bash completion of CLI

Currently, the ""neutron help"" command in CLI doesn't expose the
""bash-completion"" command to users, but actually, the ""neutron
bash-completion"" command is available. Additionally, there is a ""complete""
command in outputs of ""neutron help"", but this command will prints a wrong
result. This patch adds the ""bash-completion"" command to commands list of
neutron CLI and removes the ""complete"" command.

Change-Id: I0f2ec22da7ba36f79197acb41d0621fc726cc0f3
Closes-Bug: #1340647
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/26/107226/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_shell.py', 'neutronclient/shell.py']",2,6fef52bcd88e12383eceb273a07cf4c4917ddb9b,bug/1340647,"from neutronclient.neutron.v2_0 import UpdateCommand class _bash_completion_cls(UpdateCommand): """"""Prints all of the commands and options for bash-completion."""""" resource = ""bash_completion"" log = self.log # NOTE(liusheng): here we pop the 'complete' in commands and add the # 'bash-completion' to correct the outputs of 'neutron help'. self.command_manager.commands.pop('complete') self.command_manager.add_command('bash-completion', _bash_completion_cls)",,33,0
openstack%2Fnova~master~I2e1dd37b6297feae581b0584615266df392c0509,openstack/nova,master,I2e1dd37b6297feae581b0584615266df392c0509,libvirt: fix order of arguments in assertEqual,ABANDONED,2014-09-05 13:01:42.000000000,2015-01-13 16:04:46.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-09-05 13:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fe3c360e778515a4b6068c8181c06cf8eddf02d', 'message': 'libvirt: fix order of arguments in assertEqual\n\nSome tests used incorrect order assertEqual(observed, expected).\n\nThe correct order expected by testtools is\nassertEqual(expected, observed).\n\nChange-Id: I2e1dd37b6297feae581b0584615266df392c0509\nPartial-Bug: #1259292\n'}, {'number': 2, 'created': '2014-10-01 12:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd898c6f7f6f484538ccf5a603d870b76d15f726', 'message': 'libvirt: fix order of arguments in assertEqual\n\nSome tests used incorrect order assertEqual(observed, expected).\n\nThe correct order expected by testtools is\nassertEqual(expected, observed).\n\nChange-Id: I2e1dd37b6297feae581b0584615266df392c0509\nPartial-Bug: #1259292\n'}, {'number': 3, 'created': '2014-10-08 08:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b10463abf967b6c7421b79c262479d8eb12aadc3', 'message': 'libvirt: fix order of arguments in assertEqual\n\nSome tests used incorrect order assertEqual(observed, expected). The correct\norder expected by testtools is assertEqual(expected, observed).\n\nPartial-Bug: #1259292\nChange-Id: I2e1dd37b6297feae581b0584615266df392c0509\n'}, {'number': 4, 'created': '2014-10-21 08:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d600f5bf6f386066e2efcfd70d1a3258eb158147', 'message': 'libvirt: fix order of arguments in assertEqual\n\nSome tests used incorrect order assertEqual(observed, expected). The correct\norder expected by testtools is assertEqual(expected, observed).\n\nPartial-Bug: #1259292\nChange-Id: I2e1dd37b6297feae581b0584615266df392c0509\n'}, {'number': 5, 'created': '2014-11-19 11:39:28.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/35cc948dd5ff39dc3f6fe20716712c5b4b6e87be', 'message': 'libvirt: fix order of arguments in assertEqual\n\nSome tests used incorrect order assertEqual(observed, expected). The correct\norder expected by testtools is assertEqual(expected, observed).\n\nPartial-Bug: #1259292\nChange-Id: I2e1dd37b6297feae581b0584615266df392c0509\n'}]",0,119367,35cc948dd5ff39dc3f6fe20716712c5b4b6e87be,54,14,5,91,,,0,"libvirt: fix order of arguments in assertEqual

Some tests used incorrect order assertEqual(observed, expected). The correct
order expected by testtools is assertEqual(expected, observed).

Partial-Bug: #1259292
Change-Id: I2e1dd37b6297feae581b0584615266df392c0509
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/119367/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/virt/libvirt/test_driver.py'],1,0fe3c360e778515a4b6068c8181c06cf8eddf02d,bug/1259292," self.assertEqual('marked', pci_devices[0]['hypervisor_name']) self.assertEqual(instance_ref[""uuid""], cfg.uuid) self.assertEqual(6 * units.Ki, cfg.memory) self.assertEqual(28, cfg.vcpus) self.assertEqual(vm_mode.HVM, cfg.os_type) self.assertEqual([""hd""], cfg.os_boot_dev) self.assertEqual(9, len(cfg.devices)) self.assertEqual(1, len(cfg.metadata)) self.assertEqual(""utc"", cfg.clock.offset) self.assertEqual(""pit"", cfg.clock.timers[0].name) self.assertEqual(""delay"", cfg.clock.timers[0].tickpolicy) self.assertEqual(""rtc"", cfg.clock.timers[1].name) self.assertEqual(""catchup"", cfg.clock.timers[1].tickpolicy) self.assertEqual(""localtime"", cfg.clock.offset) self.assertEqual(2 * units.Mi, cfg.memory) self.assertEqual(1, cfg.vcpus) self.assertEqual(vm_mode.HVM, cfg.os_type) self.assertEqual([""hd""], cfg.os_boot_dev) self.assertEqual(10, len(cfg.devices)) self.assertEqual('/dev/vda', instance_ref['root_device_name']) self.assertEqual(2 * units.Mi, cfg.memory) self.assertEqual(1, cfg.vcpus) self.assertEqual(""uml"", cfg.os_type) self.assertEqual([], cfg.os_boot_dev) self.assertEqual('/dev/vdb', cfg.os_root) self.assertEqual(3, len(cfg.devices)) self.assertEqual('vdc', cfg.devices[2].target_dev) self.assertEqual('vdd', cfg.devices[3].target_dev) self.assertEqual(disk, cfg.devices[2].target_dev) self.assertEqual('virtio-scsi', cfg.devices[2].model) self.assertEqual('sdc', cfg.devices[2].target_dev) self.assertEqual('scsi', cfg.devices[2].target_bus) self.assertEqual('sdd', cfg.devices[3].target_dev) self.assertEqual('scsi', cfg.devices[3].target_bus) self.assertEqual('virtio-scsi', cfg.devices[4].model) self.assertEqual(7, len(cfg.devices)) self.assertEqual(""vnc"", cfg.devices[4].type) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""tablet"", cfg.devices[4].type) self.assertEqual(""vnc"", cfg.devices[5].type) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""tablet"", cfg.devices[4].type) self.assertEqual(""spice"", cfg.devices[5].type) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""com.redhat.spice.0"", cfg.devices[4].target_name) self.assertEqual(""spice"", cfg.devices[5].type) self.assertEqual(""qxl"", cfg.devices[6].type) self.assertEqual(6, len(cfg.devices)) self.assertEqual(""vnc"", cfg.devices[3].type) self.assertEqual(""xen"", cfg.devices[4].type) self.assertEqual(vm_mode.HVM, cfg.os_type) self.assertEqual(CONF.libvirt.xen_hvmloader_path, cfg.os_loader) self.assertEqual(vm_mode.XEN, cfg.os_type) self.assertEqual(10, len(cfg.devices)) self.assertEqual(""tablet"", cfg.devices[4].type) self.assertEqual(""com.redhat.spice.0"", cfg.devices[5].target_name) self.assertEqual(""vnc"", cfg.devices[6].type) self.assertEqual(""spice"", cfg.devices[7].type) self.assertEqual(9, len(cfg.devices)) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""vnc"", cfg.devices[5].type) self.assertEqual(""vmvga"", cfg.devices[6].type) self.assertEqual(9, len(cfg.devices)) self.assertEqual(""tablet"", cfg.devices[4].type) self.assertEqual(""vnc"", cfg.devices[5].type) self.assertEqual(""unix"", cfg.devices[7].type) self.assertEqual(""org.qemu.guest_agent.0"", cfg.devices[7].target_name) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""spice"", cfg.devices[5].type) self.assertEqual(""qxl"", cfg.devices[6].type) self.assertEqual(64, cfg.devices[6].vram) self.assertEqual(8, len(cfg.devices)) self.assertEqual(""tablet"", cfg.devices[4].type) self.assertEqual(""vnc"", cfg.devices[5].type) self.assertEqual(8, len(cfg.devices)) self.assertEqual('random', cfg.devices[6].model) self.assertEqual(7, len(cfg.devices)) self.assertEqual(8, len(cfg.devices)) self.assertEqual('random', cfg.devices[6].model) self.assertEqual(1024, cfg.devices[6].rate_bytes) self.assertEqual(2, cfg.devices[6].rate_period) self.assertEqual(8, len(cfg.devices)) self.assertEqual('random', cfg.devices[6].model) self.assertEqual('/dev/hw_rng', cfg.devices[6].backend) self.assertEqual('pci', dev.type) self.assertEqual('yes', dev.managed) self.assertEqual('subsystem', dev.mode) self.assertEqual(""0000"", dev.domain) self.assertEqual(""00"", dev.bus) self.assertEqual(""00"", dev.slot) self.assertEqual(""1"", dev.function) self.assertEqual(1, had_pci) self.assertEqual('pci', dev.type) self.assertEqual('no', dev.managed) self.assertEqual('subsystem', dev.mode) self.assertEqual(""0000"", dev.domain) self.assertEqual(""00"", dev.bus) self.assertEqual(""00"", dev.slot) self.assertEqual(""2"", dev.function) self.assertEqual(1, had_pci) self.assertEqual(""fake_os_command_line"", cfg.os_cmdline) self.assertEqual(""vexpress-a15"", cfg.os_mach_type) self.assertEqual(""virt"", cfg.os_mach_type) self.assertEqual(""fake_machine_type"", cfg.os_mach_type) self.assertEqual(""fake_machine_type"", cfg.os_mach_type) self.assertEqual('vga', cfg.devices[device_index].type) self.assertEqual(1, conf.cpu.sockets) self.assertEqual(1, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(""host-model"", conf.cpu.mode) self.assertEqual(1, conf.cpu.sockets) self.assertEqual(1, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(""host-passthrough"", conf.cpu.mode) self.assertEqual(1, conf.cpu.sockets) self.assertEqual(1, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(""host-model"", conf.cpu.mode) self.assertEqual(1, conf.cpu.sockets) self.assertEqual(1, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(""custom"", conf.cpu.mode) self.assertEqual(""Penryn"", conf.cpu.model) self.assertEqual(1, conf.cpu.sockets) self.assertEqual(1, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(""host-model"", conf.cpu.mode) self.assertEqual(4, conf.cpu.sockets) self.assertEqual(2, conf.cpu.cores) self.assertEqual(1, conf.cpu.threads) self.assertEqual(2, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(4, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(vm3.name(), doms[2].name()) self.assertEqual(vm4.name(), doms[3].name()) self.assertEqual(2, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(4, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(vm3.name(), doms[2].name()) self.assertEqual(vm4.name(), doms[3].name()) self.assertEqual(2, len(doms)) self.assertEqual(vm1.id, doms[0].id) self.assertEqual(vm2.id, doms[1].id) self.assertEqual(2, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(4, len(doms)) self.assertEqual(vm1.name(), doms[0].name()) self.assertEqual(vm2.name(), doms[1].name()) self.assertEqual(vm3.name(), doms[2].name()) self.assertEqual(vm4.name(), doms[3].name()) self.assertEqual(3, len(doms)) self.assertEqual(vm0.name(), doms[0].name()) self.assertEqual(vm1.name(), doms[1].name()) self.assertEqual(vm2.name(), doms[2].name()) self.assertEqual(vm1.name(), names[0]) self.assertEqual(vm2.name(), names[1]) self.assertEqual(vm3.name(), names[2]) self.assertEqual(vm4.name(), names[3]) self.assertEqual(4, len(uuids)) self.assertEqual(vm1.UUIDString(), uuids[0]) self.assertEqual(vm2.UUIDString(), uuids[1]) self.assertEqual(vm3.UUIDString(), uuids[2]) self.assertEqual(vm4.UUIDString(), uuids[3]) self.assertEqual(['/path/to/dev/1', '/path/to/dev/3'], devices) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('ami', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('ami', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('raw', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('raw', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('qcow2', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual('qcow2', snapshot['disk_format']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual('fake_arch', snapshot['properties']['architecture']) self.assertEqual('value_a', snapshot['properties']['key_a']) self.assertEqual('value_b', snapshot['properties']['key_b']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual('available', snapshot['properties']['image_state']) self.assertEqual(instance_ref['os_type'], snapshot['properties']['os_type']) self.assertEqual('active', snapshot['status']) self.assertEqual(snapshot_name, snapshot['name']) self.assertEqual(expected, ret) self.assertEqual(expected, ret) self.assertEqual(2, len(interfaces)) self.assertEqual('bridge', interfaces[0].get('type')) self.assertEqual('lxc:///', conn.uri()) self.assertEqual(expected_result, check(tree), self.assertEqual(expected_result, check(tree), self.assertEqual(""none"", guest_disk.get(""cache"")) self.assertEqual(""writethrough"", guest_disk.get(""cache"")) self.assertEqual(want_device_type, got_device_type) self.assertEqual(want_device_bus, got_device_bus) self.assertEqual(want_device_dev, got_device_dev) self.assertEqual(instance_ref['uuid'], tree.find('./uuid').text) self.assertEqual(expected_uri, conn.uri()) self.assertEqual(expected_result, check(tree), self.assertEqual(expected_result, check(tree), self.assertEqual(instance_filter_name, tree.find(filterref).get('filter')) self.assertEqual(testuri, conn.uri()) self.assertEqual(1, len(create_ephemeral_mock.call_args_list)) self.assertEqual(1, len(fetch_image_mock.call_args_list)) self.assertEqual(target_res, result) self.assertEqual(target_ret, ret) self.assertEqual('raw', info[0]['type']) self.assertEqual('/test/disk', info[0]['path']) self.assertEqual(10737418240, info[0]['disk_size']) self.assertEqual("""", info[0]['backing_file']) self.assertEqual(0, info[0]['over_committed_disk_size']) self.assertEqual('qcow2', info[1]['type']) self.assertEqual('/test/disk.local', info[1]['path']) self.assertEqual(21474836480, info[1]['virt_disk_size']) self.assertEqual(""file"", info[1]['backing_file']) self.assertEqual(18146236825, info[1]['over_committed_disk_size']) self.assertEqual('raw', info[0]['type']) self.assertEqual('/test/disk', info[0]['path']) self.assertEqual(10737418240, info[0]['disk_size']) self.assertEqual("""", info[0]['backing_file']) self.assertEqual(0, info[0]['over_committed_disk_size']) self.assertEqual('qcow2', info[1]['type']) self.assertEqual('/test/disk.local', info[1]['path']) self.assertEqual(21474836480, info[1]['virt_disk_size']) self.assertEqual(""file"", info[1]['backing_file']) self.assertEqual(18146236825, info[1]['over_committed_disk_size']) self.assertEqual(wantFiles, gotFiles) self.assertEqual(wantFiles, gotFiles) self.assertEqual(CONF.my_ip, ip) self.assertEqual(0, called['count']) else: self.assertEqual(1, called['count']) self.assertEqual(1, called['count']) self.assertEqual(want_device_bus, got_device_bus) self.assertEqual(10653532160, result) self.assertEqual(expect_vf, actualvf) self.assertEqual(expect_vf, actualvf) self.assertEqual(expectvfs[1][key], actctualvfs[0][key]) self.assertEqual(expect, actual) self.assertEqual(actual.serialize(), expected) self.assertEqual(expect, actual) self.assertEqual(expect, actual) self.assertEqual(expect, actual) self.assertEqual(expect, actual) self.assertEqual(1, len(got_events)) self.assertEqual(""cef19ce0-0ca2-11df-855d-b19fbce37686"", got_events[0].uuid) self.assertEqual(virtevent.EVENT_LIFECYCLE_STOPPED, got_events[0].transition) self.assertEqual('directsync', fake_conf.driver_cache) self.assertEqual('fake', fake_conf.driver_cache) self.assertEqual('5900', vnc_dict.port) self.assertEqual('5950', spice_dict.port) self.assertEqual( '/dev/vda', conn.default_root_device_name(instance, image_meta, root_bdm) ) self.assertEqual(1, self.connect_calls) self.assertEqual(1, self.register_calls) self.assertEqual(1, self.connect_calls) self.assertEqual(1, self.register_calls) self.assertEqual('/path/fake-volume1', connection_info['data']['device_path']) self.assertEqual(1, stats[""vcpus""]) self.assertEqual(497, stats[""memory_mb""]) self.assertEqual(100, stats[""local_gb""]) self.assertEqual(0, stats[""vcpus_used""]) self.assertEqual(88, stats[""memory_mb_used""]) self.assertEqual(20, stats[""local_gb_used""]) self.assertEqual('QEMU', stats[""hypervisor_type""]) self.assertEqual(13091, stats[""hypervisor_version""]) self.assertEqual('compute1', stats[""hypervisor_hostname""]) d = {""vendor"": ""Intel"", ""model"": ""pentium"", ""arch"": ""i686"", ""features"": [""ssse3"", ""monitor"", ""pni"", ""sse2"", ""sse"", ""fxsr"", ""clflush"", ""pse36"", ""pat"", ""cmov"", ""mca"", ""pge"", ""mtrr"", ""sep"", ""apic""], ""topology"": {""cores"": ""1"", ""threads"": ""1"", ""sockets"": ""1""}} self.assertEqual(d, jsonutils.loads(stats[""cpu_info""])) self.assertEqual(80, stats[""disk_available_least""]) self.assertEqual(HostStateTestCase.pci_devices, jsonutils.loads(stats[""pci_passthrough_devices""])) self.assertEqual(2, len(rulesv4)) self.assertEqual(1, len(rulesv6)) self.assertEqual(2, len(rulesv4)) self.assertEqual(0, len(rulesv6)) self.assertEqual(1, original_filter_count - len(fakefilter.filters)) self.assertEqual(1, original_filter_count - len(fakefilter.filters)) self.assertEqual(expected_result, result) self.assertEqual(""tap"", result) self.assertEqual(4592640, disk.get_disk_size('/some/path')) self.assertEqual('canary', fp.read()) self.assertEqual('hello', fp.read()) self.assertEqual('hello', fp.read()) self.assertEqual(0, mode & 0o277) self.assertEqual('hello', libvirt_utils.load_file(dst_path)) self.assertEqual('hello', fp.read()) self.assertEqual(expected_commands, self.executes) self.assertEqual(expected_commands, self.executes) self.assertEqual(expected_commands, self.executes) self.assertEqual(expected_commands, self.executes) self.assertEqual('baz', out) self.assertEqual('c', out) self.assertEqual(disk_info_text, out) self.assertEqual(disk_info_text, out) self.assertEqual(out, disk_info_text) self.assertEqual(power_on, powered_on) self.assertEqual(resize_instance, self.fake_disk_resize_called) self.assertEqual(power_on, powered_on) self.assertEqual(called, disk_inject_data.called) self.assertEqual(expected_usage, vol_usage) self.assertEqual([], vol_usage)"," self.assertEqual(pci_devices[0]['hypervisor_name'], 'marked') self.assertEqual(cfg.uuid, instance_ref[""uuid""]) self.assertEqual(cfg.memory, 6 * units.Ki) self.assertEqual(cfg.vcpus, 28) self.assertEqual(cfg.os_type, vm_mode.HVM) self.assertEqual(cfg.os_boot_dev, [""hd""]) self.assertEqual(len(cfg.devices), 9) self.assertEqual(len(cfg.metadata), 1) self.assertEqual(cfg.clock.offset, ""utc"") self.assertEqual(cfg.clock.timers[0].name, ""pit"") self.assertEqual(cfg.clock.timers[0].tickpolicy, ""delay"") self.assertEqual(cfg.clock.timers[1].name, ""rtc"") self.assertEqual(cfg.clock.timers[1].tickpolicy, ""catchup"") self.assertEqual(cfg.clock.offset, ""localtime"") self.assertEqual(cfg.memory, 2 * units.Mi) self.assertEqual(cfg.vcpus, 1) self.assertEqual(cfg.os_type, vm_mode.HVM) self.assertEqual(cfg.os_boot_dev, [""hd""]) self.assertEqual(len(cfg.devices), 10) self.assertEqual(instance_ref['root_device_name'], '/dev/vda') self.assertEqual(cfg.memory, 2 * units.Mi) self.assertEqual(cfg.vcpus, 1) self.assertEqual(cfg.os_type, ""uml"") self.assertEqual(cfg.os_boot_dev, []) self.assertEqual(cfg.os_root, '/dev/vdb') self.assertEqual(len(cfg.devices), 3) self.assertEqual(cfg.devices[2].target_dev, 'vdc') self.assertEqual(cfg.devices[3].target_dev, 'vdd') self.assertEqual(cfg.devices[2].target_dev, disk) self.assertEqual(cfg.devices[2].model, 'virtio-scsi') self.assertEqual(cfg.devices[2].target_dev, 'sdc') self.assertEqual(cfg.devices[2].target_bus, 'scsi') self.assertEqual(cfg.devices[3].target_dev, 'sdd') self.assertEqual(cfg.devices[3].target_bus, 'scsi') self.assertEqual(cfg.devices[4].model, 'virtio-scsi') self.assertEqual(len(cfg.devices), 7) self.assertEqual(cfg.devices[4].type, ""vnc"") self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[4].type, ""tablet"") self.assertEqual(cfg.devices[5].type, ""vnc"") self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[4].type, ""tablet"") self.assertEqual(cfg.devices[5].type, ""spice"") self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[4].target_name, ""com.redhat.spice.0"") self.assertEqual(cfg.devices[5].type, ""spice"") self.assertEqual(cfg.devices[6].type, ""qxl"") self.assertEqual(len(cfg.devices), 6) self.assertEqual(cfg.devices[3].type, ""vnc"") self.assertEqual(cfg.devices[4].type, ""xen"") self.assertEqual(cfg.os_type, vm_mode.HVM) self.assertEqual(cfg.os_loader, CONF.libvirt.xen_hvmloader_path) self.assertEqual(cfg.os_type, vm_mode.XEN) self.assertEqual(len(cfg.devices), 10) self.assertEqual(cfg.devices[4].type, ""tablet"") self.assertEqual(cfg.devices[5].target_name, ""com.redhat.spice.0"") self.assertEqual(cfg.devices[6].type, ""vnc"") self.assertEqual(cfg.devices[7].type, ""spice"") self.assertEqual(len(cfg.devices), 9) self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[5].type, ""vnc"") self.assertEqual(cfg.devices[6].type, ""vmvga"") self.assertEqual(len(cfg.devices), 9) self.assertEqual(cfg.devices[4].type, ""tablet"") self.assertEqual(cfg.devices[5].type, ""vnc"") self.assertEqual(cfg.devices[7].type, ""unix"") self.assertEqual(cfg.devices[7].target_name, ""org.qemu.guest_agent.0"") self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[5].type, ""spice"") self.assertEqual(cfg.devices[6].type, ""qxl"") self.assertEqual(cfg.devices[6].vram, 64) self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[4].type, ""tablet"") self.assertEqual(cfg.devices[5].type, ""vnc"") self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[6].model, 'random') self.assertEqual(len(cfg.devices), 7) self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[6].model, 'random') self.assertEqual(cfg.devices[6].rate_bytes, 1024) self.assertEqual(cfg.devices[6].rate_period, 2) self.assertEqual(len(cfg.devices), 8) self.assertEqual(cfg.devices[6].model, 'random') self.assertEqual(cfg.devices[6].backend, '/dev/hw_rng') self.assertEqual(dev.type, 'pci') self.assertEqual(dev.managed, 'yes') self.assertEqual(dev.mode, 'subsystem') self.assertEqual(dev.domain, ""0000"") self.assertEqual(dev.bus, ""00"") self.assertEqual(dev.slot, ""00"") self.assertEqual(dev.function, ""1"") self.assertEqual(had_pci, 1) self.assertEqual(dev.type, 'pci') self.assertEqual(dev.managed, 'no') self.assertEqual(dev.mode, 'subsystem') self.assertEqual(dev.domain, ""0000"") self.assertEqual(dev.bus, ""00"") self.assertEqual(dev.slot, ""00"") self.assertEqual(dev.function, ""2"") self.assertEqual(had_pci, 1) self.assertEqual(cfg.os_cmdline, ""fake_os_command_line"") self.assertEqual(cfg.os_mach_type, ""vexpress-a15"") self.assertEqual(cfg.os_mach_type, ""virt"") self.assertEqual(cfg.os_mach_type, ""fake_machine_type"") self.assertEqual(cfg.os_mach_type, ""fake_machine_type"") self.assertEqual(cfg.devices[device_index].type, 'vga') self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(conf.cpu.mode, ""host-model"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(conf.cpu.mode, ""host-passthrough"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(conf.cpu.mode, ""host-model"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(conf.cpu.mode, ""custom"") self.assertEqual(conf.cpu.model, ""Penryn"") self.assertEqual(conf.cpu.sockets, 1) self.assertEqual(conf.cpu.cores, 1) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(conf.cpu.mode, ""host-model"") self.assertEqual(conf.cpu.sockets, 4) self.assertEqual(conf.cpu.cores, 2) self.assertEqual(conf.cpu.threads, 1) self.assertEqual(len(doms), 2) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(len(doms), 4) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(doms[2].name(), vm3.name()) self.assertEqual(doms[3].name(), vm4.name()) self.assertEqual(len(doms), 2) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(len(doms), 4) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(doms[2].name(), vm3.name()) self.assertEqual(doms[3].name(), vm4.name()) self.assertEqual(len(doms), 2) self.assertEqual(doms[0].id, vm1.id) self.assertEqual(doms[1].id, vm2.id) self.assertEqual(len(doms), 2) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(len(doms), 4) self.assertEqual(doms[0].name(), vm1.name()) self.assertEqual(doms[1].name(), vm2.name()) self.assertEqual(doms[2].name(), vm3.name()) self.assertEqual(doms[3].name(), vm4.name()) self.assertEqual(len(doms), 3) self.assertEqual(doms[0].name(), vm0.name()) self.assertEqual(doms[1].name(), vm1.name()) self.assertEqual(doms[2].name(), vm2.name()) self.assertEqual(names[0], vm1.name()) self.assertEqual(names[1], vm2.name()) self.assertEqual(names[2], vm3.name()) self.assertEqual(names[3], vm4.name()) self.assertEqual(len(uuids), 4) self.assertEqual(uuids[0], vm1.UUIDString()) self.assertEqual(uuids[1], vm2.UUIDString()) self.assertEqual(uuids[2], vm3.UUIDString()) self.assertEqual(uuids[3], vm4.UUIDString()) self.assertEqual(devices, ['/path/to/dev/1', '/path/to/dev/3']) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'ami') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'ami') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'raw') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'raw') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'qcow2') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['disk_format'], 'qcow2') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['properties']['architecture'], 'fake_arch') self.assertEqual(snapshot['properties']['key_a'], 'value_a') self.assertEqual(snapshot['properties']['key_b'], 'value_b') self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(snapshot['properties']['image_state'], 'available') self.assertEqual(snapshot['properties']['os_type'], instance_ref['os_type']) self.assertEqual(snapshot['status'], 'active') self.assertEqual(snapshot['name'], snapshot_name) self.assertEqual(ret, expected) self.assertEqual(ret, expected) self.assertEqual(len(interfaces), 2) self.assertEqual(interfaces[0].get('type'), 'bridge') self.assertEqual(conn.uri(), 'lxc:///') self.assertEqual(check(tree), expected_result, self.assertEqual(check(tree), expected_result, self.assertEqual(guest_disk.get(""cache""), ""none"") self.assertEqual(guest_disk.get(""cache""), ""writethrough"") self.assertEqual(got_device_type, want_device_type) self.assertEqual(got_device_bus, want_device_bus) self.assertEqual(got_device_dev, want_device_dev) self.assertEqual(tree.find('./uuid').text, instance_ref['uuid']) self.assertEqual(conn.uri(), expected_uri) self.assertEqual(check(tree), expected_result, self.assertEqual(check(tree), expected_result, self.assertEqual(tree.find(filterref).get('filter'), instance_filter_name) self.assertEqual(conn.uri(), testuri) self.assertEqual(len(create_ephemeral_mock.call_args_list), 1) self.assertEqual(len(fetch_image_mock.call_args_list), 1) self.assertEqual(result, target_res) self.assertEqual(ret, target_ret) self.assertEqual(info[0]['type'], 'raw') self.assertEqual(info[0]['path'], '/test/disk') self.assertEqual(info[0]['disk_size'], 10737418240) self.assertEqual(info[0]['backing_file'], """") self.assertEqual(info[0]['over_committed_disk_size'], 0) self.assertEqual(info[1]['type'], 'qcow2') self.assertEqual(info[1]['path'], '/test/disk.local') self.assertEqual(info[1]['virt_disk_size'], 21474836480) self.assertEqual(info[1]['backing_file'], ""file"") self.assertEqual(info[1]['over_committed_disk_size'], 18146236825) self.assertEqual(info[0]['type'], 'raw') self.assertEqual(info[0]['path'], '/test/disk') self.assertEqual(info[0]['disk_size'], 10737418240) self.assertEqual(info[0]['backing_file'], """") self.assertEqual(info[0]['over_committed_disk_size'], 0) self.assertEqual(info[1]['type'], 'qcow2') self.assertEqual(info[1]['path'], '/test/disk.local') self.assertEqual(info[1]['virt_disk_size'], 21474836480) self.assertEqual(info[1]['backing_file'], ""file"") self.assertEqual(info[1]['over_committed_disk_size'], 18146236825) self.assertEqual(gotFiles, wantFiles) self.assertEqual(gotFiles, wantFiles) self.assertEqual(ip, CONF.my_ip) self.assertEqual(called['count'], 0) else: self.assertEqual(called['count'], 1) self.assertEqual(called['count'], 1) self.assertEqual(got_device_bus, want_device_bus) self.assertEqual(result, 10653532160) self.assertEqual(actualvf, expect_vf) self.assertEqual(actualvf, expect_vf) self.assertEqual(actctualvfs[0][key], expectvfs[1][key]) self.assertEqual(actual, expect) self.assertEqual(expected, actual.serialize()) self.assertEqual(actual, expect) self.assertEqual(actual, expect) self.assertEqual(actual, expect) self.assertEqual(actual, expect) self.assertEqual(len(got_events), 1) self.assertEqual(got_events[0].uuid, ""cef19ce0-0ca2-11df-855d-b19fbce37686"") self.assertEqual(got_events[0].transition, virtevent.EVENT_LIFECYCLE_STOPPED) self.assertEqual(fake_conf.driver_cache, 'directsync') self.assertEqual(fake_conf.driver_cache, 'fake') self.assertEqual(vnc_dict.port, '5900') self.assertEqual(spice_dict.port, '5950') self.assertEqual(conn.default_root_device_name(instance, image_meta, root_bdm), '/dev/vda') self.assertEqual(self.connect_calls, 1) self.assertEqual(self.register_calls, 1) self.assertEqual(self.connect_calls, 1) self.assertEqual(self.register_calls, 1) self.assertEqual(connection_info['data']['device_path'], '/path/fake-volume1') self.assertEqual(stats[""vcpus""], 1) self.assertEqual(stats[""memory_mb""], 497) self.assertEqual(stats[""local_gb""], 100) self.assertEqual(stats[""vcpus_used""], 0) self.assertEqual(stats[""memory_mb_used""], 88) self.assertEqual(stats[""local_gb_used""], 20) self.assertEqual(stats[""hypervisor_type""], 'QEMU') self.assertEqual(stats[""hypervisor_version""], 13091) self.assertEqual(stats[""hypervisor_hostname""], 'compute1') self.assertEqual(jsonutils.loads(stats[""cpu_info""]), {""vendor"": ""Intel"", ""model"": ""pentium"", ""arch"": ""i686"", ""features"": [""ssse3"", ""monitor"", ""pni"", ""sse2"", ""sse"", ""fxsr"", ""clflush"", ""pse36"", ""pat"", ""cmov"", ""mca"", ""pge"", ""mtrr"", ""sep"", ""apic""], ""topology"": {""cores"": ""1"", ""threads"": ""1"", ""sockets"": ""1""} }) self.assertEqual(stats[""disk_available_least""], 80) self.assertEqual(jsonutils.loads(stats[""pci_passthrough_devices""]), HostStateTestCase.pci_devices) self.assertEqual(len(rulesv4), 2) self.assertEqual(len(rulesv6), 1) self.assertEqual(len(rulesv4), 2) self.assertEqual(len(rulesv6), 0) self.assertEqual(original_filter_count - len(fakefilter.filters), 1) self.assertEqual(original_filter_count - len(fakefilter.filters), 1) self.assertEqual(result, expected_result) self.assertEqual(result, ""tap"") self.assertEqual(disk.get_disk_size('/some/path'), 4592640) self.assertEqual(fp.read(), 'canary') self.assertEqual(fp.read(), 'hello') self.assertEqual(fp.read(), 'hello') self.assertEqual(mode & 0o277, 0) self.assertEqual(libvirt_utils.load_file(dst_path), 'hello') self.assertEqual(fp.read(), 'hello') self.assertEqual(self.executes, expected_commands) self.assertEqual(self.executes, expected_commands) self.assertEqual(self.executes, expected_commands) self.assertEqual(self.executes, expected_commands) self.assertEqual(out, 'baz') self.assertEqual(out, 'c') self.assertEqual(out, disk_info_text) self.assertEqual(out, disk_info_text) self.assertEqual(disk_info_text, out) self.assertEqual(powered_on, power_on) self.assertEqual( resize_instance, self.fake_disk_resize_called) self.assertEqual(powered_on, power_on) self.assertEqual(disk_inject_data.called, called) self.assertEqual(vol_usage, expected_usage) self.assertEqual(vol_usage, [])",349,352
openstack%2Fmurano~master~I3252a0e309f23fd053571158f5104cc5ef1a6f64,openstack/murano,master,I3252a0e309f23fd053571158f5104cc5ef1a6f64,Fix usage of oslo.utils.uuidutils,MERGED,2015-01-12 16:50:26.000000000,2015-01-13 15:56:27.000000000,2015-01-13 15:56:27.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-01-12 16:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/321e8dea55470fcd2ccdce95a322c5aef2e0c1e6', 'message': 'Fixes usage of oslo.utils.uuidutils\n\nChange-Id: I3252a0e309f23fd053571158f5104cc5ef1a6f64\nCloses-Bug: #1409792\n'}, {'number': 2, 'created': '2015-01-12 17:20:01.000000000', 'files': ['murano/tests/functional/api/base.py', 'murano/engine/system/net_explorer.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/1e78446c0238842b87d1c06a047934ad37fcb923', 'message': 'Fix usage of oslo.utils.uuidutils\n\nThis changeset also fixes issue with changed tempest API\n\nChange-Id: I3252a0e309f23fd053571158f5104cc5ef1a6f64\nCloses-Bug: #1409792\n'}]",0,146569,1e78446c0238842b87d1c06a047934ad37fcb923,23,7,2,7226,,,0,"Fix usage of oslo.utils.uuidutils

This changeset also fixes issue with changed tempest API

Change-Id: I3252a0e309f23fd053571158f5104cc5ef1a6f64
Closes-Bug: #1409792
",git fetch https://review.opendev.org/openstack/murano refs/changes/69/146569/2 && git format-patch -1 --stdout FETCH_HEAD,['murano/engine/system/net_explorer.py'],1,321e8dea55470fcd2ccdce95a322c5aef2e0c1e6,bug/1409792,from oslo.utils import uuidutils if uuidutils.is_uuid_like(external_network) \,import oslo.utils if oslo.utils.uuidutils.is_uuid_like(external_network) \,2,2
openstack%2Fnova~stable%2Fjuno~I161eccc4ea48a21a80d689f6a328ca95cace2e6e,openstack/nova,stable/juno,I161eccc4ea48a21a80d689f6a328ca95cace2e6e,Make ec2 auth support v4 signature format,MERGED,2015-01-12 18:53:41.000000000,2015-01-13 15:52:23.000000000,2015-01-13 10:14:01.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 4328}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-01-12 18:53:41.000000000', 'files': ['nova/api/ec2/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/56e3dd3331a6dbece1f12ce8a01edc9b2f6b5dde', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nConflicts:\n        nova/api/ec2/__init__.py\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n(cherry picked from commit f7b1af9e13df728d086047f6763bd98cb2cad1b2)\n'}]",0,146609,56e3dd3331a6dbece1f12ce8a01edc9b2f6b5dde,14,8,1,6873,,,0,"Make ec2 auth support v4 signature format

Extract the signature and access key via whatever method is needed
for the version of the request (e.g headers for v4), and add the
headers and hashed body, which is required for keystone to calculate
the correct v4 signature when validating the request.

Conflicts:
        nova/api/ec2/__init__.py

Change-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e
Closes-Bug: #1408987
(cherry picked from commit f7b1af9e13df728d086047f6763bd98cb2cad1b2)
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/146609/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/ec2/__init__.py'],1,56e3dd3331a6dbece1f12ce8a01edc9b2f6b5dde,bug/1408987-juno,"import hashlib def _get_signature(self, req): """"""Extract the signature from the request. This can be a get/post variable or for version 4 also in a header called 'Authorization'. - params['Signature'] == version 0,1,2,3 - params['X-Amz-Signature'] == version 4 - header 'Authorization' == version 4 """""" sig = req.params.get('Signature') or req.params.get('X-Amz-Signature') if sig is None and 'Authorization' in req.headers: auth_str = req.headers['Authorization'] sig = auth_str.partition(""Signature="")[2].split(',')[0] return sig def _get_access(self, req): """"""Extract the access key identifier. For version 0/1/2/3 this is passed as the AccessKeyId parameter, for version 4 it is either an X-Amz-Credential parameter or a Credential= field in the 'Authorization' header string. """""" access = req.params.get('AWSAccessKeyId') if access is None: cred_param = req.params.get('X-Amz-Credential') if cred_param: access = cred_param.split(""/"")[0] if access is None and 'Authorization' in req.headers: auth_str = req.headers['Authorization'] cred_str = auth_str.partition(""Credential="")[2].split(',')[0] access = cred_str.split(""/"")[0] return access signature = self._get_signature(req) access = self._get_access(req) auth_params.pop('Signature', None) body_hash = hashlib.sha256(req.body).hexdigest() 'headers': req.headers, 'body_hash': body_hash # Not all arguments are mandatory with v4 signatures, as some data is # passed in the header, not query arguments. required_args = ['Action', 'Version'] # If not present assume v4 version = req.params.get('SignatureVersion', 4) if non_arg in required_args: # Remove, but raise KeyError if omitted args.pop(non_arg) else: args.pop(non_arg, None)"," signature = req.params.get('Signature') access = req.params.get('AWSAccessKeyId') auth_params.pop('Signature') version = req.params['SignatureVersion'] # Remove, but raise KeyError if omitted args.pop(non_arg)",54,6
openstack%2Fkeystoneauth-saml2~master~Ifab1ec2eeb458dfd079e5ced05e6440b81889427,openstack/keystoneauth-saml2,master,Ifab1ec2eeb458dfd079e5ced05e6440b81889427,Fix pep8 issue,MERGED,2014-12-30 20:45:38.000000000,2015-01-13 15:44:56.000000000,2015-01-13 15:44:55.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 7191}, {'_account_id': 7244}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-12-30 20:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/61c6de8a26ef234e1ac24cffaf47e412b36d3754', 'message': 'Fix pep8 issue\n\nThe pep8 test was failing with\n\n ./keystoneclient_federation/__init__.py:20:1: W391 blank line at end of file\n\nChange-Id: Ifab1ec2eeb458dfd079e5ced05e6440b81889427\n'}, {'number': 2, 'created': '2014-12-30 20:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/60337c52b2eeb610f37af36d8ab4698a572119b2', 'message': 'Fix pep8 issue\n\nThe pep8 test was failing with\n\n ./keystoneclient_federation/__init__.py:19:50: W292 no newline at end of file\n\nChange-Id: Ifab1ec2eeb458dfd079e5ced05e6440b81889427\n'}, {'number': 3, 'created': '2015-01-07 20:08:30.000000000', 'files': ['keystoneclient_federation/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/47a86b72a75ebdb17e089f2c3eac5ab0d7edd9f7', 'message': 'Fix pep8 issue\n\nThe pep8 test was failing with\n\n ./keystoneclient_federation/__init__.py:19:50: W292 no newline at end of file\n\nCloses-Bug: #1408430\nChange-Id: Ifab1ec2eeb458dfd079e5ced05e6440b81889427\n'}]",0,144511,47a86b72a75ebdb17e089f2c3eac5ab0d7edd9f7,15,6,3,6486,,,0,"Fix pep8 issue

The pep8 test was failing with

 ./keystoneclient_federation/__init__.py:19:50: W292 no newline at end of file

Closes-Bug: #1408430
Change-Id: Ifab1ec2eeb458dfd079e5ced05e6440b81889427
",git fetch https://review.opendev.org/openstack/keystoneauth-saml2 refs/changes/11/144511/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient_federation/__init__.py'],1,61c6de8a26ef234e1ac24cffaf47e412b36d3754,bug/1408430, 'keystoneclient_federation').version_string() , 'keystoneclient_federation').version_string(),1,1
openstack%2Fdiskimage-builder~master~Iff7b9fc30d5a36231598a977a9edcd55229766c5,openstack/diskimage-builder,master,Iff7b9fc30d5a36231598a977a9edcd55229766c5,Allow default repo override in rhel-common,ABANDONED,2014-12-19 20:34:14.000000000,2015-01-13 15:44:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8532}, {'_account_id': 10459}, {'_account_id': 13953}]","[{'number': 1, 'created': '2014-12-19 20:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4fe50e556671ede7783b8a31ead6d943422c511d', 'message': 'Allow default repo override in rhel-common\n\nOn investigation, the rhel and rhel-common elements can successfully build on RHEL 6\nimages, but in order to do so, the default rhel-7-server repository must be removed\nfrom the codebase. In order to allow current low-configuration behavior but allow\nextension to other versions of RHEL, I\'ve placed the line:\nrepos=""repos""\nat each point at which $REG_REPOS is looped. In this way, the user still attaches to\nrhel-7-server with no configuration, but may attach to any set of repos (including\nsets that do not include rhel-7 repos.) This does constitute an interface change, as\nin order for the user to specify an additional repository but also install\nrhel-7-server, rhel-7-server must be explicitly listed; still, the extensibility\ngain is significant.\n\nChange-Id: Iff7b9fc30d5a36231598a977a9edcd55229766c5\nCloses-Bug: 1404364\n'}, {'number': 2, 'created': '2014-12-19 22:14:13.000000000', 'files': ['elements/rhel-common/README.md', 'elements/rhel-common/os-refresh-config/pre-configure.d/06-rhel-registration', 'elements/rhel-common/pre-install.d/00-rhel-registration'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/02adfb5dacb662a4eb91a23387a930b8b754d32a', 'message': ""Allow default repo override in rhel-common\n\nOn investigation, the rhel and rhel-common elements can successfully build on RHEL 6\nimages, but in order to do so, the default rhel-7-server repository must be removed\nfrom the codebase. In order to allow current low-configuration behavior but allow\nextension to other versions of RHEL, I've added the variable $REG_REPO_BASE, which\nif unset will use the current default values but otherwise will replace the default\nrepository.\n\nChange-Id: Iff7b9fc30d5a36231598a977a9edcd55229766c5\nCloses-Bug: 1404364\n""}]",2,143182,02adfb5dacb662a4eb91a23387a930b8b754d32a,19,5,2,13953,,,0,"Allow default repo override in rhel-common

On investigation, the rhel and rhel-common elements can successfully build on RHEL 6
images, but in order to do so, the default rhel-7-server repository must be removed
from the codebase. In order to allow current low-configuration behavior but allow
extension to other versions of RHEL, I've added the variable $REG_REPO_BASE, which
if unset will use the current default values but otherwise will replace the default
repository.

Change-Id: Iff7b9fc30d5a36231598a977a9edcd55229766c5
Closes-Bug: 1404364
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/82/143182/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rhel-common/os-refresh-config/pre-configure.d/06-rhel-registration', 'elements/rhel-common/pre-install.d/00-rhel-registration']",2,4fe50e556671ede7783b8a31ead6d943422c511d,bug/1404364," repos=""repos"" repos=""repos""",,4,0
openstack%2Ffuel-main~master~If20f75c2b9286111710e19a738e8ea5499de6bd8,openstack/fuel-main,master,If20f75c2b9286111710e19a738e8ea5499de6bd8,Removed netcheck.py file,MERGED,2014-10-17 14:06:22.000000000,2015-01-13 15:40:24.000000000,2015-01-13 15:40:23.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8789}, {'_account_id': 8882}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-17 14:06:22.000000000', 'files': ['netcheck.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f9f053e7c5a3daeb207f44db64542cffe81abadb', 'message': ""Removed netcheck.py file\n\nLooks like we don't need this file at all.\n\nChange-Id: If20f75c2b9286111710e19a738e8ea5499de6bd8\n""}]",0,129265,f9f053e7c5a3daeb207f44db64542cffe81abadb,11,7,1,3009,,,0,"Removed netcheck.py file

Looks like we don't need this file at all.

Change-Id: If20f75c2b9286111710e19a738e8ea5499de6bd8
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/65/129265/1 && git format-patch -1 --stdout FETCH_HEAD,['netcheck.py'],1,f9f053e7c5a3daeb207f44db64542cffe81abadb,,,"# Copyright 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. #!/usr/bin/env python import random import logging import itertools logging.basicConfig() logger = logging.getLogger() class Vertex(object): def __init__(self, node, interface): self.node = node self.interface = interface def __str__(self): return ""<Vtx: %s.%s>"" % (self.node, self.interface) def __repr__(self): return self.__str__() def __eq__(self, other): return self.node == other.node and self.interface == other.interface def __ne__(self, other): return self.node != other.node or self.interface != other.interface def __hash__(self): return hash(str(self)) class Arc(object): def __init__(self, vertex_a, vertex_b): self.arc = (vertex_a, vertex_b) def __str__(self): return ""<Arc: %s>"" % (self.arc,) def __repr__(self): return self.__str__() def __getitem__(self, i): return self.arc[i] def __eq__(self, other): l = map(lambda x, y: x == y, self.arc, other.arc) return bool(filter(lambda x: x, l)) def __ne__(self, other): l = map(lambda x, y: x != y, self.arc, other.arc) return bool(filter(lambda x: x, l)) def __hash__(self): return hash(str(self)) def invert(self): return Arc(self.arc[1], self.arc[0]) class NetChecker(object): def __init__(self, nodes, arcs): self.nodes = nodes self.arcs = arcs logger.debug(""Init: got %d nodes and %d arcs"", len(nodes), len(self.arcs)) @staticmethod def _invert_arc(arc): return arc[1], arc[0] @staticmethod def _create_arc(a_vertex, b_vertex): return a_vertex, b_vertex @staticmethod def _disassm_vertex(vertex): index = vertex.find('.') node = vertex[:index] interface = vertex[index + 1:] return node, interface @staticmethod def _assm_vertex(node, interface): return ""%s.%s"" % (str(node), str(interface)) def get_topos(self): """""" Main method to collect all possible altermatives of interconnection. """""" topos = [] vertices = set([i[0] for i in self.arcs]) logger.debug(""Get_choices: start with %d vertices"", len(vertices)) while vertices: logger.debug("""") vertex = vertices.pop() logger.debug(""Get_choices: entry vertex is %s"", vertex) good_topos, visited_vertices = self._calc_topo(vertex) logger.debug(""Get_choices: getted %d good_topos"", len(good_topos)) logger.debug(""Get_choices: getted %d visited_vertices: %s"", len(visited_vertices), visited_vertices) topos.extend(good_topos) vertices.difference_update(visited_vertices) logger.debug(""Get_choices: %d untracked vertices left: %s"", len(vertices), vertices) return self._uniq_topos(topos) def _calc_topo(self, start_vertex): topos = [] visited_vertices = set() def extend_arcs_to_check(arcs_to_check, arcs): for failed_v, ignored_v in arcs: existed_arcs = filter( lambda x: x[0] == failed_v, arcs_to_check) if existed_arcs: existed_arc = existed_arcs[0] existed_arc[1].append(ignored_v) else: arcs_to_check.append((failed_v, [ignored_v])) # arcs_to_check consists of arcs (x, y) where # x - failed vertex, # y - list of vertices which should be ignored. arcs_to_check = [(start_vertex, [])] for fv, ignored_vertices in arcs_to_check: found_vertices = [fv] failed_arcs = [] for vertex in found_vertices: neighbors = self._get_neighbors(vertex) logger.debug(""_calc_topo: for vtx %s a neigbors found: %s"", vertex, neighbors) new_vertices, absent_vertices = self._diff_lists( found_vertices, ignored_vertices, neighbors ) logger.debug(""_calc_topo: new vtx found: %s"", new_vertices) logger.debug(""_calc_topo: absent_vertices is %s"", absent_vertices) if absent_vertices: for v in absent_vertices: failed_arc = (v, vertex) if failed_arc not in failed_arcs: failed_arcs.append(failed_arc) found_vertices.extend(new_vertices) failed_vertices = [x[0] for x in failed_arcs] topo = self._validate_topo(found_vertices, failed_vertices) visited_vertices.update(found_vertices) visited_vertices.update(failed_vertices) if topo: topos.append(topo) extend_arcs_to_check(arcs_to_check, failed_arcs) return topos, visited_vertices def _get_neighbors(self, vertex): arcs = filter( lambda x: x[0] == vertex, self.arcs) return [x[1] for x in arcs] @staticmethod def _diff_lists(found_vertices, ignored_vertices, neighbours): new_vertices = [] absent_vertices = [] for n in found_vertices: if n in neighbours: neighbours.remove(n) else: absent_vertices.append(n) new_vertices = [n for n in neighbours if n not in ignored_vertices] return new_vertices, absent_vertices def _validate_topo(self, found_v, failed_v): logger.debug(""_validate_topo: found_vertices is: %s"", found_v) logger.debug(""_validate_topo: failed_vertices is: %s"", failed_v) topo = {} for v in found_v: if v in failed_v: continue node, interface = self._disassm_vertex(v) interfaces = topo.get(node) if interfaces: interfaces.append(interface) else: topo[node] = [interface] if set(self.nodes) != set(topo.keys()): return None for l in topo.values(): l.sort() return topo def _uniq_topos(self, topos): def isincluded(topo, topos): for at in topos: included = True for n in self.nodes: if not set(topo[n]).issubset(set(at[n])): included = False if included: return True return False copy = [] logger.debug(""_uniq_topos: topos is %s"" % topos) for t in topos: logger.debug(""_uniq_topos: now testing: %s"" % t) if not isincluded(t, [i for i in topos if id(i) != id(t)]): copy.append(t) return copy class ClassbasedNetChecker(NetChecker): @staticmethod def _invert_arc(arc): return arc.invert() @staticmethod def _create_arc(a_vertex, b_vertex): return Arc(a_vertex, b_vertex) @staticmethod def _disassm_vertex(vertex): return vertex.node, vertex.interface @staticmethod def _assm_vertex(node, interface): return Vertex(node, interface) def generateFullMesh(nodes, interfaces, Klass, stability=1.0): A = [] vertices = itertools.product(nodes, interfaces, nodes, interfaces) for n1, i1, n2, i2 in vertices: # Drop some arcs if stability < 1.0 if stability == 1.0 or random.random() < stability: a_vertex = Klass._assm_vertex(n1, i1) b_vertex = Klass._assm_vertex(n2, i2) arc = Klass._create_arc(a_vertex, b_vertex) A.append(arc) logger.debug(""generateArcs: %d arcs generated"", len(A)) return A def generateMesh(nodes1, ifaces1, nodes2, ifaces2, Klass, stability=1.0): A = [] vertices = itertools.product(nodes1, ifaces1, nodes2, ifaces2) for n1, i1, n2, i2 in vertices: # Drop some arcs if stability < 1.0 if stability == 1.0 or random.random() < stability: a_vertex = Klass._assm_vertex(n1, i1) b_vertex = Klass._assm_vertex(n2, i2) arc = Klass._create_arc(a_vertex, b_vertex) A.append(arc) logger.debug(""generateArcs: %d arcs generated"", len(A)) return A def printChoice(choice, step=4): def printlist(l, indent=0, step=2): print '%s[' % (' ' * indent) for i in l: if type(i) is dict: print '%s-' % (' ' * indent) printdict(i, indent + step, step) elif type(i) in (list, tuple): printlist(i, indent + step, step) else: print '%s- %s' % (' ' * indent, str(i)) print '%s]' % (' ' * indent) def printdict(d, indent=0, step=2): for k, v in d.iteritems(): if type(v) is dict: print '%s%s:' % (' ' * indent, str(k)) printdict(v, indent + step, step) elif type(v) in (list, tuple): print '%s%s:' % (' ' * indent, str(k)) printlist(v, indent + step, step) else: print '%s%s: %s' % (' ' * indent, str(k), str(v)) if type(choice) is dict: printdict(choice, step=step) elif type(choice) is list: printlist(choice, step=step) else: print choice print """" nodes = ['s1', 's2', 's3', 's4'] interfaces = ['i0', 'i1', 'i2', 'i3'] logger.setLevel(logging.DEBUG) Klass = ClassbasedNetChecker Klass = NetChecker arcs = [] # arcs.extend(generateFullMesh(nodes[:2], interfaces[:2], Klass, 0.9)) # #arcs.extend(generateFullMesh(nodes[:2], interfaces[2:], Klass)) # arcs.extend(generateMesh(nodes[2:3], interfaces[0:1], # nodes[:3], interfaces[0:2], Klass)) # arcs.extend(generateMesh(nodes[:2], interfaces[0:2], # nodes[2:3], interfaces[0:1], Klass)) # netcheck = Klass(nodes[:3], arcs) nodes = [str(i) for i in xrange(200)] interfaces = [str(i) for i in xrange(4)] arcs = generateFullMesh(nodes, interfaces, Klass) netcheck = Klass(nodes, arcs) logger.setLevel(logging.INFO) choices = netcheck.get_topos() #printChoice(arcs) # print """" # for i in xrange(len(choices)): # print ""\n---- Choice number %d: ----\n"" % (i + 1) # printChoice(choices[i]) if not choices: print ""No choices found"" else: print ""%d choices found"" % len(choices) print """" #import time #time.sleep(5) ",0,345
openstack%2Fnova~master~I70cdfa8a3133e98cf1ce928918bab010e5b18425,openstack/nova,master,I70cdfa8a3133e98cf1ce928918bab010e5b18425,Remove pylint special comments,ABANDONED,2014-12-16 12:25:01.000000000,2015-01-13 15:35:09.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-16 12:25:01.000000000', 'files': ['nova/servicegroup/drivers/db.py', 'nova/tests/unit/api/ec2/test_middleware.py', 'nova/api/openstack/compute/views/servers.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/scheduler/filters/trusted_filter.py', 'nova/servicegroup/drivers/mc.py', 'nova/db/sqlalchemy/api.py', 'nova/db/base.py', 'nova/tests/unit/fake_ldap.py', 'nova/tests/unit/test_objectstore.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/rbd_utils.py', 'nova/openstack/common/cliutils.py', 'nova/tests/unit/api/ec2/test_api.py', 'nova/compute/manager.py', 'nova/db/api.py', 'nova/compute/api.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/933297df0bdee59a9ceb528f0377304abf1b49da', 'message': ""Remove pylint special comments\n\nDue to that pylint job isn't work,\nthis special comments are no longer needed.\n\nChange-Id: I70cdfa8a3133e98cf1ce928918bab010e5b18425\n""}]",0,142088,933297df0bdee59a9ceb528f0377304abf1b49da,7,5,1,8412,,,0,"Remove pylint special comments

Due to that pylint job isn't work,
this special comments are no longer needed.

Change-Id: I70cdfa8a3133e98cf1ce928918bab010e5b18425
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/142088/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/servicegroup/drivers/db.py', 'nova/tests/unit/api/ec2/test_middleware.py', 'nova/api/openstack/compute/views/servers.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/scheduler/filters/trusted_filter.py', 'nova/servicegroup/drivers/mc.py', 'nova/db/sqlalchemy/api.py', 'nova/db/base.py', 'nova/tests/unit/fake_ldap.py', 'nova/tests/unit/test_objectstore.py', 'nova/virt/libvirt/driver.py', 'nova/virt/libvirt/rbd_utils.py', 'nova/openstack/common/cliutils.py', 'nova/tests/unit/api/ec2/test_api.py', 'nova/compute/manager.py', 'nova/db/api.py', 'nova/compute/api.py', 'nova/virt/block_device.py']",19,933297df0bdee59a9ceb528f0377304abf1b49da,remove_pylint_special_comments, except Exception:, except Exception: # pylint: disable=W0702,23,39
openstack%2Ffuel-main~master~I38580a02b6ce19b6b2ad14fa8a46e6dda1764b72,openstack/fuel-main,master,I38580a02b6ce19b6b2ad14fa8a46e6dda1764b72,Correcting pathes to tests for Sahara and Murano,MERGED,2015-01-13 13:31:29.000000000,2015-01-13 15:32:02.000000000,2015-01-13 15:31:55.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2015-01-13 13:31:29.000000000', 'files': ['fuelweb_test/tests/test_services.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2e66c11d8b9f8e89a74b426c27d1f18f4c80d59b', 'message': 'Correcting pathes to tests for Sahara and Murano\n\nAccording to patch https://review.openstack.org/#/c/146411\nwe have to change pathes to tests for Sahara and Murano to\navoid failures in system tests.\n\nChange-Id: I38580a02b6ce19b6b2ad14fa8a46e6dda1764b72\nRelated-Bug: #1409738\n'}]",0,146857,2e66c11d8b9f8e89a74b426c27d1f18f4c80d59b,10,5,1,7428,,,0,"Correcting pathes to tests for Sahara and Murano

According to patch https://review.openstack.org/#/c/146411
we have to change pathes to tests for Sahara and Murano to
avoid failures in system tests.

Change-Id: I38580a02b6ce19b6b2ad14fa8a46e6dda1764b72
Related-Bug: #1409738
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/57/146857/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_services.py'],1,2e66c11d8b9f8e89a74b426c27d1f18f4c80d59b,bug/1409738, 'test_sahara.PlatformSaharaTests.' 'test_sahara.PlatformSaharaTests.' '.test_murano_linux.MuranoDeployLinuxServicesTests') '.test_murano_linux.MuranoDeployLinuxServicesTests'), 'test_platform_sahara.PlatformSaharaTests.' 'test_platform_sahara.PlatformSaharaTests.' '.test_platform_murano_linux.' 'MuranoDeployLinuxServicesTests') '.test_platform_murano_linux.' 'MuranoDeployLinuxServicesTests'),4,6
openstack%2Ffuel-ostf~master~I367895b1d577f56842c288d94116c63bb3aba854,openstack/fuel-ostf,master,I367895b1d577f56842c288d94116c63bb3aba854,Renaming base test files for Sahara and Murano,MERGED,2015-01-12 10:28:25.000000000,2015-01-13 15:26:15.000000000,2015-01-13 15:26:15.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-01-12 10:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/6aca9f219468b2b257ba365598a774a70fa380fd', 'message': ""Renaming base test files for Sahara and Murano\n\nIn Fuel OSTF all base test files for components look\nlike <the name of a component>manager.py. Base test files for\nSahara and Murano have different names only. So let's rename them\nfor consistency.\n\nChange-Id: I367895b1d577f56842c288d94116c63bb3aba854\n""}, {'number': 2, 'created': '2015-01-12 12:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/8a006072e29dba6af273fdbcda49b9b402d76810', 'message': ""Renaming base test files for Sahara and Murano\n\nIn Fuel OSTF all base test files for components look\nlike <the name of a component>manager.py. Only base test files for\nSahara and Murano have different names. So let's rename them\nfor consistency. Test files for Sahara and Murano in platform \nfolder were renamed for consistency too.\n\nChange-Id: I367895b1d577f56842c288d94116c63bb3aba854\n""}, {'number': 3, 'created': '2015-01-12 12:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/284e828c93dfe594d6df636738e2b1e467ce588e', 'message': ""Renaming base test files for Sahara and Murano\n\nIn Fuel OSTF all base test files for components look\nlike <the name of a component>manager.py. Only base test files \nfor Sahara and Murano have different names. So let's rename them\nfor consistency. Test files for Sahara and Murano in platform section \nwere renamed for consistency too.\n\nChange-Id: I367895b1d577f56842c288d94116c63bb3aba854\n""}, {'number': 4, 'created': '2015-01-12 14:06:03.000000000', 'files': ['fuel_health/tests/sanity/test_sanity_sahara.py', 'fuel_health/saharamanager.py', 'fuel_health/tests/platform_tests/test_murano_linux.py', 'fuel_health/muranomanager.py', 'fuel_health/tests/platform_tests/test_sahara.py', 'fuel_health/tests/sanity/test_sanity_murano.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e84945b7e66379a21c88011f271fc6d4297c6d5a', 'message': ""Renaming base test files for Sahara and Murano\n\nIn Fuel OSTF all base test files for components look\nlike <the name of a component>manager.py. Only base test files \nfor Sahara and Murano have different names. So let's rename them\nfor consistency. Test files for Sahara and Murano in platform section \nwere renamed for consistency too.\n\nCloses-Bug: #1409738\n\nChange-Id: I367895b1d577f56842c288d94116c63bb3aba854\n""}]",0,146411,e84945b7e66379a21c88011f271fc6d4297c6d5a,30,9,4,7428,,,0,"Renaming base test files for Sahara and Murano

In Fuel OSTF all base test files for components look
like <the name of a component>manager.py. Only base test files 
for Sahara and Murano have different names. So let's rename them
for consistency. Test files for Sahara and Murano in platform section 
were renamed for consistency too.

Closes-Bug: #1409738

Change-Id: I367895b1d577f56842c288d94116c63bb3aba854
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/11/146411/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/sanity/test_sanity_sahara.py', 'fuel_health/saharamanager.py', 'fuel_health/tests/platform_tests/test_murano_linux.py', 'fuel_health/muranomanager.py', 'fuel_health/tests/platform_tests/test_sahara.py', 'fuel_health/tests/sanity/test_sanity_murano.py']",6,6aca9f219468b2b257ba365598a774a70fa380fd,,from fuel_health import muranomanager class MuranoSanityTests(muranomanager.MuranoTest):,from fuel_health import murano class MuranoSanityTests(murano.MuranoTest):,8,8
openstack%2Ffuel-ostf~master~I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f,openstack/fuel-ostf,master,I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f,Add test for get alarm and list resources,MERGED,2014-12-05 12:58:01.000000000,2015-01-13 15:26:09.000000000,2015-01-13 15:26:09.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-05 12:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/9b81c2be045719f391e10c14d63c4a2bf95bd676', 'message': 'Add test for get alarm and list resources\n\nAdded steps in ceilometer tests for get alarm and list resources\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f\n'}, {'number': 2, 'created': '2014-12-15 11:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/ccb2684cd5cdaff1aac058081bdcc923baf7bb66', 'message': 'Add test for get alarm and list resources\n\nAdded steps in ceilometer tests for get alarm and list resources\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f\n'}, {'number': 3, 'created': '2014-12-15 12:20:02.000000000', 'files': ['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/tests/platform_tests/test_ceilometer.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/d8d650ed761e15c990bf9277024b828c1ff69882', 'message': 'Add test for get alarm and list resources\n\nAdded steps in ceilometer tests for get alarm and list resources.\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f\n'}]",4,139614,d8d650ed761e15c990bf9277024b828c1ff69882,21,8,3,7126,,,0,"Add test for get alarm and list resources

Added steps in ceilometer tests for get alarm and list resources.

Partially implements: blueprint ceilometer-ostf-notification-tests

Change-Id: I41286c5b14e2aeb7a9f97eaea57fb704d8921c3f
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/14/139614/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_create_alarm.py', 'fuel_health/tests/platform_tests/test_ceilometer.py']",2,9b81c2be045719f391e10c14d63c4a2bf95bd676,bp/ceilometer-ostf-notification-tests," 5. Get resource of sample fail_msg = 'Getting resource of sample is failed.' msg = 'Getting resource of sample is successful.' self.verify(self.ceilometer_client.resources.get, 5, fail_msg, msg, sample.resource_id) ",,30,19
openstack%2Ffuel-ostf~master~I9175b6d0c090d4b664b2f59d03f94219e0fa111b,openstack/fuel-ostf,master,I9175b6d0c090d4b664b2f59d03f94219e0fa111b,Add ceilometer sahara notifications tests to ostf:,MERGED,2014-11-20 16:42:52.000000000,2015-01-13 15:25:49.000000000,2015-01-13 15:25:49.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8592}, {'_account_id': 8882}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-11-20 16:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/4f5ab6de77d15dbea3b00b3b567912a12450b5e6', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 2, 'created': '2014-11-21 13:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/c01c1ae571beeed48a64e69fc6caff3e53c4a0f3', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 3, 'created': '2014-11-26 09:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/6896b4c3c38ca3ae5d99633775ea7e4279f40715', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 4, 'created': '2014-11-26 09:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b253b27995f208483e931f745ff0df32a4bbfe3f', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 5, 'created': '2014-11-26 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/b41846b48da5fd5dffe0a094d02a82677bfb1db0', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 6, 'created': '2014-11-26 10:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/3feb099a4b3da9e5e40d75130716159698380385', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 7, 'created': '2014-12-01 18:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/194bb7d9510e4bed22fb229654ae093dca8d4dfc', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 8, 'created': '2014-12-05 10:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/0f96d04886efffe65206df09f38f39dd185bde7a', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.update, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}, {'number': 9, 'created': '2014-12-15 11:27:09.000000000', 'files': ['fuel_health/config.py', 'fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7fdd1585be715a20ebd37a301cce92013953cbdb', 'message': 'Add ceilometer sahara notifications tests to ostf:\n\nAdded ceilometer tests for sahara notifications:\ncluster.create, cluster.update, cluster.delete\n\nPartially implements: blueprint ceilometer-ostf-notification-tests\n\nChange-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b\n'}]",4,136048,7fdd1585be715a20ebd37a301cce92013953cbdb,49,9,9,7126,,,0,"Add ceilometer sahara notifications tests to ostf:

Added ceilometer tests for sahara notifications:
cluster.create, cluster.update, cluster.delete

Partially implements: blueprint ceilometer-ostf-notification-tests

Change-Id: I9175b6d0c090d4b664b2f59d03f94219e0fa111b
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/48/136048/9 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/config.py', 'fuel_health/nmanager.py', 'fuel_health/tests/platform_tests/test_ceilometer.py', 'fuel_health/ceilometermanager.py']",4,4f5ab6de77d15dbea3b00b3b567912a12450b5e6,bp/ceilometer-ostf-notification-tests,"class CeilometerBaseTest(fuel_health.nmanager.PlatformServicesBaseClass): cls.sahara_cluster_notifications = [ 'cluster.create', 'cluster.delete'] def sahara_helper(self): image_id = None for image in self.compute_client.images.list(): if ('_sahara_tag_vanilla' in image.metadata and '_sahara_tag_1.2.1' in image.metadata): image_id = image.id flavor_id = next( flavor.id for flavor in self.compute_client.flavors.list() if flavor.name == 'm1.small') node_group = {'name': 'allinone', 'flavor_id': flavor_id, 'node_processes': ['namenode', 'jobtracker', 'tasktracker', 'datanode'], 'count': 1} if self.neutron_external_network_id: node_group['floating_ip_pool'] = self.neutron_external_network_id if self.floating_ip_pool: node_group['floating_ip_pool'] = self.floating_ip_pool cluster_json = {'name': rand_name(""ceilo-cluster""), 'plugin_name': ""vanilla"", 'hadoop_version': ""1.2.1"", 'default_image_id': image_id, 'cluster_configs': {}, 'node_groups': [node_group]} if self.neutron_private_network_id: cluster_json['net_id'] = self.neutron_private_network_id cluster = self.sahara_client.clusters.create(cluster_json) self.objects_for_delete.append(self.sahara_client.clusters.delete, cluster.id) self.sahara_client.clusters.delete(cluster.id) return cluster ",class CeilometerBaseTest(fuel_health.nmanager.NovaNetworkScenarioTest):,76,1
openstack%2Fpuppet-designate~master~I1ac088edd9a471773d9936a18c625abb7e5cfe76,openstack/puppet-designate,master,I1ac088edd9a471773d9936a18c625abb7e5cfe76,example: Update shipped examples,MERGED,2014-11-02 17:05:42.000000000,2015-01-13 15:24:53.000000000,2015-01-13 15:24:53.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 8083}]","[{'number': 1, 'created': '2014-11-02 17:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/27ca3c2cdde7f164fd180b94cd8687ff9083d88c', 'message': 'example: Update shipped examples\n\nrename all.pp example to all-in-one-nouth.pp and introduce\nall-in-one-keystone example.\n\nChange-Id: I1ac088edd9a471773d9936a18c625abb7e5cfe76\n'}, {'number': 2, 'created': '2015-01-12 22:55:48.000000000', 'files': ['example/all.pp', 'example/all-in-one-noauth.pp', 'example/all-in-one-keystone.pp'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/adfa097586a9069512182d02b56a61742b28086e', 'message': 'example: Update shipped examples\n\nrename all.pp example to all-in-one-nouth.pp and introduce\nall-in-one-keystone example.\n\nChange-Id: I1ac088edd9a471773d9936a18c625abb7e5cfe76\n'}]",0,132482,adfa097586a9069512182d02b56a61742b28086e,12,4,2,7155,,,0,"example: Update shipped examples

rename all.pp example to all-in-one-nouth.pp and introduce
all-in-one-keystone example.

Change-Id: I1ac088edd9a471773d9936a18c625abb7e5cfe76
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/82/132482/2 && git format-patch -1 --stdout FETCH_HEAD,"['example/all.pp', 'example/all-in-one-noauth.pp', 'example/all-in-one-keystone.pp']",3,27ca3c2cdde7f164fd180b94cd8687ff9083d88c,metadata,"# designate server-create --name designate.example.net. # designate domain-create --name example.net. --email root@example.net # designate record-create <id> --type A --name www.example.net. --data 127.0.0.1 # designate record-list <id> # dig www.example.net @127.0.0.1 +short # node /designate/ { include 'apt' include 'rabbitmq' include 'mysql::server' # Keystone parameters $keystone_db_host = '127.0.0.1' $keystone_password = 'design1tepwd' $keystone_db_password = 'admin' $keystone_admin_token = '09ebe37c-60e6-11e4-9663-63d2e0838999' # This example would install designate api # designate central service and designate backend (bind) $rabbit_host = '127.0.0.1' $rabbit_userid = 'guest' $rabbit_password = 'guest' $auth_strategy = 'keystone' $backend_driver = 'bind9' $designate_db_password = 'admin' $db_host = '127.0.0.1' # == Keystone == # class { 'keystone::db::mysql': password => $keystone_db_password, allowed_hosts => '%', } class { 'keystone': verbose => true, validate_service => true, catalog_type => 'sql', enable_pki_setup => false, admin_token => $keystone_admin_token, token_provider => 'keystone.token.providers.uuid.Provider', token_driver => 'keystone.token.backends.sql.Token', database_connection => ""mysql://keystone:${keystone_db_password}@${keystone_db_host}/keystone"", } ## Adds the admin credential to keystone. class { 'keystone::roles::admin': email => 'admin@example.com', password => $keystone_password, admin_tenant => 'admin', } ## Installs the service user endpoint. class { 'keystone::endpoint': } # == Designate == # class {'designate::db::mysql': password => $designate_db_password, } class {'designate': rabbit_host => $rabbit_host, rabbit_userid => $rabbit_userid, rabbit_password => $rabbit_password, } class {'::designate::db': database_connection => ""mysql://designate:${designate_db_password}@${db_host}/designate"" } include 'designate::client' class {'designate::api': auth_strategy => $auth_strategy, keystone_password => $keystone_password, } class {'designate::central': backend_driver => $backend_driver, } include 'designate::dns' class {'designate::backend::bind9': rndc_config_file => '', rndc_key_file => '', } class {'designate::keystone::auth': password => $keystone_password, } } ",,133,26
openstack%2Fnova~master~I55d4b91861ffec285b6d64feb277e6e68669121c,openstack/nova,master,I55d4b91861ffec285b6d64feb277e6e68669121c,VMware: ensure that fake VM deletion returns a task,MERGED,2014-12-02 15:32:42.000000000,2015-01-13 15:24:20.000000000,2015-01-13 15:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-02 15:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc548ab654ece540883d64c8ff298410c7abe7e8', 'message': 'VMware: ensure that fake VM deletion returns a task\n\nThe VM deletion was not returning a task. This would result in\nan exception. The exception was swallowed by the fact that the\ndestroy method swallows all exceptions.\n\nTrivialFix\n\nChange-Id: I55d4b91861ffec285b6d64feb277e6e68669121c\n'}, {'number': 2, 'created': '2014-12-03 08:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73d13e494dff4b6743a340c4a092721c173e9a6b', 'message': 'VMware: ensure that fake VM deletion returns a task\n\nThe VM deletion was not returning a task. This would result in\nan exception. The exception was swallowed by the fact that the\ndestroy method swallows all exceptions.\n\nTrivialFix\n\nChange-Id: I55d4b91861ffec285b6d64feb277e6e68669121c\n'}, {'number': 3, 'created': '2014-12-04 05:39:00.000000000', 'files': ['nova/tests/unit/virt/vmwareapi/fake.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a94cac73f02e6362ed1c6bbe8e0c7e7038126a35', 'message': 'VMware: ensure that fake VM deletion returns a task\n\nThe VM deletion was not returning a task. This would result in\nan exception. The exception was swallowed by the fact that the\ndestroy method swallows all exceptions.\n\nTrivialFix\n\nChange-Id: I55d4b91861ffec285b6d64feb277e6e68669121c\n'}]",0,138401,a94cac73f02e6362ed1c6bbe8e0c7e7038126a35,41,10,3,1653,,,0,"VMware: ensure that fake VM deletion returns a task

The VM deletion was not returning a task. This would result in
an exception. The exception was swallowed by the fact that the
destroy method swallows all exceptions.

TrivialFix

Change-Id: I55d4b91861ffec285b6d64feb277e6e68669121c
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/138401/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/vmwareapi/fake.py'],1,cc548ab654ece540883d64c8ff298410c7abe7e8,fake-destroy," task_mdo = create_task(method, ""success"") return task_mdo.obj",,2,0
openstack%2Fnova~master~I34a37475f2b18607fc9453764e675113c4ab773b,openstack/nova,master,I34a37475f2b18607fc9453764e675113c4ab773b,Add vision of nova rest API policy improvement in devref,MERGED,2014-12-02 06:49:09.000000000,2015-01-13 15:23:46.000000000,2015-01-13 15:23:43.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-12-02 06:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b613b7ad873da9f65cb69a88067ac856d886afe0', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 2, 'created': '2014-12-02 14:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6281dcfe6b27263b84a2dbdcb53904e4039bcd0', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 3, 'created': '2014-12-03 06:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e085a1af290896771bf2008afd0bc8a94fa1d89', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 4, 'created': '2014-12-08 04:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f21e3a8e296e1a168a3e935367ad2124acff6aa7', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 5, 'created': '2014-12-09 06:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3a3ecdb05b4c663a4c111f5f3aeac83980d17f2', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 6, 'created': '2014-12-10 03:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8e26f62d9c1c68ff76f785e7e22e2b9cb3da2f4', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 7, 'created': '2014-12-10 05:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bd5cc899d5d312a054c8efe4b2011e285b1e06e', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 8, 'created': '2014-12-10 06:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fdf409ad0d5f50670e39398cacf0aa3323d2aa3c', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 9, 'created': '2014-12-12 16:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6797cd46a07c0a802e7c345e110139a7c8fd013', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 10, 'created': '2014-12-12 16:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8358af5e5ad46a5bdff8e7caee2b0dd5fd914642', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}, {'number': 11, 'created': '2014-12-12 17:09:11.000000000', 'files': ['doc/source/devref/index.rst', 'doc/source/devref/policy_enforcement.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d921673510abb4986225c2e493e5d41c8450f35', 'message': 'Add vision of nova rest API policy improvement in devref\n\nThere are several improvements for nova rest API policy. And we\nshould have a full view for them to make sure we are on the right way.\n\nThis docs aims to describe the improvement from blueprint v3-api-policy\nand separated-policy-rule-v3-api.\n\nChange-Id: I34a37475f2b18607fc9453764e675113c4ab773b\n'}]",64,138270,6d921673510abb4986225c2e493e5d41c8450f35,107,19,11,5754,,,0,"Add vision of nova rest API policy improvement in devref

There are several improvements for nova rest API policy. And we
should have a full view for them to make sure we are on the right way.

This docs aims to describe the improvement from blueprint v3-api-policy
and separated-policy-rule-v3-api.

Change-Id: I34a37475f2b18607fc9453764e675113c4ab773b
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/138270/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/vision_of_api_policy.rst'],1,b613b7ad873da9f65cb69a88067ac856d886afe0,bp/v3-api-policy,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= The Vision of Nova API Policy ============================= There are some of ideas and requirements from Icehouse summit to improve the current nova API policy. This doc aims to provide a full view for the improvement of nova API policy to ensure the final goal is on the right way. Problem description =================== There are several problems for current API policy. * The permission checking is spread through the various levels of the nova code, also have some hard-code permission checking that make some polcy rules didn't work. * API policy rules need better granularity. Some of extensions just use one rule for all the APIs. Deployer can't get better granularity control for the APIs. * More easy way to override default policy settings for deployer. And Currently all the API(EC2, V2, V2.1) rules mix in one policy.conf file. Use Cases --------- 1. Operator want to specified role can access service API, but it's hard-code as only admin can operator those API. 2. One policy rule for one API at REST API layer. Multiple rules in different layer really confuse the developer and deployer. 3. Deployer can specified separated rule for each API in one extension. 4. Deployer can override the default policy rule easily without mix his own config and default config in one policy.conf file. Proposed change =============== The generic rule for all the improvement is keep V2 API back-compatible. The improvement just for EC2 and V2.1 API. Because V2 API may be deprecated after V2.1 parity with V2. And reduce the risk of broken what we have for now. * Enforcement policy at REST API layer and remove hard-code permission checks. Remove the permission checking from low layers of nova. This make better usability for API policy. * Use different prefix in policy rule name for EC2/V2/V2.1 API. After move all the policy into REST API layer, then all the API won't share some policy enforcement in the compute API layer. So it's time group them. We can provide different prefix in rule name for each API. * EC2 API: We name the policy rule as ""ec2_api:[action]"" * Nova V2 API: After we move to V2.1, we needn't spend time to change V2 api rule, and needn't to bother deployer upgrade their policy config. So just keep V2 API poicy rule named as before. * Nova V2.1 API: We name the policy rule as ""os_compute_api:[extension]:[action]"". The core API may be changed in the future, so we needn't name them as ""compute"" or ""compute_extension"" to distinguish the core or extension API. * Port policy.d from oslo-incubator into nova. This feature make deployer can override default policy rule easily. And When nova default policy config changed, deployer only need replace default policy config files with new one. It won't affect his own policy config in other files. * Group the policy rules into different policy files. After support policy.d we can separated the policy rules as separated files, then deployer will more clear for which rule he can set for specified API. The rules can be grouped as below: * policy.conf: It only contains the generic rule, like: :: ""context_is_admin"": ""role:admin"", ""admin_or_owner"": ""is_admin:True or project_id:%(project_id)s"", ""default"": ""rule:admin_or_owner"", * policy.d/00-ec2-api.conf: It contains all the policy rules for EC2 API. * policy.d/00-v2-api.conf: It contains all the policy rules for nova V2 API. * policy.d/00-v2.1-api.conf: It contains all the policy rules for nova v2.1 API. * Add separated rule for each API in extension. This is for provider better granularity for policy rules. Security impact --------------- All of those improvement aims to provide more clear and easier way to config API policy, that reduce the mistake happened when change policy config. Performance Impact ------------------ This will improve the error handling performance. Because the permission checking occurs at the API level rather than at a lower level in Nova less processing will occur before a request is rejected. Also potentially for newer versions of the API redundant policy checks are removed which will also improve performance. Other deployer impact --------------------- * Enforcement policy at REST API layer and remove hard-code permission checks. There is affect after remove hard-code permission checks. The deployer need update their policy config file, to add permission checks for API that db layer hard-code was removed. * Use different prefix in policy rule name for EC2/V2/V2.1 API. There isn't any affect for V2 API. For EC2 API, it need deployer update their policy config. For V2.1 API, there isn't any user yet, so there won't any effect. * Port policy.d from oslo-incubator into nova. There isn't any affect for this. * Group the policy rules into different policy files. Deployer can put his old policy config file into policy directory also. Then their old config can override the default config. * Add separated rule for each API in extension. This need user to move the policy rule into separated rule for each API. Developer impact ---------------- After those improvement, nova will have more clear way to add permission checks. ",,156,0
openstack%2Fnova~master~I92d039731f17b731d302c35fb619300078b8a638,openstack/nova,master,I92d039731f17b731d302c35fb619300078b8a638,Added hacking rule for assertTrue/False(A in B),MERGED,2014-11-26 08:01:29.000000000,2015-01-13 15:23:15.000000000,2015-01-13 15:23:11.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 24}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7604}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9550}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-26 08:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ac7586270a52a3ecb27e2d71c356342a327c084', 'message': 'Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nAdded hacking rule for these cases.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n'}, {'number': 2, 'created': '2014-12-05 09:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d93bfa37d5a95909202de136c8827194720a69d', 'message': ""Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nThe error message would now be like:\n\n   'abc' not in ['a', 'b', 'c']\n\nrather than:\n\n    'False is not True'.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n""}, {'number': 3, 'created': '2014-12-08 11:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8832a416a643839ea2c4669f634277d00b21bc81', 'message': ""Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nThe error message would now be like:\n   'abc' not in ['a', 'b', 'c']\nrather than:\n   'False is not True'.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n""}, {'number': 4, 'created': '2014-12-09 10:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a45fb509a04d8e76e38511974ea7653cffa9d694', 'message': ""Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nThe error message would now be like:\n   'abc' not in ['a', 'b', 'c']\nrather than:\n   'False is not True'.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n""}, {'number': 5, 'created': '2014-12-10 15:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/662be281c545175eae9e775d4f2dd95d63a9a615', 'message': ""Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nThe error message would now be like:\n   'abc' not in ['a', 'b', 'c']\nrather than:\n   'False is not True'.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n""}, {'number': 6, 'created': '2015-01-07 09:29:36.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_firewall.py', 'nova/tests/unit/test_iptables_network.py', 'nova/hacking/checks.py', 'nova/tests/unit/virt/libvirt/test_imagecache.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/api/ec2/test_api.py', 'nova/tests/unit/test_hacking.py', 'nova/tests/unit/cmd/test_idmapshift.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6d30549c67e113a72302164af71966a9ebace22', 'message': ""Added hacking rule for assertTrue/False(A in B)\n\nThe following replacements were done in tests to have\nclearer messages in case of failure:\n- assertTrue(a in b) with assertIn(a, b)\n- assertTrue(a not in b) with assertNotIn(a, b)\n- assertFalse(a in b) with assertNotIn(a, b)\n\nThe error message would now be like:\n   'abc' not in ['a', 'b', 'c']\nrather than:\n   'False is not True'.\n\nChange-Id: I92d039731f17b731d302c35fb619300078b8a638\n""}]",6,137297,b6d30549c67e113a72302164af71966a9ebace22,61,15,6,9569,,,0,"Added hacking rule for assertTrue/False(A in B)

The following replacements were done in tests to have
clearer messages in case of failure:
- assertTrue(a in b) with assertIn(a, b)
- assertTrue(a not in b) with assertNotIn(a, b)
- assertFalse(a in b) with assertNotIn(a, b)

The error message would now be like:
   'abc' not in ['a', 'b', 'c']
rather than:
   'False is not True'.

Change-Id: I92d039731f17b731d302c35fb619300078b8a638
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/137297/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_firewall.py', 'nova/tests/unit/test_iptables_network.py', 'nova/hacking/checks.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/tests/unit/api/ec2/test_api.py', 'nova/tests/unit/test_hacking.py', 'nova/tests/unit/cmd/test_idmapshift.py', 'nova/tests/unit/compute/test_compute_utils.py', 'HACKING.rst', 'nova/tests/unit/virt/libvirt/test_driver.py']",10,4ac7586270a52a3ecb27e2d71c356342a327c084,asserTrue," self.assertIn('fake', self.resultXML)", self.assertTrue('fake' in self.resultXML),117,40
openstack%2Fnova~master~I24c1222a3b1ac809353724500117e58d50615ac8,openstack/nova,master,I24c1222a3b1ac809353724500117e58d50615ac8,XenAPI: Check image status before uploading data,MERGED,2014-11-22 01:07:13.000000000,2015-01-13 15:22:40.000000000,2015-01-13 15:22:37.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2537}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11642}, {'_account_id': 14486}]","[{'number': 1, 'created': '2014-11-22 01:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e1a0e2de732aafddf50d0c059d2bacfeb541dbb', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends a the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nHowever, the buffering of the data still happens on the Glance server\nand the operation does not fail until after a large chunk has been\nuploaded. This may result into wastage of bandwidth and wait time on\nthe client side.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid state for data transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 2, 'created': '2014-11-22 01:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edd09b0d703708ac33c57b20a4cf3fb9778c74f5', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends a the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nHowever, the buffering of the data still happens on the Glance server\nand the operation does not fail until after a large chunk has been\nuploaded. This may result into wastage of bandwidth and wait time on\nthe client side.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid state for data transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 3, 'created': '2014-11-22 22:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70038876dbf6a7bfd036239a47bc5d9da19fd065', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 4, 'created': '2014-12-05 19:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93a321e21444226b1b72a8884750733c7c515b3b', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 5, 'created': '2014-12-15 17:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1f986507b85873becace4e61d7ab79384fff7b7', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 6, 'created': '2014-12-30 16:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f510d56d90600432aec8ed70f4d3d4252437ea77', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 7, 'created': '2014-12-30 16:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d47437f89e3c23aa08f1d135192dcd08fbf9ca59', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 8, 'created': '2014-12-30 16:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b9ff52c81a3e808c2a08173fae9ea0c6976edae', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 9, 'created': '2014-12-30 18:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b76ab24630ad5b7eda3212aecd89ad2885006ae9', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 10, 'created': '2014-12-30 18:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f38c098219abeeafd98776f93df68f00a7c5566', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 11, 'created': '2014-12-31 15:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4782cc1e7db0dbc2aeab4cde3f9fa620ba00da37', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 12, 'created': '2015-01-02 17:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5d4d029c7aa9caa7f8651067d5db4b466862a2f', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 13, 'created': '2015-01-05 21:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4cc6abe05e312397a46826be0ab3607d20410d0', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}, {'number': 14, 'created': '2015-01-05 21:23:55.000000000', 'files': ['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'], 'web_link': 'https://opendev.org/openstack/nova/commit/92118229232fd77913d272323a869f39e9a9903d', 'message': 'XenAPI: Check image status before uploading data\n\nCurrently, the Xen API plugin sends the data payload to Glance\nwithout checking the image status. In consequence, if the image is\nnot in queued status Glance will not let the image upload succeed.\nThis is by design, please refer [0].\n\nThe issue here being; buffering of the data will happen on the Glance\nserver. Consequently, the bound to be failed upload operation will not\nget a 409 until after a large chunk of data has already been streamed\nto the Glance server. This may result into client side wastage of\nbandwidth and wait time.\n\nThis patch proposes a HEAD call be made from the glance plugin to\nGlance API; thus in turn checking the valid image state for the\ndata transfer.\n\n[0] http://docs.openstack.org/developer/glance/statuses.html\n\nChange-Id: I24c1222a3b1ac809353724500117e58d50615ac8\n'}]",31,136542,92118229232fd77913d272323a869f39e9a9903d,89,12,14,2537,,,0,"XenAPI: Check image status before uploading data

Currently, the Xen API plugin sends the data payload to Glance
without checking the image status. In consequence, if the image is
not in queued status Glance will not let the image upload succeed.
This is by design, please refer [0].

The issue here being; buffering of the data will happen on the Glance
server. Consequently, the bound to be failed upload operation will not
get a 409 until after a large chunk of data has already been streamed
to the Glance server. This may result into client side wastage of
bandwidth and wait time.

This patch proposes a HEAD call be made from the glance plugin to
Glance API; thus in turn checking the valid image state for the
data transfer.

[0] http://docs.openstack.org/developer/glance/statuses.html

Change-Id: I24c1222a3b1ac809353724500117e58d50615ac8
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/136542/5 && git format-patch -1 --stdout FETCH_HEAD,['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'],1,3e1a0e2de732aafddf50d0c059d2bacfeb541dbb,xen-api," # NOTE(nikhil): Attempt to determine if the Image is in 'queued' # status. This is necessary as the process of uploading data # can result into Glance API buffering the data until # a large amount of the same has been uploaded. The server finally # checks for Image state to not be active and gives back 409 # resulting into client side bandwight usage. LP bug #1202785. conn.request('HEAD', '/v1/images/%s' % image_id) resp = conn.getresponse() except Exception, error: logging.exception('Failed to HEAD the image %(image_id)s while ' 'checking image status before attempting to ' 'upload %(url)s' % locals()) raise RetryableError(error) if resp.status != httplib.OK: logging.error(""Unexpected response while doing a HEAD call "" ""to image %s , url = %s , Response Status: "" ""%i"" % (image_id, url, resp.status)) check_resp_status_and_retry(resp, image_id, glance_host, glance_port) else: image_status = resp.getheader('x-image-meta-status') if image_status not in ['queued', ]: err_msg = ('Cannot upload data for image %(image_id)s as the ' 'image status is %(image_status)s' % locals()) logging.exception(err_msg) raise PluginError(""Got Permanent Error while uploading image "" ""[%s] to glance host [%s:%s]. "" ""Message: %s"" % (image_id, glance_host, glance_port, err_msg)) else: logging.info('Found image %(image_id)s in status ' '%(image_status)s. Attempting to ' 'upload.' % locals()) try: check_resp_status_and_retry(resp, image_id, glance_host, glance_port) def check_resp_status_and_retry(resp, image_id, glance_host, glance_port): # Note(Jesse): This branch sorts errors into those that are permanent, # those that are ephemeral, and those that are unexpected. if resp.status in (httplib.BAD_REQUEST, # 400 httplib.UNAUTHORIZED, # 401 httplib.PAYMENT_REQUIRED, # 402 httplib.FORBIDDEN, # 403 httplib.NOT_FOUND, # 404 httplib.METHOD_NOT_ALLOWED, # 405 httplib.NOT_ACCEPTABLE, # 406 httplib.PROXY_AUTHENTICATION_REQUIRED, # 407 httplib.CONFLICT, # 409 httplib.GONE, # 410 httplib.LENGTH_REQUIRED, # 411 httplib.PRECONDITION_FAILED, # 412 httplib.REQUEST_ENTITY_TOO_LARGE, # 413 httplib.REQUEST_URI_TOO_LONG, # 414 httplib.UNSUPPORTED_MEDIA_TYPE, # 415 httplib.REQUESTED_RANGE_NOT_SATISFIABLE, # 416 httplib.EXPECTATION_FAILED, # 417 httplib.UNPROCESSABLE_ENTITY, # 422 httplib.LOCKED, # 423 httplib.FAILED_DEPENDENCY, # 424 httplib.UPGRADE_REQUIRED, # 426 httplib.NOT_IMPLEMENTED, # 501 httplib.HTTP_VERSION_NOT_SUPPORTED, # 505 httplib.NOT_EXTENDED, # 510 ): raise PluginError(""Got Permanent Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) elif resp.status in (httplib.REQUEST_TIMEOUT, # 408 httplib.INTERNAL_SERVER_ERROR, # 500 httplib.BAD_GATEWAY, # 502 httplib.SERVICE_UNAVAILABLE, # 503 httplib.GATEWAY_TIMEOUT, # 504 httplib.INSUFFICIENT_STORAGE, # 507 ): raise RetryableError(""Got Ephemeral Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) else: # Note(Jesse): Assume unexpected errors are retryable. If you are # seeing this error message, the error should probably be added # to either the ephemeral or permanent error list. raise RetryableError(""Got Unexpected Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) "," # Note(Jesse): This branch sorts errors into those that are permanent, # those that are ephemeral, and those that are unexpected. if resp.status in (httplib.BAD_REQUEST, # 400 httplib.UNAUTHORIZED, # 401 httplib.PAYMENT_REQUIRED, # 402 httplib.FORBIDDEN, # 403 httplib.NOT_FOUND, # 404 httplib.METHOD_NOT_ALLOWED, # 405 httplib.NOT_ACCEPTABLE, # 406 httplib.PROXY_AUTHENTICATION_REQUIRED, # 407 httplib.CONFLICT, # 409 httplib.GONE, # 410 httplib.LENGTH_REQUIRED, # 411 httplib.PRECONDITION_FAILED, # 412 httplib.REQUEST_ENTITY_TOO_LARGE, # 413 httplib.REQUEST_URI_TOO_LONG, # 414 httplib.UNSUPPORTED_MEDIA_TYPE, # 415 httplib.REQUESTED_RANGE_NOT_SATISFIABLE, # 416 httplib.EXPECTATION_FAILED, # 417 httplib.UNPROCESSABLE_ENTITY, # 422 httplib.LOCKED, # 423 httplib.FAILED_DEPENDENCY, # 424 httplib.UPGRADE_REQUIRED, # 426 httplib.NOT_IMPLEMENTED, # 501 httplib.HTTP_VERSION_NOT_SUPPORTED, # 505 httplib.NOT_EXTENDED, # 510 ): raise PluginError(""Got Permanent Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) elif resp.status in (httplib.REQUEST_TIMEOUT, # 408 httplib.INTERNAL_SERVER_ERROR, # 500 httplib.BAD_GATEWAY, # 502 httplib.SERVICE_UNAVAILABLE, # 503 httplib.GATEWAY_TIMEOUT, # 504 httplib.INSUFFICIENT_STORAGE, # 507 ): raise RetryableError(""Got Ephemeral Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) else: # Note(Jesse): Assume unexpected errors are retryable. If you are # seeing this error message, the error should probably be added # to either the ephemeral or permanent error list. raise RetryableError(""Got Unexpected Error response [%i] while "" ""uploading image [%s] to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port))",94,50
openstack%2Fanchor~master~I575cea945aff513428f9143117055ed45296ab22,openstack/anchor,master,I575cea945aff513428f9143117055ed45296ab22,Fixing issued certificate version.,MERGED,2015-01-05 12:08:39.000000000,2015-01-13 15:17:47.000000000,2015-01-13 15:17:47.000000000,"[{'_account_id': 3}, {'_account_id': 7063}]","[{'number': 1, 'created': '2015-01-05 12:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/0e2361fe73451cb1a59d35fa4a925ca8f3e8f750', 'message': 'Fixing issued certificate version.\n\nThe issued certificate was advertised as V1 but uses V3 extensions.\nThis fixes the problem, the issued certificate now declares itself to\nbe V3.\n\nChange-Id: I575cea945aff513428f9143117055ed45296ab22\n'}, {'number': 2, 'created': '2015-01-07 14:04:18.000000000', 'files': ['anchor/certificate_ops.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/7983e8377a9c499b71c88c4dc65885b454986722', 'message': 'Fixing issued certificate version.\n\nThe issued certificate was advertised as V1 but uses V3 extensions.\nThis fixes the problem, the issued certificate now declares itself to\nbe V3.\n\nChange-Id: I575cea945aff513428f9143117055ed45296ab22\n'}]",0,144970,7983e8377a9c499b71c88c4dc65885b454986722,11,2,2,11716,,,0,"Fixing issued certificate version.

The issued certificate was advertised as V1 but uses V3 extensions.
This fixes the problem, the issued certificate now declares itself to
be V3.

Change-Id: I575cea945aff513428f9143117055ed45296ab22
",git fetch https://review.opendev.org/openstack/anchor refs/changes/70/144970/2 && git format-patch -1 --stdout FETCH_HEAD,['anchor/certificate_ops.py'],1,0e2361fe73451cb1a59d35fa4a925ca8f3e8f750,bump-cert-version, new_cert.set_version(2), new_cert.set_version(0),1,1
openstack%2Fpuppet-keystone~master~I33ea824a47ca5834b3f97aa9a714ec385984f00f,openstack/puppet-keystone,master,I33ea824a47ca5834b3f97aa9a714ec385984f00f,Add timeout to API requests,MERGED,2015-01-09 00:52:33.000000000,2015-01-13 15:17:03.000000000,2015-01-12 15:18:14.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 9500}, {'_account_id': 9983}]","[{'number': 1, 'created': '2015-01-09 00:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/aab8c4d77af2907e14ba197e3df4420e41f9b192', 'message': 'Add timeout to API requests\n\nSometimes a service is temporarily unavailable, for instance\nimmediately after puppet refreshes it. This causes the providers to\nfail when it would be optimal to wait briefly for the service to\nreturn. This patch adds a timeout loop in the style of [1] so that the\nkeystone providers can continue to attempt requests if the service was\nunavailable during their first attempt.\n\n[1] https://review.openstack.org/#/c/130155\n\nChange-Id: I33ea824a47ca5834b3f97aa9a714ec385984f00f\n'}, {'number': 2, 'created': '2015-01-09 04:36:08.000000000', 'files': ['lib/puppet/provider/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c6f70aeab01651e2b821acb75c5b4c253df3bf6a', 'message': 'Add timeout to API requests\n\nSometimes a service is temporarily unavailable, for instance\nimmediately after puppet refreshes it. This causes the providers to\nfail when it would be optimal to wait briefly for the service to\nreturn. This patch adds a timeout loop in the style of [1] so that the\nkeystone providers can continue to attempt requests if the service was\nunavailable during their first attempt.\n\n[1] https://review.openstack.org/#/c/130155\n\nChange-Id: I33ea824a47ca5834b3f97aa9a714ec385984f00f\n'}]",3,145987,c6f70aeab01651e2b821acb75c5b4c253df3bf6a,16,7,2,8482,,,0,"Add timeout to API requests

Sometimes a service is temporarily unavailable, for instance
immediately after puppet refreshes it. This causes the providers to
fail when it would be optimal to wait briefly for the service to
return. This patch adds a timeout loop in the style of [1] so that the
keystone providers can continue to attempt requests if the service was
unavailable during their first attempt.

[1] https://review.openstack.org/#/c/130155

Change-Id: I33ea824a47ca5834b3f97aa9a714ec385984f00f
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/87/145987/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/openstack.rb'],1,aab8c4d77af2907e14ba197e3df4420e41f9b192,timeout," rv = nil timeout = 120 end_time = Time.now.to_i + timeout loop do begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled rv = response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] end hash else rv = openstack(service, action, args) break rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') elsif e.message =~ /Unable to establish connection/ current_time = Time.now.to_i if current_time > end_time break else wait = end_time - current_time Puppet::debug(""Non-fatal error: \""#{e.message}\"""") notice(""#{service} service is unavailable. Retrying in #{wait} seconds."") end sleep(2) else raise e end return rv"," begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] hash else openstack(service, action, args) end rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') else raise e",36,19
openstack%2Foslo.db~master~I455e957b043318a8500909c66cadde53228b52d6,openstack/oslo.db,master,I455e957b043318a8500909c66cadde53228b52d6,Ensure DBConnectionError is raised on failed revalidate,MERGED,2014-12-05 21:44:35.000000000,2015-01-13 15:13:05.000000000,2015-01-13 15:13:04.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 11816}]","[{'number': 1, 'created': '2014-12-05 21:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/b558767f39d9e355d4c8e6789fa001fa5d38044e', 'message': ""Ensure DBConnectionError is raised when on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revaldiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  However, for\n0.9 and earlier, we need to further adjust so that we apply handle_error()\nat this point, which is achieved using updated versions of the\nexc_filters.handle_connect_error() routines.  These routines\nreach into sqlalchemy/compat where the wrapping behavior is conditional\nbased on whether or not SQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 2, 'created': '2014-12-05 21:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/29aba27a1a7bb8f07ee63b47ddba9160789e0d00', 'message': ""Ensure DBConnectionError is raised when on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revaldiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  However, for\n0.9 and earlier, we need to further adjust so that we apply handle_error()\nat this point, which is achieved using updated versions of the\nexc_filters.handle_connect_error() routines.  These routines\nreach into sqlalchemy/compat where the wrapping behavior is conditional\nbased on whether or not SQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 3, 'created': '2014-12-06 20:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d56ed7ba592e4d1e48e7d0b4d2d6d0a8e9b81eba', 'message': ""Ensure DBConnectionError is raised when on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revaldiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  However, for\n0.9 and earlier, we need to further adjust so that we apply handle_error()\nat this point, which is achieved using updated versions of the\nexc_filters.handle_connect_error() routines.  These routines\nreach into sqlalchemy/compat where the wrapping behavior is conditional\nbased on whether or not SQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 4, 'created': '2014-12-08 22:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9f75729f4641af088acd7bd60b5b59ab4fb952cf', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 5, 'created': '2014-12-09 04:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0ca8bf035ed5620ce857aed2f04182aa684535d5', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 6, 'created': '2014-12-10 17:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/bb778a7b674db5abde05b789376f0d063befcfea', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 7, 'created': '2014-12-11 14:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/49d90cb1a7d11581fa591671e5f565c6db83dbac', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 8, 'created': '2014-12-12 10:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0e5c04cf7540cc77453a2a299a9552e2c6696407', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 9, 'created': '2014-12-14 18:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/50fd233654ffa283c2fe451e74ba26fc58b76e14', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 10, 'created': '2014-12-30 20:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/021b63b6e1ce7986c3bd78b63e260855a53caadc', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 11, 'created': '2015-01-07 23:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/64595e21b0997fd866b10f0a7fe3a60345c9fac7', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 12, 'created': '2015-01-08 20:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/65b53483d580bd53a90f2e8f7b4c7588da53833f', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}, {'number': 13, 'created': '2015-01-12 21:02:09.000000000', 'files': ['oslo_db/sqlalchemy/exc_filters.py', 'oslo_db/sqlalchemy/compat/handle_error.py', 'oslo_db/sqlalchemy/session.py', 'oslo_db/tests/sqlalchemy/test_exc_filters.py', 'oslo_db/sqlalchemy/compat/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/046e576467fdf8eb03fa0dae946bf4c1897e3896', 'message': ""Ensure DBConnectionError is raised on failed revalidate\n\nThe second call to connection.scalar() inside of _connect_ping_listener()\nis not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,\nin the case that the attempt to revalidate within fails.  This causes\nthe exception to be propagated outwards as the original\nOperationalError (assuming that's what the DBAPI raised, as is typical),\nrather than it being wrapped again in DBConnectionError.\n\nSQLAlchemy 1.0 has altered this behavior such that the handle_error()\nlistener is invoked correctly for revalidiation attempts (it was being\ninvoked before, but without the correct state), as well as\nfor initial connect attempts, as part of\nhttps://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,\nwe here backport this system into oslo/db/sqlalchemy/compat.py,\nincluding that we redefine the connection pool's handler to re-throw\nthe original dbapi.Error instance directly, then move the handling\nof this error in terms of SQLAlchemy wrapping and events into\nthe Engine and Connection.   The approach here works back to\nSQLAlchemy 0.8, and is conditional based on whether or not\nSQLAlchemy 1.0 is detected.\n\nChange-Id: I455e957b043318a8500909c66cadde53228b52d6\n""}]",0,139738,046e576467fdf8eb03fa0dae946bf4c1897e3896,49,5,13,11816,,,0,"Ensure DBConnectionError is raised on failed revalidate

The second call to connection.scalar() inside of _connect_ping_listener()
is not subject to the exc_filters system under SQLAlchemy 0.9 and earlier,
in the case that the attempt to revalidate within fails.  This causes
the exception to be propagated outwards as the original
OperationalError (assuming that's what the DBAPI raised, as is typical),
rather than it being wrapped again in DBConnectionError.

SQLAlchemy 1.0 has altered this behavior such that the handle_error()
listener is invoked correctly for revalidiation attempts (it was being
invoked before, but without the correct state), as well as
for initial connect attempts, as part of
https://bitbucket.org/zzzeek/sqlalchemy/issue/3266/.  For 0.9 and earlier,
we here backport this system into oslo/db/sqlalchemy/compat.py,
including that we redefine the connection pool's handler to re-throw
the original dbapi.Error instance directly, then move the handling
of this error in terms of SQLAlchemy wrapping and events into
the Engine and Connection.   The approach here works back to
SQLAlchemy 0.8, and is conditional based on whether or not
SQLAlchemy 1.0 is detected.

Change-Id: I455e957b043318a8500909c66cadde53228b52d6
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/38/139738/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/db/sqlalchemy/exc_filters.py', 'oslo/db/sqlalchemy/compat/handle_error.py', 'oslo/db/sqlalchemy/session.py', 'tests/sqlalchemy/test_exc_filters.py']",4,b558767f39d9e355d4c8e6789fa001fa5d38044e,fix_connect_filters_for_sqla_10," def _dbapi_fixture(self, dialect_name, is_disconnect=False): mock.patch.object(engine.dialect, ""is_disconnect"", lambda *args: is_disconnect) class TestDBConnectPingWrapping(TestsExceptionFilter): @contextlib.contextmanager def _fixture( self, dialect_name, exception, good_conn_count, is_disconnect=True): engine = self.engine compat.engine_connect(engine, session._connect_ping_listener) engine = self.engine # empty out the connection pool engine.dispose() connect_fn = engine.dialect.connect real_do_execute = engine.dialect.do_execute counter = itertools.count(1) def cant_execute(*arg, **kw): value = next(counter) if value > good_conn_count: raise exception else: return real_do_execute(*arg, **kw) def cant_connect(*arg, **kw): value = next(counter) if value > good_conn_count: raise exception else: return connect_fn(*arg, **kw) with self._dbapi_fixture(dialect_name, is_disconnect=is_disconnect): with mock.patch.object(engine.dialect, ""connect"", cant_connect): with mock.patch.object( engine.dialect, ""do_execute"", cant_execute): yield def _test_ping_listener_disconnected( self, dialect_name, exc_obj, is_disconnect=True): with self._fixture(dialect_name, exc_obj, 3, is_disconnect): conn = self.engine.connect() self.assertEqual(conn.scalar(sqla.select([1])), 1) with self._fixture(dialect_name, exc_obj, 1, is_disconnect): self.assertRaises( exception.DBConnectionError, self.engine.connect ) def test_mysql_w_disconnect_flag(self): for code in [2002, 2003]: self._test_ping_listener_disconnected( ""mysql"", self.OperationalError('%d MySQL server has gone away' % code) ) def test_mysql_wo_disconnect_flag(self): for code in [2002, 2003]: self._test_ping_listener_disconnected( ""mysql"", self.OperationalError('%d MySQL server has gone away' % code), is_disconnect=False )"," def _dbapi_fixture(self, dialect_name):",88,7
openstack%2Ffuel-main~master~I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda,openstack/fuel-main,master,I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda,Check started/restarted services only during last puppet run,MERGED,2014-12-22 20:05:50.000000000,2015-01-13 15:09:57.000000000,2015-01-13 15:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-22 20:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d3407b7bfc335f8cbe1c8c22db70fb63e9571f2e', 'message': 'Check started/restarted services only during last puppet run\n\n- get count of lines between last two ""Finished catalog run""\noccurrences in the /var/log/puppet using awk, or between 0 and\nthe an occurrence,\n- get the part of the log that refers to the last puppet run\nusing \'tail -n\' and obtained count of lines,\n- search the pattern within the obtained part of the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 2, 'created': '2015-01-11 21:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/44f353aa0ca9d8bfb23f0c72a55d6a7e71cdd217', 'message': 'Check started/restarted services only during last puppet run\n\n- get count of lines between last two ""Finished catalog run""\noccurrences in the /var/log/puppet using awk, or between 0 and\nthe an occurrence,\n- get the part of the log that refers to the last puppet run\nusing \'tail -n\' and obtained count of lines,\n- search the pattern within the obtained part of the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 3, 'created': '2015-01-11 22:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ffa4959af668777e0b99b216fe4be69cb88a6b95', 'message': 'Check started/restarted services only during last puppet run\n\n- get count of lines between last two ""Finished catalog run""\noccurrences in the /var/log/puppet using awk, or between 0 and\nthe an occurrence,\n- get the part of the log that refers to the last puppet run\nusing \'tail -n\' and obtained count of lines,\n- search the pattern within the obtained part of the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 4, 'created': '2015-01-12 07:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/057b2826fde6ea28ef6c0f1338ffb06da47f3040', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 5, 'created': '2015-01-12 07:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ced0ece6a903120f4920b1c2beb587ce5a4a258d', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 6, 'created': '2015-01-12 15:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/23e185d01d7fa7a2eea400ddd4c0dff891c87838', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 7, 'created': '2015-01-13 12:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/122e1e6ecbcfb8aceb4ae2160614d45eb2801c1a', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}, {'number': 8, 'created': '2015-01-13 12:01:34.000000000', 'files': ['fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/tests_os_patching/test_os_patching.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8f7d7154cd955c8229e500028c80c387d7a309af', 'message': 'Check started/restarted services only during last puppet run\n\n- get the part of the log that refers to the last puppet run\nby count the number of lines in the log before upgrade, and\nscan for pattern only the next lines in the log.\n\nChange-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda\nCloses-Bug: #1404950\n'}]",6,143520,8f7d7154cd955c8229e500028c80c387d7a309af,53,7,8,11969,,,0,"Check started/restarted services only during last puppet run

- get the part of the log that refers to the last puppet run
by count the number of lines in the log before upgrade, and
scan for pattern only the next lines in the log.

Change-Id: I1c01a6760f9ee5de47ae4ab3a88463866a2a3eda
Closes-Bug: #1404950
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/20/143520/8 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/utils.py'],1,d3407b7bfc335f8cbe1c8c22db70fb63e9571f2e,bug/1404950," cmd = (""LAST=`grep 'Finished catalog run' --line-number {0} |"" ""cut -f1 -d: | awk 'BEGIN{{A=0;B=0;}}{{A=B;B=$1;}}"" ""END{{print B-A}}'`; tail -n $LAST {0} |"" ""grep -E '/sbin/(re)?start' {0} | awk -F' ' '{{print $11}}'"" .format('/var/log/puppet.log')) cmd = (""LAST=`grep 'Finished catalog run' --line-number {0} |"" ""cut -f1 -d: | awk 'BEGIN{{A=0;B=0;}}{{A=B;B=$1;}}"" ""END{{print B-A}}'`; tail -n $LAST {0} |"" ""grep '/sbin/service openstack-%s' {0} |"" ""awk -F' ' '{{print $11}}' "".format('/var/log/puppet.log')) for service in services_list: res = node_ssh.execute(cmd % service)['stdout']"," cmd = (""grep '/sbin/restart' /var/log/puppet.log"" "" | awk -F' ' '{print $11}' "") cmd_template = (""grep '/sbin/service openstack-%s'"" "" /var/log/puppet.log| awk -F' ' '{print $11}' "") for service in services_list: res = node_ssh.execute(cmd_template % service)['stdout']",11,5
openstack%2Fhorizon~master~I9f04452b307ad2425b45f2705b01ec22425d1e97,openstack/horizon,master,I9f04452b307ad2425b45f2705b01ec22425d1e97,Remove the version in the footer of the System Information panel,ABANDONED,2015-01-13 08:51:07.000000000,2015-01-13 15:09:36.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 4264}, {'_account_id': 14606}]","[{'number': 1, 'created': '2015-01-13 08:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3f38acb89202e681f39f491c46663fb0f9594fc7', 'message': 'Remove the version in the footer of the System Information panel\n\nChange-Id: I9f04452b307ad2425b45f2705b01ec22425d1e97\n'}, {'number': 2, 'created': '2015-01-13 08:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/15b2f36547529d7205757b36ed2fe6d332939663', 'message': 'Remove the version in the footer of the System Information panel\n\nCo-Authored-By: Thomas Kaergel <kaergel@b1-systems.de>\n\nChange-Id: I9f04452b307ad2425b45f2705b01ec22425d1e97\n'}, {'number': 3, 'created': '2015-01-13 11:18:05.000000000', 'files': ['openstack_dashboard/dashboards/admin/info/templates/info/index.html', 'openstack_dashboard/dashboards/admin/info/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e7c8e2d5524163ec43aa9eeea6c8952b4cc43fb3', 'message': 'Remove the version in the footer of the System Information panel\n\nChange-Id: I9f04452b307ad2425b45f2705b01ec22425d1e97\n'}]",0,146800,e7c8e2d5524163ec43aa9eeea6c8952b4cc43fb3,10,4,3,167,,,0,"Remove the version in the footer of the System Information panel

Change-Id: I9f04452b307ad2425b45f2705b01ec22425d1e97
",git fetch https://review.opendev.org/openstack/horizon refs/changes/00/146800/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/info/templates/info/index.html', 'openstack_dashboard/dashboards/admin/info/views.py']",2,3f38acb89202e681f39f491c46663fb0f9594fc7,admin_system_info_remove_version,,"from horizon import version try: context[""version""] = version.version_info.version_string() except Exception: exceptions.handle(self.request, _('Unable to retrieve version information.')) ",0,11
openstack%2Fnova~master~I0c2a723b94dae5b1c3838b9644537324606128e5,openstack/nova,master,I0c2a723b94dae5b1c3838b9644537324606128e5,Hyper-V: fix tgt iSCSI targets disconnect issue,MERGED,2014-11-21 17:24:54.000000000,2015-01-13 15:04:01.000000000,2015-01-13 15:03:58.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8412}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12604}]","[{'number': 1, 'created': '2014-11-21 17:24:54.000000000', 'files': ['nova/virt/hyperv/basevolumeutils.py', 'nova/tests/unit/virt/hyperv/test_basevolumeutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/16484eca967c8d3c1a194362e8d1d6d87a711983', 'message': ""Hyper-V: fix tgt iSCSI targets disconnect issue\n\nWhen detaching volumes, the Hyper-V driver decides whether the\niSCSI target should be disconnected or not by comparing the number\nof volumes being disconnected and the total number of available LUNs\nof the according iSCSI target.\n\nThis causes problems as tgt exports one extra reserved LUN. For\nthis reason, the according iSCSI target won't be disconnected\nwhen a volume exported by TGT is detached.\n\nThe fix consists in checking the disk types when counting the\navailable LUNs of a target.\n\nChange-Id: I0c2a723b94dae5b1c3838b9644537324606128e5\nCloses-Bug: #1395063\n""}]",0,136433,16484eca967c8d3c1a194362e8d1d6d87a711983,19,13,1,8543,,,0,"Hyper-V: fix tgt iSCSI targets disconnect issue

When detaching volumes, the Hyper-V driver decides whether the
iSCSI target should be disconnected or not by comparing the number
of volumes being disconnected and the total number of available LUNs
of the according iSCSI target.

This causes problems as tgt exports one extra reserved LUN. For
this reason, the according iSCSI target won't be disconnected
when a volume exported by TGT is detached.

The fix consists in checking the disk types when counting the
available LUNs of a target.

Change-Id: I0c2a723b94dae5b1c3838b9644537324606128e5
Closes-Bug: #1395063
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/136433/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hyperv/basevolumeutils.py', 'nova/tests/unit/virt/hyperv/test_basevolumeutils.py']",2,16484eca967c8d3c1a194362e8d1d6d87a711983,bug/1395063," # Only disk devices are being counted. disk_device = mock.Mock(DeviceType=self._volutils._FILE_DEVICE_DISK) init_session.Devices.append(disk_device) fake_get_devices.return_value = init_session.Devices self.assertEqual(1, lun_count)"," fake_get_devices.return_value = [init_session] self.assertEqual(len(init_session.Devices), lun_count)",10,3
openstack%2Ffuel-library~master~I5756b55b67cd18be787b1381ad00afd39ddecf7d,openstack/fuel-library,master,I5756b55b67cd18be787b1381ad00afd39ddecf7d,Make globals to write variables into Hiera,MERGED,2015-01-12 14:39:20.000000000,2015-01-13 14:56:26.000000000,2015-01-13 14:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2015-01-12 14:39:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/30c238c0a531748976d2873a1e818c71111ced17', 'message': 'Make globals to write variables into Hiera\n\nGlobals will save all the generated variables into\nthe Hiera data structure and other manifests will be able\nto use these values without importing globals directly.\n\nHelper script generetes the template file and should\nre rerun after adding or removing global variables\nand modified template should be recommited.\n\nRelated-Blueprint: fuel-library-modularization\nChange-Id: I5756b55b67cd18be787b1381ad00afd39ddecf7d\n'}, {'number': 2, 'created': '2015-01-12 14:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dfdf49ec504e8df445ca5663e48c1cab8c4b3f06', 'message': 'Make globals to write variables into Hiera\n\nGlobals will save all the generated variables into\nthe Hiera data structure and other manifests will be able\nto use these values without importing globals directly.\n\nHelper script generetes the template file and should\nre rerun after adding or removing global variables\nand modified template should be recommited.\n\nRelated-Blueprint: fuel-library-modularization\nFuel-CI: disable\nChange-Id: I5756b55b67cd18be787b1381ad00afd39ddecf7d\n'}, {'number': 3, 'created': '2015-01-13 14:12:23.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/globals.pp', 'deployment/puppet/osnailyfacter/modular/globals_template_helper.rb', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/modular/hiera.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/87ad1d86322ebb4f989c7e7dc7fd29e9fd66c04a', 'message': 'Make globals to write variables into Hiera\n\nGlobals will save all the generated variables into\nthe Hiera data structure and other manifests will be able\nto use these values without importing globals directly.\n\nHelper script generetes the template file and should\nre rerun after adding or removing global variables\nand modified template should be recommited.\n\nRelated-Blueprint: fuel-library-modularization\nFuel-CI: disable\nChange-Id: I5756b55b67cd18be787b1381ad00afd39ddecf7d\n'}]",2,146477,87ad1d86322ebb4f989c7e7dc7fd29e9fd66c04a,30,6,3,9037,,,0,"Make globals to write variables into Hiera

Globals will save all the generated variables into
the Hiera data structure and other manifests will be able
to use these values without importing globals directly.

Helper script generetes the template file and should
re rerun after adding or removing global variables
and modified template should be recommited.

Related-Blueprint: fuel-library-modularization
Fuel-CI: disable
Change-Id: I5756b55b67cd18be787b1381ad00afd39ddecf7d
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/77/146477/3 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/globals.pp', 'deployment/puppet/osnailyfacter/modular/globals_template_helper.rb', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/modular/hiera.pp']",4,30c238c0a531748976d2873a1e818c71111ced17,bp/fuel-library-modularization,"$data = ['globals','astute'] mode => '0644',<% @data.each do |name| -%> - <%= name %> <% end -%>","$data_name = 'astute' mode => '0755', - <%= @data_name %>",156,4
openstack%2Fmagnetodb-specs~master~I5e66772f0651a846a92b5f434f26ad095e3d26e7,openstack/magnetodb-specs,master,I5e66772f0651a846a92b5f434f26ad095e3d26e7,Changed URL for monitoring API,MERGED,2014-12-22 14:44:08.000000000,2015-01-13 14:50:51.000000000,2015-01-13 14:50:50.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8414}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 11006}]","[{'number': 1, 'created': '2014-12-22 14:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/7c82aa29a2a3efa556b9be761c5510338e46072b', 'message': 'Changed URL for monitoring API\n\nChange-Id: I5e66772f0651a846a92b5f434f26ad095e3d26e7\nImplements: blueprint monitoring-api-url-refactoring\n'}, {'number': 2, 'created': '2014-12-23 14:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/9aeeb0de80588e189a9d142a1fa094833c019698', 'message': 'Changed URL for monitoring API\n\nChange-Id: I5e66772f0651a846a92b5f434f26ad095e3d26e7\nImplements: blueprint monitoring-api-url-refactoring\n'}, {'number': 3, 'created': '2014-12-25 12:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/df3182c905e8f8a67f9a3b1910dab2bd96f2c186', 'message': 'Changed URL for monitoring API\n\nChange-Id: I5e66772f0651a846a92b5f434f26ad095e3d26e7\nImplements: blueprint monitoring-api-url-refactoring\n'}, {'number': 4, 'created': '2015-01-08 16:12:02.000000000', 'files': ['specs/kilo/approved/monitoring-api.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb-specs/commit/109c125591ad8f6f7b058ef33c9141da628a01c0', 'message': 'Changed URL for monitoring API\n\nChange-Id: I5e66772f0651a846a92b5f434f26ad095e3d26e7\nImplements: blueprint monitoring-api-url-refactoring\n'}]",8,143458,109c125591ad8f6f7b058ef33c9141da628a01c0,21,7,4,8414,,,0,"Changed URL for monitoring API

Change-Id: I5e66772f0651a846a92b5f434f26ad095e3d26e7
Implements: blueprint monitoring-api-url-refactoring
",git fetch https://review.opendev.org/openstack/magnetodb-specs refs/changes/58/143458/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/monitoring-api.rst'],1,7c82aa29a2a3efa556b9be761c5510338e46072b,bp/monitoring-api-url-refactoring,"2. Implement single method for tables detailes /monitoring. 3. Implement filters by table_name, table_id, project_id.URL for the monitoring resource ``````````````````````````````` v1/monitoring?project_id=my_project_id&table_name=my_table_nameFilters should be passed as URL parameters. **project_id** * Returns data filtered by specified project_id * Type: string * Required: No **table_id** * Returns data for table with specified table_id * Type: string * Required: No **table_name** * Returns data filtered by specified table_name [ { ""project_id"": ""123"", ""table_id"": ""1234"", ""table_name"": ""my_table"", ""usage_detailes"": { ""metric1"": 1003432, ""metric2"": 3000 } }, ... ]None","2. Implement REST method for list of tables /{tenant_id}/monitoring/tables. 3. Table usage details /{tenant_id}/monitoring/tables/{table_name}.URL for the resource ```````````````````` v1/{tenant_id}/monitoring/tables/{table_name}?metrics=metric1,metric2Parameters should be provided via URL. **metrics** * Names of metrics to get { ""metric1"": 1003432, ""metric2"": 3000 } List tables ----------- Method type ``````````` GET Normal http response code(s) ```````````````````````````` 200 Expected error http response code(s) ```````````````````````````````````` 500 URL for the resource ```````````````````` v1/{tenant_id}/monitoring/tables Request Parameters `````````````````` Parameters should be provided via GET query string. **exclusive_start_table_name** * The first table name that this operation will evaluate. * Type: string * Required: No **limit** * A maximum number of the items to return. * Type: int * Required: No Response Syntax ``````````````` :: { ""last_evaluated_table_name"": ""string"", ""tables"": [ { ""rel"": ""string"", ""href"": ""url"" } ] } Response Elements ````````````````` **last_evaluated_table_name** * The name of the last table in the current page of results. * Type: String **tables** * Array of the table info items * Type: array of structshttps://review.openstack.org/#/c/122330/",30,78
openstack%2Fdesignate~master~I8f5839b5223c9fa24792c1dd0b8bf04d2432434d,openstack/designate,master,I8f5839b5223c9fa24792c1dd0b8bf04d2432434d,Updated from global requirements,MERGED,2015-01-13 00:02:44.000000000,2015-01-13 14:50:28.000000000,2015-01-13 14:50:26.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}]","[{'number': 1, 'created': '2015-01-13 00:02:44.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/9c82d7ec2c04c52d62d0335a6293b4d5a7547e5b', 'message': 'Updated from global requirements\n\nChange-Id: I8f5839b5223c9fa24792c1dd0b8bf04d2432434d\n'}]",0,146687,9c82d7ec2c04c52d62d0335a6293b4d5a7547e5b,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I8f5839b5223c9fa24792c1dd0b8bf04d2432434d
",git fetch https://review.opendev.org/openstack/designate refs/changes/87/146687/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9c82d7ec2c04c52d62d0335a6293b4d5a7547e5b,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Ffuel-astute~master~I9832e405143dbb6b2fbd22ed2d2bc7ad0bc85f01,openstack/fuel-astute,master,I9832e405143dbb6b2fbd22ed2d2bc7ad0bc85f01,"Granular deployment: tests, fixes and refactoring",MERGED,2015-01-12 13:40:21.000000000,2015-01-13 14:42:19.000000000,2015-01-13 14:42:19.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8907}, {'_account_id': 8935}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2015-01-12 13:40:21.000000000', 'files': ['lib/astute/puppet_task.rb', 'spec/unit/nailgun_spec.rb', 'mcagents/puppetd.rb', 'spec/unit/granular_deployment_spec.rb', 'lib/astute/deployment_engine/granular_deployment.rb', 'spec/unit/puppet_task_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/85b1e638d8c0c73085b87d576cbcee1cba61f6e4', 'message': 'Granular deployment: tests, fixes and refactoring\n\n- fix problem with error nodes (endless loop);\n- add tests for puppet tasks.\n- update mcollective agent (should work with old version also).\n\nCloses-Bug: #1392779 (refactoring https://review.openstack.org/#/c/138790)\nImplements blueprint granular-deployment-based-on-tasks\n\nChange-Id: I9832e405143dbb6b2fbd22ed2d2bc7ad0bc85f01\n'}]",0,146464,85b1e638d8c0c73085b87d576cbcee1cba61f6e4,12,7,1,8776,,,0,"Granular deployment: tests, fixes and refactoring

- fix problem with error nodes (endless loop);
- add tests for puppet tasks.
- update mcollective agent (should work with old version also).

Closes-Bug: #1392779 (refactoring https://review.openstack.org/#/c/138790)
Implements blueprint granular-deployment-based-on-tasks

Change-Id: I9832e405143dbb6b2fbd22ed2d2bc7ad0bc85f01
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/64/146464/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/puppet_task.rb', 'spec/unit/nailgun_spec.rb', 'mcagents/puppetd.rb', 'spec/unit/granular_deployment_spec.rb', 'lib/astute/deployment_engine/granular_deployment.rb', 'spec/unit/puppet_task_spec.rb']",6,85b1e638d8c0c73085b87d576cbcee1cba61f6e4,bug/1392779,"# Copyright 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. require File.join(File.dirname(__FILE__), '../spec_helper') describe Astute::PuppetTask do include SpecHelpers let(:node) do { 'uid' => '45', 'priority' => 200, 'role' => 'ceph', 'tasks' => [ { 'priority' => 100, 'type' => 'puppet', 'uids' => ['45'] }, { 'priority' => 300, 'type' => 'puppet', 'uids' => ['45'] } ] } end let(:ctx) { ctx = mock ctx.stubs(:task_id) ctx.stubs(:deploy_log_parser).returns(Astute::LogParser::NoParsing.new) ctx.stubs(:status).returns({}) reporter = mock reporter.stubs(:report) up_reporter = Astute::ProxyReporter::DeploymentProxyReporter.new(reporter, [node]) ctx.stubs(:reporter).returns(up_reporter) ctx } let(:puppet_task) { Astute::PuppetTask.new(ctx, node)} let(:puppet_task_wo_retries) { Astute::PuppetTask.new(ctx, node, retries=0)} let(:mco_puppet_stopped) do { :changes => {""total"" => 1}, :time => {""last_run"" => 1358425701}, :resources => {""failed"" => 0}, :status => ""stopped"", :enabled => 1, :stopped => 1, :idling => 0, :running => 0, :runtime => 1358425701 } end let(:mco_puppet_running) do mco_puppet_stopped.merge( :status => 'running', :running => 1, :stopped => 0 ) end let(:mco_puppet_fail) do mco_puppet_running.merge( :runtime => 1358426000, :time => {""last_run"" => 1358426000}, :resources => {""failed"" => 1} ) end let(:mco_puppet_failed) do mco_puppet_fail.merge( :status => 'stopped', :stopped => 1, :running => 0 ) end let(:mco_puppet_finished) do mco_puppet_stopped.merge( :time => {'last_run' => 1358428000}, :status => 'stopped' ) end let(:mco_puppet_idling) do mco_puppet_stopped.merge( :status => 'idling', :running => 0, :stopped => 0, :idling => 1 ) end describe ""#run"" do it 'run puppet using mcollective' do puppet_task.expects(:puppet_status).returns(mco_puppet_stopped).times(2) puppet_task.expects(:puppet_run) puppet_task.run end end #run describe ""#status"" do before(:each) do ctx.stubs(:report_and_update_status) end it 'check puppet using mcollective' do puppet_task.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_running) .then.returns(mco_puppet_finished) puppet_task.expects(:puppet_run) puppet_task.run end it 'return error for node if puppet failed (a cycle w/o any transitional states)' do puppet_task_wo_retries.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_failed) puppet_task_wo_retries.expects(:puppet_run) puppet_task_wo_retries.run expect(puppet_task_wo_retries.status).to eql('error') end it 'retries to run puppet if it fails and return middle status' do puppet_task.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_failed) .then.returns(mco_puppet_failed) .then.returns(mco_puppet_finished) puppet_task.expects(:puppet_run).times(2) puppet_task.run expect(puppet_task.status).to eql('deploying') expect(puppet_task.status).to eql('ready') end it ""return error for node if puppet failed (a cycle with one running state only)"" do puppet_task_wo_retries.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_running) .then.returns(mco_puppet_running) .then.returns(mco_puppet_fail) .then.returns(mco_puppet_failed) puppet_task_wo_retries.expects(:puppet_run) puppet_task_wo_retries.run expect(puppet_task_wo_retries.status).to eql('deploying') expect(puppet_task_wo_retries.status).to eql('deploying') expect(puppet_task_wo_retries.status).to eql('deploying') expect(puppet_task_wo_retries.status).to eql('error') end it ""error status for node if puppet failed (a cycle w/o idle and finishing states)"" do puppet_task_wo_retries.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_running) .then.returns(mco_puppet_failed) puppet_task_wo_retries.expects(:puppet_run) puppet_task_wo_retries.run expect(puppet_task_wo_retries.status).to eql('deploying') expect(puppet_task_wo_retries.status).to eql('error') end it ""retries to run puppet if it idling"" do puppet_task.stubs(:puppet_status).returns(mco_puppet_stopped) .then.returns(mco_puppet_idling) .then.returns(mco_puppet_stopped) .then.returns(mco_puppet_running) .then.returns(mco_puppet_finished) puppet_task.expects(:puppet_run).times(2) puppet_task.run expect(puppet_task.status).to eql('deploying') expect(puppet_task.status).to eql('ready') end end #status end",,593,219
openstack%2Fproject-config~master~I8e296595945c8cfe91a88f69ae46fe33c53df2db,openstack/project-config,master,I8e296595945c8cfe91a88f69ae46fe33c53df2db,Use correct path for tempest in testr dib script,MERGED,2015-01-13 06:09:15.000000000,2015-01-13 14:33:31.000000000,2015-01-13 14:33:29.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-13 06:09:15.000000000', 'files': ['nodepool/elements/cache-devstack/install.d/99-cache-testrepository-db'], 'web_link': 'https://opendev.org/openstack/project-config/commit/87bba6b03f8a13a96fe8b41ee6847a02c450433a', 'message': 'Use correct path for tempest in testr dib script\n\nWhen seeding tempest with testrepository subunit data use the correct\npath to the tempest repo in the imgae build. Because we moved to\ninstall.d we ues a path relative to the chroot and not relative to the\nmount path.\n\nChange-Id: I8e296595945c8cfe91a88f69ae46fe33c53df2db\n'}]",0,146768,87bba6b03f8a13a96fe8b41ee6847a02c450433a,9,5,1,4146,,,0,"Use correct path for tempest in testr dib script

When seeding tempest with testrepository subunit data use the correct
path to the tempest repo in the imgae build. Because we moved to
install.d we ues a path relative to the chroot and not relative to the
mount path.

Change-Id: I8e296595945c8cfe91a88f69ae46fe33c53df2db
",git fetch https://review.opendev.org/openstack/project-config refs/changes/68/146768/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/cache-devstack/install.d/99-cache-testrepository-db'],1,87bba6b03f8a13a96fe8b41ee6847a02c450433a,fix-dib-testr-path,TEMPEST_DIR=/opt/git/openstack/tempest,TEMPEST_DIR=$TMP_MOUNT_PATH/opt/git/openstack/tempest ,1,2
openstack%2Fironic~master~I16815487d960f674cdcec6494a6314076d839cdb,openstack/ironic,master,I16815487d960f674cdcec6494a6314076d839cdb,Avoid querying the power state twice,MERGED,2015-01-12 16:31:37.000000000,2015-01-13 14:25:46.000000000,2015-01-13 14:25:45.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 8688}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2015-01-12 16:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7472c5c8fbe6c3bee25237f243815655a84e5230', 'message': ""Avoid querying the power state twice\n\n'reboot' queries the power state and turns the node off if it's already\non. Then it calls '_power_on', which does all that again before attempting\nto power the node on. Remove the code in 'reboot' so the power state is\nonly queried once.\n\nChange-Id: I16815487d960f674cdcec6494a6314076d839cdb\n""}, {'number': 2, 'created': '2015-01-13 10:33:34.000000000', 'files': ['ironic/tests/drivers/test_ssh.py', 'ironic/drivers/modules/ssh.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/dd301dd461933d1c19b4b588f5476946d1b11930', 'message': ""Avoid querying the power state twice\n\n'reboot' queries the power state and turns the node off if it's already\non. Then it calls '_power_on', which does all that again before attempting\nto power the node on. Remove the code in 'reboot' so the power state is\nonly queried once.\n\nChange-Id: I16815487d960f674cdcec6494a6314076d839cdb\n""}]",9,146554,dd301dd461933d1c19b4b588f5476946d1b11930,21,6,2,8688,,,0,"Avoid querying the power state twice

'reboot' queries the power state and turns the node off if it's already
on. Then it calls '_power_on', which does all that again before attempting
to power the node on. Remove the code in 'reboot' so the power state is
only queried once.

Change-Id: I16815487d960f674cdcec6494a6314076d839cdb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/146554/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/test_ssh.py', 'ironic/drivers/modules/ssh.py']",2,7472c5c8fbe6c3bee25237f243815655a84e5230,146554, # _power_on will turn the power off if it's already on.," current_pstate = _get_power_status(ssh_obj, driver_info) if current_pstate == states.POWER_ON: _power_off(ssh_obj, driver_info) ",1,9
openstack%2Fnova~master~Ic01b4d8d0f0100f735f675a385134cdfff5faa85,openstack/nova,master,Ic01b4d8d0f0100f735f675a385134cdfff5faa85,Metadata service: make use of get_instance_availability_zone,MERGED,2014-11-09 16:13:41.000000000,2015-01-13 14:25:19.000000000,2015-01-13 14:25:08.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-09 16:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/73fea0aa42d992689b83dd312337c97e39b186b9', 'message': 'Metadata service: make use of get_instance_availability_zone\n\nCommit 488fcb4ad345bfb4fd614a140b317b606e008872 added a helper\nfor getting the AZ for a instance. This patch makes use of that\nhelper method.\n\nChange-Id: Ic01b4d8d0f0100f735f675a385134cdfff5faa85\n'}, {'number': 2, 'created': '2014-11-13 07:28:01.000000000', 'files': ['nova/api/metadata/base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0ca75c956d5e06846ed90e9028abc0bad8b750f', 'message': 'Metadata service: make use of get_instance_availability_zone\n\nCommit 488fcb4ad345bfb4fd614a140b317b606e008872 added a helper\nfor getting the AZ for a instance. This patch makes use of that\nhelper method.\n\nChange-Id: Ic01b4d8d0f0100f735f675a385134cdfff5faa85\n'}]",2,133380,e0ca75c956d5e06846ed90e9028abc0bad8b750f,30,12,2,1653,,,0,"Metadata service: make use of get_instance_availability_zone

Commit 488fcb4ad345bfb4fd614a140b317b606e008872 added a helper
for getting the AZ for a instance. This patch makes use of that
helper method.

Change-Id: Ic01b4d8d0f0100f735f675a385134cdfff5faa85
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/133380/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/metadata/base.py'],1,73fea0aa42d992689b83dd312337c97e39b186b9,use-instance-az,"from nova import availability_zones as az self.availability_zone = az.get_instance_availability_zone(ctxt, instance)"," self.availability_zone = ec2utils.get_availability_zone_by_host( instance.host, capi)",3,2
openstack%2Fgnocchi~master~I6148639d069fb175bca878952ec58b3ff69d412e,openstack/gnocchi,master,I6148639d069fb175bca878952ec58b3ff69d412e,tests: fix AP retrieval,MERGED,2015-01-12 11:43:41.000000000,2015-01-13 14:24:40.000000000,2015-01-13 14:24:40.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-01-12 11:43:41.000000000', 'files': ['gnocchi/tests/base.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8d4803d63e09ef37a4867b86f81856e08d1e9622', 'message': 'tests: fix AP retrieval\n\nChange-Id: I6148639d069fb175bca878952ec58b3ff69d412e\n'}]",0,146426,8d4803d63e09ef37a4867b86f81856e08d1e9622,6,3,1,1669,,,0,"tests: fix AP retrieval

Change-Id: I6148639d069fb175bca878952ec58b3ff69d412e
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/26/146426/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/tests/base.py'],1,8d4803d63e09ef37a4867b86f81856e08d1e9622,jd/statsd, ap = self.archive_policies[ definition=definition) except indexer.ArchivePolicyAlreadyExists: ap = self.index.get_archive_policy(name) self.archive_policies[ name] = archive_policy.ArchivePolicy.from_dict(ap), self.archive_policies[ definition=definition)['definition'] except indexer.ArchivePolicyAlreadyExists: self.archive_policies[ name] = archive_policy.ArchivePolicy.from_dict( self.index.get_archive_policy(name)),5,5
openstack%2Fpuppet-neutron~master~Id12adbc7f75940b2f6bd01e6080c853b15cf2116,openstack/puppet-neutron,master,Id12adbc7f75940b2f6bd01e6080c853b15cf2116,Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default,MERGED,2015-01-02 21:45:06.000000000,2015-01-13 14:23:56.000000000,2015-01-13 13:32:28.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-01-02 21:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/44c8cab1f65f069bd8cc0da19ba48a3fa78ead09', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: Id12adbc7f75940b2f6bd01e6080c853b15cf2116\n""}, {'number': 2, 'created': '2015-01-12 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/057fbd9e31ffaf2459b751364441977bdd75719a', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: Id12adbc7f75940b2f6bd01e6080c853b15cf2116\n""}, {'number': 3, 'created': '2015-01-12 16:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/57b5be8bdf94d05b00158808532e985c119ac153', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: Id12adbc7f75940b2f6bd01e6080c853b15cf2116\n""}, {'number': 4, 'created': '2015-01-13 12:48:07.000000000', 'files': ['spec/classes/neutron_init_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f2b115c5669fd752965123950681a9fad78dcf0f', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: Id12adbc7f75940b2f6bd01e6080c853b15cf2116\n""}]",1,144808,f2b115c5669fd752965123950681a9fad78dcf0f,16,4,4,11166,,,0,"Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default

Rabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled
support for SSLv3. Openstack components use python's openssl
implementation which does not support TLSv1.1 and TLSv1.2 yet so we
just switch to TLSv1. Support for newer TLS should come with python
2.7.9+

Closes-Bug: #1409667
Change-Id: Id12adbc7f75940b2f6bd01e6080c853b15cf2116
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/08/144808/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_init_spec.rb', 'manifests/init.pp']",2,44c8cab1f65f069bd8cc0da19ba48a3fa78ead09,bug/1409667,"# Defaults to TLSv1' $kombu_ssl_version = 'TLSv1',","# Defaults to 'SSLv3' $kombu_ssl_version = 'SSLv3',",6,6
openstack%2Fpuppet-keystone~master~I852cf4d68de6d6b40056b9928971e63fc1b76a3b,openstack/puppet-keystone,master,I852cf4d68de6d6b40056b9928971e63fc1b76a3b,Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default,MERGED,2015-01-02 19:49:33.000000000,2015-01-13 14:23:48.000000000,2015-01-12 23:57:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-01-02 19:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/657218cdb0dad532905298cf2676a2646d2aac01', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I852cf4d68de6d6b40056b9928971e63fc1b76a3b\n""}, {'number': 2, 'created': '2015-01-12 10:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c0a6c1661c7a0a450244b7c21fe69b8daefb989c', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I852cf4d68de6d6b40056b9928971e63fc1b76a3b\n""}, {'number': 3, 'created': '2015-01-12 16:42:27.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/370f2aa24256dc54f363216ddc3009c199595d14', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I852cf4d68de6d6b40056b9928971e63fc1b76a3b\n""}]",0,144797,370f2aa24256dc54f363216ddc3009c199595d14,12,3,3,11166,,,0,"Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default

Rabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled
support for SSLv3. Openstack components use python's openssl
implementation which does not support TLSv1.1 and TLSv1.2 yet so we
just switch to TLSv1. Support for newer TLS should come with python
2.7.9+

Closes-Bug: #1409667
Change-Id: I852cf4d68de6d6b40056b9928971e63fc1b76a3b
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/97/144797/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,657218cdb0dad532905298cf2676a2646d2aac01,,"# Defaults to 'TLSv1' $kombu_ssl_version = 'TLSv1',","# Defaults to 'SSLv3' $kombu_ssl_version = 'SSLv3',",5,5
openstack%2Fpuppet-heat~master~I949421cd092a31eab3ef7f2194c4da3a9dbac818,openstack/puppet-heat,master,I949421cd092a31eab3ef7f2194c4da3a9dbac818,Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default,MERGED,2015-01-02 19:27:53.000000000,2015-01-13 14:23:39.000000000,2015-01-12 23:44:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-01-02 19:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/4f8ce8f8b5f2a8820afb9df71da9740255082238', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I949421cd092a31eab3ef7f2194c4da3a9dbac818\n""}, {'number': 2, 'created': '2015-01-12 10:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/ba1896d8837ee85c4bdaf3c2e94f55862dcadc98', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I949421cd092a31eab3ef7f2194c4da3a9dbac818\n""}, {'number': 3, 'created': '2015-01-12 16:42:17.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/c231da8de6d3ef14a23259d1d8e05c7b6c6d83ba', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I949421cd092a31eab3ef7f2194c4da3a9dbac818\n""}]",0,144793,c231da8de6d3ef14a23259d1d8e05c7b6c6d83ba,12,3,3,11166,,,0,"Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default

Rabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled
support for SSLv3. Openstack components use python's openssl
implementation which does not support TLSv1.1 and TLSv1.2 yet so we
just switch to TLSv1. Support for newer TLS should come with python
2.7.9+

Closes-Bug: #1409667
Change-Id: I949421cd092a31eab3ef7f2194c4da3a9dbac818
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/93/144793/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/heat_init_spec.rb']",2,4f8ce8f8b5f2a8820afb9df71da9740255082238,, :kombu_ssl_version => 'TLSv1' should contain_heat_config('DEFAULT/kombu_ssl_version').with_value('TLSv1') should contain_heat_config('DEFAULT/kombu_ssl_version').with_value('TLSv1') :kombu_ssl_version => 'TLSv1', :kombu_ssl_version => 'SSLv3' should contain_heat_config('DEFAULT/kombu_ssl_version').with_value('SSLv3') should contain_heat_config('DEFAULT/kombu_ssl_version').with_value('SSLv3') :kombu_ssl_version => 'SSLv3',6,6
openstack%2Fpuppet-glance~master~I6dd2dcf7d047d8cee028c3f890221194b0179b8a,openstack/puppet-glance,master,I6dd2dcf7d047d8cee028c3f890221194b0179b8a,Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default,MERGED,2015-01-02 19:18:25.000000000,2015-01-13 14:23:30.000000000,2015-01-12 23:42:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-01-02 19:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/c8147ea79e3f4332a3e0c778f5c7f1226cd83761', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I6dd2dcf7d047d8cee028c3f890221194b0179b8a\n""}, {'number': 2, 'created': '2015-01-12 10:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/d675fa3cd5af48440b7fbe12520e5efa1230f6bb', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I6dd2dcf7d047d8cee028c3f890221194b0179b8a\n""}, {'number': 3, 'created': '2015-01-12 16:42:01.000000000', 'files': ['manifests/notify/rabbitmq.pp', 'spec/classes/glance_notify_rabbitmq_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/592503bef1196d69c0e44efca3bea19104c3862b', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I6dd2dcf7d047d8cee028c3f890221194b0179b8a\n""}]",0,144791,592503bef1196d69c0e44efca3bea19104c3862b,13,4,3,11166,,,0,"Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default

Rabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled
support for SSLv3. Openstack components use python's openssl
implementation which does not support TLSv1.1 and TLSv1.2 yet so we
just switch to TLSv1. Support for newer TLS should come with python
2.7.9+

Closes-Bug: #1409667
Change-Id: I6dd2dcf7d047d8cee028c3f890221194b0179b8a
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/91/144791/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/notify/rabbitmq.pp', 'spec/classes/glance_notify_rabbitmq_spec.rb']",2,c8147ea79e3f4332a3e0c778f5c7f1226cd83761,," :kombu_ssl_version => 'TLSv1',"," :kombu_ssl_version => 'SSLv3',",3,3
openstack%2Fpuppet-ceilometer~master~I00cfa06030b84ae23cb8548b74cf5684562377aa,openstack/puppet-ceilometer,master,I00cfa06030b84ae23cb8548b74cf5684562377aa,Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default,MERGED,2015-01-02 19:05:01.000000000,2015-01-13 14:23:14.000000000,2015-01-12 23:41:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 7155}, {'_account_id': 10540}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-02 19:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/d429eafcc3fa5c40021337a2349437d46f4daf9e', 'message': ""SSLv3 is considered insecure and disabled by default\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa\n""}, {'number': 2, 'created': '2015-01-02 19:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/df7651539782e8c149d42b9144c404f27928c2f3', 'message': ""SSLv3 is considered insecure and disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa\n""}, {'number': 3, 'created': '2015-01-02 19:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/bea8d79d8de711cc8e374a8a4aa747b3bd339312', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nChange-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa\n""}, {'number': 4, 'created': '2015-01-12 10:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/ebf97c7cbc5a9cbef034fcafd937aae24c3912cd', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled support for\nSSLv3. Openstack components use python's openssl implementation which does not support\nTLSv1.1 and TLSv1.2 yet so we just switch to TLSv1. Support for newer TLS should come\nwith python 2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa\n""}, {'number': 5, 'created': '2015-01-12 16:36:44.000000000', 'files': ['manifests/init.pp', 'spec/classes/ceilometer_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/90247cf8cd0eac760d5b8eb986ceacf0db3fcc7f', 'message': ""Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default\n\nRabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled\nsupport for SSLv3. Openstack components use python's openssl\nimplementation which does not support TLSv1.1 and TLSv1.2 yet so we\njust switch to TLSv1. Support for newer TLS should come with python\n2.7.9+\n\nCloses-Bug: #1409667\nChange-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa\n""}]",1,144788,90247cf8cd0eac760d5b8eb986ceacf0db3fcc7f,19,6,5,11166,,,0,"Switch to TLSv1 as SSLv3 is considered insecure and is disabled by default

Rabbitmq won't talk to us anymore if we try to use SSLv3 as it disabled
support for SSLv3. Openstack components use python's openssl
implementation which does not support TLSv1.1 and TLSv1.2 yet so we
just switch to TLSv1. Support for newer TLS should come with python
2.7.9+

Closes-Bug: #1409667
Change-Id: I00cfa06030b84ae23cb8548b74cf5684562377aa
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/88/144788/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/ceilometer_init_spec.rb']",2,d429eafcc3fa5c40021337a2349437d46f4daf9e,, it { should contain_ceilometer_config('DEFAULT/kombu_ssl_version').with_value('TLSv1') }, it { should contain_ceilometer_config('DEFAULT/kombu_ssl_version').with_value('SSLv3') },3,3
openstack%2Fneutron~master~If063742bc1be595d1d91b60d9059a01e94d31696,openstack/neutron,master,If063742bc1be595d1d91b60d9059a01e94d31696,hacking: enable W292 (no newline at end of file),MERGED,2015-01-12 16:28:51.000000000,2015-01-13 14:22:17.000000000,2015-01-13 13:47:52.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7249}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-12 16:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bbc05ec9862c1c69d646d964c6f3ca8fa0906d57', 'message': 'hacking: enable W292 (no newline at end of file)\n\nThis check was added in hacking 0.10.\n\nChange-Id: If063742bc1be595d1d91b60d9059a01e94d31696\n'}, {'number': 2, 'created': '2015-01-12 22:46:34.000000000', 'files': ['neutron/tests/unit/ml2/drivers/mech_sriov/test_mech_sriov_nic_switch.py', 'neutron/db/migration/alembic_migrations/versions/4dbe243cd84d_nsxv.py', 'neutron/db/migration/alembic_migrations/versions/e197124d4b9_add_unique_constrain.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/tests/unit/ml2/test_type_tunnel.py', 'tox.ini', 'neutron/tests/unit/ml2/test_type_gre.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/967d4589817b1a97d62ca805e4e628fc15878661', 'message': 'hacking: enable W292 (no newline at end of file)\n\nThis check was added in hacking 0.10.\n\nChange-Id: If063742bc1be595d1d91b60d9059a01e94d31696\n'}]",0,146550,967d4589817b1a97d62ca805e4e628fc15878661,47,21,2,9656,,,0,"hacking: enable W292 (no newline at end of file)

This check was added in hacking 0.10.

Change-Id: If063742bc1be595d1d91b60d9059a01e94d31696
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/146550/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/4dbe243cd84d_nsxv.py', 'neutron/tests/unit/ml2/drivers/mech_sriov/test_mech_sriov_nic_switch.py', 'neutron/db/migration/alembic_migrations/versions/e197124d4b9_add_unique_constrain.py', 'neutron/tests/unit/ml2/test_type_vxlan.py', 'neutron/tests/unit/ml2/test_type_tunnel.py', 'tox.ini', 'neutron/tests/unit/ml2/test_type_gre.py']",7,bbc05ec9862c1c69d646d964c6f3ca8fa0906d57,hacking, DRIVER_CLASS = type_gre.GreTypeDriver , DRIVER_CLASS = type_gre.GreTypeDriver,7,8
openstack%2Fpuppet-ceilometer~master~I004d7e7a9bfccc4677d5d629503a92a15b6263c6,openstack/puppet-ceilometer,master,I004d7e7a9bfccc4677d5d629503a92a15b6263c6,Implement Ceilometer-API as a WSGI process support,MERGED,2015-01-08 00:07:31.000000000,2015-01-13 14:17:16.000000000,2015-01-12 00:14:55.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9410}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-01-08 00:07:31.000000000', 'files': ['metadata.json', 'manifests/wsgi/apache.pp', '.fixtures.yml', 'spec/classes/ceilometer_wsgi_apache_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a3fbf2e8cb9ef76d2ee960cc8087c62736f7de6c', 'message': ""Implement Ceilometer-API as a WSGI process support\n\nCeilometer API can be run as a WSGI process.\nLet's use openstacklib to run this service under WSGI process by using\nApache2.\n\nChange-Id: I004d7e7a9bfccc4677d5d629503a92a15b6263c6\n""}]",1,145638,a3fbf2e8cb9ef76d2ee960cc8087c62736f7de6c,14,7,1,3153,,,0,"Implement Ceilometer-API as a WSGI process support

Ceilometer API can be run as a WSGI process.
Let's use openstacklib to run this service under WSGI process by using
Apache2.

Change-Id: I004d7e7a9bfccc4677d5d629503a92a15b6263c6
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/38/145638/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/wsgi/apache.pp', '.fixtures.yml', 'spec/classes/ceilometer_wsgi_apache_spec.rb', 'manifests/params.pp']",5,a3fbf2e8cb9ef76d2ee960cc8087c62736f7de6c,api-wsgi, $ceilometer_wsgi_script_path = '/var/www/cgi-bin/ceilometer' $ceilometer_wsgi_script_source = '/usr/lib/python2.7/site-packages/ceilometer/api/app.wsgi' $ceilometer_wsgi_script_path = '/usr/lib/cgi-bin/ceilometer' $ceilometer_wsgi_script_source = '/usr/share/ceilometer/app.wsgi',,257,0
openstack%2Fproject-config~master~If2a1e2db462b9202251188aeff55a54db9b32e60,openstack/project-config,master,If2a1e2db462b9202251188aeff55a54db9b32e60,Add Fuel Client to Stackforge,MERGED,2015-01-08 17:12:35.000000000,2015-01-13 14:14:42.000000000,2015-01-13 14:14:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6623}, {'_account_id': 6786}, {'_account_id': 8954}, {'_account_id': 9546}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-01-08 17:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b1a6fce436df21815c571dd56f7fa0d572bf7de5', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 2, 'created': '2015-01-09 09:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/284feec298bf6163be5c2a9b658c8286a20d2ee4', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 3, 'created': '2015-01-09 10:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/108da6ec0f3121ab4f0647eabcde7cf0f3c46d69', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 4, 'created': '2015-01-09 15:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/236ef5bec460f078755457a4f9d36c2bc35cae4d', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nBlueprint: re-thinking-fuel-client\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 5, 'created': '2015-01-09 16:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ce3b46b0c94605b15c9a1569dc005189d7853a82', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nBlueprint: re-thinking-fuel-client\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 6, 'created': '2015-01-12 10:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b9458bddbacb1ab02ba8cb27f7953037bc7d91b', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be moved into a separate repository on Stackforge\n\nBlueprint: re-thinking-fuel-client\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 7, 'created': '2015-01-12 10:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3b905b07311a4906d49f45eaafce700a11686f04', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be factored out as a separate project called\npython-fuelclient and hosted on Stackforge.\n\nBlueprint: re-thinking-fuel-client\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}, {'number': 8, 'created': '2015-01-12 13:37:35.000000000', 'files': ['gerrit/acls/stackforge/python-fuelclient.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3aa3dbc6eb6f84844a8e62d3137143563396896d', 'message': 'Add Fuel Client to Stackforge\n\nAccording to the refactoring plan described in\nIf3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client\nshould be factored out as a separate project called\npython-fuelclient and hosted on Stackforge.\n\nBlueprint: re-thinking-fuel-client\nChange-Id: If2a1e2db462b9202251188aeff55a54db9b32e60\n'}]",6,145843,3aa3dbc6eb6f84844a8e62d3137143563396896d,35,10,8,6623,,,0,"Add Fuel Client to Stackforge

According to the refactoring plan described in
If3d5f5ed0ccfc9e9333034bfa2debb7f0df9b225 Fuel Client
should be factored out as a separate project called
python-fuelclient and hosted on Stackforge.

Blueprint: re-thinking-fuel-client
Change-Id: If2a1e2db462b9202251188aeff55a54db9b32e60
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/145843/8 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/stackforge/python-fuelclient.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,b1a6fce436df21815c571dd56f7fa0d572bf7de5,new-project, - name: ^(gate|check)-python-fuelclient-python33 voting: false- name: stackforge/project-fuelclient template: - name: merge-check - name: python-jobs - name: python3-jobs ,,34,0
openstack%2Ftelemetry-specs~master~Ib834707cff136114b480c8555c29f3d9ca23e6fc,openstack/telemetry-specs,master,Ib834707cff136114b480c8555c29f3d9ca23e6fc,event pipelines,MERGED,2014-12-03 23:43:29.000000000,2015-01-13 14:14:28.000000000,2015-01-13 14:14:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 7336}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-12-03 23:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/c87574caa6b825a7dc0e02248038605a1a3b11bc', 'message': 'notification pipelines\n\nChange-Id: Ib834707cff136114b480c8555c29f3d9ca23e6fc\n'}, {'number': 2, 'created': '2014-12-03 23:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/7dc7f7c5c90b4be320d18f44b18307407a5b97ef', 'message': 'notification pipelines\n\nChange-Id: Ib834707cff136114b480c8555c29f3d9ca23e6fc\n'}, {'number': 3, 'created': '2014-12-04 18:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/834340b3506d1b2c88fc43a4898c45a8430d9df5', 'message': 'event pipelines\n\nChange-Id: Ib834707cff136114b480c8555c29f3d9ca23e6fc\n'}, {'number': 4, 'created': '2014-12-04 22:55:15.000000000', 'files': ['specs/kilo/notification-pipeline.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/068e5a6d0437654118bfa9445d1f77af8b536acf', 'message': 'event pipelines\n\nChange-Id: Ib834707cff136114b480c8555c29f3d9ca23e6fc\n'}]",10,138904,068e5a6d0437654118bfa9445d1f77af8b536acf,24,9,4,6537,,,0,"event pipelines

Change-Id: Ib834707cff136114b480c8555c29f3d9ca23e6fc
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/04/138904/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/notification-pipeline.rst'],1,c87574caa6b825a7dc0e02248038605a1a3b11bc,notification-pipelines,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Notification Pipelines ====================== https://blueprints.launchpad.net/ceilometer/+spec/notification-pipeline Problem description =================== Currently, when notifications are picked up by the notification agent, they are all funnelled into a single endpoint, filtered using event_definition and pushed to the dispatchers, which is generally a database. There is a lack of flexibility to transform, extend, trigger on these events and to publish to this data to multiple consumers. Proposed change =============== Like samples, we have a pipeline for events. Like samples, we define sources and sinks. Unlike samples, we don't have an interval defined in sources. The proposed schema is:: --- sources: - name: eventA_source # any unique name for source events: # list of event_types, same wildcard technique in samples - ""*"" sinks: - sink1 - sink2 sinks: - name: sink1 # any unique name for sink transformers: # one or many transformers -- outside scope of bp triggers: # potential for triggering (short term inline alarms) publishers: # we will not support rpc it isn't great for performance - notifier:// Publishers here can be a little different. we currently publish straight to the database avoiding the collector. In this spec, I'm proposing to make the collector agent(s) the single source of data retention. This allows deployers to choose their own proprietary collection mechanisms. It also moves the (potential) logic of coordinated data collection to collectors exclusively. This will also allow ability to publish different data (ie. audit) to different storages and also allow ability to ignore notifications completely (currently, we capture a shell event for all notifications) Alternatives ------------ - continue publishing directly from notification agent to events db. - put this in same pipeline.yaml file as samples Data model impact ----------------- This will require adding an endpoint in the collector to pick up events off notification bus. REST API impact --------------- None currently but it'll affect pipeline in database work. Security impact --------------- Same security concerns as current publishers. Pipeline impact --------------- This is a completely new pipeline so yes there is impact: a new pipeline.yaml Other end user impact --------------------- You need another pipeline.yaml; You need to configure it appropriately. Performance/Scalability Impacts ------------------------------- This will by default cause no difference except overhead of publishing to collector. There's potential for less data because of ability to filter out events. There's potential for more data because of transformers and multiple publishers. We have notification agent coordination which will split pipeline and data across agents to handle scaling. Other deployer impact --------------------- Adding a configuration option for new pipeline.yaml Developer impact ---------------- Understand how pipelines work if they don't understand already. Implementation ============== Assignee(s) ----------- Primary assignee: chungg Ongoing maintainer: chungg Work Items ---------- - create event_pipeline.yaml - redirect current event endpoint to use this pipeline - add publisher support for events - add listener and write support in collector - redraw architecture diagram Future lifecycle ================ Build transformers. Build triggers. Build publishers. Dependencies ============ None. Testing ======= - extend pipeline testing to include event_pipeline Documentation Impact ==================== - redraw architecture diagram - rewrite pipeline notes to include new event_pipeline and it's differences References ========== https://blueprints.launchpad.net/ceilometer/+spec/notification-pipelines ",,153,0
openstack%2Fapi-site~master~I5e68d03e8fff85e1d83454a05a8625fb22fe0def,openstack/api-site,master,I5e68d03e8fff85e1d83454a05a8625fb22fe0def,Tested samples against Trystack; added more samples,MERGED,2014-12-22 22:00:09.000000000,2015-01-13 14:13:30.000000000,2015-01-13 14:13:30.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-12-22 22:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/262f635e4fe46dddd74a804642a051af053278fc', 'message': 'Tested samples against Trystack; added more samples\n\nChange-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def\nCloses-bug: 1392948\n'}, {'number': 2, 'created': '2014-12-22 22:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/f9776d87cd2328dabef5c585027d9ad6928136eb', 'message': 'Tested samples against Trystack; added more samples\n\nChange-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def\nCloses-bug: 1392948\n'}, {'number': 3, 'created': '2015-01-08 20:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/3a980d36eb3e3a3ae587309e102816df057b065c', 'message': 'Tested samples against Trystack; added more samples\n\nChange-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def\nCloses-bug: 1392948\n'}, {'number': 4, 'created': '2015-01-09 14:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/2a12b838829407e823277330803dc1a2101dc2ce', 'message': 'Tested samples against Trystack; added more samples\n\nChange-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def\nCloses-bug: 1392948\n'}, {'number': 5, 'created': '2015-01-09 14:45:17.000000000', 'files': ['api-quick-start/src/docbkx/images-post-resp.json', 'api-quick-start/src/docbkx/get_credentials_resp.json', 'api-quick-start/src/docbkx/api-quick-start-intro.xml', 'api-quick-start/src/docbkx/flavors-post-resp.json', 'api-quick-start/src/docbkx/servers-post-resp.json', 'api-quick-start/src/docbkx/server-post-resp.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/59d09166162721afa8f49f83305812be7cbbcd2a', 'message': 'Tested samples against Trystack; added more samples\n\nChange-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def\nCloses-bug: 1392948\n'}]",0,143549,59d09166162721afa8f49f83305812be7cbbcd2a,21,4,5,964,,,0,"Tested samples against Trystack; added more samples

Change-Id: I5e68d03e8fff85e1d83454a05a8625fb22fe0def
Closes-bug: 1392948
",git fetch https://review.opendev.org/openstack/api-site refs/changes/49/143549/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-quick-start/src/docbkx/images-post-resp.json', 'api-quick-start/src/docbkx/get_credentials_resp.json', 'api-quick-start/src/docbkx/api-quick-start-intro.xml', 'api-quick-start/src/docbkx/flavors-post-resp.json', 'api-quick-start/src/docbkx/servers-post-resp.json', 'api-quick-start/src/docbkx/server-post-resp.json']",6,262f635e4fe46dddd74a804642a051af053278fc,bug/1392948,,"{ ""server"": { ""adminPass"": ""MVk5HPrazHcG"", ""id"": ""5bbcc3c4-1da2-4437-a48a-66f15b1b13f9"", ""links"": [ { ""href"": ""http://openstack.example.com/v2/openstack/servers/5bbcc3c4-1da2-4437-a48a-66f15b1b13f9"", ""rel"": ""self"" }, { ""href"": ""http://openstack.example.com/openstack/servers/5bbcc3c4-1da2-4437-a48a-66f15b1b13f9"", ""rel"": ""bookmark"" } ] } }",425,159
openstack%2Fapi-site~master~I3bb83ddd5fee06f0be7bb74d20a21a8aa0a8360d,openstack/api-site,master,I3bb83ddd5fee06f0be7bb74d20a21a8aa0a8360d,Add conditions and troubleshoot in Images and Image data section,MERGED,2015-01-06 10:10:53.000000000,2015-01-13 14:13:16.000000000,2015-01-13 14:13:12.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 8878}]","[{'number': 1, 'created': '2015-01-06 10:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/c3a3e411ffaa20713dc377d6381431f455cdfe1d', 'message': 'Add conditions and troubleshoot in Images and Image data section\n\nAdding preconditions, postconditions and troubleshooting\ninformation in Image and Image data section.\n\nPartial-bug: #1390523\nPartial-bug: #1390528\n\nChange-Id: I3bb83ddd5fee06f0be7bb74d20a21a8aa0a8360d\n'}, {'number': 2, 'created': '2015-01-07 08:40:50.000000000', 'files': ['api-ref/src/wadls/image-api/src/v2/os-image-v2.wadl', 'api-ref/src/docbkx/ch_images-v2.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8f56a9a01c4c9f71aa3ea7c20fcf72e7c6e4536c', 'message': 'Add conditions and troubleshoot in Images and Image data section\n\nAdding preconditions, postconditions and troubleshooting\ninformation in Image and Image data section.\n\nPartial-bug: #1390523\nPartial-bug: #1390528\n\nChange-Id: I3bb83ddd5fee06f0be7bb74d20a21a8aa0a8360d\n'}]",8,145185,8f56a9a01c4c9f71aa3ea7c20fcf72e7c6e4536c,11,4,2,8878,,,0,"Add conditions and troubleshoot in Images and Image data section

Adding preconditions, postconditions and troubleshooting
information in Image and Image data section.

Partial-bug: #1390523
Partial-bug: #1390528

Change-Id: I3bb83ddd5fee06f0be7bb74d20a21a8aa0a8360d
",git fetch https://review.opendev.org/openstack/api-site refs/changes/85/145185/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/image-api/src/v2/os-image-v2.wadl', 'api-ref/src/docbkx/ch_images-v2.xml']",2,c3a3e411ffaa20713dc377d6381431f455cdfe1d,bug/add-info-images-and-data-sections, Enable users to share images with each other.</para>," Enable users to share images with each other. Also, upload and download raw image data.</para>",121,12
openstack%2Fnova~master~I7fb5726ae9e7d3a54851b975a20e84f8da091dd9,openstack/nova,master,I7fb5726ae9e7d3a54851b975a20e84f8da091dd9,Return 500 when unexpected exception raising when live migrate v2,MERGED,2014-11-07 15:36:46.000000000,2015-01-13 14:08:08.000000000,2015-01-13 14:08:00.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-07 15:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f01b025f49555987ac2099efc26986aa967fff7c', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 2, 'created': '2014-11-08 01:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0f539968c82b256c3e59bcc00ccb622577eea73', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 3, 'created': '2014-11-08 01:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/098abb15c7c06dc01251b63d5ba380a6ab3517d0', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 4, 'created': '2014-11-08 03:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ae069f320203d79fb8bad6cc35462428fa09826', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 5, 'created': '2014-11-13 10:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bb20833ccd736f07a2778eebe6c7da867ec07b5', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 6, 'created': '2014-11-17 09:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce8c0f5b73e462e554099d6277587d6049326155', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 7, 'created': '2014-11-26 09:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c10e84d641e84270c3538bd5c5a885cbdda4fdee', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\n'}, {'number': 8, 'created': '2014-11-28 02:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09a15abd9a3c221730a772baafdcf8bf049a7ff3', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 9, 'created': '2014-11-28 06:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b40daedd0031cce3c86590fd2115417579ab94a', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 10, 'created': '2014-12-11 04:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e389a0689462e5408b31a7833dde1fead579f114', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 11, 'created': '2014-12-19 03:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cc3e3cb07f21cd48ef54b63f96ed8918519fc02', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 12, 'created': '2014-12-19 08:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0e8dd6095a798310d6c517cf0c9224554387959', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 13, 'created': '2014-12-19 09:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5be5ef0453c726b94acd01aa42480692c8a8677', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}, {'number': 14, 'created': '2015-01-07 05:45:23.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_admin_actions.py', 'nova/api/openstack/compute/contrib/admin_actions.py', 'nova/tests/unit/api/openstack/compute/contrib/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e96758514e990cea0366a106aadf22851df7d2f0', 'message': 'Return 500 when unexpected exception raising when live migrate v2\n\nWhen unexpected exception raising when living migration in v2 API,\nnova return wrong status code 400, it should 500.\n\nChange-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9\nCloses-Bug: 1397153\n'}]",2,133269,e96758514e990cea0366a106aadf22851df7d2f0,112,14,14,5754,,,0,"Return 500 when unexpected exception raising when live migrate v2

When unexpected exception raising when living migration in v2 API,
nova return wrong status code 400, it should 500.

Change-Id: I7fb5726ae9e7d3a54851b975a20e84f8da091dd9
Closes-Bug: 1397153
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/133269/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/contrib/admin_actions.py'],1,f01b025f49555987ac2099efc26986aa967fff7c,bug/1397153, raise exc.HTTPInternalServerError(explanation=msg), raise exc.HTTPBadRequest(explanation=msg),1,1
openstack%2Fzaqar~master~I611d3b62d5d9866b65061542cedcb1f4e3e61629,openstack/zaqar,master,I611d3b62d5d9866b65061542cedcb1f4e3e61629,Fork v1_1 of the API into v2,MERGED,2015-01-08 10:35:13.000000000,2015-01-13 13:59:16.000000000,2015-01-13 13:59:15.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2015-01-08 10:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/06381df16b9ab7b5ac179069d583b52b0709bd3c', 'message': ""Fork v1_1 of the API into v2\n\nThis patch forks the existing v1_1 of the API and opens the\nimplementation for v2. Unfortunately, this is done by copying and\npasting the existing v1_1. Hopefully, we'll have a nicer way to do this\nin the future.\n\nChange-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629\n""}, {'number': 2, 'created': '2015-01-08 12:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/09f1655c82d1b45b4a18a69b63cf3ee632f2098c', 'message': ""Fork v1_1 of the API into v2\n\nThis patch forks the existing v1_1 of the API and opens the\nimplementation for v2. Unfortunately, this is done by copying and\npasting the existing v1_1. Hopefully, we'll have a nicer way to do this\nin the future.\n\nChange-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629\n""}, {'number': 3, 'created': '2015-01-09 10:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/775e4ca7a2b8540f702e29b9b3ceac0ff79eb748', 'message': ""Fork v1_1 of the API into v2\n\nThis patch forks the existing v1_1 of the API and opens the\nimplementation for v2. Unfortunately, this is done by copying and\npasting the existing v1_1. Hopefully, we'll have a nicer way to do this\nin the future.\n\nChange-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629\n""}, {'number': 4, 'created': '2015-01-12 12:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/902577d5f306e09a51b77ea1ee5c5e10c5c15529', 'message': ""Fork v1_1 of the API into v2\n\nThis patch forks the existing v1_1 of the API and opens the\nimplementation for v2. Unfortunately, this is done by copying and\npasting the existing v1_1. Hopefully, we'll have a nicer way to do this\nin the future.\n\nChange-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629\n""}, {'number': 5, 'created': '2015-01-13 09:18:24.000000000', 'files': ['zaqar/tests/unit/transport/wsgi/v2_0/test_media_type.py', 'tests/functional/wsgi/test_version.py', 'zaqar/tests/unit/transport/wsgi/v2_0/__init__.py', 'zaqar/transport/wsgi/v2_0/__init__.py', 'zaqar/transport/wsgi/v2_0/stats.py', 'zaqar/transport/wsgi/v2_0/health.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_health.py', 'zaqar/transport/wsgi/v2_0/messages.py', 'zaqar/transport/wsgi/version.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_pools.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_validation.py', 'zaqar/transport/wsgi/v1_1/__init__.py', 'zaqar/transport/wsgi/v2_0/pools.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_flavors.py', 'zaqar/transport/wsgi/v2_0/flavors.py', 'zaqar/common/transport/wsgi/helpers.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_home.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_queue_lifecycle.py', 'zaqar/transport/wsgi/v2_0/homedoc.py', 'tests/unit/transport/wsgi/test_v2_0.py', 'zaqar/transport/wsgi/driver.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/transport/wsgi/v2_0/ping.py', 'zaqar/transport/wsgi/v2_0/claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6222cc66545088d1f22230652e2897c957e0d483', 'message': ""Fork v1_1 of the API into v2\n\nThis patch forks the existing v1_1 of the API and opens the\nimplementation for v2. Unfortunately, this is done by copying and\npasting the existing v1_1. Hopefully, we'll have a nicer way to do this\nin the future.\n\nChange-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629\n""}]",0,145739,6222cc66545088d1f22230652e2897c957e0d483,16,3,5,6159,,,0,"Fork v1_1 of the API into v2

This patch forks the existing v1_1 of the API and opens the
implementation for v2. Unfortunately, this is done by copying and
pasting the existing v1_1. Hopefully, we'll have a nicer way to do this
in the future.

Change-Id: I611d3b62d5d9866b65061542cedcb1f4e3e61629
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/39/145739/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/functional/wsgi/test_version.py', 'zaqar/transport/wsgi/v2/messages.py', 'zaqar/transport/wsgi/version.py', 'zaqar/transport/wsgi/v2/stats.py', 'zaqar/transport/wsgi/v2/__init__.py', 'zaqar/tests/unit/transport/wsgi/v2/__init__.py', 'zaqar/transport/wsgi/v1_1/__init__.py', 'zaqar/transport/wsgi/v2/ping.py', 'zaqar/transport/wsgi/v2/claims.py', 'zaqar/transport/wsgi/v2/homedoc.py', 'zaqar/tests/unit/transport/wsgi/v2/test_validation.py', 'zaqar/tests/unit/transport/wsgi/v2/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v2/test_queue_lifecycle.py', 'zaqar/transport/wsgi/v2/queues.py', 'zaqar/tests/unit/transport/wsgi/v2/test_home.py', 'zaqar/tests/unit/transport/wsgi/v2/test_claims.py', 'zaqar/tests/unit/transport/wsgi/v2/test_health.py', 'zaqar/transport/wsgi/v2/health.py', 'zaqar/transport/wsgi/v2/pools.py', 'zaqar/tests/unit/transport/wsgi/v2/test_pools.py', 'zaqar/transport/wsgi/driver.py', 'zaqar/tests/unit/transport/wsgi/v2/test_media_type.py', 'zaqar/transport/wsgi/v2/flavors.py', 'tests/unit/transport/wsgi/test_v2.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v2/test_auth.py', 'zaqar/tests/unit/transport/wsgi/v2/test_default_limits.py', 'zaqar/tests/unit/transport/wsgi/v2/test_flavors.py']",28,06381df16b9ab7b5ac179069d583b52b0709bd3c,v2,"# Copyright (c) 2014 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may not # use this file except in compliance with the License. You may obtain a copy # of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations under # the License. import contextlib import uuid import ddt import falcon from oslo.serialization import jsonutils from zaqar import tests as testing from zaqar.tests.unit.transport.wsgi import base @contextlib.contextmanager def flavor(test, name, pool, capabilities={}): """"""A context manager for constructing a flavor for use in testing. Deletes the flavor after exiting the context. :param test: Must expose simulate_* methods :param name: Name for this flavor :type name: six.text_type :type pool: six.text_type :type capabilities: dict :returns: (name, uri, capabilities) :rtype: see above """""" doc = {'pool': pool, 'capabilities': capabilities} path = test.url_prefix + '/flavors/' + name test.simulate_put(path, body=jsonutils.dumps(doc)) try: yield name, pool, capabilities finally: test.simulate_delete(path) @contextlib.contextmanager def flavors(test, count, pool): """"""A context manager for constructing flavors for use in testing. Deletes the flavors after exiting the context. :param test: Must expose simulate_* methods :param count: Number of pools to create :type count: int :returns: (paths, pool, capabilities) :rtype: ([six.text_type], [six.text_type], [dict]) """""" base = test.url_prefix + '/flavors/' args = sorted([(base + str(i), {str(i): i}, str(i)) for i in range(count)], key=lambda tup: tup[2]) for path, capabilities, _ in args: doc = {'pool': pool, 'capabilities': capabilities} test.simulate_put(path, body=jsonutils.dumps(doc)) try: yield args finally: for path, _, _ in args: test.simulate_delete(path) @ddt.ddt class FlavorsBaseTest(base.V2Base): def setUp(self): super(FlavorsBaseTest, self).setUp() self.queue = 'test-queue' self.queue_path = self.url_prefix + '/queues/' + self.queue self.pool = 'mypool' self.pool_group = 'mypool-group' self.pool_path = self.url_prefix + '/pools/' + self.pool self.pool_doc = {'weight': 100, 'group': self.pool_group, 'uri': 'sqlite://:memory:'} self.simulate_put(self.pool_path, body=jsonutils.dumps(self.pool_doc)) self.flavor = 'test-flavor' self.doc = {'capabilities': {}, 'pool': self.pool_group} self.flavor_path = self.url_prefix + '/flavors/' + self.flavor self.simulate_put(self.flavor_path, body=jsonutils.dumps(self.doc)) self.assertEqual(self.srmock.status, falcon.HTTP_201) def tearDown(self): super(FlavorsBaseTest, self).tearDown() self.simulate_delete(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_204) self.simulate_delete(self.queue_path) def test_put_flavor_works(self): name = str(uuid.uuid1()) with flavor(self, name, self.doc['pool']): self.assertEqual(self.srmock.status, falcon.HTTP_201) def test_put_raises_if_missing_fields(self): path = self.url_prefix + '/flavors/' + str(uuid.uuid1()) self.simulate_put(path, body=jsonutils.dumps({})) self.assertEqual(self.srmock.status, falcon.HTTP_400) self.simulate_put(path, body=jsonutils.dumps({'capabilities': {}})) self.assertEqual(self.srmock.status, falcon.HTTP_400) @ddt.data(1, 2**32+1, []) def test_put_raises_if_invalid_pool(self, pool): path = self.url_prefix + '/flavors/' + str(uuid.uuid1()) self.simulate_put(path, body=jsonutils.dumps({'pool': pool})) self.assertEqual(self.srmock.status, falcon.HTTP_400) @ddt.data(-1, 'wee', []) def test_put_raises_if_invalid_capabilities(self, capabilities): path = self.url_prefix + '/flavors/' + str(uuid.uuid1()) doc = {'pool': 'a', 'capabilities': capabilities} self.simulate_put(path, body=jsonutils.dumps(doc)) self.assertEqual(self.srmock.status, falcon.HTTP_400) def test_put_existing_overwrites(self): # NOTE(cabrera): setUp creates default flavor expect = self.doc self.simulate_put(self.flavor_path, body=jsonutils.dumps(expect)) self.assertEqual(self.srmock.status, falcon.HTTP_201) result = self.simulate_get(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_200) doc = jsonutils.loads(result[0]) self.assertEqual(doc['pool'], expect['pool']) def test_create_flavor_no_pool(self): self.simulate_delete(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_204) self.simulate_delete(self.pool_path) self.assertEqual(self.srmock.status, falcon.HTTP_204) self.simulate_put(self.flavor_path, body=jsonutils.dumps(self.doc)) self.assertEqual(self.srmock.status, falcon.HTTP_400) def test_delete_works(self): self.simulate_delete(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_204) self.simulate_get(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_404) def test_get_nonexisting_raises_404(self): self.simulate_get(self.url_prefix + '/flavors/nonexisting') self.assertEqual(self.srmock.status, falcon.HTTP_404) def _flavor_expect(self, flavor, xhref, xpool): self.assertIn('href', flavor) self.assertEqual(flavor['href'], xhref) self.assertIn('pool', flavor) self.assertEqual(flavor['pool'], xpool) def test_get_works(self): result = self.simulate_get(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_200) pool = jsonutils.loads(result[0]) self._flavor_expect(pool, self.flavor_path, self.doc['pool']) def test_detailed_get_works(self): result = self.simulate_get(self.flavor_path, query_string='?detailed=True') self.assertEqual(self.srmock.status, falcon.HTTP_200) pool = jsonutils.loads(result[0]) self._flavor_expect(pool, self.flavor_path, self.doc['pool']) self.assertIn('capabilities', pool) self.assertEqual(pool['capabilities'], {}) def test_patch_raises_if_missing_fields(self): self.simulate_patch(self.flavor_path, body=jsonutils.dumps({'location': 1})) self.assertEqual(self.srmock.status, falcon.HTTP_400) def _patch_test(self, doc): self.simulate_patch(self.flavor_path, body=jsonutils.dumps(doc)) self.assertEqual(self.srmock.status, falcon.HTTP_200) result = self.simulate_get(self.flavor_path, query_string='?detailed=True') self.assertEqual(self.srmock.status, falcon.HTTP_200) pool = jsonutils.loads(result[0]) self._flavor_expect(pool, self.flavor_path, doc['pool']) self.assertEqual(pool['capabilities'], doc['capabilities']) def test_patch_works(self): doc = {'pool': 'my-pool', 'capabilities': {'a': 1}} self._patch_test(doc) def test_patch_works_with_extra_fields(self): doc = {'pool': 'my-pool', 'capabilities': {'a': 1}, 'location': 100, 'partition': 'taco'} self._patch_test(doc) @ddt.data(-1, 2**32+1, []) def test_patch_raises_400_on_invalid_pool(self, pool): self.simulate_patch(self.flavor_path, body=jsonutils.dumps({'pool': pool})) self.assertEqual(self.srmock.status, falcon.HTTP_400) @ddt.data(-1, 'wee', []) def test_patch_raises_400_on_invalid_capabilities(self, capabilities): doc = {'capabilities': capabilities} self.simulate_patch(self.flavor_path, body=jsonutils.dumps(doc)) self.assertEqual(self.srmock.status, falcon.HTTP_400) def test_patch_raises_404_if_flavor_not_found(self): self.simulate_patch(self.url_prefix + '/flavors/notexists', body=jsonutils.dumps({'pool': 'test'})) self.assertEqual(self.srmock.status, falcon.HTTP_404) def test_empty_listing(self): self.simulate_delete(self.flavor_path) result = self.simulate_get(self.url_prefix + '/flavors') results = jsonutils.loads(result[0]) self.assertEqual(self.srmock.status, falcon.HTTP_200) self.assertTrue(len(results['flavors']) == 0) self.assertIn('links', results) def _listing_test(self, count=10, limit=10, marker=None, detailed=False): # NOTE(cpp-cabrera): delete initial flavor - it will interfere # with listing tests self.simulate_delete(self.flavor_path) query = '?limit={0}&detailed={1}'.format(limit, detailed) if marker: query += '&marker={2}'.format(marker) with flavors(self, count, self.doc['pool']) as expected: result = self.simulate_get(self.url_prefix + '/flavors', query_string=query) self.assertEqual(self.srmock.status, falcon.HTTP_200) results = jsonutils.loads(result[0]) self.assertIsInstance(results, dict) self.assertIn('flavors', results) self.assertIn('links', results) flavors_list = results['flavors'] link = results['links'][0] self.assertEqual('next', link['rel']) href = falcon.uri.parse_query_string(link['href']) self.assertIn('marker', href) self.assertEqual(href['limit'], str(limit)) self.assertEqual(href['detailed'], str(detailed).lower()) next_query_string = ('?marker={marker}&limit={limit}' '&detailed={detailed}').format(**href) next_result = self.simulate_get(link['href'].split('?')[0], query_string=next_query_string) next_flavors = jsonutils.loads(next_result[0]) next_flavors_list = next_flavors['flavors'] self.assertEqual(self.srmock.status, falcon.HTTP_200) self.assertIn('links', next_flavors) if limit < count: self.assertEqual(len(next_flavors_list), min(limit, count-limit)) else: self.assertTrue(len(next_flavors_list) == 0) self.assertEqual(len(flavors_list), min(limit, count)) for i, s in enumerate(flavors_list + next_flavors_list): expect = expected[i] path, capabilities = expect[:2] self._flavor_expect(s, path, self.doc['pool']) if detailed: self.assertIn('capabilities', s) self.assertEqual(s['capabilities'], capabilities) else: self.assertNotIn('capabilities', s) def test_listing_works(self): self._listing_test() def test_detailed_listing_works(self): self._listing_test(detailed=True) @ddt.data(1, 5, 10, 15) def test_listing_works_with_limit(self, limit): self._listing_test(count=15, limit=limit) def test_listing_marker_is_respected(self): self.simulate_delete(self.flavor_path) with flavors(self, 10, self.doc['pool']) as expected: result = self.simulate_get(self.url_prefix + '/flavors', query_string='?marker=3') self.assertEqual(self.srmock.status, falcon.HTTP_200) flavor_list = jsonutils.loads(result[0])['flavors'] self.assertEqual(len(flavor_list), 6) path, capabilities = expected[4][:2] self._flavor_expect(flavor_list[0], path, self.doc['pool']) def test_queue_create_works(self): metadata = {'_flavor': self.flavor} self.simulate_put(self.queue_path, body=jsonutils.dumps(metadata)) self.assertEqual(self.srmock.status, falcon.HTTP_201) def test_queue_create_no_flavor(self): metadata = {'_flavor': self.flavor} self.simulate_delete(self.flavor_path) self.assertEqual(self.srmock.status, falcon.HTTP_204) self.simulate_put(self.queue_path, body=jsonutils.dumps(metadata)) self.assertEqual(self.srmock.status, falcon.HTTP_400) class TestFlavorsMongoDB(FlavorsBaseTest): config_file = 'wsgi_mongodb_pooled.conf' @testing.requires_mongodb def setUp(self): super(TestFlavorsMongoDB, self).setUp() ",,4489,4
openstack%2Fswift~master~I4137388a97925814748ecc36b3ab5f1ac3309659,openstack/swift,master,I4137388a97925814748ecc36b3ab5f1ac3309659,Fix large out of sync out of date containers,MERGED,2014-12-11 11:23:39.000000000,2015-01-13 13:58:40.000000000,2015-01-13 13:58:39.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-11 11:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/05e13b84388724babd004a1b0c87aec1ce0a003c', 'message': ""Fix large out of sync out of date containers\n\nAs I understand it db replication starts with a preflight sync request\nto the remote container server who's response will include the last\nsynced row_id that it has on file for the sending nodes database id.\n\nIf the difference in the last sync point returned is more than 50% of\nthe local sending db's rows, it'll fall back to sending the whole db\nover rsync and let the remote end merge items locally - but generally\nthere's just a few rows missing and they're shipped over the wire as\njson and stuffed into some rather normal looking merge_items calls.\n\nThe one thing that's a bit different with these remote merge_items calls\n(compared to your average run of the mill eat a bunch of entries out of\na .pending file) is the is source kwarg.  When this optional kwarg comes\ninto merge_items it's the remote sending db's uuid, and after we eat all\nthe rows it sent us we update our local incoming_sync table for that\nuuid so that next time when it makes it's pre-flight sync request we can\ntell it where it left off.\n\nNow normally the sending db is going to push out it's rows up from the\nreturned sync_point in 1000 item diffs, up to 10 batches total (per_diff\nand max_diffs options) - 10K rows.  If that goes well then everything is\nin sync up to at least the point it started, and the sending db will\n*also* ship over *it's* incoming_sync rows to merge_syncs on the remote\nend.  Since the sending db is in sync with these other db's up to those\npoints so is the remote db now by way of the transitive property.  Also\nnote through some weird artifact that I'm not entirely convinced isn't\nan unrelated and possibly benign bug the incoming_sync table on the\nsending db will often also happen to include it's own uuid - maybe it\ngot pushed back to it from another node?\n\nAnyway, that seemed to work well enough until a sending db got diff\ncapped (i.e. sent it's 10K rows and wasn't finished), when this happened\nthe final merge_syncs call never gets sent because the remote end is\ndefinitely *not* up to date with the other databases that the sending db\nis - it's not even up-to-date with the sending db yet!  But the hope is\ncertainly that on the next pass it'll be able to finish sending the\nremaining items.  But since the remote end is who decides what the last\nsuccessfully synced row with this local sending db was - it's super\nimportant that the incoming_sync table is getting updated in merge_items\nwhen that source kwarg is there.\n\nI observed this simple and straight forward process wasn't working well\nin one case - which is weird considering it didn't have much in the way\nof tests.  After I had the test and started looking into it seemed maybe\nthe source kwarg handling got over-indented a bit in the bulk insert\nmerge_items refactor.  I think this is correct - maybe we could send\nsomeone up to the mountain temple to seek out gholt?\n\nChange-Id: I4137388a97925814748ecc36b3ab5f1ac3309659\n""}, {'number': 2, 'created': '2015-01-08 01:23:41.000000000', 'files': ['test/unit/container/test_replicator.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/404ac092d19ef80a5f4d96e9cd36a5bd69499a1f', 'message': ""Fix large out of sync out of date containers\n\nAs I understand it db replication starts with a preflight sync request\nto the remote container server who's response will include the last\nsynced row_id that it has on file for the sending nodes database id.\n\nIf the difference in the last sync point returned is more than 50% of\nthe local sending db's rows, it'll fall back to sending the whole db\nover rsync and let the remote end merge items locally - but generally\nthere's just a few rows missing and they're shipped over the wire as\njson and stuffed into some rather normal looking merge_items calls.\n\nThe one thing that's a bit different with these remote merge_items calls\n(compared to your average run of the mill eat a bunch of entries out of\na .pending file) is the is source kwarg.  When this optional kwarg comes\ninto merge_items it's the remote sending db's uuid, and after we eat all\nthe rows it sent us we update our local incoming_sync table for that\nuuid so that next time when it makes it's pre-flight sync request we can\ntell it where it left off.\n\nNow normally the sending db is going to push out it's rows up from the\nreturned sync_point in 1000 item diffs, up to 10 batches total (per_diff\nand max_diffs options) - 10K rows.  If that goes well then everything is\nin sync up to at least the point it started, and the sending db will\n*also* ship over *it's* incoming_sync rows to merge_syncs on the remote\nend.  Since the sending db is in sync with these other db's up to those\npoints so is the remote db now by way of the transitive property.  Also\nnote through some weird artifact that I'm not entirely convinced isn't\nan unrelated and possibly benign bug the incoming_sync table on the\nsending db will often also happen to include it's own uuid - maybe it\ngot pushed back to it from another node?\n\nAnyway, that seemed to work well enough until a sending db got diff\ncapped (i.e. sent it's 10K rows and wasn't finished), when this happened\nthe final merge_syncs call never gets sent because the remote end is\ndefinitely *not* up to date with the other databases that the sending db\nis - it's not even up-to-date with the sending db yet!  But the hope is\ncertainly that on the next pass it'll be able to finish sending the\nremaining items.  But since the remote end is who decides what the last\nsuccessfully synced row with this local sending db was - it's super\nimportant that the incoming_sync table is getting updated in merge_items\nwhen that source kwarg is there.\n\nI observed this simple and straight forward process wasn't working well\nin one case - which is weird considering it didn't have much in the way\nof tests.  After I had the test and started looking into it seemed maybe\nthe source kwarg handling got over-indented a bit in the bulk insert\nmerge_items refactor.  I think this is correct - maybe we could send\nsomeone up to the mountain temple to seek out gholt?\n\nChange-Id: I4137388a97925814748ecc36b3ab5f1ac3309659\n""}]",1,141019,404ac092d19ef80a5f4d96e9cd36a5bd69499a1f,15,6,2,1179,,,0,"Fix large out of sync out of date containers

As I understand it db replication starts with a preflight sync request
to the remote container server who's response will include the last
synced row_id that it has on file for the sending nodes database id.

If the difference in the last sync point returned is more than 50% of
the local sending db's rows, it'll fall back to sending the whole db
over rsync and let the remote end merge items locally - but generally
there's just a few rows missing and they're shipped over the wire as
json and stuffed into some rather normal looking merge_items calls.

The one thing that's a bit different with these remote merge_items calls
(compared to your average run of the mill eat a bunch of entries out of
a .pending file) is the is source kwarg.  When this optional kwarg comes
into merge_items it's the remote sending db's uuid, and after we eat all
the rows it sent us we update our local incoming_sync table for that
uuid so that next time when it makes it's pre-flight sync request we can
tell it where it left off.

Now normally the sending db is going to push out it's rows up from the
returned sync_point in 1000 item diffs, up to 10 batches total (per_diff
and max_diffs options) - 10K rows.  If that goes well then everything is
in sync up to at least the point it started, and the sending db will
*also* ship over *it's* incoming_sync rows to merge_syncs on the remote
end.  Since the sending db is in sync with these other db's up to those
points so is the remote db now by way of the transitive property.  Also
note through some weird artifact that I'm not entirely convinced isn't
an unrelated and possibly benign bug the incoming_sync table on the
sending db will often also happen to include it's own uuid - maybe it
got pushed back to it from another node?

Anyway, that seemed to work well enough until a sending db got diff
capped (i.e. sent it's 10K rows and wasn't finished), when this happened
the final merge_syncs call never gets sent because the remote end is
definitely *not* up to date with the other databases that the sending db
is - it's not even up-to-date with the sending db yet!  But the hope is
certainly that on the next pass it'll be able to finish sending the
remaining items.  But since the remote end is who decides what the last
successfully synced row with this local sending db was - it's super
important that the incoming_sync table is getting updated in merge_items
when that source kwarg is there.

I observed this simple and straight forward process wasn't working well
in one case - which is weird considering it didn't have much in the way
of tests.  After I had the test and started looking into it seemed maybe
the source kwarg handling got over-indented a bit in the bulk insert
merge_items refactor.  I think this is correct - maybe we could send
someone up to the mountain temple to seek out gholt?

Change-Id: I4137388a97925814748ecc36b3ab5f1ac3309659
",git fetch https://review.opendev.org/openstack/swift refs/changes/19/141019/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_replicator.py', 'test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py', 'swift/container/backend.py']",4,05e13b84388724babd004a1b0c87aec1ce0a003c,diff-capped-sync," max_rowid = -1 if source: max_rowid = max(max_rowid, rec['ROWID']) if source: curs.execute(''' UPDATE incoming_sync SET sync_point=max(?, sync_point) WHERE remote_id=? ''', (max_rowid, source)) if curs.rowcount < 1: INSERT INTO incoming_sync (sync_point, remote_id) VALUES (?, ?)"," if source: max_rowid = max(rec['ROWID'] for rec in to_add.itervalues()) UPDATE incoming_sync SET sync_point=max(?, sync_point) WHERE remote_id=? if curs.rowcount < 1: curs.execute(''' INSERT INTO incoming_sync (sync_point, remote_id) VALUES (?, ?) ''', (max_rowid, source))",64,13
openstack%2Fhorizon~master~I42437a4db34a5b1d3c49d48edcc0f1c996766a38,openstack/horizon,master,I42437a4db34a5b1d3c49d48edcc0f1c996766a38,Replace use of <center> tag in RouterRules Grid template,MERGED,2015-01-09 11:35:23.000000000,2015-01-13 13:56:38.000000000,2015-01-13 13:56:37.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6637}, {'_account_id': 6825}, {'_account_id': 9622}, {'_account_id': 12355}, {'_account_id': 12826}, {'_account_id': 13161}, {'_account_id': 13546}, {'_account_id': 14046}, {'_account_id': 14107}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-01-09 11:35:23.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/templates/routers/extensions/routerrules/grid.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c849869959806cf58e56657e852e9458ba07d34c', 'message': 'Replace use of <center> tag in RouterRules Grid template\n\nIn ""openstack_dashboard/dashboards/project/routers/templates/""..\n..routers/extensions/routerrules/grid.html"", the <center> tag is\nused. This should be stripped and the formatting should be\nhandled via CSS.\n\nChange-Id: I42437a4db34a5b1d3c49d48edcc0f1c996766a38\nCloses-Bug: #1381574\n'}]",0,146059,c849869959806cf58e56657e852e9458ba07d34c,10,15,1,13546,,,0,"Replace use of <center> tag in RouterRules Grid template

In ""openstack_dashboard/dashboards/project/routers/templates/""..
..routers/extensions/routerrules/grid.html"", the <center> tag is
used. This should be stripped and the formatting should be
handled via CSS.

Change-Id: I42437a4db34a5b1d3c49d48edcc0f1c996766a38
Closes-Bug: #1381574
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/146059/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/routers/templates/routers/extensions/routerrules/grid.html'],1,c849869959806cf58e56657e852e9458ba07d34c,bug/1381574," <div class=""center-block""><input type=""hidden"" name=""rule_to_delete"" value=""{{ dest.rule_to_delete.id }}""/></div> <div class=""center-block""> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><i class=""fa fa-random""></i></button></div> <div class=""center-block""> </div> <div class=""center-block""><a type=""button"" class=""btn btn-default btn-xs"" href=""#modal_{{ dest.subnetid|add:row.source.subnetid }}"" data-toggle=""modal""><span class=""fa fa-exclamation-circle""></span> Conflict</a></div>"," <center><input type=""hidden"" name=""rule_to_delete"" value=""{{ dest.rule_to_delete.id }}""/></center> <center> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><i class=""fa fa-random""></i></button></center> <center> </center> <center><a type=""button"" class=""btn btn-default btn-xs"" href=""#modal_{{ dest.subnetid|add:row.source.subnetid }}"" data-toggle=""modal""><span class=""fa fa-exclamation-circle""></span> Conflict</a></center>",6,6
openstack%2Fneutron~master~I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0,openstack/neutron,master,I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0,Break out config and entry point out of l3/agent file,MERGED,2015-01-09 00:31:05.000000000,2015-01-13 13:56:19.000000000,2015-01-11 10:08:11.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-09 00:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f3a455da560da396302ad5a590779b092563b69', 'message': 'Move main entry point out of agent.py\n\nPartially-Implements: bp restructure-l3-agent\nPartially-Implements: bp core-vendor-decomposition\n\nChange-Id: I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0\n'}, {'number': 2, 'created': '2015-01-09 01:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5a6adac4a2203fd39762aa3697924a57ab5273c', 'message': 'Move main entry point out of agent.py\n\nPartially-Implements: bp restructure-l3-agent\nPartially-Implements: bp core-vendor-decomposition\n\nChange-Id: I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0\n'}, {'number': 3, 'created': '2015-01-09 03:26:55.000000000', 'files': ['neutron/agent/l3/config.py', 'neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/ovs_cleanup_util.py', 'neutron/agent/l3_agent.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2062a788d6da7a0760e826b477a316257fa33bd0', 'message': ""Break out config and entry point out of l3/agent file\n\nThis is done in order to show the split between a main() and\nthe agent's inner workings. At the same time the L3 agent for\nNeutron is also being restructured and to this aim, its config\nis also moved out of the agent file.\n\nKeep main() for the time being until we get dependent\nservices updated.\n\nPartially-Implements: bp restructure-l3-agent\nPartially-Implements: bp core-vendor-decomposition\n\nChange-Id: I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0\n""}]",0,145979,2062a788d6da7a0760e826b477a316257fa33bd0,58,24,3,748,,,0,"Break out config and entry point out of l3/agent file

This is done in order to show the split between a main() and
the agent's inner workings. At the same time the L3 agent for
Neutron is also being restructured and to this aim, its config
is also moved out of the agent file.

Keep main() for the time being until we get dependent
services updated.

Partially-Implements: bp restructure-l3-agent
Partially-Implements: bp core-vendor-decomposition

Change-Id: I0d07d91ba301ee1aa51dabcf964a96edc0d6a3e0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/145979/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/agent/l3_agent.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'setup.cfg']",4,5f3a455da560da396302ad5a590779b092563b69,bp/restructure-l3-agent, neutron-l3-agent = neutron.agent.l3_agent:main, neutron-l3-agent = neutron.agent.l3.agent:main,54,32
openstack%2Fneutron~master~I8b45413cf34e5a9db8074f9029410e3b22a92640,openstack/neutron,master,I8b45413cf34e5a9db8074f9029410e3b22a92640,"hacking: enable H238 (old style class declaration, use new style)",MERGED,2015-01-12 16:28:51.000000000,2015-01-13 13:48:07.000000000,2015-01-13 13:48:06.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-12 16:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9343c7da743bc7324b12431a4acd6b6b995968d1', 'message': 'hacking: enable H238 (old style class declaration, use new style)\n\nThe rule was added in hacking 0.10 and is useful for migration to Python 3.\n\nChange-Id: I8b45413cf34e5a9db8074f9029410e3b22a92640\n'}, {'number': 2, 'created': '2015-01-12 22:46:34.000000000', 'files': ['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/plugins/vmware/common/config.py', 'neutron/plugins/vmware/common/sync.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/brocade/nos/fake_nosdriver.py', 'neutron/debug/debug_agent.py', 'neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/plumgrid/drivers/fake_plumlib.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/vmware/vshield/tasks/tasks.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/agent/linux/ovs_lib.py', 'neutron/plugins/cisco/cfg_agent/service_helpers/routing_svc_helper.py', 'neutron/plugins/ml2/drivers/brocade/nos/nosdriver.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/plugins/cisco/common/config.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/plugins/brocade/nos/nosdriver.py', 'neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/test_linux_interface.py', 'neutron/extensions/extraroute.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/ibm/sdnve_api_fake.py', 'neutron/plugins/sriovnicagent/pci_lib.py', 'neutron/tests/unit/test_api_v2.py', 'tox.ini', 'neutron/plugins/embrane/common/constants.py', 'neutron/plugins/ibm/sdnve_neutron_plugin.py', 'neutron/plugins/vmware/common/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/548ab45a50d9ea4effba2f75ff0af294da0ccb13', 'message': 'hacking: enable H238 (old style class declaration, use new style)\n\nThe rule was added in hacking 0.10 and is useful for migration to Python 3.\n\nChange-Id: I8b45413cf34e5a9db8074f9029410e3b22a92640\n'}]",0,146551,548ab45a50d9ea4effba2f75ff0af294da0ccb13,44,21,2,9656,,,0,"hacking: enable H238 (old style class declaration, use new style)

The rule was added in hacking 0.10 and is useful for migration to Python 3.

Change-Id: I8b45413cf34e5a9db8074f9029410e3b22a92640
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/146551/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/plugins/vmware/common/config.py', 'neutron/plugins/vmware/common/sync.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/brocade/nos/fake_nosdriver.py', 'neutron/debug/debug_agent.py', 'neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/plugins/plumgrid/drivers/fake_plumlib.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/plugins/vmware/vshield/tasks/tasks.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/agent/linux/ovs_lib.py', 'neutron/plugins/cisco/cfg_agent/service_helpers/routing_svc_helper.py', 'neutron/plugins/ml2/drivers/brocade/nos/nosdriver.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/plugins/cisco/common/config.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/plugins/brocade/nos/nosdriver.py', 'neutron/plugins/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/test_linux_interface.py', 'neutron/extensions/extraroute.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/ibm/sdnve_api_fake.py', 'neutron/plugins/sriovnicagent/pci_lib.py', 'neutron/tests/unit/test_api_v2.py', 'tox.ini', 'neutron/plugins/embrane/common/constants.py', 'neutron/plugins/ibm/sdnve_neutron_plugin.py', 'neutron/plugins/vmware/common/utils.py']",34,9343c7da743bc7324b12431a4acd6b6b995968d1,hacking,class NetworkTypes(object):,class NetworkTypes:,91,92
openstack%2Fnova~master~I6d990a564df6a312bd09b2a152315bbdba732082,openstack/nova,master,I6d990a564df6a312bd09b2a152315bbdba732082,Move to hacking 0.10,MERGED,2015-01-07 20:22:34.000000000,2015-01-13 13:42:11.000000000,2015-01-13 01:51:06.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-07 20:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/258c298285ed51519881a2d2397cb19724410fae', 'message': ""Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules\n* Fix minor changes (H501, W292)\n* Clarify that H306 (imports in alphabetical order shouldn't be skipped)\n* Ignore H238: check for old style class declarations\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n""}, {'number': 2, 'created': '2015-01-07 23:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6beb83dcf981f39bf42fc9a166c6e4386bb11ef', 'message': ""Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules\n* Fix minor changes (H501)\n* Clarify that H306 (imports in alphabetical order shouldn't be skipped)\n* Ignore H238: check for old style class declarations\n* Temporary skip W292, fix in next patch.\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n""}, {'number': 3, 'created': '2015-01-10 22:40:40.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/b39df562c73bb2efba018f45261644c5c4faf3b7', 'message': ""Move to hacking 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules\n* Fix minor changes (H501)\n* Clarify that H306 (imports in alphabetical order shouldn't be skipped)\n* Ignore H238: check for old style class declarations\n* Temporary skip W292, fix in next patch.\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n""}]",0,145570,b39df562c73bb2efba018f45261644c5c4faf3b7,34,9,3,1849,,,0,"Move to hacking 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

* Remove references in tox.ini to removed rules
* Fix minor changes (H501)
* Clarify that H306 (imports in alphabetical order shouldn't be skipped)
* Ignore H238: check for old style class declarations
* Temporary skip W292, fix in next patch.

Change-Id: I6d990a564df6a312bd09b2a152315bbdba732082
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/145570/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/lintstack.py', 'nova/tests/unit/virt/test_images.py', 'test-requirements.txt', 'tox.ini']",4,258c298285ed51519881a2d2397cb19724410fae,hacking,"# New from hacking 0.9: E129, E131, H407, H405# New from hacking 0.10: H238 # H306 was mistakenly ignored, TODO to re-add ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H405,H238,H306","# H803 skipped on purpose per list discussion.# New from hacking 0.9: E129, E131, H407, H405, H904# H305,H306 Skipped due to inability to handle absolute_import ignore = E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E251,H305,H306,H405,H803,H904",9,7
openstack%2Foslo.messaging~master~I6fd99a06fb35762ce4fc7bba79d0f3dd0ae9352e,openstack/oslo.messaging,master,I6fd99a06fb35762ce4fc7bba79d0f3dd0ae9352e,"Applying i18n for _executors, notify, rpc  packages",ABANDONED,2015-01-12 16:42:25.000000000,2015-01-13 13:09:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6601}, {'_account_id': 8415}]","[{'number': 1, 'created': '2015-01-12 16:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/63adcd7bca39bb9fa699d69d28fc1e5a54b4be1b', 'message': 'Applying i18n for _executors, notify, rpc  packages\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _executors, notify, rpc packages\n\nChange-Id: I6fd99a06fb35762ce4fc7bba79d0f3dd0ae9352e\nPartial-Bug: #1409724\n'}, {'number': 2, 'created': '2015-01-12 19:06:07.000000000', 'files': ['oslo/messaging/_executors/impl_blocking.py', 'oslo/messaging/rpc/dispatcher.py', 'oslo/messaging/notify/_impl_messaging.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/notify/dispatcher.py', 'oslo/messaging/notify/notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d966567657f06eb32095a5f90475211f5ebfd61c', 'message': 'Applying i18n for _executors, notify, rpc  packages\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _executors, notify, rpc packages\n\nChange-Id: I6fd99a06fb35762ce4fc7bba79d0f3dd0ae9352e\nPartial-Bug: #1409724\n'}]",4,146564,d966567657f06eb32095a5f90475211f5ebfd61c,7,3,2,8415,,,0,"Applying i18n for _executors, notify, rpc  packages

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _executors, notify, rpc packages

Change-Id: I6fd99a06fb35762ce4fc7bba79d0f3dd0ae9352e
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/64/146564/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_executors/impl_blocking.py', 'oslo/messaging/rpc/dispatcher.py', 'oslo/messaging/notify/_impl_messaging.py', 'oslo/messaging/notify/_impl_routing.py', 'oslo/messaging/notify/dispatcher.py', 'oslo/messaging/notify/notifier.py']",6,63adcd7bca39bb9fa699d69d28fc1e5a54b4be1b,bug/1409724,"from oslo.messaging._i18n import _LELOG = logging.getLogger(__name__) LOG.exception(_LE(""Problem '%(e)s' attempting to send to "" ""notification system. Payload=%(payload)s.""), dict(e=e, payload=payload))","_LOG = logging.getLogger(__name__) _LOG.exception(""Problem '%(e)s' attempting to send to "" ""notification system. Payload=%(payload)s"", dict(e=e, payload=payload))",26,19
openstack%2Foslo.messaging~master~I58dacf0dca99b8298b6d554c5455461cd91b3e17,openstack/oslo.messaging,master,I58dacf0dca99b8298b6d554c5455461cd91b3e17,Applying i18n for _drivers/matchmaker_ring.py module,ABANDONED,2015-01-12 16:42:25.000000000,2015-01-13 13:09:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:42:25.000000000', 'files': ['oslo/messaging/_drivers/matchmaker_ring.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/285dadcce7bdbcda63b62d2f5527ca38bb81f7ce', 'message': 'Applying i18n for _drivers/matchmaker_ring.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/matchmaker_ring.py module\n\nChange-Id: I58dacf0dca99b8298b6d554c5455461cd91b3e17\nPartial-Bug: #1409724\n'}]",0,146563,285dadcce7bdbcda63b62d2f5527ca38bb81f7ce,4,1,1,8415,,,0,"Applying i18n for _drivers/matchmaker_ring.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/matchmaker_ring.py module

Change-Id: I58dacf0dca99b8298b6d554c5455461cd91b3e17
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/63/146563/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/matchmaker_ring.py'],1,285dadcce7bdbcda63b62d2f5527ca38bb81f7ce,bug/1409724,"from oslo.messaging._i18n import _LW _LW(""No key defining hosts for topic '%s', "" ""see ringfile.""), key _LW(""No key defining hosts for topic '%s', "" ""see ringfile.""), nkey","from oslo.messaging._i18n import _ _(""No key defining hosts for topic '%s', "" ""see ringfile""), key _(""No key defining hosts for topic '%s', "" ""see ringfile""), nkey",5,5
openstack%2Foslo.messaging~master~Idee71b5a54335582653e4a4f9efdbb22da022e14,openstack/oslo.messaging,master,Idee71b5a54335582653e4a4f9efdbb22da022e14,Applying i18n for _drivers/matchmaker_redis.py module,ABANDONED,2015-01-12 16:42:25.000000000,2015-01-13 13:09:19.000000000,,"[{'_account_id': 3}, {'_account_id': 8415}]","[{'number': 1, 'created': '2015-01-12 16:42:25.000000000', 'files': ['oslo/messaging/_drivers/matchmaker_redis.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e393b42532445ef47595d4f4fa81b101522f5690', 'message': 'Applying i18n for _drivers/matchmaker_redis.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/matchmaker_redis.py module\n\nChange-Id: Idee71b5a54335582653e4a4f9efdbb22da022e14\nPartial-Bug: #1409724\n'}]",0,146562,e393b42532445ef47595d4f4fa81b101522f5690,6,2,1,8415,,,0,"Applying i18n for _drivers/matchmaker_redis.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/matchmaker_redis.py module

Change-Id: Idee71b5a54335582653e4a4f9efdbb22da022e14
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/62/146562/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/matchmaker_redis.py'],1,e393b42532445ef47595d4f4fa81b101522f5690,bug/1409724,"import loggingfrom oslo.messaging._i18n import _LELOG = logging.getLogger(__name__) msg = _LE(""Failed to import module redis."") LOG.error(msg) raise ImportError(msg)"," raise ImportError(""Failed to import module redis."")",6,1
openstack%2Foslo.messaging~master~I9623ab41d9efe7a1e4ee207e8be70b47f1b21148,openstack/oslo.messaging,master,I9623ab41d9efe7a1e4ee207e8be70b47f1b21148,Applying i18n for _drivers/matchmaker.py module,ABANDONED,2015-01-12 16:42:25.000000000,2015-01-13 13:08:52.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:42:25.000000000', 'files': ['oslo/messaging/_drivers/matchmaker.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3ffd8a38bde7befb48fc85b0f939ec5e238771bb', 'message': 'Applying i18n for _drivers/matchmaker.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/matchmaker.py module\n\nChange-Id: I9623ab41d9efe7a1e4ee207e8be70b47f1b21148\nPartial-Bug: #1409724\n'}]",0,146561,3ffd8a38bde7befb48fc85b0f939ec5e238771bb,4,1,1,8415,,,0,"Applying i18n for _drivers/matchmaker.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/matchmaker.py module

Change-Id: I9623ab41d9efe7a1e4ee207e8be70b47f1b21148
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/61/146561/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/matchmaker.py'],1,3ffd8a38bde7befb48fc85b0f939ec5e238771bb,bug/1409724,"from oslo.messaging import _i18n(_, _LI) = (_i18n._, _i18n._LI) LOG.info(_LI(""Matchmaker unregistered: %(key)s, %(host)s""),","from oslo.messaging._i18n import _ LOG.info(_(""Matchmaker unregistered: %(key)s, %(host)s""),",3,2
openstack%2Foslo.messaging~master~I2b021addf81731320923d86bd25ff3cc0787c909,openstack/oslo.messaging,master,I2b021addf81731320923d86bd25ff3cc0787c909,Applying i18n for _drivers/impl_zmq.py module,ABANDONED,2015-01-12 16:42:25.000000000,2015-01-13 13:08:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:42:25.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a01534e309fabd190c4bf6cc20a4df998189b175', 'message': 'Applying i18n for _drivers/impl_zmq.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/impl_zmq.py module\n\nChange-Id: I2b021addf81731320923d86bd25ff3cc0787c909\nPartial-Bug: #1409724\n'}]",0,146560,a01534e309fabd190c4bf6cc20a4df998189b175,4,1,1,8415,,,0,"Applying i18n for _drivers/impl_zmq.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/impl_zmq.py module

Change-Id: I2b021addf81731320923d86bd25ff3cc0787c909
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/60/146560/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_zmq.py'],1,a01534e309fabd190c4bf6cc20a4df998189b175,bug/1409724,"from oslo.messaging import _i18n(_, _LW, _LE, _LC, _LI) = (_i18n._, _i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) LOG.error(_LE(""JSON serialization failed."")) LOG.debug(""Connecting to %(addr)s with %(type)s. "" ""Subscribed to %(subscribe)s "" ""bind: %(bind)s"", str_data) LOG.error(_LE(""ZeroMQ socket could not be closed."")) LOG.error(_LE(""Exception during message handling."")) LOG.error(_LE(""RPC message did not include method."")) LOG.info(_LI(""Registering reactor."")) LOG.info(_LI(""In reactor registered."")) LOG.info(_LI(""Consuming socket."")) LOG.info(_LI(""Creating proxy for topic: %s.""), topic) emsg = _LW(""Topic contained dangerous "" ""characters."") LOG.error(_LE(""Topic socket file creation failed."")) LOG.error(_LE(""Local per-topic backlog buffer full for topic "" ""%s. Dropping message.""), topic) LOG.error( _LE(""Required IPC directory does "" ""not exist at %s.""), ipc_dir) LOG.error(_LE( ""Permission denied to IPC "" ""directory at %s""), ipc_dir) with excutils.save_and_reraise_exception(): LOG.error(_LE(""Could not create ZeroMQ receiver daemon. "" ""Socket may already be in use."")) LOG.error(_LE(""ZMQ Envelope version "" ""unsupported or unknown."")) LOG.info(_LI(""Skipping topic registration. "" ""Already registered."")) LOG.warn(_LW(""No matchmaker results. Not casting."")) LOG.warn(_LW('rpc_zmq_matchmaker = %(orig)s ' 'is deprecated; use ' '%(new)s instead') % dict( LOG.warning(_LW(""Requeue not supported.""))","from oslo.messaging._i18n import _, _LE LOG.error(_(""JSON serialization failed."")) LOG.debug(""Connecting to %(addr)s with %(type)s"", str_data) LOG.debug(""-> Subscribed to %(subscribe)s"", str_data) LOG.debug(""-> bind: %(bind)s"", str_data) LOG.error(""ZeroMQ socket could not be closed."") LOG.error(_(""Exception during message handling"")) LOG.error(_(""RPC message did not include method."")) LOG.info(_(""Registering reactor"")) LOG.info(_(""In reactor registered"")) LOG.info(_(""Consuming socket"")) LOG.info(_(""Creating proxy for topic: %s""), topic) emsg = _(""Topic contained dangerous characters."") LOG.error(_(""Topic socket file creation failed."")) LOG.error(_(""Local per-topic backlog buffer full for topic "" ""%s. Dropping message.""), topic) LOG.error(_(""Required IPC directory does not exist at"" "" %s""), ipc_dir) LOG.error(_(""Permission denied to IPC directory at"" "" %s""), ipc_dir) with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create ZeroMQ receiver daemon. "" ""Socket may already be in use."")) LOG.error(_(""ZMQ Envelope version unsupported or unknown."")) LOG.info(_(""Skipping topic registration. Already registered."")) LOG.warn(_(""No matchmaker results. Not casting."")) LOG.warn(_('rpc_zmq_matchmaker = %(orig)s is deprecated; use' ' %(new)s instead') % dict( LOG.debug(""WARNING: requeue not supported"")",36,29
openstack%2Foslo.messaging~master~If30d8e4cc075ba4bb8da6f08e8fd7f58f5ed2064,openstack/oslo.messaging,master,If30d8e4cc075ba4bb8da6f08e8fd7f58f5ed2064,Applying i18n for _drivers/impl_rabbit.py module,ABANDONED,2015-01-12 16:06:04.000000000,2015-01-13 13:08:29.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:06:04.000000000', 'files': ['oslo/messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/33a42327009021e7d961972288caba803ffa694a', 'message': 'Applying i18n for _drivers/impl_rabbit.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/impl_rabbit.py module\n\nChange-Id: If30d8e4cc075ba4bb8da6f08e8fd7f58f5ed2064\nPartial-Bug: #1409724\n'}]",0,146538,33a42327009021e7d961972288caba803ffa694a,4,1,1,8415,,,0,"Applying i18n for _drivers/impl_rabbit.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/impl_rabbit.py module

Change-Id: If30d8e4cc075ba4bb8da6f08e8fd7f58f5ed2064
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/38/146538/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_rabbit.py'],1,33a42327009021e7d961972288caba803ffa694a,bug/1409724,"from oslo.messaging import _i18n(_, _LW, _LE, _LC, _LI) = (_i18n._, _i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) LOG.exception(_LE(""Declaring queue failed with (%s), "" ""retrying.""), e) LOG.exception(_LE(""Failed to process message. "" ""Skipping it."")) LOG.warn(_LW( ""Deprecated: fake_rabbit option is deprecated, set "" ""rpc_backend to kombu+memory or use the fake "" ""driver instead."")) LOG.info(_LI('Connecting to AMQP server on %(hostname)s:%(port)d.'), LOG.info(_LI('Connected to AMQP server on %(hostname)s:%(port)d.'), LOG.warn(_LW( ""Process forked after connection established! "" ""This can result in unpredictable behavior. "" ""See: http://docs.openstack.org/developer/"" ""oslo.messaging/transport.html ."")) LOG.error(_LE('AMQP server %(hostname)s:%(port)s closed' ' the connection. Check login credentials:' ' %(err_str)s.'), info) else: LOG.error(_LE('AMQP server on %(hostname)s:%(port)s is ' 'unreachable: %(err_str)s. Trying again in ' '%(sleep_time)d seconds.'), info) '%(hostname)s:%(port)d.'), msg = (_LE('Unable to connect to AMQP server on ' '%(hostname)s:%(port)d after %(retry)d ' 'tries: %(err_str)s.') % { 'hostname': self.connection.hostname, 'port': self.connection.port, 'err_str': exc, 'retry': retry}) LOG.error(_LE(""Failed to declare consumer for topic "" ""'%(topic)s': %(err_str)s.""), log_info) LOG.exception( _LE('Failed to consume message from queue: %s.'), exc) LOG.exception(_LE(""Failed to publish message to topic "" ""'%(topic)s': %(err_str)s.""), log_info)","from oslo.messaging._i18n import _ from oslo.messaging._i18n import _LI LOG.exception(_(""Declaring queue failed with (%s), retrying""), e) LOG.exception(_(""Failed to process message"" "" ... skipping it."")) LOG.warn(""Deprecated: fake_rabbit option is deprecated, set "" ""rpc_backend to kombu+memory or use the fake "" ""driver instead."") LOG.info(_LI('Connecting to AMQP server on %(hostname)s:%(port)d'), LOG.info(_LI('Connected to AMQP server on %(hostname)s:%(port)d'), LOG.warn(""Process forked after connection established! "" ""This can result in unpredictable behavior. "" ""See: http://docs.openstack.org/developer/"" ""oslo.messaging/transport.html"") LOG.error(_('AMQP server %(hostname)s:%(port)s closed' ' the connection. Check login credentials:' ' %(err_str)s'), info) else: LOG.error(_('AMQP server on %(hostname)s:%(port)s is ' 'unreachable: %(err_str)s. Trying again in ' '%(sleep_time)d seconds.'), info) '%(hostname)s:%(port)d'), msg = _('Unable to connect to AMQP server on ' '%(hostname)s:%(port)d after %(retry)d ' 'tries: %(err_str)s') % { 'hostname': self.connection.hostname, 'port': self.connection.port, 'err_str': exc, 'retry': retry} LOG.error(_(""Failed to declare consumer for topic '%(topic)s': "" ""%(err_str)s""), log_info) LOG.exception(_('Failed to consume message from queue: %s'), exc) LOG.exception(_(""Failed to publish message to topic "" ""'%(topic)s': %(err_str)s""), log_info)",40,34
openstack%2Foslo.messaging~master~Ieb37810e0e87e7d2fe9271c822e7f6ad7b15be94,openstack/oslo.messaging,master,Ieb37810e0e87e7d2fe9271c822e7f6ad7b15be94,Applying i18n for _drivers/impl_qpid.py module,ABANDONED,2015-01-12 16:06:04.000000000,2015-01-13 13:08:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:06:04.000000000', 'files': ['oslo/messaging/_drivers/impl_qpid.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e2efb3722775c70297bbf642b886e2009449200d', 'message': 'Applying i18n for _drivers/impl_qpid.py module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/impl_qpid.py module\n\nChange-Id: Ieb37810e0e87e7d2fe9271c822e7f6ad7b15be94\nPartial-Bug: #1409724\n'}]",0,146537,e2efb3722775c70297bbf642b886e2009449200d,4,1,1,8415,,,0,"Applying i18n for _drivers/impl_qpid.py module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/impl_qpid.py module

Change-Id: Ieb37810e0e87e7d2fe9271c822e7f6ad7b15be94
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/37/146537/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_qpid.py'],1,e2efb3722775c70297bbf642b886e2009449200d,bug/1409724,"from oslo.messaging import _i18n(_, _LW, _LE, _LC, _LI) = (_i18n._, _i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) msg = (_LE(""Invalid value for qpid_topology_version: %d"") % LOG.exception(_LC(""Failed to process message... skipping it."")) msg = _LE('Unable to connect to AMQP server on ' '%(broker)s after %(retry)d ' 'tries: %(e)s.') % msg_dict msg = _LE( ""Unable to connect to AMQP server on %(broker)s: "" ""%(e)s. Sleeping %(delay)s seconds."") % msg_dict LOG.info(_LI('Connected to AMQP server on %s.'), broker['host']) LOG.warn(_LW(""Process forked! "" ""This can result in unpredictable behavior. "" ""See: http://docs.openstack.org/developer/"" ""oslo.messaging/transport.html ."")) LOG.error(_LE(""Failed to declare consumer for topic "" ""'%(topic)s': %(err_str)s.""), log_info) LOG.exception(_LC('Failed to consume message from queue: %s.'), exc) LOG.exception( _LC(""Error processing message. Skipping it."")) LOG.exception(_LC(""Failed to publish message to topic "" ""'%(topic)s': %(err_str)s."") % log_info)","from oslo.messaging._i18n import _ msg = (_(""Invalid value for qpid_topology_version: %d"") % LOG.exception(_(""Failed to process message... skipping it."")) msg = _('Unable to connect to AMQP server on ' '%(broker)s after %(retry)d ' 'tries: %(e)s') % msg_dict msg = _(""Unable to connect to AMQP server on %(broker)s: "" ""%(e)s. Sleeping %(delay)s seconds"") % msg_dict LOG.info(_('Connected to AMQP server on %s'), broker['host']) LOG.warn(""Process forked! "" ""This can result in unpredictable behavior. "" ""See: http://docs.openstack.org/developer/"" ""oslo.messaging/transport.html"") LOG.error(_(""Failed to declare consumer for topic '%(topic)s': "" ""%(err_str)s""), log_info) LOG.exception(_('Failed to consume message from queue: %s'), exc) LOG.exception(_(""Error processing message. "" ""Skipping it."")) LOG.exception(_(""Failed to publish message to topic "" ""'%(topic)s': %(err_str)s""), log_info)",25,20
openstack%2Fneutron~master~I6d990a564df6a312bd09b2a152315bbdba732082,openstack/neutron,master,I6d990a564df6a312bd09b2a152315bbdba732082,Update hacking to 0.10,MERGED,2015-01-12 16:28:51.000000000,2015-01-13 13:08:11.000000000,2015-01-13 13:08:06.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-12 16:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18947f6ce8510eea4ee4e772642bfa4e0808399b', 'message': ""Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Remove custom @author check since it's now implemented in hacking.\n* Move N323 to N322 that is freed due to @author check removal.\n* Temporarily skip W292 (no newline at the end of file).\n* Temporarily skip H238 (old style classes).\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n""}, {'number': 2, 'created': '2015-01-12 22:46:34.000000000', 'files': ['neutron/tests/unit/test_hacking.py', 'test-requirements.txt', 'neutron/hacking/checks.py', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1de25088b4ade3d7f29d795980ab24bd8255c0de', 'message': ""Update hacking to 0.10\n\nRelease notes:\nhttp://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0\n\n* Remove references in tox.ini to removed rules.\n* Remove custom @author check since it's now implemented in hacking.\n* Move N323 to N322 that is freed due to @author check removal.\n* Temporarily skip W292 (no newline at the end of file).\n* Temporarily skip H238 (old style classes).\n\nChange-Id: I6d990a564df6a312bd09b2a152315bbdba732082\n""}]",0,146549,1de25088b4ade3d7f29d795980ab24bd8255c0de,39,19,2,9656,,,0,"Update hacking to 0.10

Release notes:
http://git.openstack.org/cgit/openstack-dev/hacking/tag/?id=0.10.0

* Remove references in tox.ini to removed rules.
* Remove custom @author check since it's now implemented in hacking.
* Move N323 to N322 that is freed due to @author check removal.
* Temporarily skip W292 (no newline at the end of file).
* Temporarily skip H238 (old style classes).

Change-Id: I6d990a564df6a312bd09b2a152315bbdba732082
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/146549/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'neutron/hacking/checks.py', 'tox.ini', 'HACKING.rst']",4,18947f6ce8510eea4ee4e772642bfa4e0808399b,hacking,- [N322] Detect common errors with assert_called_once_with,- [N322] We do not use @authors tags in source files. We have git to track authorship. - [N323] Detect common errors with assert_called_once_with,6,21
openstack%2Foslo.messaging~master~I1e74a9ed2627453be59e3f96969cec927ce48474,openstack/oslo.messaging,master,I1e74a9ed2627453be59e3f96969cec927ce48474,Applying i18n for _drivers/common module,ABANDONED,2015-01-12 16:06:04.000000000,2015-01-13 13:08:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:06:04.000000000', 'files': ['oslo/messaging/_drivers/common.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5039ba24e556683eb6d04da40fa2cad29e9733d7', 'message': 'Applying i18n for _drivers/common module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/common module\n\nChange-Id: I1e74a9ed2627453be59e3f96969cec927ce48474\nPartial-Bug: #1409724\n'}]",0,146536,5039ba24e556683eb6d04da40fa2cad29e9733d7,4,1,1,8415,,,0,"Applying i18n for _drivers/common module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/common module

Change-Id: I1e74a9ed2627453be59e3f96969cec927ce48474
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/36/146536/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/common.py'],1,5039ba24e556683eb6d04da40fa2cad29e9733d7,bug/1409724,"from oslo.messaging import _i18n(_, _LW, _LE, _LC, _LI) = (_i18n._, _i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) LOG.exception(_LE('Exception in string format operation.')) for name, value in six.iteritems(kwargs): LOG.error(_LE(""%(name)s: %(value)s"") % {""name"": name, ""value"": value}) LOG.error(_LE(""Returning exception %s to caller""),","from oslo.messaging._i18n import _ LOG.exception(_('Exception in string format operation')) for name, value in six.iteritems(kwargs): LOG.error(""%s: %s"", name, value) LOG.error(_(""Returning exception %s to caller""),",6,4
openstack%2Foslo.messaging~master~I94dbb097b5b8cdc7f356815ae8177f0656948c59,openstack/oslo.messaging,master,I94dbb097b5b8cdc7f356815ae8177f0656948c59,Applying i18n for _drivers/amqpdriver  module,ABANDONED,2015-01-12 15:20:49.000000000,2015-01-13 13:07:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 15:20:49.000000000', 'files': ['oslo/messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a07aff4ec81df153507ee53a44a948435fd41b0e', 'message': 'Applying i18n for _drivers/amqpdriver  module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for _drivers/amqpdriver  module\n\nChange-Id: I94dbb097b5b8cdc7f356815ae8177f0656948c59\nPartial-Bug: #1409724\n'}]",0,146493,a07aff4ec81df153507ee53a44a948435fd41b0e,4,1,1,8415,,,0,"Applying i18n for _drivers/amqpdriver  module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for _drivers/amqpdriver  module

Change-Id: I94dbb097b5b8cdc7f356815ae8177f0656948c59
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/93/146493/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/amqpdriver.py'],1,a07aff4ec81df153507ee53a44a948435fd41b0e,bug/1409724,"from oslo.messaging import _i18n (_, _LW, _LE, _LC, _LI) = (_i18n._, _i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) LOG.warn(_LW('Number of call queues is greater than warning ' 'threshold: %(threshold)d. ' 'There could be a leak. Increasing ' 'threshold to: %(threshold_2)d') % {""threshold"": self._wrn_threshold, ""threshold_2"": self._wrn_threshold * 2})","from oslo.messaging._i18n import _ from oslo.messaging._i18n import _LI LOG.warn('Number of call queues is greater than warning ' 'threshold: %d. There could be a leak. Increasing' ' threshold to: %d', self._wrn_threshold, self._wrn_threshold * 2)",10,6
openstack%2Foslo.messaging~master~Ib12be77f7b8ebe4051e22a292ac3cc58702fcca5,openstack/oslo.messaging,master,Ib12be77f7b8ebe4051e22a292ac3cc58702fcca5,Applying i18n for amqp/eventloop module,ABANDONED,2015-01-12 15:20:49.000000000,2015-01-13 13:07:42.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 15:20:49.000000000', 'files': ['oslo/messaging/_drivers/protocols/amqp/eventloop.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/99633fb711b0d0be544c2ed6efae506ba7635c0f', 'message': 'Applying i18n for amqp/eventloop module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for amqp/eventloop module\n\nChange-Id: Ib12be77f7b8ebe4051e22a292ac3cc58702fcca5\nPartial-Bug: #1409724\n'}]",0,146492,99633fb711b0d0be544c2ed6efae506ba7635c0f,4,1,1,8415,,,0,"Applying i18n for amqp/eventloop module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for amqp/eventloop module

Change-Id: Ib12be77f7b8ebe4051e22a292ac3cc58702fcca5
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/92/146492/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/protocols/amqp/eventloop.py'],1,99633fb711b0d0be544c2ed6efae506ba7635c0f,bug/1409724,"from oslo.messaging import _i18n (_LW, _LE, _LC, _LI) = (_i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) error = _LE(""Invalid peer address '%(key)s'."") % {""key"": key} error = _LE(""Socket connect failure '%(e)s'."") % {""e"": str(e)} LOG.warning( _LW(""Ignoring interrupt from select(): "" ""%(serror)s."") % {""serror"": str(serror)}) LOG.info(_LI(""eventloop thread exiting, container=%(c)s."") % {""c"": self._container.name})"," error = ""Invalid peer address '%s'"" % key error = ""Socket connect failure '%s'"" % str(e) LOG.warning(""ignoring interrupt from select(): %s"", str(serror)) LOG.info(""eventloop thread exiting, container=%s"", self._container.name)",10,6
openstack%2Foslo.messaging~master~I62142d96ee26a938692a9b44ed9f0a1ee1754a6a,openstack/oslo.messaging,master,I62142d96ee26a938692a9b44ed9f0a1ee1754a6a,Applying i18n for ampq/driver module,ABANDONED,2015-01-12 15:04:57.000000000,2015-01-13 13:07:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 15:04:57.000000000', 'files': ['oslo/messaging/_drivers/protocols/amqp/driver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/015d7378edfa9afb0f274a1620b0da70f18ed645', 'message': 'Applying i18n for ampq/driver module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for ampq/driver module\n\nChange-Id: I62142d96ee26a938692a9b44ed9f0a1ee1754a6a\nPartial-Bug: #1409724\n'}]",0,146485,015d7378edfa9afb0f274a1620b0da70f18ed645,4,1,1,8415,,,0,"Applying i18n for ampq/driver module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for ampq/driver module

Change-Id: I62142d96ee26a938692a9b44ed9f0a1ee1754a6a
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/85/146485/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/protocols/amqp/driver.py'],1,015d7378edfa9afb0f274a1620b0da70f18ed645,bug/1409724,"from oslo.messaging import _i18n(_LW, _LE, _LC, _LI) = (_i18n._LW, _i18n._LE, _i18n._LC, _i18n._LI) LOG.warn(_LW(""Send request to %(target)s aborted: TTL expired."") % {""target"": self._target}) LOG.warning(_LW(""Support for the 'amqp' transport is EXPERIMENTAL."")) LOG.warning(_LW(""Process forked after connection "" ""established!"")) LOG.info(_LI(""AMQP 1.0 messaging driver shutdown.""))"," LOG.warn(""Send request to %s aborted: TTL expired."", self._target) LOG.warning(""Support for the 'amqp' transport is EXPERIMENTAL."") LOG.warning(""Process forked after connection established!"") LOG.info(""AMQP 1.0 messaging driver shutdown"")",8,4
openstack%2Foslo.messaging~master~Ie7de375163b882e2e20eeab4ab9ee190327fe638,openstack/oslo.messaging,master,Ie7de375163b882e2e20eeab4ab9ee190327fe638,Applying i18n for ampq/controller module,ABANDONED,2015-01-12 15:04:11.000000000,2015-01-13 13:07:17.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 15:04:11.000000000', 'files': ['oslo/messaging/_drivers/protocols/amqp/controller.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5912c2aa5beae15bf0865a23fe49685e6454189c', 'message': 'Applying i18n for ampq/controller module\n\nReason(s):\n- among all OpenStack projects it is nice to have\n  translation using i18n lib to support different languages.\n\nChange(s):\n- applying i18n translation for ampq/controller module\n\nChange-Id: Ie7de375163b882e2e20eeab4ab9ee190327fe638\nPartial-Bug: #1409724\n'}]",0,146484,5912c2aa5beae15bf0865a23fe49685e6454189c,4,1,1,8415,,,0,"Applying i18n for ampq/controller module

Reason(s):
- among all OpenStack projects it is nice to have
  translation using i18n lib to support different languages.

Change(s):
- applying i18n translation for ampq/controller module

Change-Id: Ie7de375163b882e2e20eeab4ab9ee190327fe638
Partial-Bug: #1409724
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/84/146484/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/protocols/amqp/controller.py', 'tox.ini']",2,5912c2aa5beae15bf0865a23fe49685e6454189c,bug/1409724,"exclude = .tox,dist,doc,*.egg,build,__init__.py,.venv,.idea","exclude = .tox,dist,doc,*.egg,build,__init__.py",24,17
openstack%2Ffuel-library~master~I7e38754d0d65480a71e3caaed723a41fb8784cbf,openstack/fuel-library,master,I7e38754d0d65480a71e3caaed723a41fb8784cbf,Add retries for rabbitmqadmin file,MERGED,2015-01-13 11:30:07.000000000,2015-01-13 12:53:50.000000000,2015-01-13 12:53:50.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2015-01-13 11:30:07.000000000', 'files': ['deployment/puppet/staging/spec/defines/staging_file_spec.rb', 'deployment/puppet/staging/manifests/file.pp', 'deployment/puppet/rabbitmq/manifests/install/rabbitmqadmin.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5551b1467b2f6aeff97699ee6de71a1d8318b436', 'message': 'Add retries for rabbitmqadmin file\n\nStaging::file used by Rabbitmq::Install::Rabbitmqadmin cannot handle\nnon transient (connectivity) errors.\n\nThe solution is to add retries for the file transfer when non\ntransient connection errors exist, which is:\n\n* sync upstream rabbitmq module fix\n  for https://tickets.puppetlabs.com/browse/MODULES-1650\n* sync upstream staging module fix\n  for https://tickets.puppetlabs.com/browse/MODULES-1651\n\nCloses-bug: #1410119\n\nChange-Id: I7e38754d0d65480a71e3caaed723a41fb8784cbf\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,146825,5551b1467b2f6aeff97699ee6de71a1d8318b436,14,6,1,6926,,,0,"Add retries for rabbitmqadmin file

Staging::file used by Rabbitmq::Install::Rabbitmqadmin cannot handle
non transient (connectivity) errors.

The solution is to add retries for the file transfer when non
transient connection errors exist, which is:

* sync upstream rabbitmq module fix
  for https://tickets.puppetlabs.com/browse/MODULES-1650
* sync upstream staging module fix
  for https://tickets.puppetlabs.com/browse/MODULES-1651

Closes-bug: #1410119

Change-Id: I7e38754d0d65480a71e3caaed723a41fb8784cbf
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/25/146825/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/staging/spec/defines/staging_file_spec.rb', 'deployment/puppet/staging/manifests/file.pp', 'deployment/puppet/rabbitmq/manifests/install/rabbitmqadmin.pp']",3,5551b1467b2f6aeff97699ee6de71a1d8318b436,fix1410119," curl_option => '-k --noproxy localhost --retry 30 --retry-delay 6', timeout => '180',"," curl_option => '-k --noproxy localhost',",11,2
openstack%2Ftempest~master~I3434061fd19de741e36b13bd3c458cf49fdfe783,openstack/tempest,master,I3434061fd19de741e36b13bd3c458cf49fdfe783,Remove all CONF values from RestClient,MERGED,2014-12-24 08:09:53.000000000,2015-01-13 12:51:52.000000000,2015-01-13 12:51:51.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-24 08:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/726876374b920b12f7bb20b1eb19770c1980bb7f', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients.\nThis patch makes duplicated code related to ""dscv"", ""ca_certs"" and\n""trace_requests"". The alternative way was that adds a new class for\njust passing these values to RestClient, but that also is redundant.\nSo this patch does this way.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 2, 'created': '2014-12-25 00:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c01c8b2eadb1b74526e5621aba42e70ad600c43', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients.\nThis patch makes duplicated code related to ""dscv"", ""ca_certs"" and\n""trace_requests"". The alternative way was that adds a new class for\njust passing these values to RestClient, but that also is redundant.\nSo this patch does this way.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 3, 'created': '2014-12-25 08:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b7472f0f46f426281df06ea46a41b8583ae14b3', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients.\nThis patch makes duplicated code related to ""dscv"", ""ca_certs"" and\n""trace_requests"". The alternative way was that adds a new class for\njust passing these values to RestClient, but that also is redundant.\nSo this patch does this way.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 4, 'created': '2014-12-25 08:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fa2f75b0439d9801d8a09736441d7531ab93d810', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 5, 'created': '2014-12-25 08:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b8268ec3fa6251e1ece254eba0a27cb37b7512de', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 6, 'created': '2014-12-26 01:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e898517cb5b76cdbc2bcd5b0e641cf17ab59659', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 7, 'created': '2014-12-26 01:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a20530fabca15670915fd580f620532cfb48c359', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 8, 'created': '2014-12-26 02:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/65d97b5535aeea8ee05bbb097b9c0d53e2609b20', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 9, 'created': '2015-01-08 05:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce6bce67b4c7a2d10be4a6de1a84ea76ac4f8661', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 10, 'created': '2015-01-09 01:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b05063fb2e267e6d70e0b96e166c29e608847771', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 11, 'created': '2015-01-09 04:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c669bf760044744eb9bd36a9d3f817cd678e84b', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 12, 'created': '2015-01-09 05:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6287eb07dc9a0c253dd82e194eb2dfc326fafe00', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 13, 'created': '2015-01-12 23:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ffd6c51b7a65a918388ce0c569049e655f32e17d', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}, {'number': 14, 'created': '2015-01-13 00:42:25.000000000', 'files': ['tempest/services/orchestration/json/orchestration_client.py', 'tempest/common/rest_client.py', 'tempest/services/network/json/network_client.py', 'tempest/services/identity/v3/json/base.py', 'tempest/services/messaging/json/messaging_client.py', 'tempest/services/object_storage/base.py', 'tempest/services/volume/json/base.py', 'tempest/services/compute/json/base.py', 'tempest/common/service_client.py', 'tempest/services/telemetry/json/telemetry_client.py', 'tempest/services/data_processing/v1_1/client.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/database/json/flavors_client.py', 'tempest/services/baremetal/base.py', 'tempest/services/database/json/versions_client.py', 'tempest/services/image/v1/json/image_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e83665d9821c82655c7cb398b7db298fc780d58', 'message': 'Remove all CONF values from RestClient\n\nTo moving RestClient to tempest-lib, this patch moves all CONF values\nfrom RestClient to service clients. This patch adds TempestRestClient\nwhich passes common CONF values for Tempest own values.\n\nChange-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783\n'}]",10,143792,0e83665d9821c82655c7cb398b7db298fc780d58,61,9,14,6167,,,0,"Remove all CONF values from RestClient

To moving RestClient to tempest-lib, this patch moves all CONF values
from RestClient to service clients. This patch adds TempestRestClient
which passes common CONF values for Tempest own values.

Change-Id: I3434061fd19de741e36b13bd3c458cf49fdfe783
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/143792/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/orchestration/json/orchestration_client.py', 'tempest/common/rest_client.py', 'tempest/services/network/json/network_client.py', 'tempest/services/identity/v3/json/base.py', 'tempest/services/messaging/json/messaging_client.py', 'tempest/services/object_storage/base.py', 'tempest/services/volume/json/base.py', 'tempest/services/compute/json/base.py', 'tempest/services/telemetry/json/telemetry_client.py', 'tempest/services/data_processing/v1_1/client.py', 'tempest/services/image/v2/json/image_client.py', 'tempest/services/identity/json/identity_client.py', 'tempest/services/database/json/flavors_client.py', 'tempest/services/baremetal/base.py', 'tempest/services/database/json/versions_client.py', 'tempest/services/image/v1/json/image_client.py']",16,726876374b920b12f7bb20b1eb19770c1980bb7f,rest-client," endpoint_type=CONF.image.endpoint_type, dscv=CONF.identity.disable_ssl_certificate_validation, ca_certs=CONF.identity.ca_certificates_file, trace_requests=CONF.debug.trace_requests)", CONF.image.endpoint_type),93,41
openstack%2Fdevstack~master~Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd,openstack/devstack,master,Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd,neutron: use config files from neutron-*aas repos,MERGED,2014-12-22 10:52:11.000000000,2015-01-13 12:51:18.000000000,2015-01-13 12:51:13.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 8074}, {'_account_id': 9656}, {'_account_id': 10385}, {'_account_id': 10980}, {'_account_id': 11080}]","[{'number': 1, 'created': '2014-12-22 10:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1caae3654ad0b2a7cbac3976e75f20391c7e032c', 'message': 'neutron: use config files from neutron-*aas repos\n\nNow that we split the neutron repository and have service configuration\nfiles maintained in their own repos, start using them.\n\nThe old files are going to be cleaned up from the Neutron tree.\n\nChange-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd\n'}, {'number': 2, 'created': '2015-01-05 14:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/89965d1e9fcd5dc9f0fe3b59a201c0ab37b0c5d9', 'message': 'neutron: use config files from neutron-*aas repos\n\nNow that we split the neutron repository and have service configuration\nfiles maintained in their own repos, start using them.\n\nThe old files are going to be cleaned up from the Neutron tree.\n\nChange-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd\n'}, {'number': 3, 'created': '2015-01-09 13:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d2efd18457f460d581151d09d8c80ebde59f3725', 'message': 'neutron: use config files from neutron-*aas repos\n\nNow that we split the neutron repository and have service configuration\nfiles maintained in their own repos, start using them.\n\nThe old files are going to be cleaned up from the Neutron tree.\n\nChange-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd\n'}, {'number': 4, 'created': '2015-01-09 14:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/30f2da46c1ef98cd7110f2d0951f49cc12acee48', 'message': 'neutron: use config files from neutron-*aas repos\n\nNow that we split the neutron repository and have service configuration\nfiles maintained in their own repos, start using them.\n\nThe old files are going to be cleaned up from the Neutron tree.\n\nChange-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd\n'}, {'number': 5, 'created': '2015-01-12 09:48:34.000000000', 'files': ['lib/neutron_plugins/services/loadbalancer', 'lib/neutron', 'lib/neutron_plugins/services/vpn', 'lib/neutron_plugins/services/firewall'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5893cc7c5f14ecf645a010b930577eaaa01a3eb8', 'message': 'neutron: use config files from neutron-*aas repos\n\nNow that we split the neutron repository and have service configuration\nfiles maintained in their own repos, start using them.\n\nThe old files are going to be cleaned up from the Neutron tree.\n\nChange-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd\n'}]",5,143421,5893cc7c5f14ecf645a010b930577eaaa01a3eb8,44,11,5,9656,,,0,"neutron: use config files from neutron-*aas repos

Now that we split the neutron repository and have service configuration
files maintained in their own repos, start using them.

The old files are going to be cleaned up from the Neutron tree.

Change-Id: Iaeff0b9de88e9bcca87da1092cc888c4cc1bedfd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/21/143421/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/services/loadbalancer', 'lib/neutron', 'lib/neutron_plugins/services/firewall']",3,1caae3654ad0b2a7cbac3976e75f20391c7e032c,, cp $NEUTRON_FWAAS_DIR/etc/fwaas_driver.ini $FWAAS_DRIVER_CONF_FILENAME, cp $NEUTRON_DIR/etc/fwaas_driver.ini $FWAAS_DRIVER_CONF_FILENAME,3,3
openstack%2Fneutron~master~Ib37651f7f802debd472ab292b148c2a2496063a3,openstack/neutron,master,Ib37651f7f802debd472ab292b148c2a2496063a3,Ensure config directory created before updating leases,MERGED,2015-01-05 12:38:44.000000000,2015-01-13 12:50:58.000000000,2015-01-13 12:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 642}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 6524}, {'_account_id': 6681}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-05 12:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b369f97964c76dcca518aa0f686a8961d59b213d', 'message': ""Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp agent via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure it's creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n""}, {'number': 2, 'created': '2015-01-05 14:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86d84153016feda2de7aa1404fa56ef51e668843', 'message': 'Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp local process via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure its creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n'}, {'number': 3, 'created': '2015-01-07 10:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb8e19be2913e319c7c2b63d3c680d95fa93f71b', 'message': 'Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp local process via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure its creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n'}, {'number': 4, 'created': '2015-01-07 10:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c585ec621210d3b7a29f07556b9ff14fc01a15fa', 'message': 'Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp local process via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure its creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n'}, {'number': 5, 'created': '2015-01-10 01:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94b0679fe2335921d9ef364b3aa3e467b43eb618', 'message': 'Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp local process via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure its creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n'}, {'number': 6, 'created': '2015-01-12 11:19:24.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/midonet/test_midonet_driver.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/057e540087150d57a2e628b5f08dcdaa8b43a307', 'message': 'Ensure config directory created before updating leases\n\nUnder high load conditions dhcp-agent could try to start the\ndhcp local process via reload_allocations. But it will fail since\nthe dhcp config directory for the specific network is not\ncreated yet.\n\nWe ensure its creation with this patch.\n\nCloses-Bug: 1407618\n\nChange-Id: Ib37651f7f802debd472ab292b148c2a2496063a3\n'}]",29,144977,057e540087150d57a2e628b5f08dcdaa8b43a307,127,34,6,8788,,,0,"Ensure config directory created before updating leases

Under high load conditions dhcp-agent could try to start the
dhcp local process via reload_allocations. But it will fail since
the dhcp config directory for the specific network is not
created yet.

We ensure its creation with this patch.

Closes-Bug: 1407618

Change-Id: Ib37651f7f802debd472ab292b148c2a2496063a3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/144977/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,b369f97964c76dcca518aa0f686a8961d59b213d,bug/1407618," def test_ensure_conf_dir(self): lp._ensure_conf_dir() makedirs.assert_called_once_with( '/dhcp/aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa', mock.ANY) with mock.patch.object(lp, '_ensure_conf_dir') as ensure_conf: conf_file.return_value = '/interface' lp.interface_name = 'tap0' self.assertTrue(ensure_conf.called) conf_file.assert_called_once_with('interface') replace.assert_called_once_with(mock.ANY, 'tap0') ['_output_opts_file', 'get_conf_file_name', 'interface_name', '_ensure_conf_dir']] mock.patch.object(dm, 'device_manager'), mock.patch.object(dhcp.Dnsmasq, '_ensure_conf_dir') ) as (isdir, active, pid, interface_name, ip_map, device_manager, ensure_conf_dir): self.assertTrue(ensure_conf_dir.called)"," def test_get_conf_file_name_ensure_dir(self): tpl = '/dhcp/aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa/dev' self.assertEqual(lp.get_conf_file_name('dev', True), tpl) self.assertTrue(makedirs.called) conf_file.return_value = '/interface' lp.interface_name = 'tap0' conf_file.assert_called_once_with('interface', ensure_conf_dir=True) replace.assert_called_once_with(mock.ANY, 'tap0') ['_output_opts_file', 'get_conf_file_name', 'interface_name']] mock.patch.object(dm, 'device_manager') ) as (isdir, active, pid, interface_name, ip_map, device_manager):",34,23
openstack%2Fceilometer~master~I3b8e62a1eda69120b2f1e6110b99dddf03512e94,openstack/ceilometer,master,I3b8e62a1eda69120b2f1e6110b99dddf03512e94,Updated from global requirements,MERGED,2015-01-13 00:02:09.000000000,2015-01-13 12:50:34.000000000,2015-01-13 12:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-13 00:02:09.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be084832585a20cb4adf15e47e3e3841e8a4b734', 'message': 'Updated from global requirements\n\nChange-Id: I3b8e62a1eda69120b2f1e6110b99dddf03512e94\n'}]",0,146686,be084832585a20cb4adf15e47e3e3841e8a4b734,11,6,1,11131,,,0,"Updated from global requirements

Change-Id: I3b8e62a1eda69120b2f1e6110b99dddf03512e94
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/146686/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,be084832585a20cb4adf15e47e3e3841e8a4b734,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fheat~master~I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032,openstack/heat,master,I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032,Make the attribute tests not need a nested stack,MERGED,2015-01-05 05:54:15.000000000,2015-01-13 12:50:22.000000000,2015-01-13 12:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-01-05 05:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/053807da0fdf9ba4218ab60996b982037195c7f4', 'message': 'Make the attribute tests not need a nested stack\n\npart of blueprint decouple-nested\n\nChange-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032\n'}, {'number': 2, 'created': '2015-01-06 13:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6f00e9f352cda0f9ce4b64940d41df78ce7ddf57', 'message': 'Make the attribute tests not need a nested stack\n\npart of blueprint decouple-nested\n\nChange-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032\n'}, {'number': 3, 'created': '2015-01-07 06:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d3afa603165421d63ad4cd2ab198bb24ed26b633', 'message': 'Make the attribute tests not need a nested stack\n\npart of blueprint decouple-nested\n\nChange-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032\n'}, {'number': 4, 'created': '2015-01-08 06:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0f295393aeb177a95e9643c14b5ffec9e046da17', 'message': 'Make the attribute tests not need a nested stack\n\npart of blueprint decouple-nested\n\nChange-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032\n'}, {'number': 5, 'created': '2015-01-12 13:35:16.000000000', 'files': ['heat/tests/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d193b74eb63d43d024c9b299599189a5bb7bd09f', 'message': 'Make the attribute tests not need a nested stack\n\npart of blueprint decouple-nested\n\nChange-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032\n'}]",0,144924,d193b74eb63d43d024c9b299599189a5bb7bd09f,29,6,5,4715,,,0,"Make the attribute tests not need a nested stack

part of blueprint decouple-nested

Change-Id: I804e8f79ac47e6e88b29191ca5d91a0a6ddb3032
",git fetch https://review.opendev.org/openstack/heat refs/changes/24/144924/5 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_resource_group.py'],1,053807da0fdf9ba4218ab60996b982037195c7f4,bp/decouple-nested," resg = self._create_dummy_stack(template_attr, expect_attrs={'0': 2, '1': 2}) resg = self._create_dummy_stack(template_attr, expect_attrs={'0': 3, '1': 3}) resg = self._create_dummy_stack(template_attr, expect_attrs=expected) def _create_dummy_stack(self, template_data=template, expect_count=2, expect_attrs=None): fake_res = {} if expect_attrs is None: expect_attrs = {} for resc in range(expect_count): res = str(resc) fake_res[res] = mock.Mock() fake_res[res].FnGetRefId.return_value = 'ID-%s' % res if res in expect_attrs: fake_res[res].FnGetAtt.return_value = expect_attrs[res] else: fake_res[res].FnGetAtt.return_value = res resg.nested = mock.Mock(return_value=fake_res) names = [str(name) for name in range(expect_count)] resg._resource_names = mock.Mock(return_value=names)"," resg = self._create_dummy_stack(template_attr) resg = self._create_dummy_stack(template_attr) def test_get_attr_path(self): """""" Test attribute aggregation and that we mimic the nested resource's attributes. """""" resg = self._create_dummy_stack(template_attr) expected = ['abc', 'abc'] self.assertEqual(expected, resg.stack.output('nested_strings')) resg = self._create_dummy_stack(template_attr) def _create_dummy_stack(self, template_data=template, expect_count=2): scheduler.TaskRunner(resg.create)() self.stack = resg.nested() self.assertEqual(expect_count, len(resg.nested())) self.assertEqual((resg.CREATE, resg.COMPLETE), resg.state)",22,17
openstack%2Fheat~master~I29bb1c4c2f5124adba213568ddaff10238544c88,openstack/heat,master,I29bb1c4c2f5124adba213568ddaff10238544c88,Separate the nested resources attribute tests,MERGED,2014-12-31 10:28:32.000000000,2015-01-13 12:50:11.000000000,2015-01-13 12:50:06.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 7385}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-31 10:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/800202bf9b666fa0ce4dd065bf3c74e6ff8c3c27', 'message': 'separate the template resource attribute tests\n\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}, {'number': 2, 'created': '2015-01-05 05:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b6a6a4423a4b55a4e3d5dc329feeb0d28e0f3f5a', 'message': 'Separate the nested resources attribute tests\n\nThis is to make it clearer what they are doing.\n\nPart of blueprint decouple-nested\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}, {'number': 3, 'created': '2015-01-06 13:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eb7c0f6c0f44b047e4fc22a12005823ea42ec65a', 'message': 'Separate the nested resources attribute tests\n\nThis is to make it clearer what they are doing.\n\nPart of blueprint decouple-nested\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}, {'number': 4, 'created': '2015-01-07 06:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/427399551caf7f7090490adf722e3d62bf25cc18', 'message': 'Separate the nested resources attribute tests\n\nThis is to make it clearer what they are doing.\n\nPart of blueprint decouple-nested\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}, {'number': 5, 'created': '2015-01-08 06:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/69715f4a35e9ab6e8b7877c2c58a68bf6b1e0e27', 'message': 'Separate the nested resources attribute tests\n\nThis is to make it clearer what they are doing.\n\nPart of blueprint decouple-nested\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}, {'number': 6, 'created': '2015-01-12 13:35:16.000000000', 'files': ['heat/tests/test_resource_group.py', 'heat/tests/test_stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d6026238d1e04184ec8fbfa019c059033cb70b2a', 'message': 'Separate the nested resources attribute tests\n\nThis is to make it clearer what they are doing.\n\nPart of blueprint decouple-nested\nChange-Id: I29bb1c4c2f5124adba213568ddaff10238544c88\n'}]",2,144626,d6026238d1e04184ec8fbfa019c059033cb70b2a,28,6,6,4715,,,0,"Separate the nested resources attribute tests

This is to make it clearer what they are doing.

Part of blueprint decouple-nested
Change-Id: I29bb1c4c2f5124adba213568ddaff10238544c88
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/144626/6 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_stack_resource.py'],1,800202bf9b666fa0ce4dd065bf3c74e6ff8c3c27,bp/decouple-nested," class StackResourceAttrTest(common.HeatTestCase): def setUp(self): super(StackResourceAttrTest, self).setUp() resource._register_class('some_magic_type', MyStackResource) ws_resname = ""provider_resource"" t = templatem.Template( {'HeatTemplateFormatVersion': '2012-12-12', 'Resources': {ws_resname: ws_res_snippet}}) self.parent_stack = parser.Stack(utils.dummy_context(), 'test_stack', t, stack_id=str(uuid.uuid4()), user_creds_id='uc123', stack_user_project_id='aprojectid') resource_defns = t.resource_definitions(self.parent_stack) self.parent_resource = MyStackResource('test', resource_defns[ws_resname], self.parent_stack) ",,19,0
openstack%2Fos-cloud-config~master~Ifae32d806575fd48cc7d261deedd94efb5511d0d,openstack/os-cloud-config,master,Ifae32d806575fd48cc7d261deedd94efb5511d0d,Add support to create a Keystone domain for Heat,MERGED,2014-11-17 06:12:55.000000000,2015-01-13 12:23:46.000000000,2015-01-13 12:23:45.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7585}, {'_account_id': 9369}, {'_account_id': 9712}, {'_account_id': 13762}]","[{'number': 1, 'created': '2014-11-17 06:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/a1e5f6c03b1040ac7f96b1c858b829b97c078b29', 'message': 'Add support to create a Keystone domain for Heat\n\nHeat in Kilo will require configuration that specifies a domain\nthat is set up in Keystone in its configuration. To facilitate that\nundeprecate initialize_for_heat(), wean it off its use of the admin\ntoken, and add a CLI utility to make calling it from -incubator easy.\n\nChange-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d\n'}, {'number': 2, 'created': '2014-11-17 06:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/fb18254a97cb8e143ab94b8f2224cb3488822181', 'message': 'Add support to create a Keystone domain for Heat\n\nHeat in Kilo will require configuration that specifies a domain\nthat is set up in Keystone in its configuration. To facilitate that\nundeprecate initialize_for_heat(), wean it off its use of the admin\ntoken, and add a CLI utility to make calling it from -incubator easy.\n\nChange-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d\n'}, {'number': 3, 'created': '2014-11-19 02:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/df96780bc519907cd589d13f09a0908b4a505510', 'message': 'Add support to create a Keystone domain for Heat\n\nHeat in Kilo will require configuration that specifies a domain\nthat is set up in Keystone in its configuration. To facilitate that\nundeprecate initialize_for_heat(), wean it off its use of the admin\ntoken, and add a CLI utility to make calling it from -incubator easy.\n\nChange-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d\n'}, {'number': 4, 'created': '2014-11-21 04:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/51876dc227cbb17f71839f02f7f52dba7445d2ef', 'message': 'Add support to create a Keystone domain for Heat\n\nHeat in Kilo will require configuration that specifies a domain\nthat is set up in Keystone in its configuration. To facilitate that\nundeprecate initialize_for_heat(), wean it off its use of the admin\ntoken, and add a CLI utility to make calling it from -incubator easy.\n\nChange-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d\n'}, {'number': 5, 'created': '2014-12-10 05:09:22.000000000', 'files': ['os_cloud_config/tests/test_keystone.py', 'os_cloud_config/cmd/tests/test_init_keystone_heat_domain.py', 'os_cloud_config/keystone.py', 'os_cloud_config/cmd/init_keystone_heat_domain.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/601d7bdc161c7c32751e1e2d391683ec84d92424', 'message': 'Add support to create a Keystone domain for Heat\n\nHeat in Kilo will require configuration that specifies a domain\nthat is set up in Keystone in its configuration. To facilitate that\nundeprecate initialize_for_heat(), wean it off its use of the admin\ntoken, and add a CLI utility to make calling it from -incubator easy.\n\nChange-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d\n'}]",4,134858,601d7bdc161c7c32751e1e2d391683ec84d92424,31,7,5,9369,,,0,"Add support to create a Keystone domain for Heat

Heat in Kilo will require configuration that specifies a domain
that is set up in Keystone in its configuration. To facilitate that
undeprecate initialize_for_heat(), wean it off its use of the admin
token, and add a CLI utility to make calling it from -incubator easy.

Change-Id: Ifae32d806575fd48cc7d261deedd94efb5511d0d
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/58/134858/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_cloud_config/tests/test_keystone.py', 'os_cloud_config/cmd/tests/test_init_keystone_heat_domain.py', 'os_cloud_config/keystone.py', 'os_cloud_config/cmd/init_keystone_heat_domain.py', 'setup.cfg']",5,a1e5f6c03b1040ac7f96b1c858b829b97c078b29,add-heat-domain-support, init-keystone-heat-domain = os_cloud_config.cmd.init_keystone_heat_domain:main,,100,20
openstack%2Ffuel-main~master~I1ac0b1bee9e28129c4644fd43d3b9b8470dca697,openstack/fuel-main,master,I1ac0b1bee9e28129c4644fd43d3b9b8470dca697,Remove changes about ntp.conf in kickstart,MERGED,2014-12-18 14:33:14.000000000,2015-01-13 12:13:39.000000000,2015-01-13 12:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}]","[{'number': 1, 'created': '2014-12-18 14:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/717ebc6d704a77502cf6a7bb922f57ac26a57873', 'message': ""Remove changes about ntp.conf in kickstart\n\nWe actually cannot configure ntp.conf over kickstart today, cause\nnow we use NTP puppet module that do so and do it later than kickstart,\nthat lead to fully rewrite NTP configuration. So, that strings about\nNTP in kickstart don't have sense anymore.\n\nChange-Id: I1ac0b1bee9e28129c4644fd43d3b9b8470dca697\nRelated-Bug: 1298360\n""}, {'number': 2, 'created': '2014-12-18 14:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/63bbce8499cabc8590d6f982012d0927462c32fd', 'message': 'Remove NTP configuration in kickstart\n\nWe now configure NTP properly with the NTP puppet module.\nThe configuration being removed is no longer necessary.\n\nChange-Id: I1ac0b1bee9e28129c4644fd43d3b9b8470dca697\nRelated-Bug: 1298360\n'}, {'number': 3, 'created': '2014-12-30 10:59:37.000000000', 'files': ['iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/45a2d2ebbaa695ba1700de7c21dab4535a04cc9a', 'message': ""Remove changes about ntp.conf in kickstart\n\nWe actually cannot configure ntp.conf over kickstart today, cause\nnow we use NTP puppet module that do so and do it later than kickstart,\nthat lead to fully rewrite NTP configuration. So, that strings about\nNTP in kickstart don't have sense anymore.\n\nChange-Id: I1ac0b1bee9e28129c4644fd43d3b9b8470dca697\nRelated-Bug: 1298360\n""}]",0,142799,45a2d2ebbaa695ba1700de7c21dab4535a04cc9a,28,9,3,11827,,,0,"Remove changes about ntp.conf in kickstart

We actually cannot configure ntp.conf over kickstart today, cause
now we use NTP puppet module that do so and do it later than kickstart,
that lead to fully rewrite NTP configuration. So, that strings about
NTP in kickstart don't have sense anymore.

Change-Id: I1ac0b1bee9e28129c4644fd43d3b9b8470dca697
Related-Bug: 1298360
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/99/142799/3 && git format-patch -1 --stdout FETCH_HEAD,['iso/ks.template'],1,717ebc6d704a77502cf6a7bb922f57ac26a57873,bug/1298360,,"# Enabling/configuring NTPD and ntpdate services echo ""server 127.127.1.0"" >> /etc/ntp.conf echo ""fudge 127.127.1.0 stratum 10"" >> /etc/ntp.conf echo ""tos orphan 7"" >> /etc/ntp.conf ",0,5
openstack%2Fanchor~master~Ia722e6c9aad69f8700d8fefd7d5e04e88d3101ef,openstack/anchor,master,Ia722e6c9aad69f8700d8fefd7d5e04e88d3101ef,Adding the first tests against X509 CSRs,MERGED,2015-01-12 18:00:43.000000000,2015-01-13 12:00:19.000000000,2015-01-13 12:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 7063}, {'_account_id': 11397}]","[{'number': 1, 'created': '2015-01-12 18:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/3c1f9bb2574999bc9a38cfde7677807550fe18ce', 'message': 'Adding the first tests against X509 CSRs\n\n- Also fixing some minor X509Name issues that showed up\n\nChange-Id: Ia722e6c9aad69f8700d8fefd7d5e04e88d3101ef\n'}, {'number': 2, 'created': '2015-01-13 10:35:25.000000000', 'files': ['tests/X509/test_x509_csr.py', 'anchor/X509/name.py', 'tests/X509/__init__.py', 'anchor/app.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/c9940c47998be6cd404c77891bb211761972ff7e', 'message': 'Adding the first tests against X509 CSRs\n\n- Also fixing some minor X509Name issues that showed up\n\nChange-Id: Ia722e6c9aad69f8700d8fefd7d5e04e88d3101ef\n'}]",0,146586,c9940c47998be6cd404c77891bb211761972ff7e,10,3,2,11716,,,0,"Adding the first tests against X509 CSRs

- Also fixing some minor X509Name issues that showed up

Change-Id: Ia722e6c9aad69f8700d8fefd7d5e04e88d3101ef
",git fetch https://review.opendev.org/openstack/anchor refs/changes/86/146586/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/X509/test_x509_csr.py', 'anchor/X509/name.py', 'tests/X509/__init__.py']",3,3c1f9bb2574999bc9a38cfde7677807550fe18ce,x509-csr-tests,,,173,10
openstack%2Fironic-inspector~master~I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a,openstack/ironic-inspector,master,I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a,Add introspect client call and switch functest to it,MERGED,2015-01-12 14:48:05.000000000,2015-01-13 11:59:04.000000000,2015-01-13 11:59:03.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 8688}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-12 14:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/136346594b0a56c8832b4429381a8c71f7153dd1', 'message': 'Add introspect client call and switch functest to it\n\nChange-Id: I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a\nImplements: blueprint v1-api-reform\n'}, {'number': 2, 'created': '2015-01-12 15:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c4e1e82207c50060e8e20270b446c81848e36b41', 'message': 'Add introspect client call and switch functest to it\n\nChange-Id: I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a\nImplements: blueprint v1-api-reform\n'}, {'number': 3, 'created': '2015-01-13 11:19:42.000000000', 'files': ['ironic_discoverd/client.py', 'ironic_discoverd/test/test_client.py', 'README.rst', 'functest/run.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f39c8a29aa0b73842e4c421d581d886e0153e597', 'message': ""Add introspect client call and switch functest to it\n\nAlso make README reflect the current reality, as it wasn't updated\nin the previous (already merged) patch.\n\nChange-Id: I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a\nImplements: blueprint v1-api-reform\n""}]",7,146479,f39c8a29aa0b73842e4c421d581d886e0153e597,21,4,3,10239,,,0,"Add introspect client call and switch functest to it

Also make README reflect the current reality, as it wasn't updated
in the previous (already merged) patch.

Change-Id: I32a95a7f428f08fec564c3e3bc2b6413bd38bf3a
Implements: blueprint v1-api-reform
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/79/146479/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/client.py', 'ironic_discoverd/test/test_client.py', 'functest/run.py']",3,136346594b0a56c8832b4429381a8c71f7153dd1,bp/v1-api-reform," client.introspect(self.uuid, auth_token='token')"," client.discover([self.uuid], auth_token='token')",53,33
openstack%2Fpython-neutronclient~master~Ifa3b09b63c9d6f01e4bb5aac9d7331e1692d69b2,openstack/python-neutronclient,master,Ifa3b09b63c9d6f01e4bb5aac9d7331e1692d69b2,Allow security group rules to be specified in both directions,ABANDONED,2014-12-11 12:46:13.000000000,2015-01-13 11:57:34.000000000,,"[{'_account_id': 3}, {'_account_id': 7293}]","[{'number': 1, 'created': '2014-12-11 12:46:13.000000000', 'files': ['neutronclient/neutron/v2_0/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/deb47d54f5cab5a1e22b1f70b6d2d7454e1b236c', 'message': ""Allow security group rules to be specified in both directions\n\nCurrently it is only possible to create security group rules\nwith ingress or egress direction. This means that in case\nwhen a user needs to create identically configured ingress and\negress rules he/she has to run the create command twice.\n\nThis patch extends a list of choices for security-group-rule-create\ndirection argument with 'both'.\n\nCorresponding patch for neutron:\n    https://review.openstack.org/#/c/140676\n\nChange-Id: Ifa3b09b63c9d6f01e4bb5aac9d7331e1692d69b2\nCloses-Bug: #1325736\n""}]",0,141039,deb47d54f5cab5a1e22b1f70b6d2d7454e1b236c,4,2,1,7293,,,0,"Allow security group rules to be specified in both directions

Currently it is only possible to create security group rules
with ingress or egress direction. This means that in case
when a user needs to create identically configured ingress and
egress rules he/she has to run the create command twice.

This patch extends a list of choices for security-group-rule-create
direction argument with 'both'.

Corresponding patch for neutron:
    https://review.openstack.org/#/c/140676

Change-Id: Ifa3b09b63c9d6f01e4bb5aac9d7331e1692d69b2
Closes-Bug: #1325736
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/39/141039/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/securitygroup.py'],1,deb47d54f5cab5a1e22b1f70b6d2d7454e1b236c,bug/1325736," default='ingress', choices=['ingress', 'egress', 'both'],"," default='ingress', choices=['ingress', 'egress'],",1,1
openstack%2Fneutron~master~Icb3e720c15ac7ed8a657596c72cc3c08098f0931,openstack/neutron,master,Icb3e720c15ac7ed8a657596c72cc3c08098f0931,Allow security group rules to be specified in both directions,ABANDONED,2014-12-10 13:29:16.000000000,2015-01-13 11:57:13.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-10 13:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3208031cd2f1452c7e7b8951f76947c3032a9df', 'message': 'WIP: Allow security group rules to be specified in both directions\n\nChange-Id: Icb3e720c15ac7ed8a657596c72cc3c08098f0931\nCloses-Bug: #1325736\n'}, {'number': 2, 'created': '2014-12-11 12:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/87b777a850da6ddf5975ed2f43a28d36d3380f2b', 'message': ""Allow security group rules to be specified in both directions\n\nCurrently it is only possible to create security group rules\nwith ingress or egress direction. This means that in case\nwhen a user needs to create identically configured ingress and\negress rules he/she has to run the create command twice.\n\nThis patch adds a 'both' value to the direction argument.\nCreating a security group rule with direction='both' would\nlead to creation of two iptables rules: for egress and\ningress directions.\n\nChange-Id: Icb3e720c15ac7ed8a657596c72cc3c08098f0931\nCloses-Bug: #1325736\n""}, {'number': 3, 'created': '2014-12-11 12:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f92912c17c6cfb40fa30e2216d745c4003493f4e', 'message': ""Allow security group rules to be specified in both directions\n\nCurrently it is only possible to create security group rules\nwith ingress or egress direction. This means that in case\nwhen a user needs to create identically configured ingress and\negress rules he/she has to run the create command twice.\n\nThis patch adds a 'both' value to the direction argument.\nCreating a security group rule with direction='both' would\nlead to creation of two iptables rules: for egress and\ningress directions.\n\nChange-Id: Icb3e720c15ac7ed8a657596c72cc3c08098f0931\nCloses-Bug: #1325736\n""}, {'number': 4, 'created': '2014-12-12 14:06:04.000000000', 'files': ['neutron/tests/unit/test_extension_security_group.py', 'neutron/plugins/midonet/plugin.py', 'neutron/db/securitygroups_db.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/extensions/securitygroup.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/db/migration/alembic_migrations/versions/54b20ffd529c_security_group_rule_both_direction.py', 'neutron/tests/unit/test_iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb00b637ebfd9467fe46282213a82bdaa17b5c35', 'message': ""Allow security group rules to be specified in both directions\n\nCurrently it is only possible to create security group rules\nwith ingress or egress direction. This means that in case\nwhen a user needs to create identically configured ingress and\negress rules he/she has to run the create command twice.\n\nThis patch adds a 'both' value to the direction argument.\nCreating a security group rule with direction='both' would\nlead to creation of two iptables rules: for egress and\ningress directions.\n\nRelated patch to python-neutronclient:\n    https://review.openstack.org/#/c/141039/\n\nChange-Id: Icb3e720c15ac7ed8a657596c72cc3c08098f0931\nCloses-Bug: #1325736\n""}]",0,140676,eb00b637ebfd9467fe46282213a82bdaa17b5c35,75,24,4,7293,,,0,"Allow security group rules to be specified in both directions

Currently it is only possible to create security group rules
with ingress or egress direction. This means that in case
when a user needs to create identically configured ingress and
egress rules he/she has to run the create command twice.

This patch adds a 'both' value to the direction argument.
Creating a security group rule with direction='both' would
lead to creation of two iptables rules: for egress and
ingress directions.

Related patch to python-neutronclient:
    https://review.openstack.org/#/c/141039/

Change-Id: Icb3e720c15ac7ed8a657596c72cc3c08098f0931
Closes-Bug: #1325736
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/140676/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/extensions/securitygroup.py', 'neutron/db/migration/alembic_migrations/versions/54b20ffd529c_security_group_rule_both_direction.py', 'neutron/db/migration/alembic_migrations/versions/HEAD']",5,b3208031cd2f1452c7e7b8951f76947c3032a9df,bug/1325736,54b20ffd529c,408cfbf6923c,57,5
openstack%2Ftelemetry-specs~master~I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1,openstack/telemetry-specs,master,I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1,Adds spec for Hyper-V disk latency metrics,MERGED,2014-12-11 16:40:34.000000000,2015-01-13 11:51:18.000000000,2015-01-13 11:51:18.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7052}]","[{'number': 1, 'created': '2014-12-11 16:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d5de9991cbbfb9b1d6cbffd9445dd15da03bc704', 'message': 'Adds spec for Hyper-V disk latency metrics\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/hyper-v-disk-latency-metrics\n\nChange-Id: I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1\n'}, {'number': 2, 'created': '2014-12-11 16:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/cf1944d174ef2c5b819c58e3816ea93dd4644e2a', 'message': 'Adds spec for Hyper-V disk latency metrics\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/hyper-v-disk-latency-metrics\n\nChange-Id: I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1\n'}, {'number': 3, 'created': '2014-12-16 09:17:00.000000000', 'files': ['specs/kilo/hyper-v-disk-latency-metrics.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/95e42c4caae5abb8244eb869a931fb2409c00923', 'message': 'Adds spec for Hyper-V disk latency metrics\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/hyper-v-disk-latency-metrics\n\nChange-Id: I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1\n'}]",2,141093,95e42c4caae5abb8244eb869a931fb2409c00923,12,4,3,8213,,,0,"Adds spec for Hyper-V disk latency metrics

https://blueprints.launchpad.net/ceilometer/+spec/hyper-v-disk-latency-metrics

Change-Id: I9f4a78dd75b87e5e243e214d1c0958ff63fcc4b1
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/93/141093/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/hyper-v-disk-latency-metrics.rst'],1,d5de9991cbbfb9b1d6cbffd9445dd15da03bc704,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================= Adds disk latency metrics implementation in the Hyper-V Inspector ================================================================= https://blueprints.launchpad.net/ceilometer/+spec/hyper-v-disk-latency-metrics High latency between I/O requests can be signs of issues. Collecting disk latency metrics can help us detect those issues. Hyper-V Inspector can collect those metrics. Problem description =================== Disk latency metrics are important in telemetry and useful when determining instance's performance. This spec adds implementation to collect those stats in the Hyper-V Inspector. Proposed change =============== Add DiskLatencyPollster and PerDeviceDiskLatencyPollster pollsters, which creates samples having the properties: * name: 'disk.latency' * type: 'gauge' * unit: 'ms' Add the method 'inspect_disk_latency' in Inspector and implementing it in the HyperVInspector, fetching disk latency stats data from Hyper-V VMs, located in the Msvm_AggregationMetricValue objects (further referred to as 'metrics objects') associated with the VMs. The metrics objects 'MetricDefinitionId' must be the equal to the 'Id' of Msvm_AggregationMetricDefinition object having the Caption 'Average Disk Latency'. Hyper-V disk metrics were introduced in Windows / Hyper-V Server 2012 R2 (kernel version 6.3). They are not supported in the previous versions. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- Users will have to add meter 'disk.latency' in the disk_source source in pipeline.yaml By default, the disk usage metrics collection is enabled in Nova, we just need to collect the data from the Hyper-V API. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <cbelu> Work Items ---------- * Adds the DiskLatencyPollster and PerDeviceDiskLatencyPollster pollsters * Adds the method 'inspector_disk_latency' in Inspector. * Implements the method 'inspect_disk_latency' in HyperVInspector. * Adds related unit tests. * Updates ceilometer measurements document. Future lifecycle ================ Once this feature is enabled, it needs tests and bug fixing in the next 2 releases to avoid regression. Dependencies ============ * Windows / Hyper-V Server 2012 R2 (kernel version 6.3) * wmi 1.4.9+ Testing ======= Unit tests are needed to test the new pollsters and the implementation on the Hyper-V side. Documentation Impact ==================== The added metrics will need to be documented in the `measurements section`_. .. _measurements section: http://docs.openstack.org/developer/ceilometer/measurements.html References ========== * [1] http://msdn.microsoft.com/en-us/library/cc768535%28v=bts.10%29.aspx ",,136,0
openstack%2Ffuel-docs~stable%2F6.0~Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3,openstack/fuel-docs,stable/6.0,Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3,Adds configuration and limitations information on plugins into User guide,ABANDONED,2014-12-30 09:50:45.000000000,2015-01-13 11:44:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11163}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-30 09:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c84d5c8327dd5e7e0c360e82e8376223552e7b70', 'message': ""Adds configuration and limitations information on plugins into User guide\n\n* Prerequisites\n\n* Limitations\n\n* Minor additions (according to Evgeniya's comments)\n\nChange-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3\n""}, {'number': 2, 'created': '2014-12-30 10:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/07eb9d21a79c85a7b27e3cbf6b54809a88f3465f', 'message': ""Adds configuration and limitations information on plugins into User guide\n\n* Prerequisites\n\n* Limitations\n\n* Minor additions (according to Evgeniya's comments)\n\nChange-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3\n""}, {'number': 3, 'created': '2014-12-30 12:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/055e3d4ebb2b71276fcb30b05cb19a0af71df309', 'message': ""Adds configuration and limitations information on plugins into User guide\n\n* Prerequisites\n\n* Limitations\n\n* Minor additions (according to Evgeniya's comments)\n\nChange-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3\n""}, {'number': 4, 'created': '2014-12-30 20:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4e218c1b6de20586e7eadeac1c7d667dee888a6f', 'message': ""Adds configuration and limitations information on plugins into User guide\n\n* Prerequisites\n\n* Limitations\n\n* Minor additions (according to Evgeniya's comments)\n\nChange-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3\n""}, {'number': 5, 'created': '2014-12-31 07:10:37.000000000', 'files': ['pages/terminology/p/plug-in-term.rst', 'pages/user-guide/fuel-plugins/022-plugin-lbaas.rst', 'pages/user-guide/fuel-plugins/021-plugin-gluster.rst', 'pages/user-guide/fuel-plugins/032-plugin-netapp.rst', 'pages/user-guide/fuel-plugins/031-plugin-vpnaas.rst', 'pages/user-guide/fuel-plugins/010-install-plugin.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3787adf2403c40dc755db4ffaecaee3fd87aa938', 'message': ""Adds configuration and limitations information on plugins into User guide\n\n* Prerequisites\n\n* Limitations\n\n* Minor additions (according to Evgeniya's comments)\n\nChange-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3\n""}]",59,144429,3787adf2403c40dc755db4ffaecaee3fd87aa938,28,7,5,13082,,,0,"Adds configuration and limitations information on plugins into User guide

* Prerequisites

* Limitations

* Minor additions (according to Evgeniya's comments)

Change-Id: Ieeae7b89d2643f9b2802aa5db1e5f3afeba1dea3
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/29/144429/5 && git format-patch -1 --stdout FETCH_HEAD,"['pages/user-guide/fuel-plugins/022-plugin-lbaas.rst', 'pages/user-guide/fuel-plugins/021-plugin-gluster.rst', 'pages/user-guide/fuel-plugins/032-plugin-netapp.rst', 'pages/user-guide/fuel-plugins/031-plugin-vpnaas.rst', 'pages/user-guide/fuel-plugins/010-install-plugin.rst']",5,c84d5c8327dd5e7e0c360e82e8376223552e7b70,plugin-final-additions,"Fuel features the ability to install plug-ins before you deploy your environment. FUel plug-ins are downloadable software components that extend the functionality of your environments in a flexible, repeatable and reliable manner. For example, :ref:`Neutron LBaaS<plugin-lbaas>` plug-in for Fuel provides Load-Balancing-as-a-Service for Neutron. Fuel plug-ins fall into two categories:All Fuel plug-ins, both certified and non-certified are digitally signed and hosted by Mirantis.","Fuel features the ability to install plug-ins when you deploy your environment. Plug-ins are downloadable software components that extend the functionality of your environments in a flexible, repeatable and reliable manner. For example, :ref:`Neutron LBaaS<plugin-lbaas>` provides Load-Balancing-as-a-Service for Neutron, OpenStack Network Service. Plug-ins fall into two categories:All plug-ins, both certified and non-certified are digitally signed and hosted by Mirantis.",270,10
openstack%2Ffuel-docs~stable%2F6.0~Id11adc8587061396ff1cc47ab0877a67d461a8a3,openstack/fuel-docs,stable/6.0,Id11adc8587061396ff1cc47ab0877a67d461a8a3,Adds requirements and limitations to Fuel Plug-in Guide,ABANDONED,2014-12-30 12:13:44.000000000,2015-01-13 11:44:41.000000000,,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 11163}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-30 12:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8b64692399f3db66b2b0172cf2b73c86093d3192', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 2, 'created': '2014-12-30 13:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9054a5398ec2bd09558b8311a53e936b7248ee47', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 3, 'created': '2014-12-30 14:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/924199cb66c56f5863224e310a4fc1bf01dcd8e3', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 4, 'created': '2014-12-30 20:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/630348faf0f8ea694b4c3499e3d1d70166662e3a', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 5, 'created': '2014-12-31 07:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c5500741fa6036ab555cc8c188fed9a02c7fe063', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 6, 'created': '2015-01-03 07:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/2228a8d36a9eca4e923fb8d36184e39d1d2c40e5', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}, {'number': 7, 'created': '2015-01-12 08:42:20.000000000', 'files': ['pages/plugin-dev/020-fuel-plugin-dev.rst', 'pages/plugin-dev/0421-plugin-vpnaas.rst', 'pages/plugin-dev/040-install-plugin.rst', 'pages/plugin-dev/0412-plugin-lbaas.rst', 'pages/plugin-dev/0411-plugin-gluster.rst', 'pages/plugin-dev/0422-plugin-netapp.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c96674653a2644206a96487848b0e8141e47c2fb', 'message': 'Adds requirements and limitations to Fuel Plug-in Guide\n\nIt also fixed link to Plugin Catalog\n\nChange-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3\n'}]",98,144447,c96674653a2644206a96487848b0e8141e47c2fb,36,6,7,13082,,,0,"Adds requirements and limitations to Fuel Plug-in Guide

It also fixed link to Plugin Catalog

Change-Id: Id11adc8587061396ff1cc47ab0877a67d461a8a3
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/47/144447/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/plugin-dev/0421-plugin-vpnaas.rst', 'pages/plugin-dev/040-install-plugin.rst', 'pages/plugin-dev/0412-plugin-lbaas.rst', 'pages/plugin-dev/0411-plugin-gluster.rst', 'pages/plugin-dev/0422-plugin-netapp.rst']",5,8b64692399f3db66b2b0172cf2b73c86093d3192,plugin-dev-guide-additions-patch4,"NetApp plug-in will replace `Cinder LVM <http://docs.openstack.org/juno/config-reference/content/lvm-volume-driver.html>`_, the default volume backend that uses local volumes managed by LVM. Note that to enable NetApp plug-in for Cinder, you should check the following:**Limitations** Since only one Cinder node should be deployed, Cinder volume is **not** highly available. **NetApp appliance configuration** NetApp plug-in was tested via NetApp NFS Simulator and configured according to the step-by- *Pre setup* Using VMware ESX or VMware Player, create 2 networks called VM Network and Cluster Network. Untar the vsim and add it to your VMware ESX inventory/VMware Player inventory. .. note:: The VM will have 4 NICs. The first 2 (e0a and e0b) are connected to Cluster Network and the second 2 (e0c and e0d) are connected to the VM Network. The VM Network should be the regular VMware vSwitch that is bridged onto the lab network. The Cluster Network is a vSwitch that's connected to nothing. The purpose of the Cluster Network is the following: when you have multiple vsims you want to cluster together, they use this private network to talk to each other. The point is not in clustering vsims (this will not be done), so this network will be unused, but you should still create it. You should only take into consideration that e0a and e0b are connected to a fake network so you should not use them; use e0c and e0d exclusively. *OS setup* #. Start up the VM with the console open. #. Press Ctrl-C when the message about the boot menu appears (you only get about 10-15 seconds to do this so do not miss it). #. Select option 4 (*Clean configuration and initialize all disks*). #. Answer Yes to the next 2 questions. The VM will reboot and do some work. *Cluster setup* #. When asked if you want to join or create a cluster, select *Create*. #. Answer Yes when asked about a single node cluster. #. Enter the cluster name: *<cluster_name>-cluster*. #. Enter cluster base license key. Do not enter any more license keys. #. Enter the admin password twice. * Cluster management interface configuration** :: Port: e0c IP address: 192.168.4.10 Netmask: 255.255.255.128 Default gateway 192.168.4.1 DNS domain name: <name>.netapp.com Nameserver IP: 192.18.4.1 Location: <location_name> * Node management interface configuration* :: Port: e0c IP address: 192.168.4.12 Netmask: 255.255.255.128 Default gateway 192.168.4.1 Press enter to acknowledge the autosupport notification. * Cluster configuration* #. You can either continue through the VMware console, or switch to SSH at this point. If you SSH, connect to the cluster management interface (in our case, that is 192.168.4.10). #. Login at the prompt using <admin_name> and <password>. #. Add the unassigned disks to the node by entering the following command: :: storage disk assign -all true -node <cluster_name>-cluster-01 *Create an aggregate using 10 disks* :: storage aggregate create -aggregate aggr1 -diskcount 10 *Create a vserver* :: vserver create -vserver <server_name>-vserver -rootvolume vol1 -aggregate aggr1 -ns-switch file -rootvolume-security-style unix * Create a data LIF :: network interface create -vserver bswartz-vserver -lif bswartz-data -role data -home-node <cluster_name>-cluster-01 -home-port e0d -address <192.168.4.15>-netmask <255.255.255.128> Add a rule to the default export policy: vserver export-policy rule create -vserver <server_name>-vserver -policyname default -clientmatch 0.0.0.0/0 -rorule any -rwrule any -superuser any -anon 0 * Enable NFS on the vserver* :: vserver nfs create -vserver <server_name>-vserver -access true * Create a volume with some free space* :: volume create -vserver <server_name>-vserver -volume vol<volume_number> -aggregate aggr1 -size 5g -junction-path /vol<volume_number> #. Download the plug-in from `<https://software.mirantis.com/fuel-plug-ins>`_. .. image:: /_images/fuel-plugin-netapp-configuration.png","NetApp plug-in will replace `Cinder LVM driver <http://docs.openstack.org/juno/config-reference/content/lvm-volume-driver.html>`_.To enable NetApp plug-in for Cinder, you should check the following:.. note:: Since only one Cinder node should be deployed, Cinder volume is **not** highly available.#. Download the plug-in from `<https://software.mirantis.com/fuel-plugins>`_. .. image:: /_images/plugins/fuel_plugin_netapp_configuration.png",283,23
openstack%2Foslo.serialization~master~Ie966392c96f595a9bc7e683dd919e44efce78b5a,openstack/oslo.serialization,master,Ie966392c96f595a9bc7e683dd919e44efce78b5a,Bump to hacking 0.10,MERGED,2015-01-12 20:02:44.000000000,2015-01-13 11:36:12.000000000,2015-01-13 11:36:10.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2015-01-12 20:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/0daa71562abae999a2370b3e8bf6ed597b20c99b', 'message': 'Bump to hacking 0.10\n\nNo changes needed\n\nChange-Id: Ie966392c96f595a9bc7e683dd919e44efce78b5a\n'}, {'number': 2, 'created': '2015-01-12 21:08:27.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/12bd905758c9913c353034129aad1b1dddaa210f', 'message': 'Bump to hacking 0.10\n\nNo changes needed\n\nChange-Id: Ie966392c96f595a9bc7e683dd919e44efce78b5a\n'}]",0,146627,12bd905758c9913c353034129aad1b1dddaa210f,9,2,2,6928,,,0,"Bump to hacking 0.10

No changes needed

Change-Id: Ie966392c96f595a9bc7e683dd919e44efce78b5a
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/27/146627/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0daa71562abae999a2370b3e8bf6ed597b20c99b,hacking-bump,"hacking>=0.10,<0.11","hacking>=0.9.2,<0.10",1,1
openstack%2Foslo.concurrency~master~Ie7c31b3c9fc4ac00e8e3281888ab9faf84bc19c5,openstack/oslo.concurrency,master,Ie7c31b3c9fc4ac00e8e3281888ab9faf84bc19c5,Bump to hacking 0.10,MERGED,2015-01-12 20:00:18.000000000,2015-01-13 11:31:57.000000000,2015-01-13 11:31:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6601}]","[{'number': 1, 'created': '2015-01-12 20:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/43bb76c80238ca1cd53245bdc996a35d21372c62', 'message': 'Bump to hacking 0.10\n\nOnly had to add a couple of newlines to the end of files.\n\nChange-Id: Ie7c31b3c9fc4ac00e8e3281888ab9faf84bc19c5\n'}, {'number': 2, 'created': '2015-01-12 21:10:58.000000000', 'files': ['test-requirements.txt', 'oslo_concurrency/opts.py', 'tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/3dfefe69192b25906c7b05809811a19014716a7a', 'message': 'Bump to hacking 0.10\n\nOnly had to add a couple of newlines to the end of files.\n\nChange-Id: Ie7c31b3c9fc4ac00e8e3281888ab9faf84bc19c5\n'}]",0,146626,3dfefe69192b25906c7b05809811a19014716a7a,9,3,2,6928,,,0,"Bump to hacking 0.10

Only had to add a couple of newlines to the end of files.

Change-Id: Ie7c31b3c9fc4ac00e8e3281888ab9faf84bc19c5
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/26/146626/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'oslo_concurrency/opts.py', 'tests/__init__.py']",3,43bb76c80238ca1cd53245bdc996a35d21372c62,hacking-bump, eventlet.monkey_patch() , eventlet.monkey_patch(),3,3
openstack%2Fsahara~master~Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca,openstack/sahara,master,Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca,Enable 5.3 version choice in cdh plugin,MERGED,2014-12-30 13:18:20.000000000,2015-01-13 11:31:22.000000000,2015-01-12 20:21:02.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13662}]","[{'number': 1, 'created': '2014-12-30 13:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/71859514be51dd57569187b510d9601272c1d9c1', 'message': 'Enable 5.3 version choice in cdh plugin\n\nCloses-bug: #1406533\n\nChange-Id: Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca\n'}, {'number': 2, 'created': '2015-01-06 01:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a0285392bb489091be27d309d6b9882cb12b58be', 'message': 'Enable 5.3 version choice in cdh plugin\n\nCloses-bug: #1406533\n\nChange-Id: Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca\n'}, {'number': 3, 'created': '2015-01-09 01:54:05.000000000', 'files': ['sahara/plugins/cdh/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e6d9dfaa38a286e518016ef1dde7dd212e326e38', 'message': 'Enable 5.3 version choice in cdh plugin\n\nCloses-bug: #1406533\n\nChange-Id: Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca\n'}]",0,144452,e6d9dfaa38a286e518016ef1dde7dd212e326e38,58,10,3,13662,,,0,"Enable 5.3 version choice in cdh plugin

Closes-bug: #1406533

Change-Id: Ifc629b159bc75dd59bb5bdc73daa0cb96cbdb0ca
",git fetch https://review.opendev.org/openstack/sahara refs/changes/52/144452/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/cdh/plugin.py'],1,71859514be51dd57569187b510d9601272c1d9c1,Bug1406533," return ['5', '5.2.0', '5.3.0']"," return ['5', '5.2.0']",1,1
openstack%2Ftooz~master~I4f09ac98028d2b9a525cc90d35960ddfdd55afc0,openstack/tooz,master,I4f09ac98028d2b9a525cc90d35960ddfdd55afc0,Allow to pass arguments to retry(),MERGED,2015-01-12 15:51:26.000000000,2015-01-13 11:21:21.000000000,2015-01-13 11:21:20.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2015-01-12 15:51:26.000000000', 'files': ['tooz/drivers/_retry.py', 'tooz/tests/drivers/test_retry.py', 'tooz/drivers/memcached.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/ae65ae547804b683c9c6175a652cd6eb09eb09f9', 'message': 'Allow to pass arguments to retry()\n\nChange-Id: I4f09ac98028d2b9a525cc90d35960ddfdd55afc0\n'}]",0,146506,ae65ae547804b683c9c6175a652cd6eb09eb09f9,7,3,1,1669,,,0,"Allow to pass arguments to retry()

Change-Id: I4f09ac98028d2b9a525cc90d35960ddfdd55afc0
",git fetch https://review.opendev.org/openstack/tooz refs/changes/06/146506/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/_retry.py', 'tooz/tests/drivers/test_retry.py', 'tooz/drivers/memcached.py']",3,ae65ae547804b683c9c6175a652cd6eb09eb09f9,jd/filelock," def acquire(self, blocking=True): @_retry.retry(stop_max_delay=blocking) return _acquire() @_retry.retry() @_retry.retry() @_retry.retry() @_retry.retry() @_retry.retry() @_retry.retry() @_retry.retry()"," @_retry.retry def acquire(self, blocking=True): kwargs = _retry.RETRYING_KWARGS.copy() kwargs['stop_max_delay'] = blocking return _retry.Retrying(**kwargs).call(_acquire) @_retry.retry @_retry.retry @_retry.retry @_retry.retry @_retry.retry @_retry.retry @_retry.retry",16,14
openstack%2Fironic-inspector~master~I3b039a742639725e42ed6e2651075fd338dd6014,openstack/ironic-inspector,master,I3b039a742639725e42ed6e2651075fd338dd6014,Update HTTP API documentation to reflect the current reality,ABANDONED,2015-01-12 15:40:42.000000000,2015-01-13 11:20:27.000000000,,"[{'_account_id': 3}, {'_account_id': 8688}]","[{'number': 1, 'created': '2015-01-12 15:40:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f8ee63152fe216058ca7f233c8a79083e90353c6', 'message': 'Update HTTP API documentation to reflect the current reality\n\nChange-Id: I3b039a742639725e42ed6e2651075fd338dd6014\nImplements: blueprint v1-api-reform\n'}]",1,146498,f8ee63152fe216058ca7f233c8a79083e90353c6,4,2,1,10239,,,0,"Update HTTP API documentation to reflect the current reality

Change-Id: I3b039a742639725e42ed6e2651075fd338dd6014
Implements: blueprint v1-api-reform
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/98/146498/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,f8ee63152fe216058ca7f233c8a79083e90353c6,bp/v1-api-reform," python -m ironic_discoverd.client --auth-token TOKEN introspect UUIDHTTP API consist of these endpoints: * ``POST /v1/introspection/<UUID>`` initiate hardware discovery for node ``<UUID>``. All power management configuration for this node needs to be done prior to calling the endpoint. Requires X-Auth-Token header with Keystone token for authentication. * 401, 403 - missing or invalid authentication Client library function: ``ironic_discoverd.client.introspect`` for node ``<UUID>``. * ``GET /v1/introspection/<UUID>`` get hardware discovery status. Requires X-Auth-Token header with Keystone token for authentication. Response: * 200 - OK * 400 - bad request * 401, 403 - missing or invalid authentication * 404 - node cannot be found Response body: JSON dictionary with keys: * ``finished`` (boolean) whether discovery is finished * ``error`` error string or ``null`` Client library function: ``ironic_discoverd.client.get_status``. * New API ``GET /v1/introspection/<uuid>`` and ``client.get_status`` for getting discovery status. See `get-status-api blueprint`_ for details. * New API ``POST /v1/introspection/<uuid>`` and ``client.introspect`` is now used to initiate discovery, ``/v1/discover`` is deprecated. See `v1 API reform blueprint`_ for details. * This call now returns value as a JSON dict (currently empty).. _v1 API reform blueprint: https://blueprints.launchpad.net/ironic-discoverd/+spec/v1-api-reform"," python -m ironic_discoverd.client --auth-token TOKEN UUID1 UUID2HTTP API consist of 2 endpoints: * ``POST /v1/discover`` initiate hardware discovery. Request body: JSON - list of UUID's of nodes to discover. All power management configuration for these nodes needs to be done prior to calling the endpoint. Requires X-Auth-Token header with Keystone token for authentication. Nodes will be put into maintenance mode during discovery. It's up to caller to put them back into use after discovery is done. .. note:: Before version 0.2.0 this endpoint was not authenticated. Now it is, but check for admin role is not implemented yet - see `bug #1391866`_. Successful response body is a JSON dictionary with keys: * ``node`` node as returned by Ironic .. _bug #1391866: https://bugs.launchpad.net/ironic-discoverd/+bug/1391866 * This call now returns value as a JSON dict* Add new API ``GET /v1/introspection/<uuid>`` and ``client.get_status`` for getting discovery status. See `get-status-api blueprint`_ for details. ",40,24
openstack%2Fmagnetodb~master~Ia8928980453613a191802449749184f76dd70b95,openstack/magnetodb,master,Ia8928980453613a191802449749184f76dd70b95,Using another control exchange instead of using not durable exchange,MERGED,2015-01-12 23:28:40.000000000,2015-01-13 10:59:49.000000000,2015-01-13 10:59:49.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 11006}]","[{'number': 1, 'created': '2015-01-12 23:28:40.000000000', 'files': ['contrib/devstack/lib/magnetodb'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/24b4284aaeac519e5b6f5d8c785753c50e86e90d', 'message': 'Using another control exchange instead of using not durable exchange\n\nCloses-bug: #1409945\nChange-Id: Ia8928980453613a191802449749184f76dd70b95\n'}]",0,146681,24b4284aaeac519e5b6f5d8c785753c50e86e90d,7,5,1,8863,,,0,"Using another control exchange instead of using not durable exchange

Closes-bug: #1409945
Change-Id: Ia8928980453613a191802449749184f76dd70b95
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/81/146681/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/magnetodb'],1,24b4284aaeac519e5b6f5d8c785753c50e86e90d,fix-rabbit, iniset $MAGNETODB_CONF_DIR/magnetodb-api.conf DEFAULT control_exchange mdb iniset $MAGNETODB_CONF_DIR/magnetodb-async-task-executor.conf DEFAULT control_exchange mdb, iniset $MAGNETODB_CONF_DIR/magnetodb-api.conf DEFAULT amqp_durable_queues False iniset $MAGNETODB_CONF_DIR/magnetodb-async-task-executor.conf DEFAULT amqp_durable_queues False,2,2
openstack%2Fneutron~master~Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde,openstack/neutron,master,Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde,"Use ""if dict.get(key):"" instead ""if key in dict and dict[key]:""",MERGED,2014-08-07 08:26:49.000000000,2015-01-13 10:56:33.000000000,2015-01-13 09:10:41.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5215}, {'_account_id': 5948}, {'_account_id': 5950}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 8449}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 8792}, {'_account_id': 8873}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9911}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 12215}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}]","[{'number': 1, 'created': '2014-08-07 08:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32fa3a3c1865bdba575ea9ba9b213d5e959dc7cc', 'message': 'Use dict\'s get fucntion instead of check by hand\n\nUse ""if dict.get(key):"" instead of ""if item in dict and dict[key]""\nwhich make code more clear and intelligible.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 2, 'created': '2014-08-07 09:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7cde643eb41dadad01210a0d32445caa9f65b221', 'message': 'Use dict\'s get fucntion instead of check by hand\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich make code more clear and intelligible.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 3, 'created': '2014-08-09 12:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3704768620bfa0a86e9d07392a7e83aadd70d258', 'message': 'Use dict\'s get fucntion instead of check by hand\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 4, 'created': '2014-08-09 17:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e4c857abef392c851717cf1be2cbf9943420b8a', 'message': 'Use dict\'s get fucntion instead of check by hand\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 5, 'created': '2014-08-12 14:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b50e35f6706eb42ec642dc9f66fae152086cc0c9', 'message': '""if dict.get(key):"" over ""if key in dict and dict[key]:""\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible. Note this patch doesn\'t\nchange judging conditions, all ""is not None"" are retained.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 6, 'created': '2014-08-13 11:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a980ae824ea82f2e5240ab37916b7f18bb5872d', 'message': 'Use ""if dict.get(key):"" over ""if key in dict and dict[key]:""\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible. Note this patch doesn\'t\nchange judging conditions, all ""is not None"" are retained.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 7, 'created': '2014-11-09 13:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2681c1ec7322ba05940e3d39e8cd99d751082863', 'message': 'Use ""if dict.get(key):"" over ""if key in dict and dict[key]:""\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible. Note this patch doesn\'t\nchange judging conditions, all ""is not None"" are retained.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 8, 'created': '2015-01-08 10:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/75fd7f4932cc0074c23ce4aeb139bebe6b13ed65', 'message': 'Use ""if dict.get(key):"" over ""if key in dict and dict[key]:""\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible. Note this patch doesn\'t\nchange judging conditions, all ""is not None"" are retained.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}, {'number': 9, 'created': '2015-01-12 22:06:14.000000000', 'files': ['neutron/tests/unit/nuage/fake_nuageclient.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/plugins/vmware/plugins/base.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/tests/unit/vmware/extensions/test_networkgw.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2066f34e1187e4b021ecf6d1ec18a1e55b6eb21', 'message': 'Use ""if dict.get(key):"" instead ""if key in dict and dict[key]:""\n\nUse ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""\nwhich makes code more clear and intelligible. Note this patch doesn\'t\nchange judging conditions, all ""is not None"" are retained.\n\nChange-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde\n'}]",17,112511,e2066f34e1187e4b021ecf6d1ec18a1e55b6eb21,252,62,9,9911,,,0,"Use ""if dict.get(key):"" instead ""if key in dict and dict[key]:""

Use ""if dict.get(key):"" instead of ""if key in dict and dict[key]:""
which makes code more clear and intelligible. Note this patch doesn't
change judging conditions, all ""is not None"" are retained.

Change-Id: Ieed57a21eb4b08c6f9a25b180a3625154a0d5fde
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/112511/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/firewall/fwaas_plugin.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/l3_db.py']",4,32fa3a3c1865bdba575ea9ba9b213d5e959dc7cc,improve/use-builtin-function, if fip.get('fixed_ip_address'): if fip.get(fixed_ip_address) and not fip.get('port_id'): if fip.get('port_id'):, if 'fixed_ip_address' in fip and fip['fixed_ip_address']: if (('fixed_ip_address' in fip and fip['fixed_ip_address']) and not ('port_id' in fip and fip['port_id'])): if 'port_id' in fip and fip['port_id']:,6,8
openstack%2Ffuel-library~stable%2F5.1~I3782f23bf814fa5402f4ca9d3ac09050dc270fea,openstack/fuel-library,stable/5.1,I3782f23bf814fa5402f4ca9d3ac09050dc270fea,Fix nproc issues for CentOS,ABANDONED,2014-10-03 01:03:12.000000000,2015-01-13 10:56:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-03 01:03:12.000000000', 'files': ['deployment/puppet/cobbler/templates/snippets/bug1376564.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/horizon/templates/zzz_performance_tuning.conf.erb', 'deployment/puppet/cobbler/manifests/snippets.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b859c05e52a9b952d9719c54240438d4882ebbda', 'message': 'Fix nproc issues for CentOS\n\n1) Remove nproc.conf file with stupid\n1024 process limit against fork\nbombs\n\n2) Limit httpd.event childs to 6\n\nChange-Id: I3782f23bf814fa5402f4ca9d3ac09050dc270fea\nPartial-bug: #1376564\n'}]",0,125842,b859c05e52a9b952d9719c54240438d4882ebbda,8,3,1,8786,,,0,"Fix nproc issues for CentOS

1) Remove nproc.conf file with stupid
1024 process limit against fork
bombs

2) Limit httpd.event childs to 6

Change-Id: I3782f23bf814fa5402f4ca9d3ac09050dc270fea
Partial-bug: #1376564
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/42/125842/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cobbler/templates/snippets/bug1376564.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/horizon/templates/zzz_performance_tuning.conf.erb', 'deployment/puppet/cobbler/manifests/snippets.pp']",4,b859c05e52a9b952d9719c54240438d4882ebbda,, cobbler_snippet {'bug1376564':},,5,1
openstack%2Ffuel-library~master~I3782f23bf814fa5402f4ca9d3ac09050dc270fea,openstack/fuel-library,master,I3782f23bf814fa5402f4ca9d3ac09050dc270fea,Fix nproc issues for CentOS,ABANDONED,2014-10-03 01:00:40.000000000,2015-01-13 10:56:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-10-03 01:00:40.000000000', 'files': ['deployment/puppet/cobbler/templates/snippets/bug1376564.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/horizon/templates/zzz_performance_tuning.conf.erb', 'deployment/puppet/cobbler/manifests/snippets.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b2dc537d8251b89d11b6279b30a1c34a433a0d87', 'message': 'Fix nproc issues for CentOS\n\n1) Remove nproc.conf file with stupid\n1024 process limit against fork\nbombs\n\n2) Limit httpd.event childs to 6\n\nChange-Id: I3782f23bf814fa5402f4ca9d3ac09050dc270fea\nPartial-bug: #1376564\n'}]",0,125840,b2dc537d8251b89d11b6279b30a1c34a433a0d87,8,3,1,8786,,,0,"Fix nproc issues for CentOS

1) Remove nproc.conf file with stupid
1024 process limit against fork
bombs

2) Limit httpd.event childs to 6

Change-Id: I3782f23bf814fa5402f4ca9d3ac09050dc270fea
Partial-bug: #1376564
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/40/125840/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cobbler/templates/snippets/bug1376564.erb', 'deployment/puppet/cobbler/templates/kickstart/centos.ks.erb', 'deployment/puppet/horizon/templates/zzz_performance_tuning.conf.erb', 'deployment/puppet/cobbler/manifests/snippets.pp']",4,b2dc537d8251b89d11b6279b30a1c34a433a0d87,, cobbler_snippet {'bug1376564':},,5,1
openstack%2Fmurano-specs~master~Id1aee05e75b12588f3b20db4ca345a2b1cec5850,openstack/murano-specs,master,Id1aee05e75b12588f3b20db4ca345a2b1cec5850,update configuration language support spec,ABANDONED,2014-12-12 11:26:44.000000000,2015-01-13 10:46:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7600}, {'_account_id': 13931}]","[{'number': 1, 'created': '2014-12-12 11:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/47abc9a8beaedb461e49faedbb6b5b46c91e8e83', 'message': 'Initial contribution for Support Configuration Language spec\n\nChange-Id: Id1aee05e75b12588f3b20db4ca345a2b1cec5850\n'}, {'number': 2, 'created': '2014-12-15 10:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/fc38c64e79740009a00e7b85ded37c80b053b58a', 'message': 'Initial contribution for Support Configuration Language spec\n\nChange-Id: Id1aee05e75b12588f3b20db4ca345a2b1cec5850\n'}, {'number': 3, 'created': '2015-01-13 10:41:17.000000000', 'files': ['specs/kilo/conf-language-support.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/fd09642f63e5262483337c3d6f532b15b8712f77', 'message': 'update configuration language support spec\n\nChange-Id: Id1aee05e75b12588f3b20db4ca345a2b1cec5850\n'}]",3,141335,fd09642f63e5262483337c3d6f532b15b8712f77,9,4,3,13931,,,0,"update configuration language support spec

Change-Id: Id1aee05e75b12588f3b20db4ca345a2b1cec5850
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/35/141335/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/configurationlanguages.rst'],1,47abc9a8beaedb461e49faedbb6b5b46c91e8e83,specs/supportconfigurationlanguages,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Configuration Language Support ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/murano/+spec/conf-language-support Problem description =================== They are a huge community of applications (opscode, puppet-labs) where the deployment installations instructions are specified in configuration languages (puppet, chef). In order to reuse this community, some adaptors (chef adaptor and puppet adaptor) are required in the VM side, since current applications execute shell scripts Proposed change =============== Inclusion of new Application objects to be used by murano-agent. They can be called like PuppetApplication and ChefApplication for the configuration of software. Alternatives ------------ None Data model impact ----------------- ***TBD** REST API impact --------------- None Versioning impact ------------------------- None Other end user impact --------------------- None Deployer impact --------------- **TBD** Developer impact ---------------- **TBD** Murano-dashboard / Horizon impact --------------------------------- **TBD** Implementation ============== Assignee(s) ----------- **TBD** Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- **TBD** Dependencies ============ **TBD** Testing ======= **TBD** Documentation Impact ==================== **TBD** References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,133,0
openstack%2Fmistral~master~If365516c2cf1c67c5c0396539a6c85afc12c2c47,openstack/mistral,master,If365516c2cf1c67c5c0396539a6c85afc12c2c47,Small fixes in default config,MERGED,2015-01-10 02:59:40.000000000,2015-01-13 10:42:17.000000000,2015-01-13 10:42:17.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 11863}]","[{'number': 1, 'created': '2015-01-10 02:59:40.000000000', 'files': ['mistral/utils/__init__.py', 'mistral/config.py', 'mistral/db/sqlalchemy/base.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/a7e300a3572944d1faf282faa26bd1e9b041d3c7', 'message': 'Small fixes in default config\n\nTo ensure better defaults, so Mistral will work more adequately with less configuration.\n\n* enable INFO output by default so that console shows workflow executions, etc.\nOur current INFO level is not too verbose and most adequate as default.\n\n* supply working default for sqlite; this way mistral at least starts without supplying config file.\n\nChange-Id: If365516c2cf1c67c5c0396539a6c85afc12c2c47\n'}]",2,146254,a7e300a3572944d1faf282faa26bd1e9b041d3c7,9,5,1,9432,,,0,"Small fixes in default config

To ensure better defaults, so Mistral will work more adequately with less configuration.

* enable INFO output by default so that console shows workflow executions, etc.
Our current INFO level is not too verbose and most adequate as default.

* supply working default for sqlite; this way mistral at least starts without supplying config file.

Change-Id: If365516c2cf1c67c5c0396539a6c85afc12c2c47
",git fetch https://review.opendev.org/openstack/mistral refs/changes/54/146254/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/utils/__init__.py', 'mistral/config.py', 'mistral/db/sqlalchemy/base.py']",3,a7e300a3572944d1faf282faa26bd1e9b041d3c7,small-fixes,"# Note(dzimine): sqlite only works for basic testing. options.set_defaults(cfg.CONF, connection=""sqlite:///mistral.sqlite"")","options.set_defaults(cfg.CONF, sqlite_db=""mistral.sqlite"")",4,7
openstack%2Fmistral~master~Ifce1e77012bc3be7785597ab84b998209b866ae8,openstack/mistral,master,Ifce1e77012bc3be7785597ab84b998209b866ae8,small tox fixes,MERGED,2015-01-10 02:59:40.000000000,2015-01-13 10:42:11.000000000,2015-01-13 10:42:09.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7227}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 11863}]","[{'number': 1, 'created': '2015-01-10 02:59:40.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral/commit/533fdbb54638f16a02db38628d1b34aae6659ad9', 'message': ""small tox fixes\n\n* remove py26: it no longer used in gates, and fails the tests on:\n\n    (dt.datetime.now() - time_before).total_seconds(),\n    AttributeError: 'datetime.timedelta' object has no\n    attribute'total_seconds'`\n\n* don't generate __pycache__ folders\n\nChange-Id: Ifce1e77012bc3be7785597ab84b998209b866ae8\n""}]",0,146253,533fdbb54638f16a02db38628d1b34aae6659ad9,8,6,1,9432,,,0,"small tox fixes

* remove py26: it no longer used in gates, and fails the tests on:

    (dt.datetime.now() - time_before).total_seconds(),
    AttributeError: 'datetime.timedelta' object has no
    attribute'total_seconds'`

* don't generate __pycache__ folders

Change-Id: Ifce1e77012bc3be7785597ab84b998209b866ae8
",git fetch https://review.opendev.org/openstack/mistral refs/changes/53/146253/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,533fdbb54638f16a02db38628d1b34aae6659ad9,small-fixes,"envlist = py27,py33,py34,pep8 PYTHONDONTWRITEBYTECODE = 1","envlist = py26,py27,py33,py34,pep8",2,1
openstack%2Fmistral~master~Iac1ddfdd2c4aa011f593f28ee9fc82eaf3654ebf,openstack/mistral,master,Iac1ddfdd2c4aa011f593f28ee9fc82eaf3654ebf,Small: refactor commands,MERGED,2015-01-13 04:35:55.000000000,2015-01-13 10:39:36.000000000,2015-01-13 10:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}]","[{'number': 1, 'created': '2015-01-13 04:35:55.000000000', 'files': ['mistral/engine1/commands.py', 'mistral/tests/unit/engine1/test_commands.py', 'mistral/workflow/base.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/1b932da897e16a61d182ac8ef347c840f8cde37b', 'message': 'Small: refactor commands\n\nEngine commands should not change execution state directly,\nbut only do it via workflow handler.\n\nChange-Id: Iac1ddfdd2c4aa011f593f28ee9fc82eaf3654ebf'}]",0,146756,1b932da897e16a61d182ac8ef347c840f8cde37b,7,4,1,9432,,,0,"Small: refactor commands

Engine commands should not change execution state directly,
but only do it via workflow handler.

Change-Id: Iac1ddfdd2c4aa011f593f28ee9fc82eaf3654ebf",git fetch https://review.opendev.org/openstack/mistral refs/changes/56/146756/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/commands.py', 'mistral/tests/unit/engine1/test_commands.py', 'mistral/workflow/base.py']",3,1b932da897e16a61d182ac8ef347c840f8cde37b,fixes," def succeed_workflow(self): """"""Completes workflow with SUCCESS status. :return: Execution object. """""" self._set_execution_state(states.SUCCESS) return self.exec_db def pause_workflow(self): """"""Pauses workflow this handler is associated with. def fail_workflow(self): """"""Stops workflow with ERROR state. :return: Execution object. """""" self._set_execution_state(states.ERROR) return self.exec_db "," def pause_workflow(self): """"""Stops workflow this handler is associated with.",27,35
openstack%2Fheat~master~Ifb128f113807092001396113d3390b644bf53cad,openstack/heat,master,Ifb128f113807092001396113d3390b644bf53cad,LB: Make unit tests for _haproxy_config,MERGED,2015-01-09 07:28:47.000000000,2015-01-13 10:38:17.000000000,2015-01-13 10:38:16.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-09 07:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e01f651343284af69360335440e705ddf42fae3', 'message': 'LB: Make unit tests for _haproxy_config\n\nPart of blueprint decouple-nested\n\nChange-Id: Ifb128f113807092001396113d3390b644bf53cad\n'}, {'number': 2, 'created': '2015-01-13 02:20:03.000000000', 'files': ['heat/tests/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ecbf62976b28821ffbdfa9e7993e868e328edb37', 'message': 'LB: Make unit tests for _haproxy_config\n\nPart of blueprint decouple-nested\n\nChange-Id: Ifb128f113807092001396113d3390b644bf53cad\n'}]",2,146031,ecbf62976b28821ffbdfa9e7993e868e328edb37,17,4,2,4715,,,0,"LB: Make unit tests for _haproxy_config

Part of blueprint decouple-nested

Change-Id: Ifb128f113807092001396113d3390b644bf53cad
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/146031/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_loadbalancer.py'],1,8e01f651343284af69360335440e705ddf42fae3,bp/decouple-nested," class HaProxyConfigTest(common.HeatTestCase): def setUp(self): super(HaProxyConfigTest, self).setUp() stack = utils.parse_stack(template_format.parse(lb_template)) resource_name = 'LoadBalancer' lb_defn = stack.t.resource_definitions(stack)[resource_name] self.lb = lb.LoadBalancer(resource_name, lb_defn, stack) self.lb.client_plugin = mock.Mock() def _mock_props(self, props): def get_props(name): return props[name] self.lb.properties = mock.MagicMock() self.lb.properties.__getitem__.side_effect = get_props def test_combined(self): self.lb._haproxy_config_global = mock.Mock(return_value='one,') self.lb._haproxy_config_frontend = mock.Mock(return_value='two,') self.lb._haproxy_config_backend = mock.Mock(return_value='three,') self.lb._haproxy_config_servers = mock.Mock(return_value='four') actual = self.lb._haproxy_config([3, 5]) self.assertEqual('one,two,three,four\n', actual) self.lb._haproxy_config_global.assert_called_once_with() self.lb._haproxy_config_frontend.assert_called_once_with() self.lb._haproxy_config_backend.assert_called_once_with() self.lb._haproxy_config_servers.assert_called_once_with([3, 5]) def test_frontend(self): exp = ''' global daemon maxconn 256 stats socket /tmp/.haproxy-stats defaults mode http timeout connect 5000ms timeout client 50000ms timeout server 50000ms ''' actual = self.lb._haproxy_config_global() self.assertEqual(exp, actual) def test_backend_with_timeout(self): props = {'HealthCheck': {'Timeout': 43}} self._mock_props(props) actual = self.lb._haproxy_config_backend() exp = ''' default_backend servers backend servers balance roundrobin option http-server-close option forwardfor option httpchk timeout check 43s ''' self.assertEqual(exp, actual) def test_backend_no_timeout(self): self._mock_props({'HealthCheck': None}) be = self.lb._haproxy_config_backend() exp = ''' default_backend servers backend servers balance roundrobin option http-server-close option forwardfor option httpchk ''' self.assertEqual(exp, be) def test_servers_none(self): props = {'HealthCheck': {}, 'Listeners': [{'InstancePort': 1234}]} self._mock_props(props) actual = self.lb._haproxy_config_servers([]) exp = '' self.assertEqual(exp, actual) def test_servers_no_check(self): props = {'HealthCheck': {}, 'Listeners': [{'InstancePort': 4511}]} self._mock_props(props) def fake_to_ipaddr(inst): return '192.168.1.%s' % inst to_ip = self.lb.client_plugin.return_value.server_to_ipaddress to_ip.side_effect = fake_to_ipaddr actual = self.lb._haproxy_config_servers(range(1, 3)) self.assertIn('server server1 192.168.1.1:4511', actual) self.assertIn('server server2 192.168.1.2:4511', actual) def test_servers_servers_and_check(self): props = {'HealthCheck': {'HealthyThreshold': 1, 'Interval': 2, 'Target': 'HTTP:80/', 'Timeout': 45, 'UnhealthyThreshold': 5 }, 'Listeners': [{'InstancePort': 1234}]} self._mock_props(props) def fake_to_ipaddr(inst): return '192.168.1.%s' % inst to_ip = self.lb.client_plugin.return_value.server_to_ipaddress to_ip.side_effect = fake_to_ipaddr actual = self.lb._haproxy_config_servers(range(1, 3)) exp = '''\ server server1 192.168.1.1:1234 check inter 2s fall 5 rise 1 server server2 192.168.1.2:1234 check inter 2s fall 5 rise 1''' self.assertEqual(exp, actual)","import re import six ha_cfg = rsrc._haproxy_config(rsrc.properties['Instances']) self.assertRegexpMatches(ha_cfg, 'bind \*:80') self.assertRegexpMatches(ha_cfg, 'server server1 1\.2\.3\.4:80 ' 'check inter 30s fall 5 rise 3') self.assertRegexpMatches(ha_cfg, 'timeout check 5s') def assertRegexpMatches(self, text, expected_regexp, msg=None): """"""Fail the test unless the text matches the regular expression."""""" if isinstance(expected_regexp, six.string_types): expected_regexp = re.compile(expected_regexp) if not expected_regexp.search(text): msg = msg or ""Regexp didn't match"" msg = '%s: %r not found in %r' % (msg, expected_regexp.pattern, text) raise self.failureException(msg) ",124,19
openstack%2Fheat~master~Ie2be9b530e0fa3e19960adc49f930cbcb3ffa2fb,openstack/heat,master,Ie2be9b530e0fa3e19960adc49f930cbcb3ffa2fb,LB: Break up _haproxy_config to enable easier unit testing,MERGED,2015-01-09 07:28:47.000000000,2015-01-13 10:36:36.000000000,2015-01-13 10:36:35.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-09 07:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5671516094056714cec5b2e0f5551cd40abec5de', 'message': 'LB: Break up _haproxy_config to enable easier unit testing\n\nThe tests are to follow, just proving that no test needed to\nbe changed.\n\nPart of blueprint decouple-nested\nChange-Id: Ie2be9b530e0fa3e19960adc49f930cbcb3ffa2fb\n'}, {'number': 2, 'created': '2015-01-13 02:20:03.000000000', 'files': ['heat/engine/resources/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4837b9fbe1c8e3de8d6eda3af67934e6818ab359', 'message': 'LB: Break up _haproxy_config to enable easier unit testing\n\nThe tests are to follow, just proving that no test needed to\nbe changed.\nFix the indentation of the resultant config file.\n\nPart of blueprint decouple-nested\nChange-Id: Ie2be9b530e0fa3e19960adc49f930cbcb3ffa2fb\n'}]",11,146030,4837b9fbe1c8e3de8d6eda3af67934e6818ab359,23,5,2,4715,,,0,"LB: Break up _haproxy_config to enable easier unit testing

The tests are to follow, just proving that no test needed to
be changed.
Fix the indentation of the resultant config file.

Part of blueprint decouple-nested
Change-Id: Ie2be9b530e0fa3e19960adc49f930cbcb3ffa2fb
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/146030/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/loadbalancer.py'],1,5671516094056714cec5b2e0f5551cd40abec5de,bp/decouple-nested," def _haproxy_config_global(self): return ''' def _haproxy_config_frontend(self): return ''' def _haproxy_config_backend(self): spaces = ' ' else: spaces = '' return '''%s%s ''' % (spaces, timeout_check) def _haproxy_config_servers(self, instances): listener = self.properties[self.LISTENERS][0] inst_port = listener[self.LISTENER_INSTANCE_PORT] spaces = ' ' check = '' health_chk = self.properties[self.HEALTH_CHECK] if health_chk: check = 'check inter %ss fall %s rise %s' % ( health_chk[self.HEALTH_CHECK_INTERVAL], health_chk[self.HEALTH_CHECK_UNHEALTHY_THRESHOLD], health_chk[self.HEALTH_CHECK_HEALTHY_THRESHOLD]) return '\n'.join(servers) def _haproxy_config(self, instances): # initial simplifications: # - only one Listener # - only http (no tcp or ssl) # # option httpchk HEAD /check.txt HTTP/1.0 return '%s%s%s%s\n' % (self._haproxy_config_global(), self._haproxy_config_frontend(), self._haproxy_config_backend(), self._haproxy_config_servers(instances))"," def _haproxy_config(self, instances): # initial simplifications: # - only one Listener # - only http (no tcp or ssl) # # option httpchk HEAD /check.txt HTTP/1.0 gl = ''' inst_port = listener[self.LISTENER_INSTANCE_PORT] spaces = ' ' frontend = ''' check = 'check inter %ss fall %s rise %s' % ( health_chk[self.HEALTH_CHECK_INTERVAL], health_chk[self.HEALTH_CHECK_UNHEALTHY_THRESHOLD], health_chk[self.HEALTH_CHECK_HEALTHY_THRESHOLD]) else: check = '' backend = ''' %s ''' % timeout_check return '%s%s%s%s\n' % (gl, frontend, backend, '\n'.join(servers))",33,19
openstack%2Foslo.messaging~master~Ia562010c152a214f1c0fed767c82022c7c2c52e7,openstack/oslo.messaging,master,Ia562010c152a214f1c0fed767c82022c7c2c52e7,Move files out of the namespace package,MERGED,2015-01-02 19:32:34.000000000,2015-01-13 10:33:40.000000000,2015-01-13 10:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 8415}, {'_account_id': 9107}, {'_account_id': 9656}, {'_account_id': 11356}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-01-02 19:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9b2c383f8c0a1fbb7e94d9dae0ee09a3edebbcac', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 2, 'created': '2015-01-02 23:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/31e782b4c51c1c4fa9e38bd5d6d09fcbe9f04fd3', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 3, 'created': '2015-01-02 23:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/00e0bfc114bb722cdbf418a39a543a68737bc82b', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 4, 'created': '2015-01-05 15:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a722a88b0594d0db2797d6dd45a8204bf3350833', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 5, 'created': '2015-01-06 16:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/276fec8a97af4f2c98c39d78b4383a0453be51a2', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 6, 'created': '2015-01-08 21:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/623cb04d2462925bb28e844e4c1a12b230da8a53', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}, {'number': 7, 'created': '2015-01-12 18:02:59.000000000', 'files': ['tests/rpc/test_dispatcher.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/notify/middleware.py', 'oslo_messaging/exceptions.py', 'oslo_messaging/notify/log_handler.py', 'tests/functional/utils.py', 'doc/source/target.rst', 'oslo_messaging/notify/notifier.py', 'oslo_messaging/openstack/__init__.py', 'oslo_messaging/_drivers/impl_rabbit.py', 'oslo_messaging/tests/executors/test_executor.py', 'oslo_messaging/openstack/common/context.py', 'oslo/messaging/transport.py', 'oslo_messaging/rpc/__init__.py', 'oslo_messaging/_drivers/protocols/amqp/driver.py', 'oslo_messaging/rpc/server.py', 'oslo_messaging/rpc/client.py', 'oslo_messaging/_drivers/amqp.py', 'oslo_messaging/serializer.py', 'oslo/messaging/server.py', 'oslo_messaging/tests/test_urls.py', 'tests/drivers/test_pool.py', 'oslo_messaging/tests/notify/test_notifier.py', 'oslo_messaging/notify/logger.py', 'oslo_messaging/_drivers/protocols/amqp/eventloop.py', 'tests/test_urls.py', 'tests/test_transport.py', 'oslo_messaging/tests/drivers/test_matchmaker_redis.py', 'oslo_messaging/_utils.py', 'oslo_messaging/notify/__init__.py', 'oslo/messaging/target.py', 'oslo/messaging/notify/logger.py', 'oslo_messaging/_drivers/protocols/amqp/controller.py', 'tests/test_expected_exceptions.py', 'oslo_messaging/tests/rpc/__init__.py', 'oslo_messaging/tests/rpc/test_client.py', 'doc/source/notification_listener.rst', 'oslo_messaging/_drivers/pool.py', 'oslo_messaging/opts.py', 'oslo_messaging/notify/listener.py', 'tests/rpc/test_client.py', 'oslo_messaging/tests/drivers/test_impl_qpid.py', 'tests/drivers/test_impl_zmq.py', 'oslo_messaging/_drivers/base.py', 'oslo_messaging/tests/rpc/test_dispatcher.py', 'oslo_messaging/tests/test_expected_exceptions.py', 'tests/notify/test_dispatcher.py', 'oslo/messaging/notify/notifier.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo/messaging/serializer.py', 'oslo_messaging/_executors/impl_thread.py', 'oslo_messaging/tests/test_target.py', 'oslo/messaging/rpc/server.py', 'oslo_messaging/_executors/base.py', 'oslo_messaging/_drivers/impl_qpid.py', 'oslo_messaging/target.py', 'oslo_messaging/tests/notify/__init__.py', 'oslo_messaging/tests/notify/test_logger.py', 'oslo_messaging/openstack/common/__init__.py', 'oslo/messaging/localcontext.py', 'oslo_messaging/tests/notify/test_middleware.py', 'oslo_messaging/_drivers/impl_zmq.py', 'tests/drivers/test_matchmaker.py', 'oslo/messaging/notify/middleware.py', 'oslo_messaging/rpc/dispatcher.py', 'oslo/messaging/rpc/dispatcher.py', 'oslo_messaging/_drivers/protocols/amqp/opts.py', 'tests/notify/test_notifier.py', 'oslo_messaging/_drivers/impl_fake.py', 'oslo_messaging/tests/drivers/test_pool.py', 'oslo_messaging/tests/drivers/__init__.py', 'doc/source/rpcclient.rst', 'oslo_messaging/_i18n.py', 'tests/notify/test_log_handler.py', 'oslo_messaging/tests/utils.py', 'tests/test_amqp_driver.py', 'oslo_messaging/_drivers/matchmaker_ring.py', 'oslo_messaging/notify/_impl_test.py', 'oslo_messaging/tests/notify/test_listener.py', 'tests/rpc/test_server.py', 'oslo_messaging/tests/test_exception_serialization.py', 'doc/source/server.rst', 'oslo_messaging/tests/test_opts.py', 'tests/drivers/test_matchmaker_redis.py', 'oslo_messaging/_drivers/common.py', 'doc/source/notifier.rst', 'oslo/messaging/exceptions.py', 'doc/source/exceptions.rst', 'doc/source/opts.rst', 'oslo_messaging/_executors/__init__.py', 'oslo_messaging/conffixture.py', 'oslo_messaging/_cmd/zmq_receiver.py', 'oslo/messaging/notify/listener.py', 'oslo_messaging/tests/test_transport.py', 'oslo/messaging/conffixture.py', 'oslo/messaging/__init__.py', 'oslo_messaging/server.py', 'oslo_messaging/tests/drivers/test_impl_zmq.py', 'oslo_messaging/__init__.py', 'oslo_messaging/tests/drivers/test_matchmaker_ring.py', 'oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo/messaging/rpc/client.py', 'oslo_messaging/notify/_impl_routing.py', 'oslo_messaging/_executors/impl_eventlet.py', 'oslo_messaging/tests/notify/test_log_handler.py', 'doc/source/AMQP1.0.rst', 'setup.cfg', 'tests/drivers/test_impl_qpid.py', 'tests/notify/test_listener.py', 'tox.ini', 'oslo_messaging/_drivers/protocols/amqp/__init__.py', 'oslo_messaging/tests/drivers/test_matchmaker.py', 'tests/test_warning.py', 'oslo_messaging/tests/functional/__init__.py', 'doc/source/executors.rst', 'oslo_messaging/notify/_impl_noop.py', 'oslo_messaging/tests/executors/__init__.py', 'oslo_messaging/_cmd/__init__.py', 'oslo_messaging/_drivers/matchmaker.py', 'tests/notify/test_logger.py', 'tests/drivers/test_impl_rabbit.py', 'oslo_messaging/notify/_impl_log.py', 'oslo/messaging/notify/log_handler.py', 'oslo_messaging/transport.py', 'tests/notify/test_middleware.py', 'oslo_messaging/tests/functional/test_functional.py', 'oslo_messaging/tests/test_utils.py', 'doc/source/conffixture.rst', 'doc/source/transport.rst', 'tests/drivers/test_matchmaker_ring.py', 'oslo_messaging/_executors/impl_blocking.py', 'tests/test_utils.py', 'oslo_messaging/tests/__init__.py', 'tests/test_target.py', 'doc/source/serializer.rst', 'oslo_messaging/_drivers/__init__.py', 'oslo_messaging/notify/_impl_messaging.py', 'oslo_messaging/tests/rpc/test_server.py', 'oslo_messaging/tests/test_amqp_driver.py', 'oslo/messaging/notify/dispatcher.py', 'oslo_messaging/localcontext.py', 'oslo_messaging/tests/notify/test_dispatcher.py', 'oslo_messaging/_drivers/matchmaker_redis.py', 'oslo_messaging/_drivers/protocols/__init__.py', 'tests/test_exception_serialization.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e55a83e832d888e1a5fb087863590b08e7bd6090', 'message': 'Move files out of the namespace package\n\nMove the public API out of oslo.messaging to oslo_messaging. Retain\nthe ability to import from the old namespace package for backwards\ncompatibility for this release cycle.\n\nbp/drop-namespace-packages\n\nCo-authored-by: Mehdi Abaakouk <mehdi.abaakouk@enovance.com>\nChange-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7\n'}]",0,144794,e55a83e832d888e1a5fb087863590b08e7bd6090,33,10,7,2472,,,0,"Move files out of the namespace package

Move the public API out of oslo.messaging to oslo_messaging. Retain
the ability to import from the old namespace package for backwards
compatibility for this release cycle.

bp/drop-namespace-packages

Co-authored-by: Mehdi Abaakouk <mehdi.abaakouk@enovance.com>
Change-Id: Ia562010c152a214f1c0fed767c82022c7c2c52e7
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/94/144794/5 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/rpc/__init__.py', 'tests/rpc/test_dispatcher.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/notify/middleware.py', 'oslo_messaging/exceptions.py', 'oslo_messaging/notify/log_handler.py', 'oslo_messaging/notify/notifier.py', 'oslo_messaging/openstack/__init__.py', 'oslo_messaging/_drivers/impl_rabbit.py', 'oslo_messaging/tests/executors/test_executor.py', 'oslo_messaging/openstack/common/context.py', 'oslo/messaging/transport.py', 'oslo_messaging/rpc/__init__.py', 'oslo_messaging/_drivers/protocols/amqp/driver.py', 'oslo_messaging/rpc/server.py', 'oslo_messaging/rpc/client.py', 'oslo_messaging/_drivers/amqp.py', 'oslo_messaging/serializer.py', 'oslo/messaging/server.py', 'oslo_messaging/tests/test_urls.py', 'oslo_messaging/tests/notify/test_notifier.py', 'oslo_messaging/notify/logger.py', 'oslo_messaging/_drivers/protocols/amqp/eventloop.py', 'tests/test_urls.py', 'tests/test_transport.py', 'oslo_messaging/tests/drivers/test_matchmaker_redis.py', 'oslo_messaging/_utils.py', 'oslo_messaging/notify/__init__.py', 'oslo/messaging/target.py', 'oslo/messaging/notify/logger.py', 'oslo_messaging/_drivers/protocols/amqp/controller.py', 'tests/test_expected_exceptions.py', 'oslo_messaging/tests/rpc/__init__.py', 'oslo_messaging/tests/rpc/test_client.py', 'oslo_messaging/_drivers/pool.py', 'oslo_messaging/opts.py', 'oslo_messaging/notify/listener.py', 'tests/rpc/test_client.py', 'oslo_messaging/tests/drivers/test_impl_qpid.py', 'oslo_messaging/_drivers/base.py', 'oslo_messaging/tests/rpc/test_dispatcher.py', 'oslo_messaging/tests/test_expected_exceptions.py', 'tests/notify/test_dispatcher.py', 'oslo/messaging/notify/notifier.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo/messaging/serializer.py', 'oslo_messaging/tests/test_target.py', 'oslo/messaging/rpc/server.py', 'oslo_messaging/_executors/base.py', 'oslo_messaging/_drivers/impl_qpid.py', 'oslo_messaging/target.py', 'oslo_messaging/tests/notify/__init__.py', 'oslo_messaging/tests/notify/test_logger.py', 'oslo_messaging/openstack/common/__init__.py', 'oslo/messaging/localcontext.py', 'oslo/messaging/notify/__init__.py', 'oslo_messaging/tests/notify/test_middleware.py', 'oslo_messaging/_drivers/impl_zmq.py', 'oslo/messaging/notify/middleware.py', 'oslo_messaging/rpc/dispatcher.py', 'oslo/messaging/rpc/dispatcher.py', 'oslo_messaging/_drivers/protocols/amqp/opts.py', 'tests/notify/test_notifier.py', 'oslo_messaging/_drivers/impl_fake.py', 'oslo_messaging/tests/drivers/test_pool.py', 'oslo_messaging/tests/drivers/__init__.py', 'oslo_messaging/_i18n.py', 'tests/notify/test_log_handler.py', 'oslo_messaging/tests/utils.py', 'tests/test_amqp_driver.py', 'oslo_messaging/_drivers/matchmaker_ring.py', 'oslo_messaging/notify/_impl_test.py', 'oslo_messaging/tests/notify/test_listener.py', 'tests/rpc/test_server.py', 'oslo_messaging/tests/test_exception_serialization.py', 'oslo_messaging/tests/test_opts.py', 'oslo_messaging/_drivers/common.py', 'oslo/messaging/exceptions.py', 'oslo_messaging/_executors/__init__.py', 'oslo_messaging/conffixture.py', 'oslo_messaging/_cmd/zmq_receiver.py', 'oslo/messaging/notify/listener.py', 'oslo_messaging/tests/test_transport.py', 'oslo/messaging/conffixture.py', 'oslo/messaging/__init__.py', 'oslo_messaging/server.py', 'oslo_messaging/__init__.py', 'oslo_messaging/tests/drivers/test_matchmaker_ring.py', 'oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo/messaging/rpc/client.py', 'oslo_messaging/notify/_impl_routing.py', 'oslo_messaging/_executors/impl_eventlet.py', 'oslo_messaging/tests/notify/test_log_handler.py', 'setup.cfg', 'tests/notify/test_listener.py', 'tox.ini', 'oslo_messaging/_drivers/protocols/amqp/__init__.py', 'oslo_messaging/tests/drivers/test_matchmaker.py', 'tests/test_warning.py', 'oslo_messaging/tests/functional/__init__.py', 'oslo_messaging/notify/_impl_noop.py', 'oslo_messaging/tests/executors/__init__.py', 'oslo_messaging/_cmd/__init__.py', 'oslo_messaging/_drivers/matchmaker.py', 'tests/notify/test_logger.py', 'oslo_messaging/notify/_impl_log.py', 'oslo/messaging/notify/log_handler.py', 'oslo_messaging/transport.py', 'tests/notify/test_middleware.py', 'oslo_messaging/tests/functional/test_functional.py', 'oslo_messaging/tests/test_utils.py', 'tests/executors/test_executor.py', 'oslo_messaging/_executors/impl_blocking.py', 'tests/test_utils.py', 'oslo_messaging/tests/__init__.py', 'tests/test_target.py', 'oslo_messaging/_drivers/__init__.py', 'oslo_messaging/notify/_impl_messaging.py', 'oslo_messaging/tests/rpc/test_server.py', 'oslo_messaging/tests/test_amqp_driver.py', 'oslo/messaging/notify/dispatcher.py', 'oslo_messaging/localcontext.py', 'oslo_messaging/tests/notify/test_dispatcher.py', 'oslo_messaging/_drivers/matchmaker_redis.py', 'oslo_messaging/_drivers/protocols/__init__.py', 'tests/test_exception_serialization.py']",127,9b2c383f8c0a1fbb7e94d9dae0ee09a3edebbcac,bp/drop-namespace-packages,from oslo_messaging._drivers import common as exceptions from oslo_messaging.tests import utils as test_utils,from oslo.messaging._drivers import common as exceptionsfrom tests import utils as test_utils,7586,2593
openstack%2Fheat~master~Idd136b0de0611d12228a076fd3d739078a116a1c,openstack/heat,master,Idd136b0de0611d12228a076fd3d739078a116a1c,"LB: Remove unused ""templ"" parameter to _haproxy_config",MERGED,2015-01-09 07:28:47.000000000,2015-01-13 10:30:48.000000000,2015-01-13 10:30:45.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-09 07:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d435e7b59353fc30af87b94fbed13bf3def44321', 'message': 'LB: Remove unused ""templ"" parameter to _haproxy_config\n\nThis is not at all used, so remove it.\n\nChange-Id: Idd136b0de0611d12228a076fd3d739078a116a1c\n'}, {'number': 2, 'created': '2015-01-13 02:20:03.000000000', 'files': ['heat/engine/resources/loadbalancer.py', 'heat/tests/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/cca9f558eba3f40a2e254fdca1aa986b82baf978', 'message': 'LB: Remove unused ""templ"" parameter to _haproxy_config\n\nThis is not at all used, so remove it.\n\nChange-Id: Idd136b0de0611d12228a076fd3d739078a116a1c\n'}]",0,146029,cca9f558eba3f40a2e254fdca1aa986b82baf978,15,4,2,4715,,,0,"LB: Remove unused ""templ"" parameter to _haproxy_config

This is not at all used, so remove it.

Change-Id: Idd136b0de0611d12228a076fd3d739078a116a1c
",git fetch https://review.opendev.org/openstack/heat refs/changes/29/146029/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/loadbalancer.py', 'heat/tests/test_loadbalancer.py']",2,d435e7b59353fc30af87b94fbed13bf3def44321,bp/decouple-nested, ha_cfg = rsrc._haproxy_config(rsrc.properties['Instances'])," templ = template_format.parse(lb.lb_template_default) ha_cfg = rsrc._haproxy_config(templ, rsrc.properties['Instances'])",4,6
openstack%2Fmurano-specs~master~Iddc18b3b56597cd41d8a80180f01a040eb960947,openstack/murano-specs,master,Iddc18b3b56597cd41d8a80180f01a040eb960947,update information in the specs,ABANDONED,2015-01-13 10:28:48.000000000,2015-01-13 10:30:03.000000000,,[],"[{'number': 1, 'created': '2015-01-13 10:28:48.000000000', 'files': ['specs/kilo/conf-language-support.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/1d417fca8c469ca19db6a49059092545353c79a1', 'message': 'update information in the specs\n\nChange-Id: Iddc18b3b56597cd41d8a80180f01a040eb960947\n'}]",0,146811,1d417fca8c469ca19db6a49059092545353c79a1,2,0,1,13931,,,0,"update information in the specs

Change-Id: Iddc18b3b56597cd41d8a80180f01a040eb960947
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/11/146811/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/conf-language-support.rst'],1,1d417fca8c469ca19db6a49059092545353c79a1,specs/supportconfigurationlanguages,"in the VM side. Both chef and puppet recipes will not be managed by centralized server (chef-server, puppet-master) but they will use the standlone version, concretely the usage of chef-solo and puppet apply.Inclusion of new Application executors in the murano-agent project. These executor will be objects to be used by murano-agent. Concretely, two executors will be implemented the PuppetApplication to manage puppet and ChefApplication for Chef. Both executors will be in charge of: - installing the required software (puppet or chef-solo) - generating the required files: manifests and hieradata for puppet and node specifications for chef - download and install the required modules or cookbooks - execute the chef-solo or puppet-apply process In addition, the structure of the Application will change in order to incorporate all the required information (cookbooks names, url, recipes and so on). Some examples of new applications can be found on: - Chef: http://paste.openstack.org/show/156841/ - Puppet: http://paste.openstack.org/show/156905/ Finally, the configuration params to be include in the configuration files should arrive to the murano-agent. We will use variables for that usage.NoeNoneNoneNonePrimary assignee: hmunfru TBD1.- Generate ChefAplication executor 2.- Generate PuppetApplication executor 3.- Work on configurationNoneIntegration tests (in murano-agent) will be doneInformation about how to define application for puppet and chef will have to be documented, explaining the different fields.* http://es.slideshare.net/hmunfru/fiware-and-murano-support-for-configuration-languages * https://etherpad.openstack.org/p/conf-language-support-spec * http://paste.openstack.org/show/156841/ * http://paste.openstack.org/show/156905/ ","in the VM side, since current applications execute shell scriptsInclusion of new Application objects to be used by murano-agent. They can be called like PuppetApplication and ChefApplication for the configuration of software.***TBD****TBD****TBD****TBD****TBD** Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> <launchpad-id or None>**TBD****TBD****TBD****TBD**Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to",35,33
openstack%2Fneutron~master~I7866c0bf6c5fe3f37c5a7ea7f9161087b913127a,openstack/neutron,master,I7866c0bf6c5fe3f37c5a7ea7f9161087b913127a,Fix AttributeError on check_foreign_keys in functional job,MERGED,2015-01-12 21:30:31.000000000,2015-01-13 10:15:02.000000000,2015-01-13 06:22:33.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14212}]","[{'number': 1, 'created': '2015-01-12 21:30:31.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe59a3a1bcc9553c8cdc3f391e1431d3f27d6d28', 'message': ""Fix AttributeError on check_foreign_keys in functional job\n\nSince change 75b402be3b8, the method is no longer available. This\npatch makes a similar fix for the Neutron's functiona job test case.\n\nCloses-bug: #1409909\n\nChange-Id: I7866c0bf6c5fe3f37c5a7ea7f9161087b913127a\n""}]",0,146644,fe59a3a1bcc9553c8cdc3f391e1431d3f27d6d28,40,19,1,748,,,0,"Fix AttributeError on check_foreign_keys in functional job

Since change 75b402be3b8, the method is no longer available. This
patch makes a similar fix for the Neutron's functiona job test case.

Closes-bug: #1409909

Change-Id: I7866c0bf6c5fe3f37c5a7ea7f9161087b913127a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/146644/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/db/test_migrations.py'],1,fe59a3a1bcc9553c8cdc3f391e1431d3f27d6d28,bug/1409909," diff = alembic.autogenerate.compare_metadata(mc, self.get_metadata()) result = filter(self.remove_unrelated_errors, diff)"," diff1 = alembic.autogenerate.compare_metadata(mc, self.get_metadata()) diff2 = self.check_foreign_keys(self.get_metadata(), self.get_engine()) result = filter(self.remove_unrelated_errors, diff1 + diff2)",3,5
openstack%2Fec2-api~master~I6341a26ad4adf33f09307655f14347a0610e2319,openstack/ec2-api,master,I6341a26ad4adf33f09307655f14347a0610e2319,Made instances work without neutron.,MERGED,2015-01-12 18:43:23.000000000,2015-01-13 09:53:07.000000000,2015-01-13 09:53:07.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-01-12 18:43:23.000000000', 'files': ['ec2api/api/instance.py', 'ec2api/tests/test_instance.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e95c9d60171daee81dd1177d6dc3f7a130a51e92', 'message': 'Made instances work without neutron.\n\n(only run_instances and describe_instances checked so far)\nAdded ec2 classic instance describe unit test.\n\nChange-Id: I6341a26ad4adf33f09307655f14347a0610e2319\n'}]",0,146604,e95c9d60171daee81dd1177d6dc3f7a130a51e92,6,3,1,9312,,,0,"Made instances work without neutron.

(only run_instances and describe_instances checked so far)
Added ec2 classic instance describe unit test.

Change-Id: I6341a26ad4adf33f09307655f14347a0610e2319
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/04/146604/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/instance.py', 'ec2api/tests/test_instance.py']",2,e95c9d60171daee81dd1177d6dc3f7a130a51e92,,"from ec2api.api import instance @mock.patch('ec2api.api.instance.InstanceEngineNeutron.' 'get_vpc_default_security_group_id') def test_run_instances(self, get_vpc_default_security_group_id): instance.instance_engine = ( instance.InstanceEngineNeutron()) get_vpc_default_security_group_id.return_value = None @mock.patch('ec2api.api.instance.InstanceEngineNeutron.' 'get_vpc_default_security_group_id') self, get_vpc_default_security_group_id): instance.instance_engine = ( instance.InstanceEngineNeutron()) get_vpc_default_security_group_id.return_value = None instance.instance_engine = ( instance.InstanceEngineNeutron()) instance.instance_engine = ( instance.InstanceEngineNeutron()) instance.instance_engine = ( instance.InstanceEngineNeutron()) @mock.patch('ec2api.api.instance.security_group_api.' '_format_security_groups_ids_names') def test_describe_instances_ec2_classic(self, format_security_groups_ids_names): instance.instance_engine = ( instance.InstanceEngineNova()) self.db_api.get_items.side_effect = ( lambda _, kind: [fakes.DB_INSTANCE_2] if kind == 'i' else [fakes.DB_IMAGE_1, fakes.DB_IMAGE_2] if kind == 'ami' else []) self.nova_servers.list.return_value = [fakes.OS_INSTANCE_2] instance_get_by_uuid = fakes.get_db_api_get_item_by_id({ fakes.ID_OS_INSTANCE_2: fakes.NOVADB_INSTANCE_2}) self.novadb.instance_get_by_uuid.side_effect = ( lambda context, item_id: instance_get_by_uuid(context, None, item_id)) fake_flavor = self.fake_flavor_class('fake_flavor') self.nova_flavors.get.return_value = fake_flavor format_security_groups_ids_names.return_value = {} self.novadb.block_device_mapping_get_all_by_instance.return_value = [] resp = self.execute('DescribeInstances', {}) self.assertEqual(200, resp['http_status_code']) resp.pop('http_status_code') self.assertThat(resp, matchers.DictMatches( {'reservationSet': [fakes.EC2_RESERVATION_2]}, orderless_lists=True)) instance.instance_engine = ( instance.InstanceEngineNeutron())# TODO(ft): add tests for get_vpc_default_security_group_id"," @mock.patch('ec2api.api.instance._get_vpc_default_security_group_id') def test_run_instances(self, _get_vpc_default_security_group_id): _get_vpc_default_security_group_id.return_value = None @mock.patch('ec2api.api.instance._get_vpc_default_security_group_id') self, _get_vpc_default_security_group_id): _get_vpc_default_security_group_id.return_value = None# TODO(ft): add tests for _get_vpc_default_security_group_id",547,394
openstack%2Fironic-inspector~master~I4de50e666298aedcbeddcac27fe2d1ac74472cbb,openstack/ironic-inspector,master,I4de50e666298aedcbeddcac27fe2d1ac74472cbb,Refactor stable API to be /v1/introspection/<UUID>,MERGED,2015-01-12 14:33:31.000000000,2015-01-13 09:41:45.000000000,2015-01-13 09:41:44.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-01-12 14:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/54a67449196d2ee96b38de6de6f0ba62b0fc2df2', 'message': 'Refactor stable API to be /v1/introspection/<UUID>\n\nAlso:\n* Stop doing bulk-processing of discovery requests\n  Seems like nobody is actually using it and it complicates testing.\n* Rename discover.discover -> introspect\n* Fix one missing retry_on_conflict (found during test refactor)\n* Stop setting unused /extra/discovery_timestamp\n* Refactor tests\n* Keep old API around of compatibility\n\nChange-Id: I4de50e666298aedcbeddcac27fe2d1ac74472cbb\nImplements: blueprint v1-api-reform\n'}, {'number': 2, 'created': '2015-01-12 15:40:42.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/test/base.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/8da4fd576bbc2fd8061249842cd936b0757d84e1', 'message': 'Refactor stable API to be /v1/introspection/<UUID>\n\nAlso:\n* Stop doing bulk-processing of discovery requests\n  Seems like nobody is actually using it and it complicates testing.\n* Rename discover.discover -> introspect\n* Fix one missing retry_on_conflict (found during test refactor)\n* Stop setting unused /extra/discovery_timestamp\n* Refactor tests\n* Keep old API around of compatibility\n\nChange-Id: I4de50e666298aedcbeddcac27fe2d1ac74472cbb\nImplements: blueprint v1-api-reform\n'}]",0,146475,8da4fd576bbc2fd8061249842cd936b0757d84e1,9,3,2,10239,,,0,"Refactor stable API to be /v1/introspection/<UUID>

Also:
* Stop doing bulk-processing of discovery requests
  Seems like nobody is actually using it and it complicates testing.
* Rename discover.discover -> introspect
* Fix one missing retry_on_conflict (found during test refactor)
* Stop setting unused /extra/discovery_timestamp
* Refactor tests
* Keep old API around of compatibility

Change-Id: I4de50e666298aedcbeddcac27fe2d1ac74472cbb
Implements: blueprint v1-api-reform
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/75/146475/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/test/base.py']",5,54a67449196d2ee96b38de6de6f0ba62b0fc2df2,bp/v1-api-reform," self.node = mock.Mock(driver='pxe_ipmitool', driver_info={'ipmi_address': self.bmc_address},"," self.node = mock.Mock(driver_info={'ipmi_address': self.bmc_address},",239,228
openstack%2Ffuel-main~stable%2F5.1~Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,openstack/fuel-main,stable/5.1,Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,Add wait for nodes to get online state after upgrade,MERGED,2015-01-08 14:59:22.000000000,2015-01-13 09:25:32.000000000,2015-01-13 09:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}, {'_account_id': 12867}]","[{'number': 1, 'created': '2015-01-08 14:59:22.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b26a23ed0906adde01accb42827dcd954a45a6da', 'message': 'Add wait for nodes to get online state after upgrade\n\n- Add wait for nodes to get online state after upgrade\nto prevent OSTF failure\n\nChange-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd\nCloses-Bug: #1398825\n(cherry picked from commit de1434ba7810e024afb47610a4a2c57dc47d52cb)\n'}]",0,145804,b26a23ed0906adde01accb42827dcd954a45a6da,9,8,1,10136,,,0,"Add wait for nodes to get online state after upgrade

- Add wait for nodes to get online state after upgrade
to prevent OSTF failure

Change-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd
Closes-Bug: #1398825
(cherry picked from commit de1434ba7810e024afb47610a4a2c57dc47d52cb)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/04/145804/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,b26a23ed0906adde01accb42827dcd954a45a6da,, self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:5]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]),,4,0
openstack%2Ffuel-main~stable%2F6.0~Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,openstack/fuel-main,stable/6.0,Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd,Add wait for nodes to get online state after upgrade,MERGED,2015-01-08 14:59:06.000000000,2015-01-13 09:24:36.000000000,2015-01-13 09:24:35.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}, {'_account_id': 12867}]","[{'number': 1, 'created': '2015-01-08 14:59:06.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f1e063891d2a91cf7f4797ad2b6500c3b2fe959f', 'message': 'Add wait for nodes to get online state after upgrade\n\n- Add wait for nodes to get online state after upgrade\nto prevent OSTF failure\n\nChange-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd\nCloses-Bug: #1398825\n(cherry picked from commit de1434ba7810e024afb47610a4a2c57dc47d52cb)\n'}]",0,145803,f1e063891d2a91cf7f4797ad2b6500c3b2fe959f,9,8,1,10136,,,0,"Add wait for nodes to get online state after upgrade

- Add wait for nodes to get online state after upgrade
to prevent OSTF failure

Change-Id: Ie9714eed49aea7aa6ae06fa9e6285796e070b8fd
Closes-Bug: #1398825
(cherry picked from commit de1434ba7810e024afb47610a4a2c57dc47d52cb)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/03/145803/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,f1e063891d2a91cf7f4797ad2b6500c3b2fe959f,, self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:5]) self.fuel_web.wait_nodes_get_online_state(self.env.nodes().slaves[:3]),,4,0
openstack%2Fmurano~master~I558d738eef6a6158d8bc2a770500525927311a2a,openstack/murano,master,I558d738eef6a6158d8bc2a770500525927311a2a,Fix DSVM gate,ABANDONED,2015-01-12 16:36:59.000000000,2015-01-13 09:05:57.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-01-12 16:36:59.000000000', 'files': ['murano/tests/functional/api/base.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/80779589deda58b9bb14a56111b6f3409b692ae2', 'message': 'Fix DSVM gate\n\nFixes Murano API tests after a change in tempest.\n\nChange-Id: I558d738eef6a6158d8bc2a770500525927311a2a\n'}]",0,146557,80779589deda58b9bb14a56111b6f3409b692ae2,6,4,1,13962,,,0,"Fix DSVM gate

Fixes Murano API tests after a change in tempest.

Change-Id: I558d738eef6a6158d8bc2a770500525927311a2a
",git fetch https://review.opendev.org/openstack/murano refs/changes/57/146557/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/tests/functional/api/base.py'],1,80779589deda58b9bb14a56111b6f3409b692ae2,," def __init__(self, auth_provider, service, region): super(MuranoClient, self).__init__(auth_provider, service, region) self.region = 'RegionOne' mgr.region = 'RegionOne' mgr.service = 'application_catalog' cls.client = MuranoClient(mgr.auth_provider, mgr.service, mgr.region) mgr.region = 'RegionOne' mgr.service = 'application-catalog' cls.alt_client = MuranoClient(mgr.auth_provider, mgr.service, mgr.region)"," def __init__(self, auth_provider): super(MuranoClient, self).__init__(auth_provider) cls.client = MuranoClient(mgr.auth_provider) cls.alt_client = MuranoClient(mgr.auth_provider)",10,4
openstack%2Ffuel-main~master~I3a72802a7728121581e71227b013bb7aeffaf049,openstack/fuel-main,master,I3a72802a7728121581e71227b013bb7aeffaf049,parallel make fixes: add missing dependencies,MERGED,2014-12-25 12:01:51.000000000,2015-01-13 08:52:34.000000000,2015-01-13 08:52:34.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/993040e9de19f0121359a51bc0789457644b6656', 'message': 'packages: be more parellel build friendly\n\nBuild each package in a separate directory so several packages can be\nbuilt in parallel. Note: make -j still fails with this patch due to\nmissing dependencies, these issues will be addressed later on.\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 2, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a1edcccb3ff97e5898482cb0829233aa365a19be', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 3, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/18f67fc215625a24d6daf4584dd8108241cdd0ea', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 4, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7078955f3eb989a9f616d68886e06e354286bf74', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 5, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2a7b897f93a28927998242ff3f3dd41d6a5fb535', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 6, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/646346bda6d5bb2922565873ea6996db4b6fb5c6', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 7, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f156a831a410d832a8bc61947836606ec618e0c0', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 8, 'created': '2015-01-02 15:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/65f898556254bcdb8c62914a95830b116c8bf5c8', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* docker:\n  - start an instance of the simple http server per a container being built,\n    make sure those processes listen the different ports.\n  - fix sporadic build failures due to the HTTP daemon premature exit.\n    The simple_http_daemon which serves RPM repository exits in 600 seconds\n    by default. However a container might require more time (due to a slow\n    machine, a high load, etc), thus the HTTP server might exit before\n    the required packages have been downloaded. Set the default timeout\n    to infinity to prevent such an obscure error.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}, {'number': 9, 'created': '2015-01-13 04:49:18.000000000', 'files': ['repos.mk', 'packages/deb/module.mk', 'packages/module.mk', 'bootstrap/module.mk', 'image/centos/module.mk', 'docker/module.mk', 'utils/simple_http_daemon.py', 'packages/rpm/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b9a580d2c7efbb1817a573c2749aa24d067032d1', 'message': 'parallel make fixes: add missing dependencies\n\n* packages:\n  - build each package in a separate directory so sereral packages can be\n    built in parallel.\n  - prepare_*_source: make sure git repositories are cloned before using\n    them.\n\n* image/centos, bootstrap, docker: add dependency on the locally built\n  nailgun, astute and co. RPMs to make sure RPMs are ready before trying\n  to install them.\n\n* docker:\n  - start an instance of the simple http server per a container being built,\n    make sure those processes listen the different ports.\n  - fix sporadic build failures due to the HTTP daemon premature exit.\n    The simple_http_daemon which serves RPM repository exits in 600 seconds\n    by default. However a container might require more time (due to a slow\n    machine, a high load, etc), thus the HTTP server might exit before\n    the required packages have been downloaded. Set the default timeout\n    to infinity to prevent such an obscure error.\n\n* repos.mk: several repositories can be cloned at the same time, so writes\n  to version.yaml should be serialized. To keep things simple create\n  version.yaml after cloning the repositories (with Fuel components).\n  While at it polish the rule which clones the repository.\n\n* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can\n  run in parallel).\n\nblueprint support-ubuntu-trusty\nChange-Id: I3a72802a7728121581e71227b013bb7aeffaf049\n'}]",5,143972,b9a580d2c7efbb1817a573c2749aa24d067032d1,53,7,9,13194,,,0,"parallel make fixes: add missing dependencies

* packages:
  - build each package in a separate directory so sereral packages can be
    built in parallel.
  - prepare_*_source: make sure git repositories are cloned before using
    them.

* image/centos, bootstrap, docker: add dependency on the locally built
  nailgun, astute and co. RPMs to make sure RPMs are ready before trying
  to install them.

* docker:
  - start an instance of the simple http server per a container being built,
    make sure those processes listen the different ports.
  - fix sporadic build failures due to the HTTP daemon premature exit.
    The simple_http_daemon which serves RPM repository exits in 600 seconds
    by default. However a container might require more time (due to a slow
    machine, a high load, etc), thus the HTTP server might exit before
    the required packages have been downloaded. Set the default timeout
    to infinity to prevent such an obscure error.

* repos.mk: several repositories can be cloned at the same time, so writes
  to version.yaml should be serialized. To keep things simple create
  version.yaml after cloning the repositories (with Fuel components).
  While at it polish the rule which clones the repository.

* packages/rpm, bootstrap: depend only on CentOS repo (more tasks can
  run in parallel).

blueprint support-ubuntu-trusty
Change-Id: I3a72802a7728121581e71227b013bb7aeffaf049
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/72/143972/1 && git format-patch -1 --stdout FETCH_HEAD,"['packages/deb/module.mk', 'packages/rpm/module.mk']",2,993040e9de19f0121359a51bc0789457644b6656,support-ubuntu-trusty," -mount | grep '$(BUILD_DIR)/packages/rpm/SANDBOX' | while read entry do; \ set -- $$entry; \ mntpt=""$$3""; \ sudo umount $$mntpt; \ done$(BUILD_DIR)/packages/rpm/$1.done: SANDBOX:=$(BUILD_DIR)/packages/rpm/SANDBOX/$1", -sudo umount $(BUILD_DIR)/packages/rpm/SANDBOX/proc -sudo umount $(BUILD_DIR)/packages/rpm/SANDBOX/dev$(BUILD_DIR)/packages/rpm/$1.done: SANDBOX:=$(BUILD_DIR)/packages/rpm/SANDBOX,12,6
openstack%2Fnova~master~I9177279a19bb662bd8acc4dc4586438cddd31546,openstack/nova,master,I9177279a19bb662bd8acc4dc4586438cddd31546,libvirt: Add workaround for baselineCPU on system z,ABANDONED,2014-11-26 17:49:51.000000000,2015-01-13 08:52:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 11351}, {'_account_id': 13816}]","[{'number': 1, 'created': '2014-11-26 17:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b59e25f9721fead56a7409107d2e5fad475b52f', 'message': 'Add workaround for libvirt baselineCPU on system z\n\nThe cpu capabilites on system z do NOT return the <model> tag until\n1Q2015. This leads to an ""XML error: Missing CPU model name"" which\nhides the ""not supported"" exception for the baselineCPU call. An added\nrandom model string prevents the XML error and brings the desired ""not\nsupported"" error.\n\nImplements blueprint libvirt-kvm-systemz\n\nChange-Id: I9177279a19bb662bd8acc4dc4586438cddd31546\n'}, {'number': 2, 'created': '2014-11-27 17:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/345a8ad01bf4d0f8a712c6f36ebb70a3d4ade8e3', 'message': 'Add workaround for libvirt baselineCPU on system z\n\nThe cpu capabilites on system z do NOT return the <model> tag until\n1Q2015. This leads to an ""XML error: Missing CPU model name"" which\nhides the ""not supported"" exception for the baselineCPU call. An added\nrandom model string prevents the XML error and brings the desired ""not\nsupported"" error.\n\nPartial-Implements blueprint libvirt-kvm-systemz\n\nChange-Id: I9177279a19bb662bd8acc4dc4586438cddd31546\n'}, {'number': 3, 'created': '2014-12-01 11:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f22f8f04f6a959ba175b7a06195251da65bd3680', 'message': 'Add workaround for libvirt baselineCPU on system z\n\nThe cpu capabilites on system z do NOT return the <model> tag until\n1Q2015. This leads to an ""XML error: Missing CPU model name"" which\nhides the ""not supported"" exception for the baselineCPU call. An added\nfixed model string prevents the XML error and brings the desired ""not\nsupported"" error.\n\nPartial-Implements blueprint libvirt-kvm-systemz\n\nChange-Id: I9177279a19bb662bd8acc4dc4586438cddd31546\n'}, {'number': 4, 'created': '2014-12-01 16:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6174af0f125a4fa0193fbc1b8c008a41f310df92', 'message': 'libvirt: Add workaround for baselineCPU on system z\n\nThe cpu capabilites on system z do NOT return the <model> tag until\n1Q2015. This leads to an ""XML error: Missing CPU model name"" which\nhides the ""not supported"" exception for the baselineCPU call. An added\nfixed model string prevents the XML error and brings the desired ""not\nsupported"" error.\n\nPartial-Implements blueprint libvirt-kvm-systemz\n\nChange-Id: I9177279a19bb662bd8acc4dc4586438cddd31546\n'}, {'number': 5, 'created': '2014-12-03 16:21:37.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/074b576dbe5837085e70e0b8b1e66b17064d02d9', 'message': 'libvirt: Add workaround for baselineCPU on system z\n\nThe cpu capabilites on system z do NOT return the <model> tag until\n1Q2015. This leads to an ""XML error: Missing CPU model name"" which\nhides the ""not supported"" exception for the baselineCPU call. An added\nfixed model string prevents the XML error and brings the desired ""not\nsupported"" error.\n\nPartial-Implements blueprint libvirt-kvm-systemz\n\nChange-Id: I9177279a19bb662bd8acc4dc4586438cddd31546\n'}]",22,137424,074b576dbe5837085e70e0b8b1e66b17064d02d9,72,16,5,11303,,,0,"libvirt: Add workaround for baselineCPU on system z

The cpu capabilites on system z do NOT return the <model> tag until
1Q2015. This leads to an ""XML error: Missing CPU model name"" which
hides the ""not supported"" exception for the baselineCPU call. An added
fixed model string prevents the XML error and brings the desired ""not
supported"" error.

Partial-Implements blueprint libvirt-kvm-systemz

Change-Id: I9177279a19bb662bd8acc4dc4586438cddd31546
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/137424/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,9b59e25f9721fead56a7409107d2e5fad475b52f,bp/libvirt-kvm-systemz," # FIXME(mzoeller): The cpu caps on s390/s390x does NOT # return the <model> tag until 1Q2015. # This leads to an ""XML error: Missing CPU # model name"" which hides the ""not supported"" # exception for the baselineCPU call. This random # model string prevents the XML error and brings # the desired ""not supported"" error. if self._caps.host.cpu.arch in (arch.S390, arch.S390X): self._caps.host.cpu.model = ""z10"" ",,11,0
openstack%2Ffuel-main~master~Id10c13946ce9a7d56d69067772bfd5db012722e4,openstack/fuel-main,master,Id10c13946ce9a7d56d69067772bfd5db012722e4,mirror/ubuntu: use debootstrap instead of multistrap,MERGED,2014-12-30 10:59:18.000000000,2015-01-13 08:51:48.000000000,2015-01-13 08:51:48.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/340b618c2b5b0a8649b0569e915cb2f7563f0a5e', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 2, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/06f4f74a4e8e638aece1a43fb239e9bacc82372b', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 3, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f66ff50385d2707944c769278b92c8ef3bcc66df', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 4, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7cd2e14a79abac0ed18e82ab2c0abb60a44d3896', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 5, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/df24078111920bc4121fc831977b4c9c510c039b', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 6, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f187262f3d7f4bb7aa46f1885c2317d2dafdb116', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 7, 'created': '2015-01-02 15:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/998649dc4f32edf424b9f7296ad595c12e8486ca', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}, {'number': 8, 'created': '2015-01-13 04:49:18.000000000', 'files': ['mirror/ubuntu/multistrap.conf', 'mirror/ubuntu/files/mkrepo.sh', 'mirror/ubuntu/createchroot.mk', 'prepare-build-env.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c83a59b403636e38c46c320d5ca9bdfe21e90e20', 'message': 'mirror/ubuntu: use debootstrap instead of multistrap\n\nThe only purpose of using multistrap was collecting the base packages\nfrom the multiple APT repositories, now this task is done properly with\nAPT itself, so multistrap is not necessary any more.\n\nblueprint support-ubuntu-trusty\n\nDocImpact\nChange-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4\n'}]",0,144438,c83a59b403636e38c46c320d5ca9bdfe21e90e20,48,7,8,13194,,,0,"mirror/ubuntu: use debootstrap instead of multistrap

The only purpose of using multistrap was collecting the base packages
from the multiple APT repositories, now this task is done properly with
APT itself, so multistrap is not necessary any more.

blueprint support-ubuntu-trusty

DocImpact
Change-Id: Id10c13946ce9a7d56d69067772bfd5db012722e4
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/38/144438/1 && git format-patch -1 --stdout FETCH_HEAD,"['mirror/ubuntu/multistrap.conf', 'mirror/ubuntu/files/mkrepo.sh', 'mirror/ubuntu/createchroot.mk', 'prepare-build-env.sh']",4,340b618c2b5b0a8649b0569e915cb2f7563f0a5e,support-ubuntu-trusty, python-pip kpartx extlinux unzip genisoimage \,"# - We also should use multistrap version 2.1.6 from devops mirror # we need multistrap version 2.1.6, let's install it from devops mirror # be sure, that we will not update multistrap in future sudo tee /etc/apt/preferences.d/fuel-pin-300 <<EOF Package: *multistrap* Pin: version 2.1.6* Pin-Priority: 1000 EOF python-pip kpartx extlinux unzip genisoimage multistrap \",52,145
openstack%2Ftaskflow~master~Ied570a25e52de94370b59d844ecdcc6d3551fd3d,openstack/taskflow,master,Ied570a25e52de94370b59d844ecdcc6d3551fd3d,Create and use a multiprocessing sync manager subclass,MERGED,2015-01-13 02:26:32.000000000,2015-01-13 08:51:31.000000000,2015-01-13 08:51:30.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-13 02:26:32.000000000', 'files': ['taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eb536daa0e63aa2e110ac48ff5da65b27b48473c', 'message': 'Create and use a multiprocessing sync manager subclass\n\nInstead of accessing private variables of the manager\nbase class just create a subclass and more nicely expose\nmethods that can be used to introspect the managers state\nand perform actions based on that state.\n\nChange-Id: Ied570a25e52de94370b59d844ecdcc6d3551fd3d\n'}]",0,146739,eb536daa0e63aa2e110ac48ff5da65b27b48473c,10,2,1,1297,,,0,"Create and use a multiprocessing sync manager subclass

Instead of accessing private variables of the manager
base class just create a subclass and more nicely expose
methods that can be used to introspect the managers state
and perform actions based on that state.

Change-Id: Ied570a25e52de94370b59d844ecdcc6d3551fd3d
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/39/146739/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/executor.py'],1,eb536daa0e63aa2e110ac48ff5da65b27b48473c,,"class _ViewableSyncManager(managers.SyncManager): """"""Manager that exposes its state as methods."""""" def is_shutdown(self): return self._state.value == managers.State.SHUTDOWN def is_running(self): return self._state.value == managers.State.STARTED self._manager = _ViewableSyncManager() # These don't seem restartable; make a new one... if self._manager.is_shutdown(): self._manager = _ViewableSyncManager() if not self._manager.is_running():",import multiprocessing self._manager = multiprocessing.Manager() # TODO(harlowja): do something else here besides accessing a state # of the manager internals (it doesn't seem to expose any way to know # this information)... if self._manager._state.value == managers.State.SHUTDOWN: self._manager = multiprocessing.Manager() if self._manager._state.value == managers.State.INITIAL:,15,8
openstack%2Ftricircle~master~Id179b03b5d60af0af8cccfb64a7fad1ca709bf83,openstack/tricircle,master,Id179b03b5d60af0af8cccfb64a7fad1ca709bf83,"add keystoneclient/cinderclient token unauthorized exception caught when cinderClient being generated, b/c this will be helpful to break out from recursion when cinderclient being constructed from invalid user/password",MERGED,2015-01-13 08:34:34.000000000,2015-01-13 08:36:17.000000000,2015-01-13 08:36:17.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2015-01-13 08:34:34.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/22f28d590836fe93f0ba05ff2d5aa5ce1c5f6c00', 'message': 'add keystoneclient/cinderclient token unauthorized exception caught\nwhen cinderClient being generated, b/c this will be helpful to break\nout from recursion when cinderclient being constructed from invalid\nuser/password\n\nChange-Id: Id179b03b5d60af0af8cccfb64a7fad1ca709bf83\n'}]",0,146797,22f28d590836fe93f0ba05ff2d5aa5ce1c5f6c00,6,2,1,13924,,,0,"add keystoneclient/cinderclient token unauthorized exception caught
when cinderClient being generated, b/c this will be helpful to break
out from recursion when cinderclient being constructed from invalid
user/password

Change-Id: Id179b03b5d60af0af8cccfb64a7fad1ca709bf83
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/97/146797/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,22f28d590836fe93f0ba05ff2d5aa5ce1c5f6c00,master,from keystoneclient import exceptions as keystone_exception LOG.error(_('Token unauthorized failed for keystoneclient ' 'constructed when get cascaded admin client')) LOG.error(_('Token unauthorized failed for cascaded ',from keystoneclient import exceptions as keystone_exception LOG.error(_('Token unauthorized failed for keystoneclient' ' constructed when get cascaded admin client')) LOG.error(_('Token unauthorized failed for cascaded',4,4
openstack%2Fnova~master~I0f5cb7cea040ac778189f71a84e80df3874a84ef,openstack/nova,master,I0f5cb7cea040ac778189f71a84e80df3874a84ef,Remove unused XML_WARNING variable in servers API,MERGED,2015-01-08 16:16:44.000000000,2015-01-13 08:30:58.000000000,2015-01-12 23:58:51.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1063}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}]","[{'number': 1, 'created': '2015-01-08 16:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2b935a5835f675e645b96dbe7b9df5e77fae133', 'message': ""Remove unused XML_WARNING variable in servers API\n\nXML support was removed but this variable wasn't removed with it, so\nit's not unused and we can remove it also.\n\nChange-Id: I0f5cb7cea040ac778189f71a84e80df3874a84ef\n""}, {'number': 2, 'created': '2015-01-08 18:28:34.000000000', 'files': ['nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5e4ccef737a9d49b01e2bc9f8d3a70a0ea61c166', 'message': ""Remove unused XML_WARNING variable in servers API\n\nXML support was removed but this variable wasn't removed with it, so\nit's not used and we can remove it also.\n\nChange-Id: I0f5cb7cea040ac778189f71a84e80df3874a84ef\n""}]",3,145822,5e4ccef737a9d49b01e2bc9f8d3a70a0ea61c166,33,13,2,6873,,,0,"Remove unused XML_WARNING variable in servers API

XML support was removed but this variable wasn't removed with it, so
it's not used and we can remove it also.

Change-Id: I0f5cb7cea040ac778189f71a84e80df3874a84ef
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/145822/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/servers.py'],1,e2b935a5835f675e645b96dbe7b9df5e77fae133,rm-xml-warn,,XML_WARNING = False ,0,2
openstack%2Ffuel-plugins~master~I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc,openstack/fuel-plugins,master,I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc,Fuel HA Fencing plugin for puppet,MERGED,2014-12-30 09:44:12.000000000,2015-01-13 08:25:22.000000000,2015-01-13 08:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-30 09:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/53f443ee101eeaaebb50478021aa371a20c5d70c', 'message': 'Fuel HA Fencing plugin for puppet\n\nAll documentation provided in README.md\n\nImplements blueprint fencing-in-puppet-manifests\n\n* Use Fuel corosync from 5.1.1\n* Add cluster-recheck-interval 3 min setting\n* Add parser functions and facts from Fuel library\n* Add pre-build hook for dependencies:\n  * puppetlabs/stdlib v 4.5.0\n  * Fuel corosync v 5.1.1\n* Add examples of YAML for fence_virsh, fence_ipmilan,\n  fence_apc_snmp and fence topology\n\nChange-Id: I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2014-12-30 09:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/f66a7610455abd3605746ed95f86e9a9dd4d90f0', 'message': 'Fuel HA Fencing plugin for puppet\n\nAll documentation provided in README.md\n\nImplements blueprint fencing-in-puppet-manifests\n\n* Use Fuel corosync from 5.1.1\n* Add cluster-recheck-interval 3 min setting\n* Add parser functions and facts from Fuel library\n* Add pre-build hook for dependencies:\n  * puppetlabs/stdlib v 4.5.0\n  * Fuel corosync v 5.1.1\n* Add examples of YAML for fence_virsh, fence_ipmilan,\n  fence_apc_snmp and fence topology\n\nDocImpact: new plugin for HA fencing (Fuel 6.0)\n\nChange-Id: I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2014-12-30 12:11:07.000000000', 'files': ['ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/LICENSE', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/provider/cs_fencetopo/crm.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/pacemaker_hostname.rb', 'ha_fencing/pre_build_hook', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/fixtures/cib/cib_no_topo.xml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/.fixtures.yml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/fencing_config.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/examples/pcs_fencing.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/filter_nodes.rb', 'ha_fencing/metadata.yaml', 'ha_fencing/environment_config.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/.gitignore', 'ha_fencing/deployment_scripts/puppet/manifests/site.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/test/site.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/classes/fencing_primitives_spec.rb', 'ha_fencing/LICENSE', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/type/cs_fencetopo.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/provider/corosync.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/unit/puppet/provider/cs_fencetopo/crm_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Gemfile', 'ha_fencing/tasks.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/defines/fencing_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/examples/pcs_fencing_virsh.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/spec_helper.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/README.md', 'ha_fencing/repositories/ubuntu/.gitkeep', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/naily.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Rakefile', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/unit/puppet/type/cs_fencetopo_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/manifests/fencing.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Gemfile.lock', 'ha_fencing/.gitignore', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/parseyaml.rb', 'ha_fencing/README.md', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/filter_hash.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/manifests/fencing_primitives.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/metadata.json', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/fixtures/cib/cib.xml', 'ha_fencing/repositories/centos/.gitkeep'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/7d428893f45c1b5555cee934371b5f71ef1e2ac7', 'message': 'Fuel HA Fencing plugin for puppet\n\nAll documentation provided in README.md\n\nImplements blueprint fencing-in-puppet-manifests\n\n* Use Fuel corosync from 5.1.1\n* Add cluster-recheck-interval 3 min setting\n* Add parser functions and facts from Fuel library\n* Add pre-build hook for dependencies:\n  * puppetlabs/stdlib v 4.5.0\n  * Fuel corosync v 5.1.1\n* Add examples of YAML for fence_virsh, fence_ipmilan,\n  fence_apc_snmp and fence topology\n\nChange-Id: I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",1,144425,7d428893f45c1b5555cee934371b5f71ef1e2ac7,21,11,3,6926,,,0,"Fuel HA Fencing plugin for puppet

All documentation provided in README.md

Implements blueprint fencing-in-puppet-manifests

* Use Fuel corosync from 5.1.1
* Add cluster-recheck-interval 3 min setting
* Add parser functions and facts from Fuel library
* Add pre-build hook for dependencies:
  * puppetlabs/stdlib v 4.5.0
  * Fuel corosync v 5.1.1
* Add examples of YAML for fence_virsh, fence_ipmilan,
  fence_apc_snmp and fence topology

Change-Id: I15dc9ff747957f7d22ca3ccd12628423c3c5c8cc
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/25/144425/2 && git format-patch -1 --stdout FETCH_HEAD,"['ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/LICENSE', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/provider/cs_fencetopo/crm.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/pacemaker_hostname.rb', 'ha_fencing/pre_build_hook', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/fixtures/cib/cib_no_topo.xml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/.fixtures.yml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/fencing_config.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/examples/pcs_fencing.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/filter_nodes.rb', 'ha_fencing/metadata.yaml', 'ha_fencing/environment_config.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/.gitignore', 'ha_fencing/deployment_scripts/puppet/manifests/site.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/test/site.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/classes/fencing_primitives_spec.rb', 'ha_fencing/LICENSE', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/type/cs_fencetopo.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/provider/corosync.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/unit/puppet/provider/cs_fencetopo/crm_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Gemfile', 'ha_fencing/tasks.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/defines/fencing_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/examples/pcs_fencing_virsh.yaml', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/spec_helper.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/README.md', 'ha_fencing/repositories/ubuntu/.gitkeep', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/facter/naily.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Rakefile', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/unit/puppet/type/cs_fencetopo_spec.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/manifests/fencing.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/Gemfile.lock', 'ha_fencing/.gitignore', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/parseyaml.rb', 'ha_fencing/README.md', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/lib/puppet/parser/functions/filter_hash.rb', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/manifests/fencing_primitives.pp', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/metadata.json', 'ha_fencing/deployment_scripts/puppet/modules/pcs_fencing/spec/fixtures/cib/cib.xml', 'ha_fencing/repositories/centos/.gitkeep']",39,53f443ee101eeaaebb50478021aa371a20c5d70c,bp/fencing-in-puppet-manifests,,,2083,0
openstack%2Ftaskflow~master~I9a1852427bae22a01f5993862617e384f10ec005,openstack/taskflow,master,I9a1852427bae22a01f5993862617e384f10ec005,Include docstrings for parallel engine types/strings supported,MERGED,2015-01-10 22:25:36.000000000,2015-01-13 08:22:19.000000000,2015-01-13 08:22:18.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-10 22:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a55bba11ba1f59aeb7288d6655b868618ed2d600', 'message': ""Include docstrings for parallel engine types/strings supported\n\nWhen a 'executor' option is passed to a action engine requested\nto run in parallel mode that option will internally be examined\nand it will affect the internally used execution model that the\nengine will use; to make it understandable what the valid options\nare include a docstring + table(s) that describes the options and\nthere valid values.\n\nChange-Id: I9a1852427bae22a01f5993862617e384f10ec005\n""}, {'number': 2, 'created': '2015-01-10 22:39:02.000000000', 'files': ['taskflow/engines/action_engine/engine.py', 'doc/source/engines.rst', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2f7d86ac3e606c144f78d1dfa7190cdb0e9c306d', 'message': ""Include docstrings for parallel engine types/strings supported\n\nWhen a 'executor' option is passed to a action engine requested\nto run in parallel mode that option will internally be examined\nand it will affect the internally used execution model that the\nengine will use; to make it understandable what the valid options\nare include a docstring + table(s) that describes the options and\nthere valid values.\n\nChange-Id: I9a1852427bae22a01f5993862617e384f10ec005\n""}]",0,146287,2f7d86ac3e606c144f78d1dfa7190cdb0e9c306d,7,2,2,1297,,,0,"Include docstrings for parallel engine types/strings supported

When a 'executor' option is passed to a action engine requested
to run in parallel mode that option will internally be examined
and it will affect the internally used execution model that the
engine will use; to make it understandable what the valid options
are include a docstring + table(s) that describes the options and
there valid values.

Change-Id: I9a1852427bae22a01f5993862617e384f10ec005
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/87/146287/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/engine.py', 'doc/source/engines.rst', 'taskflow/engines/action_engine/executor.py']",3,a55bba11ba1f59aeb7288d6655b868618ed2d600,, #: Options this executor supports (passed in from engine options). #: Options this executor supports (passed in from engine options).,,44,12
openstack%2Ftaskflow~master~Ia6d0f2be4dd7cd161ef7b6d8afc32aab532fd69b,openstack/taskflow,master,Ia6d0f2be4dd7cd161ef7b6d8afc32aab532fd69b,Fix for job consumption example using wrong object,MERGED,2015-01-07 20:28:42.000000000,2015-01-13 08:22:11.000000000,2015-01-13 08:22:08.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-07 20:28:42.000000000', 'files': ['doc/source/jobs.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a18a939aae1dff42a4741a1852829abe5280aa80', 'message': 'Fix for job consumption example using wrong object\n\nChange job consumption example in Job documentation to use\npersistence.get_connection().destroy_logbook() instead of\npersistence.destroy_logbook()\n\nChange-Id: Ia6d0f2be4dd7cd161ef7b6d8afc32aab532fd69b\nCloses-Bug: 1408434\n'}]",0,145574,a18a939aae1dff42a4741a1852829abe5280aa80,7,2,1,10584,,,0,"Fix for job consumption example using wrong object

Change job consumption example in Job documentation to use
persistence.get_connection().destroy_logbook() instead of
persistence.destroy_logbook()

Change-Id: Ia6d0f2be4dd7cd161ef7b6d8afc32aab532fd69b
Closes-Bug: 1408434
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/74/145574/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/jobs.rst'],1,a18a939aae1dff42a4741a1852829abe5280aa80,bug/1408434, persistence.get_connection().destroy_logbook(my_job.book.uuid), persistence.destroy_logbook(my_job.book.uuid),1,1
openstack%2Ftaskflow~master~Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0,openstack/taskflow,master,Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0,Add split time capturing to the stop watch,MERGED,2015-01-13 03:59:05.000000000,2015-01-13 08:22:01.000000000,2015-01-13 08:22:01.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-13 03:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/225d3944066a6704917f69f86ff2b4ae95643960', 'message': 'Add split time capturing to the stop watch\n\nFor cases where it is useful to capture the elapsed time\nof a watch and later examine those split times create a\nmethod on the stop watch that allows for these kinds of\ncaptures and iterations that correspond to the common stop\nwatch split capability.\n\nChange-Id: Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0\n'}, {'number': 2, 'created': '2015-01-13 04:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c3bc152f555c3574f16c2c275c72f29db0c5c1d9', 'message': 'Add split time capturing to the stop watch\n\nFor cases where it is useful to capture the elapsed time\nof a watch and later examine those split times create a\nmethod on the stop watch that allows for these kinds of\ncaptures and iterations that correspond to the common stop\nwatch split capability.\n\nAlso adds basic docstrings to the stop watch public\nmethods so that people know what they are and can use them.\n\nChange-Id: Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0\n'}, {'number': 3, 'created': '2015-01-13 04:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7b8d1b7a500903d237e68b9922f3eb74eaac3a6b', 'message': 'Add split time capturing to the stop watch\n\nFor cases where it is useful to capture the elapsed time\nof a watch and later examine those split times create a\nmethod on the stop watch that allows for these kinds of\ncaptures and iterations that correspond to the common stop\nwatch split capability.\n\nAlso adds basic docstrings to the stop watch public\nmethods so that people know what they are and can use them.\n\nChange-Id: Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0\n'}, {'number': 4, 'created': '2015-01-13 04:40:33.000000000', 'files': ['taskflow/types/timing.py', 'taskflow/tests/unit/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fe99ba7106c4de5655c40c28d175e136ddd29d2', 'message': 'Add split time capturing to the stop watch\n\nFor cases where it is useful to capture the elapsed time\nof a watch and later examine those split times create a\nmethod on the stop watch that allows for these kinds of\ncaptures and iterations that correspond to the common stop\nwatch split capability.\n\nAlso adds basic docstrings to the stop watch public\nmethods so that people know what they are and can use them.\n\nChange-Id: Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0\n'}]",0,146752,9fe99ba7106c4de5655c40c28d175e136ddd29d2,9,2,4,1297,,,0,"Add split time capturing to the stop watch

For cases where it is useful to capture the elapsed time
of a watch and later examine those split times create a
method on the stop watch that allows for these kinds of
captures and iterations that correspond to the common stop
watch split capability.

Also adds basic docstrings to the stop watch public
methods so that people know what they are and can use them.

Change-Id: Ic52ae5dfcca9a117ccd0dda5cc62a14c09e15ce0
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/52/146752/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/timing.py'],1,225d3944066a6704917f69f86ff2b4ae95643960,," self._splits = [] def __iter__(self): """"""Iterates over all split times that have been captured."""""" return iter(self._splits) def split(self): """"""Captures a split/elapsed since start time (and doesn't stop)."""""" if self._state == self._STARTED: self._splits.append(self.elapsed()) return self._splits[-1] else: raise RuntimeError(""Can not create a split time of a stopwatch"" "" if it has not been started"") ",,14,0
openstack%2Ftaskflow~master~Icc533ed4d4c94f461b7f19600b74146221f17b18,openstack/taskflow,master,Icc533ed4d4c94f461b7f19600b74146221f17b18,Use platform neutral line separator(s),MERGED,2015-01-11 21:05:30.000000000,2015-01-13 08:21:44.000000000,2015-01-13 08:21:43.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-11 21:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5ae6dcfef87f3b073441127d295b5394a9912992', 'message': ""Use platform neutral line separator in table type\n\nTo at least try to support things like windows it's better\nif we can make an attempt to use the platform neutral\ncharacters for line separator(s); to start doing this make\nusage of that in the table type.\n\nChange-Id: Icc533ed4d4c94f461b7f19600b74146221f17b18\n""}, {'number': 2, 'created': '2015-01-11 22:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/24f1032e20ad8a0744b38e85ec20ce6b097e640c', 'message': ""Use platform neutral line separator(s)\n\nTo at least try to support things like windows it's better\nif we can make an attempt to use the platform neutral\ncharacters for line separator(s) where appropriate.\n\nChange-Id: Icc533ed4d4c94f461b7f19600b74146221f17b18\n""}, {'number': 3, 'created': '2015-01-12 02:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3ab4d82e0f00940d4174ccdffe2ba6c14286355b', 'message': ""Use platform neutral line separator(s)\n\nTo at least try to support things like windows it's better\nif we can make an attempt to use the platform neutral\ncharacters for line separator(s) where appropriate.\n\nChange-Id: Icc533ed4d4c94f461b7f19600b74146221f17b18\n""}, {'number': 4, 'created': '2015-01-13 04:34:28.000000000', 'files': ['taskflow/types/table.py', 'taskflow/types/graph.py', 'taskflow/utils/persistence_utils.py', 'taskflow/types/tree.py', 'taskflow/types/failure.py', 'taskflow/listeners/claims.py', 'taskflow/listeners/logging.py', 'taskflow/exceptions.py', 'taskflow/utils/misc.py', 'taskflow/engines/worker_based/worker.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/42a665d06f5a75672417a28375ca4e1988365aa8', 'message': ""Use platform neutral line separator(s)\n\nTo at least try to support things like windows it's better\nif we can make an attempt to use the platform neutral\ncharacters for line separator(s) where appropriate.\n\nChange-Id: Icc533ed4d4c94f461b7f19600b74146221f17b18\n""}]",0,146347,42a665d06f5a75672417a28375ca4e1988365aa8,13,2,4,1297,,,0,"Use platform neutral line separator(s)

To at least try to support things like windows it's better
if we can make an attempt to use the platform neutral
characters for line separator(s) where appropriate.

Change-Id: Icc533ed4d4c94f461b7f19600b74146221f17b18
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/47/146347/4 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/types/table.py'],1,5ae6dcfef87f3b073441127d295b5394a9912992,,import os LINE_SEP = os.linesep content_buf.write(self.LINE_SEP) content_buf.write(self.LINE_SEP) content_buf.write(self.LINE_SEP) content_buf.write(self.LINE_SEP) content_buf.write(self.LINE_SEP)," content_buf.write(""\n"") content_buf.write(""\n"") content_buf.write(""\n"") content_buf.write(""\n"") content_buf.write(""\n"")",7,5
openstack%2Ftricircle~master~I038a1ea15c3f18e1b83a3da6a798ba69a523ead7,openstack/tricircle,master,I038a1ea15c3f18e1b83a3da6a798ba69a523ead7,add token authorized exception caught when cinder client being generated,MERGED,2015-01-13 08:14:26.000000000,2015-01-13 08:19:32.000000000,2015-01-13 08:19:32.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2015-01-13 08:14:26.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/f295bfbc32e51a3d7254708f301ddee1612477f5', 'message': 'add token authorized exception caught when cinder client being generated\n\nwhen cinder client unauthorized, exception will be caught and will break\nout from recursion.\n\nChange-Id: I038a1ea15c3f18e1b83a3da6a798ba69a523ead7\n'}]",0,146792,f295bfbc32e51a3d7254708f301ddee1612477f5,6,2,1,13924,,,0,"add token authorized exception caught when cinder client being generated

when cinder client unauthorized, exception will be caught and will break
out from recursion.

Change-Id: I038a1ea15c3f18e1b83a3da6a798ba69a523ead7
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/92/146792/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,f295bfbc32e51a3d7254708f301ddee1612477f5,master,from keystoneclient import exceptions as keystone_exception return cinderclient except keystone_exception.Unauthorized: with excutils.save_and_reraise_exception(): LOG.error(_('Token unauthorized failed for keystoneclient' ' constructed when get cascaded admin client')) except cinder_exception.Unauthorized: with excutils.save_and_reraise_exception(): LOG.error(_('Token unauthorized failed for cascaded' 'cinderClient constructed')) except Exception: with excutils.save_and_reraise_exception(): LOG.error(_('Failed to query volumes by pagination.')) except Exception: with excutils.save_and_reraise_exception(): LOG.error(_('Failed to query snapshots by all tenant.')), return cinderclient except cinder_exception.Unauthorized: self.adminCinderClient = self._get_cinder_cascaded_admin_client(),17,5
openstack%2Fpython-openstackclient~master~I4be717979bd4371bc544312d556934aef4f3a629,openstack/python-openstackclient,master,I4be717979bd4371bc544312d556934aef4f3a629,Updated from global requirements,MERGED,2015-01-13 00:15:55.000000000,2015-01-13 07:50:10.000000000,2015-01-13 07:50:09.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-01-13 00:15:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fa84566dac0b16bb02438521b0787c495ff8db6b', 'message': 'Updated from global requirements\n\nChange-Id: I4be717979bd4371bc544312d556934aef4f3a629\n'}]",0,146709,fa84566dac0b16bb02438521b0787c495ff8db6b,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4be717979bd4371bc544312d556934aef4f3a629
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/09/146709/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,fa84566dac0b16bb02438521b0787c495ff8db6b,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fheat~master~I1f065b1e219207a69b9c721703221945c93d69ac,openstack/heat,master,I1f065b1e219207a69b9c721703221945c93d69ac,Split tests for AWS/OS waitconditions,MERGED,2014-12-23 08:45:22.000000000,2015-01-13 07:48:40.000000000,2015-01-13 07:48:39.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}]","[{'number': 1, 'created': '2014-12-23 08:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a2a71c2e4b053a0423da9abd62f6c0a10db396f', 'message': 'Split tests for AWS/OS waitconditions\n\nMove the OS waitconditions tests to\nheat/tests/test_os_waitcondition.py\n\nChange-Id: I1f065b1e219207a69b9c721703221945c93d69ac\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 2, 'created': '2014-12-24 07:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/88e39bce788a9fbc1cd515b9318c79f561ab1aa9', 'message': 'Split tests for AWS/OS waitconditions\n\nMove the OS waitconditions tests to\nheat/tests/openstack/test_waitcondition.py\nand move the AWS waitconditions tests to\nheat/tests/aws/test_waitcondition.py.\n\nChange-Id: I1f065b1e219207a69b9c721703221945c93d69ac\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 3, 'created': '2014-12-26 03:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e8311ff68d43ca7b0881952973de619af6ba782f', 'message': 'Split tests for AWS/OS waitconditions\n\nMove the OS waitconditions tests to\nheat/tests/openstack/test_waitcondition.py\nand move the AWS waitconditions tests to\nheat/tests/aws/test_waitcondition.py.\n\nChange-Id: I1f065b1e219207a69b9c721703221945c93d69ac\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 4, 'created': '2015-01-13 03:42:44.000000000', 'files': ['heat/tests/aws/test_waitcondition.py', 'heat/tests/openstack/test_waitcondition.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9fadfa4a7dbd5287e5766ce5c07decaf349c13ad', 'message': 'Split tests for AWS/OS waitconditions\n\nMove the OS waitconditions tests to\nheat/tests/openstack/test_waitcondition.py\nand move the AWS waitconditions tests to\nheat/tests/aws/test_waitcondition.py.\n\nChange-Id: I1f065b1e219207a69b9c721703221945c93d69ac\nImplements: blueprint decouple-aws-os-resources\n'}]",0,143626,9fadfa4a7dbd5287e5766ce5c07decaf349c13ad,19,5,4,8289,,,0,"Split tests for AWS/OS waitconditions

Move the OS waitconditions tests to
heat/tests/openstack/test_waitcondition.py
and move the AWS waitconditions tests to
heat/tests/aws/test_waitcondition.py.

Change-Id: I1f065b1e219207a69b9c721703221945c93d69ac
Implements: blueprint decouple-aws-os-resources
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/143626/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_waitcondition.py', 'heat/tests/test_os_waitcondition.py']",2,4a2a71c2e4b053a0423da9abd62f6c0a10db396f,bp/decouple-aws-os-resources,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six import time import uuid from heat.common import identifier from heat.common import template_format from heat.db import api as db_api from heat.engine.clients.os import heat_plugin from heat.engine import environment from heat.engine import parser from heat.engine import resource from heat.engine.resources.openstack import wait_condition_handle as heat_wch from heat.engine import scheduler from heat.tests import common from heat.tests import utils test_template_heat_waitcondition = ''' heat_template_version: 2013-05-23 resources: wait_condition: type: OS::Heat::WaitCondition properties: handle: {get_resource: wait_handle} timeout: 5 wait_handle: type: OS::Heat::WaitConditionHandle ''' test_template_heat_waitcondition_count = ''' heat_template_version: 2013-05-23 resources: wait_condition: type: OS::Heat::WaitCondition properties: handle: {get_resource: wait_handle} count: 3 timeout: 5 wait_handle: type: OS::Heat::WaitConditionHandle ''' test_template_heat_waithandle = ''' heat_template_version: 2013-05-23 resources: wait_handle: type: OS::Heat::WaitConditionHandle ''' test_template_update_waithandle = ''' heat_template_version: 2013-05-23 resources: update_wait_handle: type: OS::Heat::UpdateWaitConditionHandle ''' class HeatWaitConditionTest(common.HeatTestCase): def setUp(self): super(HeatWaitConditionTest, self).setUp() self.stub_keystoneclient() self.tenant_id = 'test_tenant' def create_stack(self, stack_id=None, template=test_template_heat_waitcondition_count, params={}, stub=True, stub_status=True): temp = template_format.parse(template) template = parser.Template(temp) ctx = utils.dummy_context(tenant_id=self.tenant_id) stack = parser.Stack(ctx, 'test_stack', template, environment.Environment(params), disable_rollback=True) # Stub out the stack ID so we have a known value if stack_id is None: stack_id = str(uuid.uuid4()) self.stack_id = stack_id with utils.UUIDStub(self.stack_id): stack.store() if stub: id = identifier.ResourceIdentifier('test_tenant', stack.name, stack.id, '', 'wait_handle') self.m.StubOutWithMock(heat_wch.HeatWaitConditionHandle, 'identifier') heat_wch.HeatWaitConditionHandle.\ identifier().MultipleTimes().AndReturn(id) if stub_status: self.m.StubOutWithMock(heat_wch.HeatWaitConditionHandle, 'get_status') return stack def test_post_complete_to_handle(self): self.stack = self.create_stack() heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS']) heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS', 'SUCCESS']) heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS', 'SUCCESS', 'SUCCESS']) self.m.ReplayAll() self.stack.create() rsrc = self.stack['wait_condition'] self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) r = db_api.resource_get_by_name_and_stack(None, 'wait_handle', self.stack.id) self.assertEqual('wait_handle', r.name) self.m.VerifyAll() def test_post_failed_to_handle(self): self.stack = self.create_stack() heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS']) heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS', 'SUCCESS']) heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS', 'SUCCESS', 'FAILURE']) self.m.ReplayAll() self.stack.create() rsrc = self.stack['wait_condition'] self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) reason = rsrc.status_reason self.assertTrue(reason.startswith('WaitConditionFailure:')) r = db_api.resource_get_by_name_and_stack(None, 'wait_handle', self.stack.id) self.assertEqual('wait_handle', r.name) self.m.VerifyAll() def test_timeout(self): st = time.time() self.stack = self.create_stack() # Avoid the stack create exercising the timeout code at the same time self.m.StubOutWithMock(self.stack, 'timeout_secs') self.stack.timeout_secs().MultipleTimes().AndReturn(None) self.m.StubOutWithMock(scheduler, 'wallclock') scheduler.wallclock().AndReturn(st) scheduler.wallclock().AndReturn(st + 0.001) scheduler.wallclock().AndReturn(st + 0.1) heat_wch.HeatWaitConditionHandle.get_status().AndReturn([]) scheduler.wallclock().AndReturn(st + 4.1) heat_wch.HeatWaitConditionHandle.get_status().AndReturn([]) scheduler.wallclock().AndReturn(st + 5.1) self.m.ReplayAll() self.stack.create() rsrc = self.stack['wait_condition'] self.assertEqual((rsrc.CREATE, rsrc.FAILED), rsrc.state) reason = rsrc.status_reason self.assertTrue(reason.startswith('WaitConditionTimeout:')) self.m.VerifyAll() def _create_heat_wc_and_handle(self): self.stack = self.create_stack( template=test_template_heat_waitcondition) heat_wch.HeatWaitConditionHandle.get_status().AndReturn(['SUCCESS']) self.m.ReplayAll() self.stack.create() rsrc = self.stack['wait_condition'] self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) wc_att = rsrc.FnGetAtt('data') self.assertEqual(six.text_type({}), wc_att) handle = self.stack['wait_handle'] self.assertEqual((handle.CREATE, handle.COMPLETE), handle.state) return (rsrc, handle) def test_data(self): rsrc, handle = self._create_heat_wc_and_handle() test_metadata = {'data': 'foo', 'reason': 'bar', 'status': 'SUCCESS', 'id': '123'} ret = handle.handle_signal(details=test_metadata) wc_att = rsrc.FnGetAtt('data') self.assertEqual('{""123"": ""foo""}', wc_att) self.assertEqual('status:SUCCESS reason:bar', ret) test_metadata = {'data': 'dog', 'reason': 'cat', 'status': 'SUCCESS', 'id': '456'} ret = handle.handle_signal(details=test_metadata) wc_att = rsrc.FnGetAtt('data') self.assertEqual(u'{""123"": ""foo"", ""456"": ""dog""}', wc_att) self.assertEqual('status:SUCCESS reason:cat', ret) self.m.VerifyAll() def test_data_noid(self): rsrc, handle = self._create_heat_wc_and_handle() test_metadata = {'data': 'foo', 'reason': 'bar', 'status': 'SUCCESS'} ret = handle.handle_signal(details=test_metadata) wc_att = rsrc.FnGetAtt('data') self.assertEqual('{""1"": ""foo""}', wc_att) self.assertEqual('status:SUCCESS reason:bar', ret) test_metadata = {'data': 'dog', 'reason': 'cat', 'status': 'SUCCESS'} ret = handle.handle_signal(details=test_metadata) wc_att = rsrc.FnGetAtt('data') self.assertEqual(u'{""1"": ""foo"", ""2"": ""dog""}', wc_att) self.assertEqual('status:SUCCESS reason:cat', ret) self.m.VerifyAll() def test_data_nodata(self): rsrc, handle = self._create_heat_wc_and_handle() ret = handle.handle_signal() expected = 'status:SUCCESS reason:Signal 1 received' self.assertEqual(expected, ret) wc_att = rsrc.FnGetAtt('data') self.assertEqual('{""1"": null}', wc_att) handle.handle_signal() wc_att = rsrc.FnGetAtt('data') self.assertEqual(u'{""1"": null, ""2"": null}', wc_att) self.m.VerifyAll() def test_data_partial_complete(self): rsrc, handle = self._create_heat_wc_and_handle() test_metadata = {'status': 'SUCCESS'} ret = handle.handle_signal(details=test_metadata) expected = 'status:SUCCESS reason:Signal 1 received' self.assertEqual(expected, ret) wc_att = rsrc.FnGetAtt('data') self.assertEqual('{""1"": null}', wc_att) test_metadata = {'status': 'SUCCESS'} ret = handle.handle_signal(details=test_metadata) expected = 'status:SUCCESS reason:Signal 2 received' self.assertEqual(expected, ret) wc_att = rsrc.FnGetAtt('data') self.assertEqual(u'{""1"": null, ""2"": null}', wc_att) self.m.VerifyAll() def _create_heat_handle(self): self.stack = self.create_stack( template=test_template_heat_waithandle, stub_status=False) self.m.ReplayAll() self.stack.create() handle = self.stack['wait_handle'] self.assertEqual((handle.CREATE, handle.COMPLETE), handle.state) return handle def test_get_status_none_complete(self): handle = self._create_heat_handle() ret = handle.handle_signal() expected = 'status:SUCCESS reason:Signal 1 received' self.assertEqual(expected, ret) self.assertEqual(['SUCCESS'], handle.get_status()) md_expected = {'1': {'data': None, 'reason': 'Signal 1 received', 'status': 'SUCCESS'}} self.assertEqual(md_expected, handle.metadata_get()) self.m.VerifyAll() def test_get_status_partial_complete(self): handle = self._create_heat_handle() test_metadata = {'status': 'SUCCESS'} ret = handle.handle_signal(details=test_metadata) expected = 'status:SUCCESS reason:Signal 1 received' self.assertEqual(expected, ret) self.assertEqual(['SUCCESS'], handle.get_status()) md_expected = {'1': {'data': None, 'reason': 'Signal 1 received', 'status': 'SUCCESS'}} self.assertEqual(md_expected, handle.metadata_get()) self.m.VerifyAll() def test_get_status_failure(self): handle = self._create_heat_handle() test_metadata = {'status': 'FAILURE'} ret = handle.handle_signal(details=test_metadata) expected = 'status:FAILURE reason:Signal 1 received' self.assertEqual(expected, ret) self.assertEqual(['FAILURE'], handle.get_status()) md_expected = {'1': {'data': None, 'reason': 'Signal 1 received', 'status': 'FAILURE'}} self.assertEqual(md_expected, handle.metadata_get()) self.m.VerifyAll() def test_getatt_token(self): handle = self._create_heat_handle() self.assertEqual('adomainusertoken', handle.FnGetAtt('token')) self.m.VerifyAll() def test_getatt_endpoint(self): self.m.StubOutWithMock(heat_plugin.HeatClientPlugin, 'get_heat_url') heat_plugin.HeatClientPlugin.get_heat_url().AndReturn( 'foo/%s' % self.tenant_id) self.m.ReplayAll() handle = self._create_heat_handle() expected = ('foo/aprojectid/stacks/test_stack/%s/resources/' 'wait_handle/signal' % self.stack_id) self.assertEqual(expected, handle.FnGetAtt('endpoint')) self.m.VerifyAll() def test_getatt_curl_cli(self): self.m.StubOutWithMock(heat_plugin.HeatClientPlugin, 'get_heat_url') heat_plugin.HeatClientPlugin.get_heat_url().AndReturn( 'foo/%s' % self.tenant_id) self.m.ReplayAll() handle = self._create_heat_handle() expected = (""curl -i -X POST -H 'X-Auth-Token: adomainusertoken' "" ""-H 'Content-Type: application/json' "" ""-H 'Accept: application/json' "" ""foo/aprojectid/stacks/test_stack/%s/resources/wait_handle"" ""/signal"" % self.stack_id) self.assertEqual(expected, handle.FnGetAtt('curl_cli')) self.m.VerifyAll() def test_create_update_updatehandle(self): self.stack = self.create_stack( template=test_template_update_waithandle, stub_status=False) self.m.ReplayAll() self.stack.create() handle = self.stack['update_wait_handle'] self.assertEqual((handle.CREATE, handle.COMPLETE), handle.state) self.assertRaises( resource.UpdateReplace, handle.update, None, None) ",,358,353
openstack%2Ffuel-plugins~master~I3e56798dfaf5d81e33e09b107ea55900c9a3a7fe,openstack/fuel-plugins,master,I3e56798dfaf5d81e33e09b107ea55900c9a3a7fe,Adds links to README.md file,ABANDONED,2014-12-19 13:00:29.000000000,2015-01-13 07:47:40.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-19 13:00:29.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/31deea56d880b6db3f635fefaadd5ab3ff583d03', 'message': 'Adds links to README.md file\n\nChange-Id: I3e56798dfaf5d81e33e09b107ea55900c9a3a7fe\n'}]",0,143076,31deea56d880b6db3f635fefaadd5ab3ff583d03,6,2,1,13082,,,0,"Adds links to README.md file

Change-Id: I3e56798dfaf5d81e33e09b107ea55900c9a3a7fe
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/76/143076/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,31deea56d880b6db3f635fefaadd5ab3ff583d03,upd-README-links,"Beginning with Mirantis OpenStack 6.0, the deployment manager, Fuel, features the ability to install plug-ins when you deploy your environment. Fuel plug-ins allow you to install and configure additional capabilities for your cloud, such as additional storage types and networking functionality. For example, a Load Balancing as a Service (LBaaS) plug-in allows you to add network load balancing functionality to your cloud so that incoming traffic can be spread across multiple nodes. Or you might want to use a GlusterFS plug-in so that you can use a Gluster file system as backend storage for blocks (Cinder).* *fuel_plugin_example* - simple Fuel plug-in example that shows how you can create a plug-in. It deploys simple service on your Controller nodes. * *lbaas* - Fuel plug-in that provides [Neutron LBaaS](https://wiki.openstack.org/wiki/Neutron/LBaaS/PluginDrivers ""Neutron LBaaS"") for multi-node mode. * *external_glusterfs* - Fuel plug-in that allows to use existing [GlusterFS](http://www.gluster.org/documentation/About_Gluster/ ""GlusterFS"") cluster as the Cinder backend. For instructions on creating your plug-in, see <ADD LINK TO PLUG-IN DEV GUIDE> For instructions on installing plug-ins, see [Mirantis Plug-ins Catalog]( https://software.mirantis.com/fuel-plugins/ ""Mirantis Plug-ins Catalog""). For built development plug-in versions, see [Fuel CI job]( https://fuel-jenkins.mirantis.com/job/stackforge-master-fuel-plugins/ ""Fuel CI job"")","Starting with version 6.0, Fuel supports Pluggable architecture. Currently, Cinder and Neutron plugins are available.* *fuel_plugin_example* - simple Fuel plugin example that shows how you can create a plugin. It deploys simple service on your Controller nodes. * *lbaas* - Fuel plugin that provides [Neutron LBaaS](https://wiki.openstack.org/wiki/Neutron/LBaaS/PluginDrivers ""Neutron LBaaS"") for multinode mode. * *external_glusterfs* - Fuel plugin that allows to use existing [GlusterFS](http://www.gluster.org/documentation/About_Gluster/ ""GlusterFS"") cluster as the Cinder backend. For instructions on creating your plugin, see <link> For instructions on installing your plugin, see <link> For production plugin versions, see <link> For built development plugin versions, see [Fuel CI job]( https://fuel-jenkins.mirantis.com/job/stackforge-master-fuel-plugins/ ""Fuel CI job"")",10,9
openstack%2Fpython-openstackclient~master~I6db798d272ff416a77f169c0e912d2096fa02504,openstack/python-openstackclient,master,I6db798d272ff416a77f169c0e912d2096fa02504,Command doc: policy,MERGED,2015-01-10 07:43:41.000000000,2015-01-13 07:45:22.000000000,2015-01-13 07:45:22.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-01-10 07:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/13ea6c76abf5d67ba2881963c516b6890c448223', 'message': 'Command doc: policy\n\nChange-Id: I6db798d272ff416a77f169c0e912d2096fa02504\n'}, {'number': 2, 'created': '2015-01-12 21:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/660c10bbc204da0713832d52fc56d97f91a1e41e', 'message': ""Command doc: policy\n\nAlso tweaked a bunch of the code to not show 'blob', but 'rules'\ninstead.\n\nChange-Id: I6db798d272ff416a77f169c0e912d2096fa02504\n""}, {'number': 3, 'created': '2015-01-13 02:59:56.000000000', 'files': ['doc/source/commands.rst', 'doc/source/command-objects/policy.rst', 'openstackclient/identity/v3/policy.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/673e0d88ffc299230823204793eb4b4a18a37530', 'message': ""Command doc: policy\n\nAlso tweaked a bunch of the code to not show 'blob', but 'rules'\ninstead.\n\nChange-Id: I6db798d272ff416a77f169c0e912d2096fa02504\n""}]",8,146270,673e0d88ffc299230823204793eb4b4a18a37530,22,4,3,6482,,,0,"Command doc: policy

Also tweaked a bunch of the code to not show 'blob', but 'rules'
instead.

Change-Id: I6db798d272ff416a77f169c0e912d2096fa02504
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/70/146270/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/commands.rst', 'doc/source/command-objects/policy.rst', 'openstackclient/identity/v3/policy.py']",3,13ea6c76abf5d67ba2881963c516b6890c448223,policy_stuff," """"""Create new policy"""""" metavar='<type>', help='New MIME type of the policy blob ' '(defaults to application/json)', 'blob', metavar='<filename>', help='New set of policy rules, as a serialized blob', blob = utils.read_blob_file_contents(parsed_args.blob) """"""Delete policy"""""" metavar='<policy>', help='Policy to delete', """"""List policies"""""" help='List additional fields in output', """"""Set policy properties"""""" metavar='<policy>', help='Policy to modify', help='New MIME type of the policy blob', '--blob', metavar='<filename>', help='New set of policy rules, as a serialized blob', if parsed_args.blob: blob = utils.read_blob_file_contents(parsed_args.blob) """"""Display policy details"""""" help='Policy to display',"," """"""Create policy command"""""" metavar='<policy-type>', help='New MIME type of the policy blob - i.e.: application/json', 'blob_file', metavar='<blob-file>', help='New policy rule set itself, as a serialized blob, in a file', blob = utils.read_blob_file_contents(parsed_args.blob_file) """"""Delete policy command"""""" metavar='<policy-id>', help='ID of policy to delete', """"""List policy command"""""" help='Additional fields are listed in output', """"""Set policy command"""""" metavar='<policy-id>', help='ID of policy to change', help='New MIME Type of the policy blob - i.e.: application/json', '--blob-file', metavar='<blob_file>', help='New policy rule set itself, as a serialized blob, in a file', if parsed_args.blob_file: blob = utils.read_blob_file_contents(parsed_args.blob_file) """"""Show policy command"""""" help='ID of policy to display',",121,24
openstack%2Fpython-openstackclient~master~Id7f8b48bdf99773ad55ca7f204f3c779f84633d5,openstack/python-openstackclient,master,Id7f8b48bdf99773ad55ca7f204f3c779f84633d5,Tweaks to the catalog doc and show command,MERGED,2015-01-10 04:45:51.000000000,2015-01-13 07:45:16.000000000,2015-01-13 07:45:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-10 04:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/224e6d991b9f9be7cdf3ed3abfb66078e3e229a2', 'message': ""Tweaks to the catalog doc and show command\n\nLooks like providing a service id isn't working, so it the help\nmessage was reduced to just type and name.\nAdded a bit more to the docs, too.\n\nChange-Id: Id7f8b48bdf99773ad55ca7f204f3c779f84633d5\n""}, {'number': 2, 'created': '2015-01-12 03:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/207f5d7fa1bfb64dab916bbec48daf0c375979cd', 'message': ""Tweaks to the catalog doc and show command\n\nLooks like providing a service id isn't working, so it the help\nmessage was reduced to just type and name.\nAdded a bit more to the docs, too.\n\nChange-Id: Id7f8b48bdf99773ad55ca7f204f3c779f84633d5\n""}, {'number': 3, 'created': '2015-01-12 03:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5b9a7940a268e13379755ad2977b3ed8ec44b494', 'message': ""Tweaks to the catalog doc and show command\n\nLooks like providing a service id isn't working, so it the help\nmessage was reduced to just type and name.\nAdded a bit more to the docs, too.\n\nChange-Id: Id7f8b48bdf99773ad55ca7f204f3c779f84633d5\n""}, {'number': 4, 'created': '2015-01-13 05:59:38.000000000', 'files': ['openstackclient/identity/v2_0/catalog.py', 'doc/source/command-objects/catalog.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c04b49ef07defdecadcf614d9ff4cde4b3dd029b', 'message': ""Tweaks to the catalog doc and show command\n\nLooks like providing a service id isn't working, so it the help\nmessage was reduced to just type and name.\nAdded a bit more to the docs, too.\n\nChange-Id: Id7f8b48bdf99773ad55ca7f204f3c779f84633d5\n""}]",7,146262,c04b49ef07defdecadcf614d9ff4cde4b3dd029b,15,5,4,6482,,,0,"Tweaks to the catalog doc and show command

Looks like providing a service id isn't working, so it the help
message was reduced to just type and name.
Added a bit more to the docs, too.

Change-Id: Id7f8b48bdf99773ad55ca7f204f3c779f84633d5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/62/146262/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/catalog.py', 'doc/source/command-objects/catalog.rst']",2,224e6d991b9f9be7cdf3ed3abfb66078e3e229a2,doc_catalog_better,.. program:: catalog list .. describe:: <service> Service to display (type or name),,11,1
openstack%2Fpython-openstackclient~master~I47dfa8ee23ac5c41b355796415eb515155832f65,openstack/python-openstackclient,master,I47dfa8ee23ac5c41b355796415eb515155832f65,Fine tune some of the helps commands,MERGED,2015-01-09 23:53:49.000000000,2015-01-13 07:41:49.000000000,2015-01-13 07:41:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-09 23:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/dc9b2cebd9f80276100181ae3deb6343d3411f9d', 'message': 'Fine tuning small changes\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n'}, {'number': 2, 'created': '2015-01-10 00:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cef5614139597721de74dfbe658961f22febcb48', 'message': 'Fine tuning small changes\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n'}, {'number': 3, 'created': '2015-01-10 00:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/88a9350fe8c2bd6b5419e32104eaaf29ff7324a1', 'message': 'Fine tune some of the helps commands\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n'}, {'number': 4, 'created': '2015-01-10 00:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/05fde91b46fabc670cf59b01c9cdbc0e4837df7e', 'message': ""Fine tune some of the helps commands\n\ntry and add some consistency with the show and delete commands.\n\nreplace 'show x' with 'display x'\nchange 'delete a y' with just 'delete y'\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n""}, {'number': 5, 'created': '2015-01-12 03:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e7557953a61b41fb9815ab6205a676b9976fe302', 'message': ""Fine tune some of the helps commands\n\ntry and add some consistency with the show and delete commands.\n\nreplace 'show x' with 'display x'\nchange 'delete a y' with just 'delete y'\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n""}, {'number': 6, 'created': '2015-01-13 05:59:04.000000000', 'files': ['openstackclient/identity/v2_0/catalog.py', 'doc/source/command-objects/mapping.rst', 'openstackclient/identity/v2_0/user.py', 'openstackclient/identity/v3/project.py', 'openstackclient/identity/v3/federation_protocol.py', 'openstackclient/identity/v3/service.py', 'openstackclient/identity/v3/identity_provider.py', 'openstackclient/object/v1/object.py', 'doc/source/command-objects/identity-provider.rst', 'doc/source/command-objects/project.rst', 'openstackclient/object/v1/container.py', 'doc/source/command-objects/user.rst', 'doc/source/command-objects/consumer.rst', 'doc/source/command-objects/region.rst', 'openstackclient/identity/v3/role.py', 'doc/source/command-objects/catalog.rst', 'doc/source/command-objects/aggregate.rst', 'doc/source/command-objects/object.rst', 'openstackclient/compute/v2/aggregate.py', 'openstackclient/identity/v3/user.py', 'openstackclient/identity/v2_0/role.py', 'doc/source/command-objects/domain.rst', 'openstackclient/compute/v2/flavor.py', 'openstackclient/identity/v3/region.py', 'doc/source/command-objects/flavor.rst', 'openstackclient/identity/v2_0/project.py', 'doc/source/command-objects/role.rst', 'openstackclient/identity/v2_0/service.py', 'doc/source/command-objects/container.rst', 'openstackclient/identity/v3/consumer.py', 'doc/source/command-objects/keypair.rst', 'openstackclient/identity/v3/mapping.py', 'openstackclient/compute/v2/keypair.py', 'doc/source/command-objects/federation-protocol.rst', 'openstackclient/identity/v3/domain.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/019c155e9b308dab002f23064b969452bc3d7a89', 'message': ""Fine tune some of the helps commands\n\ntry and add some consistency with the show and delete commands.\n\nreplace 'show x' with 'display x'\nchange 'delete a y' with just 'delete y'\n\nChange-Id: I47dfa8ee23ac5c41b355796415eb515155832f65\n""}]",8,146226,019c155e9b308dab002f23064b969452bc3d7a89,21,5,6,6482,,,0,"Fine tune some of the helps commands

try and add some consistency with the show and delete commands.

replace 'show x' with 'display x'
change 'delete a y' with just 'delete y'

Change-Id: I47dfa8ee23ac5c41b355796415eb515155832f65
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/26/146226/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/catalog.py', 'doc/source/command-objects/limits.rst', 'doc/source/command-objects/mapping.rst', 'openstackclient/identity/v2_0/user.py', 'openstackclient/identity/v3/project.py', 'openstackclient/identity/v3/federation_protocol.py', 'openstackclient/identity/v3/service.py', 'openstackclient/identity/v3/identity_provider.py', 'openstackclient/object/v1/object.py', 'doc/source/command-objects/identity-provider.rst', 'doc/source/command-objects/project.rst', 'openstackclient/object/v1/container.py', 'doc/source/command-objects/credentials.rst', 'doc/source/command-objects/user.rst', 'doc/source/command-objects/consumer.rst', 'openstackclient/identity/v3/role.py', 'doc/source/command-objects/aggregate.rst', 'doc/source/command-objects/object.rst', 'openstackclient/compute/v2/aggregate.py', 'openstackclient/identity/v3/user.py', 'doc/source/command-objects/server-image.rst', 'openstackclient/identity/v2_0/role.py', 'doc/source/command-objects/domain.rst', 'openstackclient/compute/v2/flavor.py', 'openstackclient/identity/v3/region.py', 'doc/source/command-objects/quota.rst', 'doc/source/command-objects/flavor.rst', 'doc/source/command-objects/console-url.rst', 'openstackclient/identity/v2_0/project.py', 'doc/source/command-objects/role.rst', 'openstackclient/identity/v2_0/service.py', 'doc/source/command-objects/console-log.rst', 'doc/source/command-objects/container.rst', 'doc/source/command-objects/server.rst', 'openstackclient/identity/v3/consumer.py', 'doc/source/command-objects/keypair.rst', 'openstackclient/identity/v3/mapping.py', 'openstackclient/compute/v2/keypair.py', 'doc/source/command-objects/federation-protocol.rst', 'doc/source/command-objects/user-role.rst', 'openstackclient/identity/v3/domain.py']",41,dc9b2cebd9f80276100181ae3deb6343d3411f9d,another," """"""Display domain details"""""""," """"""Show domain details""""""",70,43
openstack%2Fheat-translator~master~I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498,openstack/heat-translator,master,I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498,Add new tosca blockstorage template,ABANDONED,2014-09-19 03:12:25.000000000,2015-01-13 07:33:25.000000000,,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7193}, {'_account_id': 10856}, {'_account_id': 11349}, {'_account_id': 11602}]","[{'number': 1, 'created': '2014-09-19 03:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/06f331d1576d2a413f0129053cc8efb794d21771', 'message': 'Add new tosca blockstorage template\n\nImplement new notation style of Blockstorage attachto Node.\n1.Add example template of new notetion type described in Tosca wd03 F1.3.\n2.Change example file name of exsisted example file.\n\nChange-Id: I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498\n'}, {'number': 2, 'created': '2014-09-19 03:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/194922202ec070e4eeedbbbbd81bd462e32a2208', 'message': 'Add new tosca blockstorage template\n\nImplement new notation style of Blockstorage attachto Node.\n1.Add example template of new notetion type described in Tosca wd03 F1.3.\n2.Change example file name of exsisted example file.\n\nImplements: blueprint new-blockstorage-templates-tosca\n\nChange-Id: I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498\n'}, {'number': 3, 'created': '2014-09-19 06:08:07.000000000', 'files': ['translator/toscalib/nodetemplate.py', 'translator/tests/data/tosca_blockstorage_with_attachment_notation2.yaml', 'translator/tests/test_blockstorage.py', 'translator/tests/data/tosca_blockstorage_with_attachment_notation1.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/6f529d1cd7bb784ef2ca3f6a84142eec150e2984', 'message': 'Add new tosca blockstorage template\n\nImplement new notation style of Blockstorage attachto Node.\n1.Add example template of new notetion type described in Tosca wd03 F1.3.\n2.Change file name of exsisted example file.\n\nImplements: blueprint new-blockstorage-templates-tosca\n\nChange-Id: I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498\n'}]",1,122594,6f529d1cd7bb784ef2ca3f6a84142eec150e2984,9,6,3,10818,,,0,"Add new tosca blockstorage template

Implement new notation style of Blockstorage attachto Node.
1.Add example template of new notetion type described in Tosca wd03 F1.3.
2.Change file name of exsisted example file.

Implements: blueprint new-blockstorage-templates-tosca

Change-Id: I9eb4e22fb117aa6eeef6da2a4fab467cdd37d498
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/94/122594/3 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/nodetemplate.py', 'translator/tests/data/tosca_blockstorage_with_attachment_notation2.yaml', 'translator/tests/test_blockstorage.py', 'translator/tests/data/tosca_blockstorage_with_attachment_notation1.yaml']",4,06f331d1576d2a413f0129053cc8efb794d21771,bp/new-blockstorage-templates-tosca,,,102,14
openstack%2Fheat~master~I2f7d34058356d381ffbf4f580316c9593492402c,openstack/heat,master,I2f7d34058356d381ffbf4f580316c9593492402c,Split wait condition handle into separate files,MERGED,2014-12-05 02:48:22.000000000,2015-01-13 07:27:03.000000000,2015-01-13 07:27:02.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-05 02:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb2f3370ba3a127806ba8dbff13a95c81c0e88a9', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::WaitConditionHandle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 2, 'created': '2014-12-05 03:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5aac2ee9272ce005527791c2e9c7532a5db2a80', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::WaitConditionHandle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 3, 'created': '2014-12-08 04:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1d912dd7e85a821935014196f51947b9d46ec98e', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::WaitConditionHandle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 4, 'created': '2014-12-09 07:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f2915a330831c09d3d2006109c02b1b03e389ed6', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 5, 'created': '2014-12-10 04:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5d7288da15aa24b71ee5ee1d0cc1b050e689e845', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 6, 'created': '2014-12-11 03:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/18eabc6a23aaa82e95675a92d18630c289b0b81b', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 7, 'created': '2014-12-12 09:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10d9bc8ac7528447b7d6c70b2569e3753b3ee47c', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 8, 'created': '2014-12-12 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/13a8507750c756042c52704800e0abf2155a32f1', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 9, 'created': '2014-12-23 02:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a4ae3df62ad541dee90cadd4aa5f32f9b12e0b8f', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 10, 'created': '2014-12-24 07:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bca5351debceee411a9650b180b5a566755058c1', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 11, 'created': '2014-12-26 03:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bf62ce3c8ee9479f3595dc0ca51ea0c44738a37a', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 12, 'created': '2015-01-13 03:11:33.000000000', 'files': ['heat/tests/test_metadata_refresh.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/engine/resources/aws/wait_condition_handle.py', 'heat/engine/resources/aws/wait_condition.py', 'heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py', 'heat/engine/resources/openstack/wait_condition_handle.py', 'heat/tests/test_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7588fdbb262295593201bee8b6b69ba60094acfa', 'message': 'Split wait condition handle into separate files\n\nMove OS::Heat::*Handle resource to\n/resources/openstack/wait_condition_handle.py and move\nAWS::CloudFormation::WaitConditionHandle resource to\n/resources/aws/wait_condition_handle.py.\n\nChange-Id: I2f7d34058356d381ffbf4f580316c9593492402c\nImplements: blueprint decouple-aws-os-resources\n'}]",0,139303,7588fdbb262295593201bee8b6b69ba60094acfa,48,9,12,8289,,,0,"Split wait condition handle into separate files

Move OS::Heat::*Handle resource to
/resources/openstack/wait_condition_handle.py and move
AWS::CloudFormation::WaitConditionHandle resource to
/resources/aws/wait_condition_handle.py.

Change-Id: I2f7d34058356d381ffbf4f580316c9593492402c
Implements: blueprint decouple-aws-os-resources
",git fetch https://review.opendev.org/openstack/heat refs/changes/03/139303/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_metadata_refresh.py', 'heat/engine/resources/openstack/update_wait_condition_handle.py', 'heat/engine/resources/aws/wait_condition_handle.py', 'heat/tests/test_autoscaling_update_policy.py', 'heat/tests/test_waitcondition.py', 'heat/engine/resources/wait_condition.py', 'heat/engine/resources/openstack/wait_condition_handle.py', 'heat/tests/test_loadbalancer.py']",8,cb2f3370ba3a127806ba8dbff13a95c81c0e88a9,bp/decouple-aws-os-resources,"from heat.engine.resources.aws import wait_condition_handle as aws_wch self.m.StubOutWithMock(aws_wch.WaitConditionHandle, 'get_status') aws_wch.WaitConditionHandle.get_status().AndReturn(['SUCCESS'])","from heat.engine.resources import wait_condition as wc self.m.StubOutWithMock(wc.WaitConditionHandle, 'get_status') wc.WaitConditionHandle.get_status().AndReturn(['SUCCESS'])",312,250
openstack%2Fproject-config~master~I7ed7e6eb8225a29c06245b8056ad4495b3136679,openstack/project-config,master,I7ed7e6eb8225a29c06245b8056ad4495b3136679,Reduce number of services running in large-ops,MERGED,2015-01-09 20:07:35.000000000,2015-01-13 07:19:58.000000000,2015-01-13 07:19:57.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5196}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-09 20:07:35.000000000', 'files': ['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3b8f2eb4a7ab1bf2326c00b971d85986889f067f', 'message': ""Reduce number of services running in large-ops\n\nAdd the change to large-ops-testing from 73e4d13d145029fecb42913500a15e348fbf7eef\nto large-ops. This change worked in the expermental queue as part of the\nlarge-ops-testing jobs.\n\nThe large-ops test is hitting mysql's default connection limit of 151\nperiodically. Even services at rest can make DB calls, so stop running\nservices that aren't in use.\n\nChange-Id: I7ed7e6eb8225a29c06245b8056ad4495b3136679\nRelated-Bug: #1403284\n""}]",0,146192,3b8f2eb4a7ab1bf2326c00b971d85986889f067f,9,5,1,1849,,,0,"Reduce number of services running in large-ops

Add the change to large-ops-testing from 73e4d13d145029fecb42913500a15e348fbf7eef
to large-ops. This change worked in the expermental queue as part of the
large-ops-testing jobs.

The large-ops test is hitting mysql's default connection limit of 151
periodically. Even services at rest can make DB calls, so stop running
services that aren't in use.

Change-Id: I7ed7e6eb8225a29c06245b8056ad4495b3136679
Related-Bug: #1403284
",git fetch https://review.opendev.org/openstack/project-config refs/changes/92/146192/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,3b8f2eb4a7ab1bf2326c00b971d85986889f067f,bug/1403284," export DEVSTACK_GATE_NO_SERVICES=1 export ENABLED_SERVICES=n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key,n-net export DEVSTACK_GATE_NO_SERVICES=1 export ENABLED_SERVICES=n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,g-api,g-reg,key",,4,3
openstack%2Fhorizon~master~I35dd828f13cb69eae059f9e4bbbca9beefecf053,openstack/horizon,master,I35dd828f13cb69eae059f9e4bbbca9beefecf053,removed reference to angular-cookies,ABANDONED,2015-01-12 12:32:37.000000000,2015-01-13 07:19:49.000000000,,"[{'_account_id': 3}, {'_account_id': 7665}]","[{'number': 1, 'created': '2015-01-12 12:32:37.000000000', 'files': ['horizon/templates/horizon/_scripts.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/eccf67b132eabc2b2a1cd68c18d49e63e030bb92', 'message': 'removed reference to angular-cookies\n\nChange-Id: I35dd828f13cb69eae059f9e4bbbca9beefecf053\nCloses-Bug: 1409706\n'}]",0,146446,eccf67b132eabc2b2a1cd68c18d49e63e030bb92,8,2,1,4264,,,0,"removed reference to angular-cookies

Change-Id: I35dd828f13cb69eae059f9e4bbbca9beefecf053
Closes-Bug: 1409706
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/146446/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/_scripts.html'],1,eccf67b132eabc2b2a1cd68c18d49e63e030bb92,bug/1409706,,<script src='{{ STATIC_URL }}horizon/lib/angular/angular-cookies.js' type='text/javascript' charset='utf-8'></script>,0,1
openstack%2Fheat~master~I35d8615c5294950a07ba1318eb0108699179e591,openstack/heat,master,I35d8615c5294950a07ba1318eb0108699179e591,Split wait condition into separate files,MERGED,2014-12-04 09:05:54.000000000,2015-01-13 07:18:31.000000000,2015-01-13 07:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-04 09:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/72d963e7a41af3b3f38b0c23055ac1d49d15991f', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 2, 'created': '2014-12-04 09:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d132be3ff7af976ac5f0eb849d5c0c75f04d91c8', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 3, 'created': '2014-12-04 10:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fc639d94154c33bc80ab6272197cc222771bc27a', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 4, 'created': '2014-12-04 10:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b1f4a75a080f1016017f20b8c962b6aca9f0cf9e', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 5, 'created': '2014-12-05 02:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5be2eca868224e4755f2a7f02bc783555284587', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 6, 'created': '2014-12-08 04:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5583f0b9f05ab80d2dd7aa54557c100b52fbf3b', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 7, 'created': '2014-12-09 03:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/925f57c99cf1cb3914ddabd78a1b68e9c2d83b46', 'message': 'Reorganize WaitConditions code\n\nDecouple AWS and OS WaitConditions resources.\nMove OS resources to /heat/engine/resources/openstack\n/wait_condition.py and move AWS resources to\n/heat/engine/resources/aws/wait_condition.py.\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 8, 'created': '2014-12-09 07:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/22be9a7558211e7c10509d2d0ddf8c313879cd77', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 9, 'created': '2014-12-10 03:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/80a43480c558682c62fed9b0ce7d6e7b496521e2', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 10, 'created': '2014-12-10 08:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa1054d957f8097024bcb59088ec421c6ec42c9c', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 11, 'created': '2014-12-11 03:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e989349be3d3f824cf6278656fd20ec2e3fdeef', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint reorg-wait-condition-code\n'}, {'number': 12, 'created': '2014-12-12 09:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7aea93abbc63007af26b139265129f070d039272', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 13, 'created': '2014-12-12 09:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b5ed8d750967837c2ecc01bbec7fb42597bb3544', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 14, 'created': '2014-12-23 01:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/721bb21d0e7de5d86ebd67311cc421864dc9020b', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 15, 'created': '2014-12-24 07:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3b7768f5536e5a4a5813324817f749cb9ee3dc74', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 16, 'created': '2014-12-26 03:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/03e7c629191168f33e9c811371651daa32964a47', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 17, 'created': '2015-01-13 02:04:19.000000000', 'files': ['heat/engine/resources/aws/wait_condition.py', 'heat/tests/test_notifications.py', 'heat/engine/resources/wait_condition.py', 'heat/engine/resources/openstack/wait_condition.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c2bf586880807005fd8e762177988a38a85ef736', 'message': 'Split wait condition into separate files\n\nMove OS::Heat::WaitCondition resource to\n/resources/openstack/wait_condition.py and move\nAWS::CloudFormation::WaitCondition resource to\n/resources/aws/wait_condition.py\n\nChange-Id: I35d8615c5294950a07ba1318eb0108699179e591\nImplements: blueprint decouple-aws-os-resources\n'}]",0,138993,c2bf586880807005fd8e762177988a38a85ef736,64,12,17,8289,,,0,"Split wait condition into separate files

Move OS::Heat::WaitCondition resource to
/resources/openstack/wait_condition.py and move
AWS::CloudFormation::WaitCondition resource to
/resources/aws/wait_condition.py

Change-Id: I35d8615c5294950a07ba1318eb0108699179e591
Implements: blueprint decouple-aws-os-resources
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/138993/16 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/aws/wait_condition.py', 'heat/engine/resources/wait_condition.py', 'heat/engine/resources/openstack/wait_condition.py']",3,72d963e7a41af3b3f38b0c23055ac1d49d15991f,bp/decouple-aws-os-resources,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json from heat.common.i18n import _ from heat.common.i18n import _LI from heat.engine import attributes from heat.engine import constraints from heat.engine import properties from heat.engine import resource from heat.engine.resources import wait_condition as wc_base from heat.engine import scheduler from heat.openstack.common import log as logging LOG = logging.getLogger(__name__) class HeatWaitCondition(resource.Resource): PROPERTIES = ( HANDLE, TIMEOUT, COUNT, ) = ( 'handle', 'timeout', 'count', ) ATTRIBUTES = ( DATA, ) = ( 'data', ) properties_schema = { HANDLE: properties.Schema( properties.Schema.STRING, _('A reference to the wait condition handle used to signal this ' 'wait condition.'), required=True ), TIMEOUT: properties.Schema( properties.Schema.NUMBER, _('The number of seconds to wait for the correct number of ' 'signals to arrive.'), required=True, constraints=[ constraints.Range(1, 43200), ] ), COUNT: properties.Schema( properties.Schema.NUMBER, _('The number of success signals that must be received before ' 'the stack creation process continues.'), constraints=[ constraints.Range(min=1), ], default=1, update_allowed=True ), } attributes_schema = { DATA: attributes.Schema( _('JSON serialized dict containing data associated with wait ' 'condition signals sent to the handle.'), cache_mode=attributes.Schema.CACHE_NONE ), } def __init__(self, name, definition, stack): super(HeatWaitCondition, self).__init__(name, definition, stack) def _get_handle_resource(self): return self.stack.resource_by_refid(self.properties[self.HANDLE]) def _wait(self, handle): while True: try: yield except scheduler.Timeout: timeout = wc_base.WaitConditionTimeout(self, handle) LOG.info(_LI('%(name)s Timed out (%(timeout)s)'), {'name': str(self), 'timeout': str(timeout)}) raise timeout handle_status = handle.get_status() if any(s != handle.STATUS_SUCCESS for s in handle_status): failure = wc_base.WaitConditionFailure(self, handle) LOG.info(_LI('%(name)s Failed (%(failure)s)'), {'name': str(self), 'failure': str(failure)}) raise failure if len(handle_status) >= self.properties[self.COUNT]: LOG.info(_LI(""%s Succeeded""), str(self)) return def handle_create(self): handle = self._get_handle_resource() runner = scheduler.TaskRunner(self._wait, handle) runner.start(timeout=float(self.properties[self.TIMEOUT])) return runner def check_create_complete(self, runner): return runner.step() def handle_update(self, json_snippet, tmpl_diff, prop_diff): if prop_diff: self.properties = json_snippet.properties(self.properties_schema, self.context) handle = self._get_handle_resource() runner = scheduler.TaskRunner(self._wait, handle) runner.start(timeout=float(self.properties[self.TIMEOUT])) return runner def check_update_complete(self, runner): return runner.step() def handle_delete(self): handle = self._get_handle_resource() if handle: handle.metadata_set({}) def _resolve_attribute(self, key): handle = self._get_handle_resource() if key == self.DATA: meta = handle.metadata_get(refresh=True) # Note, can't use a dict generator on python 2.6, hence: res = dict([(k, meta[k][handle.DATA]) for k in meta]) LOG.debug('%(name)s.GetAtt(%(key)s) == %(res)s' % {'name': self.name, 'key': key, 'res': res}) return unicode(json.dumps(res)) def resource_mapping(): return { 'OS::Heat::WaitCondition': HeatWaitCondition, } ",,268,212
openstack%2Fopenstack-manuals~master~I4b4bb75064129e07473cbbb9dd46b921ceddac85,openstack/openstack-manuals,master,I4b4bb75064129e07473cbbb9dd46b921ceddac85,Imported Translations from Transifex,MERGED,2015-01-13 06:14:18.000000000,2015-01-13 07:15:08.000000000,2015-01-13 07:15:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-01-13 06:14:18.000000000', 'files': ['doc/install-guide/locale/pt_BR.po', 'doc/networking-guide/locale/networking-guide.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/71e86e7dad94229415deb2034b13aa1a4a8d78b6', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4b4bb75064129e07473cbbb9dd46b921ceddac85\n'}]",0,146769,71e86e7dad94229415deb2034b13aa1a4a8d78b6,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I4b4bb75064129e07473cbbb9dd46b921ceddac85
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/146769/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/pt_BR.po', 'doc/networking-guide/locale/networking-guide.pot', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/common/locale/ja.po', 'doc/common/locale/fr.po']",6,71e86e7dad94229415deb2034b13aa1a4a8d78b6,transifex/translations,"""POT-Creation-Date: 2015-01-12 20:28+0000\n"" ""PO-Revision-Date: 2015-01-12 20:28+0000\n""#: ./doc/common/section_getstart_compute.xml24(term) msgid ""<systemitem class=\""service\"">nova-api</systemitem> service""","""POT-Creation-Date: 2015-01-08 20:45+0000\n"" ""PO-Revision-Date: 2015-01-08 20:44+0000\n""#: ./doc/common/section_getstart_compute.xml24(systemitem) msgid ""nova-api service""",54,54
openstack%2Ftaskflow~master~I1e1ab6c708c855e5868061bc338d399a38ad954e,openstack/taskflow,master,I1e1ab6c708c855e5868061bc338d399a38ad954e,Use a single sender,MERGED,2015-01-13 02:26:19.000000000,2015-01-13 07:13:39.000000000,2015-01-13 07:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-13 02:26:19.000000000', 'files': ['taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4c756ef852d62239f07d8dfbf6773512e92053c0', 'message': 'Use a single sender\n\nInstead of register many different senders (one for each needed\nproxy notification type) just use a single sender for all the\ndifferent types to save space and time when the senders are\npickled across to the worker(s).\n\nChange-Id: I1e1ab6c708c855e5868061bc338d399a38ad954e\n'}]",0,146738,4c756ef852d62239f07d8dfbf6773512e92053c0,6,2,1,1297,,,0,"Use a single sender

Instead of register many different senders (one for each needed
proxy notification type) just use a single sender for all the
different types to save space and time when the senders are
pickled across to the worker(s).

Change-Id: I1e1ab6c708c855e5868061bc338d399a38ad954e
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/38/146738/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/executor.py'],1,4c756ef852d62239f07d8dfbf6773512e92053c0,," if needed: sender = _EventSender(channel) for event_type in needed: clone.notifier.register(event_type, sender)"," for event_type in needed: clone.notifier.register(event_type, _EventSender(channel))",4,2
openstack%2Fmistral~master~I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4,openstack/mistral,master,I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4,Fix mistralclient initialization,MERGED,2015-01-12 11:01:57.000000000,2015-01-13 06:57:04.000000000,2015-01-13 06:57:02.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-01-12 11:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2d18ba1607b5ee526528f0e53620ac1b3de1206e', 'message': 'Fix mistralclient initialization\n\nChange-Id: I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4\n'}, {'number': 2, 'created': '2015-01-12 12:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2c4cff41a720567513f77ee9639753c068c35acf', 'message': 'Fix mistralclient initialization\n\nChange-Id: I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4\n'}, {'number': 3, 'created': '2015-01-12 13:45:30.000000000', 'files': ['mistral/tests/functional/api/v1/test_workflow_execution.py', 'mistral/tests/functional/api/v1/test_mistral_basic.py', 'mistral/tests/functional/base.py', 'mistral/tests/functional/api/v2/test_mistral_basic_v2.py', 'mistral/tests/functional/engine/actions/test_openstack_actions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/fa0bbe08426abf6323ef5e76b5d570b7b8144f59', 'message': 'Fix mistralclient initialization\n\nChange-Id: I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4\n'}]",1,146418,fa0bbe08426abf6323ef5e76b5d570b7b8144f59,12,4,3,8592,,,0,"Fix mistralclient initialization

Change-Id: I2ea334cecbcd5992bb8e5dd944ed6c49c5aff3e4
",git fetch https://review.opendev.org/openstack/mistral refs/changes/18/146418/2 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/functional/base.py'],1,2d18ba1607b5ee526528f0e53620ac1b3de1206e,(detached," super(MistralClientBase, self).__init__(auth_provider, None)"," super(MistralClientBase, self).__init__(auth_provider)",1,1
openstack%2Fpython-mistralclient~master~I25865143325a238a85e5811f06503f4a43cc3bcb,openstack/python-mistralclient,master,I25865143325a238a85e5811f06503f4a43cc3bcb,Fix client initialization in the integration tests,MERGED,2015-01-12 15:21:49.000000000,2015-01-13 06:52:24.000000000,2015-01-13 06:52:24.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-01-12 15:21:49.000000000', 'files': ['mistralclient/tests/functional/client/v1/base.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/6051e45f55c347c16875bc2e59f9d70afd6f990c', 'message': 'Fix client initialization in the integration tests\n\nChange-Id: I25865143325a238a85e5811f06503f4a43cc3bcb\n'}]",0,146494,6051e45f55c347c16875bc2e59f9d70afd6f990c,7,4,1,8592,,,0,"Fix client initialization in the integration tests

Change-Id: I25865143325a238a85e5811f06503f4a43cc3bcb
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/94/146494/1 && git format-patch -1 --stdout FETCH_HEAD,['mistralclient/tests/functional/client/v1/base.py'],1,6051e45f55c347c16875bc2e59f9d70afd6f990c,,"from tempest import configCONF = config.CONF super(ClientAuth, self).__init__( auth_provider=auth_provider, service='workflow', region=CONF.identity.region)"," super(ClientAuth, self).__init__(auth_provider)",7,1
openstack%2Fironic~master~If0bb375ecda543526195f8dfd1503469775321fa,openstack/ironic,master,If0bb375ecda543526195f8dfd1503469775321fa,Adds support for deploying whole disk images,ABANDONED,2014-02-12 20:46:45.000000000,2015-01-13 06:42:27.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 6899}, {'_account_id': 8106}, {'_account_id': 8412}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-02-12 20:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/872ff56ceaf472343f9df1eab1a94dbd1cd61bdf', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if it has has to deploy disk images, it checks for a\ncustom glance property 'is_disk_image'='1' that must be set\nmanually in Glance. Furthermore, added a new pxe configuration\nfile necessary for deploying disk images.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 2, 'created': '2014-02-14 14:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a00775b538798148d1569f368d343ba433be095', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if it has has to deploy disk images, it checks for a\ncustom glance property 'is_disk_image'='1' that must be set\nmanually in Glance. Furthermore, added a new pxe configuration\nfile necessary for deploying disk images.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 3, 'created': '2014-02-16 20:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0daa651f258826dd61f1b63919f4fee5a3d0cc14', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if it has has to deploy disk images, it checks for a\ncustom glance property 'is_disk_image'='1' that must be set\nmanually in Glance. Furthermore, added a new pxe configuration\nfile necessary for deploying disk images.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 4, 'created': '2014-02-16 20:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5698e38ea1317466094226adc09b7ec983031e51', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if it has has to deploy disk images, it checks for a\ncustom glance property 'is_disk_image'='1' that must be set\nmanually in Glance. Furthermore, added a new pxe configuration\nfile necessary for deploying disk images.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 5, 'created': '2014-02-22 08:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/522864d929b4ab4bac1a8d8a2f50efa253943942', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if it has has to deploy disk images, it checks for a\ncustom glance property 'is_disk_image'='1' that must be set\nmanually in Glance. Furthermore, added a new pxe configuration\nfile necessary for deploying disk images.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 6, 'created': '2014-02-22 09:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4ed74fbed60b27356e463e51eac6b8bb794d2178', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 7, 'created': '2014-03-04 22:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/05c29d405cbebcd481761207dc88a8d44c44e2dc', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 8, 'created': '2014-04-15 09:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e85eca6295d856a7c4d6c73c182e20442a8ca622', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 9, 'created': '2014-04-24 17:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/36b4ce059f1101d4a7ad1cd466cf0eefc6d38963', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 10, 'created': '2014-04-24 20:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/def7a44f977b103c645d6271da67489e18ac3ea9', 'message': ""Adds support for deploying Disk Images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 11, 'created': '2014-04-28 19:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7cd324f32376b6778a76d635161aaaa0239abf95', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\nTo know if ironic needs to deploy disk images, it checks the\nproperties of the image being deployed. If the image has associated\nkernel/ramdisk, then we deploy the image via pxe and pxe boot the\nnode. If the image doesn't have a kernel/radmsik, then its assumed\nits a disk image and we only deploy the image via pxe and localboot\nthe node thereafter.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 12, 'created': '2014-05-18 16:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a89ddcb797795d94fd8cabdfeee698ced6f7ac62', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. Theres no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed pxe_deploy_disk in driver_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has kernel/ramdisk, its considered a partition\nimage, otherwise its considered a bootable disk image and thus sets\nIronic's driver_info:pxe_deploy_disk accordingly.\n\nFor disk images, the image is only deployed via PXE but is then booted\nlocally via a Power Manager call to change the boot order.\nFurthermore, PXE Boot will also be disabled from Neutron.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 13, 'created': '2014-05-22 04:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3dd43cc5c25b7bf0f84614a871d098612b68eb8c', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. There is no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed pxe_deploy_disk in driver_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has kernel/ramdisk, it's considered a partition\nimage, otherwise it's considered a bootable disk image and thus sets\nIronic's driver_info:pxe_deploy_disk accordingly.\n\nDisk images are only deployed via pxe but is then booted from\nhard disk(localboot) thereafter by changing the boot order via\na Power Manager call.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 14, 'created': '2014-05-22 04:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b261a16f645438c3f42843775a482c8254601f99', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. There is no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed pxe_deploy_disk in driver_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has kernel/ramdisk, it's considered a partition\nimage, otherwise it's considered a bootable disk image and thus sets\nIronic's driver_info:pxe_deploy_disk accordingly.\n\nDisk images are only deployed via pxe but is then booted from\nhard disk(localboot) thereafter by changing the boot order via\na Power Manager call.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 15, 'created': '2014-05-23 07:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/77422b3c793be936801ab3da012df3c9b9f72ba7', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. There is no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed pxe_deploy_disk in driver_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has kernel/ramdisk, it's considered a partition\nimage, otherwise it's considered a bootable disk image and thus sets\nIronic's driver_info:pxe_deploy_disk accordingly.\n\nDisk images are only deployed via pxe but is then booted from\nhard disk(localboot) thereafter by changing the boot order via\na Power Manager call.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 16, 'created': '2014-05-26 04:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4fdf2f8b49ac8f090379c4d3e8ffba002b548a8f', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. There is no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed pxe_deploy_disk in driver_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has kernel/ramdisk, it's considered a partition\nimage, otherwise it's considered a bootable disk image and thus sets\nIronic's driver_info:pxe_deploy_disk accordingly.\n\nDisk images are only deployed via pxe but are then booted from\nhard disk(localboot) thereafter by changing the boot order via\na Power Manager call.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}, {'number': 17, 'created': '2014-10-07 18:53:39.000000000', 'files': ['ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/drivers/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d252e0ddeb8b8203da9c8b98fcf06453791aba5', 'message': ""Adds support for deploying whole disk images\n\nCertain operating systems do not support pxe booting via a certain\nkernel and ramdisk. There is no choice but to boot whole disk images\nof these operating systems.\n\nThis patch extends the PXE Driver to deploy disk images.\n\nIronic will deploy disk/partition images based on a boolean parameter\nnamed is_whole_disk_image in instance_info.\n\nNova checks the image properties to determine the type of image being\ndeployed. If the image has a custome property named 'is_whole_disk_image',\nit's considered a partition image, otherwise it's considered a bootable\ndisk image and thus sets Ironic's instance_info:is_whole_disk_image\naccordingly.\n\nDisk images are only deployed via pxe but are then booted from\nhard disk(localboot) thereafter by changing the boot order via\na Power Manager call.\n\nImplements blueprint windows-disk-image-support\n\nChange-Id: If0bb375ecda543526195f8dfd1503469775321fa\n""}]",126,73054,1d252e0ddeb8b8203da9c8b98fcf06453791aba5,136,9,17,6899,,,0,"Adds support for deploying whole disk images

Certain operating systems do not support pxe booting via a certain
kernel and ramdisk. There is no choice but to boot whole disk images
of these operating systems.

This patch extends the PXE Driver to deploy disk images.

Ironic will deploy disk/partition images based on a boolean parameter
named is_whole_disk_image in instance_info.

Nova checks the image properties to determine the type of image being
deployed. If the image has a custome property named 'is_whole_disk_image',
it's considered a partition image, otherwise it's considered a bootable
disk image and thus sets Ironic's instance_info:is_whole_disk_image
accordingly.

Disk images are only deployed via pxe but are then booted from
hard disk(localboot) thereafter by changing the boot order via
a Power Manager call.

Implements blueprint windows-disk-image-support

Change-Id: If0bb375ecda543526195f8dfd1503469775321fa
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/73054/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/db/utils.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/pxe.py', 'ironic/drivers/modules/pxe_config_disk.template', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/drivers/test_deploy_utils.py']",6,872ff56ceaf472343f9df1eab1a94dbd1cd61bdf,bp/windows-disk-image-support," deploy_disk = False mock.call.get_image_mb(image_path), deploy_disk, root_mb, swap_mb) deploy_disk = False #mock.call.get_image_mb(image_path), mock.call.work_on_disk(dev, image_path, deploy_disk, root_mb, swap_mb), pxe_config_path, deploy_disk, root_mb, swap_mb) self.deploy_disk = False self.mock_gim = mock.patch.object(utils, 'get_image_mb').start() self.mock_gim.return_value = 128 self.addCleanup(self.mock_gim.stop) utils.work_on_disk, self.dev, self.image_path, self.deploy_disk, self.root_mb, self.swap_mb) utils.work_on_disk, self.dev, self.image_path, self.deploy_disk, self.root_mb, self.swap_mb) utils.work_on_disk, self.dev, self.image_path, self.deploy_disk, self.root_mb, self.swap_mb)"," mock.call.get_image_mb(image_path), root_mb, swap_mb) mock.call.get_image_mb(image_path), mock.call.work_on_disk(dev, root_mb, swap_mb, image_path), pxe_config_path, root_mb, swap_mb) utils.work_on_disk, self.dev, self.root_mb, self.swap_mb, self.image_path) utils.work_on_disk, self.dev, self.root_mb, self.swap_mb, self.image_path) utils.work_on_disk, self.dev, self.root_mb, self.swap_mb, self.image_path)",97,61
openstack%2Fneutron~master~I993daf594a28918de6fafff465f5f40e7b89305e,openstack/neutron,master,I993daf594a28918de6fafff465f5f40e7b89305e,Make L3 HA VIPs ordering consistent in keepalived.conf,MERGED,2014-12-23 18:38:33.000000000,2015-01-13 06:29:16.000000000,2015-01-13 06:29:14.000000000,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 7743}, {'_account_id': 7921}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-23 18:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b623943d1ea460df3b6b065c721e5c5798919957', 'message': 'Make L3 HA VIPs ordering consistent in keepalived.conf\n\nCloses-Bug: #1404945\nChange-Id: I993daf594a28918de6fafff465f5f40e7b89305e\n'}, {'number': 2, 'created': '2014-12-23 19:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bec203c2e4b4392e989e9f0d2dcd21f103a7e34b', 'message': 'Make L3 HA VIPs ordering consistent in keepalived.conf\n\nCloses-Bug: #1404945\nChange-Id: I993daf594a28918de6fafff465f5f40e7b89305e\n'}, {'number': 3, 'created': '2014-12-24 11:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/808a9d2679bbc42fe00c35c35fff178290f8308f', 'message': ""Make L3 HA VIPs ordering consistent in keepalived.conf\n\nCurrently the order of VIPs in keepalived.conf is determined\nby sorting the VIPs whenever one is added or removed. As it\nturns out, keepalived doesn't like it when the primary VIP\nchanges. One side effect is that virtual routes, in our case\nthe router's default route, may be removed.\n\nThis patch fabricates an IP address on the router's HA interface\nand uses it as the primary VIP.\n\nCloses-Bug: #1404945\nChange-Id: I993daf594a28918de6fafff465f5f40e7b89305e\n""}, {'number': 4, 'created': '2015-01-06 09:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebc8ab958316cdb5c39f31102d63c0c560fe1697', 'message': ""Make L3 HA VIPs ordering consistent in keepalived.conf\n\nCurrently the order of VIPs in keepalived.conf is determined\nby sorting the VIPs whenever one is added or removed. As it\nturns out, keepalived doesn't like it when the primary VIP\nchanges. One side effect is that virtual routes, in our case\nthe router's default route, may be removed.\n\nThis patch fabricates an IP address on the router's HA interface\nand uses it as the primary VIP.\n\nCloses-Bug: #1404945\nChange-Id: I993daf594a28918de6fafff465f5f40e7b89305e\n""}, {'number': 5, 'created': '2015-01-07 11:55:58.000000000', 'files': ['neutron/tests/unit/agent/linux/test_keepalived.py', 'neutron/agent/linux/keepalived.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/agent/l3/ha.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea587e113a838f74efed9a04c78c0ff3d860d04b', 'message': ""Make L3 HA VIPs ordering consistent in keepalived.conf\n\nCurrently the order of VIPs in keepalived.conf is determined\nby sorting the VIPs whenever one is added or removed. As it\nturns out, keepalived doesn't like it when the primary VIP\nchanges. One side effect is that virtual routes, in our case\nthe router's default route, may be removed.\n\nThis patch fabricates an IP address on the router's HA interface\nand uses it as the primary VIP.\n\nCloses-Bug: #1404945\nChange-Id: I993daf594a28918de6fafff465f5f40e7b89305e\n""}]",18,143714,ea587e113a838f74efed9a04c78c0ff3d860d04b,92,25,5,8873,,,0,"Make L3 HA VIPs ordering consistent in keepalived.conf

Currently the order of VIPs in keepalived.conf is determined
by sorting the VIPs whenever one is added or removed. As it
turns out, keepalived doesn't like it when the primary VIP
changes. One side effect is that virtual routes, in our case
the router's default route, may be removed.

This patch fabricates an IP address on the router's HA interface
and uses it as the primary VIP.

Closes-Bug: #1404945
Change-Id: I993daf594a28918de6fafff465f5f40e7b89305e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/143714/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_keepalived.py', 'neutron/agent/linux/keepalived.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/unit/test_l3_agent.py']",4,b623943d1ea460df3b6b065c721e5c5798919957,bug/1404945,," def test_ha_router_keepalived_config(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = prepare_router_data(enable_ha=True) router['routes'] = [ {'destination': '8.8.8.8/32', 'nexthop': '35.4.0.10'}, {'destination': '8.8.4.4/32', 'nexthop': '35.4.0.11'}] ri = l3router.RouterInfo(router['id'], self.conf.root_helper, router=router) ri.router = router with contextlib.nested(mock.patch.object(agent, '_spawn_metadata_proxy'), mock.patch('neutron.agent.linux.' 'utils.replace_file'), mock.patch('neutron.agent.linux.' 'utils.execute'), mock.patch('os.makedirs')): agent.process_ha_router_added(ri) agent.process_router(ri) config = ri.keepalived_manager.config ha_iface = agent.get_ha_device_name(ri.ha_port['id']) ex_iface = agent.get_external_device_name(ri.ex_gw_port['id']) int_iface = agent.get_internal_device_name( ri.internal_ports[0]['id']) expected = """"""vrrp_sync_group VG_1 { group { VR_1 } } vrrp_instance VR_1 { state BACKUP interface %(ha_iface)s virtual_router_id 1 priority 50 nopreempt advert_int 2 track_interface { %(ha_iface)s } virtual_ipaddress { 19.4.4.4/24 dev %(ex_iface)s } virtual_ipaddress_excluded { 35.4.0.4/24 dev %(int_iface)s } virtual_routes { 0.0.0.0/0 via 19.4.4.1 dev %(ex_iface)s 8.8.8.8/32 via 35.4.0.10 8.8.4.4/32 via 35.4.0.11 } }"""""" % {'ha_iface': ha_iface, 'ex_iface': ex_iface, 'int_iface': int_iface} self.assertEqual(expected, config.get_config_str()) ",117,64
openstack%2Fnova~master~I0278394942bab138adfbe738668a69368eb38feb,openstack/nova,master,I0278394942bab138adfbe738668a69368eb38feb,initialize objects with context in Migration object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-13 06:25:58.000000000,2015-01-12 21:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fba18a0303bb3c573d1d7a66f135dd81daf83928', 'message': ""initialize objects with context in Migration object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0278394942bab138adfbe738668a69368eb38feb\n""}, {'number': 2, 'created': '2015-01-06 20:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb792d3afd767d2dafe102586026ca4f91504bc8', 'message': ""initialize objects with context in Migration object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0278394942bab138adfbe738668a69368eb38feb\n""}, {'number': 3, 'created': '2015-01-08 06:50:50.000000000', 'files': ['nova/tests/unit/objects/test_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/39256b802351e6786d3cb210504cdb461b9fa053', 'message': ""initialize objects with context in Migration object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I0278394942bab138adfbe738668a69368eb38feb\n""}]",0,142283,39256b802351e6786d3cb210504cdb461b9fa053,34,10,3,4690,,,0,"initialize objects with context in Migration object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I0278394942bab138adfbe738668a69368eb38feb
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/142283/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_migration.py'],1,fba18a0303bb3c573d1d7a66f135dd81daf83928,bp/kilo-objects, mig = migration.Migration(context=ctxt) mig.create() mig = migration.Migration(context=ctxt) mig.create() mig = migration.Migration(context=ctxt) mig.save(), mig = migration.Migration() mig.create(ctxt) mig = migration.Migration() mig.create(ctxt) mig = migration.Migration() mig.save(ctxt),6,6
openstack%2Fmagnum~master~I1d29dad44f2f6828679e3095ff1b8b31ca733829,openstack/magnum,master,I1d29dad44f2f6828679e3095ff1b8b31ca733829,Fix creation service instance,ABANDONED,2015-01-12 23:17:54.000000000,2015-01-13 06:21:39.000000000,,"[{'_account_id': 3}, {'_account_id': 668}]","[{'number': 1, 'created': '2015-01-12 23:17:54.000000000', 'files': ['magnum/objects/service.py', 'magnum/api/controllers/v1/service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/eb5eb7de23713aa6e1c84c67fd89532a9e3c713c', 'message': 'Fix creation service instance\n\nIn the creation time, service port and name is not determined. These should\nbe determined by k8s when service is created.\n\nChange-Id: I1d29dad44f2f6828679e3095ff1b8b31ca733829\n'}]",0,146678,eb5eb7de23713aa6e1c84c67fd89532a9e3c713c,4,2,1,12385,,,0,"Fix creation service instance

In the creation time, service port and name is not determined. These should
be determined by k8s when service is created.

Change-Id: I1d29dad44f2f6828679e3095ff1b8b31ca733829
",git fetch https://review.opendev.org/openstack/magnum refs/changes/78/146678/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/objects/service.py', 'magnum/api/controllers/v1/service.py']",2,eb5eb7de23713aa6e1c84c67fd89532a9e3c713c,impl-pod-create, name = wtypes.text," name = wsme.wsattr(wtypes.text, mandatory=True)",2,2
openstack%2Fnova~master~Ic1aec955a795f95270f595f1411ca9f58d93c8ea,openstack/nova,master,Ic1aec955a795f95270f595f1411ca9f58d93c8ea,initialize objects with context in base object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-13 06:03:35.000000000,2015-01-13 02:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb28e029a764ad00dd21d4c1ce783ee094e384d0', 'message': ""initialize objects with context in base object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ic1aec955a795f95270f595f1411ca9f58d93c8ea\n""}, {'number': 2, 'created': '2015-01-06 20:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38ca455cb718d463af4da8e13b2159c9e38a3f30', 'message': ""initialize objects with context in base object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ic1aec955a795f95270f595f1411ca9f58d93c8ea\n""}, {'number': 3, 'created': '2015-01-06 22:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d23fa90cf11eed1dfb757c5bfcbb102dba922e07', 'message': ""initialize objects with context in base object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ic1aec955a795f95270f595f1411ca9f58d93c8ea\n""}, {'number': 4, 'created': '2015-01-08 06:50:51.000000000', 'files': ['nova/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1c9ae597c53b32d37f5bb42e985d8f9975f8c4c9', 'message': ""initialize objects with context in base object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Ic1aec955a795f95270f595f1411ca9f58d93c8ea\n""}]",2,142284,1c9ae597c53b32d37f5bb42e985d8f9975f8c4c9,45,11,4,4690,,,0,"initialize objects with context in base object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: Ic1aec955a795f95270f595f1411ca9f58d93c8ea
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/142284/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_objects.py'],1,bb28e029a764ad00dd21d4c1ce783ee094e384d0,bp/kilo-objects, obj.refresh(), obj.refresh(self.context),1,1
openstack%2Fhorizon~master~I6c308fbd76abdd4764f5fe6f0ad3b2fdef2f31db,openstack/horizon,master,I6c308fbd76abdd4764f5fe6f0ad3b2fdef2f31db,Updated from global requirements,MERGED,2015-01-13 00:03:36.000000000,2015-01-13 06:00:55.000000000,2015-01-13 06:00:53.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-01-13 00:03:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c04c1304a9b1a75d32e0483a45f952171dcc3ba4', 'message': 'Updated from global requirements\n\nChange-Id: I6c308fbd76abdd4764f5fe6f0ad3b2fdef2f31db\n'}]",0,146691,c04c1304a9b1a75d32e0483a45f952171dcc3ba4,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I6c308fbd76abdd4764f5fe6f0ad3b2fdef2f31db
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/146691/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c04c1304a9b1a75d32e0483a45f952171dcc3ba4,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fneutron-vpnaas~master~Ie624f66e7977b57bb83b4bad93767d592f482790,openstack/neutron-vpnaas,master,Ie624f66e7977b57bb83b4bad93767d592f482790,Adapt VPN agent to use new main for L3 Agent,MERGED,2015-01-09 17:32:43.000000000,2015-01-13 06:00:46.000000000,2015-01-13 06:00:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 6659}]","[{'number': 1, 'created': '2015-01-09 17:32:43.000000000', 'files': ['neutron_vpnaas/services/vpn/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/cce21fafbfafe823d51c30b4ed149b3fdea7df11', 'message': 'Adapt VPN agent to use new main for L3 Agent\n\nPatch [1] broke out the main logic out of the L3 agent module, but\nit kept the old entry point for bw compat. This patch follows up to\nreflect the new location.\n\n[1] https://review.openstack.org/#/c/145979/\n\nChange-Id: Ie624f66e7977b57bb83b4bad93767d592f482790\nPartially-Implements: bp restructure-l3-agent\n'}]",0,146144,cce21fafbfafe823d51c30b4ed149b3fdea7df11,10,4,1,748,,,0,"Adapt VPN agent to use new main for L3 Agent

Patch [1] broke out the main logic out of the L3 agent module, but
it kept the old entry point for bw compat. This patch follows up to
reflect the new location.

[1] https://review.openstack.org/#/c/145979/

Change-Id: Ie624f66e7977b57bb83b4bad93767d592f482790
Partially-Implements: bp restructure-l3-agent
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/44/146144/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/services/vpn/agent.py'],1,cce21fafbfafe823d51c30b4ed149b3fdea7df11,bp/restructure-l3-agent,from neutron.agent import l3_agent as entry entry.main(manager='neutron_vpnaas.services.vpn.agent.VPNAgent'), l3_agent.main(manager='neutron_vpnaas.services.vpn.agent.VPNAgent'),2,1
openstack%2Fnova~master~I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82,openstack/nova,master,I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82,initialize objects with context in KeyPair object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-13 05:52:59.000000000,2015-01-12 21:23:33.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f594fa22f380e0e914617aab9ce70b41ff852f05', 'message': ""initialize objects with context in KeyPair object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82\n""}, {'number': 2, 'created': '2015-01-06 20:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a9c668bbab5dee21ab3c20471c317067d1f91b2', 'message': ""initialize objects with context in KeyPair object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82\n""}, {'number': 3, 'created': '2015-01-08 06:50:50.000000000', 'files': ['nova/tests/unit/objects/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce28166dcf25a3d589e6f020b2dfa64705d15126', 'message': ""initialize objects with context in KeyPair object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82\n""}]",0,142282,ce28166dcf25a3d589e6f020b2dfa64705d15126,34,10,3,4690,,,0,"initialize objects with context in KeyPair object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I3ce858062a3d28b9d4b8fe4bd8f2b9a826318b82
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/142282/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_keypair.py'],1,f594fa22f380e0e914617aab9ce70b41ff852f05,bp/kilo-objects, keypair_obj = keypair.KeyPair(context=self.context) keypair_obj.create() keypair_obj = keypair.KeyPair(context=self.context) keypair_obj.create() keypair_obj = keypair.KeyPair(context=self.context) keypair_obj.destroy(), keypair_obj = keypair.KeyPair() keypair_obj.create(self.context) keypair_obj = keypair.KeyPair() keypair_obj.create(self.context) keypair_obj = keypair.KeyPair() keypair_obj.destroy(self.context),6,6
openstack%2Fmagnum~master~I2ab74528a0914d4bd63ce65a5c62211ccc6d723a,openstack/magnum,master,I2ab74528a0914d4bd63ce65a5c62211ccc6d723a,Parse stack output value for bay,MERGED,2015-01-13 00:25:55.000000000,2015-01-13 05:21:34.000000000,2015-01-13 05:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 00:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e9be322d599062f8ec38c0030d3fbfc99a753bfe', 'message': 'Parse stack output value for bay\n\nTo retrieve a k8s address correctly, this parses stack output values.\nSequence of outputs seems have no particular order.\n\nChange-Id: I2ab74528a0914d4bd63ce65a5c62211ccc6d723a\n'}, {'number': 2, 'created': '2015-01-13 01:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9fb5981f6a99ca59572c0e28fad0b894b56580b5', 'message': 'Parse stack output value for bay\n\nTo retrieve a k8s address correctly, this parses stack output values.\nSequence of outputs seems have no particular order.\n\nChange-Id: I2ab74528a0914d4bd63ce65a5c62211ccc6d723a\n'}, {'number': 3, 'created': '2015-01-13 01:37:45.000000000', 'files': ['magnum/tests/conductor/handlers/test_bay_k8s_heat.py', 'magnum/conductor/handlers/bay_k8s_heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/cdd963fd2d5938f091e2faf4ef71d2d6f3fcf21a', 'message': 'Parse stack output value for bay\n\nTo retrieve a k8s address correctly, this parses stack output values.\nSequence of outputs seems have no particular order.\n\nChange-Id: I2ab74528a0914d4bd63ce65a5c62211ccc6d723a\n'}]",4,146715,cdd963fd2d5938f091e2faf4ef71d2d6f3fcf21a,14,5,3,12385,,,0,"Parse stack output value for bay

To retrieve a k8s address correctly, this parses stack output values.
Sequence of outputs seems have no particular order.

Change-Id: I2ab74528a0914d4bd63ce65a5c62211ccc6d723a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/15/146715/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/conductor/handlers/test_bay_k8s_heat.py', 'magnum/conductor/handlers/bay_k8s_heat.py']",2,e9be322d599062f8ec38c0030d3fbfc99a753bfe,retrive-master-address-from-outputs,"def _parse_stack_outputs(outputs): parsed_outputs = {} for output in outputs: output_key = output[""output_key""] output_value = output[""output_value""] if output_key == ""kube_minions_external"": parsed_outputs[""kube_minions_external""] = output_value if output_key == ""kube_minions"": parsed_outputs[""kube_minions""] = output_value if output_key == ""kube_master"": parsed_outputs[""kube_master""] = output_value return parsed_outputs parsed_outputs = _parse_stack_outputs(stack.outputs) master_address = parsed_outputs[""kube_master""] minion_addresses = parsed_outputs[""kube_minions_external""]", master_address = stack.outputs[0]['output_value'] minion_addresses = stack.outputs[2]['output_value'],50,2
openstack%2Fmagnum~master~I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2,openstack/magnum,master,I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2,Remove apiserver_port attribute from bay_definition,MERGED,2015-01-13 00:16:18.000000000,2015-01-13 05:16:32.000000000,2015-01-13 05:16:31.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-13 00:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e9aed940508d8a6f50ebc367bbbc9f96a6514afa', 'message': ""Remove apiserver_port attribute from bay_definition\n\nIn this time, our heat-template doesn't support apiserver_port parameter.\nSo this parameter causes failing to create a stack.\nThis patch removes this parameter to use.\n\nChange-Id: I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2\n""}, {'number': 2, 'created': '2015-01-13 01:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/efbc282d21db8a9e6b82e58edeebb43884c37582', 'message': ""Remove apiserver_port attribute from bay_definition\n\nIn this time, our heat-template doesn't support apiserver_port parameter.\nSo this parameter causes failing to create a stack.\nThis patch removes this parameter to use.\n\nChange-Id: I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2\n""}, {'number': 3, 'created': '2015-01-13 01:37:45.000000000', 'files': ['magnum/tests/conductor/handlers/test_bay_k8s_heat.py', 'magnum/conductor/handlers/bay_k8s_heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/596233a2b4d524960db37f1948c6fa0035b0ee92', 'message': ""Remove apiserver_port attribute from bay_definition\n\nIn this time, our heat-template doesn't support apiserver_port parameter.\nSo this parameter causes failing to create a stack.\nThis patch removes this parameter to use.\n\nChange-Id: I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2\n""}]",0,146711,596233a2b4d524960db37f1948c6fa0035b0ee92,13,5,3,12385,,,0,"Remove apiserver_port attribute from bay_definition

In this time, our heat-template doesn't support apiserver_port parameter.
So this parameter causes failing to create a stack.
This patch removes this parameter to use.

Change-Id: I8edd23a9464fed45c87f14aaa0d3609ad7f07fc2
",git fetch https://review.opendev.org/openstack/magnum refs/changes/11/146711/3 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/conductor/handlers/test_bay_k8s_heat.py', 'magnum/conductor/handlers/bay_k8s_heat.py']",2,e9aed940508d8a6f50ebc367bbbc9f96a6514afa,retrive-master-address-from-outputs,, 'apiserver_port': 8080 if baymodel.apiserver_port: bay_definition['apiserver_port'] = baymodel.apiserver_port,0,9
openstack%2Fpython-novaclient~master~I1ae9906842bc1b4f91de0cb3b047f2c57d751fd7,openstack/python-novaclient,master,I1ae9906842bc1b4f91de0cb3b047f2c57d751fd7,Updated from global requirements,MERGED,2015-01-13 00:15:52.000000000,2015-01-13 04:21:53.000000000,2015-01-13 04:21:52.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-01-13 00:15:52.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/17367002609f011710014aef12a898e9f16db81c', 'message': 'Updated from global requirements\n\nChange-Id: I1ae9906842bc1b4f91de0cb3b047f2c57d751fd7\n'}]",0,146708,17367002609f011710014aef12a898e9f16db81c,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I1ae9906842bc1b4f91de0cb3b047f2c57d751fd7
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/08/146708/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,17367002609f011710014aef12a898e9f16db81c,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Ftaskflow~master~I94077bf76d9f13728c6c14b5e263bc7ced3ab0e8,openstack/taskflow,master,I94077bf76d9f13728c6c14b5e263bc7ced3ab0e8,The taskflow logger module does not provide a logging adapter,MERGED,2015-01-10 01:00:26.000000000,2015-01-13 04:20:27.000000000,2015-01-13 04:20:24.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9608}]","[{'number': 1, 'created': '2015-01-10 01:00:26.000000000', 'files': ['taskflow/listeners/logging.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0d602a89f3d34055de2e0d39d13ad748c0aa5c2f', 'message': 'The taskflow logger module does not provide a logging adapter\n\nThe expected use is that this comparison check for older versions\nof python (only 2.6) should check against the logging modules\nlogger adapter type and not the taskflow modules helper logger\nmodule which does not expose this type.\n\nFixes bug 1409178\n\nChange-Id: I94077bf76d9f13728c6c14b5e263bc7ced3ab0e8\n'}]",0,146242,0d602a89f3d34055de2e0d39d13ad748c0aa5c2f,9,3,1,1297,,,0,"The taskflow logger module does not provide a logging adapter

The expected use is that this comparison check for older versions
of python (only 2.6) should check against the logging modules
logger adapter type and not the taskflow modules helper logger
module which does not expose this type.

Fixes bug 1409178

Change-Id: I94077bf76d9f13728c6c14b5e263bc7ced3ab0e8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/42/146242/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/listeners/logging.py'],1,0d602a89f3d34055de2e0d39d13ad748c0aa5c2f,bug/1409178,"import logging as logging_base if _PY26 and isinstance(logger, logging_base.LoggerAdapter):"," if _PY26 and isinstance(logger, logging.LoggerAdapter):",2,1
openstack%2Fpython-neutronclient~master~Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951,openstack/python-neutronclient,master,Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951,Add '--router:external' option to 'net-create',MERGED,2014-05-29 07:18:04.000000000,2015-01-13 04:15:00.000000000,2015-01-13 04:15:00.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1923}, {'_account_id': 6072}, {'_account_id': 6348}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8289}, {'_account_id': 8290}, {'_account_id': 8336}, {'_account_id': 8871}, {'_account_id': 8976}, {'_account_id': 9820}, {'_account_id': 11208}, {'_account_id': 12683}]","[{'number': 1, 'created': '2014-05-29 07:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c26055f96775067026df70a95cfeab9cfc4418f2', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 2, 'created': '2014-05-29 10:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4ccd3726c88a95e1e91a645131e910095952035c', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 3, 'created': '2014-06-04 08:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9bd3f664c48dfa465cc1c5ff5ca8b20b5ad73439', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 4, 'created': '2014-06-05 04:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d51ced18f8a083b14b5986e9cedf30b2f0176607', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 5, 'created': '2014-06-05 10:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7a94ea7b42e232fe3f6f7b95812a0c92d059bc21', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 6, 'created': '2014-06-06 01:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d56f42397eb2f843164ed2ea086e3f01b236d8fb', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 7, 'created': '2014-06-06 03:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ec90af6eeab8b29af0e9229efae83ff83d6de66b', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 8, 'created': '2014-06-06 03:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/008e11ab26761252241ecd1773ace9a958982a18', 'message': ""Add help information of '--router' to 'net-create'\n\n'net-create' support the parameter of '--router', but it lack of help\ninformation.\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 9, 'created': '2014-06-06 08:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/6a6fbbc299707d67af189caaaf2c88f50ebd0f2f', 'message': ""Add '--external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 10, 'created': '2014-07-14 09:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9893b751471c4a6a902ea4858c6466ad47ac02df', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 11, 'created': '2014-07-15 01:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/90d0154054b41825d78770830a8326501b679a57', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 12, 'created': '2014-12-31 06:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b685fb6f03293793a29cbd6c222becbe1c5bc334', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 13, 'created': '2015-01-04 02:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/704dbec5eafc38e2fb9694851fe905a25db802dd', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 14, 'created': '2015-01-04 02:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c3c64ec593887149037a32a14c2fe246885f23ef', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}, {'number': 15, 'created': '2015-01-12 01:35:00.000000000', 'files': ['neutronclient/neutron/v2_0/network.py', 'neutronclient/tests/unit/test_cli20_network.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/096fd1b175085fcc3c46a248b4afb67561fd29ef', 'message': ""Add '--router:external' option to 'net-create'\n\nChange-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951\nCloses-bug: #1320793\n""}]",30,96372,096fd1b175085fcc3c46a248b4afb67561fd29ef,125,18,15,8976,,,0,"Add '--router:external' option to 'net-create'

Change-Id: Ibb100d54a5fd8b04ac5e1fc3a26826c695f4d951
Closes-bug: #1320793
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/72/96372/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/network.py'],1,c26055f96775067026df70a95cfeab9cfc4418f2,bug/1320793," '--router:', choices=['external=True', 'external=False'], help=_('Set network as external')) parser.add_argument(",,4,0
openstack%2Fpython-neutronclient~master~I727ac76babb6f6aef1a0f619c011ad67a6e2fccf,openstack/python-neutronclient,master,I727ac76babb6f6aef1a0f619c011ad67a6e2fccf,Use adapter from keystoneclient,MERGED,2014-08-31 03:13:39.000000000,2015-01-13 04:14:52.000000000,2015-01-13 04:14:51.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7191}, {'_account_id': 7787}, {'_account_id': 7930}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-08-31 03:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bf16570d35d12e543af6fcf5c668bf36ef256e09', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 2, 'created': '2014-08-31 03:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c8320af0694dfedafbc0190167469c5ea904ba18', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 3, 'created': '2014-09-01 05:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/416f95955d1f76b29e7b7509a9d82bcf4a021ac8', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 4, 'created': '2014-09-02 05:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c4097ca8ecaafc51a5421c8c68b01b4bd424f75c', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 5, 'created': '2014-09-09 04:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a90a86dec697152629ea574bd3a89408ded7f233', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 6, 'created': '2014-09-09 04:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/0bf6705ad856831f66c08b8631d975beeda72980', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 7, 'created': '2014-09-09 05:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f728523862fb5066b421058626392170fa25f4e2', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 8, 'created': '2014-11-21 03:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ac98df0ae4611633d6d1361a665ab6f3533e14f2', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 9, 'created': '2014-11-21 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/26b6166ec4326a84aead8969602256b37ac659bf', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 10, 'created': '2014-12-02 04:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b56fbdf3e970f9d2882dc3049a3c23dd5781aa22', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 11, 'created': '2014-12-02 05:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/10a2e3c3ae64ddf837a64be664d880701b089af2', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 12, 'created': '2014-12-02 05:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/17c5bf63df103ebb719b60ff558f70818f58853f', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 13, 'created': '2014-12-16 01:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c7af3e30bbaf3bd966247d33e38a8560c80d182c', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 14, 'created': '2014-12-18 05:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8cd87e0d52d904d601b5cc7cda820b0c2d9cbda6', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nCloses-Bug: #1403726\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}, {'number': 15, 'created': '2014-12-23 00:33:59.000000000', 'files': ['neutronclient/client.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py', 'neutronclient/tests/unit/test_auth.py', 'neutronclient/tests/unit/test_cli20_network.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/799e288f48e5d99731dedbfb94808a8cbe01c05c', 'message': 'Use adapter from keystoneclient\n\nThe adapter in keystoneclient is there to abstract the common client\nparameters that may be used when sending a request. We should use that\nrather than keeping our own methods.\n\nCloses-Bug: #1403726\nChange-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf\n'}]",0,118006,799e288f48e5d99731dedbfb94808a8cbe01c05c,51,6,15,7191,,,0,"Use adapter from keystoneclient

The adapter in keystoneclient is there to abstract the common client
parameters that may be used when sending a request. We should use that
rather than keeping our own methods.

Closes-Bug: #1403726
Change-Id: I727ac76babb6f6aef1a0f619c011ad67a6e2fccf
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/06/118006/8 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/client.py'],1,bf16570d35d12e543af6fcf5c668bf36ef256e09,test2,"from keystoneclient import adapterclass SessionClient(adapter.Adapter, NeutronClientMixin): def __init__(self, session, auth=None, **kwargs): kwargs.setdefault('user_agent', self.USER_AGENT) super(SessionClient, self).__init__(session, auth=auth, **kwargs) def request(self, *args, **kwargs): resp = super(SessionClient, self).request(*args, **kwargs)","class SessionClient(NeutronClientMixin): def __init__(self, session, auth, interface=None, service_type=None, region_name=None): self.session = session self.auth = auth self.interface = interface self.service_type = service_type self.region_name = region_name def request(self, url, method, **kwargs): kwargs.setdefault('user_agent', self.USER_AGENT) kwargs.setdefault('auth', self.auth) endpoint_filter = kwargs.setdefault('endpoint_filter', {}) endpoint_filter.setdefault('interface', self.interface) endpoint_filter.setdefault('service_type', self.service_type) endpoint_filter.setdefault('region_name', self.region_name) resp = self.session.request(url, method, **kwargs)",7,22
openstack%2Fpython-neutronclient~master~I2633bcaf36388fb4db1de4cd75d5ccd76f961509,openstack/python-neutronclient,master,I2633bcaf36388fb4db1de4cd75d5ccd76f961509,Use requests_mock instead of mox,MERGED,2014-10-31 11:12:39.000000000,2015-01-13 04:14:38.000000000,2015-01-13 04:14:36.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 5950}, {'_account_id': 7191}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-10-31 11:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c49b1523847b8c7f12e8a55b0419ae088a1c08ed', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}, {'number': 2, 'created': '2014-11-20 21:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/93a8076b071bcd017fc7438805c756dad9473802', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}, {'number': 3, 'created': '2014-11-21 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e9785420e819c1a329f216627d3d24bd61c5abe3', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}, {'number': 4, 'created': '2014-12-02 04:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/46dc36df869a5a58d73089a53a217a511acb308e', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}, {'number': 5, 'created': '2014-12-16 01:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/19b0b8823e265487de68562884db4bee1b94d34c', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}, {'number': 6, 'created': '2014-12-23 00:33:59.000000000', 'files': ['neutronclient/tests/unit/test_http.py', 'neutronclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5822d619e56ece42b711fdc378de772ebda65f38', 'message': 'Use requests_mock instead of mox\n\nKill off mox and use requests_mock. There are fixtures available for\neverything we want to test - there is no reason to resort to using mox.\nThis cleans up and makes clearer a lot of tests.\n\nChange-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509\n'}]",11,132213,5822d619e56ece42b711fdc378de772ebda65f38,44,7,6,7191,,,0,"Use requests_mock instead of mox

Kill off mox and use requests_mock. There are fixtures available for
everything we want to test - there is no reason to resort to using mox.
This cleans up and makes clearer a lot of tests.

Change-Id: I2633bcaf36388fb4db1de4cd75d5ccd76f961509
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/13/132213/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_http.py', 'neutronclient/tests/unit/test_auth.py']",2,c49b1523847b8c7f12e8a55b0419ae088a1c08ed,test2,"import loggingfrom requests_mock.contrib import fixture as mock_fixturefrom keystoneclient import fixture as ksc_fixtureENDPOINT_URL = 'http://localurl' PUBLIC_ENDPOINT_URL = '%s/public' % ENDPOINT_URL ADMIN_ENDPOINT_URL = '%s/admin' % ENDPOINT_URL INTERNAL_ENDPOINT_URL = '%s/internal' % ENDPOINT_URL ENDPOINT_OVERRIDE = 'http://otherurl'KS_TOKEN_RESULT = ksc_fixture.V2Token()_v2 = ksc_fixture.V2Discovery(V2_URL) _v3 = ksc_fixture.V3Discovery(V3_URL)def setup_keystone_v2(mrequests): v2_token = ksc_fixture.V2Token(token_id=TOKENID) v3_token = ksc_fixture.V3Token() self.requests = self.useFixture(mock_fixture.Fixture()) url = ENDPOINT_URL + '/resource' self.requests.get(ENDPOINT_URL + '/resource') self.assertEqual(url, self.requests.last_request.url) self.logger = self.useFixture(fixtures.FakeLogger(level=logging.DEBUG)) self.requests = self.useFixture(mock_fixture.Fixture()) def test_get_token(self): auth_session, auth_plugin = setup_keystone_v2(self.requests) m = self.requests.get(PUBLIC_ENDPOINT_URL + '/resource', request_headers={'X-Auth-Token': TOKENID}) self.assertTrue(m.called) res_url = ENDPOINT_URL + '/resource' v2_url = AUTH_URL + '/tokens' self.requests.get(res_url, response_list=[{'status_code': 401}, {'status_code': 200}]) self.requests.post(v2_url, json=KS_TOKEN_RESULT) self.assertEqual(3, len(self.requests.request_history)) self.assertEqual(res_url, self.requests.request_history[0].url) self.assertEqual(v2_url, self.requests.request_history[1].url) self.assertEqual(res_url, self.requests.request_history[2].url) def test_refresh_token_no_auth_url(self): self.requests.get(ENDPOINT_URL + '/resource', status_code=401) self.requests.get(AUTH_URL + '/tokens/%s/endpoints' % token_id, json=ENDPOINTS_RESULT) self.requests.get(ENDPOINT_URL + '/resource') self.assertEqual(token_id, self.requests.last_request.headers['X-Auth-Token']) self.requests.get(ENDPOINT_OVERRIDE + '/resource') self.assertEqual(token_id, self.requests.last_request.headers['X-Auth-Token']) self.requests.get(AUTH_URL + '/tokens/%s/endpoints' % token_id, json=ENDPOINTS_RESULT) self.requests.get(AUTH_URL + '/tokens/%s/endpoints' % token_id, status_code=401) self.requests.post(AUTH_URL + '/tokens', json=KS_TOKEN_RESULT) m = self.requests.get(ENDPOINT_URL + '/resource') self.assertEqual(KS_TOKEN_RESULT.token_id, m.last_request.headers['X-Auth-Token']) def test_endpoint_type(self): auth_session, auth_plugin = setup_keystone_v3(self.requests) m = self.requests.post(AUTH_URL + '/tokens', json=KS_TOKEN_RESULT) self.requests.get(ENDPOINT_URL + '/resource') self.assertNotIn(self.client.password, self.logger.output) self.assertIn(self.client.password, m.last_request.body) self.requests = self.useFixture(mock_fixture.Fixture()) def test_v2_auth(self): auth_session, auth_plugin = setup_keystone_v2(self.requests) m = self.requests.get(PUBLIC_ENDPOINT_URL + '/resource') self.assertTrue(m.called) def test_v3_auth(self): auth_session, auth_plugin = setup_keystone_v3(self.requests) m = self.requests.get(PUBLIC_ENDPOINT_URL + '/resource') self.assertTrue(m.called)","from mox3 import moximport requests import requests_mock import sixfrom keystoneclient import fixturefrom neutronclient.common import utilsENDPOINT_URL = 'localurl' PUBLIC_ENDPOINT_URL = 'public_%s' % ENDPOINT_URL ADMIN_ENDPOINT_URL = 'admin_%s' % ENDPOINT_URL INTERNAL_ENDPOINT_URL = 'internal_%s' % ENDPOINT_URL ENDPOINT_OVERRIDE = 'otherurl'KS_TOKEN_RESULT = fixture.V2Token()_v2 = fixture.V2Discovery(V2_URL) _v3 = fixture.V3Discovery(V3_URL)def get_response(status_code, headers=None): response = mox.Mox().CreateMock(requests.Response) response.headers = headers or {} response.status_code = status_code return response def setup_keystone_v2(mrequests): v2_token = fixture.V2Token(token_id=TOKENID) v3_token = fixture.V3Token() self.mox = mox.Mox() self.addCleanup(self.mox.VerifyAll) self.addCleanup(self.mox.UnsetStubs) self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.IsA(dict), ).AndReturn((res200, '')) self.mox.ReplayAll() self.mox = mox.Mox() self.addCleanup(self.mox.VerifyAll) self.addCleanup(self.mox.UnsetStubs) @requests_mock.Mocker() def test_get_token(self, mrequests): auth_session, auth_plugin = setup_keystone_v2(mrequests) self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) self.client.request( '/resource', 'GET', authenticated=True ).AndReturn((res200, '')) self.mox.ReplayAll() self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) res401 = get_response(401) # If a token is expired, neutron server retruns 401 self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', token_id) ).AndReturn((res401, '')) self.client.request( AUTH_URL + '/tokens', 'POST', body=mox.IsA(str), headers=mox.IsA(dict) ).AndReturn((res200, json.dumps(KS_TOKEN_RESULT))) self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', KS_TOKEN_RESULT.token_id) ).AndReturn((res200, '')) self.mox.ReplayAll() def test_refresh_token_no_auth_url(self): self.mox.StubOutWithMock(self.client, ""request"") res401 = get_response(401) # If a token is expired, neutron server returns 401 self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', token_id) ).AndReturn((res401, '')) self.mox.ReplayAll() self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) self.client.request( mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) ).AndReturn((res200, json.dumps(ENDPOINTS_RESULT))) self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', token_id) ).AndReturn((res200, '')) self.mox.ReplayAll() self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) self.client.request( mox.StrContains(ENDPOINT_OVERRIDE + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', token_id) ).AndReturn((res200, '')) self.mox.ReplayAll() self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) self.client.request( mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) ).AndReturn((res200, json.dumps(ENDPOINTS_RESULT))) self.mox.ReplayAll() self.mox.StubOutWithMock(self.client, ""request"") res200 = get_response(200) res401 = get_response(401) self.client.request( mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) ).AndReturn((res401, '')) self.client.request( AUTH_URL + '/tokens', 'POST', body=mox.IsA(str), headers=mox.IsA(dict) ).AndReturn((res200, json.dumps(KS_TOKEN_RESULT))) self.client.request( mox.StrContains(ENDPOINT_URL + '/resource'), 'GET', headers=mox.ContainsKeyValue('X-Auth-Token', KS_TOKEN_RESULT.token_id) ).AndReturn((res200, '')) self.mox.ReplayAll() @requests_mock.Mocker() def test_endpoint_type(self, mrequests): auth_session, auth_plugin = setup_keystone_v3(mrequests) def verify_no_credentials(kwargs): return ('REDACTED' in kwargs['body']) and ( self.client.password not in kwargs['body']) def verify_credentials(body): return 'REDACTED' not in body and self.client.password in body self.mox.StubOutWithMock(self.client, ""request"") self.mox.StubOutWithMock(utils, ""http_log_req"") res200 = get_response(200) utils.http_log_req(mox.IgnoreArg(), mox.IgnoreArg(), mox.Func( verify_no_credentials)) self.client.request( mox.IsA(six.string_types), mox.IsA(six.string_types), body=mox.Func(verify_credentials), headers=mox.IgnoreArg() ).AndReturn((res200, json.dumps(KS_TOKEN_RESULT))) utils.http_log_req(mox.IgnoreArg(), mox.IgnoreArg(), mox.IgnoreArg()) self.client.request( mox.IsA(six.string_types), mox.IsA(six.string_types), headers=mox.IsA(dict) ).AndReturn((res200, '')) self.mox.ReplayAll() self.mox = mox.Mox() self.addCleanup(self.mox.VerifyAll) self.addCleanup(self.mox.UnsetStubs) @requests_mock.Mocker() def test_v2_auth(self, mrequests): auth_session, auth_plugin = setup_keystone_v2(mrequests) res200 = get_response(200) self.mox.StubOutWithMock(self.client, ""request"") self.client.request( '/resource', 'GET', authenticated=True ).AndReturn((res200, '')) self.mox.ReplayAll() @requests_mock.Mocker() def test_v3_auth(self, mrequests): auth_session, auth_plugin = setup_keystone_v3(mrequests) res200 = get_response(200) self.mox.StubOutWithMock(self.client, ""request"") self.client.request( '/resource', 'GET', authenticated=True ).AndReturn((res200, '')) self.mox.ReplayAll()",101,223
openstack%2Foctavia~master~Iadceba964761548625550d4aa2c5a4ad90e76684,openstack/octavia,master,Iadceba964761548625550d4aa2c5a4ad90e76684,Add nsCertType and ExtendedKey usage extensions to CertGenerator,MERGED,2015-01-01 01:36:45.000000000,2015-01-13 04:14:20.000000000,2015-01-13 04:14:20.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 7398}, {'_account_id': 10273}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-01 01:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a3688e933ddb18ce901e5ea7d12ce7f35471583a', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating certs as well.\nThe x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}, {'number': 2, 'created': '2015-01-01 01:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0159173850142935953888f6af5ffced08ea41a3', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating\ncerts as well. The x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}, {'number': 3, 'created': '2015-01-02 07:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/712a29e8fbb2c78cd8f9224df1b6c22b18f8fbfe', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating\ncerts as well. The x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}, {'number': 4, 'created': '2015-01-07 18:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9ecb406d541b9a81d196e45d6fd1da08cb321bd1', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating\ncerts as well. The x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}, {'number': 5, 'created': '2015-01-08 00:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/33800f6631c76f2e3a132d75640767e9e8c9ac18', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating\ncerts as well. The x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}, {'number': 6, 'created': '2015-01-09 06:38:19.000000000', 'files': ['octavia/certificates/generator/local.py', 'octavia/tests/unit/certificates/generator/test_local.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/19856c014e2fbd6c72ce01ec62dc4a8888ee7e07', 'message': 'Add nsCertType and ExtendedKey usage extensions to CertGenerator\n\nThe generated certs should be recognized as client authenticating\ncerts as well. The x509 should also be version 3.\n\nChange-Id: Iadceba964761548625550d4aa2c5a4ad90e76684\n'}]",10,144670,19856c014e2fbd6c72ce01ec62dc4a8888ee7e07,31,6,6,7398,,,0,"Add nsCertType and ExtendedKey usage extensions to CertGenerator

The generated certs should be recognized as client authenticating
certs as well. The x509 should also be version 3.

Change-Id: Iadceba964761548625550d4aa2c5a4ad90e76684
",git fetch https://review.opendev.org/openstack/octavia refs/changes/70/144670/5 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/certificates/generator/local.py', 'octavia/tests/unit/certificates/generator/test_local.py']",2,a3688e933ddb18ce901e5ea7d12ce7f35471583a,tls_cruft,"import six cert_text = crypto.dump_certificate(crypto.FILETYPE_TEXT, cert) self.assertIn(six.b(""Version: 3""), cert_text) self.assertIn(six.b(""TLS Web Server Authentication""), cert_text) self.assertIn(six.b(""TLS Web Client Authentication""), cert_text) self.assertIn(six.b(""SSL Server""), cert_text) self.assertIn(six.b(""SSL Client""), cert_text) self.assertIn(six.b(""CA:FALSE""), cert_text)",,21,0
openstack%2Fsolum~master~I59843b4f7f93cb38584233295fc96f9dd8b3b34e,openstack/solum,master,I59843b4f7f93cb38584233295fc96f9dd8b3b34e,Fix worker.shell._get_environment() for build_lp,ABANDONED,2014-12-18 17:52:50.000000000,2015-01-13 04:13:59.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-18 17:52:50.000000000', 'files': ['solum/worker/handlers/shell.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/3647d2a97bfcda6b54f682187d02395447f6002f', 'message': 'Fix worker.shell._get_environment() for build_lp\n\nIn the case of building LP assembly_id is None.\n\nChange-Id: I59843b4f7f93cb38584233295fc96f9dd8b3b34e\n'}]",0,142858,3647d2a97bfcda6b54f682187d02395447f6002f,21,6,1,6662,,,0,"Fix worker.shell._get_environment() for build_lp

In the case of building LP assembly_id is None.

Change-Id: I59843b4f7f93cb38584233295fc96f9dd8b3b34e
",git fetch https://review.opendev.org/openstack/solum refs/changes/58/142858/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/worker/handlers/shell.py'],1,3647d2a97bfcda6b54f682187d02395447f6002f,build-lp," def _get_environment(self, ctxt, assembly_id=None):"," def _get_environment(self, ctxt, assembly_id):",1,1
openstack%2Ftempest~master~I026ccce62f76dbae2b215b7b839194f848635bc9,openstack/tempest,master,I026ccce62f76dbae2b215b7b839194f848635bc9,Floatingip as port fixed ip,MERGED,2014-11-27 09:01:36.000000000,2015-01-13 03:46:29.000000000,2015-01-13 03:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6983}, {'_account_id': 7141}, {'_account_id': 7249}, {'_account_id': 7350}, {'_account_id': 8298}, {'_account_id': 8556}, {'_account_id': 10016}, {'_account_id': 10237}, {'_account_id': 10385}, {'_account_id': 11671}]","[{'number': 1, 'created': '2014-11-27 09:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e28faeba35e65dbace8dbbc31561a131227b0ef', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 2, 'created': '2014-11-28 06:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f5db5c3489b5a0bac790b759466cf49fa6e50a9', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 3, 'created': '2014-11-28 07:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1411c56ced65c52d283438778152ebc32394ac51', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 4, 'created': '2014-12-11 09:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec87265b749f0f4b91dca3fc31ecbb140b630736', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 5, 'created': '2014-12-12 13:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5cdded5953314d6ea4df464d7d6877e360845586', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 6, 'created': '2014-12-18 04:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/20ca4a611b69c0c08d8adfcec5828afc5b3920cb', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}, {'number': 7, 'created': '2014-12-25 06:07:40.000000000', 'files': ['tempest/api/network/admin/test_external_networks_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/92c12e579c23c166ff696c4fc29a2dca87680df7', 'message': 'Floatingip as port fixed ip\n\nAdded a test cases which checks if port-create on a public\nnetwork, called with a fixed-ip address equivalent to a\npre created floatinip address raises a Conflict\n\nChange-Id: I026ccce62f76dbae2b215b7b839194f848635bc9\n'}]",12,137549,92c12e579c23c166ff696c4fc29a2dca87680df7,60,15,7,8298,,,0,"Floatingip as port fixed ip

Added a test cases which checks if port-create on a public
network, called with a fixed-ip address equivalent to a
pre created floatinip address raises a Conflict

Change-Id: I026ccce62f76dbae2b215b7b839194f848635bc9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/137549/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/admin/test_external_network_extension.py'],1,6e28faeba35e65dbace8dbbc31561a131227b0ef,,"from tempest import exceptions def test_create_port_with_precreated_floatingip_as_fixed_ip(self): # create a floating ip client = self.admin_client _, body = client.create_network(**{'router:external': True}) external_network = body['network'] self.addCleanup(self._try_delete_resource, client.delete_network, external_network['id']) self.create_subnet(external_network, client=client) _, body = client.create_floatingip( floating_network_id=external_network['id']) created_floating_ip = body['floatingip'] self.addCleanup(self._try_delete_resource, client.delete_floatingip, created_floating_ip['id']) floating_ip_address = created_floating_ip['floating_ip_address'] self.assertIsNotNone(floating_ip_address) fixed_ips = [{'ip_address': floating_ip_address}] # Create port with the floatingip_address as fixed ip self.assertRaises(exceptions.Conflict, client.create_port, network_id=external_network['id'], fixed_ips=fixed_ips)",,27,0
openstack%2Fceilometer~master~I585a62a9070640be241d173e86f2ad9a87bd35b4,openstack/ceilometer,master,I585a62a9070640be241d173e86f2ad9a87bd35b4,Use right function to create extension list for agent test,MERGED,2015-01-12 05:32:34.000000000,2015-01-13 03:39:34.000000000,2015-01-13 03:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-12 05:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6a4eefc8fc793893aba8d29742c064de05e08200', 'message': 'Use right function to create extension list for agent test\n\nUpdate the function to create_extension_list after agent merge, also remove\nunnecessary hack of extention creation for code clean\n\nChange-Id: I585a62a9070640be241d173e86f2ad9a87bd35b4\n'}, {'number': 2, 'created': '2015-01-12 08:38:10.000000000', 'files': ['ceilometer/tests/agent/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8a8f5b31d7afb3d37a4af9ded7fa277fb6d1d64e', 'message': 'Use right function to create extension list for agent test\n\nUpdate the function to create_extension_list after agent merge, also remove\nunnecessary hack of extention creation for code clean\n\nChange-Id: I585a62a9070640be241d173e86f2ad9a87bd35b4\n'}]",0,146373,8a8f5b31d7afb3d37a4af9ded7fa277fb6d1d64e,12,6,2,11235,,,0,"Use right function to create extension list for agent test

Update the function to create_extension_list after agent merge, also remove
unnecessary hack of extention creation for code clean

Change-Id: I585a62a9070640be241d173e86f2ad9a87bd35b4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/73/146373/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/agent/test_manager.py'],1,6a4eefc8fc793893aba8d29742c064de05e08200,bug/agent-test-fix," def create_extension_list(self): exts = super(TestRunTasks, self).create_extension_list()"," def get_extension_list(self): exts = super(TestRunTasks, self).get_extension_list() self.mgr.extensions = itertools.chain( self.mgr.extensions, [extension.Extension('testkeystone', None, None, self.PollsterKeystone())])",2,6
openstack%2Foctavia~master~I13a3258200b807f1d011b25574e40affbc9f29d1,openstack/octavia,master,I13a3258200b807f1d011b25574e40affbc9f29d1,Creation of Octavia API Documentation,MERGED,2014-11-21 22:06:47.000000000,2015-01-13 03:36:02.000000000,2015-01-13 03:36:02.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10477}, {'_account_id': 10806}, {'_account_id': 10980}, {'_account_id': 11685}, {'_account_id': 13438}, {'_account_id': 14398}]","[{'number': 1, 'created': '2014-11-21 22:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fd87f661f0fccf831da3d63988fbbcf671ef804b', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 2, 'created': '2014-11-24 21:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/97f3a77bd708106dd9f9d1286c1e196fd7e60472', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 3, 'created': '2014-11-24 21:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/acbda065a78a0b79c4d7c246981d9aae72cd933e', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 4, 'created': '2014-11-25 18:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e8c7f76d891bccf6757438da8cf7e18f87ba3ce9', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 5, 'created': '2014-12-04 22:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c35b3ddfb5b969afee24b2efe73a1a29a64c6823', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 6, 'created': '2014-12-05 19:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b26c6cd51eb18e17333b4f9b8407d0bd6fa7459f', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 7, 'created': '2014-12-05 21:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/62775503f95e33460512606b572b304e21f38af6', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 8, 'created': '2014-12-10 22:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/02d2d1dd598b401b14f60028b50f670e7487ad4d', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 9, 'created': '2014-12-11 16:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/33dae2ae12f249b3886539906dfa58d9ae0062fb', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 10, 'created': '2014-12-12 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e08ec4290493d7c632b22af096a69ab2d2284572', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 11, 'created': '2014-12-15 16:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b7fb98f29da6553010d680f2da2741cfb18db707', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 12, 'created': '2014-12-22 22:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8dc31b982dc8aef957d7fe469baabc94152d85e6', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}, {'number': 13, 'created': '2015-01-09 16:21:21.000000000', 'files': ['doc/source/main/octaviaapi.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/cea3d203815ee3db6032603b4d8521d9a9f3f79f', 'message': 'Creation of Octavia API Documentation\n\nAdded operator api documentation file\n\nChange-Id: I13a3258200b807f1d011b25574e40affbc9f29d1\n'}]",30,136499,cea3d203815ee3db6032603b4d8521d9a9f3f79f,56,8,13,10806,,,0,"Creation of Octavia API Documentation

Added operator api documentation file

Change-Id: I13a3258200b807f1d011b25574e40affbc9f29d1
",git fetch https://review.opendev.org/openstack/octavia refs/changes/99/136499/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/main/octaviaapi.rst'],1,fd87f661f0fccf831da3d63988fbbcf671ef804b,bp/operator-api,"Using Octavia's Operator API ============================ Authentication -------------- Using the 0.5 API ----------------- For the purpose of examples, assume there is an Octavia API server running at the URL ``http://octavia.example.com`` on the default port 80. List Load Balancers ******************* Retrieve a list of load balancers belonging to a user. Issue a ``GET`` request to ``http://octavia.example.com/v0.5/loadbalancers`` to retrieve a list of load balancers. The data is returned as a JSON-encoded mapping in the following format:: {'loadbalancers': [ { 'id': 'uuid', 'vip': { 'net_port_id': 'uuid', 'subnet_id': 'uuid', 'floating_ip_id': 'uuid', 'floating_ip_network_id': 'uuid' }, 'tenant_id': 'uuid', 'name': 'lb_name', 'description': 'lb_description', 'enabled': true, 'provisioning_status': 'ACTIVE', 'operating_status': 'ONLINE' } ]} List Load Balancer Details ************************** Retrieve a specific load balancer's details. Issue a ``GET`` request to ``http://octavia.example.com/v0.5/loadbalancers/{lb_id}`` to retrieve the load balancer details for one with the id ``lb_id``. The data is returned as a JSON-encoded mapping in the following format:: {'loadbalancer': { 'id': 'uuid', 'vip':{ 'net_port_id': 'uuid', 'subnet_id': 'uuid', 'floating_ip_id': 'uuid', 'floating_ip_network_id': 'uuid' }, 'tenant_id': 'uuid', 'name': 'lb_name', 'description': 'lb_description', 'enabled': true, 'provisioning_status': 'ACTIVE', 'operating_status': 'ONLINE' }} Create Load Balancer ******************** Create a load balancer. Issue a ``POST`` request to ``http://octavia.example.com/v0.5/loadbalancers`` to create a load balancer. The request body should be a JSON-encoded mapping in the following format:: {'loadbalancer': { 'vip': { 'net_port_id': 'uuid' }, 'tenant_id': 'uuid', 'name': 'lb_name', 'description': ""lb_description', 'enabled': true }} The response will be a JSON-encoded mapping in the following format:: {'loadbalancer': { 'id': 'uuid', 'vip':{ 'net_port_id': 'uuid', 'subnet_id': 'uuid', 'floating_ip_id': 'uuid', 'floating_ip_network_id': 'uuid' }, 'tenant_id': 'uuid', 'name': 'lb_name', 'description': 'lb_description', 'enabled': true, 'provisioning_status': 'PENDING_CREATE', 'operating_status': 'OFFLINE' }} Update Load Balancer ******************** Issue a ``PUT`` request to ``http://octavia.example.com/v0.5/loadbalancers/{lb_id}`` to create a load balancer. The request body should be a JSON-encoded mapping in the following format:: {'loadbalancer': { 'name': 'diff_lb_name' }} The response will be a JSON-encoded mapping in the following format:: {'loadbalancer': { 'id': 'uuid', 'vip':{ 'net_port_id': 'uuid', 'subnet_id': 'uuid', 'floating_ip_id': 'uuid', 'floating_ip_network_id': 'uuid' }, 'tenant_id': 'uuid', 'name': 'lb_name', 'description': 'lb_description', 'enabled': true, 'provisioning_status': 'PENDING_CREATE', 'operating_status': 'OFFLINE' }} Delete Load Balancer ******************** List Listeners ************** List Listener Details ********************* List Listener Statistics ************************ Create Listener *************** Update Listener *************** Delete Listener *************** List Pools ********** List Pool Details ***************** Create Pool *********** Update Pool *********** Delete Pool *********** List Health Monitor Details *************************** Create Health Monitor ********************* Update Health Monitor ********************* Delete Health Monitor ********************* List Members ************ List Member Details ******************* Create Member ************* Update Member ************* Delete Member ************* ",,196,0
openstack%2Fceilometer~master~Ia2d4dd64ea30df92919fe756281230fdf5f2e767,openstack/ceilometer,master,Ia2d4dd64ea30df92919fe756281230fdf5f2e767,fix the bug in a better way,ABANDONED,2014-12-27 06:07:26.000000000,2015-01-13 03:34:46.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12952}, {'_account_id': 14084}]","[{'number': 1, 'created': '2014-12-27 06:07:26.000000000', 'files': ['ceilometer/compute/virt/inspector.py', 'ceilometer/compute/virt/vmware/inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/437bb300f90ce5a2db62d7381003302e05ad21b2', 'message': 'fix the bug in a better way\n\nChange-Id: Ia2d4dd64ea30df92919fe756281230fdf5f2e767\n'}]",1,144194,437bb300f90ce5a2db62d7381003302e05ad21b2,10,8,1,12260,,,0,"fix the bug in a better way

Change-Id: Ia2d4dd64ea30df92919fe756281230fdf5f2e767
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/94/144194/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/virt/inspector.py', 'ceilometer/compute/virt/vmware/inspector.py']",2,437bb300f90ce5a2db62d7381003302e05ad21b2,fix_bug_1404192,"def validate_instance_status(instance): if instance.to_dict().get('OS-EXT-STS:vm_state', """").lower() != ""active"": raise virt_inspector.InstanceStatusInvalidException(_('VM %s is unavilable, current status is: %s') % (instance.id, instance.to_dict().get('OS-EXT-STS:vm_state', """"))) validate_instance_status(instance) validate_instance_status(instance) validate_instance_status(instance) validate_instance_status(instance)"," if instance.to_dict()['OS-EXT-STS:vm_state'] == ""shutoff"": raise virt_inspector.InstanceIsShutoffException(_('VM %s is shutoff') % instance.id) if instance.to_dict()['OS-EXT-STS:vm_state'] == ""shutoff"": raise virt_inspector.InstanceIsShutoffException(_('VM %s is shutoff') % instance.id) if instance.to_dict()['OS-EXT-STS:vm_state'] == ""shutoff"": raise virt_inspector.InstanceIsShutoffException(_('VM %s is shutoff') % instance.id) if instance.to_dict()['OS-EXT-STS:vm_state'] == ""shutoff"": raise virt_inspector.InstanceIsShutoffException(_('VM %s is shutoff') % instance.id)",10,9
openstack%2Fceilometer~master~I33f39b682da7a941d5b255baf879b1319dd09365,openstack/ceilometer,master,I33f39b682da7a941d5b255baf879b1319dd09365,changed error log format a little bit,ABANDONED,2014-12-27 06:07:26.000000000,2015-01-13 03:34:34.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12952}, {'_account_id': 14084}]","[{'number': 1, 'created': '2014-12-27 06:07:26.000000000', 'files': ['ceilometer/compute/virt/vmware/inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/57fd0495476904b009a2563dd72e4e789dfa6939', 'message': 'changed error log format a little bit\n\nChange-Id: I33f39b682da7a941d5b255baf879b1319dd09365\n'}]",0,144197,57fd0495476904b009a2563dd72e4e789dfa6939,9,7,1,12260,,,0,"changed error log format a little bit

Change-Id: I33f39b682da7a941d5b255baf879b1319dd09365
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/144197/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/virt/vmware/inspector.py'],1,57fd0495476904b009a2563dd72e4e789dfa6939,fix_bug_1404192," raise virt_inspector.InstanceStatusInvalidException(_('VM id[%s] is unavilable, current status is: %s') % (instance.id, instance.to_dict().get('OS-EXT-STS:vm_state', """")))"," raise virt_inspector.InstanceStatusInvalidException(_('VM %s is unavilable, current status is: %s') % (instance.id, instance.to_dict().get('OS-EXT-STS:vm_state', """")))",1,1
openstack%2Fceilometer~master~Ie8a9ade5642ac98ad8d2177c3263821709d20e06,openstack/ceilometer,master,Ie8a9ade5642ac98ad8d2177c3263821709d20e06,fixed a typo,ABANDONED,2014-12-27 06:07:26.000000000,2015-01-13 03:34:13.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12952}, {'_account_id': 14084}]","[{'number': 1, 'created': '2014-12-27 06:07:26.000000000', 'files': ['ceilometer/compute/virt/vmware/inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/56b384444d4f1b0b8a07f823cf0fa3c5c7b6b9d5', 'message': 'fixed a typo\n\nChange-Id: Ie8a9ade5642ac98ad8d2177c3263821709d20e06\n'}]",1,144193,56b384444d4f1b0b8a07f823cf0fa3c5c7b6b9d5,10,7,1,12260,,,0,"fixed a typo

Change-Id: Ie8a9ade5642ac98ad8d2177c3263821709d20e06
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/93/144193/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/virt/vmware/inspector.py'],1,56b384444d4f1b0b8a07f823cf0fa3c5c7b6b9d5,fix_bug_1404192, rx_bytes_rate = (stat_val(VC_NETWORK_RX_COUNTER) * units.Ki) tx_bytes_rate = (stat_val(VC_NETWORK_TX_COUNTER) * units.Ki), rx_bytes_rate = (stat_val[VC_NETWORK_RX_COUNTER] * units.Ki) tx_bytes_rate = (stat_val[VC_NETWORK_TX_COUNTER] * units.Ki),2,2
openstack%2Fceilometer~master~I1354b5f8da93b9b6ed7ae763f79ed817244b3137,openstack/ceilometer,master,I1354b5f8da93b9b6ed7ae763f79ed817244b3137,revised unit test case,ABANDONED,2014-12-27 06:07:26.000000000,2015-01-13 03:34:01.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 12952}, {'_account_id': 14084}]","[{'number': 1, 'created': '2014-12-27 06:07:26.000000000', 'files': ['ceilometer/tests/compute/virt/vmware/test_inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2fd68b0958d4f4ada044df5c41788b16db268035', 'message': 'revised unit test case\n\nChange-Id: I1354b5f8da93b9b6ed7ae763f79ed817244b3137\n'}]",0,144195,2fd68b0958d4f4ada044df5c41788b16db268035,9,7,1,12260,,,0,"revised unit test case

Change-Id: I1354b5f8da93b9b6ed7ae763f79ed817244b3137
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/95/144195/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/compute/virt/vmware/test_inspector.py'],1,2fd68b0958d4f4ada044df5c41788b16db268035,fix_bug_1404192," fake_instance_to_dict = {""OS-EXT-STS:vm_state"":""active""} instance_object.to_dict = lambda: fake_instance_to_dict fake_instance_to_dict = {""OS-EXT-STS:vm_state"":""active""} instance_object.to_dict = lambda: fake_instance_to_dict mock_instance = mock.MagicMock() mock_instance = lambda: {""OS-EXT-STS:vm_state"":""active""} result = self._inspector.inspect_vnic_rates(mock_instance) mock_instance = mock.MagicMock() mock_instance = lambda: {""OS-EXT-STS:vm_state"":""active""} result = self._inspector.inspect_disk_rates(mock_instance)", result = self._inspector.inspect_vnic_rates(mock.MagicMock()) result = self._inspector.inspect_disk_rates(mock.MagicMock()),10,2
openstack%2Fceilometer~master~I52e0bbd962afa77759be6ef407472d545dfcc79d,openstack/ceilometer,master,I52e0bbd962afa77759be6ef407472d545dfcc79d,fixed test case bug,ABANDONED,2014-12-27 06:07:26.000000000,2015-01-13 03:33:03.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 14084}]","[{'number': 1, 'created': '2014-12-27 06:07:26.000000000', 'files': ['ceilometer/tests/compute/virt/vmware/test_inspector.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e34dbb9a4d6f815b4166e9826916cafa03053f8d', 'message': 'fixed test case bug\n\nChange-Id: I52e0bbd962afa77759be6ef407472d545dfcc79d\n'}]",0,144196,e34dbb9a4d6f815b4166e9826916cafa03053f8d,8,6,1,12260,,,0,"fixed test case bug

Change-Id: I52e0bbd962afa77759be6ef407472d545dfcc79d
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/96/144196/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/compute/virt/vmware/test_inspector.py'],1,e34dbb9a4d6f815b4166e9826916cafa03053f8d,fix_bug_1404192," mock_instance.to_dict = lambda: {""OS-EXT-STS:vm_state"":""active""} mock_instance.to_dict = lambda: {""OS-EXT-STS:vm_state"":""active""}"," mock_instance = lambda: {""OS-EXT-STS:vm_state"":""active""} mock_instance = lambda: {""OS-EXT-STS:vm_state"":""active""}",2,2
openstack%2Fpython-openstackclient~master~Ic81ab01aa0cddc15bb27419d7fec3e5a6d4ec0c7,openstack/python-openstackclient,master,Ic81ab01aa0cddc15bb27419d7fec3e5a6d4ec0c7,Upgrade hacking to 0.10,MERGED,2015-01-12 20:23:08.000000000,2015-01-13 03:26:24.000000000,2015-01-13 03:26:23.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-01-12 20:23:08.000000000', 'files': ['test-requirements.txt', 'openstackclient/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b17c475f8a3c5dee7b9ef86e73620b9f819a8942', 'message': 'Upgrade hacking to 0.10\n\nAlso resolve the only error that was produced.\n\nChange-Id: Ic81ab01aa0cddc15bb27419d7fec3e5a6d4ec0c7\n'}]",1,146631,b17c475f8a3c5dee7b9ef86e73620b9f819a8942,10,4,1,6482,,,0,"Upgrade hacking to 0.10

Also resolve the only error that was produced.

Change-Id: Ic81ab01aa0cddc15bb27419d7fec3e5a6d4ec0c7
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/31/146631/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'openstackclient/tests/fakes.py']",2,b17c475f8a3c5dee7b9ef86e73620b9f819a8942,up_hacking,class FakeStdout(object):,class FakeStdout:,2,2
openstack%2Fcinder~stable%2Fjuno~I00fe72153973ed5bded35a71486493a52ad479a7,openstack/cinder,stable/juno,I00fe72153973ed5bded35a71486493a52ad479a7,Cap oslo.i18n at 1.1.0 to avoid breaking stable/juno,ABANDONED,2015-01-12 16:13:41.000000000,2015-01-13 03:26:20.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 6601}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 12202}, {'_account_id': 12491}, {'_account_id': 12492}]","[{'number': 1, 'created': '2015-01-12 16:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f090e61ff808217bc0561780f57b87d28b9a2d1f', 'message': 'Cap oslo.i18n at 1.1.0 to avoid breaking stable/juno\n\nThe new release of oslo.i18n 1.2.0 breaks a number of test\ncases in Cinder.  The test cases in master have been disabled\nand other improvements have been made to be compatible with\noslo.i18n 1.2.0.  Different errors are encountered on stable/juno\nwhen trying to backport the changes.\n\nThe recommendation, at this point, is to cap oslo.i18n at 1.1.0 as\nnone of the changes in master should be needed in stable/juno.\n\nChange-Id: I00fe72153973ed5bded35a71486493a52ad479a7\nPartial-bug: #1408099\n'}, {'number': 2, 'created': '2015-01-12 21:32:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b4df434b1684bb9b984ae783863dcbd773b498d', 'message': 'Cap oslo.i18n at 1.1.0 to avoid breaking stable/juno\n\nThe new release of oslo.i18n 1.2.0 breaks a number of test\ncases in Cinder.  The test cases in master have been disabled\nand other improvements have been made to be compatible with\noslo.i18n 1.2.0.  Different errors are encountered on stable/juno\nwhen trying to backport the changes.\n\nThe recommendation, at this point, is to cap oslo.i18n at 1.1.0 as\nnone of the changes in master should be needed in stable/juno.\n\nChange-Id: I00fe72153973ed5bded35a71486493a52ad479a7\nPartial-bug: #1408099\n'}]",2,146545,8b4df434b1684bb9b984ae783863dcbd773b498d,16,10,2,7198,,,0,"Cap oslo.i18n at 1.1.0 to avoid breaking stable/juno

The new release of oslo.i18n 1.2.0 breaks a number of test
cases in Cinder.  The test cases in master have been disabled
and other improvements have been made to be compatible with
oslo.i18n 1.2.0.  Different errors are encountered on stable/juno
when trying to backport the changes.

The recommendation, at this point, is to cap oslo.i18n at 1.1.0 as
none of the changes in master should be needed in stable/juno.

Change-Id: I00fe72153973ed5bded35a71486493a52ad479a7
Partial-bug: #1408099
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/146545/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f090e61ff808217bc0561780f57b87d28b9a2d1f,bug/1408099,oslo.i18n<=1.1.0 # Apache-2.0,oslo.i18n>=1.0.0 # Apache-2.0,1,1
openstack%2Fnova~master~Ic8b22569a4a8fb05b4d875e34432ada97a52f10c,openstack/nova,master,Ic8b22569a4a8fb05b4d875e34432ada97a52f10c,Move WarningsFixture after DatabaseFixture so emit once,MERGED,2015-01-08 20:41:35.000000000,2015-01-13 03:21:29.000000000,2015-01-12 20:52:04.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6486}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 14384}]","[{'number': 1, 'created': '2015-01-08 20:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ab7d9eecae87460230e01d24f5b8b1ca547aedb', 'message': 'Move WarningsFixture after DatabaseFixture so emit once\n\nThe DatabaseFixture must be messing with the warnings module.\n\nChange-Id: Ic8b22569a4a8fb05b4d875e34432ada97a52f10c\nPartial-Bug: #1407736\n'}, {'number': 2, 'created': '2015-01-08 20:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fac458224019bdc7da28d6b4ac1a12954b860262', 'message': 'Move WarningsFixture after DatabaseFixture so emit once\n\nThe DatabaseFixture must be messing with the warnings module.\n\nChange-Id: Ic8b22569a4a8fb05b4d875e34432ada97a52f10c\nPartial-Bug: #1407736\n'}, {'number': 3, 'created': '2015-01-08 21:40:35.000000000', 'files': ['nova/test.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bcaff21f07763e9dbd859ea81f72cbca83a6e113', 'message': 'Move WarningsFixture after DatabaseFixture so emit once\n\nThe DatabaseFixture must be messing with the warnings module.\n\nChange-Id: Ic8b22569a4a8fb05b4d875e34432ada97a52f10c\nPartial-Bug: #1407736\n'}]",2,145927,bcaff21f07763e9dbd859ea81f72cbca83a6e113,30,9,3,6486,,,0,"Move WarningsFixture after DatabaseFixture so emit once

The DatabaseFixture must be messing with the warnings module.

Change-Id: Ic8b22569a4a8fb05b4d875e34432ada97a52f10c
Partial-Bug: #1407736
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/145927/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/test.py'],1,7ab7d9eecae87460230e01d24f5b8b1ca547aedb,bug/1407736, self.useFixture(nova_fixtures.WarningsFixture()) , self.useFixture(nova_fixtures.WarningsFixture()),2,1
openstack%2Fos-cloud-config~master~I50e36edd10d521f83b05ff68f8f2992537e3668c,openstack/os-cloud-config,master,I50e36edd10d521f83b05ff68f8f2992537e3668c,Updated from global requirements,MERGED,2015-01-08 18:50:18.000000000,2015-01-13 03:04:34.000000000,2015-01-13 03:04:34.000000000,"[{'_account_id': 3}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-01-08 18:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/b5387c84a9e60255fc5091c7643e01e27a036d06', 'message': 'Updated from global requirements\n\nChange-Id: I50e36edd10d521f83b05ff68f8f2992537e3668c\n'}, {'number': 2, 'created': '2015-01-13 00:14:08.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-cloud-config/commit/8f0ff31c51309047353a1b85eca90c4dd27d6f54', 'message': 'Updated from global requirements\n\nChange-Id: I50e36edd10d521f83b05ff68f8f2992537e3668c\n'}]",0,145889,8f0ff31c51309047353a1b85eca90c4dd27d6f54,12,3,2,11131,,,0,"Updated from global requirements

Change-Id: I50e36edd10d521f83b05ff68f8f2992537e3668c
",git fetch https://review.opendev.org/openstack/os-cloud-config refs/changes/89/145889/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b5387c84a9e60255fc5091c7643e01e27a036d06,openstack/requirements,oslo.config>=1.6.0 # Apache-2.0,oslo.config>=1.4.0 # Apache-2.0,1,1
openstack%2Fnetworking-odl~master~I8addb54d519ce1ab4398d32eee1bebf87c5e37b6,openstack/networking-odl,master,I8addb54d519ce1ab4398d32eee1bebf87c5e37b6,Establish a successful baseline for CI jobs,MERGED,2015-01-12 22:40:09.000000000,2015-01-13 02:49:47.000000000,2015-01-13 02:49:47.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 7016}, {'_account_id': 9656}, {'_account_id': 11240}, {'_account_id': 11952}]","[{'number': 1, 'created': '2015-01-12 22:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/ee850d0c1b0eaf3505972376a27790c14d9f6134', 'message': 'Fix test baseline\n\nGo through a number of tweaks to get the first successful test run.\nAlso, prune the requirements to use only the ones that are stricly\nrequired.\n\nChange-Id: I8addb54d519ce1ab4398d32eee1bebf87c5e37b6\n'}, {'number': 2, 'created': '2015-01-13 01:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/1e31a466f06e7b44cab78ce6fd00ebac0bc29dd0', 'message': 'Fix jobs success baseline\n\nGo through a number of tweaks to get the first successful job runs.\nAlso, prune the requirements to use only the ones that are stricly\nrequired.\n\nCurrently a copy of the policy.json file is needed to get existing\ntests to pass. Something smarter will need to be devised to avoid\nholding a copy of a file that ultimately belongs to Neutron core.\n\nChange-Id: I8addb54d519ce1ab4398d32eee1bebf87c5e37b6\n'}, {'number': 3, 'created': '2015-01-13 01:57:26.000000000', 'files': ['test-requirements.txt', 'networking_odl/tests/__init__.py', 'doc/source/usage.rst', 'CONTRIBUTING.rst', 'networking_odl/plugins/ml2/drivers/mechanism_odl.py', 'openstack-common.conf', 'networking_odl/__init__.py', 'networking_odl/openstack/common/_i18n.py', 'networking_odl/openstack/__init__.py', 'etc/policy.json', 'networking_odl/openstack/common/__init__.py', 'networking_odl/openstack/common/local.py', 'networking_odl/tests/unit/ml2/test_mechanism_odl.py', 'networking_odl/openstack/common/eventlet_backdoor.py', 'doc/source/installation.rst', 'networking_odl/openstack/common/periodic_task.py', 'networking_odl/openstack/common/versionutils.py', 'networking_odl/tests/unit/__init__.py', 'networking_odl/openstack/common/fileutils.py', 'networking_odl/openstack/common/log.py', 'networking_odl/tests/unit/db/__init__.py', 'networking_odl/openstack/common/systemd.py', 'networking_odl/openstack/common/loopingcall.py', 'setup.cfg', 'tox.ini', 'doc/source/contributing.rst', 'networking_odl/tests/unit/ml2/__init__.py', '.gitignore', 'networking_odl/plugins/ml2/drivers/__init__.py', 'networking_odl/openstack/common/fixture/logging.py', 'networking_odl/openstack/common/cache/__init__.py', 'networking_odl/openstack/common/middleware/__init__.py', 'networking_odl/openstack/common/cache/backends.py', 'networking_odl/plugins/ml2/__init__.py', 'requirements.txt', 'networking_odl/plugins/ml2/drivers/README.odl', 'networking_odl/openstack/common/context.py', 'networking_odl/openstack/common/policy.py', 'networking_odl/openstack/common/fixture/__init__.py', 'doc/source/conf.py', 'networking_odl/openstack/common/threadgroup.py', 'doc/source/index.rst', 'networking_odl/openstack/common/middleware/catch_errors.py', 'networking_odl/openstack/common/service.py', 'networking_odl/openstack/common/uuidutils.py', '.testr.conf', 'networking_odl/openstack/common/cache/cache.py', 'doc/source/readme.rst', 'networking_odl/openstack/common/middleware/request_id.py'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/dc99cadceeff327ec5decd9430079a948f78e86c', 'message': 'Establish a successful baseline for CI jobs\n\nTweaks involved renaming the odl module to avoid dashes. Also, a copy of\nthe policy.json file was needed to get existing tests to pass. Something\nsmarter will have to be devised to avoid holding a copy of a file that\nultimately belongs to Neutron core. Missing doc files were also added.\n\nLastly, prune the requirements to use only the ones that are stricly\nrequired.\n\nChange-Id: I8addb54d519ce1ab4398d32eee1bebf87c5e37b6\n'}]",0,146668,dc99cadceeff327ec5decd9430079a948f78e86c,13,7,3,748,,,0,"Establish a successful baseline for CI jobs

Tweaks involved renaming the odl module to avoid dashes. Also, a copy of
the policy.json file was needed to get existing tests to pass. Something
smarter will have to be devised to avoid holding a copy of a file that
ultimately belongs to Neutron core. Missing doc files were also added.

Lastly, prune the requirements to use only the ones that are stricly
required.

Change-Id: I8addb54d519ce1ab4398d32eee1bebf87c5e37b6
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/68/146668/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_odl/tests/unit/ml2/__init__.py', '.gitignore', 'test-requirements.txt', 'networking_odl/plugins/ml2/drivers/__init__.py', 'networking_odl/openstack/common/fixture/logging.py', 'networking_odl/tests/__init__.py', 'networking_odl/openstack/common/cache/__init__.py', 'networking_odl/openstack/common/middleware/__init__.py', 'networking_odl/openstack/common/cache/backends.py', 'networking_odl/plugins/ml2/__init__.py', 'requirements.txt', 'networking_odl/plugins/ml2/drivers/mechanism_odl.py', 'networking_odl/plugins/ml2/drivers/README.odl', 'networking_odl/openstack/common/context.py', 'openstack-common.conf', 'networking_odl/__init__.py', 'networking_odl/openstack/common/_i18n.py', 'networking_odl/openstack/__init__.py', 'networking_odl/openstack/common/policy.py', 'networking_odl/openstack/common/fixture/__init__.py', 'networking_odl/openstack/common/__init__.py', 'networking_odl/openstack/common/local.py', 'networking_odl/tests/unit/ml2/test_mechanism_odl.py', 'networking_odl/openstack/common/eventlet_backdoor.py', 'networking_odl/openstack/common/periodic_task.py', 'networking_odl/openstack/common/threadgroup.py', 'networking_odl/openstack/common/versionutils.py', 'networking_odl/openstack/common/middleware/catch_errors.py', 'networking_odl/openstack/common/service.py', 'networking_odl/tests/unit/__init__.py', 'networking_odl/openstack/common/fileutils.py', 'networking_odl/openstack/common/uuidutils.py', 'networking_odl/openstack/common/log.py', '.testr.conf', 'networking_odl/tests/unit/db/__init__.py', 'networking_odl/openstack/common/cache/cache.py', 'networking_odl/openstack/common/systemd.py', 'networking_odl/openstack/common/loopingcall.py', 'setup.cfg', 'tox.ini', 'networking_odl/openstack/common/middleware/request_id.py']",41,ee850d0c1b0eaf3505972376a27790c14d9f6134,fix-baseline,from networking_odl.openstack.common import versionutils,from networking-odl.openstack.common import versionutils,66,143
openstack%2Ftaskflow~master~I2a471d6d1c70d77784c0370ccb3de547590031cf,openstack/taskflow,master,I2a471d6d1c70d77784c0370ccb3de547590031cf,Updated from global requirements,MERGED,2015-01-13 00:16:35.000000000,2015-01-13 02:28:27.000000000,2015-01-13 02:28:27.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-01-13 00:16:35.000000000', 'files': ['requirements-py2.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/45c28bd482971a6cf324ff987114b380e581d1c7', 'message': 'Updated from global requirements\n\nChange-Id: I2a471d6d1c70d77784c0370ccb3de547590031cf\n'}]",0,146712,45c28bd482971a6cf324ff987114b380e581d1c7,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I2a471d6d1c70d77784c0370ccb3de547590031cf
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/12/146712/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-py2.txt', 'requirements-py3.txt']",2,45c28bd482971a6cf324ff987114b380e581d1c7,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,2,2
openstack%2Fmagnum~master~Ie56d32638af04df5c0a6e1684c7673b22c919e0d,openstack/magnum,master,Ie56d32638af04df5c0a6e1684c7673b22c919e0d,Add tests for baymodel rest api,MERGED,2015-01-12 17:17:36.000000000,2015-01-13 02:26:01.000000000,2015-01-13 02:25:58.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-12 17:17:36.000000000', 'files': ['magnum/tests/objects/utils.py', 'magnum/tests/api/controllers/v1/test_baymodel.py', 'magnum/tests/api/utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/794322c2fea865415f72d2b9844fb7a3e8063732', 'message': 'Add tests for baymodel rest api\n\nChange-Id: Ie56d32638af04df5c0a6e1684c7673b22c919e0d\n'}]",0,146579,794322c2fea865415f72d2b9844fb7a3e8063732,7,3,1,11536,,,0,"Add tests for baymodel rest api

Change-Id: Ie56d32638af04df5c0a6e1684c7673b22c919e0d
",git fetch https://review.opendev.org/openstack/magnum refs/changes/79/146579/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/objects/utils.py', 'magnum/tests/api/controllers/v1/test_baymodel.py', 'magnum/tests/api/utils.py']",3,794322c2fea865415f72d2b9844fb7a3e8063732,api,"# -*- encoding: utf-8 -*- # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Utils for testing the API service. """""" from magnum.api.controllers.v1 import baymodel as baymodel_controller from magnum.tests.db import utils def remove_internal(values, internal): # NOTE(yuriyz): internal attributes should not be posted, except uuid int_attr = [attr.lstrip('/') for attr in internal if attr != '/uuid'] return dict([(k, v) for (k, v) in values.iteritems() if k not in int_attr]) def baymodel_post_data(**kw): baymodel = utils.get_test_baymodel(**kw) internal = baymodel_controller.BayModelPatchType.internal_attrs() return remove_internal(baymodel, internal)",,400,43
openstack%2Fmagnum~master~I6a29ab8b7f635c1883f79b672f8b76a2ce94cc6e,openstack/magnum,master,I6a29ab8b7f635c1883f79b672f8b76a2ce94cc6e,Fix the list of unset fields in baymodel,MERGED,2015-01-12 17:17:36.000000000,2015-01-13 02:25:22.000000000,2015-01-13 02:25:20.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-12 17:17:36.000000000', 'files': ['magnum/api/controllers/v1/baymodel.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/566219a1f122cc37501786c2e3b91104f14217f1', 'message': 'Fix the list of unset fields in baymodel\n\nChange-Id: I6a29ab8b7f635c1883f79b672f8b76a2ce94cc6e\n'}]",0,146578,566219a1f122cc37501786c2e3b91104f14217f1,7,3,1,11536,,,0,"Fix the list of unset fields in baymodel

Change-Id: I6a29ab8b7f635c1883f79b672f8b76a2ce94cc6e
",git fetch https://review.opendev.org/openstack/magnum refs/changes/78/146578/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/controllers/v1/baymodel.py'],1,566219a1f122cc37501786c2e3b91104f14217f1,api," baymodel.unset_fields_except(['uuid', 'name', 'image_id', 'apiserver_port'])"," baymodel.unset_fields_except(['uuid', 'name', 'type', 'image_id', 'ironic_baymodel_id', 'apiserver_port'])",2,2
openstack%2Fmagnum~master~I24ab855d2eb0b14a1da3b56808eaf3f10d506ff2,openstack/magnum,master,I24ab855d2eb0b14a1da3b56808eaf3f10d506ff2,Add max_limit to sample config,MERGED,2015-01-12 17:17:36.000000000,2015-01-13 02:23:55.000000000,2015-01-13 02:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-01-12 17:17:36.000000000', 'files': ['etc/magnum/magnum.conf.sample'], 'web_link': 'https://opendev.org/openstack/magnum/commit/01be8b5ba9d699d57750447005e8c5c4bb2017b9', 'message': 'Add max_limit to sample config\n\nChange-Id: I24ab855d2eb0b14a1da3b56808eaf3f10d506ff2\n'}]",0,146577,01be8b5ba9d699d57750447005e8c5c4bb2017b9,9,5,1,11536,,,0,"Add max_limit to sample config

Change-Id: I24ab855d2eb0b14a1da3b56808eaf3f10d506ff2
",git fetch https://review.opendev.org/openstack/magnum refs/changes/77/146577/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/magnum/magnum.conf.sample'],1,01be8b5ba9d699d57750447005e8c5c4bb2017b9,api,# The maximum number of items returned in a single response # from a collection resource. (integer value) #max_limit=1000 ,,4,0
openstack%2Fcinder~master~I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb,openstack/cinder,master,I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb,Make ProphetStor drivers compliant with logging standards,MERGED,2014-12-30 04:13:12.000000000,2015-01-13 02:04:18.000000000,2015-01-05 04:33:59.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 177}, {'_account_id': 1736}, {'_account_id': 5538}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9416}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13628}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-12-30 04:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/acaa5bdb73f50b4b595c67170bc272296a13d25f', 'message': 'Make ProphetStor drivers compliant with loggin standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 2, 'created': '2014-12-31 01:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0654fee5be1df60eb4adaecb5809132b82c652d4', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 3, 'created': '2014-12-31 01:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/485e4e7c98ca64be880484f1a08652e968cfcd68', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 4, 'created': '2014-12-31 01:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/043a17ccd9ec81d1129061402fa473837a8b0bae', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 5, 'created': '2014-12-31 08:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f5ed2cf15d1d44ac88e9c049e384204b0240876', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 6, 'created': '2015-01-03 13:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/09ab0bb434ac3bc823d564e98711818e88d7725b', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\nrecheck\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 7, 'created': '2015-01-03 13:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c292d0b46af43f47ccd24dcaf299894edd9ec49c', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}, {'number': 8, 'created': '2015-01-04 15:57:35.000000000', 'files': ['cinder/volume/drivers/prophetstor/dplcommon.py', 'cinder/volume/drivers/prophetstor/dpl_iscsi.py', 'cinder/volume/drivers/prophetstor/dpl_fc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc3ec5824ef3f91e14eeba2d3b3a1a5efceebd42', 'message': 'Make ProphetStor drivers compliant with logging standards\n\nThe guidelines are specified here:\nhttp://docs.openstack.org/developer/oslo.i18n/guidelines.html\n\nChange-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb\nPartial-Bug: 1384312\n'}]",49,144402,cc3ec5824ef3f91e14eeba2d3b3a1a5efceebd42,66,19,8,9416,,,0,"Make ProphetStor drivers compliant with logging standards

The guidelines are specified here:
http://docs.openstack.org/developer/oslo.i18n/guidelines.html

Change-Id: I9e76f3159ee6fbee2c7394aa59ac05f5904ae1cb
Partial-Bug: 1384312
",git fetch https://review.opendev.org/openstack/cinder refs/changes/02/144402/8 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/prophetstor/dplcommon.py', 'cinder/volume/drivers/prophetstor/dpl_iscsi.py', 'cinder/volume/drivers/prophetstor/dpl_fc.py']",3,acaa5bdb73f50b4b595c67170bc272296a13d25f,bug/1384312,"from cinder.i18n import _, _LE msg = _(""Failed to get fiber channel info from storage due "" ""to %(stat)s"") % {'stat': six.text_type(e)} msg = _(""Failed to get fiber channel target from storage server"" "" due to %(stat)s"") % {'stat': six.text_type(e)} msg = _(""Failed to get target wwpns from storage due "" ""to %(stat)s"") % {'stat': six.text_type(e)} msg = _('Volume %(volumeid)s failed to send assign command, ' 'ret: %(status)s output: %(output)s') % \ msg = _('Flexvisor succeed to unassign volume ' '%(id)s.') % {'id': volumeid} msg = _('initialize_connection volume: %(volume)s, connector:' ' %(connector)s') % {""volume"": volume, ""connector"": connector} msg = _('Prefer use target wwpn %(wwpn)s') % {'wwpn': lsTargetWwpn} msg = _('Failed to export fiber channel target ' 'due to %s') % (six.text_type(e)) msg = _('%(volume)s assign type fibre_channel, properties ' '%(properties)s') % {'volume': volume['id'], 'properties': properties} msg = _('Connect initialization info: ' '{driver_volume_type: fibre_channel, ' 'data: %(properties)s') % {'properties': properties} msg = _('terminate_connection volume: %(volume)s, ' 'connector: %(con)s') % {'volume': volume, 'con': connector}","from cinder.i18n import _, _LI, _LE msg = _LE(""Failed to get fiber channel info from storage due "" ""to %(stat)s"") % {'stat': six.text_type(e)} msg = _LE(""Failed to get fiber channel target from storage server"" "" due to %(stat)s"") % {'stat': six.text_type(e)} msg = _LE(""Failed to get target wwpns from storage due "" ""to %(stat)s"") % {'stat': six.text_type(e)} msg = _LE('Volume %(volumeid)s failed to send assign command, ' 'ret: %(status)s output: %(output)s') % \ msg = _LI('Flexvisor succeed to unassign volume ' '%(id)s.') % {'id': volumeid} msg = _LI('initialize_connection volume: %(volume)s, connector:' ' %(connector)s') % {""volume"": volume, ""connector"": connector} msg = _LI('Prefer use target wwpn %(wwpn)s') % {'wwpn': lsTargetWwpn} msg = _LE('Failed to export fiber channel target ' 'due to %s') % (six.text_type(e)) msg = _LI('%(volume)s assign type fibre_channel, properties ' '%(properties)s') % {'volume': volume['id'], 'properties': properties} msg = _LI('Connect initialization info: ' '{driver_volume_type: fibre_channel, ' 'data: %(properties)s') % {'properties': properties} msg = _LI('terminate_connection volume: %(volume)s, ' 'connector: %(con)s') % {'volume': volume, 'con': connector}",93,98
openstack%2Fcinder~master~I43190d1dac33748fe55fa00f260f32ab209be656,openstack/cinder,master,I43190d1dac33748fe55fa00f260f32ab209be656,Transition LVM Driver to use Target Objects,MERGED,2014-11-18 00:49:32.000000000,2015-01-13 02:04:11.000000000,2015-01-05 21:28:07.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12285}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 14206}, {'_account_id': 14428}]","[{'number': 1, 'created': '2014-11-18 00:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d5de416fbfd401ca3aba5d8e363296646c13688', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\nClean up some more testing\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 2, 'created': '2014-11-18 04:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bf23b55f0b523b4cebc397b5ecfd4e48b879f23a', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\n\n** Currenlty disabled following tests\ncinder.tests.test_volume.VolumeTestCase.test_init_host_count_allocated_capacity\ncinder.tests.test_volume.test_volume.VolumeTestCase.test_run_attach_detach_volume_with_attach_mode\ncinder.tests.test_volume.test_run_attach_detach_volume_for_instance\n\nClean up some more testing\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 3, 'created': '2014-11-19 04:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b313c44e592ca815a9246fb032747e1b18fbe59', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 4, 'created': '2014-11-19 04:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08d87ccf1a702915492e95ee4dee6d233552ec0b', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 5, 'created': '2014-11-19 22:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/21ee609c9b3d0d960b7bfbd442dfe71aa6b3491b', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 6, 'created': '2014-11-19 22:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a03a4b8b9f9523d880478040c90e4e2efbe71d72', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\n*** WIP ***\nRemove cinder/brick/iscsi and cinder/volume/iscsi\nUpdate any drivers that were using the base driver\nwith iSCSI code in it.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 7, 'created': '2014-11-24 16:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e65bbcec38de4f863f8f70c5d90325883039738b', 'message': ""Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\n*** WIP ***\nThree tests in test_volume that still need fixed\ndue to config mocking that I haven't quite figured\nout yet..\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n""}, {'number': 8, 'created': '2014-11-24 23:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/950239c1a18645cdf362ab68b30f94ed5885f4b7', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\n*** WIP ***\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 9, 'created': '2014-11-29 18:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f02c53fb2c3c2f82a6ff121dd27190010b0de1d', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\n*** WIP ***\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 10, 'created': '2014-12-01 17:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3a4a09cb92de9ad1d9378b5e93225a6afcfac517', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\n*** WIP ***\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 11, 'created': '2014-12-01 19:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b9cd23776893e08116416ed5e24efd26d2800892', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\n*** WIP ***\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 12, 'created': '2014-12-01 21:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b96e1e0fba23516fc45936e9d400fa1bf55713d', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 13, 'created': '2014-12-04 18:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e8df973765588bdef6236e1a0eadeb867ff2cbeb', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 14, 'created': '2014-12-04 19:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7237edfcbd00d6442bd2e0b498f54d4444c83ad5', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 15, 'created': '2014-12-07 00:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/87c168ae8b13f4d96092b931e4a595c4ab4868ec', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 16, 'created': '2014-12-08 19:32:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e3755c67258e000f27268edaaae4a6066bf81e4f', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 17, 'created': '2014-12-08 23:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cd7c579ce596b68e99ee4260df707284003e206c', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 18, 'created': '2014-12-17 17:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7366e95016b6bfc4b4758f494d8ae93585fa6cea', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 19, 'created': '2014-12-18 15:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/694b6a5fe52c18c78fa7c138e4fbc580c45ad861', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 20, 'created': '2014-12-18 16:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c685ddc95583d4cd5eb6fc5dc9c5bd25b95fe6a2', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 21, 'created': '2014-12-18 16:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90d8ce7be429d37f9f0a645fa6ed560521e99d10', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 22, 'created': '2014-12-18 22:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed199dc5a5df049780db651242284224460b7d96', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 23, 'created': '2014-12-22 22:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6084140f7b736d1340324268b015ed22ce5c9003', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 24, 'created': '2015-01-02 19:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ad6d279f6c3d3ed79cbdd85f8d7a3027438d4c1', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}, {'number': 25, 'created': '2015-01-02 20:13:49.000000000', 'files': ['cinder/tests/fake_driver.py', 'cinder/volume/drivers/block_device.py', 'cinder/volume/targets/driver.py', 'cinder/volume/iscsi.py', 'cinder/tests/test_iscsi.py', 'cinder/volume/targets/fake.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/tests/test_volume.py', 'cinder/volume/drivers/srb.py', 'cinder/volume/targets/iet.py', 'cinder/volume/targets/iscsi.py', 'cinder/tests/test_block_device.py', 'cinder/volume/driver.py', 'cinder/tests/api/contrib/test_admin_actions.py', 'cinder/tests/test_solidfire.py', 'cinder/brick/iscsi/__init__.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9651f547147188645942466602c92cce06666483', 'message': 'Transition LVM Driver to use Target Objects\n\nThis patch refactors the LVM Driver to take a\nseperate Target object instead of mixing the\ncontrol and data path implementations inside the\ndriver itself.\n\nIt removes the volume/iscsi.py and brick/iscsis/*\nfiles which were duplicating code and actually\nvery messy in terms of where calls were actually\nbeing implemented.\n\nChange-Id: I43190d1dac33748fe55fa00f260f32ab209be656\n'}]",34,135139,9651f547147188645942466602c92cce06666483,174,23,25,2243,,,0,"Transition LVM Driver to use Target Objects

This patch refactors the LVM Driver to take a
seperate Target object instead of mixing the
control and data path implementations inside the
driver itself.

It removes the volume/iscsi.py and brick/iscsis/*
files which were duplicating code and actually
very messy in terms of where calls were actually
being implemented.

Change-Id: I43190d1dac33748fe55fa00f260f32ab209be656
",git fetch https://review.opendev.org/openstack/cinder refs/changes/39/135139/6 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/targets/fake.py', 'cinder/tests/api/contrib/test_admin_actions.py', 'cinder/tests/test_volume.py', 'cinder/volume/drivers/lvm.py']",4,3d5de416fbfd401ca3aba5d8e363296646c13688,140451,"from cinder.openstack.common import importutils# FIXME(jdg): We'll put the lvm_ prefix back on these when we # move over to using this as the real LVM driver, for now we'll # rename them so that the config generation utility doesn't barf # on duplicate entries.TARGET_MAPPING = { 'fake': 'cinder.volume.targets.fake.FakeTarget', 'ietadm': 'cinder.volume.targets.tgt.IetAdm', 'iseradm': 'cinder.volume.targets.tgt.ISERTgtAdm', 'lioadm': 'cinder.volume.targets.tgt.LioAdm', 'tgtadm': 'cinder.volume.targets.tgt.TgtAdm', } VERSION = '3.0.0' # Parent sets db, host, _execute and base config # Target Driver is what handles data-transport # Transport specific code should NOT be in # the driver (control path), this way # different target drivers can be added (iscsi, FC etc) target_driver = \ TARGET_MAPPING[self.configuration.safe_get('iscsi_helper')] LOG.debug('Attempting to initialize LVM driver with the ' 'following target_driver: %s', target_driver) self.target_driver = importutils.import_object( target_driver, configuration=self.configuration, db=self.db, executor=self._execute) self.protocol = self.target_driver.protocol def _update_volume_stats(self): """"""Retrieve stats info from volume group."""""" LOG.debug((""Updating volume stats"")) if self.vg is None: LOG.warning(_('Unable to update stats on non-initialized ' 'Volume Group: %s'), self.configuration.volume_group) return self.vg.update_volume_group_info() data = {} # Note(zhiteng): These information are driver/backend specific, # each driver may define these values in its own config options # or fetch from driver specific configuration file. data[""volume_backend_name""] = self.backend_name data[""vendor_name""] = 'Open Source' data[""driver_version""] = self.VERSION data[""storage_protocol""] = self.protocol data[""pools""] = [] if self.configuration.lvm_mirrors > 0: total_capacity =\ self.vg.vg_mirror_size(self.configuration.lvm_mirrors) free_capacity =\ self.vg.vg_mirror_free_space(self.configuration.lvm_mirrors) elif self.configuration.lvm_type == 'thin': total_capacity = self.vg.vg_thin_pool_size free_capacity = self.vg.vg_thin_pool_free_space else: total_capacity = self.vg.vg_size free_capacity = self.vg.vg_free_space location_info = \ ('LVMVolumeDriver:%(hostname)s:%(vg)s' ':%(lvm_type)s:%(lvm_mirrors)s' % {'hostname': self.hostname, 'vg': self.configuration.volume_group, 'lvm_type': self.configuration.lvm_type, 'lvm_mirrors': self.configuration.lvm_mirrors}) # Skip enabled_pools setting, treat the whole backend as one pool # XXX FIXME if multipool support is added to LVM driver. single_pool = {} single_pool.update(dict( pool_name=data[""volume_backend_name""], total_capacity_gb=total_capacity, free_capacity_gb=free_capacity, reserved_percentage=self.configuration.reserved_percentage, location_info=location_info, QoS_support=False, )) data[""pools""].append(single_pool) self._stats = data def check_for_setup_error(self): """"""Verify that requirements are in place to use LVM driver."""""" if self.vg is None: root_helper = utils.get_root_helper() try: self.vg = lvm.LVM(self.configuration.volume_group, root_helper, lvm_type=self.configuration.lvm_type, executor=self._execute) except brick_exception.VolumeGroupNotFound: message = (""Volume Group %s does not exist"" % self.configuration.volume_group) raise exception.VolumeBackendAPIException(data=message) vg_list = volutils.get_all_volume_groups( self.configuration.volume_group) vg_dict = \ (vg for vg in vg_list if vg['name'] == self.vg.vg_name).next() if vg_dict is None: message = (""Volume Group %s does not exist"" % self.configuration.volume_group) raise exception.VolumeBackendAPIException(data=message) if self.configuration.lvm_type == 'thin': # Specific checks for using Thin provisioned LV's if not volutils.supports_thin_provisioning(): message = (""Thin provisioning not supported "" ""on this version of LVM."") raise exception.VolumeBackendAPIException(data=message) pool_name = ""%s-pool"" % self.configuration.volume_group if self.vg.get_volume(pool_name) is None: try: self.vg.create_thin_pool(pool_name) except processutils.ProcessExecutionError as exc: exception_message = (""Failed to create thin pool, "" ""error message was: %s"" % exc.stderr) raise exception.VolumeBackendAPIException( data=exception_message) message = (""Destination Volume Group %s does not exist"" % LOG.error(_('%s'), message) model_update = self.create_export(ctxt, volume) # ####### Interface methods for DataPath (Target Driver) ######## def ensure_export(self, context, volume): volume_name = volume['name'] volume_path = ""/dev/%s/%s"" % (self.configuration.volume_group, volume_name) model_update = \ self.target_driver.ensure_export(context, volume, volume_path=volume_path) return model_update def create_export(self, context, volume): volume_path = ""/dev/%s/%s"" % (self.configuration.volume_group, volume['name']) export_info = self.target_driver.create_export(context, volume, volume_path) return {'provider_location': export_info['location'], 'provider_auth': export_info['auth'], } def remove_export(self, context, volume): self.target_driver.remove_export(context, volume) def initialize_connection(self, volume, connector): return self.target_driver.initialize_connection(volume, connector) def validate_connector(self, connector): return self.target_driver.validate_connector(connector) def terminate_connection(self, volume, connector, **kwargs): pass class LVMISCSIDriver(LVMVolumeDriver): """"""Empty class designation for LVMISCSI. Since we've decoupled the inheritance of iSCSI and LVM we don't really need this class any longer. We do however want to keep it (at least for now). def __init__(self, *args, **kwargs): super(LVMISCSIDriver, self).__init__(*args, **kwargs) class LVMISERDriver(LVMVolumeDriver): """"""Empty class designation for LVMISER. Since we've decoupled the inheritance of data path in LVM we don't really need this class any longer. We do however want to keep it (at least for now). """""" def __init__(self, *args, **kwargs): super(LVMISERDriver, self).__init__(*args, **kwargs) LOG.debug('Attempting to initialize LVM driver with the ' 'following target_driver: ' 'cinder.volume.targets.iser.ISERTgtAdm') self.target_driver = importutils.import_object( 'cinder.volume.targets.iser.ISERTgtAdm', configuration=self.configuration, db=self.db, executor=self._execute)","# Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # VERSION = '2.0.0' self.protocol = 'local' def set_execute(self, execute): self._execute = execute def check_for_setup_error(self): """"""Verify that requirements are in place to use LVM driver."""""" if self.vg is None: root_helper = utils.get_root_helper() try: self.vg = lvm.LVM(self.configuration.volume_group, root_helper, lvm_type=self.configuration.lvm_type, executor=self._execute) except brick_exception.VolumeGroupNotFound: message = (""Volume Group %s does not exist"" % self.configuration.volume_group) raise exception.VolumeBackendAPIException(data=message) vg_list = volutils.get_all_volume_groups( self.configuration.volume_group) vg_dict = \ (vg for vg in vg_list if vg['name'] == self.vg.vg_name).next() if vg_dict is None: message = (""Volume Group %s does not exist"" % self.configuration.volume_group) raise exception.VolumeBackendAPIException(data=message) if self.configuration.lvm_type == 'thin': # Specific checks for using Thin provisioned LV's if not volutils.supports_thin_provisioning(): message = (""Thin provisioning not supported "" ""on this version of LVM."") raise exception.VolumeBackendAPIException(data=message) pool_name = ""%s-pool"" % self.configuration.volume_group if self.vg.get_volume(pool_name) is None: try: self.vg.create_thin_pool(pool_name) except processutils.ProcessExecutionError as exc: exception_message = (""Failed to create thin pool, "" ""error message was: %s"" % exc.stderr) raise exception.VolumeBackendAPIException( data=exception_message) def _update_volume_stats(self): """"""Retrieve stats info from volume group."""""" LOG.debug(""Updating volume stats"") if self.vg is None: LOG.warning(_('Unable to update stats on non-initialized ' 'Volume Group: %s'), self.configuration.volume_group) return self.vg.update_volume_group_info() data = {} # Note(zhiteng): These information are driver/backend specific, # each driver may define these values in its own config options # or fetch from driver specific configuration file. data[""volume_backend_name""] = self.backend_name data[""vendor_name""] = 'Open Source' data[""driver_version""] = self.VERSION data[""storage_protocol""] = self.protocol data[""pools""] = [] total_capacity = 0 free_capacity = 0 if self.configuration.lvm_mirrors > 0: total_capacity = \ self.vg.vg_mirror_size(self.configuration.lvm_mirrors) free_capacity = \ self.vg.vg_mirror_free_space(self.configuration.lvm_mirrors) elif self.configuration.lvm_type == 'thin': total_capacity = self.vg.vg_thin_pool_size free_capacity = self.vg.vg_thin_pool_free_space else: total_capacity = self.vg.vg_size free_capacity = self.vg.vg_free_space location_info = \ ('LVMVolumeDriver:%(hostname)s:%(vg)s' ':%(lvm_type)s:%(lvm_mirrors)s' % {'hostname': self.hostname, 'vg': self.configuration.volume_group, 'lvm_type': self.configuration.lvm_type, 'lvm_mirrors': self.configuration.lvm_mirrors}) # Skip enabled_pools setting, treat the whole backend as one pool # XXX FIXME if multipool support is added to LVM driver. single_pool = {} single_pool.update(dict( pool_name=data[""volume_backend_name""], total_capacity_gb=total_capacity, free_capacity_gb=free_capacity, reserved_percentage=self.configuration.reserved_percentage, location_info=location_info, QoS_support=False, )) data[""pools""].append(single_pool) self._stats = data def get_pool(self, volume): return self.backend_name class LVMISCSIDriver(LVMVolumeDriver, driver.ISCSIDriver): """"""Executes commands relating to ISCSI volumes. We make use of model provider properties as follows: ``provider_location`` if present, contains the iSCSI target information in the same format as an ietadm discovery i.e. '<ip>:<port>,<portal> <target IQN>' ``provider_auth`` if present, contains a space-separated triple: '<auth method> <auth username> <auth password>'. `CHAP` is the only auth_method in use at the moment. """""" def __init__(self, *args, **kwargs): self.db = kwargs.get('db') self.target_helper = self.get_target_helper(self.db) super(LVMISCSIDriver, self).__init__(*args, **kwargs) self.backend_name =\ self.configuration.safe_get('volume_backend_name') or 'LVM_iSCSI' self.protocol = 'iSCSI' def set_execute(self, execute): super(LVMISCSIDriver, self).set_execute(execute) if self.target_helper is not None: self.target_helper.set_execute(execute) def _create_target(self, iscsi_name, iscsi_target, volume_path, chap_auth, lun=0, check_exit_code=False, old_name=None): # NOTE(jdg): tgt driver has an issue where with a lot of activity # (or sometimes just randomly) it will get *confused* and attempt # to reuse a target ID, resulting in a target already exists error # Typically a simple retry will address this # For now we have this while loop, might be useful in the # future to throw a retry decorator in common or utils attempts = 2 while attempts > 0: attempts -= 1 try: # NOTE(jdg): For TgtAdm case iscsi_name is all we need # should clean this all up at some point in the future tid = self.target_helper.create_iscsi_target( iscsi_name, iscsi_target, 0, volume_path, chap_auth, check_exit_code=check_exit_code, old_name=old_name) break except brick_exception.ISCSITargetCreateFailed: if attempts == 0: raise else: LOG.warning(_('Error creating iSCSI target, retrying ' 'creation for target: %s') % iscsi_name) return tid def ensure_export(self, context, volume): volume_name = volume['name'] iscsi_name = ""%s%s"" % (self.configuration.iscsi_target_prefix, volume_name) volume_path = ""/dev/%s/%s"" % (self.configuration.volume_group, volume_name) # NOTE(jdg): For TgtAdm case iscsi_name is the ONLY param we need # should clean this all up at some point in the future model_update = self.target_helper.ensure_export( context, volume, iscsi_name, volume_path, self.configuration.volume_group, self.configuration) if model_update: self.db.volume_update(context, volume['id'], model_update) def create_export(self, context, volume): return self._create_export(context, volume) def _create_export(self, context, volume, vg=None): """"""Creates an export for a logical volume."""""" if vg is None: vg = self.configuration.volume_group volume_path = ""/dev/%s/%s"" % (vg, volume['name']) data = self.target_helper.create_export(context, volume, volume_path, self.configuration) return { 'provider_location': data['location'], 'provider_auth': data['auth'], } def remove_export(self, context, volume): self.target_helper.remove_export(context, volume) message = (_(""Destination Volume Group %s does not exist"") % LOG.error(message) model_update = self._create_export(ctxt, volume, vg=dest_vg) def _iscsi_location(self, ip, target, iqn, lun=None): return ""%s:%s,%s %s %s"" % (ip, self.configuration.iscsi_port, target, iqn, lun) def _iscsi_authentication(self, chap, name, password): return ""%s %s %s"" % (chap, name, password) class LVMISERDriver(LVMISCSIDriver, driver.ISERDriver): """"""Executes commands relating to ISER volumes. We make use of model provider properties as follows: ``provider_location`` if present, contains the iSER target information in the same format as an ietadm discovery i.e. '<ip>:<port>,<portal> <target IQN>' ``provider_auth`` if present, contains a space-separated triple: '<auth method> <auth username> <auth password>'. `CHAP` is the only auth_method in use at the moment. def __init__(self, *args, **kwargs): self.target_helper = self.get_target_helper(kwargs.get('db')) LVMVolumeDriver.__init__(self, *args, **kwargs) self.backend_name =\ self.configuration.safe_get('volume_backend_name') or 'LVM_iSER' self.protocol = 'iSER'",255,262
openstack%2Fcinder~master~Ib0d36ad878613daa55b286337d61b7e7463378d3,openstack/cinder,master,Ib0d36ad878613daa55b286337d61b7e7463378d3,Convert mox to mock: tests/test_glusterfs.py,MERGED,2014-12-17 10:15:21.000000000,2015-01-13 02:04:09.000000000,2015-01-02 18:13:08.000000000,"[{'_account_id': 3}, {'_account_id': 177}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 10796}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13527}, {'_account_id': 13636}, {'_account_id': 13900}, {'_account_id': 14428}]","[{'number': 1, 'created': '2014-12-17 10:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80365a6f304b096dd6154673c1e29d5bbdfaa76f', 'message': 'Convert mox to mock: tests/test_glusterfs.py\n\nReplace mox testing library by mock in the file\ncinder/tests/test_glusterfs.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: Ib0d36ad878613daa55b286337d61b7e7463378d3\n'}, {'number': 2, 'created': '2014-12-23 09:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/38523828afcac73618ee7634691408e3baa86b47', 'message': 'Convert mox to mock: tests/test_glusterfs.py\n\nReplace mox testing library by mock in the file\ncinder/tests/test_glusterfs.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: Ib0d36ad878613daa55b286337d61b7e7463378d3\n'}, {'number': 3, 'created': '2014-12-30 13:08:18.000000000', 'files': ['cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/37daf03b634792e903d2db3ede27330c08bfa680', 'message': 'Convert mox to mock: tests/test_glusterfs.py\n\nReplace mox testing library by mock in the file\ncinder/tests/test_glusterfs.py\n\nImplements: blueprint mox-to-mock-conversion\nChange-Id: Ib0d36ad878613daa55b286337d61b7e7463378d3\n'}]",3,142412,37daf03b634792e903d2db3ede27330c08bfa680,59,21,3,13527,,,0,"Convert mox to mock: tests/test_glusterfs.py

Replace mox testing library by mock in the file
cinder/tests/test_glusterfs.py

Implements: blueprint mox-to-mock-conversion
Change-Id: Ib0d36ad878613daa55b286337d61b7e7463378d3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/142412/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_glusterfs.py'],1,80365a6f304b096dd6154673c1e29d5bbdfaa76f,glusterfs-mox-to-mock-conversion," self._configuration = mock.MagicMock() with contextlib.nested( mock.patch.object(rfsclient, 'set_execute') ) as (mock_set_execute,): def my_execute(*a, **k): pass drv.set_execute(my_execute) mock_set_execute.assert_called_once_with(my_execute) with contextlib.nested( mock.patch.object(drv, '_execute') ) as (mock_execute,): drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT) expected = [mock.call('mkdir', '-p', '/mnt/glusterfs'), mock.call('mount', '-t', 'glusterfs', 'glusterfs-host1:/export', '/mnt/glusterfs', run_as_root=True)] self.assertEqual(mock_execute.mock_calls, expected) with contextlib.nested( mock.patch.object(drv, '_execute') ) as (mock_execute,): execute_iterable = (None, putils.ProcessExecutionError( stderr='is busy or already mounted')) mock_execute.side_effect = execute_iterable drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT, ensure=True) expected = [mock.call('mkdir', '-p', '/mnt/glusterfs'), mock.call('mount', '-t', 'glusterfs', 'glusterfs-host1:/export', '/mnt/glusterfs', run_as_root=True)] self.assertEqual(mock_execute.mock_calls, expected) with contextlib.nested( mock.patch.object(drv, '_execute') ) as (mock_execute,): execute_iterable = (None, putils.ProcessExecutionError( stderr='is busy or already mounted')) mock_execute.side_effect = execute_iterable self.assertRaises(putils.ProcessExecutionError, drv._mount_glusterfs, self.TEST_EXPORT1, self.TEST_MNT_POINT, ensure=False) expected = [mock.call('mkdir', '-p', '/mnt/glusterfs'), mock.call('mount', '-t', 'glusterfs', 'glusterfs-host1:/export', '/mnt/glusterfs', run_as_root=True)] self.assertEqual(mock_execute.mock_calls, expected) with contextlib.nested( mock.patch.object(drv, '_execute') ) as (mock_execute,): drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT) expected = [mock.call('mkdir', '-p', '/mnt/glusterfs'), mock.call('mount', '-t', 'glusterfs', 'glusterfs-host1:/export', '/mnt/glusterfs', run_as_root=True)] self.assertEqual(mock_execute.mock_calls, expected) with contextlib.nested( mock.patch.object(brick.remotefs.remotefs.RemoteFsClient, 'get_mount_point') ) as (mock_get_mount_point,): mock_get_mount_point.return_value = hashed_path result = drv._get_mount_point_for_share(self.TEST_EXPORT1) self.assertEqual(result, hashed_path) with contextlib.nested( mock.patch.object(drv, '_get_mount_point_for_share'), mock.patch.object(drv, '_execute') ) as (mock_get_mount_point_for_share, mock_execute): mock_get_mount_point_for_share.\ return_value = self.TEST_MNT_POINT mock_execute.return_value = (df_output, None) result = drv._get_available_capacity(self.TEST_EXPORT1) self.assertEqual(result, (df_avail, df_total_size)) with contextlib.nested( mock.patch.object(drv, '_read_config_file') ) as (mock_read_config_file,): config_data = [] config_data.append(self.TEST_EXPORT1) config_data.append('#' + self.TEST_EXPORT2) config_data.append(self.TEST_EXPORT2 + ' ' + self.TEST_EXPORT2_OPTIONS) config_data.append('broken:share_format') config_data.append('') mock_read_config_file.return_value = config_data drv._load_shares_config(drv.configuration.glusterfs_shares_config) self.assertIn(self.TEST_EXPORT1, drv.shares) self.assertIn(self.TEST_EXPORT2, drv.shares) self.assertEqual(len(drv.shares), 2) self.assertEqual(drv.shares[self.TEST_EXPORT2], self.TEST_EXPORT2_OPTIONS) with contextlib.nested( mock.patch.object(utils, 'get_file_mode'), mock.patch.object(utils, 'get_file_gid'), mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_ensure_share_writable'), mock.patch.object(drv, '_get_mount_point_for_share'), mock.patch.object(drv, '_mount_glusterfs') ) as (mock_get_file_mode, mock_get_file_gid, mock_execute, mock_ensure_share_writable, mock_get_mount_point_for_share, mock_mount_glusterfs): mock_get_mount_point_for_share.return_value = self.TEST_MNT_POINT mock_get_file_mode.return_value = 0o777 mock_get_file_gid.return_value = 333333 drv._ensure_share_mounted(self.TEST_EXPORT1) mock_get_file_mode.assert_called_once_with(self.TEST_MNT_POINT) mock_get_file_gid.assert_called_once_with(self.TEST_MNT_POINT) mock_ensure_share_writable.assert_called_once_with( self.TEST_MNT_POINT) with contextlib.nested( mock.patch.object(drv, '_read_config_file'), mock.patch.object(drv, '_ensure_share_mounted') ) as (mock_read_config_file, mock_ensure_share_mounted): config_data = [] config_data.append(self.TEST_EXPORT1) mock_read_config_file.return_value = config_data drv._ensure_shares_mounted() mock_ensure_share_mounted.\ assert_called_once_with(self.TEST_EXPORT1) self.assertEqual(1, len(drv._mounted_shares)) self.assertEqual(self.TEST_EXPORT1, drv._mounted_shares[0]) with contextlib.nested( mock.patch.object(drv, '_read_config_file'), mock.patch.object(drv, '_ensure_share_mounted') ) as (mock_read_config_file, mock_ensure_share_mounted): config_data = [] config_data.append(self.TEST_EXPORT1) mock_read_config_file.return_value = config_data mock_ensure_share_mounted.side_effect = Exception() drv._ensure_shares_mounted() self.assertEqual(0, len(drv._mounted_shares)) mock.MagicMock()) @mock.patch.object(os.path, 'exists') def test_setup_should_throw_exception_if_client_is_not_installed( self, mock_exists): with contextlib.nested( mock.patch.object(drv, '_execute') ) as (mock_execute,): mock_exists.return_value = True mock_execute.side_effect = OSError(errno.ENOENT, 'No such file or directory') self.assertRaisesAndMessageMatches(exception.GlusterfsException, 'mount.glusterfs is not ' 'installed', drv.do_setup, mock.MagicMock()) def _fake_load_shares_config(self, config): @mock.patch.object(os, 'getegid') @mock.patch.object(os.path, 'exists') def test_setup_set_share_permissions(self, mock_exists, mock_getegid): with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(utils, 'get_file_gid'), mock.patch.object(utils, 'get_file_mode'), mock.patch.object(tempfile, 'NamedTemporaryFile') ) as (mock_execute, mock_get_file_gid, mock_get_file_mode, mock_named_temp): drv._load_shares_config = self._fake_load_shares_config mock_named_temp.return_value = self._fake_NamedTemporaryFile mock_exists.return_value = True mock_get_file_gid.return_value = 33333 mock_get_file_mode.return_value = 0o000 mock_getegid.return_value = 888 drv.do_setup(mock.MagicMock()) expected = [ mock.call('mount.glusterfs', check_exit_code=False), mock.call('umount', '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005', run_as_root=True), mock.call('mkdir', '-p', '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005'), mock.call('mount', '-t', 'glusterfs', '127.7.7.7:/gluster1', '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005', run_as_root=True), mock.call('chgrp', 888, '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005', run_as_root=True), mock.call('chmod', 'g+w', '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005', run_as_root=True)] self.assertEqual(mock_execute.mock_calls, expected) with contextlib.nested( mock.patch.object(drv, '_get_available_capacity') ) as (mock_get_available_capacity,): capacity = {self.TEST_EXPORT1: (2 * units.Gi, 5 * units.Gi), self.TEST_EXPORT2: (3 * units.Gi, 10 * units.Gi)} def capacity_side_effect(*args, **kwargs): return capacity[args[0]] mock_get_available_capacity.side_effect = capacity_side_effect self.assertEqual(self.TEST_EXPORT2, drv._find_share(self.TEST_SIZE_IN_GB)) drv._mounted_shares = [self.TEST_EXPORT1, self.TEST_EXPORT2] with contextlib.nested( mock.patch.object(drv, '_get_available_capacity') ) as (mock_get_available_capacity,): capacity = {self.TEST_EXPORT1: (0, 5 * units.Gi), self.TEST_EXPORT2: (0, 10 * units.Gi)} def capacity_side_effect(*args, **kwargs): return capacity[args[0]] mock_get_available_capacity.side_effect = capacity_side_effect self.assertRaises(exception.GlusterfsNoSuitableShareFound, drv._find_share, self.TEST_SIZE_IN_GB) with contextlib.nested( mock.patch.object(drv, '_create_sparsed_file'), mock.patch.object(drv, '_set_rw_permissions_for_all') ) as (mock_create_sparsed_file, mock_set_rw_permissions_for_all): drv._do_create_volume(volume) volume_path = drv.local_path(volume) volume_size = volume['size'] mock_create_sparsed_file.assert_called_once_with(volume_path, volume_size) mock_set_rw_permissions_for_all.\ assert_called_once_with(volume_path) with contextlib.nested( mock.patch.object(drv, '_create_regular_file'), mock.patch.object(drv, '_set_rw_permissions_for_all') ) as (mock_create_regular_file, mock_set_rw_permissions_for_all): drv._do_create_volume(volume) volume_path = drv.local_path(volume) volume_size = volume['size'] mock_create_regular_file.assert_called_once_with(volume_path, volume_size) mock_set_rw_permissions_for_all.\ assert_called_once_with(volume_path) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_set_rw_permissions_for_all') ) as (mock_execute, mock_set_rw_permissions_for_all): hashed = drv._get_hash_str(volume['provider_location']) path = '%s/%s/volume-%s' % (self.TEST_MNT_POINT_BASE, hashed, self.VOLUME_UUID) drv._do_create_volume(volume) volume_path = drv.local_path(volume) volume_size = volume['size'] mock_execute.assert_called_once_with('qemu-img', 'create', '-f', 'qcow2', '-o', 'preallocation=metadata', path, str(volume_size * units.Gi), run_as_root=True) mock_set_rw_permissions_for_all.\ assert_called_once_with(volume_path) with contextlib.nested( mock.patch.object(glusterfs, 'LOG'), mock.patch.object(drv, '_find_share'), mock.patch.object(drv, '_do_create_volume'), mock.patch.object(drv, '_ensure_shares_mounted') ) as (mock_log, mock_find_share, mock_do_create_volume, mock_ensure_shares_mounted): volume = DumbVolume() volume['size'] = self.TEST_SIZE_IN_GB drv.create_volume(volume) with contextlib.nested( mock.patch.object(glusterfs, 'LOG'), mock.patch.object(drv, '_find_share'), mock.patch.object(drv, '_do_create_volume'), mock.patch.object(drv, '_ensure_shares_mounted') ) as (mock_log, mock_find_share, mock_do_create_volume, mock_ensure_shares_mounted): mock_find_share.return_value = self.TEST_EXPORT1 volume = DumbVolume() volume['size'] = self.TEST_SIZE_IN_GB result = drv.create_volume(volume) self.assertEqual(self.TEST_EXPORT1, result['provider_location']) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_create_snapshot'), mock.patch.object(drv, '_delete_snapshot'), mock.patch.object(drv, '_read_info_file'), mock.patch.object(image_utils, 'convert_image'), mock.patch.object(drv, '_copy_volume_from_snapshot') ) as (mock_create_snapshot, mock_delete_snapshot, mock_read_info_file, mock_convert_image, mock_copy_volume_from_snapshot): volume = self._simple_volume() src_vref = self._simple_volume() src_vref['id'] = '375e32b2-804a-49f2-b282-85d1d5a5b9e1' src_vref['name'] = 'volume-%s' % src_vref['id'] volume_ref = {'id': volume['id'], 'name': volume['name'], 'status': volume['status'], 'provider_location': volume['provider_location'], 'size': volume['size']} snap_ref = {'volume_name': src_vref['name'], 'name': 'clone-snap-%s' % src_vref['id'], 'size': src_vref['size'], 'volume_size': src_vref['size'], 'volume_id': src_vref['id'], 'id': 'tmp-snap-%s' % src_vref['id'], 'volume': src_vref} drv.create_cloned_volume(volume, src_vref) mock_create_snapshot.assert_called_once_with(snap_ref) mock_copy_volume_from_snapshot.\ assert_called_once_with(snap_ref, volume_ref, volume['size']) self.assertTrue(mock_delete_snapshot.called) with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_ensure_share_mounted') ) as (mock_execute, mock_ensure_share_mounted): volume = DumbVolume() volume['name'] = 'volume-123' volume['provider_location'] = self.TEST_EXPORT1 drv.delete_volume(volume) mock_ensure_share_mounted.\ assert_called_once_with(self.TEST_EXPORT1) with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_ensure_share_mounted') ) as (mock_execute, mock_ensure_share_mounted): volume = DumbVolume() volume['name'] = 'volume-123' volume['provider_location'] = None drv.delete_volume(volume) self.assertFalse(mock_ensure_share_mounted.called) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_read_file') ) as (mock_read_file,): hashed = drv._get_hash_str(self.TEST_EXPORT1) volume_path = '%s/%s/volume-%s' % (self.TEST_MNT_POINT_BASE, hashed, self.VOLUME_UUID) info_path = '%s%s' % (volume_path, '.info') mock_read_file.return_value = '{""%(id)s"": ""volume-%(id)s""}' %\ {'id': self.VOLUME_UUID} volume = DumbVolume() volume['id'] = self.VOLUME_UUID volume['name'] = 'volume-%s' % self.VOLUME_UUID info = drv._read_info_file(info_path) self.assertEqual(info[self.VOLUME_UUID], 'volume-%s' % self.VOLUME_UUID) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(image_utils, 'resize_image') ) as (mock_execute, mock_get_active_image_from_info, mock_qemu_img_info, mock_resize_image): mock_get_active_image_from_info.return_value = volume['name'] mock_qemu_img_info.return_value = img_info drv.extend_volume(volume, 3) self.assertTrue(mock_resize_image.called) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_do_create_snapshot'), mock.patch.object(db, 'snapshot_get'), mock.patch.object(drv, '_nova'), mock.patch.object(time, 'sleep') ) as (mock_execute, mock_do_create_snapshot, mock_snapshot_get, mock_nova, mock_sleep): create_info = {'snapshot_id': snap_ref['id'], 'type': 'qcow2', 'new_file': snap_file} snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' mock_snapshot_get.side_effect = [ snap_ref_progress_0p, snap_ref_progress_50p, snap_ref_progress_90p ] drv._create_snapshot_online(snap_ref, snap_file, snap_path) mock_do_create_snapshot.\ assert_called_once_with(snap_ref, snap_file, snap_path) mock_nova.create_volume_snapshot.\ assert_called_once_with(ctxt, self.VOLUME_UUID, create_info) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_do_create_snapshot'), mock.patch.object(db, 'snapshot_get'), mock.patch.object(drv, '_nova'), mock.patch.object(time, 'sleep') ) as (mock_execute, mock_do_create_snapshot, mock_snapshot_get, mock_nova, mock_sleep): snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' snap_ref_progress_99p = snap_ref_progress.copy() snap_ref_progress_99p['progress'] = '99%' snap_ref_progress_99p['status'] = 'error' mock_snapshot_get.side_effect = [ snap_ref_progress_0p, snap_ref_progress_50p, snap_ref_progress_99p ] self.assertRaisesAndMessageMatches( exception.RemoteFSException, 'Nova returned ""error"" status while creating snapshot.', drv._create_snapshot_online, snap_ref, snap_file, snap_path) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_nova'), mock.patch.object(time, 'sleep'), mock.patch.object(drv, '_read_info_file'), mock.patch.object(drv, '_write_info_file'), mock.patch.object(db, 'snapshot_get'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(drv, '_ensure_share_writable') ) as (mock_execute, mock_nova, mock_sleep, mock_read_info_file, mock_write_info_file, mock_snapshot_get, mock_qemu_img_info, mock_ensure_share_writable): snap_info = {'active': snap_file, self.SNAP_UUID: snap_file} mock_read_info_file.return_value = snap_info qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) paths = {snap_path: img_info, volume_path: volume_img_info} def img_info_side_effect(*args, **kwargs): return paths[args[0]] mock_qemu_img_info.side_effect = img_info_side_effect delete_info = { 'type': 'qcow2', 'merge_target_file': None, 'file_to_merge': None, 'volume_id': self.VOLUME_UUID } snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' mock_snapshot_get.side_effect = [ snap_ref_progress_0p, snap_ref_progress_50p, snap_ref_progress_90p ] drv.delete_snapshot(snap_ref) mock_ensure_share_writable.assert_called_once_with(volume_dir) mock_nova.delete_volume_snapshot.\ assert_called_once_with(ctxt, self.SNAP_UUID, delete_info) mock_write_info_file.assert_called_once_with(info_path, snap_info) mock_execute.assert_called_once_with('rm', '-f', volume_path, run_as_root=True) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_nova'), mock.patch.object(time, 'sleep'), mock.patch.object(drv, '_read_info_file'), mock.patch.object(drv, '_write_info_file'), mock.patch.object(db, 'snapshot_get'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(drv, '_ensure_share_writable') ) as (mock_execute, mock_nova, mock_sleep, mock_read_info_file, mock_write_info_file, mock_snapshot_get, mock_qemu_img_info, mock_ensure_share_writable): snap_info = {'active': snap_file_2, self.SNAP_UUID: snap_file, self.SNAP_UUID_2: snap_file_2} mock_read_info_file.return_value = snap_info qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) paths = {snap_path: img_info, volume_path: volume_img_info} def img_info_side_effect(*args, **kwargs): return paths[args[0]] mock_qemu_img_info.side_effect = img_info_side_effect delete_info = {'type': 'qcow2', 'merge_target_file': volume_file, 'file_to_merge': snap_file, 'volume_id': self.VOLUME_UUID} snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' mock_snapshot_get.side_effect = [ snap_ref_progress_0p, snap_ref_progress_50p, snap_ref_progress_90p] drv.delete_snapshot(snap_ref) mock_ensure_share_writable.assert_called_once_with(volume_dir) mock_nova.delete_volume_snapshot.\ assert_called_once_with(ctxt, self.SNAP_UUID, delete_info) mock_write_info_file.assert_called_once_with(info_path, snap_info) mock_execute.assert_called_once_with('rm', '-f', snap_path, run_as_root=True) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_execute'), mock.patch.object(drv, '_nova'), mock.patch.object(time, 'sleep'), mock.patch.object(drv, '_read_info_file'), mock.patch.object(drv, '_write_info_file'), mock.patch.object(db, 'snapshot_get'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(drv, '_ensure_share_writable') ) as (mock_execute, mock_nova, mock_sleep, mock_read_info_file, mock_write_info_file, mock_snapshot_get, mock_qemu_img_info, mock_ensure_share_writable): snap_info = {'active': snap_file, self.SNAP_UUID: snap_file} mock_read_info_file.return_value = snap_info qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) paths = {snap_path: img_info, volume_path: volume_img_info} def img_info_side_effect(*args, **kwargs): return paths[args[0]] mock_qemu_img_info.side_effect = img_info_side_effect snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['status'] = 'error_deleting' snap_ref_progress_90p['progress'] = '90%' mock_snapshot_get.side_effect = [ snap_ref_progress_0p, snap_ref_progress_50p, snap_ref_progress_90p] self.assertRaisesAndMessageMatches(exception.RemoteFSException, 'Unable to delete snapshot', drv.delete_snapshot, snap_ref) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_local_volume_dir'), mock.patch.object(image_utils, 'qemu_img_info') ) as (mock_local_volume_dir, mock_qemu_img_info): qemu_img_output_base = """"""image: %(image_name)s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" qemu_img_output = """"""image: %(image_name)s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %(backing_file)s """""" qemu_img_output_1 = qemu_img_output_base %\ {'image_name': vol_filename} qemu_img_output_2 = qemu_img_output %\ {'image_name': vol_filename_2, 'backing_file': vol_filename} qemu_img_output_3 = qemu_img_output %\ {'image_name': vol_filename_3, 'backing_file': vol_filename_2} info_1 = imageutils.QemuImgInfo(qemu_img_output_1) info_2 = imageutils.QemuImgInfo(qemu_img_output_2) info_3 = imageutils.QemuImgInfo(qemu_img_output_3) img_infos = {vol_path_3: info_3, vol_path_2: info_2, vol_path: info_1} def img_info_side_effect(*args, **kwargs): return img_infos[args[0]] mock_qemu_img_info.side_effect = img_info_side_effect mock_local_volume_dir.return_value = vol_dir chain = drv._get_backing_chain_for_path(volume, vol_path_3) # Verify chain contains all expected data item_1 = drv._get_matching_backing_file(chain, vol_filename) self.assertEqual(item_1['filename'], vol_filename_2) chain.remove(item_1) item_2 = drv._get_matching_backing_file(chain, vol_filename_2) self.assertEqual(item_2['filename'], vol_filename_3) chain.remove(item_2) self.assertEqual(len(chain), 1) self.assertEqual(chain[0]['filename'], vol_filename) drv = self._driver with contextlib.nested( mock.patch.object(image_utils, 'convert_image'), mock.patch.object(drv, '_read_info_file'), mock.patch.object(image_utils, 'qemu_img_info'), mock.patch.object(drv, '_set_rw_permissions_for_all') ) as (mock_convert_image, mock_read_info_file, mock_qemu_img_info, mock_set_rw_permissions): dest_volume = self._simple_volume( 'c1073000-0000-0000-0000-0000000c1073') src_volume = self._simple_volume() vol_dir = os.path.join(self.TEST_MNT_POINT_BASE, drv._get_hash_str(self.TEST_EXPORT1)) src_vol_path = os.path.join(vol_dir, src_volume['name']) dest_vol_path = os.path.join(vol_dir, dest_volume['name']) snapshot = {'volume_name': src_volume['name'], 'name': 'clone-snap-%s' % src_volume['id'], 'size': src_volume['size'], 'volume_size': src_volume['size'], 'volume_id': src_volume['id'], 'id': 'tmp-snap-%s' % src_volume['id'], 'volume': src_volume} snap_file = dest_volume['name'] + '.' + snapshot['id'] size = dest_volume['size'] mock_read_info_file.return_value = {'active': snap_file, snapshot['id']: snap_file} qemu_img_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, src_volume['name']) img_info = imageutils.QemuImgInfo(qemu_img_output) mock_qemu_img_info.return_value = img_info drv._copy_volume_from_snapshot(snapshot, dest_volume, size) mock_convert_image.assert_called_once_with(src_vol_path, dest_vol_path, 'raw') mock_set_rw_permissions.assert_called_once_with(dest_vol_path) drv = self._driver with contextlib.nested( mock.patch.object(drv, '_ensure_shares_mounted'), mock.patch.object(drv, '_find_share'), mock.patch.object(drv, '_do_create_volume'), mock.patch.object(drv, '_copy_volume_from_snapshot') ) as (mock_ensure_shares_mounted, mock_find_share, mock_do_create_volume, mock_copy_volume): mock_find_share.return_value = self.TEST_EXPORT1 drv.create_volume_from_snapshot(new_volume, snap_ref) self.assertTrue(mock_ensure_shares_mounted.called) mock_do_create_volume.assert_called_once_with(new_volume) mock_copy_volume.assert_called_once_with(snap_ref, new_volume, new_volume['size']) drv = self._driver with contextlib.nested( mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(image_utils, 'qemu_img_info') ) as (mock_get_active_image_from_info, mock_qemu_img_info): mock_get_active_image_from_info.return_value = volume['name'] mock_qemu_img_info.return_value = img_info conn_info = drv.initialize_connection(volume, None) self.assertEqual(conn_info['data']['format'], 'raw') self.assertEqual(conn_info['driver_volume_type'], 'glusterfs') self.assertEqual(conn_info['data']['name'], volume['name']) self.assertEqual(conn_info['mount_point_base'], self.TEST_MNT_POINT_BASE) drv = self._driver with contextlib.nested( mock.patch.object(drv.db, 'volume_get'), mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_qemu_img_info'), mock.patch.object(base_driver.VolumeDriver, 'backup_volume') ) as (mock_volume_get, mock_get_active_image_from_info, mock_qemu_img_info, mock_backup_volume): ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} mock_volume_get.return_value = volume mock_get_active_image_from_info.return_value = '/some/path' info = imageutils.QemuImgInfo() info.file_format = 'raw' mock_qemu_img_info.return_value = info drv.backup_volume(ctxt, backup, mock.MagicMock()) self.assertTrue(mock_backup_volume.called) drv = self._driver with contextlib.nested( mock.patch.object(drv.db, 'volume_get'), mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_qemu_img_info'), mock.patch.object(base_driver.VolumeDriver, 'backup_volume') ) as (mock_volume_get, mock_get_active_image_from_info, mock_qemu_img_info, mock_backup_volume): ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} mock_volume_get.return_value = volume mock_get_active_image_from_info.return_value = '/some/file2' info = imageutils.QemuImgInfo() info.file_format = 'raw' mock_qemu_img_info.return_value = info drv.backup_volume(ctxt, backup, mock.MagicMock()) self.assertTrue(mock_backup_volume.called) drv = self._driver with contextlib.nested( mock.patch.object(drv.db, 'snapshot_get_all_for_volume') ) as (mock_snapshot_get_all_for_volume,): ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} mock_snapshot_get_all_for_volume.return_value = [ {'snap1': 'a'}, {'snap2': 'b'} ] self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, mock.MagicMock()) drv = self._driver with contextlib.nested( mock.patch.object(drv.db, 'volume_get'), mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_qemu_img_info') ) as (mock_volume_get, mock_get_active_image_from_info, mock_qemu_img_info): ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} mock_volume_get.return_value = volume mock_get_active_image_from_info.return_value = '/some/path/file2' info = imageutils.QemuImgInfo() info.file_format = 'raw' info.backing_file = 'file1' mock_qemu_img_info.return_value = info self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, mock.MagicMock()) drv = self._driver with contextlib.nested( mock.patch.object(drv.db, 'volume_get'), mock.patch.object(drv, 'get_active_image_from_info'), mock.patch.object(drv, '_qemu_img_info') ) as (mock_volume_get, mock_get_active_image_from_info, mock_qemu_img_info): ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} mock_volume_get.return_value = volume mock_get_active_image_from_info.return_value = '/some/path' info = imageutils.QemuImgInfo() info.file_format = 'qcow2' self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, mock.MagicMock()) mock_volume_get.return_value = volume mock_qemu_img_info.return_value = info self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, mock.MagicMock())","import mox as mox_lib from mox import IgnoreArg from mox import IsA from mox import stuboutfrom cinder.volume import configuration as conf self._mox = mox_lib.Mox() self._configuration = mox_lib.MockObject(conf.Configuration) self._configuration.append_config_values(mox_lib.IgnoreArg()) self.stubs = stubout.StubOutForTesting() self.addCleanup(self._mox.UnsetStubs) def stub_out_not_replaying(self, obj, attr_name): attr_to_replace = getattr(obj, attr_name) stub = mox_lib.MockObject(attr_to_replace) self.stubs.Set(obj, attr_name, stub) mox = self._mox mox.StubOutWithMock(rfsclient, 'set_execute') def my_execute(*a, **k): pass rfsclient.set_execute(my_execute) mox.ReplayAll() drv.set_execute(my_execute) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_execute') drv._execute('mkdir', '-p', self.TEST_MNT_POINT) drv._execute('mount', '-t', 'glusterfs', self.TEST_EXPORT1, self.TEST_MNT_POINT, run_as_root=True) mox.ReplayAll() drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_execute') drv._execute('mkdir', '-p', self.TEST_MNT_POINT) drv._execute('mount', '-t', 'glusterfs', self.TEST_EXPORT1, self.TEST_MNT_POINT, run_as_root=True).\ AndRaise(putils.ProcessExecutionError( stderr='is busy or already mounted')) mox.ReplayAll() drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT, ensure=True) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_execute') drv._execute('mkdir', '-p', self.TEST_MNT_POINT) drv._execute( 'mount', '-t', 'glusterfs', self.TEST_EXPORT1, self.TEST_MNT_POINT, run_as_root=True). \ AndRaise(putils.ProcessExecutionError(stderr='is busy or ' 'already mounted')) mox.ReplayAll() self.assertRaises(putils.ProcessExecutionError, drv._mount_glusterfs, self.TEST_EXPORT1, self.TEST_MNT_POINT, ensure=False) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_execute') drv._execute('mkdir', '-p', self.TEST_MNT_POINT) drv._execute(*([IgnoreArg()] * 5), run_as_root=IgnoreArg()) mox.ReplayAll() drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(brick.remotefs.remotefs.RemoteFsClient, 'get_mount_point') self.override_config(""glusterfs_mount_point_base"", self.TEST_MNT_POINT_BASE) brick.remotefs.remotefs.RemoteFsClient.\ get_mount_point(self.TEST_EXPORT1).AndReturn(hashed_path) mox.ReplayAll() drv._get_mount_point_for_share(self.TEST_EXPORT1) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_get_mount_point_for_share') drv._get_mount_point_for_share(self.TEST_EXPORT1).\ AndReturn(self.TEST_MNT_POINT) mox.StubOutWithMock(drv, '_execute') drv._execute('df', '--portability', '--block-size', '1', self.TEST_MNT_POINT, run_as_root=True).AndReturn((df_output, None)) mox.ReplayAll() self.assertEqual((df_avail, df_total_size), drv._get_available_capacity(self.TEST_EXPORT1)) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_read_config_file') config_data = [] config_data.append(self.TEST_EXPORT1) config_data.append('#' + self.TEST_EXPORT2) config_data.append(self.TEST_EXPORT2 + ' ' + self.TEST_EXPORT2_OPTIONS) config_data.append('broken:share_format') config_data.append('') drv._read_config_file(self.TEST_SHARES_CONFIG_FILE).\ AndReturn(config_data) mox.ReplayAll() drv._load_shares_config(drv.configuration.glusterfs_shares_config) self.assertIn(self.TEST_EXPORT1, drv.shares) self.assertIn(self.TEST_EXPORT2, drv.shares) self.assertEqual(len(drv.shares), 2) self.assertEqual(drv.shares[self.TEST_EXPORT2], self.TEST_EXPORT2_OPTIONS) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(utils, 'get_file_mode') mox.StubOutWithMock(utils, 'get_file_gid') mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_ensure_share_writable') mox.StubOutWithMock(drv, '_get_mount_point_for_share') drv._get_mount_point_for_share(self.TEST_EXPORT1).\ AndReturn(self.TEST_MNT_POINT) mox.StubOutWithMock(drv, '_mount_glusterfs') drv._mount_glusterfs(self.TEST_EXPORT1, self.TEST_MNT_POINT, ensure=True) utils.get_file_gid(self.TEST_MNT_POINT).AndReturn(333333) utils.get_file_mode(self.TEST_MNT_POINT).AndReturn(0o777) drv._ensure_share_writable(self.TEST_MNT_POINT) drv._execute('chgrp', IgnoreArg(), self.TEST_MNT_POINT, run_as_root=True) mox.ReplayAll() drv._ensure_share_mounted(self.TEST_EXPORT1) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_read_config_file') config_data = [] config_data.append(self.TEST_EXPORT1) drv._read_config_file(self.TEST_SHARES_CONFIG_FILE).\ AndReturn(config_data) mox.StubOutWithMock(drv, '_ensure_share_mounted') drv._ensure_share_mounted(self.TEST_EXPORT1) mox.ReplayAll() drv._ensure_shares_mounted() self.assertEqual(1, len(drv._mounted_shares)) self.assertEqual(self.TEST_EXPORT1, drv._mounted_shares[0]) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_read_config_file') config_data = [] config_data.append(self.TEST_EXPORT1) drv._read_config_file(self.TEST_SHARES_CONFIG_FILE).\ AndReturn(config_data) mox.StubOutWithMock(drv, '_ensure_share_mounted') drv._ensure_share_mounted(self.TEST_EXPORT1).AndRaise(Exception()) mox.ReplayAll() drv._ensure_shares_mounted() self.assertEqual(0, len(drv._mounted_shares)) mox.VerifyAll() IsA(context.RequestContext)) def test_setup_should_throw_exception_if_client_is_not_installed(self): mox = self._mox mox.StubOutWithMock(os.path, 'exists') os.path.exists(self.TEST_SHARES_CONFIG_FILE).AndReturn(True) mox.StubOutWithMock(drv, '_execute') drv._execute('mount.glusterfs', check_exit_code=False).\ AndRaise(OSError(errno.ENOENT, 'No such file or directory')) mox.ReplayAll() self.assertRaisesAndMessageMatches(exception.GlusterfsException, 'mount.glusterfs is not installed', drv.do_setup, IsA(context.RequestContext)) mox.VerifyAll() def _fake_load_shares_config(self, conf): def test_setup_set_share_permissions(self): mox = self._mox self.stubs.Set(drv, '_load_shares_config', self._fake_load_shares_config) self.stubs.Set(tempfile, 'NamedTemporaryFile', self._fake_NamedTemporaryFile) mox.StubOutWithMock(os.path, 'exists') mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(utils, 'get_file_gid') mox.StubOutWithMock(utils, 'get_file_mode') mox.StubOutWithMock(os, 'getegid') drv._execute('mount.glusterfs', check_exit_code=False) drv._execute('umount', '/mnt/test/8f0473c9ad824b8b6a27264b9cacb005', run_as_root=True) drv._execute('mkdir', '-p', mox_lib.IgnoreArg()) os.path.exists(self.TEST_SHARES_CONFIG_FILE).AndReturn(True) drv._execute('mount', '-t', 'glusterfs', '127.7.7.7:/gluster1', mox_lib.IgnoreArg(), run_as_root=True) utils.get_file_gid(mox_lib.IgnoreArg()).AndReturn(33333) # perms not writable utils.get_file_mode(mox_lib.IgnoreArg()).AndReturn(0o000) os.getegid().AndReturn(888) drv._execute('chgrp', 888, mox_lib.IgnoreArg(), run_as_root=True) drv._execute('chmod', 'g+w', mox_lib.IgnoreArg(), run_as_root=True) mox.ReplayAll() drv.do_setup(IsA(context.RequestContext)) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_get_available_capacity') drv._get_available_capacity(self.TEST_EXPORT1).\ AndReturn((2 * units.Gi, 5 * units.Gi)) drv._get_available_capacity(self.TEST_EXPORT2).\ AndReturn((3 * units.Gi, 10 * units.Gi)) mox.ReplayAll() self.assertEqual(self.TEST_EXPORT2, drv._find_share(self.TEST_SIZE_IN_GB)) mox.VerifyAll() mox = self._mox drv._mounted_shares = [self.TEST_EXPORT1, self.TEST_EXPORT2] mox.StubOutWithMock(drv, '_get_available_capacity') drv._get_available_capacity(self.TEST_EXPORT1).\ AndReturn((0, 5 * units.Gi)) drv._get_available_capacity(self.TEST_EXPORT2).\ AndReturn((0, 10 * units.Gi)) mox.ReplayAll() self.assertRaises(exception.GlusterfsNoSuitableShareFound, drv._find_share, self.TEST_SIZE_IN_GB) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_create_sparsed_file') mox.StubOutWithMock(drv, '_set_rw_permissions_for_all') drv._create_sparsed_file(IgnoreArg(), IgnoreArg()) drv._set_rw_permissions_for_all(IgnoreArg()) mox.ReplayAll() drv._do_create_volume(volume) mox.VerifyAll() mox = self._mox mox.StubOutWithMock(drv, '_create_regular_file') mox.StubOutWithMock(drv, '_set_rw_permissions_for_all') drv._create_regular_file(IgnoreArg(), IgnoreArg()) drv._set_rw_permissions_for_all(IgnoreArg()) mox.ReplayAll() drv._do_create_volume(volume) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_execute') hashed = drv._get_hash_str(volume['provider_location']) path = '%s/%s/volume-%s' % (self.TEST_MNT_POINT_BASE, hashed, self.VOLUME_UUID) drv._execute('qemu-img', 'create', '-f', 'qcow2', '-o', 'preallocation=metadata', path, str(volume['size'] * units.Gi), run_as_root=True) drv._execute('chmod', 'ugo+rw', path, run_as_root=True) mox.ReplayAll() drv._do_create_volume(volume) mox.VerifyAll() mox = self._mox self.stub_out_not_replaying(glusterfs, 'LOG') self.stub_out_not_replaying(drv, '_find_share') self.stub_out_not_replaying(drv, '_do_create_volume') mox.StubOutWithMock(drv, '_ensure_shares_mounted') drv._ensure_shares_mounted() mox.ReplayAll() volume = DumbVolume() volume['size'] = self.TEST_SIZE_IN_GB drv.create_volume(volume) mox.VerifyAll() mox = self._mox self.stub_out_not_replaying(glusterfs, 'LOG') self.stub_out_not_replaying(drv, '_ensure_shares_mounted') self.stub_out_not_replaying(drv, '_do_create_volume') mox.StubOutWithMock(drv, '_find_share') drv._find_share(self.TEST_SIZE_IN_GB).AndReturn(self.TEST_EXPORT1) mox.ReplayAll() volume = DumbVolume() volume['size'] = self.TEST_SIZE_IN_GB result = drv.create_volume(volume) self.assertEqual(self.TEST_EXPORT1, result['provider_location']) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_create_snapshot') mox.StubOutWithMock(drv, '_delete_snapshot') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(image_utils, 'convert_image') mox.StubOutWithMock(drv, '_copy_volume_from_snapshot') volume = self._simple_volume() src_vref = self._simple_volume() src_vref['id'] = '375e32b2-804a-49f2-b282-85d1d5a5b9e1' src_vref['name'] = 'volume-%s' % src_vref['id'] volume_ref = {'id': volume['id'], 'name': volume['name'], 'status': volume['status'], 'provider_location': volume['provider_location'], 'size': volume['size']} snap_ref = {'volume_name': src_vref['name'], 'name': 'clone-snap-%s' % src_vref['id'], 'size': src_vref['size'], 'volume_size': src_vref['size'], 'volume_id': src_vref['id'], 'id': 'tmp-snap-%s' % src_vref['id'], 'volume': src_vref} drv._create_snapshot(snap_ref) drv._copy_volume_from_snapshot(snap_ref, volume_ref, volume['size']) drv._delete_snapshot(mox_lib.IgnoreArg()) mox.ReplayAll() drv.create_cloned_volume(volume, src_vref) mox.VerifyAll() mox = self._mox self.stub_out_not_replaying(drv, '_execute') volume = DumbVolume() volume['name'] = 'volume-123' volume['provider_location'] = self.TEST_EXPORT1 mox.StubOutWithMock(drv, '_ensure_share_mounted') drv._ensure_share_mounted(self.TEST_EXPORT1) mox.ReplayAll() drv.delete_volume(volume) mox.VerifyAll() mox = self._mox self.stub_out_not_replaying(drv, '_ensure_share_mounted') volume = DumbVolume() volume['name'] = 'volume-123' volume['provider_location'] = None mox.StubOutWithMock(drv, '_execute') mox.ReplayAll() drv.delete_volume(volume) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_read_file') hashed = drv._get_hash_str(self.TEST_EXPORT1) volume_path = '%s/%s/volume-%s' % (self.TEST_MNT_POINT_BASE, hashed, self.VOLUME_UUID) info_path = '%s%s' % (volume_path, '.info') drv._read_file(info_path).AndReturn('{""%(id)s"": ""volume-%(id)s""}' % {'id': self.VOLUME_UUID}) mox.ReplayAll() volume = DumbVolume() volume['id'] = self.VOLUME_UUID volume['name'] = 'volume-%s' % self.VOLUME_UUID info = drv._read_info_file(info_path) self.assertEqual(info[self.VOLUME_UUID], 'volume-%s' % self.VOLUME_UUID) mox.VerifyAll() (mox, drv) = self._mox, self._driver volume_path = '%s/%s/volume-%s' % (self.TEST_MNT_POINT_BASE, drv._get_hash_str( self.TEST_EXPORT1), self.VOLUME_UUID) mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, 'get_active_image_from_info') mox.StubOutWithMock(image_utils, 'qemu_img_info') mox.StubOutWithMock(image_utils, 'resize_image') drv.get_active_image_from_info(volume).AndReturn(volume['name']) image_utils.qemu_img_info(volume_path).AndReturn(img_info) image_utils.resize_image(volume_path, 3) mox.ReplayAll() drv.extend_volume(volume, 3) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_do_create_snapshot') mox.StubOutWithMock(db, 'snapshot_get') mox.StubOutWithMock(drv, '_nova') # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') drv._do_create_snapshot(snap_ref, snap_file, snap_path) create_info = {'snapshot_id': snap_ref['id'], 'type': 'qcow2', 'new_file': snap_file} drv._nova.create_volume_snapshot(ctxt, self.VOLUME_UUID, create_info) snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) mox.ReplayAll() drv._create_snapshot_online(snap_ref, snap_file, snap_path) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_do_create_snapshot') mox.StubOutWithMock(drv, '_nova') # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') mox.StubOutWithMock(db, 'snapshot_get') drv._do_create_snapshot(snap_ref, snap_file, snap_path) create_info = {'snapshot_id': snap_ref['id'], 'type': 'qcow2', 'new_file': snap_file} drv._nova.create_volume_snapshot(ctxt, self.VOLUME_UUID, create_info) snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'creating' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_99p = snap_ref_progress.copy() snap_ref_progress_99p['progress'] = '99%' snap_ref_progress_99p['status'] = 'error' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_99p) mox.ReplayAll() self.assertRaisesAndMessageMatches( exception.RemoteFSException, 'Nova returned ""error"" status while creating snapshot.', drv._create_snapshot_online, snap_ref, snap_file, snap_path) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_nova') # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(drv, '_write_info_file') mox.StubOutWithMock(db, 'snapshot_get') mox.StubOutWithMock(image_utils, 'qemu_img_info') mox.StubOutWithMock(drv, '_ensure_share_writable') snap_info = {'active': snap_file, self.SNAP_UUID: snap_file} drv._ensure_share_writable(volume_dir) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(snap_path).AndReturn(img_info) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) delete_info = { 'type': 'qcow2', 'merge_target_file': None, 'file_to_merge': None, 'volume_id': self.VOLUME_UUID } drv._nova.delete_volume_snapshot(ctxt, self.SNAP_UUID, delete_info) drv._read_info_file(info_path).AndReturn(snap_info) snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) drv._write_info_file(info_path, snap_info) drv._execute('rm', '-f', volume_path, run_as_root=True) mox.ReplayAll() drv.delete_snapshot(snap_ref) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_nova') # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(drv, '_write_info_file') mox.StubOutWithMock(db, 'snapshot_get') mox.StubOutWithMock(image_utils, 'qemu_img_info') mox.StubOutWithMock(drv, '_ensure_share_writable') snap_info = {'active': snap_file_2, self.SNAP_UUID: snap_file, self.SNAP_UUID_2: snap_file_2} drv._ensure_share_writable(volume_dir) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(snap_path).AndReturn(img_info) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) delete_info = {'type': 'qcow2', 'merge_target_file': volume_file, 'file_to_merge': snap_file, 'volume_id': self.VOLUME_UUID} drv._nova.delete_volume_snapshot(ctxt, self.SNAP_UUID, delete_info) drv._read_info_file(info_path).AndReturn(snap_info) snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) drv._write_info_file(info_path, snap_info) drv._execute('rm', '-f', snap_path, run_as_root=True) mox.ReplayAll() drv.delete_snapshot(snap_ref) mox.VerifyAll() (mox, drv) = self._mox, self._driver volume_dir = os.path.join(self.TEST_MNT_POINT_BASE, hashed) info_path = '%s.info' % volume_path mox.StubOutWithMock(drv, '_execute') mox.StubOutWithMock(drv, '_nova') # Stub out the busy wait. self.stub_out_not_replaying(time, 'sleep') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(db, 'snapshot_get') mox.StubOutWithMock(image_utils, 'qemu_img_info') mox.StubOutWithMock(drv, '_ensure_share_writable') snap_info = {'active': snap_file, self.SNAP_UUID: snap_file} drv._ensure_share_writable(volume_dir) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) qemu_img_info_output = """"""image: %s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, volume_file) img_info = imageutils.QemuImgInfo(qemu_img_info_output) vol_qemu_img_info_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" % volume_file volume_img_info = imageutils.QemuImgInfo(vol_qemu_img_info_output) image_utils.qemu_img_info(snap_path).AndReturn(img_info) image_utils.qemu_img_info(volume_path).AndReturn(volume_img_info) drv._read_info_file(info_path, empty_if_missing=True).\ AndReturn(snap_info) delete_info = { 'type': 'qcow2', 'merge_target_file': None, 'file_to_merge': None, 'volume_id': self.VOLUME_UUID } drv._nova.delete_volume_snapshot(ctxt, self.SNAP_UUID, delete_info) drv._read_info_file(info_path).AndReturn(snap_info) snap_ref_progress = snap_ref.copy() snap_ref_progress['status'] = 'deleting' snap_ref_progress_0p = snap_ref_progress.copy() snap_ref_progress_0p['progress'] = '0%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_0p) snap_ref_progress_50p = snap_ref_progress.copy() snap_ref_progress_50p['progress'] = '50%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_50p) snap_ref_progress_90p = snap_ref_progress.copy() snap_ref_progress_90p['status'] = 'error_deleting' snap_ref_progress_90p['progress'] = '90%' db.snapshot_get(ctxt, self.SNAP_UUID).AndReturn(snap_ref_progress_90p) mox.ReplayAll() self.assertRaisesAndMessageMatches(exception.RemoteFSException, 'Unable to delete snapshot', drv.delete_snapshot, snap_ref) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_local_volume_dir') mox.StubOutWithMock(image_utils, 'qemu_img_info') qemu_img_output_base = """"""image: %(image_name)s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K """""" qemu_img_output = """"""image: %(image_name)s file format: qcow2 virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %(backing_file)s """""" qemu_img_output_1 = qemu_img_output_base % {'image_name': vol_filename} qemu_img_output_2 = qemu_img_output % {'image_name': vol_filename_2, 'backing_file': vol_filename} qemu_img_output_3 = qemu_img_output % {'image_name': vol_filename_3, 'backing_file': vol_filename_2} info_1 = imageutils.QemuImgInfo(qemu_img_output_1) info_2 = imageutils.QemuImgInfo(qemu_img_output_2) info_3 = imageutils.QemuImgInfo(qemu_img_output_3) image_utils.qemu_img_info(vol_path_3).\ AndReturn(info_3) drv._local_volume_dir(volume).AndReturn(vol_dir) image_utils.qemu_img_info(vol_path_2).\ AndReturn(info_2) drv._local_volume_dir(volume).AndReturn(vol_dir) image_utils.qemu_img_info(vol_path).\ AndReturn(info_1) mox.ReplayAll() chain = drv._get_backing_chain_for_path(volume, vol_path_3) mox.VerifyAll() # Verify chain contains all expected data item_1 = drv._get_matching_backing_file(chain, vol_filename) self.assertEqual(item_1['filename'], vol_filename_2) chain.remove(item_1) item_2 = drv._get_matching_backing_file(chain, vol_filename_2) self.assertEqual(item_2['filename'], vol_filename_3) chain.remove(item_2) self.assertEqual(len(chain), 1) self.assertEqual(chain[0]['filename'], vol_filename) (mox, drv) = self._mox, self._driver mox.StubOutWithMock(image_utils, 'convert_image') mox.StubOutWithMock(drv, '_read_info_file') mox.StubOutWithMock(image_utils, 'qemu_img_info') mox.StubOutWithMock(drv, '_set_rw_permissions_for_all') dest_volume = self._simple_volume( 'c1073000-0000-0000-0000-0000000c1073') src_volume = self._simple_volume() vol_dir = os.path.join(self.TEST_MNT_POINT_BASE, drv._get_hash_str(self.TEST_EXPORT1)) src_vol_path = os.path.join(vol_dir, src_volume['name']) dest_vol_path = os.path.join(vol_dir, dest_volume['name']) info_path = os.path.join(vol_dir, src_volume['name']) + '.info' snapshot = {'volume_name': src_volume['name'], 'name': 'clone-snap-%s' % src_volume['id'], 'size': src_volume['size'], 'volume_size': src_volume['size'], 'volume_id': src_volume['id'], 'id': 'tmp-snap-%s' % src_volume['id'], 'volume': src_volume} snap_file = dest_volume['name'] + '.' + snapshot['id'] snap_path = os.path.join(vol_dir, snap_file) size = dest_volume['size'] drv._read_info_file(info_path).AndReturn( {'active': snap_file, snapshot['id']: snap_file} ) qemu_img_output = """"""image: %s file format: raw virtual size: 1.0G (1073741824 bytes) disk size: 173K backing file: %s """""" % (snap_file, src_volume['name']) img_info = imageutils.QemuImgInfo(qemu_img_output) image_utils.qemu_img_info(snap_path).AndReturn(img_info) image_utils.convert_image(src_vol_path, dest_vol_path, 'raw') drv._set_rw_permissions_for_all(dest_vol_path) mox.ReplayAll() drv._copy_volume_from_snapshot(snapshot, dest_volume, size) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_ensure_shares_mounted') mox.StubOutWithMock(drv, '_find_share') mox.StubOutWithMock(drv, '_do_create_volume') mox.StubOutWithMock(drv, '_copy_volume_from_snapshot') drv._ensure_shares_mounted() drv._find_share(new_volume['size']).AndReturn(self.TEST_EXPORT1) drv._do_create_volume(new_volume) drv._copy_volume_from_snapshot(snap_ref, new_volume, new_volume['size']) mox.ReplayAll() drv.create_volume_from_snapshot(new_volume, snap_ref) mox.VerifyAll() (mox, drv) = self._mox, self._driver vol_dir = os.path.join(self.TEST_MNT_POINT_BASE, drv._get_hash_str(self.TEST_EXPORT1)) vol_path = os.path.join(vol_dir, volume['name']) mox.StubOutWithMock(drv, 'get_active_image_from_info') mox.StubOutWithMock(image_utils, 'qemu_img_info') drv.get_active_image_from_info(volume).AndReturn(volume['name']) image_utils.qemu_img_info(vol_path).AndReturn(img_info) mox.ReplayAll() conn_info = drv.initialize_connection(volume, None) mox.VerifyAll() self.assertEqual(conn_info['data']['format'], 'raw') self.assertEqual(conn_info['driver_volume_type'], 'glusterfs') self.assertEqual(conn_info['data']['name'], volume['name']) self.assertEqual(conn_info['mount_point_base'], self.TEST_MNT_POINT_BASE) (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv.db, 'volume_get') mox.StubOutWithMock(drv, 'get_active_image_from_info') mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) drv.get_active_image_from_info(IgnoreArg()).AndReturn('/some/path') info = imageutils.QemuImgInfo() info.file_format = 'raw' drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) base_driver.VolumeDriver.backup_volume(IgnoreArg(), IgnoreArg(), IgnoreArg()) mox.ReplayAll() drv.backup_volume(ctxt, backup, IgnoreArg()) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv.db, 'volume_get') mox.StubOutWithMock(drv, 'get_active_image_from_info') mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(base_driver.VolumeDriver, 'backup_volume') ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) drv.get_active_image_from_info(IgnoreArg()).AndReturn('/some/file2') info = imageutils.QemuImgInfo() info.file_format = 'raw' drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) base_driver.VolumeDriver.backup_volume(IgnoreArg(), IgnoreArg(), IgnoreArg()) mox.ReplayAll() drv.backup_volume(ctxt, backup, IgnoreArg()) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv.db, 'snapshot_get_all_for_volume') ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} drv.db.snapshot_get_all_for_volume(ctxt, volume['id']).AndReturn( [{'snap1': 'a'}, {'snap2': 'b'}]) mox.ReplayAll() self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, IgnoreArg()) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv.db, 'volume_get') mox.StubOutWithMock(drv, 'get_active_image_from_info') mox.StubOutWithMock(drv, '_qemu_img_info') ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) drv.get_active_image_from_info(IgnoreArg()).\ AndReturn('/some/path/file2') info = imageutils.QemuImgInfo() info.file_format = 'raw' info.backing_file = 'file1' drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) mox.ReplayAll() self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, IgnoreArg()) mox.VerifyAll() (mox, drv) = self._mox, self._driver mox.StubOutWithMock(drv, '_qemu_img_info') mox.StubOutWithMock(drv.db, 'volume_get') mox.StubOutWithMock(drv, 'get_active_image_from_info') ctxt = context.RequestContext('fake_user', 'fake_project') volume = self._simple_volume() backup = {'volume_id': volume['id']} drv.get_active_image_from_info(IgnoreArg()).AndReturn('/some/path') info = imageutils.QemuImgInfo() info.file_format = 'qcow2' drv.db.volume_get(ctxt, volume['id']).AndReturn(volume) drv._qemu_img_info(IgnoreArg(), IgnoreArg()).AndReturn(info) mox.ReplayAll() self.assertRaises(exception.InvalidVolume, drv.backup_volume, ctxt, backup, IgnoreArg()) mox.VerifyAll()",764,923
openstack%2Fcinder~master~I2671fc0a186acb75767d9adb1edeb9ad705fc958,openstack/cinder,master,I2671fc0a186acb75767d9adb1edeb9ad705fc958,Clean up QoSSpecManageApiTest setup,MERGED,2015-01-09 15:46:27.000000000,2015-01-13 02:04:07.000000000,2015-01-12 05:22:47.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2759}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12779}, {'_account_id': 13636}]","[{'number': 1, 'created': '2015-01-09 15:46:27.000000000', 'files': ['cinder/tests/api/contrib/test_qos_specs_manage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/96b1d5b8a2abf92df6aab201807ad11e021fcf2b', 'message': 'Clean up QoSSpecManageApiTest setup\n\nThere is currently unnecessary work being performed in setUp\nfor QoSSpecManageApiTest and confusing comments. This cleans\nthat up to avoid confusion.\n\nTest was explicitly calling a reset on a fake, but the cleanup\nfor each test will do this as well. Relatively harmless, but\nthis makes the code cleaner.\n\nChange-Id: I2671fc0a186acb75767d9adb1edeb9ad705fc958\n'}]",0,146121,96b1d5b8a2abf92df6aab201807ad11e021fcf2b,17,13,1,11904,,,0,"Clean up QoSSpecManageApiTest setup

There is currently unnecessary work being performed in setUp
for QoSSpecManageApiTest and confusing comments. This cleans
that up to avoid confusion.

Test was explicitly calling a reset on a fake, but the cleanup
for each test will do this as well. Relatively harmless, but
this makes the code cleaner.

Change-Id: I2671fc0a186acb75767d9adb1edeb9ad705fc958
",git fetch https://review.opendev.org/openstack/cinder refs/changes/21/146121/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/api/contrib/test_qos_specs_manage.py'],1,96b1d5b8a2abf92df6aab201807ad11e021fcf2b,test_qos_specs_manage_cleanup, # Reset notifications for each test," #reset notifier drivers left over from other api/contrib tests # NOTE(flaper87) WTF? ^^^^ Cleanups should happen in each test, # not the purpose of this patch, though. fake_notifier.reset()",1,4
openstack%2Fpbr~master~Ia23672b851d50af38c61823936f19b8572a78c4f,openstack/pbr,master,Ia23672b851d50af38c61823936f19b8572a78c4f,Be more aggressive about building wheels,MERGED,2015-01-12 21:56:23.000000000,2015-01-13 02:02:52.000000000,2015-01-13 02:02:52.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-01-12 21:56:23.000000000', 'files': ['tools/integration.sh'], 'web_link': 'https://opendev.org/openstack/pbr/commit/afc8c1bb56fe8de72c7620138893f6ceba105093', 'message': 'Be more aggressive about building wheels\n\nWhen ""pip wheel"" hits a package where building the egg-info metadata\nfails, it completely falls over and stops trying to build more wheels.\nLoop over our requirements one by one, so we can ignore the packages\nthat fail to build wheels, and build any that come in the list after\nthose.\n\nChange-Id: Ia23672b851d50af38c61823936f19b8572a78c4f\n'}]",0,146650,afc8c1bb56fe8de72c7620138893f6ceba105093,10,4,1,2472,,,0,"Be more aggressive about building wheels

When ""pip wheel"" hits a package where building the egg-info metadata
fails, it completely falls over and stops trying to build more wheels.
Loop over our requirements one by one, so we can ignore the packages
that fail to build wheels, and build any that come in the list after
those.

Change-Id: Ia23672b851d50af38c61823936f19b8572a78c4f
",git fetch https://review.opendev.org/openstack/pbr refs/changes/50/146650/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/integration.sh'],1,afc8c1bb56fe8de72c7620138893f6ceba105093,build-more-wheels,"grep -v '^#' $REPODIR/requirements/global-requirements.txt | while read req do $tmpdir/wheelhouse/bin/pip wheel ""$req"" done",$tmpdir/wheelhouse/bin/pip wheel -r $REPODIR/requirements/global-requirements.txt,4,1
openstack%2Fhorizon~master~I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a,openstack/horizon,master,I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a,Password reveal feature should be configurable,MERGED,2014-12-10 23:03:37.000000000,2015-01-13 01:58:38.000000000,2015-01-13 01:58:37.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 1941}, {'_account_id': 6635}, {'_account_id': 6763}, {'_account_id': 8040}, {'_account_id': 8512}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11881}, {'_account_id': 13785}, {'_account_id': 14107}, {'_account_id': 14151}, {'_account_id': 14223}]","[{'number': 1, 'created': '2014-12-10 23:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7c9d2ef199a3fa97760dd1745d347ed1a1e856c6', 'message': 'Password reveal feature should be configurable\n\nHorizon has a password reveal eye button which allows the\npassword field to be viewed in plain text.  This is a security risk\nbecause a malicious user can check the OpenStack password at an\nunattended computer.\n\nAdd new ENABLE_PASSWORD_REVEAL setting which is by default, False.\n\nChange-Id: I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a\nCloses-Bug: #1400872\n'}, {'number': 2, 'created': '2015-01-08 00:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9355b1618266d6be17dc3df69289608c5a7bb5c4', 'message': 'Password reveal feature should be configurable\n\nHorizon has a password reveal eye button which allows the\npassword field to be viewed in plain text.  This is a security risk\nbecause a malicious user can check the OpenStack password at an\nunattended computer.\n\nAdd new DISABLE_PASSWORD_REVEAL setting which is by default, False.\n\nDocImpact\n\nChange-Id: I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a\nCloses-Bug: #1400872\n'}, {'number': 3, 'created': '2015-01-08 19:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8608278a84ebd77c1beccc8a055153cc9834eebe', 'message': 'Password reveal feature should be configurable\n\nHorizon has a password reveal eye button which allows the\npassword field to be viewed in plain text.  This is a security risk\nbecause a malicious user can check the OpenStack password at an\nunattended computer.\n\nAdd new DISABLE_PASSWORD_REVEAL setting which is by default, False.\n\nDocImpact\n\nChange-Id: I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a\nCloses-Bug: #1400872\n'}, {'number': 4, 'created': '2015-01-08 19:43:46.000000000', 'files': ['horizon/templates/horizon/_conf.html', 'horizon/static/horizon/js/horizon.forms.js', 'doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example'], 'web_link': 'https://opendev.org/openstack/horizon/commit/afbca3d4310073b3a6bf1127890fe9d756ab5418', 'message': 'Password reveal feature should be configurable\n\nHorizon has a password reveal eye button which allows the\npassword field to be viewed in plain text.  This is a security risk\nbecause a malicious user can check the OpenStack password at an\nunattended computer.\n\nAdd new DISABLE_PASSWORD_REVEAL setting which is by default, False.\n\nDocImpact\n\nChange-Id: I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a\nCloses-Bug: #1400872\n'}]",5,140862,afbca3d4310073b3a6bf1127890fe9d756ab5418,36,15,4,9622,,,0,"Password reveal feature should be configurable

Horizon has a password reveal eye button which allows the
password field to be viewed in plain text.  This is a security risk
because a malicious user can check the OpenStack password at an
unattended computer.

Add new DISABLE_PASSWORD_REVEAL setting which is by default, False.

DocImpact

Change-Id: I21a2eaedbff4c1ee73d97c5674eca43c0258ca1a
Closes-Bug: #1400872
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/140862/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/_conf.html', 'horizon/static/horizon/js/horizon.forms.js', 'doc/source/topics/settings.rst', 'openstack_dashboard/local/local_settings.py.example']",4,7c9d2ef199a3fa97760dd1745d347ed1a1e856c6,bug/1400872,"# Disable reveal button for password fields including on login form. # HORIZON_CONFIG[""enable_password_reveal""] = False ",,18,3
openstack%2Fkeystone~master~I2a296b7ed407c75018fff3b60bd13aaa4fa9a849,openstack/keystone,master,I2a296b7ed407c75018fff3b60bd13aaa4fa9a849,Additional test coverage for password changes,MERGED,2015-01-12 18:11:08.000000000,2015-01-13 01:57:31.000000000,2015-01-13 01:57:29.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-01-12 18:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/31315dd223c1cb79d3c81f5624b3937e2909671b', 'message': ""Additional test coverage for password changes\n\nKeystone has four API calls which may result in a user's password\nchanging.\n\n1. Administrative password reset on v2:\n\n    POST /v2.0/users/{user_id}/OS-KSADM/password\n\n2. Self-service password change on v2:\n\n    PATCH /v2.0/OS-KSCRUD/users/{user_id}\n\n3. Administrative password reset on v3:\n\n    POST /v3/users/{user_id}\n\n4. Self-service password change on v3:\n\n    POST /v3/users/{user_id}/password\n\nThis patch adds additional test coverage to *consistently* ensure that:\n\n- Old passwords no longer work\n- Old tokens no longer work\n- The new password works\n\nChange-Id: I2a296b7ed407c75018fff3b60bd13aaa4fa9a849\nCloses-Bug: 1407105\n""}, {'number': 2, 'created': '2015-01-12 19:37:27.000000000', 'files': ['keystone/tests/test_keystoneclient.py', 'keystone/tests/test_v3_identity.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a22aa08bf2176ac2da75258223f58d70303259e4', 'message': ""Additional test coverage for password changes\n\nKeystone has four API calls which may result in a user's password\nchanging.\n\n1. Administrative password reset on v2:\n\n    POST /v2.0/users/{user_id}/OS-KSADM/password\n\n2. Self-service password change on v2:\n\n    PATCH /v2.0/OS-KSCRUD/users/{user_id}\n\n3. Administrative password reset on v3:\n\n    POST /v3/users/{user_id}\n\n4. Self-service password change on v3:\n\n    POST /v3/users/{user_id}/password\n\nThis patch adds additional test coverage to *consistently* ensure that:\n\n- Old passwords no longer work\n- Old tokens no longer work\n- The new password works\n\nChange-Id: I2a296b7ed407c75018fff3b60bd13aaa4fa9a849\nCloses-Bug: 1407105\n""}]",1,146589,a22aa08bf2176ac2da75258223f58d70303259e4,10,3,2,4,,,0,"Additional test coverage for password changes

Keystone has four API calls which may result in a user's password
changing.

1. Administrative password reset on v2:

    POST /v2.0/users/{user_id}/OS-KSADM/password

2. Self-service password change on v2:

    PATCH /v2.0/OS-KSCRUD/users/{user_id}

3. Administrative password reset on v3:

    POST /v3/users/{user_id}

4. Self-service password change on v3:

    POST /v3/users/{user_id}/password

This patch adds additional test coverage to *consistently* ensure that:

- Old passwords no longer work
- Old tokens no longer work
- The new password works

Change-Id: I2a296b7ed407c75018fff3b60bd13aaa4fa9a849
Closes-Bug: 1407105
",git fetch https://review.opendev.org/openstack/keystone refs/changes/89/146589/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_keystoneclient.py', 'keystone/tests/test_v3_identity.py']",2,31315dd223c1cb79d3c81f5624b3937e2909671b,bug/1407105," def test_admin_password_reset(self): # bootstrap a user as admin user_ref = self.new_user_ref(domain_id=self.domain['id']) password = user_ref['password'] user_ref = self.identity_api.create_user(user_ref) # auth as user should work before a password change old_password_auth = self.build_authentication_request( user_id=user_ref['id'], password=password) r = self.v3_authenticate_token(old_password_auth, expected_status=201) old_token = r.headers.get('X-Subject-Token') # auth as user with a token should work before a password change old_token_auth = self.build_authentication_request(token=old_token) self.v3_authenticate_token(old_token_auth, expected_status=201) # administrative password reset new_password = uuid.uuid4().hex self.patch('/users/%s' % user_ref['id'], body={'user': {'password': new_password}}, expected_status=200) # auth as user with original password should not work after change self.v3_authenticate_token(old_password_auth, expected_status=401) # auth as user with an old token should not work after change self.v3_authenticate_token(old_token_auth, expected_status=404) # new password should work new_password_auth = self.build_authentication_request( user_id=user_ref['id'], password=new_password) self.v3_authenticate_token(new_password_auth, expected_status=201) token_id = self.get_request_token(self.user_ref['password'], expected_status=201) # original token works old_token_auth = self.build_authentication_request(token=token_id) self.v3_authenticate_token(old_token_auth, expected_status=201) # old token fails self.v3_authenticate_token(old_token_auth, expected_status=404) "," self.get_request_token(self.user_ref['password'], expected_status=201)",99,14
openstack%2Frally~master~I27fbaa2a546f47b2e00dc8e54348ec45410865a6,openstack/rally,master,I27fbaa2a546f47b2e00dc8e54348ec45410865a6,Adds timestamps to scenarios iterations,MERGED,2015-01-12 07:09:40.000000000,2015-01-13 01:56:03.000000000,2015-01-13 01:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 14135}]","[{'number': 1, 'created': '2015-01-12 07:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9fbdeecf530e7434eba961365c381f67bfe55a2e', 'message': '(WIP) Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6\n'}, {'number': 2, 'created': '2015-01-12 09:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ba57a62286c4d0fe5cecc7f160594e70d236c19', 'message': '(WIP) Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6\n'}, {'number': 3, 'created': '2015-01-12 12:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aa7392bbca878ed7cc38a3f5f208196366e11577', 'message': '(WIP) Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6\n'}, {'number': 4, 'created': '2015-01-12 13:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/36f677b74ccec2116aed07f80e892435148b9f14', 'message': '(WIP) Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6\n'}, {'number': 5, 'created': '2015-01-12 13:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/627300807361b7b7085e25b232e8998b4b07954c', 'message': '(WIP) Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6\n'}, {'number': 6, 'created': '2015-01-12 14:57:27.000000000', 'files': ['rally/benchmark/runners/base.py', 'tests/unit/fakes.py', 'rally/common/utils.py', 'tests/unit/benchmark/runners/test_base.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ae2ce3e0cc7d21b9d105a210ca3afe5278449aaf', 'message': 'Adds timestamps to scenarios iterations\n\nIn preparation for parallel scenario runners\n\nChange-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6'}]",1,146385,ae2ce3e0cc7d21b9d105a210ca3afe5278449aaf,26,6,6,8576,,,0,"Adds timestamps to scenarios iterations

In preparation for parallel scenario runners

Change-Id: I27fbaa2a546f47b2e00dc8e54348ec45410865a6",git fetch https://review.opendev.org/openstack/rally refs/changes/85/146385/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/runners/base.py', 'rally/benchmark/scenarios/base.py', 'rally/common/utils.py']",3,9fbdeecf530e7434eba961365c381f67bfe55a2e,iteration_ts,import datetime def timestamp(self): return datetime.datetime.fromtimestamp(self.start) ,,16,4
openstack%2Fkeystonemiddleware~master~I6969232fa02c810bf3911cf32b37104ebd05e279,openstack/keystonemiddleware,master,I6969232fa02c810bf3911cf32b37104ebd05e279,Updated from global requirements,MERGED,2015-01-13 00:04:02.000000000,2015-01-13 01:34:14.000000000,2015-01-13 01:34:13.000000000,"[{'_account_id': 3}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-01-13 00:04:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d25c7ad3cb177a6ee296cf74dc1aaa6e41f4c176', 'message': 'Updated from global requirements\n\nChange-Id: I6969232fa02c810bf3911cf32b37104ebd05e279\n'}]",0,146695,d25c7ad3cb177a6ee296cf74dc1aaa6e41f4c176,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6969232fa02c810bf3911cf32b37104ebd05e279
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/95/146695/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d25c7ad3cb177a6ee296cf74dc1aaa6e41f4c176,openstack/requirements,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fproject-config~master~Ie172e50de57b5168264964644cd28530f023542a,openstack/project-config,master,Ie172e50de57b5168264964644cd28530f023542a,Set the executable bit on all dib element scripts,MERGED,2015-01-13 00:15:49.000000000,2015-01-13 01:16:06.000000000,2015-01-13 01:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-01-13 00:15:49.000000000', 'files': ['nodepool/elements/nodepool-base/install.d/90-venv-swift-logs', 'nodepool/elements/cache-devstack/install.d/50-download-pkgs'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3d6303f3fc7f1700ec1cba6ffca1940b0d4c8537', 'message': 'Set the executable bit on all dib element scripts\n\nDIB needs its scripts to be executable or they are not run. Update\npermissions on two files that were missing the executable bit.\n\nChange-Id: Ie172e50de57b5168264964644cd28530f023542a\n'}]",0,146707,3d6303f3fc7f1700ec1cba6ffca1940b0d4c8537,7,3,1,4146,,,0,"Set the executable bit on all dib element scripts

DIB needs its scripts to be executable or they are not run. Update
permissions on two files that were missing the executable bit.

Change-Id: Ie172e50de57b5168264964644cd28530f023542a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/146707/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/nodepool-base/install.d/90-venv-swift-logs', 'nodepool/elements/cache-devstack/install.d/50-download-pkgs']",2,3d6303f3fc7f1700ec1cba6ffca1940b0d4c8537,prepare-devstack,,,0,0
openstack%2Fproject-config~master~I093d02706f2965e071e2a76ab1131ac29016d03c,openstack/project-config,master,I093d02706f2965e071e2a76ab1131ac29016d03c,Use PyMySQL and venv path when caching subunit2sql,MERGED,2015-01-12 23:32:47.000000000,2015-01-13 01:15:58.000000000,2015-01-13 01:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-01-12 23:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e8885f5923e2a28ddf321719ac17fae97a9328fc', 'message': 'Use PyMySQL and venv path when caching subunit2sql\n\nChange-Id: I093d02706f2965e071e2a76ab1131ac29016d03c\n'}, {'number': 2, 'created': '2015-01-12 23:35:47.000000000', 'files': ['nodepool/scripts/prepare_tempest_testrepository.py', 'nodepool/elements/cache-devstack/install.d/99-cache-testrepository-db', 'nodepool/scripts/prepare_node_devstack.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b70a27d6c41d2b791e4abc32b1a34c0032c98c91', 'message': 'Use PyMySQL and venv path when caching subunit2sql\n\nAlso rename the element to one which runs in the context of the\ndiskimage chroot rather than in the root context, and make it\nexecutable.\n\nChange-Id: I093d02706f2965e071e2a76ab1131ac29016d03c\n'}]",0,146682,b70a27d6c41d2b791e4abc32b1a34c0032c98c91,8,3,2,5263,,,0,"Use PyMySQL and venv path when caching subunit2sql

Also rename the element to one which runs in the context of the
diskimage chroot rather than in the root context, and make it
executable.

Change-Id: I093d02706f2965e071e2a76ab1131ac29016d03c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/146682/2 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/cache-devstack/extra-data.d/51-cache-testrepository-db', 'nodepool/scripts/prepare_tempest_testrepository.py', 'nodepool/scripts/prepare_node_devstack.sh']",3,e8885f5923e2a28ddf321719ac17fae97a9328fc,prepare-devstack,sudo -H /opt/git/subunit2sql-env/bin/pip install -U testrepository subunit2sql PyMySQLsudo -i env PATH=/opt/git/subunit2sql-env/bin:$PATH /opt/git/subunit2sql-env/bin/python2 /opt/nodepool-scripts/prepare_tempest_testrepository.py $TEMPEST_DIR,sudo -H /opt/git/subunit2sql-env/bin/pip install -U testrepository subunit2sqlsudo -i /opt/git/subunit2sql-env/bin/python2 /opt/nodepool-scripts/prepare_tempest_testrepository.py $TEMPEST_DIR,5,5
openstack%2Fneutron~master~I6c8b872087d17da2c3de43186d1916fc368dd786,openstack/neutron,master,I6c8b872087d17da2c3de43186d1916fc368dd786,Passing admin tenant name to EOS,MERGED,2014-09-08 22:12:17.000000000,2015-01-13 01:13:27.000000000,2014-09-12 17:33:06.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6558}, {'_account_id': 6854}, {'_account_id': 8213}, {'_account_id': 8645}, {'_account_id': 9596}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-08 22:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7825e6c33ebe1e8baaefded68c31bd8b0461ba90', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nthe it is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}, {'number': 2, 'created': '2014-09-09 21:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f9feafc28de8dcb0b8846606f89ec510caba2c9', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nthe it is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}, {'number': 3, 'created': '2014-09-09 21:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e75cabe0aef2a04e70c79700374564998b6a926', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nit is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}, {'number': 4, 'created': '2014-09-09 21:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/620c2d63e0842a5ec4b8f13c28e19c1afea150cf', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nit is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}, {'number': 5, 'created': '2014-09-10 19:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/939e546e1039e37a53a44d98cc26546838166764', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nit is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}, {'number': 6, 'created': '2014-09-11 00:23:25.000000000', 'files': ['neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/tests/unit/ml2/drivers/arista/test_arista_mechanism_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ccebf0c166c4204ec32e922871ec39bd62225ab0', 'message': 'Passing admin tenant name to EOS\n\nThe Arista ML2 plugin was not passing the admin tenant name to EOS without which\nit is not possible to authenticate with keystone using just the admin name\nand password. This patch passes the admin tenant name along with the admin\ncredentials.\n\nChange-Id: I6c8b872087d17da2c3de43186d1916fc368dd786\nCloses-Bug: 1359417\n'}]",22,119940,ccebf0c166c4204ec32e922871ec39bd62225ab0,126,27,6,9596,,,0,"Passing admin tenant name to EOS

The Arista ML2 plugin was not passing the admin tenant name to EOS without which
it is not possible to authenticate with keystone using just the admin name
and password. This patch passes the admin tenant name along with the admin
credentials.

Change-Id: I6c8b872087d17da2c3de43186d1916fc368dd786
Closes-Bug: 1359417
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/119940/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/arista/mechanism_arista.py', 'neutron/tests/unit/ml2/drivers/arista/test_arista_mechanism_driver.py']",2,7825e6c33ebe1e8baaefded68c31bd8b0461ba90,bug/1359417," timestampCmds = ['show openstack config region RegionOne timestamp'] auth = fake_keystone_info_class() host = '%s://%s:%s/v2.0/' % (auth.auth_protocol, auth.auth_host, auth.auth_port) authUrl = 'auth url %s user %s password %s tenant %s' % (host, auth.admin_user, auth.admin_password, auth.admin_tenant_name) authUrlCmds = ['enable', 'configure', 'cvx', 'service openstack', 'region RegionOne', authUrl, 'exit', 'exit', 'exit', timestampCmds[0], ] expectedCalls = [mock.call(version=1, cmds=timestampCmds), mock.call(version=1, cmds=authUrlCmds), ] assert self.drv._server.runCmds.call_args_list == expectedCalls admin_tenant_name = 'tenant_name'"," cmds = ['show openstack config region RegionOne timestamp'] self.drv._server.runCmds.assert_called_once_with(version=1, cmds=cmds)",90,13
openstack%2Fnova~master~I6b256b783852cb91869ea99e699b3cafd8665adf,openstack/nova,master,I6b256b783852cb91869ea99e699b3cafd8665adf,initialize objects with context in InstanceNUMATopology object tests,MERGED,2014-12-17 00:50:13.000000000,2015-01-13 01:04:37.000000000,2015-01-12 20:06:06.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-17 00:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac82ebefa3cd1e585c12fbe45dee9b6a6b7025d4', 'message': ""initialize objects with context in InstanceNUMATopology object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I6b256b783852cb91869ea99e699b3cafd8665adf\n""}, {'number': 2, 'created': '2015-01-06 20:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a102327fab4d61a9678d4e7b7edd24e28fa9be0b', 'message': ""initialize objects with context in InstanceNUMATopology object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I6b256b783852cb91869ea99e699b3cafd8665adf\n""}, {'number': 3, 'created': '2015-01-08 06:50:50.000000000', 'files': ['nova/tests/unit/objects/test_instance_numa_topology.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8f39e436fb83e2e9901a560b9b428dfddacf4b87', 'message': ""initialize objects with context in InstanceNUMATopology object tests\n\nThese changes aim to clean up the pattern of passing a context in\nobject member functions create/destroy/refresh/save and instead\ninitialize the object with the context when it's constructed.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I6b256b783852cb91869ea99e699b3cafd8665adf\n""}]",1,142281,8f39e436fb83e2e9901a560b9b428dfddacf4b87,47,11,3,4690,,,0,"initialize objects with context in InstanceNUMATopology object tests

These changes aim to clean up the pattern of passing a context in
object member functions create/destroy/refresh/save and instead
initialize the object with the context when it's constructed.

Related to blueprint kilo-objects

Change-Id: I6b256b783852cb91869ea99e699b3cafd8665adf
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/142281/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_instance_numa_topology.py'],1,ac82ebefa3cd1e585c12fbe45dee9b6a6b7025d4,bp/kilo-objects,def get_fake_obj_numa_topology(context): fake_obj_numa_topology_cpy = fake_obj_numa_topology.obj_clone() fake_obj_numa_topology_cpy._context = context return fake_obj_numa_topology_cpy topo_obj = get_fake_obj_numa_topology(self.context) topo_obj.create() topo_obj = get_fake_obj_numa_topology(self.context), topo_obj = fake_obj_numa_topology topo_obj.create(self.context) topo_obj = fake_obj_numa_topology,9,3
openstack%2Fpuppet-keystone~stable%2Fjuno~I45f364efb585e09412de4398cc3f65615ebc5bb7,openstack/puppet-keystone,stable/juno,I45f364efb585e09412de4398cc3f65615ebc5bb7,Test keystone_user password with Net::HTTP,MERGED,2015-01-12 15:44:42.000000000,2015-01-13 00:40:58.000000000,2015-01-13 00:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-12 15:44:42.000000000', 'files': ['lib/puppet/provider/keystone_user/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b65ddba19f5d89fe13bd0264e988ef702ba2b5c9', 'message': 'Test keystone_user password with Net::HTTP\n\nOpenstackclient 0.3.0 does not have the `token issue` command. If the\nuser is not an admin then there are no other keystone-related actions\nthe user can perform with the openstack command in order to verify\ntheir password. This patch changes the password verification step to\nmake an HTTP request directly against the API. Since there is no\nsession state that needs to be managed, and because this is a special\ntype of request, we do not need to go through the\nPuppet::Provider::Openstack request methods in order to accomplish this\nverification.\n\nCloses-bug: 1408754\n\nChange-Id: I45f364efb585e09412de4398cc3f65615ebc5bb7\n(cherry picked from commit 079a99692eacbd4fe6e28a48ff2d5b73c4e9146d)\n'}]",0,146503,b65ddba19f5d89fe13bd0264e988ef702ba2b5c9,7,4,1,9983,,,0,"Test keystone_user password with Net::HTTP

Openstackclient 0.3.0 does not have the `token issue` command. If the
user is not an admin then there are no other keystone-related actions
the user can perform with the openstack command in order to verify
their password. This patch changes the password verification step to
make an HTTP request directly against the API. Since there is no
session state that needs to be managed, and because this is a special
type of request, we do not need to go through the
Puppet::Provider::Openstack request methods in order to accomplish this
verification.

Closes-bug: 1408754

Change-Id: I45f364efb585e09412de4398cc3f65615ebc5bb7
(cherry picked from commit 079a99692eacbd4fe6e28a48ff2d5b73c4e9146d)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/03/146503/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/keystone_user/openstack.rb'],1,b65ddba19f5d89fe13bd0264e988ef702ba2b5c9,145635,"require 'net/http' # LP#1408754 # Ideally this would be checked with the `openstack token issue` command, # but that command is not available with version 0.3.0 of openstackclient # which is what ships on Ubuntu during Juno. # Instead we'll check whether the user can authenticate with curl. creds_hash = { :auth => { :passwordCredentials => { :username => auth_params['username'], :password => auth_params['password'], } } } url = URI.parse(endpoint) response = Net::HTTP.start(url.host, url.port) do |http| http.request_post('/v2.0/tokens', creds_hash.to_json, {'Content-Type' => 'application/json'}) end if response.code == 401 || response.code == 403 # 401 => unauthorized, 403 => userDisabled elsif ! (response.code == 200 || response.code == 203) return resource[:password] else raise(Puppet::Error, ""Received bad response while trying to authenticate user: #{response.body}"")"," begin request('token', 'issue', nil, auth_params, nil) rescue Puppet::Error::OpenstackUnauthorizedError => e # Could not authenticate, so most likely password is not up to date return resource[:password]",23,5
openstack%2Fpuppet-keystone~stable%2Fjuno~I33ea824a47ca5834b3f97aa9a714ec385984f00f,openstack/puppet-keystone,stable/juno,I33ea824a47ca5834b3f97aa9a714ec385984f00f,Add timeout to API requests,MERGED,2015-01-12 15:44:23.000000000,2015-01-13 00:38:08.000000000,2015-01-13 00:38:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-12 15:44:23.000000000', 'files': ['lib/puppet/provider/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a98a8b354f88a337739dd59a64309fad33549316', 'message': 'Add timeout to API requests\n\nSometimes a service is temporarily unavailable, for instance\nimmediately after puppet refreshes it. This causes the providers to\nfail when it would be optimal to wait briefly for the service to\nreturn. This patch adds a timeout loop in the style of [1] so that the\nkeystone providers can continue to attempt requests if the service was\nunavailable during their first attempt.\n\n[1] https://review.openstack.org/#/c/130155\n\nChange-Id: I33ea824a47ca5834b3f97aa9a714ec385984f00f\n(cherry picked from commit c6f70aeab01651e2b821acb75c5b4c253df3bf6a)\n'}]",0,146502,a98a8b354f88a337739dd59a64309fad33549316,7,4,1,9983,,,0,"Add timeout to API requests

Sometimes a service is temporarily unavailable, for instance
immediately after puppet refreshes it. This causes the providers to
fail when it would be optimal to wait briefly for the service to
return. This patch adds a timeout loop in the style of [1] so that the
keystone providers can continue to attempt requests if the service was
unavailable during their first attempt.

[1] https://review.openstack.org/#/c/130155

Change-Id: I33ea824a47ca5834b3f97aa9a714ec385984f00f
(cherry picked from commit c6f70aeab01651e2b821acb75c5b4c253df3bf6a)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/02/146502/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/openstack.rb'],1,a98a8b354f88a337739dd59a64309fad33549316,145635," rv = nil timeout = 120 end_time = Time.now.to_i + timeout loop do begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled rv = response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] end hash else rv = openstack(service, action, args) break rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') elsif e.message =~ /Unable to establish connection/ current_time = Time.now.to_i if current_time > end_time break else wait = end_time - current_time Puppet::debug(""Non-fatal error: \""#{e.message}\""; retrying for #{wait} more seconds."") if wait > timeout - 2 # Only notice the first time notice(""#{service} service is unavailable. Will retry for up to #{wait} seconds."") end end sleep(2) else raise e end return rv"," begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] hash else openstack(service, action, args) end rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') else raise e",38,19
openstack%2Fpuppet-keystone~stable%2Fjuno~I0e486cfe016799fe22e2024c7c1bc2649933908d,openstack/puppet-keystone,stable/juno,I0e486cfe016799fe22e2024c7c1bc2649933908d,Remove keystone.rb provider for keystone_endpoint,MERGED,2015-01-12 15:44:01.000000000,2015-01-13 00:33:13.000000000,2015-01-13 00:33:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-12 15:44:01.000000000', 'files': ['lib/puppet/provider/keystone_endpoint/keystone.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/74626cbc031dbc1dfd56a2c11d08638c5bbce5b6', 'message': 'Remove keystone.rb provider for keystone_endpoint\n\nIf both keystone.rb and openstack.rb are available there is be no way\nfor puppet to choose between them except by random. This commit removes\nthe old keystone.rb provider for keystone_endpoint so that the correct\nprovider is always used.\n\nChange-Id: I0e486cfe016799fe22e2024c7c1bc2649933908d\n(cherry picked from commit 6e17d965f818c00099b53dc3c850d77ab2c9a40a)\n'}]",0,146501,74626cbc031dbc1dfd56a2c11d08638c5bbce5b6,7,4,1,9983,,,0,"Remove keystone.rb provider for keystone_endpoint

If both keystone.rb and openstack.rb are available there is be no way
for puppet to choose between them except by random. This commit removes
the old keystone.rb provider for keystone_endpoint so that the correct
provider is always used.

Change-Id: I0e486cfe016799fe22e2024c7c1bc2649933908d
(cherry picked from commit 6e17d965f818c00099b53dc3c850d77ab2c9a40a)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/01/146501/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/keystone_endpoint/keystone.rb'],1,74626cbc031dbc1dfd56a2c11d08638c5bbce5b6,145635,,"$LOAD_PATH.push(File.join(File.dirname(__FILE__), '..', '..', '..')) require 'puppet/provider/keystone' Puppet::Type.type(:keystone_endpoint).provide( :keystone, :parent => Puppet::Provider::Keystone ) do desc <<-EOT Provider that uses the keystone client tool to manage keystone endpoints This provider makes a few assumptions/ 1. assumes that the admin endpoint can be accessed via localhost. 2. Assumes that the admin token and port can be accessed from /etc/keystone/keystone.conf EOT optional_commands :keystone => ""keystone"" def initialize(resource = nil) super(resource) @property_flush = {} end def self.prefetch(resources) endpoints = instances resources.keys.each do |name| if provider = endpoints.find{ |endpoint| endpoint.name == name } resources[name].provider = provider end end end def self.instances list_keystone_objects('endpoint', [5,6]).collect do |endpoint| service_name = get_keystone_object('service', endpoint[5], 'name') new( :name => ""#{endpoint[1]}/#{service_name}"", :ensure => :present, :id => endpoint[0], :region => endpoint[1], :public_url => endpoint[2], :internal_url => endpoint[3], :admin_url => endpoint[4], :service_id => endpoint[5], :service_name => service_name ) end end def create optional_opts = [] { :public_url => '--publicurl', :internal_url => '--internalurl', :admin_url => '--adminurl' }.each do |param, opt| if resource[param] optional_opts.push(opt).push(resource[param]) end end (region, service_name) = resource[:name].split('/') resource[:region] = region optional_opts.push('--region').push(resource[:region]) service_id = self.class.list_keystone_objects('service', 4).detect do |s| s[1] == service_name end.first auth_keystone('endpoint-create', '--service-id', service_id, optional_opts) end def exists? @property_hash[:ensure] == :present end def destroy auth_keystone('endpoint-delete', @property_hash[:id]) end def flush if ! @property_flush.empty? destroy create @property_flush.clear end @property_hash = resource.to_hash end def id @property_hash[:id] end def region @property_hash[:region] end def public_url @property_hash[:public_url] end def internal_url @property_hash[:internal_url] end def admin_url @property_hash[:admin_url] end def public_url=(value) @property_hash[:public_url] = value @property_flush[:public_url] = value end def internal_url=(value) @property_hash[:internal_url] = value @property_flush[:internal_url] = value end def admin_url=(value) @property_hash[:admin_url] = value @property_flush[:admin_url] = value end end ",0,125
openstack%2Fpuppet-keystone~stable%2Fjuno~I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13,openstack/puppet-keystone,stable/juno,I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13,Add lib directories to $LOAD_PATH if not present,MERGED,2015-01-08 17:57:34.000000000,2015-01-13 00:30:13.000000000,2015-01-13 00:30:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:57:34.000000000', 'files': ['lib/puppet/type/keystone_service.rb', 'lib/puppet/type/keystone_user_role.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/type/keystone_role.rb', 'lib/puppet/type/keystone_user.rb', 'lib/puppet/type/keystone_endpoint.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/726754fec68b39515a8d17b57665e35c54c42bae', 'message': 'Add lib directories to $LOAD_PATH if not present\n\nA combination of issues with puppet and rspec-puppet make it impossible\nfor rspec-puppet to properly load puppet/util/openstack when other\nmodules run tests against puppet-keystone. This patch works around the\nissue by adding all directories in lib/puppet to the $LOAD_PATH prior\nto attempting to use them.\n\nChange-Id: I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13\nCloses-bug: 1408531\n(cherry picked from commit 031300546a104377623a96506b5d1b8eabc5b4c9)\n'}]",0,145868,726754fec68b39515a8d17b57665e35c54c42bae,10,4,1,9983,,,0,"Add lib directories to $LOAD_PATH if not present

A combination of issues with puppet and rspec-puppet make it impossible
for rspec-puppet to properly load puppet/util/openstack when other
modules run tests against puppet-keystone. This patch works around the
issue by adding all directories in lib/puppet to the $LOAD_PATH prior
to attempting to use them.

Change-Id: I1137459c18e8645e4e8d3b8abb5f93d8b8dbab13
Closes-bug: 1408531
(cherry picked from commit 031300546a104377623a96506b5d1b8eabc5b4c9)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/68/145868/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/type/keystone_service.rb', 'lib/puppet/type/keystone_user_role.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/type/keystone_role.rb', 'lib/puppet/type/keystone_user.rb', 'lib/puppet/type/keystone_endpoint.rb']",6,726754fec68b39515a8d17b57665e35c54c42bae,145635,"# LP#1408531 File.expand_path('../..', File.dirname(__FILE__)).tap { |dir| $LOAD_PATH.unshift(dir) unless $LOAD_PATH.include?(dir) }",,12,0
openstack%2Fpuppet-keystone~stable%2Fjuno~I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5,openstack/puppet-keystone,stable/juno,I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5,Use openstackclient for keystone_endpoint,MERGED,2015-01-08 17:57:29.000000000,2015-01-13 00:26:10.000000000,2015-01-13 00:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:57:29.000000000', 'files': ['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/65e9542a2f651d7025e5271d9234ac7311ef66af', 'message': 'Use openstackclient for keystone_endpoint\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 0696d02d8b5ac3a1088d6f5e2543d749d07816e6)\n'}]",0,145867,65e9542a2f651d7025e5271d9234ac7311ef66af,7,4,1,9983,,,0,"Use openstackclient for keystone_endpoint

blueprint use-openstackclient-in-module-resources

Change-Id: I17194b1c7dd8e8d6650e12c140b7c7e5dc1df4c5
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 0696d02d8b5ac3a1088d6f5e2543d749d07816e6)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/67/145867/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_endpoint/openstack_spec.rb', 'lib/puppet/provider/keystone_endpoint/openstack.rb', 'spec/unit/provider/keystone_endpoint/keystone_spec.rb', 'lib/puppet/type/keystone_endpoint.rb']",4,65e9542a2f651d7025e5271d9234ac7311ef66af,145635,"require 'puppet/util/openstack' desc 'Type for managing keystone endpoints.' auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_openstack_type_methods(self, auth_param_doc)", desc <<-EOT This is currently used to model the management of keystone endpoint. EOT # TODO I should do some url validation,233,79
openstack%2Fpuppet-keystone~stable%2Fjuno~Iba420322e21c2aadeeadc5568ce15e0adcd89f19,openstack/puppet-keystone,stable/juno,Iba420322e21c2aadeeadc5568ce15e0adcd89f19,Use openstackclient for keystone_user_role,MERGED,2015-01-08 17:57:26.000000000,2015-01-13 00:23:27.000000000,2015-01-13 00:23:27.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:57:26.000000000', 'files': ['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/53f2062383a7b5d3cf2058d976b51b16dd2535e2', 'message': 'Use openstackclient for keystone_user_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 80ab6d86a5e286e087e9352231b13f7fab41d7bd)\n'}]",0,145866,53f2062383a7b5d3cf2058d976b51b16dd2535e2,7,4,1,9983,,,0,"Use openstackclient for keystone_user_role

blueprint use-openstackclient-in-module-resources

Change-Id: Iba420322e21c2aadeeadc5568ce15e0adcd89f19
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 80ab6d86a5e286e087e9352231b13f7fab41d7bd)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/66/145866/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user_role/keystone_spec.rb', 'lib/puppet/provider/keystone_user_role/keystone.rb', 'lib/puppet/provider/keystone_user_role/openstack.rb', 'lib/puppet/type/keystone_user_role.rb', 'spec/unit/provider/keystone_user_role/openstack_spec.rb']",5,53f2062383a7b5d3cf2058d976b51b16dd2535e2,145635,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_user_role/openstack' provider_class = Puppet::Type.type(:keystone_user_role).provider(:openstack) describe provider_class do describe 'when updating a user\'s role' do let(:user_role_attrs) do { :name => 'foo@example.com@foo', :ensure => 'present', :roles => ['foo', 'bar'], :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_user_role.new(user_role_attrs) end let(:provider) do provider_class.new(resource) end before(:each) do provider.class.stubs(:openstack) .with('user', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('project', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') end describe '#create' do it 'adds all the roles to the user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05cfed7c24279be884ba4f6520263"",""bar"",""foo"",""foo@example.com"" ') provider.class.stubs(:openstack) .with('role', 'add', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'add', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'removes all the roles from a user' do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User""') provider.class.stubs(:openstack) .with('role', 'remove', [['foo', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.class.stubs(:openstack) .with('role', 'remove', [['bar', '--project', 'foo', '--user', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do subject(:response) do provider.class.stubs(:openstack) .with('user role', 'list', '--quiet', '--format', 'csv', [['--project', 'foo', 'foo@example.com', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Project"",""User"" ""1cb05ed7c24279be884ba4f6520262"",""foo"",""foo"",""foo@example.com"" ""1cb05ed7c24279be884ba4f6520262"",""bar"",""foo"",""foo@example.com"" ') response = provider.exists? end it { is_expected.to be_truthy } end end end ",,255,288
openstack%2Fpuppet-keystone~stable%2Fjuno~I127f44178084978fd37281ac2f79f3e65b96897a,openstack/puppet-keystone,stable/juno,I127f44178084978fd37281ac2f79f3e65b96897a,Use openstackclient for keystone_user,MERGED,2015-01-08 17:57:23.000000000,2015-01-13 00:16:13.000000000,2015-01-13 00:16:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:57:23.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0b35169db2906a1b24258adbb2e0c979fbacd608', 'message': 'Use openstackclient for keystone_user\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I127f44178084978fd37281ac2f79f3e65b96897a\nCo-Authored-By: Rich Megginson <rmeggins@redhat.com>\n(cherry picked from commit 6af8ac6320c8e93a8dae73aa286350d98d3972f1)\n'}]",0,145865,0b35169db2906a1b24258adbb2e0c979fbacd608,7,4,1,9983,,,0,"Use openstackclient for keystone_user

blueprint use-openstackclient-in-module-resources

Change-Id: I127f44178084978fd37281ac2f79f3e65b96897a
Co-Authored-By: Rich Megginson <rmeggins@redhat.com>
(cherry picked from commit 6af8ac6320c8e93a8dae73aa286350d98d3972f1)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/65/145865/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'spec/unit/provider/keystone_user/keystone_spec.rb', 'lib/puppet/provider/keystone_user/openstack.rb', 'lib/puppet/provider/keystone_user/keystone.rb', 'lib/puppet/type/keystone_user.rb']",5,0b35169db2906a1b24258adbb2e0c979fbacd608,145635,"require 'puppet/util/openstack' desc 'Type for managing keystone users.' newvalues(/(t|T)rue/, /(f|F)alse/, true, false) defaultto(true) value.to_s.downcase.to_sym auth_param_doc=<<EOT If no other credentials are present, the provider will search in /etc/keystone/keystone.conf for an admin token and auth url. EOT Puppet::Util::Openstack.add_openstack_type_methods(self, auth_param_doc)"," desc <<-EOT This is currently used to model the creation of keystone users. It currently requires that both the password as well as the tenant are specified. EOT # TODO support description?? newvalues(/(t|T)rue/, /(f|F)alse/) defaultto('True') value.to_s.capitalize",276,224
openstack%2Fpuppet-nova~master~I711aa640726cba76a0cb64ae685b9c3e282f8395,openstack/puppet-nova,master,I711aa640726cba76a0cb64ae685b9c3e282f8395,Correct section for cell_type nova.conf parameter,MERGED,2014-12-16 19:20:46.000000000,2015-01-13 00:13:24.000000000,2014-12-18 10:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2014-12-16 19:20:46.000000000', 'files': ['spec/classes/nova_cells_spec.rb', 'manifests/cells.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a744554e4a7b33e714969eef2db886ac060ed58d', 'message': 'Correct section for cell_type nova.conf parameter\n\nMove the cell_type parameter to the [cells] section, from the\n[DEFAULT] section.\n\nChange-Id: I711aa640726cba76a0cb64ae685b9c3e282f8395\nCloses-bug: 1403174\n'}]",0,142196,a744554e4a7b33e714969eef2db886ac060ed58d,10,3,1,9060,,,0,"Correct section for cell_type nova.conf parameter

Move the cell_type parameter to the [cells] section, from the
[DEFAULT] section.

Change-Id: I711aa640726cba76a0cb64ae685b9c3e282f8395
Closes-bug: 1403174
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/96/142196/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_cells_spec.rb', 'manifests/cells.pp']",2,a744554e4a7b33e714969eef2db886ac060ed58d,bug/1403174, nova_config { 'cells/cell_type': value => 'api' } nova_config { 'cells/cell_type': value => 'compute' }, nova_config { 'DEFAULT/cell_type': value => 'api' } nova_config { 'DEFAULT/cell_type': value => 'compute' },4,2
openstack%2Fpuppet-keystone~stable%2Fjuno~I9fc83d541266ddd28d697df500f6642208235b86,openstack/puppet-keystone,stable/juno,I9fc83d541266ddd28d697df500f6642208235b86,Use openstackclient for keystone_role,MERGED,2015-01-08 17:57:20.000000000,2015-01-13 00:11:50.000000000,2015-01-13 00:11:49.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:57:20.000000000', 'files': ['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb', 'spec/unit/provider/keystone_role/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/918f8f087a7576a7f6ed37dfbcc5be04564267bb', 'message': 'Use openstackclient for keystone_role\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I9fc83d541266ddd28d697df500f6642208235b86\n(cherry picked from commit 4b4850473a940f3d7782dba008697444a942572b)\n'}]",0,145864,918f8f087a7576a7f6ed37dfbcc5be04564267bb,7,4,1,9983,,,0,"Use openstackclient for keystone_role

blueprint use-openstackclient-in-module-resources

Change-Id: I9fc83d541266ddd28d697df500f6642208235b86
(cherry picked from commit 4b4850473a940f3d7782dba008697444a942572b)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/64/145864/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_role/keystone.rb', 'lib/puppet/provider/keystone_role/openstack.rb', 'lib/puppet/type/keystone_role.rb', 'spec/unit/provider/keystone_role/openstack_spec.rb']",4,918f8f087a7576a7f6ed37dfbcc5be04564267bb,145635,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_role/openstack' provider_class = Puppet::Type.type(:keystone_role).provider(:openstack) describe provider_class do describe 'when creating a role' do let(:role_attrs) do { :name => 'foo', :ensure => 'present', :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_role.new(role_attrs) end let(:provider) do provider_class.new(resource) end describe '#create' do it 'creates a role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') provider.class.stubs(:openstack) .with('role', 'create', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'destroys a role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name""') provider.class.stubs(:openstack) .with('role', 'delete', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do context 'when role exists' do subject(:response) do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') response = provider.exists? end it { is_expected.to be_truthy } end context 'when role does not exist' do subject(:response) do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name""') response = provider.exists? end it { is_expected.to be_falsey } end end describe '#instances' do it 'finds every role' do provider.class.stubs(:openstack) .with('role', 'list', '--quiet', '--format', 'csv', [['--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"" ') instances = provider.instances expect(instances.count).to eq(1) end end end end ",,158,65
openstack%2Foslo.db~master~Id892567bd60d6b4b88765bbfe3cd5c5e75910b25,openstack/oslo.db,master,Id892567bd60d6b4b88765bbfe3cd5c5e75910b25,Restore the check_foreign_keys() method.,MERGED,2015-01-12 22:27:53.000000000,2015-01-13 00:05:05.000000000,2015-01-13 00:05:04.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 7249}, {'_account_id': 7491}]","[{'number': 1, 'created': '2015-01-12 22:27:53.000000000', 'files': ['oslo_db/sqlalchemy/test_migrations.py', 'oslo_db/tests/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/b1fc55c7ce6004311379f4002fdceddcc8da9784', 'message': 'Restore the check_foreign_keys() method.\n\nThis method was prematurely removed from oslo.db without\na deprecation phase, when Alembic added support for\nforeign key autodetection.   oslo.db continues to use\nalembic for this purpose, however the\nModelsMigrationsSync.check_foreign_keys() method is restored\ndirectly for those projects which were calling into it\nexplicitly.\n\nChange-Id: Id892567bd60d6b4b88765bbfe3cd5c5e75910b25\n'}]",0,146663,b1fc55c7ce6004311379f4002fdceddcc8da9784,7,5,1,11816,,,0,"Restore the check_foreign_keys() method.

This method was prematurely removed from oslo.db without
a deprecation phase, when Alembic added support for
foreign key autodetection.   oslo.db continues to use
alembic for this purpose, however the
ModelsMigrationsSync.check_foreign_keys() method is restored
directly for those projects which were calling into it
explicitly.

Change-Id: Id892567bd60d6b4b88765bbfe3cd5c5e75910b25
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/63/146663/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/test_migrations.py', 'oslo_db/tests/sqlalchemy/test_migrations.py']",2,b1fc55c7ce6004311379f4002fdceddcc8da9784,restore_check_foreign_keys," class TestOldCheckForeignKeys(test_base.DbTestCase): def setUp(self): super(TestOldCheckForeignKeys, self).setUp() test = self class MigrateSync(migrate.ModelsMigrationsSync): def get_engine(self): return test.engine def get_metadata(self): return test.metadata def db_sync(self): raise NotImplementedError() self.migration_sync = MigrateSync() def _fk_added_fixture(self): self.metadata = sa.MetaData() self.metadata_migrations = sa.MetaData() sa.Table( 'testtbl_one', self.metadata, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata, sa.Column('id', sa.Integer, primary_key=True), sa.Column('tone_id', sa.Integer), mysql_engine='InnoDB' ) sa.Table( 'testtbl_one', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), sa.Column( 'tone_id', sa.Integer, sa.ForeignKey('testtbl_one.id', name=""tone_id_fk"")), mysql_engine='InnoDB' ) def _fk_removed_fixture(self): self.metadata = sa.MetaData() self.metadata_migrations = sa.MetaData() sa.Table( 'testtbl_one', self.metadata, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata, sa.Column('id', sa.Integer, primary_key=True), sa.Column( 'tone_id', sa.Integer, sa.ForeignKey('testtbl_one.id', name=""tone_id_fk"")), mysql_engine='InnoDB' ) sa.Table( 'testtbl_one', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), sa.Column('tone_id', sa.Integer), mysql_engine='InnoDB' ) def _fk_no_change_fixture(self): self.metadata = sa.MetaData() self.metadata_migrations = sa.MetaData() sa.Table( 'testtbl_one', self.metadata, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata, sa.Column('id', sa.Integer, primary_key=True), sa.Column( 'tone_id', sa.Integer, sa.ForeignKey('testtbl_one.id', name=""tone_id_fk"")), mysql_engine='InnoDB' ) sa.Table( 'testtbl_one', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), mysql_engine='InnoDB' ) sa.Table( 'testtbl_two', self.metadata_migrations, sa.Column('id', sa.Integer, primary_key=True), sa.Column( 'tone_id', sa.Integer, sa.ForeignKey('testtbl_one.id', name=""tone_id_fk"")), mysql_engine='InnoDB' ) def _run_test(self): self.metadata.create_all(bind=self.engine) return self.migration_sync.check_foreign_keys( self.metadata_migrations, self.engine) def _compare_diffs(self, diffs, compare_to): diffs = [ ( cmd, fk._get_colspec() if isinstance(fk, sa.ForeignKey) else ""tone_id_fk"" if fk is None # sqlite workaround else fk, tname, fk_info ) for cmd, fk, tname, fk_info in diffs ] self.assertEqual(diffs, compare_to) def test_fk_added(self): self._fk_added_fixture() diffs = self._run_test() self._compare_diffs( diffs, [( 'add_key', 'testtbl_one.id', 'testtbl_two', self.migration_sync.FKInfo( constrained_columns=('tone_id',), referred_table='testtbl_one', referred_columns=('id',)) )] ) def test_fk_removed(self): self._fk_removed_fixture() diffs = self._run_test() self._compare_diffs( diffs, [( 'drop_key', ""tone_id_fk"", 'testtbl_two', self.migration_sync.FKInfo( constrained_columns=('tone_id',), referred_table='testtbl_one', referred_columns=('id',)) )] ) def test_fk_no_change(self): self._fk_no_change_fixture() diffs = self._run_test() self._compare_diffs( diffs, []) class PGTestOldCheckForeignKeys( TestOldCheckForeignKeys, test_base.PostgreSQLOpportunisticTestCase): pass class MySQLTestOldCheckForeignKeys( TestOldCheckForeignKeys, test_base.MySQLOpportunisticTestCase): pass",,259,0
openstack%2Ftempest~master~Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70,openstack/tempest,master,Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70,Avoid to use boto 2.35.0 for workaround,ABANDONED,2015-01-09 04:49:07.000000000,2015-01-13 00:04:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-09 04:49:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/926d49ee6f313b65b5864f91625209a17774f25c', 'message': 'Avoid to use boto 2.35.0 for workaround\n\nAfter the latest boto 2.35.0, Tempest tests have been failed now.\nThis patch adds the cap of the lastest boto for temporary workaround.\n\nChange-Id: Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70\nDepends-On: I1c07aca5614158698a5a796d30018173082671a5\n'}]",0,146015,926d49ee6f313b65b5864f91625209a17774f25c,8,4,1,6167,,,0,"Avoid to use boto 2.35.0 for workaround

After the latest boto 2.35.0, Tempest tests have been failed now.
This patch adds the cap of the lastest boto for temporary workaround.

Change-Id: Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70
Depends-On: I1c07aca5614158698a5a796d30018173082671a5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/15/146015/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,926d49ee6f313b65b5864f91625209a17774f25c,workaround-boto,"boto>=2.32.1,<2.35.0",boto>=2.32.1,1,1
openstack%2Fnova~master~Iac3e8798638b1220073b233ce36fcc31eec4936e,openstack/nova,master,Iac3e8798638b1220073b233ce36fcc31eec4936e,Avoid to use boto 2.35.0 for workaround,ABANDONED,2015-01-09 03:27:56.000000000,2015-01-13 00:04:29.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-01-09 03:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62a01f54d60e046cea62e68114abde9637083d33', 'message': 'Avoid to use boto 2.35.0 for workaround\n\nAfter the latest boto 2.35.0, the unit tests and Tempest tests have\nbeen failed now.\nThis patch adds the cap of the lastest boto for temporary workaround.\n\nChange-Id: Iac3e8798638b1220073b233ce36fcc31eec4936e\n'}, {'number': 2, 'created': '2015-01-09 03:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37d939c21109a7c836cb1b5c14550bca440ef385', 'message': 'Avoid to use boto 2.35.0 for workaround\n\nAfter the latest boto 2.35.0, the unit tests and Tempest tests have\nbeen failed now.\nThis patch adds the cap of the lastest boto for temporary workaround.\n\nDepends-On: I1c07aca5614158698a5a796d30018173082671a5\nChange-Id: Iac3e8798638b1220073b233ce36fcc31eec4936e\n'}, {'number': 3, 'created': '2015-01-09 05:22:35.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/1854b29d8f2a0d27b54df72874909022367a537e', 'message': 'Avoid to use boto 2.35.0 for workaround\n\nAfter the latest boto 2.35.0, the unit tests and Tempest tests have\nbeen failed now.\nThis patch adds the cap of the lastest boto for temporary workaround.\n\nDepends-On: I1c07aca5614158698a5a796d30018173082671a5\nDepends-On: Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70\nChange-Id: Iac3e8798638b1220073b233ce36fcc31eec4936e\n'}]",0,146005,1854b29d8f2a0d27b54df72874909022367a537e,14,7,3,6167,,,0,"Avoid to use boto 2.35.0 for workaround

After the latest boto 2.35.0, the unit tests and Tempest tests have
been failed now.
This patch adds the cap of the lastest boto for temporary workaround.

Depends-On: I1c07aca5614158698a5a796d30018173082671a5
Depends-On: Ied79ba55dba0aaa92d6251d1a8c41b2bcc968f70
Change-Id: Iac3e8798638b1220073b233ce36fcc31eec4936e
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/146005/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,62a01f54d60e046cea62e68114abde9637083d33,workaround-boto,"boto>=2.32.1,<2.35.0",boto>=2.32.1,1,1
openstack%2Fpuppet-keystone~stable%2Fjuno~Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0,openstack/puppet-keystone,stable/juno,Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0,Use openstackclient for keystone_service,MERGED,2015-01-08 17:55:59.000000000,2015-01-13 00:02:32.000000000,2015-01-13 00:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-08 17:55:59.000000000', 'files': ['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb', 'spec/unit/provider/keystone_service/openstack_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/0a9d308bbbd143f9483c69ee3d49de9cbb950f2c', 'message': 'Use openstackclient for keystone_service\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0\n(cherry picked from commit 72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed)\n'}]",0,145862,0a9d308bbbd143f9483c69ee3d49de9cbb950f2c,7,4,1,9983,,,0,"Use openstackclient for keystone_service

blueprint use-openstackclient-in-module-resources

Change-Id: Ib889dbc6b13c22f77e73747d0b2fd589d0882ef0
(cherry picked from commit 72a02aa70880bb5cb07d0a2b1e828fffbae5d0ed)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/62/145862/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/keystone_service/openstack.rb', 'lib/puppet/type/keystone_service.rb', 'lib/puppet/provider/keystone_service/keystone.rb', 'spec/unit/provider/keystone_service/openstack_spec.rb']",4,0a9d308bbbd143f9483c69ee3d49de9cbb950f2c,145635,"require 'puppet' require 'spec_helper' require 'puppet/provider/keystone_service/openstack' provider_class = Puppet::Type.type(:keystone_service).provider(:openstack) describe provider_class do describe 'when creating a service' do let(:service_attrs) do { :name => 'foo', :description => 'foo', :ensure => 'present', :type => 'foo', :auth => { 'username' => 'test', 'password' => 'abc123', 'tenant_name' => 'foo', 'auth_url' => 'http://127.0.0.1:5000/v2.0', } } end let(:resource) do Puppet::Type::Keystone_service.new(service_attrs) end let(:provider) do provider_class.new(resource) end describe '#create' do it 'creates a service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') provider.class.stubs(:openstack) .with('service', 'create', [['foo', '--description', 'foo', '--type', 'foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.create expect(provider.exists?).to be_truthy end end describe '#destroy' do it 'destroys a service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description""') provider.class.stubs(:openstack) .with('service', 'delete', [['foo', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) provider.destroy expect(provider.exists?).to be_falsey end end describe '#exists' do context 'when service exists' do subject(:response) do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') response = provider.exists? end it { is_expected.to be_truthy } end context 'when service does not exist' do subject(:response) do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description""') response = provider.exists? end it { is_expected.to be_falsey } end end describe '#instances' do it 'finds every service' do provider.class.stubs(:openstack) .with('service', 'list', '--quiet', '--format', 'csv', [['--long', '--os-username', 'test', '--os-password', 'abc123', '--os-tenant-name', 'foo', '--os-auth-url', 'http://127.0.0.1:5000/v2.0']]) .returns('""ID"",""Name"",""Type"",""Description"" ""1cb05cfed7c24279be884ba4f6520262"",""foo"",""foo"",""foo"" ') instances = provider.instances expect(instances.count).to eq(1) end end end end ",,218,102
openstack%2Fpuppet-heat~master~I3d6545cf1e5338b1098ee52daedcc17dc9ad990b,openstack/puppet-heat,master,I3d6545cf1e5338b1098ee52daedcc17dc9ad990b,Move keystone role creation to keystone area,MERGED,2014-12-10 22:47:33.000000000,2015-01-13 00:02:12.000000000,2015-01-13 00:02:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-12-10 22:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/43f7a155207c1846b557d1ca42119a047c00c4d3', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 2, 'created': '2014-12-10 22:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/91d08f7983f2163dc315a86fbdd33bdbb624d1f1', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 3, 'created': '2014-12-16 18:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/1bbbc78a41cfbf647fa29e5ae679ea3882c53302', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 4, 'created': '2014-12-16 19:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/95b5cb9cb0a1c43b9be740ba2889d07c7a845cf1', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 5, 'created': '2015-01-05 15:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/963b479383ab28de964f366b9d0cb400b4fd122a', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 6, 'created': '2015-01-12 00:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/01f53aa347a23e03cbdcfa45786e759fee1f0629', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 7, 'created': '2015-01-12 21:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/66d4ac6e3007b5131750a05935d514daf3bbbad8', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}, {'number': 8, 'created': '2015-01-12 21:26:01.000000000', 'files': ['manifests/engine.pp', 'spec/classes/heat_keystone_auth_spec.rb', 'spec/classes/heat_engine_spec.rb', 'manifests/keystone/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/74e874365933b3d7a07d6413762597e78efaaaa8', 'message': 'Move keystone role creation to keystone area\n\nWhen the engine code does things with Keystone roles/etc it breaks when\nrun on nodes that are not running Keystone. Some environments have\nKeystone in a separate node thereby causing issues. This moves it into\nthe Keystone auth class to match the functaionality of other puppet\nmodules and avoid this issue. The older parameters are deprecated but\nwill still work.\n\nBased on the original patch by Vladislav Belogrudov.\n\nChange-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b\nCloses-Bug: #1393293\n'}]",3,140854,74e874365933b3d7a07d6413762597e78efaaaa8,25,5,8,9500,,,0,"Move keystone role creation to keystone area

When the engine code does things with Keystone roles/etc it breaks when
run on nodes that are not running Keystone. Some environments have
Keystone in a separate node thereby causing issues. This moves it into
the Keystone auth class to match the functaionality of other puppet
modules and avoid this issue. The older parameters are deprecated but
will still work.

Based on the original patch by Vladislav Belogrudov.

Change-Id: I3d6545cf1e5338b1098ee52daedcc17dc9ad990b
Closes-Bug: #1393293
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/54/140854/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/engine.pp', 'manifests/keystone/auth.pp']",2,43f7a155207c1846b557d1ca42119a047c00c4d3,bug/1393293,"# [*trusts_delegated_roles*] # (optional) Array of trustor roles to be delegated to heat. # Defaults to ['heat_stack_owner'] # # [*configure_delegated_roles*] # (optional) Whether to configure the delegated roles. # Defaults to true # $trusts_delegated_roles = ['heat_stack_owner'], $configure_delegated_roles = true, if $configure_delegated_roles { keystone_role { $trusts_delegated_roles: ensure => present, } }",,15,16
openstack%2Fcinder~master~Icd91eff614fa6b3e61e48edccda4bd7bf3955b60,openstack/cinder,master,Icd91eff614fa6b3e61e48edccda4bd7bf3955b60,Adds cinder iscsi driver for CloudByte storage,MERGED,2014-06-25 12:36:07.000000000,2015-01-12 23:59:12.000000000,2015-01-12 23:59:11.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8475}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9067}, {'_account_id': 9533}, {'_account_id': 9751}, {'_account_id': 10068}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12492}, {'_account_id': 12493}, {'_account_id': 12779}, {'_account_id': 12780}, {'_account_id': 13628}, {'_account_id': 13645}, {'_account_id': 13900}, {'_account_id': 14056}, {'_account_id': 14059}, {'_account_id': 14102}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14428}]","[{'number': 1, 'created': '2014-06-25 12:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/578a6fd2c6d7cdaa6a5e2f752e36fb515983c7b1', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 2, 'created': '2014-06-26 10:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b23c87c2c69a08adeb9b5b27159e71a0cc7146a2', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 3, 'created': '2014-06-27 07:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/397b5496edcc7ffc304083b8affdc2d5c0a03818', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 4, 'created': '2014-07-04 07:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a5a11859958c87b3a8ca61e7bfbf1911c7dfa8d0', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 5, 'created': '2014-07-04 11:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/560c0440f00ee52c80941b89444a78ed40ea8f76', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 6, 'created': '2014-10-13 10:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3f338d31a1e3fe6e54ae09e4881f6c4e5999c998', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 7, 'created': '2014-10-14 12:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/afccf287177dc07625c6087cb88e81643d2b2375', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 8, 'created': '2014-10-15 06:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/26edd6d9ff1802a762582c5c34eb3295a5717b4a', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 9, 'created': '2014-10-15 10:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a1f48db22e22bd0653eb4350731299d4bd8303d9', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 10, 'created': '2014-10-15 11:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d338893002188b6776e56cafbcc4c3f319178398', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 11, 'created': '2014-11-18 09:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c43f53a8b119470184e95bd92cf66bd487e6829', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 12, 'created': '2014-11-28 12:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/94d576849acbfd3a2f837ebc59aa145e63e3de3c', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 13, 'created': '2014-12-12 12:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/51a0407253ce876416c7993e3e21aec96beaf18e', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 14, 'created': '2014-12-15 06:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b029e610f5fa226ed5ccc6e523c4013cfc6bba94', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 15, 'created': '2014-12-16 07:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bee5b1d0cd5acbb869a8274ed2dc25235ff51daf', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 16, 'created': '2014-12-18 10:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1478dd07941041faaf94751d6f853d5392b1d29c', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 17, 'created': '2014-12-30 09:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f952a32b01d45efb6406546f5bc886b73d95faa4', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 18, 'created': '2014-12-30 11:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea7c03d8484b51bd6bcbb6716aee952eb871b500', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 19, 'created': '2014-12-30 12:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1d4862b5035e677e40eb51571a1f49c7680843da', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 20, 'created': '2014-12-31 11:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/38b25f26720ed0d437c2b194eef19f32de7feee6', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 21, 'created': '2015-01-05 12:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20b853921dc37b97b5e2065f2e4cfc866c5c7300', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 22, 'created': '2015-01-06 07:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6b1ab91bff873673e4b7aacedf92017cb1257dea', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}, {'number': 23, 'created': '2015-01-07 06:20:01.000000000', 'files': ['cinder/volume/drivers/cloudbyte/cloudbyte.py', 'cinder/volume/drivers/cloudbyte/__init__.py', 'cinder/volume/drivers/cloudbyte/options.py', 'cinder/tests/test_cloudbyte.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/54d4769a3bcdefd18139b8fd59430a2a80e18a9d', 'message': 'Adds cinder iscsi driver for CloudByte storage\n\nThis patch satisfies the basic requirements for a cinder driver. It has\nthe necessary code to provision storage volume, snapshot and clone.\n\nDriver certification results url https://bugs.launchpad.net/cinder/+bug/1380126\n\nChange-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60\nImplements: blueprint CloudByte-ElastiStor-Cinder-Driver\n'}]",193,102511,54d4769a3bcdefd18139b8fd59430a2a80e18a9d,265,40,23,8475,,,0,"Adds cinder iscsi driver for CloudByte storage

This patch satisfies the basic requirements for a cinder driver. It has
the necessary code to provision storage volume, snapshot and clone.

Driver certification results url https://bugs.launchpad.net/cinder/+bug/1380126

Change-Id: Icd91eff614fa6b3e61e48edccda4bd7bf3955b60
Implements: blueprint CloudByte-ElastiStor-Cinder-Driver
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/102511/11 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/cloudbyte/cloudbyte.py', 'cinder/volume/manager.py', 'cinder/exception.py', 'cinder/volume/drivers/cloudbyte/__init__.py', 'cinder/tests/test_cloudbyte.py', 'cinder/volume/drivers/cloudbyte/options.py']",6,578a6fd2c6d7cdaa6a5e2f752e36fb515983c7b1,bp/CloudByte-ElastiStor-Cinder-Driver,"# Copyright 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo.config import cfg cloudbyte_connection_opts = [ cfg.StrOpt('cb_apikey', default='None', help=('Elasticenter authorization purpose;')), cfg.StrOpt('cb_account_name', default='None', help=('Used to create tsm;')), cfg.StrOpt('tsm_name', default='None', help=('Used to create volume;')), cfg.IntOpt('confirm_vol_sleep_interval', default=5, help=('Sleep value is in seconds')), cfg.IntOpt('confirm_vol_sleep_counter', default=5, help=('Will confirm a successful volume ' 'creation by making this many attempts')), ] cloudbyte_add_qosgroup_opts = [ cfg.DictOpt('add_qosgroup', default={ 'iops': '10', 'latency': '15', 'graceallowed': 'false', 'networkspeed': '0', 'memlimit': '0', 'tpcontrol': 'true', 'iopscontrol': 'true' }, help=('These values will be used by addQos api;')), ] cloudbyte_create_volume_opts = [ cfg.DictOpt('create_volume', default={ 'blocklength': '512B', 'compression': 'off', 'deduplication': 'off', 'sync': 'always', 'recordsize': '128k', 'protocoltype': 'ISCSI' }, help=('These values will be used by createVolume api;')), ] CONF = cfg.CONF CONF.register_opts(cloudbyte_add_qosgroup_opts) CONF.register_opts(cloudbyte_create_volume_opts) CONF.register_opts(cloudbyte_connection_opts) ",,2406,1
openstack%2Frequirements~master~Id1de584c06c81beaa7b91ddec9d63a7382e9443f,openstack/requirements,master,Id1de584c06c81beaa7b91ddec9d63a7382e9443f,Use oslo.serialization without the namespace package,MERGED,2015-01-08 21:37:07.000000000,2015-01-12 23:58:35.000000000,2015-01-12 23:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1955}, {'_account_id': 2750}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-08 21:37:07.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/42e2271f4ce95703db652126655020e0963ccdf3', 'message': 'Use oslo.serialization without the namespace package\n\nAllow applications to depend on a version of oslo.serialization\nthat has code outside of the namespace package.\n\nbp/drop-namespace-packages\n\nChange-Id: Id1de584c06c81beaa7b91ddec9d63a7382e9443f\n'}]",0,145937,42e2271f4ce95703db652126655020e0963ccdf3,14,5,1,2472,,,0,"Use oslo.serialization without the namespace package

Allow applications to depend on a version of oslo.serialization
that has code outside of the namespace package.

bp/drop-namespace-packages

Change-Id: Id1de584c06c81beaa7b91ddec9d63a7382e9443f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/37/145937/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,42e2271f4ce95703db652126655020e0963ccdf3,bp/drop-namespace-packages,oslo.serialization>=1.2.0 # Apache-2.0,oslo.serialization>=1.0.0 # Apache-2.0,1,1
openstack%2Fpuppet-keystone~stable%2Fjuno~I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39,openstack/puppet-keystone,stable/juno,I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39,Use openstackclient for keystone_tenant,MERGED,2015-01-07 23:43:08.000000000,2015-01-12 23:57:59.000000000,2015-01-12 23:57:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-01-07 23:43:08.000000000', 'files': ['spec/unit/provider/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'manifests/init.pp', 'lib/puppet/provider/keystone_tenant/openstack.rb', 'lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'lib/puppet/util/openstack.rb', 'spec/spec_helper.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'spec/unit/provider/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a09bc1bc4a12d4eb28d9f644bc145e5d963c3b02', 'message': 'Use openstackclient for keystone_tenant\n\nThis patch migrates the keystone_tenant provider to use the universal\nopenstack client instead of the keystone client. It uses the openstack\nparent provider in openstacklib to handle multiple authenticating\nmethods. The keystone_tenant type uses the openstacklib openstack\nutility to add a new auth parameter to the keystone_tenant type.\n\nThis patch also moves functionality for parsing keystone.conf for the\nservice token back to the keystone module from openstacklib. It creates\nthree tiers of inheritance: Keystone_tenant < Keystone < Openstack, so\nthat keystone-specific functionality can stay in keystone.\n\nIt also adds a flush method which should help improve performance.\n\nblueprint use-openstackclient-in-module-resources\n\nChange-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39\n(cherry picked from commit acf3dc6f06b6dcc5af876517c8511a5225e5e3f6)\n'}]",0,145635,a09bc1bc4a12d4eb28d9f644bc145e5d963c3b02,7,4,1,9983,,,0,"Use openstackclient for keystone_tenant

This patch migrates the keystone_tenant provider to use the universal
openstack client instead of the keystone client. It uses the openstack
parent provider in openstacklib to handle multiple authenticating
methods. The keystone_tenant type uses the openstacklib openstack
utility to add a new auth parameter to the keystone_tenant type.

This patch also moves functionality for parsing keystone.conf for the
service token back to the keystone module from openstacklib. It creates
three tiers of inheritance: Keystone_tenant < Keystone < Openstack, so
that keystone-specific functionality can stay in keystone.

It also adds a flush method which should help improve performance.

blueprint use-openstackclient-in-module-resources

Change-Id: I2d9a16f334d1e60ebdd36805e2f8d8d2ef82cf39
(cherry picked from commit acf3dc6f06b6dcc5af876517c8511a5225e5e3f6)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/35/145635/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_spec.rb', 'spec/unit/provider/keystone_tenant/keystone_spec.rb', 'manifests/init.pp', 'lib/puppet/provider/keystone_tenant/openstack.rb', 'lib/puppet/provider/keystone.rb', 'lib/puppet/provider/keystone_tenant/keystone.rb', 'lib/puppet/util/openstack.rb', 'spec/spec_helper.rb', 'spec/unit/provider/keystone_tenant/openstack_spec.rb', 'spec/unit/provider/openstack_spec.rb', 'lib/puppet/type/keystone_tenant.rb', 'lib/puppet/provider/openstack.rb']",12,a09bc1bc4a12d4eb28d9f644bc145e5d963c3b02,,"# TODO: This needs to be extracted out into openstacklib in the Kilo cycle require 'csv' require 'puppet' class Puppet::Error::OpenstackAuthInputError < Puppet::Error end class Puppet::Error::OpenstackUnauthorizedError < Puppet::Error end class Puppet::Provider::Openstack < Puppet::Provider initvars # so commands will work commands :openstack => 'openstack' def request(service, action, object, credentials, *properties) if password_credentials_set?(credentials) auth_args = password_auth_args(credentials) elsif openrc_set?(credentials) credentials = get_credentials_from_openrc(credentials['openrc']) auth_args = password_auth_args(credentials) elsif service_credentials_set?(credentials) auth_args = token_auth_args(credentials) elsif env_vars_set? # noop; auth needs no extra arguments auth_args = nil else # All authentication efforts failed raise(Puppet::Error::OpenstackAuthInputError, 'No credentials provided.') end args = [object, properties, auth_args].flatten.compact authenticate_request(service, action, args) end def self.request(service, action, object, *properties) if env_vars_set? # noop; auth needs no extra arguments auth_args = nil else # All authentication efforts failed raise(Puppet::Error::OpenstackAuthInputError, 'No credentials provided.') end args = [object, properties, auth_args].flatten.compact authenticate_request(service, action, args) end # Returns an array of hashes, where the keys are the downcased CSV headers # with underscores instead of spaces def self.authenticate_request(service, action, *args) begin if(action == 'list') response = openstack(service, action, '--quiet', '--format', 'csv', args) response = CSV.parse(response.to_s) keys = response.delete_at(0) # ID,Name,Description,Enabled response.collect do |line| hash = {} keys.each_index do |index| key = keys[index].downcase.gsub(/ /, '_').to_sym hash[key] = line[index] end hash end else openstack(service, action, args) end rescue Puppet::ExecutionFailure => e if e.message =~ /HTTP 401/ raise(Puppet::Error::OpenstackUnauthorizedError, 'Could not authenticate.') else raise e end end end def authenticate_request(service, action, *args) self.class.authenticate_request(service, action, *args) end private def password_credentials_set?(auth_params) auth_params && auth_params['username'] && auth_params['password'] && auth_params['tenant_name'] && auth_params['auth_url'] end def openrc_set?(auth_params) auth_params && auth_params['openrc'] end def service_credentials_set?(auth_params) auth_params && auth_params['token'] && auth_params['auth_url'] end def self.env_vars_set? ENV['OS_USERNAME'] && ENV['OS_PASSWORD'] && ENV['OS_TENANT_NAME'] && ENV['OS_AUTH_URL'] end def env_vars_set? self.class.env_vars_set? end def self.password_auth_args(credentials) ['--os-username', credentials['username'], '--os-password', credentials['password'], '--os-tenant-name', credentials['tenant_name'], '--os-auth-url', credentials['auth_url']] end def password_auth_args(credentials) self.class.password_auth_args(credentials) end def self.token_auth_args(credentials) ['--os-token', credentials['token'], '--os-url', credentials['auth_url']] end def token_auth_args(credentials) self.class.token_auth_args(credentials) end def get_credentials_from_openrc(file) creds = {} File.open(file).readlines.delete_if{|l| l=~ /^#/}.each do |line| key, value = line.split('=') key = key.split(' ').last.downcase.sub(/^os_/, '') value = value.chomp.gsub(/'/, '') creds[key] = value end return creds end def self.get_credentials_from_env env = ENV.to_hash.dup.delete_if { |key, _| ! (key =~ /^OS_/) } credentials = {} env.each do |name, value| credentials[name.downcase.sub(/^os_/, '')] = value end credentials end def get_credentials_from_env self.class.get_credentials_from_env end end ",,707,214
openstack%2Fcongress~master~I3e1200331303062caba1e10229482a0ef41807af,openstack/congress,master,I3e1200331303062caba1e10229482a0ef41807af,Handle case when last_policy_change is None,MERGED,2015-01-12 22:02:33.000000000,2015-01-12 23:32:17.000000000,2015-01-12 23:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-12 22:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6a8ba293d52495c8a0228c1929c0bc32328e1a35', 'message': 'Handle case when last_policy_change is None\n\nThe previous version assumed that last_policy_change is always non-None.\nHowever, the timing can work out such that nothing calls\nreceive_policy_update, before the first retry, and therefore hte\nlast_policy_change is None.  This causes intermittent test failurse.\n\nChange-Id: I3e1200331303062caba1e10229482a0ef41807af\n'}, {'number': 2, 'created': '2015-01-12 22:42:40.000000000', 'files': ['congress/tests/helper.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/626d6868400aebbdefa1285f2d9e18315b5e453c', 'message': 'Handle case when last_policy_change is None\n\nThe previous version assumed that last_policy_change is always non-None.\nHowever, the timing can work out such that nothing calls\nreceive_policy_update, before the first retry, and therefore hte\nlast_policy_change is None.  This causes intermittent test failurse.\n\nChange-Id: I3e1200331303062caba1e10229482a0ef41807af\n'}]",0,146654,626d6868400aebbdefa1285f2d9e18315b5e453c,10,3,2,12875,,,0,"Handle case when last_policy_change is None

The previous version assumed that last_policy_change is always non-None.
However, the timing can work out such that nothing calls
receive_policy_update, before the first retry, and therefore hte
last_policy_change is None.  This causes intermittent test failurse.

Change-Id: I3e1200331303062caba1e10229482a0ef41807af
",git fetch https://review.opendev.org/openstack/congress refs/changes/54/146654/2 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests/helper.py'],1,6a8ba293d52495c8a0228c1929c0bc32328e1a35,bug/1404975," if obj.last_policy_change is None: raise Exception(""last_policy_change == None"")",,2,0
openstack%2Fcongress~master~Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e,openstack/congress,master,Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e,Split up runtime.py into more separate files,MERGED,2015-01-09 23:58:44.000000000,2015-01-12 23:30:41.000000000,2015-01-12 23:30:41.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-09 23:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c5239e92a3ea1cff00cf3976e574eb14989201cf', 'message': 'Split up runtime.py into more separate files\n\nruntime.py was still too big.  This change finishes splitting it up.\n\nChange-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e\nCloses-Bug: #1404975\n'}, {'number': 2, 'created': '2015-01-12 19:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/21bf83b6747831024d6e53afa847e4bb7b197bb3', 'message': 'Split up runtime.py into more separate files\n\nruntime.py was still too big.  This change finishes splitting it up.\n\nChange-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e\nCloses-Bug: #1404975\n'}, {'number': 3, 'created': '2015-01-12 21:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/27fb00d7be68b54f258a5d4b6964ee7228fd39bf', 'message': 'Split up runtime.py into more separate files\n\nruntime.py was still too big.  This change finishes splitting it up.\n\nChange-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e\nCloses-Bug: #1404975\n'}, {'number': 4, 'created': '2015-01-12 22:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/11d9cedb442da1964968949adb6b79dcf6b77653', 'message': 'Split up runtime.py into more separate files\n\nruntime.py was still too big.  This change finishes splitting it up.\n\nChange-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e\nCloses-Bug: #1404975\n'}, {'number': 5, 'created': '2015-01-12 22:42:40.000000000', 'files': ['congress/tests/policy/test_unify.py', 'congress/policy/base.py', 'congress/policy/materialized.py', 'congress/policy/database.py', 'congress/policy/runtime.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/1ecfac263969fd11ee7534952f711b3631ed5c8a', 'message': 'Split up runtime.py into more separate files\n\nruntime.py was still too big.  This change finishes splitting it up.\n\nChange-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e\nCloses-Bug: #1404975\n'}]",3,146227,1ecfac263969fd11ee7534952f711b3631ed5c8a,21,4,5,12875,,,0,"Split up runtime.py into more separate files

runtime.py was still too big.  This change finishes splitting it up.

Change-Id: Ic0267d3d81a88e1835e33cb2dd49a783b64c6d8e
Closes-Bug: #1404975
",git fetch https://review.opendev.org/openstack/congress refs/changes/27/146227/4 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy/test_unify.py', 'congress/policy/base.py', 'congress/policy/materialized.py', 'congress/policy/database.py', 'congress/policy/runtime.py']",5,c5239e92a3ea1cff00cf3976e574eb14989201cf,bug/1404975,from congress.policy.database import Database from congress.policy.materialized import MaterializedViewTheory,"from congress.policy.base import DELTA_POLICY_TYPEfrom congress.policy.base import EventQueuefrom congress.policy.base import Theoryfrom congress.policy.builtin.congressbuiltin import builtin_registryfrom congress.policy.ruleset import RuleSet from congress.policy.topdown import TopDownTheory# Logical Building Blocks ############################################################################## class Proof(object): """"""A single proof. Differs semantically from Database's Proof in that this verison represents a proof that spans rules, instead of just a proof for a single rule. """""" def __init__(self, root, children): self.root = root self.children = children def __str__(self): return self.str_tree(0) def str_tree(self, depth): s = "" "" * depth s += str(self.root) s += ""\n"" for child in self.children: s += child.str_tree(depth + 1) return s def leaves(self): if len(self.children) == 0: return [self.root] result = [] for child in self.children: result.extend(child.leaves()) return result class DeltaRule(object): """"""Rule describing how updates to data sources change table."""""" def __init__(self, trigger, head, body, original): self.trigger = trigger # atom self.head = head # atom self.body = body # list of literals self.original = original # Rule from which SELF was derived def __str__(self): return ""<trigger: {}, head: {}, body: {}>"".format( str(self.trigger), str(self.head), [str(lit) for lit in self.body]) def __eq__(self, other): return (self.trigger == other.trigger and self.head == other.head and len(self.body) == len(other.body) and all(self.body[i] == other.body[i] for i in xrange(0, len(self.body)))) def variables(self): """"""Return the set of variables occurring in this delta rule."""""" vs = self.trigger.variables() vs |= self.head.variables() for atom in self.body: vs |= atom.variables() return vs def tablenames(self): """"""Return the set of tablenames occurring in this delta rule."""""" tables = set() tables.add(self.head.tablename()) tables.add(self.trigger.tablename()) for atom in self.body: tables.add(atom.tablename()) return tables ############################################################################## # Concrete Theory: Database ############################################################################## class Database(TopDownTheory): class Proof(object): def __init__(self, binding, rule): self.binding = binding self.rule = rule def __str__(self): return ""apply({}, {})"".format(str(self.binding), str(self.rule)) def __eq__(self, other): result = (self.binding == other.binding and self.rule == other.rule) # LOG.debug(""Pf: Comparing %s and %s: %s"", self, other, result) # LOG.debug(""Pf: %s == %s is %s"", # self.binding, other.binding, self.binding == other.binding) # LOG.debug(""Pf: %s == %s is %s"", # self.rule, other.rule, self.rule == other.rule) return result class ProofCollection(object): def __init__(self, proofs): self.contents = list(proofs) def __str__(self): return '{' + "","".join(str(x) for x in self.contents) + '}' def __isub__(self, other): if other is None: return # LOG.debug(""PC: Subtracting %s and %s"", self, other) remaining = [] for proof in self.contents: if proof not in other.contents: remaining.append(proof) self.contents = remaining return self def __ior__(self, other): if other is None: return # LOG.debug(""PC: Unioning %s and %s"", self, other) for proof in other.contents: # LOG.debug(""PC: Considering %s"", proof) if proof not in self.contents: self.contents.append(proof) return self def __getitem__(self, key): return self.contents[key] def __len__(self): return len(self.contents) def __ge__(self, iterable): for proof in iterable: if proof not in self.contents: # LOG.debug(""Proof %s makes %s not >= %s"", # proof, self, iterstr(iterable)) return False return True def __le__(self, iterable): for proof in self.contents: if proof not in iterable: # LOG.debug(""Proof %s makes %s not <= %s"", # proof, self, iterstr(iterable)) return False return True def __eq__(self, other): return self <= other and other <= self class DBTuple(object): def __init__(self, iterable, proofs=None): self.tuple = tuple(iterable) if proofs is None: proofs = [] self.proofs = Database.ProofCollection(proofs) def __eq__(self, other): return self.tuple == other.tuple def __str__(self): return str(self.tuple) + str(self.proofs) def __len__(self): return len(self.tuple) def __getitem__(self, index): return self.tuple[index] def __setitem__(self, index, value): self.tuple[index] = value def match(self, atom, unifier): # LOG.debug(""DBTuple matching %s against atom %s in %s"", # self, iterstr(atom.arguments), unifier) if len(self.tuple) != len(atom.arguments): return None changes = [] for i in xrange(0, len(atom.arguments)): val, binding = unifier.apply_full(atom.arguments[i]) # LOG.debug(""val(%s)=%s at %s; comparing to object %s"", # atom.arguments[i], val, binding, self.tuple[i]) if val.is_variable(): changes.append(binding.add( val, compile.Term.create_from_python(self.tuple[i]), None)) else: if val.name != self.tuple[i]: unify.undo_all(changes) return None return changes def __init__(self, name=None, abbr=None, theories=None, schema=None): super(Database, self).__init__( name=name, abbr=abbr, theories=theories, schema=schema) self.data = {} self.kind = DATABASE_POLICY_TYPE def str2(self): def hash2str(h): s = ""{"" s += "", "".join([""{} : {}"".format(str(key), str(h[key])) for key in h]) return s def hashlist2str(h): strings = [] for key in h: s = ""{} : "".format(key) s += '[' s += ', '.join([str(val) for val in h[key]]) s += ']' strings.append(s) return '{' + "", "".join(strings) + '}' return hashlist2str(self.data) def __eq__(self, other): return self.data == other.data def __sub__(self, other): def add_tuple(table, dbtuple): new = [table] new.extend(dbtuple.tuple) results.append(new) results = [] for table in self.data: if table not in other.data: for dbtuple in self.data[table]: add_tuple(table, dbtuple) else: for dbtuple in self.data[table]: if dbtuple not in other.data[table]: add_tuple(table, dbtuple) return results def __or__(self, other): def add_db(db): for table in db.data: for dbtuple in db.data[table]: result.insert(compile.Literal.create_from_table_tuple( table, dbtuple.tuple), proofs=dbtuple.proofs) result = Database() add_db(self) add_db(other) return result def __getitem__(self, key): # KEY must be a tablename return self.data[key] def content(self, tablenames=None): """"""Return a sequence of Literals representing all the table data."""""" results = [] if tablenames is None: tablenames = self.data.keys() for table in tablenames: if table not in self.data: continue for dbtuple in self.data[table]: results.append(compile.Literal.create_from_table_tuple( table, dbtuple.tuple)) return results def is_noop(self, event): """"""Returns T if EVENT is a noop on the database."""""" # insert/delete same code but with flipped return values # Code below is written as insert, except noop initialization. if event.is_insert(): noop = True else: noop = False if event.formula.table not in self.data: return not noop event_data = self.data[event.formula.table] raw_tuple = tuple(event.formula.argument_names()) for dbtuple in event_data: if dbtuple.tuple == raw_tuple: if event.proofs <= dbtuple.proofs: return noop return not noop def explain(self, atom): if atom.table not in self.data or not atom.is_ground(): return self.ProofCollection([]) args = tuple([x.name for x in atom.arguments]) for dbtuple in self.data[atom.table]: if dbtuple.tuple == args: return dbtuple.proofs def tablenames(self): """"""Return all table names occurring in this theory."""""" return self.data.keys() # overloads for TopDownTheory so we can properly use the # top_down_evaluation routines def defined_tablenames(self): return self.data.keys() def head_index(self, table, match_literal=None): if table not in self.data: return [] return self.data[table] def head(self, thing): return thing def body(self, thing): return [] def bi_unify(self, dbtuple, unifier1, atom, unifier2): """"""THING1 is always a ground DBTuple and THING2 is always an ATOM."""""" return dbtuple.match(atom, unifier2) def atom_to_internal(self, atom, proofs=None): return atom.table, self.DBTuple(atom.argument_names(), proofs) def insert(self, atom, proofs=None): """"""Inserts ATOM into the DB. Returns changes."""""" return self.modify(Event(formula=atom, insert=True, proofs=proofs)) def delete(self, atom, proofs=None): """"""Deletes ATOM from the DB. Returns changes."""""" return self.modify(Event(formula=atom, insert=False, proofs=proofs)) def update(self, events): """"""Applies all of EVENTS to the DB. Each event is either an insert or a delete. """""" changes = [] for event in events: changes.extend(self.modify(event)) return changes def update_would_cause_errors(self, events): """"""Return a list of compile.CongressException. Return a list of compile.CongressException if we were to apply the events EVENTS to the current policy. """""" self.log(None, ""update_would_cause_errors %s"", iterstr(events)) errors = [] for event in events: if not compile.is_atom(event.formula): errors.append(compile.CongressException( ""Non-atomic formula is not permitted: {}"".format( str(event.formula)))) else: errors.extend(compile.fact_errors( event.formula, self.theories, self.name)) return errors def modify(self, event): """"""Insert/Delete atom. Inserts/deletes ATOM and returns a list of changes that were caused. That list contains either 0 or 1 Event. """""" assert compile.is_atom(event.formula), ""Modify requires Atom"" atom = event.formula self.log(atom.table, ""Modify: %s"", atom) if self.is_noop(event): self.log(atom.table, ""Event %s is a noop"", event) return [] if event.insert: self.insert_actual(atom, proofs=event.proofs) else: self.delete_actual(atom, proofs=event.proofs) return [event] def insert_actual(self, atom, proofs=None): """"""Workhorse for inserting ATOM into the DB. Along with proofs explaining how ATOM was computed from other tables. """""" assert compile.is_atom(atom), ""Insert requires Atom"" table, dbtuple = self.atom_to_internal(atom, proofs) self.log(table, ""Insert: %s"", atom) if table not in self.data: self.data[table] = [dbtuple] self.log(atom.table, ""First tuple in table %s"", table) return else: for existingtuple in self.data[table]: assert existingtuple.proofs is not None if existingtuple.tuple == dbtuple.tuple: assert existingtuple.proofs is not None existingtuple.proofs |= dbtuple.proofs assert existingtuple.proofs is not None return self.data[table].append(dbtuple) def delete_actual(self, atom, proofs=None): """"""Workhorse for deleting ATOM from the DB. Along with the proofs that are no longer true. """""" assert compile.is_atom(atom), ""Delete requires Atom"" self.log(atom.table, ""Delete: %s"", atom) table, dbtuple = self.atom_to_internal(atom, proofs) if table not in self.data: return for i in xrange(0, len(self.data[table])): existingtuple = self.data[table][i] if existingtuple.tuple == dbtuple.tuple: existingtuple.proofs -= dbtuple.proofs if len(existingtuple.proofs) == 0: del self.data[table][i] return def policy(self): """"""Return the policy for this theory. No policy in this theory; only data. """""" return [] def update_dependency_graph(self): self.dependency_graph = compile.cross_theory_dependency_graph([]) def get_arity_self(self, tablename): if tablename not in self.data: return None if len(self.data[tablename]) == 0: return None return len(self.data[tablename][0].tuple) def __str__(self): s = """" for lit in self.content(): s += str(lit) + '\n' return s + '\n' ############################################################################## # Concrete Theories: other ############################################################################## class DeltaRuleTheory (Theory): """"""A collection of DeltaRules. Not useful by itself as a policy."""""" def __init__(self, name=None, abbr=None, theories=None): super(DeltaRuleTheory, self).__init__( name=name, abbr=abbr, theories=theories) # dictionary from table name to list of rules with that table as # trigger self.rules = RuleSet() # dictionary from delta_rule to the rule from which it was derived self.originals = set() # dictionary from table name to number of rules with that table in # head self.views = {} # all tables self.all_tables = {} self.kind = DELTA_POLICY_TYPE def modify(self, event): """"""Insert/delete the compile.Rule RULE into the theory. Return list of changes (either the empty list or a list including just RULE). """""" self.log(None, ""DeltaRuleTheory.modify %s"", event.formula) self.log(None, ""originals: %s"", iterstr(self.originals)) if event.insert: if self.insert(event.formula): return [event] else: if self.delete(event.formula): return [event] return [] def insert(self, rule): """"""Insert a compile.Rule into the theory. Return True iff the theory changed. """""" assert compile.is_regular_rule(rule), ( ""DeltaRuleTheory only takes rules"") self.log(rule.tablename(), ""Insert: %s"", rule) if rule in self.originals: self.log(None, iterstr(self.originals)) return False self.log(rule.tablename(), ""Insert 2: %s"", rule) for delta in self.compute_delta_rules([rule]): self.insert_delta(delta) self.originals.add(rule) return True def insert_delta(self, delta): """"""Insert a delta rule."""""" self.log(None, ""Inserting delta rule %s"", delta) # views (tables occurring in head) if delta.head.table in self.views: self.views[delta.head.table] += 1 else: self.views[delta.head.table] = 1 # tables for table in delta.tablenames(): if table in self.all_tables: self.all_tables[table] += 1 else: self.all_tables[table] = 1 # contents # TODO(thinrichs): eliminate dups, maybe including # case where bodies are reorderings of each other self.rules.add_rule(delta.trigger.table, delta) def delete(self, rule): """"""Delete a compile.Rule from theory. Assumes that COMPUTE_DELTA_RULES is deterministic. Returns True iff the theory changed. """""" self.log(rule.tablename(), ""Delete: %s"", rule) if rule not in self.originals: return False for delta in self.compute_delta_rules([rule]): self.delete_delta(delta) self.originals.remove(rule) return True def delete_delta(self, delta): """"""Delete the DeltaRule DELTA from the theory."""""" # views if delta.head.table in self.views: self.views[delta.head.table] -= 1 if self.views[delta.head.table] == 0: del self.views[delta.head.table] # tables for table in delta.tablenames(): if table in self.all_tables: self.all_tables[table] -= 1 if self.all_tables[table] == 0: del self.all_tables[table] # contents self.rules.discard_rule(delta.trigger.table, delta) def policy(self): return self.originals def get_arity_self(self, tablename): for p in self.originals: if p.head.table == tablename: return len(p.head.arguments) return None def __str__(self): return str(self.rules) def rules_with_trigger(self, table): """"""Return the list of DeltaRules that trigger on the given TABLE."""""" if table in self.rules: return self.rules.get_rules(table) else: return [] def is_view(self, x): return x in self.views def is_known(self, x): return x in self.all_tables def base_tables(self): base = [] for table in self.all_tables: if table not in self.views: base.append(table) return base @classmethod def eliminate_self_joins(cls, formulas): """"""Remove self joins. Return new list of formulas that is equivalent to the list of formulas FORMULAS except that there are no self-joins. """""" def new_table_name(name, arity, index): return ""___{}_{}_{}"".format(name, arity, index) def n_variables(n): vars = [] for i in xrange(0, n): vars.append(""x"" + str(i)) return vars # dict from (table name, arity) tuple to # max num of occurrences of self-joins in any rule global_self_joins = {} # remove self-joins from rules results = [] for rule in formulas: if rule.is_atom(): results.append(rule) continue LOG.debug(""eliminating self joins from %s"", rule) occurrences = {} # for just this rule for atom in rule.body: table = atom.tablename() arity = len(atom.arguments) tablearity = (table, arity) if tablearity not in occurrences: occurrences[tablearity] = 1 else: # change name of atom atom.table = new_table_name(table, arity, occurrences[tablearity]) # update our counters occurrences[tablearity] += 1 if tablearity not in global_self_joins: global_self_joins[tablearity] = 1 else: global_self_joins[tablearity] = ( max(occurrences[tablearity] - 1, global_self_joins[tablearity])) results.append(rule) LOG.debug(""final rule: %s"", rule) # add definitions for new tables for tablearity in global_self_joins: table = tablearity[0] arity = tablearity[1] for i in xrange(1, global_self_joins[tablearity] + 1): newtable = new_table_name(table, arity, i) args = [compile.Variable(var) for var in n_variables(arity)] head = compile.Literal(newtable, args) body = [compile.Literal(table, args)] results.append(compile.Rule(head, body)) LOG.debug(""Adding rule %s"", results[-1]) return results @classmethod def compute_delta_rules(cls, formulas): """"""Return list of DeltaRules computed from formulas. Assuming FORMULAS has no self-joins, return a list of DeltaRules derived from those FORMULAS. """""" # Should do the following for correctness, but it needs to be # done elsewhere so that we can properly maintain the tables # that are generated. # formulas = cls.eliminate_self_joins(formulas) delta_rules = [] for rule in formulas: if rule.is_atom(): continue rule = compile.reorder_for_safety(rule) for literal in rule.body: if builtin_registry.is_builtin(literal.table, len(literal.arguments)): continue newbody = [lit for lit in rule.body if lit is not literal] delta_rules.append( DeltaRule(literal, rule.head, newbody, rule)) return delta_rules class MaterializedViewTheory(TopDownTheory): """"""A theory that stores the table contents of views explicitly. Relies on included theories to define the contents of those tables not defined by the rules of the theory. Recursive rules are allowed. """""" def __init__(self, name=None, abbr=None, theories=None, schema=None): super(MaterializedViewTheory, self).__init__( name=name, abbr=abbr, theories=theories, schema=schema) # queue of events left to process self.queue = EventQueue() # data storage db_name = None db_abbr = None delta_name = None delta_abbr = None if name is not None: db_name = name + ""Database"" delta_name = name + ""Delta"" if abbr is not None: db_abbr = abbr + ""DB"" delta_abbr = abbr + ""Dlta"" self.database = Database(name=db_name, abbr=db_abbr) # rules that dictate how database changes in response to events self.delta_rules = DeltaRuleTheory(name=delta_name, abbr=delta_abbr) self.update_dependency_graph() self.kind = MATERIALIZED_POLICY_TYPE def set_tracer(self, tracer): if isinstance(tracer, Tracer): self.tracer = tracer self.database.tracer = tracer self.delta_rules.tracer = tracer else: self.tracer = tracer['self'] self.database.tracer = tracer['database'] self.delta_rules.tracer = tracer['delta_rules'] def get_tracer(self): return {'self': self.tracer, 'database': self.database.tracer, 'delta_rules': self.delta_rules.tracer} # External Interface # SELECT is handled by TopDownTheory def insert(self, formula): return self.update([Event(formula=formula, insert=True)]) def delete(self, formula): return self.update([Event(formula=formula, insert=False)]) def update(self, events): """"""Apply inserts/deletes described by EVENTS and return changes. Does not check if EVENTS would cause errors. """""" for event in events: assert compile.is_datalog(event.formula), ( ""Non-formula not allowed: {}"".format(str(event.formula))) self.enqueue_any(event) changes = self.process_queue() if changes: self.update_dependency_graph() return changes def update_would_cause_errors(self, events): """"""Return a list of compile.CongressException. Return a list of compile.CongressException if we were to apply the events EVENTS to the current policy. """""" self.log(None, ""update_would_cause_errors %s"", iterstr(events)) errors = [] current = set(self.policy()) # copy so can modify and discard # compute new rule set for event in events: assert compile.is_datalog(event.formula), ( ""update_would_cause_errors operates only on objects"") self.log(None, ""Updating %s"", event.formula) if event.formula.is_atom(): errors.extend(compile.fact_errors( event.formula, self.theories, self.name)) else: errors.extend(compile.rule_errors( event.formula, self.theories, self.name)) if event.insert: current.add(event.formula) elif event.formula in current: current.remove(event.formula) # check for stratified # TODO(thinrichs): include path in error message if not compile.is_stratified(current): errors.append(compile.CongressException( ""Rules are not stratified"")) if self._causes_recursion_across_theories(current): errors.append(compile.CongressException( ""Rules are recursive across theories"")) return errors def explain(self, query, tablenames, find_all): """"""Returns a list of proofs if QUERY is true or None if else."""""" assert compile.is_atom(query), ""Explain requires an atom"" # ignoring TABLENAMES and FIND_ALL # except that we return the proper type. proof = self.explain_aux(query, 0) if proof is None: return None else: return [proof] def policy(self): return self.delta_rules.policy() def get_arity_self(self, tablename): result = self.database.get_arity_self(tablename) if result: return result return self.delta_rules.get_arity_self(tablename) # Interface implementation def explain_aux(self, query, depth): self.log(query.table, ""Explaining %s"", query, depth=depth) # Bail out on negated literals. Need different # algorithm b/c we need to introduce quantifiers. if query.is_negated(): return Proof(query, []) # grab first local proof, since they're all equally good localproofs = self.database.explain(query) if localproofs is None: return None if len(localproofs) == 0: # base fact return Proof(query, []) localproof = localproofs[0] rule_instance = localproof.rule.plug(localproof.binding) subproofs = [] for lit in rule_instance.body: subproof = self.explain_aux(lit, depth + 1) if subproof is None: return None subproofs.append(subproof) return Proof(query, subproofs) def modify(self, event): """"""Modifies contents of theory to insert/delete FORMULA. Returns True iff the theory changed. """""" self.log(None, ""Materialized.modify"") self.enqueue_any(event) changes = self.process_queue() self.log(event.formula.tablename(), ""modify returns %s"", iterstr(changes)) return changes def enqueue_any(self, event): """"""Enqueue event. Processing rules is a bit different than processing atoms in that they generate additional events that we want to process either before the rule is deleted or after it is inserted. PROCESS_QUEUE is similar but assumes that only the data will cause propagations (and ignores included theories). """""" # Note: all included theories must define MODIFY formula = event.formula if formula.is_atom(): self.log(formula.tablename(), ""compute/enq: atom %s"", formula) assert not self.is_view(formula.table), ( ""Cannot directly modify tables"" + "" computed from other tables"") # self.log(formula.table, ""%s: %s"", text, formula) self.enqueue(event) return [] else: # rules do not need to talk to included theories because they # only generate events for views # need to eliminate self-joins here so that we fill all # the tables introduced by self-join elimination. for rule in DeltaRuleTheory.eliminate_self_joins([formula]): new_event = Event(formula=rule, insert=event.insert, target=event.target) self.enqueue(new_event) return [] def enqueue(self, event): self.log(event.tablename(), ""Enqueueing: %s"", event) self.queue.enqueue(event) def process_queue(self): """"""Data and rule propagation routine. Returns list of events that were not noops """""" self.log(None, ""Processing queue"") history = [] while len(self.queue) > 0: event = self.queue.dequeue() self.log(event.tablename(), ""Dequeued %s"", event) if compile.is_regular_rule(event.formula): changes = self.delta_rules.modify(event) if len(changes) > 0: history.extend(changes) bindings = self.top_down_evaluation( event.formula.variables(), event.formula.body) self.log(event.formula.tablename(), ""new bindings after top-down: %s"", iterstr(bindings)) self.process_new_bindings(bindings, event.formula.head, event.insert, event.formula) else: self.propagate(event) history.extend(self.database.modify(event)) self.log(event.tablename(), ""History: %s"", iterstr(history)) return history def propagate(self, event): """"""Propagate event. Computes and enqueue events generated by EVENT and the DELTA_RULES. """""" self.log(event.formula.table, ""Processing event: %s"", event) applicable_rules = self.delta_rules.rules_with_trigger( event.formula.table) if len(applicable_rules) == 0: self.log(event.formula.table, ""No applicable delta rule"") for delta_rule in applicable_rules: self.propagate_rule(event, delta_rule) def propagate_rule(self, event, delta_rule): """"""Propagate event and delta_rule. Compute and enqueue new events generated by EVENT and DELTA_RULE. """""" self.log(event.formula.table, ""Processing event %s with rule %s"", event, delta_rule) # compute tuples generated by event (either for insert or delete) # print ""event: {}, event.tuple: {}, # event.tuple.rawtuple(): {}"".format( # str(event), str(event.tuple), str(event.tuple.raw_tuple())) # binding_list is dictionary # Save binding for delta_rule.trigger; throw away binding for event # since event is ground. binding = self.new_bi_unifier() assert compile.is_literal(delta_rule.trigger) assert compile.is_literal(event.formula) undo = self.bi_unify(delta_rule.trigger, binding, event.formula, self.new_bi_unifier()) if undo is None: return self.log(event.formula.table, ""binding list for event and delta-rule trigger: %s"", binding) bindings = self.top_down_evaluation( delta_rule.variables(), delta_rule.body, binding) self.log(event.formula.table, ""new bindings after top-down: %s"", "","".join([str(x) for x in bindings])) if delta_rule.trigger.is_negated(): insert_delete = not event.insert else: insert_delete = event.insert self.process_new_bindings(bindings, delta_rule.head, insert_delete, delta_rule.original) def process_new_bindings(self, bindings, atom, insert, original_rule): """"""Process new bindings. For each of BINDINGS, apply to ATOM, and enqueue it as an insert if INSERT is True and as a delete otherwise. """""" # for each binding, compute generated tuple and group bindings # by the tuple they generated new_atoms = {} for binding in bindings: new_atom = atom.plug(binding) if new_atom not in new_atoms: new_atoms[new_atom] = [] new_atoms[new_atom].append(Database.Proof( binding, original_rule)) self.log(atom.table, ""new tuples generated: %s"", iterstr(new_atoms)) # enqueue each distinct generated tuple, recording appropriate bindings for new_atom in new_atoms: # self.log(event.table, ""new_tuple %s: %s"", new_tuple, # new_tuples[new_tuple]) # Only enqueue if new data. # Putting the check here is necessary to support recursion. self.enqueue(Event(formula=new_atom, proofs=new_atoms[new_atom], insert=insert)) def is_view(self, x): """"""Return True if the table X is defined by the theory."""""" return self.delta_rules.is_view(x) def is_known(self, x): """"""Return True if this theory has any rule mentioning table X."""""" return self.delta_rules.is_known(x) def base_tables(self): """"""Get base tables. Return the list of tables that are mentioned in the rules but for which there are no rules with those tables in the head. """""" return self.delta_rules.base_tables() def top_down_th(self, context, caller): return self.database.top_down_th(context, caller) def content(self, tablenames=None): return self.database.content(tablenames=tablenames) def update_dependency_graph(self): self.dependency_graph = compile.cross_theory_dependency_graph( self.policy(), theory=self.name) ##############################################################################",1042,995
openstack%2Fpuppet-neutron~master~I6ce3e31f048dfc47cd39bbbbea9de0934f015ba4,openstack/puppet-neutron,master,I6ce3e31f048dfc47cd39bbbbea9de0934f015ba4,Subscribe neutron db sync to db connection setting,MERGED,2015-01-10 01:07:13.000000000,2015-01-12 23:28:23.000000000,2015-01-12 23:28:22.000000000,"[{'_account_id': 3}, {'_account_id': 6994}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-01-10 01:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/34a3d71dfe680b3ab2a9c59e8700ac033368e6e5', 'message': 'Subscribe neutron db sync to db connection setting\n\nCurrently, neutron db sync is requires the db connection to\nbe set, but is only triggered by changes in the neutron package.\nSince the neutron package, containing the neutron-server binary\nis a dependency of other neutron services, this means that if\nany other neutron service is installed before neutron-server, the\ndb will not be synced.\n\nThis patch modifies the exec resource to subscribe to the db connection\nstring, handling both the above case and also the case where the\ndb connection string is changed to point to a new database for\nwhatever reason and must be re-synced.\n\nChange-Id: I6ce3e31f048dfc47cd39bbbbea9de0934f015ba4\n'}, {'number': 2, 'created': '2015-01-10 04:15:05.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/12991b23758ffc5d2caf91a5f82c5f3e70b890f7', 'message': 'Subscribe neutron db sync to db connection setting\n\nCurrently, neutron db sync is requires the db connection to\nbe set, but is only triggered by changes in the neutron package.\nSince the neutron package, containing the neutron-server binary\nis a dependency of other neutron services, this means that if\nany other neutron service is installed before neutron-server, the\ndb will not be synced.\n\nThis patch modifies the exec resource to subscribe to the db connection\nstring, handling both the above case and also the case where the\ndb connection string is changed to point to a new database for\nwhatever reason and must be re-synced.\n\nChange-Id: I6ce3e31f048dfc47cd39bbbbea9de0934f015ba4\n'}]",0,146243,12991b23758ffc5d2caf91a5f82c5f3e70b890f7,14,5,2,6994,,,0,"Subscribe neutron db sync to db connection setting

Currently, neutron db sync is requires the db connection to
be set, but is only triggered by changes in the neutron package.
Since the neutron package, containing the neutron-server binary
is a dependency of other neutron services, this means that if
any other neutron service is installed before neutron-server, the
db will not be synced.

This patch modifies the exec resource to subscribe to the db connection
string, handling both the above case and also the case where the
db connection string is changed to point to a new database for
whatever reason and must be re-synced.

Change-Id: I6ce3e31f048dfc47cd39bbbbea9de0934f015ba4
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/43/146243/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/server.pp'],1,34a3d71dfe680b3ab2a9c59e8700ac033368e6e5,," subscribe => Neutron_config['database/connection'],"," require => Neutron_config['database/connection'],",2,1
openstack%2Fpuppet-cinder~master~Id70709c9f35983650de992be1903cc4b133b47e7,openstack/puppet-cinder,master,Id70709c9f35983650de992be1903cc4b133b47e7,Don't configure admin URI using fragments,MERGED,2015-01-06 20:50:30.000000000,2015-01-12 23:27:15.000000000,2015-01-12 23:27:15.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7191}, {'_account_id': 8482}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-01-06 20:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/3afe35f55024102ec278237f315ce0f0352d0cbf', 'message': ""Don't configure admin URI using fragments\n\nAdmin URI using fragments is deprecated since the 0.8 release of\nKeystone Client (april, 2014). Instead, we build a simple identity_uri\nand use it. Fields left as-is for backwards compatibility.\n\nThis eliminates the following deprecation warning:\nWARNING keystoneclient.middleware.auth_token [-] Configuring admin URI\nusing auth fragments. This is deprecated, use 'identity_uri' instead.\n\nhttp://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware/\n\nChange-Id: Id70709c9f35983650de992be1903cc4b133b47e7\n""}, {'number': 2, 'created': '2015-01-08 21:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/3705e7745c89810b432a770a0ffff41d9d56ad93', 'message': ""Don't configure admin URI using fragments\n\nAdmin URI using fragments is deprecated since the 0.8 release of\nKeystone Client (april, 2014). Instead, we build a simple identity_uri\nand use it. Fields left as-is for backwards compatibility.\n\nThis eliminates the following deprecation warning:\nWARNING keystoneclient.middleware.auth_token [-] Configuring admin URI\nusing auth fragments. This is deprecated, use 'identity_uri' instead.\n\nhttp://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware/\n\nChange-Id: Id70709c9f35983650de992be1903cc4b133b47e7\n""}, {'number': 3, 'created': '2015-01-08 21:29:45.000000000', 'files': ['manifests/api.pp', 'spec/classes/cinder_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/dca0f367f2ddd4d575843456b07454db3aeeb3ee', 'message': ""Don't configure admin URI using fragments\n\nAdmin URI using fragments is deprecated since the 0.8 release of\nKeystone Client (april, 2014). Instead, we build a simple identity_uri\nand use it. Fields left as-is for backwards compatibility.\n\nThis eliminates the following deprecation warning:\nWARNING keystoneclient.middleware.auth_token [-] Configuring admin URI\nusing auth fragments. This is deprecated, use 'identity_uri' instead.\n\nhttp://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware/\n\nChange-Id: Id70709c9f35983650de992be1903cc4b133b47e7\n""}]",2,145333,dca0f367f2ddd4d575843456b07454db3aeeb3ee,17,6,3,9500,,,0,"Don't configure admin URI using fragments

Admin URI using fragments is deprecated since the 0.8 release of
Keystone Client (april, 2014). Instead, we build a simple identity_uri
and use it. Fields left as-is for backwards compatibility.

This eliminates the following deprecation warning:
WARNING keystoneclient.middleware.auth_token [-] Configuring admin URI
using auth fragments. This is deprecated, use 'identity_uri' instead.

http://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware/

Change-Id: Id70709c9f35983650de992be1903cc4b133b47e7
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/33/145333/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/cinder_api_spec.rb']",2,3afe35f55024102ec278237f315ce0f0352d0cbf,fix_deprecations, should contain_cinder_api_paste_ini('filter:authtoken/identity_uri').with( :value => 'http://localhost:35357', should contain_cinder_api_paste_ini('filter:authtoken/auth_protocol').with( :value => 'http' ) should contain_cinder_api_paste_ini('filter:authtoken/auth_host').with( :value => 'localhost' ) should contain_cinder_api_paste_ini('filter:authtoken/auth_port').with( :value => '35357',3,11
openstack%2Fpuppet-keystone~master~I5fa41f33de88af4ad7128f1c4b04aef1c994c445,openstack/puppet-keystone,master,I5fa41f33de88af4ad7128f1c4b04aef1c994c445,Fix deprecated LDAP config options,MERGED,2015-01-12 15:49:42.000000000,2015-01-12 23:26:52.000000000,2015-01-12 23:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}]","[{'number': 1, 'created': '2015-01-12 15:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/96ae4106afa62ee052b46516dbac4a6c1005830f', 'message': 'Fix deprecated LDAP config options\n\nIn Juno, the tenant_* LDAP related options are deprecated in favor of\nproject_*. See Table 7.38 here:\nhttp://docs.openstack.org/trunk/config-reference/content/keystone-conf-changes-juno.html\n\nChange-Id: I5fa41f33de88af4ad7128f1c4b04aef1c994c445\n'}, {'number': 2, 'created': '2015-01-12 15:51:20.000000000', 'files': ['spec/classes/keystone_ldap_spec.rb', 'examples/ldap_full.pp', 'manifests/ldap.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c50800f352a62a7ee07a64a566af1d77af6744b1', 'message': 'Fix deprecated LDAP config options\n\nIn Juno, the tenant_* LDAP related options are deprecated in favor of\nproject_*. See Table 7.38 here:\nhttp://docs.openstack.org/trunk/config-reference/content/keystone-conf-changes-juno.html\n\ncherry-picked from f8e3ed7fdd155383ab2fe461349aaa9095ed80a2\n\nChange-Id: I5fa41f33de88af4ad7128f1c4b04aef1c994c445'}]",0,146504,c50800f352a62a7ee07a64a566af1d77af6744b1,8,3,2,9500,,,0,"Fix deprecated LDAP config options

In Juno, the tenant_* LDAP related options are deprecated in favor of
project_*. See Table 7.38 here:
http://docs.openstack.org/trunk/config-reference/content/keystone-conf-changes-juno.html

cherry-picked from f8e3ed7fdd155383ab2fe461349aaa9095ed80a2

Change-Id: I5fa41f33de88af4ad7128f1c4b04aef1c994c445",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/04/146504/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_ldap_spec.rb', 'examples/ldap_full.pp', 'manifests/ldap.pp']",3,96ae4106afa62ee052b46516dbac4a6c1005830f,stable/juno," $tenant_tree_dn = undef, #DEPRECATED $project_tree_dn = undef, $tenant_filter = undef, #DEPRECATED $project_filter = undef, $tenant_objectclass = undef, #DEPRECATED $project_objectclass = undef, $tenant_id_attribute = undef, #DEPRECATED $project_id_attribute = undef, $tenant_member_attribute = undef, #DEPRECATED $project_member_attribute = undef, $tenant_desc_attribute = undef, #DEPRECATED $project_desc_attribute = undef, $tenant_name_attribute = undef, #DEPRECATED $project_name_attribute = undef, $tenant_enabled_attribute = undef, #DEPRECATED $project_enabled_attribute = undef, $tenant_domain_id_attribute = undef, #DEPRECATED $project_domain_id_attribute = undef, $tenant_attribute_ignore = undef, #DEPRECATED $project_attribute_ignore = undef, $tenant_allow_create = undef, #DEPRECATED $project_allow_create = undef, $tenant_allow_update = undef, #DEPRECATED $project_allow_update = undef, $tenant_allow_delete = undef, #DEPRECATED $project_allow_delete = undef, $tenant_enabled_emulation = undef, #DEPRECATED $project_enabled_emulation = undef, $tenant_enabled_emulation_dn = undef, #DEPRECATED $project_enabled_emulation_dn = undef, $tenant_additional_attribute_mapping = undef, #DEPRECATED $project_additional_attribute_mapping= undef, # In Juno the term ""tenant"" was deprecated in the config in favor of ""project"" # Let's assume project_ is being used and warning otherwise. If both are set we will # fail, because having both set may cause unexpected results in Keystone. if ($tenant_tree_dn) { $project_tree_dn_real = $tenant_tree_dn warning ('tenant_tree_dn is deprecated in Juno. switch to project_tree_dn') if ($project_tree_dn) { fail ('tenant_tree_dn and project_tree_dn are both set. results may be unexpected') } } else { $project_tree_dn_real = $project_tree_dn } if ($tenant_filter) { $project_filter_real = $tenant_filter warning ('tenant_filter is deprecated in Juno. switch to project_filter') if ($project_filter) { fail ('tenant_filter and project_filter are both set. results may be unexpected') } } else { $project_filter_real = $project_filter } if ($tenant_objectclass) { $project_objectclass_real = $tenant_objectclass warning ('tenant_objectclass is deprecated in Juno. switch to project_objectclass') if ($project_objectclass) { fail ('tenant_objectclass and project_objectclass are both set. results may be unexpected') } } else { $project_objectclass_real = $project_objectclass } if ($tenant_id_attribute) { $project_id_attribute_real = $tenant_id_attribute warning ('tenant_id_attribute is deprecated in Juno. switch to project_id_attribute') if ($project_id_attribute) { fail ('tenant_id_attribute and project_id_attribute are both set. results may be unexpected') } } else { $project_id_attribute_real = $project_id_attribute } if ($tenant_member_attribute) { $project_member_attribute_real = $tenant_member_attribute warning ('tenant_member_attribute is deprecated in Juno. switch to project_member_attribute') if ($project_member_attribute) { fail ('tenant_member_attribute and project_member_attribute are both set. results may be unexpected') } } else { $project_member_attribute_real = $project_member_attribute } if ($tenant_desc_attribute) { $project_desc_attribute_real = $tenant_desc_attribute warning ('tenant_desc_attribute is deprecated in Juno. switch to project_desc_attribute') if ($project_desc_attribute) { fail ('tenant_desc_attribute and project_desc_attribute are both set. results may be unexpected') } } else { $project_desc_attribute_real = $project_desc_attribute } if ($tenant_name_attribute) { $project_name_attribute_real = $tenant_name_attribute warning ('tenant_name_attribute is deprecated in Juno. switch to project_name_attribute') if ($project_name_attribute) { fail ('tenant_name_attribute and project_name_attribute are both set. results may be unexpected') } } else { $project_name_attribute_real = $project_name_attribute } if ($tenant_enabled_attribute) { $project_enabled_attribute_real = $tenant_enabled_attribute warning ('tenant_enabled_attribute is deprecated in Juno. switch to project_enabled_attribute') if ($project_enabled_attribute) { fail ('tenant_enabled_attribute and project_enabled_attribute are both set. results may be unexpected') } } else { $project_enabled_attribute_real = $project_enabled_attribute } if ($tenant_attribute_ignore) { $project_attribute_ignore_real = $tenant_attribute_ignore warning ('tenant_attribute_ignore is deprecated in Juno. switch to project_attribute_ignore') if ($project_attribute_ignore) { fail ('tenant_attribute_ignore and project_attribute_ignore are both set. results may be unexpected') } } else { $project_attribute_ignore_real = $project_attribute_ignore } if ($tenant_domain_id_attribute) { $project_domain_id_attribute_real = $tenant_domain_id_attribute warning ('tenant_domain_id_attribute is deprecated in Juno. switch to project_domain_id_attribute') if ($project_domain_id_attribute) { fail ('tenant_domain_id_attribute and project_domain_id_attribute are both set. results may be unexpected') } } else { $project_domain_id_attribute_real = $project_domain_id_attribute } if ($tenant_allow_create) { $project_allow_create_real = $tenant_allow_create warning ('tenant_allow_create is deprecated in Juno. switch to project_allow_create') if ($project_allow_create) { fail ('tenant_allow_create and project_allow_create are both set. results may be unexpected') } } else { $project_allow_create_real = $project_allow_create } if ($tenant_allow_update) { $project_allow_update_real = $tenant_allow_update warning ('tenant_allow_update is deprecated in Juno. switch to project_allow_update') if ($project_allow_update) { fail ('tenant_allow_update and project_allow_update are both set. results may be unexpected') } } else { $project_allow_update_real = $project_allow_update } if ($tenant_allow_delete) { $project_allow_delete_real = $tenant_allow_delete warning ('tenant_allow_delete is deprecated in Juno. switch to project_allow_delete') if ($project_allow_delete) { fail ('tenant_allow_delete and project_allow_delete are both set. results may be unexpected') } } else { $project_allow_delete_real = $project_allow_delete } if ($tenant_enabled_emulation) { $project_enabled_emulation_real = $tenant_enabled_emulation warning ('tenant_enabled_emulation is deprecated in Juno. switch to project_enabled_emulation') if ($project_enabled_emulation) { fail ('tenant_enabled_emulation and project_enabled_emulation are both set. results may be unexpected') } } else { $project_enabled_emulation_real = $project_enabled_emulation } if ($tenant_enabled_emulation_dn) { $project_enabled_emulation_dn_real = $tenant_enabled_emulation_dn warning ('tenant_enabled_emulation_dn is deprecated in Juno. switch to project_enabled_emulation_dn') if ($project_enabled_emulation_dn) { fail ('tenant_enabled_emulation_dn and project_enabled_emulation_dn are both set. results may be unexpected') } } else { $project_enabled_emulation_dn_real = $project_enabled_emulation_dn } if ($tenant_additional_attribute_mapping) { $project_additional_attribute_mapping_real = $tenant_additional_attribute_mapping warning ('tenant_additional_attribute_mapping is deprecated in Juno. switch to project_additional_attribute_mapping') if ($project_additional_attribute_mapping) { fail ('tenant_additional_attribute_mapping and project_additional_attribute_mapping are both set. results may be unexpected') } } else { $project_additional_attribute_mapping_real = $project_additional_attribute_mapping } 'ldap/project_tree_dn': value => $project_tree_dn_real; 'ldap/project_filter': value => $project_filter_real; 'ldap/project_objectclass': value => $project_objectclass_real; 'ldap/project_id_attribute': value => $project_id_attribute_real; 'ldap/project_member_attribute': value => $project_member_attribute_real; 'ldap/project_desc_attribute': value => $project_desc_attribute_real; 'ldap/project_name_attribute': value => $project_name_attribute_real; 'ldap/project_enabled_attribute': value => $project_enabled_attribute_real; 'ldap/project_attribute_ignore': value => $project_attribute_ignore_real; 'ldap/project_domain_id_attribute': value => $project_domain_id_attribute_real; 'ldap/project_allow_create': value => $project_allow_create_real; 'ldap/project_allow_update': value => $project_allow_update_real; 'ldap/project_allow_delete': value => $project_allow_delete_real; 'ldap/project_enabled_emulation': value => $project_enabled_emulation_real; 'ldap/project_enabled_emulation_dn': value => $project_enabled_emulation_dn_real; 'ldap/project_additional_attribute_mapping': value => $project_additional_attribute_mapping_real;"," $tenant_tree_dn = undef, $tenant_filter = undef, $tenant_objectclass = undef, $tenant_id_attribute = undef, $tenant_member_attribute = undef, $tenant_desc_attribute = undef, $tenant_name_attribute = undef, $tenant_enabled_attribute = undef, $tenant_domain_id_attribute = undef, $tenant_attribute_ignore = undef, $tenant_allow_create = undef, $tenant_allow_update = undef, $tenant_allow_delete = undef, $tenant_enabled_emulation = undef, $tenant_enabled_emulation_dn = undef, $tenant_additional_attribute_mapping = undef, 'ldap/project_tree_dn': value => $tenant_tree_dn; 'ldap/project_filter': value => $tenant_filter; 'ldap/project_objectclass': value => $tenant_objectclass; 'ldap/project_id_attribute': value => $tenant_id_attribute; 'ldap/project_member_attribute': value => $tenant_member_attribute; 'ldap/project_desc_attribute': value => $tenant_desc_attribute; 'ldap/project_name_attribute': value => $tenant_name_attribute; 'ldap/project_enabled_attribute': value => $tenant_enabled_attribute; 'ldap/project_attribute_ignore': value => $tenant_attribute_ignore; 'ldap/project_domain_id_attribute': value => $tenant_domain_id_attribute; 'ldap/project_allow_create': value => $tenant_allow_create; 'ldap/project_allow_update': value => $tenant_allow_update; 'ldap/project_allow_delete': value => $tenant_allow_delete; 'ldap/project_enabled_emulation': value => $tenant_enabled_emulation; 'ldap/project_enabled_emulation_dn': value => $tenant_enabled_emulation_dn; 'ldap/project_additional_attribute_mapping': value => $tenant_additional_attribute_mapping;",310,61
openstack%2Fcongress~master~I0d5a770ea7ac3119772faec5b08b9d331d7f73ee,openstack/congress,master,I0d5a770ea7ac3119772faec5b08b9d331d7f73ee,Fix tempest test failures,MERGED,2015-01-12 21:03:26.000000000,2015-01-12 23:17:13.000000000,2015-01-12 23:12:05.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2015-01-12 21:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/52637e009ea21b168e135ccbeb51fd78dac88a6b', 'message': 'Fix tempest test failures\n\nThe keystone tests were expecing multiple return values from get_users(),\nlist_tenants(), and list_roles().  The new version returns just one version,\nresulting in a ValueError.\n\nChange-Id: I0d5a770ea7ac3119772faec5b08b9d331d7f73ee\n'}, {'number': 2, 'created': '2015-01-12 22:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bb4b7cee652e6dfa2e12f40ec3a52dbc842a75c0', 'message': 'Fix tempest test failures\n\nThe keystone tests were expecing multiple return values from get_users(),\nlist_tenants(), and list_roles().  The new version returns just one version,\nresulting in a ValueError.\n\nChange-Id: I0d5a770ea7ac3119772faec5b08b9d331d7f73ee\n'}, {'number': 3, 'created': '2015-01-12 22:42:40.000000000', 'files': ['contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/666a973c00c815bf0c760bef92ffe680b4189ff8', 'message': 'Fix tempest test failures\n\nThe keystone tests were expecing multiple return values from get_users(),\nlist_tenants(), and list_roles().  The new version returns just one version,\nresulting in a ValueError.\n\nChange-Id: I0d5a770ea7ac3119772faec5b08b9d331d7f73ee\n'}]",0,146641,666a973c00c815bf0c760bef92ffe680b4189ff8,17,4,3,12875,,,0,"Fix tempest test failures

The keystone tests were expecing multiple return values from get_users(),
list_tenants(), and list_roles().  The new version returns just one version,
resulting in a ValueError.

Change-Id: I0d5a770ea7ac3119772faec5b08b9d331d7f73ee
",git fetch https://review.opendev.org/openstack/congress refs/changes/41/146641/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/tempest/tempest/scenario/congress_datasources/test_keystonev2.py'],1,52637e009ea21b168e135ccbeb51fd78dac88a6b,bug/1404975, users = self.keystone.get_users() roles = self.keystone.list_roles() tenants = self.keystone.list_tenants()," _, users = self.keystone.get_users() _, roles = self.keystone.list_roles() _, tenants = self.keystone.list_tenants()",3,3
openstack%2Fdevstack-gate~master~I1dcb5e41e7fd33a9eab4d54a1a66d4c40f5f74fc,openstack/devstack-gate,master,I1dcb5e41e7fd33a9eab4d54a1a66d4c40f5f74fc,"Revert ""Handle more than one stream stored testrepository""",ABANDONED,2015-01-12 21:59:24.000000000,2015-01-12 22:51:46.000000000,,[],"[{'number': 1, 'created': '2015-01-12 21:59:24.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ca479a6c0086bfdbd9d8dcc881008d3b4a321877', 'message': 'Revert ""Handle more than one stream stored testrepository""\n\nRevert commit that breaks testrepository.subunit.gz and testr_results.html.gz\nhttp://logs.openstack.org/27/143727/2/check/check-tempest-dsvm-full/0ad3107/logs/\n\nThis reverts commit 736d1c987be90fd97ec55f15b6b7560e1f295c29.\n\nChange-Id: I1dcb5e41e7fd33a9eab4d54a1a66d4c40f5f74fc\n'}]",0,146652,ca479a6c0086bfdbd9d8dcc881008d3b4a321877,2,0,1,9624,,,0,"Revert ""Handle more than one stream stored testrepository""

Revert commit that breaks testrepository.subunit.gz and testr_results.html.gz
http://logs.openstack.org/27/143727/2/check/check-tempest-dsvm-full/0ad3107/logs/

This reverts commit 736d1c987be90fd97ec55f15b6b7560e1f295c29.

Change-Id: I1dcb5e41e7fd33a9eab4d54a1a66d4c40f5f74fc
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/52/146652/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,ca479a6c0086bfdbd9d8dcc881008d3b4a321877,fixtestrResults, sudo cp $BASE/new/tempest/.testrepository/0 $BASE/logs/testrepository.subunit sudo cp $BASE/old/tempest/.testrepository/0 $BASE/logs/old/testrepository.subunit, pushd $BASE/new/tempest testr last --subunit > $WORKSPACE/testrepository.subunit popd sudo mv $WORKSPACE/testrepository.subunit $BASE/logs/testrepository.subunit pushd $BASE/old/tempest testr last --subunit > $WORKSPACE/testrepository.subunit popd sudo mv $WORKSPACE/testrepository.subunit $BASE/logs/old/testrepository.subunit,2,8
openstack%2Fpython-manilaclient~master~I1e5f0d1cd57cd2cc35208b1433c1a5f3c97fe9a1,openstack/python-manilaclient,master,I1e5f0d1cd57cd2cc35208b1433c1a5f3c97fe9a1,Sync oslo common cliutils code to fix the prints incompatibility in py3,MERGED,2015-01-12 02:24:37.000000000,2015-01-12 22:48:54.000000000,2015-01-12 22:48:54.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 11878}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-01-12 02:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/304a759289f3baae74d26799ed80e375ac338f79', 'message': 'Sync oslo common cliutil code to resotre  py3 string decoing\n\ncommit dbca53e90d2558339bbddb15948c3451b888c0fa\nMerge: c8d143b 442fc22\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Fri Jan 9 19:08:06 2015 +0000\n\nChange-Id: I1e5f0d1cd57cd2cc35208b1433c1a5f3c97fe9a1\n'}, {'number': 2, 'created': '2015-01-12 07:43:51.000000000', 'files': ['manilaclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/6773889fd6465d020e90d627ee3bbf808fb6e2d3', 'message': 'Sync oslo common cliutils code to fix the prints incompatibility in py3\n\ncommit dbca53e90d2558339bbddb15948c3451b888c0fa\nMerge: c8d143b 442fc22\nAuthor: Jenkins <jenkins@review.openstack.org>\nDate:   Fri Jan 9 19:08:06 2015 +0000\n\nChange-Id: I1e5f0d1cd57cd2cc35208b1433c1a5f3c97fe9a1\n'}]",1,146366,6773889fd6465d020e90d627ee3bbf808fb6e2d3,11,5,2,13634,,,0,"Sync oslo common cliutils code to fix the prints incompatibility in py3

commit dbca53e90d2558339bbddb15948c3451b888c0fa
Merge: c8d143b 442fc22
Author: Jenkins <jenkins@review.openstack.org>
Date:   Fri Jan 9 19:08:06 2015 +0000

Change-Id: I1e5f0d1cd57cd2cc35208b1433c1a5f3c97fe9a1
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/66/146366/1 && git format-patch -1 --stdout FETCH_HEAD,['manilaclient/openstack/common/cliutils.py'],1,304a759289f3baae74d26799ed80e375ac338f79,sync-oslo, if six.PY3: print(encodeutils.safe_encode(pt.get_string(**kwargs)).decode()) else: print(encodeutils.safe_encode(pt.get_string(**kwargs))) if six.PY3: print(encodeutils.safe_encode(pt.get_string()).decode()) else: print(encodeutils.safe_encode(pt.get_string())), print(encodeutils.safe_encode(pt.get_string(**kwargs))) print(encodeutils.safe_encode(pt.get_string())),9,2
openstack%2Ftooz~master~Ie0a134f02617e8552a87c8bcd49996daaba07f4e,openstack/tooz,master,Ie0a134f02617e8552a87c8bcd49996daaba07f4e,Update sentinel support to allow multiple sentinel hosts,MERGED,2015-01-12 13:35:44.000000000,2015-01-12 22:48:00.000000000,2015-01-12 22:48:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-01-12 13:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/ddce7db8c338ec0c2b35b431b7ab5945ebbf9c5c', 'message': ""Update sentinel support to allow multiple sentinel hosts\n\nMultiple sentinel hosts are now allowed by listing the additional\nhosts as multipel 'sentinel_fallback' parameters. These are combined\nwith the first sentinel host to create a list that is provided to\nSentinel class constructor.\n\nThis provides safety in the case when the first (or any other) sentinel\nhost goes down.\n\nChange-Id: Ie0a134f02617e8552a87c8bcd49996daaba07f4e\n""}, {'number': 2, 'created': '2015-01-12 13:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/4f700ae05d4a30d3b438ddae91c19a8e4d55081a', 'message': ""Update sentinel support to allow multiple sentinel hosts\n\nMultiple sentinel hosts are now allowed by listing the additional\nhosts as multiple 'sentinel_fallback' parameters. These are combined\nwith the first sentinel host to create a list that is provided to\nSentinel class constructor.\n\nThis provides safety in the case when the first (or any other) sentinel\nhost goes down.\n\nChange-Id: Ie0a134f02617e8552a87c8bcd49996daaba07f4e\n""}, {'number': 3, 'created': '2015-01-12 14:19:28.000000000', 'files': ['doc/source/drivers.rst', 'setup-sentinel-env.sh', 'tooz/drivers/redis.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/886aa622b0e402d3264bac6c77352312e65b1241', 'message': ""Update sentinel support to allow multiple sentinel hosts\n\nMultiple sentinel hosts are now allowed by listing the additional\nhosts as multiple 'sentinel_fallback' parameters. These are combined\nwith the first sentinel host to create a list that is provided to\nSentinel class constructor.\n\nThis provides safety in the case when the first (or any other) sentinel\nhost goes down.\n\nTests are run twice: once with fallbacks, once without.\n\nChange-Id: Ie0a134f02617e8552a87c8bcd49996daaba07f4e\n""}]",2,146463,886aa622b0e402d3264bac6c77352312e65b1241,12,6,3,11564,,,0,"Update sentinel support to allow multiple sentinel hosts

Multiple sentinel hosts are now allowed by listing the additional
hosts as multiple 'sentinel_fallback' parameters. These are combined
with the first sentinel host to create a list that is provided to
Sentinel class constructor.

This provides safety in the case when the first (or any other) sentinel
host goes down.

Tests are run twice: once with fallbacks, once without.

Change-Id: Ie0a134f02617e8552a87c8bcd49996daaba07f4e
",git fetch https://review.opendev.org/openstack/tooz refs/changes/63/146463/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/drivers.rst', 'setup-sentinel-env.sh', 'tooz/drivers/redis.py']",3,ddce7db8c338ec0c2b35b431b7ab5945ebbf9c5c,cd/multiple-sentinels," Additional sentinel hosts are listed with mutiple ``sentinel_fallback`` parameters as follows: redis://<sentinel host>:<sentinel port>?sentinel=<master name>& sentinel_fallback=<other sentinel host>:<sentinel port>& sentinel_fallback=<other sentinel host>:<sentinel port>& sentinel_fallback=<other sentinel host>:<sentinel port> 'sentinel_fallback', ]) _CLIENT_LIST_ARGS = frozenset([ 'sentinel_fallback', elif a in cls._CLIENT_LIST_ARGS: v = options[a] sentinel_hosts = [tuple(fallback.split(':')) for fallback in kwargs['sentinel_fallback']] sentinel_hosts.insert(0, (kwargs['host'], kwargs['port'])) sentinel_hosts, del kwargs['sentinel_fallback']"," [(kwargs['host'], kwargs['port'])],",44,12
openstack%2Ftooz~master~Id6bbb08b542bcc96e4534e6b9df5df82b63bd204,openstack/tooz,master,Id6bbb08b542bcc96e4534e6b9df5df82b63bd204,IPC simplification,MERGED,2015-01-12 11:55:11.000000000,2015-01-12 22:47:15.000000000,2015-01-12 22:47:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-12 11:55:11.000000000', 'files': ['tooz/drivers/ipc.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/e0e8519b1b9001ed3db9477beb0437e3ad65c1ff', 'message': 'IPC simplification\n\nChange-Id: Id6bbb08b542bcc96e4534e6b9df5df82b63bd204\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}]",0,146431,e0e8519b1b9001ed3db9477beb0437e3ad65c1ff,7,3,1,1669,,,0,"IPC simplification

Change-Id: Id6bbb08b542bcc96e4534e6b9df5df82b63bd204
Signed-off-by: Julien Danjou <julien@danjou.info>
",git fetch https://review.opendev.org/openstack/tooz refs/changes/31/146431/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/ipc.py'],1,e0e8519b1b9001ed3db9477beb0437e3ad65c1ff,," self._group_list = sysv_ipc.SharedMemory( ftok(self._GROUP_LIST_KEY, self._GROUP_PROJECT), sysv_ipc.IPC_CREAT, size=self._SEGMENT_SIZE) try: self._group_list.detach() self._group_list.remove() except sysv_ipc.ExistentialError: pass"," try: self._group_list = sysv_ipc.SharedMemory( ftok(self._GROUP_LIST_KEY, self._GROUP_PROJECT), sysv_ipc.IPC_CREAT, size=self._SEGMENT_SIZE) except sysv_ipc.ExistentialError: raise def __del__(self): if hasattr(self, ""_group_list""): try: self._group_list.detach() self._group_list.remove() except sysv_ipc.ExistentialError: pass",9,15
openstack%2Fmonasca-api~master~Ie085d6b91692565a6600e9a8da6d8146b5c0f282,openstack/monasca-api,master,Ie085d6b91692565a6600e9a8da6d8146b5c0f282,Add pagination,MERGED,2015-01-12 17:15:57.000000000,2015-01-12 22:44:45.000000000,2015-01-12 22:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11094}, {'_account_id': 11809}, {'_account_id': 12108}, {'_account_id': 12133}, {'_account_id': 12512}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-01-12 17:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/654f51d1ab2eea36a326990da432c6a8e4241e82', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 2, 'created': '2015-01-12 18:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f9d15c15a6bf350db107a14b04048fac8736645b', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 3, 'created': '2015-01-12 18:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/33671161d03d6bedbac34e522b37c8fd202f2b93', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 4, 'created': '2015-01-12 18:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5333cea11d7a18111442e8575313ccbe4595bf8f', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 5, 'created': '2015-01-12 20:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e221fee0b1600adbe598953ad3dc293886b31aa6', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 6, 'created': '2015-01-12 20:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5cf5f3b15a4500ca9962a4ccff07c859c626eac8', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 7, 'created': '2015-01-12 20:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/482bf6b19a1fd04c426adf9f14b63311ad3fc719', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}, {'number': 8, 'created': '2015-01-12 21:45:13.000000000', 'files': ['monasca/common/repositories/alarm_definitions_repository.py', 'monasca/common/repositories/notifications_repository.py', 'monasca/v2/reference/notifications.py', 'monasca/v2/reference/metrics.py', 'monasca/common/repositories/constants.py', 'monasca/common/repositories/alarms_repository.py', 'monasca/v2/reference/helpers.py', 'monasca/common/repositories/influxdb/metrics_repository.py', 'monasca/v2/reference/alarms.py', 'monasca/common/repositories/mysql/alarm_definitions_repository.py', 'monasca/common/repositories/mysql/alarms_repository.py', 'monasca/common/repositories/mysql/notifications_repository.py', 'monasca/common/repositories/metrics_repository.py', 'monasca/v2/reference/alarm_definitions.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/6c6fc3e7a2452af6523d36fd88130db77b44df5f', 'message': ""Add pagination\n\nFor now, use query parameter 'offset=x' to enter the pagination mode.\n\nChange-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282\n""}]",10,146575,6c6fc3e7a2452af6523d36fd88130db77b44df5f,23,8,8,12512,,,0,"Add pagination

For now, use query parameter 'offset=x' to enter the pagination mode.

Change-Id: Ie085d6b91692565a6600e9a8da6d8146b5c0f282
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/75/146575/8 && git format-patch -1 --stdout FETCH_HEAD,"['monasca/common/repositories/alarm_definitions_repository.py', 'monasca/common/repositories/notifications_repository.py', 'monasca/v2/reference/notifications.py', 'monasca/v2/reference/metrics.py', 'monasca/common/repositories/constants.py', 'monasca/common/repositories/alarms_repository.py', 'monasca/v2/reference/helpers.py', 'monasca/common/repositories/influxdb/metrics_repository.py', 'monasca/v2/reference/alarms.py', 'monasca/common/repositories/mysql/alarm_definitions_repository.py', 'monasca/common/repositories/mysql/alarms_repository.py', 'monasca/common/repositories/mysql/notifications_repository.py', 'monasca/common/repositories/metrics_repository.py', 'monasca/v2/reference/alarm_definitions.py']",14,654f51d1ab2eea36a326990da432c6a8e4241e82,feature/pagination," offset = helpers.normalize_offset(helpers.get_query_param(req, 'offset')) req.uri, offset) def _alarm_definition_list(self, tenant_id, name, dimensions, req_uri, offset): dimensions, offset)) result = helpers.paginate(result, req_uri, offset) "," req.uri) def _alarm_definition_list(self, tenant_id, name, dimensions, req_uri): dimensions))",319,56
openstack%2Fmagnum~master~I5c0c481c37ad3f2b23dfe0f1c6c70ce74c3290f1,openstack/magnum,master,I5c0c481c37ad3f2b23dfe0f1c6c70ce74c3290f1,Update the sequence for master_address and minion_addresses,MERGED,2015-01-12 06:11:59.000000000,2015-01-12 22:42:38.000000000,2015-01-12 22:42:38.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-12 06:11:59.000000000', 'files': ['magnum/conductor/handlers/bay_k8s_heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a7f505810fa22e6e64f54510ef8c4cba1677febd', 'message': 'Update the sequence for master_address and minion_addresses\n\nIn the output of kubecluster.yaml, master_address is the 0th value\nand minion_addresses is the 2nd value\n\nChange-Id: I5c0c481c37ad3f2b23dfe0f1c6c70ce74c3290f1\n'}]",0,146381,a7f505810fa22e6e64f54510ef8c4cba1677febd,7,3,1,7494,,,0,"Update the sequence for master_address and minion_addresses

In the output of kubecluster.yaml, master_address is the 0th value
and minion_addresses is the 2nd value

Change-Id: I5c0c481c37ad3f2b23dfe0f1c6c70ce74c3290f1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/81/146381/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/handlers/bay_k8s_heat.py'],1,a7f505810fa22e6e64f54510ef8c4cba1677febd,master, master_address = stack.outputs[0]['output_value'] minion_addresses = stack.outputs[2]['output_value'], master_address = stack.outputs[2]['output_value'] minion_addresses = stack.outputs[0]['output_value'],2,2
openstack%2Fkeystonemiddleware~master~Ic6252b1e00168fa2236f8a892212084da6cfdd64,openstack/keystonemiddleware,master,Ic6252b1e00168fa2236f8a892212084da6cfdd64,Adds Memcached dependencies doc,MERGED,2014-11-17 16:15:29.000000000,2015-01-12 22:41:07.000000000,2015-01-12 22:41:06.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-11-17 16:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/262e38939d24536f975a3cdbaef1f5a21486a878', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 2, 'created': '2014-11-19 13:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d65b9af2dbfb5c55a6d57a186798e2e83bc34c3c', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 3, 'created': '2014-11-19 14:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/08c37f5e992448fb62887516e06b5db8445bc2ec', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 4, 'created': '2014-11-19 17:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/fba2746da759cf87fee486b140edd7cbba4a4d4c', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 5, 'created': '2014-11-26 00:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d2300ec322fcc0577d0cdfe58f4c53fc08d6b358', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 6, 'created': '2014-12-16 11:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/0599c481766e84fa61acf315008f03a0059ab924', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}, {'number': 7, 'created': '2014-12-18 00:32:16.000000000', 'files': ['doc/source/middlewarearchitecture.rst'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c00c98209d1af763a62441e1048708ddc6f1b388', 'message': 'Adds Memcached dependencies doc\n\nSince Memcached is not used by the majority of deployments, its\ndependencies are not included by default in the requirements.txt\nfile. This patch adds the documentation about the need to\nmanually install those dependencies.\n\nChange-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64\nCloses-Bug: 1392264\n'}]",19,134993,c00c98209d1af763a62441e1048708ddc6f1b388,75,9,7,11022,,,0,"Adds Memcached dependencies doc

Since Memcached is not used by the majority of deployments, its
dependencies are not included by default in the requirements.txt
file. This patch adds the documentation about the need to
manually install those dependencies.

Change-Id: Ic6252b1e00168fa2236f8a892212084da6cfdd64
Closes-Bug: 1392264
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/93/134993/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/middlewarearchitecture.rst'],1,262e38939d24536f975a3cdbaef1f5a21486a878,bug/1392264,"Memcached dependencies ====================== In order to use `memcached`_ it is also necessary to manually install the required libs: `python-memcached` and `pycrypto`, since they are not listed by default in the requirements.txt file. .. _`memcached`: http://memcached.org/ ",.. _`memcached`: http://memcached.org/ ,9,2
openstack%2Fpython-solumclient~master~I6fa184c45371fe8e4882e0e2251a84d6c0cf4ad7,openstack/python-solumclient,master,I6fa184c45371fe8e4882e0e2251a84d6c0cf4ad7,Make languagepack metadata an option input,MERGED,2015-01-09 20:43:37.000000000,2015-01-12 22:37:03.000000000,2015-01-12 22:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}]","[{'number': 1, 'created': '2015-01-09 20:43:37.000000000', 'files': ['solumclient/tests/test_solum.py', 'solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/e0af9506c3b05a21d7af83f633a217676cd20794', 'message': 'Make languagepack metadata an option input\n\nI’m making the language pack metadata file an optional\nparameter while building languagepacks.\n\nThis patch is related to\nhttps://review.openstack.org/#/c/146027/\n\nChange-Id: I6fa184c45371fe8e4882e0e2251a84d6c0cf4ad7\n'}]",0,146198,e0af9506c3b05a21d7af83f633a217676cd20794,7,3,1,9095,,,0,"Make languagepack metadata an option input

I’m making the language pack metadata file an optional
parameter while building languagepacks.

This patch is related to
https://review.openstack.org/#/c/146027/

Change-Id: I6fa184c45371fe8e4882e0e2251a84d6c0cf4ad7
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/98/146198/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/tests/test_solum.py', 'solumclient/solum.py']",2,e0af9506c3b05a21d7af83f633a217676cd20794,," self.parser.add_argument('--lp_metadata', lp_metadata = None if args.lp_metadata: with open(args.lp_metadata) as lang_pack_metadata: try: lp_metadata = json.dumps(json.load(lang_pack_metadata)) except ValueError as exc: print(""Error in language pack file: %s"", str(exc)) sys.exit(1) fields = ['uuid', 'name', 'decription', 'state']"," self.parser.add_argument('lp_metadata', with open(args.lp_metadata) as lang_pack_metadata: try: lp_metadata = json.dumps(json.load(lang_pack_metadata)) except ValueError as exc: print(""Error in language pack file: %s"", str(exc)) sys.exit(1) fields = ['uuid', 'name']",13,9
openstack%2Foslo.db~master~I590d9767554498116d0f4e3c4e80bee685a812c2,openstack/oslo.db,master,I590d9767554498116d0f4e3c4e80bee685a812c2,"Revert ""Remove check_foreign_keys from ModelsMigrationsSync""",ABANDONED,2015-01-12 22:10:03.000000000,2015-01-12 22:32:44.000000000,,"[{'_account_id': 2472}, {'_account_id': 7249}, {'_account_id': 7491}, {'_account_id': 11816}]","[{'number': 1, 'created': '2015-01-12 22:10:03.000000000', 'files': ['oslo_db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3eea42d94e54555ee3984abd7140283b9fa29293', 'message': 'Revert ""Remove check_foreign_keys from ModelsMigrationsSync""\n\nThis reverts commit 75b402be3b8497d12bd21f8c371b52427931952d , which\nremoved a function from public API and broke Neutron tests.\n\nThe function is restored to roll back the API change, but it\'s not\nused anymore as we are using the alembic for this now.\n\nRelated-Bug: #1409909\n\nChange-Id: I590d9767554498116d0f4e3c4e80bee685a812c2\n'}]",0,146658,3eea42d94e54555ee3984abd7140283b9fa29293,2,4,1,6849,,,0,"Revert ""Remove check_foreign_keys from ModelsMigrationsSync""

This reverts commit 75b402be3b8497d12bd21f8c371b52427931952d , which
removed a function from public API and broke Neutron tests.

The function is restored to roll back the API change, but it's not
used anymore as we are using the alembic for this now.

Related-Bug: #1409909

Change-Id: I590d9767554498116d0f4e3c4e80bee685a812c2
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/58/146658/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_db/sqlalchemy/test_migrations.py'],1,3eea42d94e54555ee3984abd7140283b9fa29293,bug/1409909,"import collections FKInfo = collections.namedtuple('fk_info', ['constrained_columns', 'referred_table', 'referred_columns']) def check_foreign_keys(self, metadata, bind): """"""DEPRECATED: this method is deprecated and is going to be removed alembic now provides this functionality out of box in compare_metadata(). Compare foreign keys between model and db table. :returns: a list that contains information about: * should be a new key added or removed existing, * name of that key, * source table, * referred table, * constrained columns, * referred columns Output:: [('drop_key', 'testtbl_fk_check_fkey', 'testtbl', fk_info(constrained_columns=(u'fk_check',), referred_table=u'table', referred_columns=(u'fk_check',)))] """""" diff = [] insp = sqlalchemy.engine.reflection.Inspector.from_engine(bind) # Get all tables from db db_tables = insp.get_table_names() # Get all tables from models model_tables = metadata.tables for table in db_tables: if table not in model_tables: continue # Get all necessary information about key of current table from db fk_db = dict((self._get_fk_info_from_db(i), i['name']) for i in insp.get_foreign_keys(table)) fk_db_set = set(fk_db.keys()) # Get all necessary information about key of current table from # models fk_models = dict((self._get_fk_info_from_model(fk), fk) for fk in model_tables[table].foreign_keys) fk_models_set = set(fk_models.keys()) for key in (fk_db_set - fk_models_set): diff.append(('drop_key', fk_db[key], table, key)) LOG.info((""Detected removed foreign key %(fk)r on "" ""table %(table)r""), {'fk': fk_db[key], 'table': table}) for key in (fk_models_set - fk_db_set): diff.append(('add_key', fk_models[key], table, key)) LOG.info(( ""Detected added foreign key for column %(fk)r on table "" ""%(table)r""), {'fk': fk_models[key].column.name, 'table': table}) return diff def _get_fk_info_from_db(self, fk): return self.FKInfo(tuple(fk['constrained_columns']), fk['referred_table'], tuple(fk['referred_columns'])) def _get_fk_info_from_model(self, fk): return self.FKInfo((fk.parent.name,), fk.column.table.name, (fk.column.name,)) ",,73,0
openstack%2Foctavia~master~Ie71235519dc568353670befe2847c6d017291e7f,openstack/octavia,master,Ie71235519dc568353670befe2847c6d017291e7f,Renaming amphora.host_id to amphora.compute_id,MERGED,2015-01-10 08:13:57.000000000,2015-01-12 22:23:42.000000000,2015-01-12 22:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2015-01-10 08:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/17b9f7c643a779edc06522ddf6db70c8deb77d7f', 'message': 'Renaming amphora.host_id to amphora.compute_id\n\namphora.id was originally intended to be the storage of the\nid returned by compute (i.e. nova).  However, octavia will\nneed to have its own internal id for all amphorae, so amphora.id\ncannot be used.  amphora.host_id kind of makes sense for storing\nthe id returned by the compute service but it would be better\nto name it compute_id instead for more clarity.\n\nChange-Id: Ie71235519dc568353670befe2847c6d017291e7f\n'}, {'number': 2, 'created': '2015-01-11 06:06:32.000000000', 'files': ['octavia/tests/functional/db/test_repositories.py', 'octavia/common/data_models.py', 'octavia/db/models.py', 'octavia/db/migration/alembic_migrations/versions/3a1e1cdb7b27_rename_amphora_host_id.py', 'octavia/tests/functional/db/test_models.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/b6ec4e4568524bdd38770c9adee577c694879703', 'message': 'Renaming amphora.host_id to amphora.compute_id\n\namphora.id was originally intended to be the storage of the\nid returned by compute (i.e. nova).  However, octavia will\nneed to have its own internal id for all amphorae, so amphora.id\ncannot be used.  amphora.host_id kind of makes sense for storing\nthe id returned by the compute service but it would be better\nto name it compute_id instead for more clarity.\n\nChange-Id: Ie71235519dc568353670befe2847c6d017291e7f\n'}]",2,146272,b6ec4e4568524bdd38770c9adee577c694879703,11,5,2,6951,,,0,"Renaming amphora.host_id to amphora.compute_id

amphora.id was originally intended to be the storage of the
id returned by compute (i.e. nova).  However, octavia will
need to have its own internal id for all amphorae, so amphora.id
cannot be used.  amphora.host_id kind of makes sense for storing
the id returned by the compute service but it would be better
to name it compute_id instead for more clarity.

Change-Id: Ie71235519dc568353670befe2847c6d017291e7f
",git fetch https://review.opendev.org/openstack/octavia refs/changes/72/146272/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/functional/db/test_repositories.py', 'octavia/common/data_models.py', 'octavia/db/models.py', 'octavia/db/migration/alembic_migrations/versions/3a1e1cdb7b27_rename_amphora_host_id.py', 'octavia/tests/functional/db/test_models.py']",5,17b9f7c643a779edc06522ddf6db70c8deb77d7f,rename-amphora-host-id," 'compute_id': self.FAKE_UUID_1, self.assertEqual(self.FAKE_UUID_1, amphora.compute_id)"," 'host_id': self.FAKE_UUID_1, self.assertEqual(self.FAKE_UUID_1, amphora.host_id)",49,11
openstack%2Foctavia~master~Id8752e42853156923fce9e6b6c2aeebe2191d107,openstack/octavia,master,Id8752e42853156923fce9e6b6c2aeebe2191d107,Combine migration scripts into one,ABANDONED,2014-12-19 23:57:27.000000000,2015-01-12 22:15:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-19 23:57:27.000000000', 'files': ['octavia/db/migration/alembic_migrations/versions/13500e2e978d_update_url_and_name_size.py', 'octavia/db/migration/alembic_migrations/versions/initialize.py', 'octavia/db/migration/alembic_migrations/versions/4faaa983e7a9_update_member_address_column.py', 'octavia/db/migration/alembic_migrations/versions/4c094013699a_update_load_balancer_amphora.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3560bd30885cafe383cf20f8f4f15cabc23956cc', 'message': ""Combine migration scripts into one\n\nIt doesn't make sense to add new migration scripts until there\nis an actual version release.  Whenever we need to change the\ndatabase schema we should just edit this script and also the\nmodels.\n\nChange-Id: Id8752e42853156923fce9e6b6c2aeebe2191d107\n""}]",0,143221,3560bd30885cafe383cf20f8f4f15cabc23956cc,5,3,1,6951,,,0,"Combine migration scripts into one

It doesn't make sense to add new migration scripts until there
is an actual version release.  Whenever we need to change the
database schema we should just edit this script and also the
models.

Change-Id: Id8752e42853156923fce9e6b6c2aeebe2191d107
",git fetch https://review.opendev.org/openstack/octavia refs/changes/21/143221/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/db/migration/alembic_migrations/versions/13500e2e978d_update_url_and_name_size.py', 'octavia/db/migration/alembic_migrations/versions/initialize.py', 'octavia/db/migration/alembic_migrations/versions/4faaa983e7a9_update_member_address_column.py', 'octavia/db/migration/alembic_migrations/versions/4c094013699a_update_load_balancer_amphora.py']",4,3560bd30885cafe383cf20f8f4f15cabc23956cc,combine-migrations,,"# Copyright 2014 Rackspace # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. '''update load balancer amphora relationship Revision ID: 4c094013699a Revises: 35dee79d5865 Create Date: 2014-09-15 14:42:44.875448 ''' # revision identifiers, used by Alembic. revision = '4c094013699a' down_revision = '35dee79d5865' from alembic import op import sqlalchemy as sa def upgrade(): op.add_column( u'amphora', sa.Column(u'load_balancer_id', sa.String(36), sa.ForeignKey(u'load_balancer.id', name=u'fk_amphora_load_balancer_id'), nullable=True) ) op.drop_table(u'load_balancer_amphora') op.drop_constraint( u'fk_container_provisioning_status_name', u'amphora', type_=u'foreignkey' ) op.create_foreign_key( u'fk_amphora_provisioning_status_name', u'amphora', u'provisioning_status', [u'status'], [u'name'] ) def downgrade(): op.drop_constraint( u'fk_amphora_load_balancer_id', u'amphora', type_=u'foreignkey' ) op.drop_column( u'amphora', u'load_balancer_id' ) op.create_table( u'load_balancer_amphora', sa.Column(u'amphora_id', sa.String(36), nullable=False), sa.Column(u'load_balancer_id', sa.String(36), nullable=False), sa.ForeignKeyConstraint( [u'load_balancer_id'], [u'load_balancer.id'], name=u'fk_load_balancer_amphora_load_balancer_id'), sa.ForeignKeyConstraint([u'amphora_id'], [u'amphora.id'], name=u'fk_load_balancer_amphora_id'), sa.PrimaryKeyConstraint(u'amphora_id', u'load_balancer_id') ) op.drop_constraint( u'fk_amphora_provisioning_status_name', u'amphora', type_=u'foreignkey' ) op.create_foreign_key( u'fk_container_provisioning_status_name', u'amphora', u'provisioning_status', [u'status'], [u'name'] ) ",14,197
openstack%2Fkeystone-specs~master~I2dcb4ce973819952df4483f41ff070c47ac782f9,openstack/keystone-specs,master,I2dcb4ce973819952df4483f41ff070c47ac782f9,Specify default values for identity providers.,MERGED,2015-01-12 09:49:16.000000000,2015-01-12 22:14:34.000000000,2015-01-12 22:14:33.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-01-12 09:49:16.000000000', 'files': ['api/v3/identity-api-v3-os-federation-ext.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/22aef2748ed9e48e36c5065a386f9d8a8bc5e4e8', 'message': 'Specify default values for identity providers.\n\nCurrently documentation is not clear about default values while creating\nOS-FEDERATION ``identity provider`` objects. This change sets values\nthat reflect current logic in the code.\n\nChange-Id: I2dcb4ce973819952df4483f41ff070c47ac782f9\n'}]",0,146405,22aef2748ed9e48e36c5065a386f9d8a8bc5e4e8,9,6,1,8978,,,0,"Specify default values for identity providers.

Currently documentation is not clear about default values while creating
OS-FEDERATION ``identity provider`` objects. This change sets values
that reflect current logic in the code.

Change-Id: I2dcb4ce973819952df4483f41ff070c47ac782f9
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/05/146405/1 && git format-patch -1 --stdout FETCH_HEAD,['api/v3/identity-api-v3-os-federation-ext.rst'],1,22aef2748ed9e48e36c5065a386f9d8a8bc5e4e8,identity_provider_changes," If a value is not specified by the client, the service will default this value to ``null``. If a value is not specified by the client, the service will default this to ``false``."," If a value is not specified by the client, the service may default this value to either an empty string or ``null``. If a value is not specified by the client, the service may default this to either ``true`` or ``false``.",4,4
openstack%2Fpuppet-glance~master~Ib73439b9fead52e644dc9b463e61e20e9108b6c8,openstack/puppet-glance,master,Ib73439b9fead52e644dc9b463e61e20e9108b6c8,Fix policy configuration for Puppet future parser,ABANDONED,2015-01-12 20:53:42.000000000,2015-01-12 22:13:21.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 20:53:42.000000000', 'files': ['manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6de1c9b99835ddd3e4a0c17fdbcbba7677216e28', 'message': 'Fix policy configuration for Puppet future parser\n\nWhen the future parser is enabled, use a lamba/iterator to declare\nthe openstacklib::policy::base resources instead of create_resources.\n\nThis solves a problem introduced by the future parser where the\ninternal function call API squashes hashes, and thus breaks the\ndata structure used in the create_resources call.\n\nChange-Id: Ib73439b9fead52e644dc9b463e61e20e9108b6c8\nCloses-bug: 1409897\n'}]",0,146638,6de1c9b99835ddd3e4a0c17fdbcbba7677216e28,3,1,1,9060,,,0,"Fix policy configuration for Puppet future parser

When the future parser is enabled, use a lamba/iterator to declare
the openstacklib::policy::base resources instead of create_resources.

This solves a problem introduced by the future parser where the
internal function call API squashes hashes, and thus breaks the
data structure used in the create_resources call.

Change-Id: Ib73439b9fead52e644dc9b463e61e20e9108b6c8
Closes-bug: 1409897
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/38/146638/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/policy.pp'],1,6de1c9b99835ddd3e4a0c17fdbcbba7677216e28,bug/1409897," # If using the future/4.x parser, use a lambda to define the # openstacklib::policy::base resources. create_resources breaks # under the future parser, because hashes get flattened through # the internal Puppet function call API. if $::settings::parser == 'future' { each($policies) |$name, $description| { each($description) |$policy, $setting| { openstacklib::policy::base { ""${name}-${policy}"": key => $policy, value => $setting, } } } } else { create_resources('openstacklib::policy::base', $policies) }"," create_resources('openstacklib::policy::base', $policies)",16,1
openstack%2Fpuppet-neutron~master~I433412870e280daf077ec7beade9fac7d6a3f9ca,openstack/puppet-neutron,master,I433412870e280daf077ec7beade9fac7d6a3f9ca,Fix policy configuration for Puppet future parser,ABANDONED,2015-01-12 20:52:36.000000000,2015-01-12 22:13:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 20:52:36.000000000', 'files': ['manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fd4d9664d8fa136155a2efaf8028a8da68742d00', 'message': 'Fix policy configuration for Puppet future parser\n\nWhen the future parser is enabled, use a lamba/iterator to declare\nthe openstacklib::policy::base resources instead of create_resources.\n\nThis solves a problem introduced by the future parser where the\ninternal function call API squashes hashes, and thus breaks the\ndata structure used in the create_resources call.\n\nChange-Id: I433412870e280daf077ec7beade9fac7d6a3f9ca\nCloses-bug: 1409897\n'}]",0,146637,fd4d9664d8fa136155a2efaf8028a8da68742d00,3,1,1,9060,,,0,"Fix policy configuration for Puppet future parser

When the future parser is enabled, use a lamba/iterator to declare
the openstacklib::policy::base resources instead of create_resources.

This solves a problem introduced by the future parser where the
internal function call API squashes hashes, and thus breaks the
data structure used in the create_resources call.

Change-Id: I433412870e280daf077ec7beade9fac7d6a3f9ca
Closes-bug: 1409897
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/37/146637/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/policy.pp'],1,fd4d9664d8fa136155a2efaf8028a8da68742d00,bug/1409897," # If using the future/4.x parser, use a lambda to define the # openstacklib::policy::base resources. create_resources breaks # under the future parser, because hashes get flattened through # the internal Puppet function call API. if $::settings::parser == 'future' { each($policies) |$name, $description| { each($description) |$policy, $setting| { openstacklib::policy::base { ""${name}-${policy}"": key => $policy, value => $setting, } } } } else { create_resources('openstacklib::policy::base', $policies) }"," create_resources('openstacklib::policy::base', $policies)",16,1
openstack%2Fpuppet-nova~master~I2a00c4d411f2f0666f382ad5f5659d333002cd7a,openstack/puppet-nova,master,I2a00c4d411f2f0666f382ad5f5659d333002cd7a,Fix policy configuration for Puppet future parser,ABANDONED,2015-01-12 20:51:09.000000000,2015-01-12 22:12:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 20:51:09.000000000', 'files': ['manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ee4dede017a727dfd16e51407cb66e3808c347c1', 'message': 'Fix policy configuration for Puppet future parser\n\nWhen the future parser is enabled, use a lamba/iterator to declare\nthe openstacklib::policy::base resources instead of create_resources.\n\nThis solves a problem introduced by the future parser where the\ninternal function call API squashes hashes, and thus breaks the\ndata structure used in the create_resources call.\n\nChange-Id: I2a00c4d411f2f0666f382ad5f5659d333002cd7a\nCloses-bug: 1409897\n'}]",0,146635,ee4dede017a727dfd16e51407cb66e3808c347c1,3,1,1,9060,,,0,"Fix policy configuration for Puppet future parser

When the future parser is enabled, use a lamba/iterator to declare
the openstacklib::policy::base resources instead of create_resources.

This solves a problem introduced by the future parser where the
internal function call API squashes hashes, and thus breaks the
data structure used in the create_resources call.

Change-Id: I2a00c4d411f2f0666f382ad5f5659d333002cd7a
Closes-bug: 1409897
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/35/146635/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/policy.pp'],1,ee4dede017a727dfd16e51407cb66e3808c347c1,bug/1409897," # If using the future/4.x parser, use a lambda to define the # openstacklib::policy::base resources. create_resources breaks # under the future parser, because hashes get flattened through # the internal Puppet function call API. if $::settings::parser == 'future' { each($policies) |$name, $description| { each($description) |$policy, $setting| { openstacklib::policy::base { ""${name}-${policy}"": key => $policy, value => $setting, } } } } else { create_resources('openstacklib::policy::base', $policies) }"," create_resources('openstacklib::policy::base', $policies)",16,1
openstack%2Fbarbican~master~Id534c335544f3045472dca495f3aa5f802ac9b7e,openstack/barbican,master,Id534c335544f3045472dca495f3aa5f802ac9b7e,Configure keystomemiddleware using identity_uri,MERGED,2015-01-09 14:45:46.000000000,2015-01-12 22:10:23.000000000,2015-01-12 22:10:22.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7354}, {'_account_id': 7355}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-01-09 14:45:46.000000000', 'files': ['etc/barbican/barbican-api-paste.ini', 'doc/source/setup/keystone.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c9f9d89641c142d74fd01b4ec827b92f694edaf6', 'message': 'Configure keystomemiddleware using identity_uri\n\nThe auth fragments (auth_protocol, auth_host and auth_port) are\ndeprecated, and the usage of identity_uri is recommended as a\nreplacement. This change fixes that.\n\nChange-Id: Id534c335544f3045472dca495f3aa5f802ac9b7e\n'}]",0,146100,c9f9d89641c142d74fd01b4ec827b92f694edaf6,22,13,1,10873,,,0,"Configure keystomemiddleware using identity_uri

The auth fragments (auth_protocol, auth_host and auth_port) are
deprecated, and the usage of identity_uri is recommended as a
replacement. This change fixes that.

Change-Id: Id534c335544f3045472dca495f3aa5f802ac9b7e
",git fetch https://review.opendev.org/openstack/barbican refs/changes/00/146100/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/barbican-api-paste.ini', 'doc/source/setup/keystone.rst']",2,c9f9d89641c142d74fd01b4ec827b92f694edaf6,identity_uri, identity_uri = http://{YOUR_KEYSTONE_ENDPOINT}:35357, auth_host = {YOUR_KEYSTONE_ENDPOINT} auth_port = 35357 auth_protocol = http,2,6
openstack%2Ffuel-plugins~master~I51632b81eb6d73e24861f778c888b9691a41e945,openstack/fuel-plugins,master,I51632b81eb6d73e24861f778c888b9691a41e945,Update README for plugin release data,MERGED,2015-01-12 19:37:32.000000000,2015-01-12 21:57:53.000000000,2015-01-12 21:56:16.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9147}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-01-12 19:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/8b32eba7daa38bf3f2d815078b66cce62bf11508', 'message': 'Update README for plugin release data\n\nRe-structures the README page to more clearly explain purpose of the repo\n and update links to point to live documentation now that it is available.\n\nChange-Id: I51632b81eb6d73e24861f778c888b9691a41e945\n'}, {'number': 2, 'created': '2015-01-12 20:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/1bf004121719b615456f7b54558e4a30c04ba4de', 'message': 'Update README for plugin release data\n\nRe-structures the README page to more clearly explain purpose of the repo\n and update links to point to live documentation now that it is available.\n\nChange-Id: I51632b81eb6d73e24861f778c888b9691a41e945\n'}, {'number': 3, 'created': '2015-01-12 20:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/8fb3cd9b590d1d2073269d29c7f307ecc0fafb3b', 'message': 'Update README for plugin release data\n\nRe-structures the README page to more clearly explain purpose of the repo\n and update links to point to live documentation now that it is available.\n\nChange-Id: I51632b81eb6d73e24861f778c888b9691a41e945\n'}, {'number': 4, 'created': '2015-01-12 21:08:43.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/fuel-plugins/commit/8952ec8b4ef5a5618c70134dc953a95f6a083762', 'message': 'Update README for plugin release data\n\nRe-structures the README page to more clearly explain purpose of the repo\n and update links to point to live documentation now that it is available.\n\nChange-Id: I51632b81eb6d73e24861f778c888b9691a41e945\n'}]",12,146620,8952ec8b4ef5a5618c70134dc953a95f6a083762,25,7,4,8797,,,0,"Update README for plugin release data

Re-structures the README page to more clearly explain purpose of the repo
 and update links to point to live documentation now that it is available.

Change-Id: I51632b81eb6d73e24861f778c888b9691a41e945
",git fetch https://review.opendev.org/openstack/fuel-plugins refs/changes/20/146620/4 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,8b32eba7daa38bf3f2d815078b66cce62bf11508,,"Fuel Plugins ============ Starting with version 6.0, Fuel supports a Pluggable architecture. Fuel plug-ins allow you to install and configure additional capabilities for your cloud, such as additional storage types and networking functionality. For example, a Load Balancing as a Service (LBaaS) plug-in allows you to add network load balancing functionality to your cloud so that incoming traffic can be spread across multiple nodes. Or you might want to use a GlusterFS plug-in so that you can use a Gluster file system as backend storage for blocks (Cinder). Finding Plugins =============== For production versions of plugins, including certified plugins, see [Released Plugins Catalog](https://software.mirantis.com/download-mirantis-openstack-fuel-plug-ins/ ""Released Plugins Catalog"") StackForge Fuel-plugins Repository ================================== Structure --------- This repository contains plugins maintained by the Fuel development team. Additionally it contains an example plugin, and the fuel plugin builder tool (fpb). The plugin code here might not be suitable for production use please see [Released Plugins](https://software.mirantis.com/download-mirantis-openstack-fuel-plug-ins/ ""Released Plugins"") to download release versions of these and other fuel plugins. * **fuel_plugin_builder** - the command line interface that helps to create, check and build Fuel plugin. You can create your own plugin in three simple steps: * `fpb --build <path to plugin>` * **fuel_plugin_example** - simple Fuel plugin example that shows how you can create a plugin. It deploys simple service on your Controller nodes. * **lbaas** - Fuel plugin that provides [Neutron LBaaS](https://wiki.openstack.org/wiki/Neutron/LBaaS/PluginDrivers ""Neutron LBaaS"") for multinode mode. * **external_glusterfs** - Fuel plugin that allows to use existing [GlusterFS](http://www.gluster.org/documentation/About_Gluster/ ""GlusterFS"") cluster as the Cinder backend. Other Plugin repos ------------------ Other location known to have fuel plugins. *Note, these may not be supported by the fuel team* * [Mirantis Plugins](https://github.com/mirantis/fuel-plugins ""Mirantis Plugins"") More Information ---------------- For instructions on creating your plugin, see [Plugin Development](http://docs.mirantis.com/openstack/fuel/fuel-6.0/plugin-dev.html ""Plugin Development"") For instructions on installing your plugin, see [Installing Plugins](http://docs.mirantis.com/openstack/fuel/fuel-6.0/user-guide.html#install-fuel-plug-ins ""Installing Plugins"")","Fuel plugins repository ======================= Starting with version 6.0, Fuel supports Pluggable architecture. Currently, Cinder and Neutron plugins are available. * *fuel_plugin_builder* - command line interface that helps to create, check and build Fuel plugin. You can create your own plugin in three simple steps: * `fpb --build fuel_plugin_name` * *fuel_plugin_example* - simple Fuel plugin example that shows how you can create a plugin. It deploys simple service on your Controller nodes. * *lbaas* - Fuel plugin that provides [Neutron LBaaS](https://wiki.openstack.org/wiki/Neutron/LBaaS/PluginDrivers ""Neutron LBaaS"") for multinode mode. * *external_glusterfs* - Fuel plugin that allows to use existing [GlusterFS](http://www.gluster.org/documentation/About_Gluster/ ""GlusterFS"") cluster as the Cinder backend. For instructions on creating your plugin, see <link> For instructions on installing your plugin, see <link> For production plugin versions, see <link>",50,12
openstack%2Foslo.concurrency~master~I54a4ed67549c28f70e66b37f5915edfcbc7dd0f3,openstack/oslo.concurrency,master,I54a4ed67549c28f70e66b37f5915edfcbc7dd0f3,Updated from global requirements,MERGED,2015-01-09 18:35:01.000000000,2015-01-12 21:51:21.000000000,2015-01-12 21:51:20.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-01-09 18:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/ad40c3dcdcb888599f1a8bda42907c8e052f2ca5', 'message': 'Updated from global requirements\n\nChange-Id: I54a4ed67549c28f70e66b37f5915edfcbc7dd0f3\n'}, {'number': 2, 'created': '2015-01-10 22:48:24.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/43dc67e0dce1c3c9d95375b0f421d1e027ab0abf', 'message': 'Updated from global requirements\n\nChange-Id: I54a4ed67549c28f70e66b37f5915edfcbc7dd0f3\n'}]",0,146160,43dc67e0dce1c3c9d95375b0f421d1e027ab0abf,19,3,2,11131,,,0,"Updated from global requirements

Change-Id: I54a4ed67549c28f70e66b37f5915edfcbc7dd0f3
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/60/146160/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ad40c3dcdcb888599f1a8bda42907c8e052f2ca5,openstack/requirements,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Ffuel-library~stable%2F5.1~Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,openstack/fuel-library,stable/5.1,Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,Fix for murano-manage package-import,MERGED,2014-12-12 08:27:58.000000000,2015-01-12 21:46:27.000000000,2015-01-12 21:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7225}, {'_account_id': 7613}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-12 08:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aae97f42e5a62cedcf4eec5d188f00fcabb230bc', 'message': 'Fix for murano-manage package-import\n\n* This patchset resolves issue with re-upload of already existing murano application package\n\nChange-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a\nRelated-Bug: # 1401503\n(cherry picked from commit 9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13)\n'}, {'number': 2, 'created': '2015-01-12 12:46:06.000000000', 'files': ['deployment/puppet/murano/manifests/application_package.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c202ac28f65d5f321d4c78b0cbe896b9795b800b', 'message': 'Fix for murano-manage package-import\n\n* This patchset resolves issue with re-upload of already existing murano application package\n\nChange-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a\nRelated-Bug: #1401503\n(cherry picked from commit 9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13)\n'}]",0,141302,c202ac28f65d5f321d4c78b0cbe896b9795b800b,19,6,2,6926,,,0,"Fix for murano-manage package-import

* This patchset resolves issue with re-upload of already existing murano application package

Change-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a
Related-Bug: #1401503
(cherry picked from commit 9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/02/141302/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/murano/manifests/application_package.pp'],1,aae97f42e5a62cedcf4eec5d188f00fcabb230bc,," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' --update"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}' --update"","," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}'"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}'"",",2,2
openstack%2Fneutron-fwaas~master~I2f299b44ce84f886291f2d1d7fb70b85cb188504,openstack/neutron-fwaas,master,I2f299b44ce84f886291f2d1d7fb70b85cb188504,Fix the neutron-fwaas unit test failures,MERGED,2015-01-12 18:22:34.000000000,2015-01-12 21:46:11.000000000,2015-01-12 21:46:10.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 7448}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-01-12 18:22:34.000000000', 'files': ['neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/services/firewall/agents/varmour/varmour_router.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/23ef44f5ad98f010c41b88398cf303dc643d6638', 'message': 'Fix the neutron-fwaas unit test failures\n\nneutron-fwaas Unit tests are failing because of the\nthe neutron commit (51a6260266dc59c066072ca890ad9c40b1aad6cf)\n\nThis patch fixes those failures.\n\nChange-Id: I2f299b44ce84f886291f2d1d7fb70b85cb188504\nCloses-bug: #1409786\n'}]",0,146593,23ef44f5ad98f010c41b88398cf303dc643d6638,10,5,1,10237,,,0,"Fix the neutron-fwaas unit test failures

neutron-fwaas Unit tests are failing because of the
the neutron commit (51a6260266dc59c066072ca890ad9c40b1aad6cf)

This patch fixes those failures.

Change-Id: I2f299b44ce84f886291f2d1d7fb70b85cb188504
Closes-bug: #1409786
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/93/146593/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/services/firewall/agents/varmour/varmour_router.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py']",4,23ef44f5ad98f010c41b88398cf303dc643d6638,bug/1409786,from neutron.agent.l3 import config as l3_config self.conf.register_opts(l3_config.OPTS), self.conf.register_opts(varmour_router.vArmourL3NATAgent.OPTS),8,5
openstack%2Ffuel-docs~stable%2F6.0~Iae8c444927a63be76f6dea116c5fd776c32657d4,openstack/fuel-docs,stable/6.0,Iae8c444927a63be76f6dea116c5fd776c32657d4,Remove support for external MongoDB server from Release Notes,MERGED,2015-01-12 21:35:49.000000000,2015-01-12 21:45:45.000000000,2015-01-12 21:45:45.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2015-01-12 21:35:49.000000000', 'files': ['pages/release-notes/v6-0/0020-new-features.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e957155468dbfe05098618c10ce6baba1db72ef1', 'message': 'Remove support for external MongoDB server from Release Notes\n\nThis feature was moved to 6.1 but is included in the ""New Features""\nlist of the Release Notes.  I left the file in place, just commented\nout the line that sources it, since we expect to include this feature\nin a later release.\n\nChange-Id: Iae8c444927a63be76f6dea116c5fd776c32657d4\n(cherry picked from commit 387b96711152e6e208914ba3cd1bbaced39378cc)\n'}]",0,146646,e957155468dbfe05098618c10ce6baba1db72ef1,7,4,1,8787,,,0,"Remove support for external MongoDB server from Release Notes

This feature was moved to 6.1 but is included in the ""New Features""
list of the Release Notes.  I left the file in place, just commented
out the line that sources it, since we expect to include this feature
in a later release.

Change-Id: Iae8c444927a63be76f6dea116c5fd776c32657d4
(cherry picked from commit 387b96711152e6e208914ba3cd1bbaced39378cc)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/46/146646/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/0020-new-features.rst'],1,e957155468dbfe05098618c10ce6baba1db72ef1,,.. include /pages/release-notes/v6-0/new-features/mongodb-external.rst,.. include:: /pages/release-notes/v6-0/new-features/mongodb-external.rst,1,1
openstack%2Foslo.vmware~master~I4acca54d9e23f1d4204017b574c09453369d42f1,openstack/oslo.vmware,master,I4acca54d9e23f1d4204017b574c09453369d42f1,Update oslo.i18n version to one that includes ToggleLazy fixture,ABANDONED,2015-01-12 19:12:43.000000000,2015-01-12 21:43:17.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 19:12:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/088e1d68dcc9181052a8d3a8af066e2e9e61d901', 'message': 'Update oslo.i18n version to one that includes ToggleLazy fixture\n\nMerged patch https://review.openstack.org/#/c/145923 changed\nto using the ToggleLazy fixture from oslo.i18n, but that support\nwas added in the 1.3.0 release.\n\nChange-Id: I4acca54d9e23f1d4204017b574c09453369d42f1\n'}]",0,146615,088e1d68dcc9181052a8d3a8af066e2e9e61d901,3,1,1,6601,,,0,"Update oslo.i18n version to one that includes ToggleLazy fixture

Merged patch https://review.openstack.org/#/c/145923 changed
to using the ToggleLazy fixture from oslo.i18n, but that support
was added in the 1.3.0 release.

Change-Id: I4acca54d9e23f1d4204017b574c09453369d42f1
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/15/146615/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,088e1d68dcc9181052a8d3a8af066e2e9e61d901,master,oslo.i18n>=1.3.0 # Apache-2.0,oslo.i18n>=1.0.0 # Apache-2.0,1,1
openstack%2Fpython-keystoneclient~master~Ifbf4add0b27433560373070610a4e0562b3eb3c0,openstack/python-keystoneclient,master,Ifbf4add0b27433560373070610a4e0562b3eb3c0,Upgrade hacking to 0.10.0,ABANDONED,2015-01-12 21:39:20.000000000,2015-01-12 21:40:15.000000000,,[],"[{'number': 1, 'created': '2015-01-12 21:39:20.000000000', 'files': ['test-requirements.txt', 'keystoneclient/tests/v2_0/test_certificates.py', 'keystoneclient/v2_0/certificates.py', 'keystoneclient/middleware/auth_token.py', 'keystoneclient/common/cms.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e3792879bb7efc4ae2d80a03cd01752643462957', 'message': 'Upgrade hacking to 0.10.0\n\nAlso fixed a few of the errors that came up\n\nChange-Id: Ifbf4add0b27433560373070610a4e0562b3eb3c0\n'}]",0,146647,e3792879bb7efc4ae2d80a03cd01752643462957,2,0,1,6482,,,0,"Upgrade hacking to 0.10.0

Also fixed a few of the errors that came up

Change-Id: Ifbf4add0b27433560373070610a4e0562b3eb3c0
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/47/146647/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'keystoneclient/tests/v2_0/test_certificates.py', 'keystoneclient/v2_0/certificates.py', 'keystoneclient/middleware/auth_token.py', 'keystoneclient/common/cms.py']",5,e3792879bb7efc4ae2d80a03cd01752643462957,up_hacking,class OpensslCmsExitStatus(object):,class OpensslCmsExitStatus:,5,5
openstack%2Ffuel-docs~master~Iae8c444927a63be76f6dea116c5fd776c32657d4,openstack/fuel-docs,master,Iae8c444927a63be76f6dea116c5fd776c32657d4,Remove support for external MongoDB server from Release Notes,MERGED,2015-01-12 09:22:43.000000000,2015-01-12 21:35:49.000000000,2015-01-12 21:35:41.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 7732}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2015-01-12 09:22:43.000000000', 'files': ['pages/release-notes/v6-0/0020-new-features.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/387b96711152e6e208914ba3cd1bbaced39378cc', 'message': 'Remove support for external MongoDB server from Release Notes\n\nThis feature was moved to 6.1 but is included in the ""New Features""\nlist of the Release Notes.  I left the file in place, just commented\nout the line that sources it, since we expect to include this feature\nin a later release.\n\nChange-Id: Iae8c444927a63be76f6dea116c5fd776c32657d4\n'}]",0,146398,387b96711152e6e208914ba3cd1bbaced39378cc,13,7,1,10014,,,0,"Remove support for external MongoDB server from Release Notes

This feature was moved to 6.1 but is included in the ""New Features""
list of the Release Notes.  I left the file in place, just commented
out the line that sources it, since we expect to include this feature
in a later release.

Change-Id: Iae8c444927a63be76f6dea116c5fd776c32657d4
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/98/146398/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-0/0020-new-features.rst'],1,387b96711152e6e208914ba3cd1bbaced39378cc,no-remote-mongodb,.. include /pages/release-notes/v6-0/new-features/mongodb-external.rst,.. include:: /pages/release-notes/v6-0/new-features/mongodb-external.rst,1,1
openstack%2Foslo.db~master~I77a2bba2de08125b5a601de03c1d2d5c73fa33ee,openstack/oslo.db,master,I77a2bba2de08125b5a601de03c1d2d5c73fa33ee,Remove check_foreign_keys from ModelsMigrationsSync,MERGED,2014-12-04 09:39:59.000000000,2015-01-12 21:34:30.000000000,2015-01-05 09:24:08.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 11816}, {'_account_id': 12363}]","[{'number': 1, 'created': '2014-12-04 09:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/cd9ed47f336b4c6532a036e93063df77cead87cc', 'message': 'Remove check_foreign_keys from ModelsMigrationsSync\n\nAlembic 0.7.1 contains checks of foreign keys so method\ncheck_foreign_keys is not needed anymore.\n\nChange-Id: I77a2bba2de08125b5a601de03c1d2d5c73fa33ee\n'}, {'number': 2, 'created': '2014-12-30 15:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0b903f82f173378cb64fe5a92742fafbe27f012f', 'message': 'Remove check_foreign_keys from ModelsMigrationsSync\n\nAlembic 0.7.1 contains checks of foreign keys so method\ncheck_foreign_keys is not needed anymore.\n\nChange-Id: I77a2bba2de08125b5a601de03c1d2d5c73fa33ee\n'}, {'number': 3, 'created': '2014-12-31 08:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0c835ec2eae8b2bea0e2fd30b58a3acfb27a2927', 'message': 'Remove check_foreign_keys from ModelsMigrationsSync\n\nAlembic 0.7.1 contains checks of foreign keys so method\ncheck_foreign_keys is not needed anymore.\n\nChange-Id: I77a2bba2de08125b5a601de03c1d2d5c73fa33ee\n'}, {'number': 4, 'created': '2014-12-31 08:57:12.000000000', 'files': ['oslo_db/sqlalchemy/test_migrations.py', 'oslo_db/tests/sqlalchemy/test_migrations.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/75b402be3b8497d12bd21f8c371b52427931952d', 'message': 'Remove check_foreign_keys from ModelsMigrationsSync\n\nAlembic 0.7.1 contains checks of foreign keys so method\ncheck_foreign_keys is not needed anymore.\n\nChange-Id: I77a2bba2de08125b5a601de03c1d2d5c73fa33ee\n'}]",0,139002,75b402be3b8497d12bd21f8c371b52427931952d,18,6,4,7249,,,0,"Remove check_foreign_keys from ModelsMigrationsSync

Alembic 0.7.1 contains checks of foreign keys so method
check_foreign_keys is not needed anymore.

Change-Id: I77a2bba2de08125b5a601de03c1d2d5c73fa33ee
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/02/139002/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/sqlalchemy/test_migrations.py', 'oslo/db/sqlalchemy/test_migrations.py']",2,cd9ed47f336b4c6532a036e93063df77cead87cc,fk_check," diff = alembic.autogenerate.compare_metadata(mc, self.get_metadata())","import collections FKInfo = collections.namedtuple('fk_info', ['constrained_columns', 'referred_table', 'referred_columns']) def check_foreign_keys(self, metadata, bind): """"""Compare foreign keys between model and db table. :returns: a list that contains information about: * should be a new key added or removed existing, * name of that key, * source table, * referred table, * constrained columns, * referred columns Output:: [('drop_key', 'testtbl_fk_check_fkey', 'testtbl', fk_info(constrained_columns=(u'fk_check',), referred_table=u'table', referred_columns=(u'fk_check',)))] """""" diff = [] insp = sqlalchemy.engine.reflection.Inspector.from_engine(bind) # Get all tables from db db_tables = insp.get_table_names() # Get all tables from models model_tables = metadata.tables for table in db_tables: if table not in model_tables: continue # Get all necessary information about key of current table from db fk_db = dict((self._get_fk_info_from_db(i), i['name']) for i in insp.get_foreign_keys(table)) fk_db_set = set(fk_db.keys()) # Get all necessary information about key of current table from # models fk_models = dict((self._get_fk_info_from_model(fk), fk) for fk in model_tables[table].foreign_keys) fk_models_set = set(fk_models.keys()) for key in (fk_db_set - fk_models_set): diff.append(('drop_key', fk_db[key], table, key)) LOG.info((""Detected removed foreign key %(fk)r on "" ""table %(table)r""), {'fk': fk_db[key], 'table': table}) for key in (fk_models_set - fk_db_set): diff.append(('add_key', fk_models[key], table, key)) LOG.info(( ""Detected added foreign key for column %(fk)r on table "" ""%(table)r""), {'fk': fk_models[key].column.name, 'table': table}) return diff def _get_fk_info_from_db(self, fk): return self.FKInfo(tuple(fk['constrained_columns']), fk['referred_table'], tuple(fk['referred_columns'])) def _get_fk_info_from_model(self, fk): return self.FKInfo((fk.parent.name,), fk.column.table.name, (fk.column.name,)) diff1 = alembic.autogenerate.compare_metadata(mc, self.get_metadata()) diff2 = self.check_foreign_keys(self.get_metadata(), self.get_engine()) diff = diff1 + diff2",3,74
openstack%2Fheat~master~I5facf5540ca16ed36318977e4b4aa2b2e2d5bf60,openstack/heat,master,I5facf5540ca16ed36318977e4b4aa2b2e2d5bf60,Sync the remainder of the composition doc from manuals,MERGED,2015-01-12 12:51:26.000000000,2015-01-12 21:30:41.000000000,2015-01-12 21:30:39.000000000,"[{'_account_id': 3}, {'_account_id': 7193}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-12 12:51:26.000000000', 'files': ['doc/source/template_guide/composition.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/f0bf08f8a102281cc0d2c4c98aa48ad75472b2b7', 'message': 'Sync the remainder of the composition doc from manuals\n\nThe docs team have improved the language and layout.\n\nChange-Id: I5facf5540ca16ed36318977e4b4aa2b2e2d5bf60\n'}]",0,146455,f0bf08f8a102281cc0d2c4c98aa48ad75472b2b7,16,3,1,4715,,,0,"Sync the remainder of the composition doc from manuals

The docs team have improved the language and layout.

Change-Id: I5facf5540ca16ed36318977e4b4aa2b2e2d5bf60
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/146455/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/template_guide/composition.rst'],1,f0bf08f8a102281cc0d2c4c98aa48ad75472b2b7,comp-docs,"Template resources provide a feature similar to the :hotref:`AWS::CloudFormation::Stack` resource, but also provide a way to: * Define new resource types and build your own resource library. * Override the default behaviour of existing resource types. To achieve this: * The Orchestration client gets the associated template files and passes them along in the ``files`` section of the ``POST stacks/`` API request. * The environment in the Orchestration engine manages the mapping of resource type to template creation. * The Orchestration engine translates template parameters into resource properties. The following examples illustrate how you can use a custom template to define new types of resources. These examples use a custom template stored in a :file:`my_nova.yml` file: flavor: m1.small image: ubuntu-trusty-x86_64 Use the template filename as type ================================= The following template defines the :file:`my_nova.yaml` file as value for the ``type`` property of a resource:The ``key_name`` argument of the ``my_nova.yaml`` template gets its value from the ``key_name`` property of the new template. .. note:: The above reference to ``my_nova.yaml`` assumes it is in the same directory. You can use any of the following forms: * Relative path (``my_nova.yaml``) * Absolute path (``file:///home/user/templates/my_nova.yaml``) * Http URL (``http://example.com/templates/my_nova.yaml``) * Https URL (``https://example.com/templates/my_nova.yaml``) To create the stack run: .. code-block:: console $ heat stack-create -f main.yaml stack1 Define a new resource type ========================== You can associate a name to the ``my_nova.yaml`` template in an environment file. If the name is already known by the Orchestration module then your new resource will override the default one. In the following example a new ``OS::Nova::Server`` resource overrides the default resource of the same name. An :file:`env.yaml` environment file holds the definition of the new resource:.. note:: See :ref:`environments` for more detail about environment files. You can now use the new ``OS::Nova::Server`` in your new template:To create the stack run: .. code-block:: consoleGet access to nested attributes ==============================="," How to use template resources for composition --------------------------------------------- Template resources do a very similar job to AWS::CloudFormation::Stack, but they are more powerful as they allow a template to ""stand in for"" any resource type. Template resources can be used to do the following: * Define new resource types (make you own resource library). * Override the default behaviour of existing resource types. The way this is achieved is: * The heat client gets the associated template files and passes them along in the ""files"" section of the ""POST stacks/"". * The environment in Orchestration engine manages the mapping of resource type to template creation. * Translation of the template parameters into resource properties. Let's go through some examples. In all examples assume the same resource template. This is a simple wrapper around a nova server (my_nova.yaml). flavor: my.best image: the_one_i_always_use Example 1 ~~~~~~~~~ In this example you will not map a resource type name at all, but directly specify the template URL as the resource type. Your main template (main.yaml) would look like this.Some notes about URLs: The above reference to my_nova.yaml assumes it is in the same directory. You could use any of the following forms: * Relative path (type: my_nova.yaml) * Absolute path (type: file:///home/user/templates/my_nova.yaml) * Http URL (type: http://example.com/templates/my_nova.yaml) * Https URL (type: https://example.com/templates/my_nova.yaml) To create the stack, run:: $ heat stack-create -f main.yaml example-one Example 2 ~~~~~~~~~ In this example you will use the environment (env.yaml) to override the OS::Nova::Server with my_nova to get the defaults you want.A more detailed discussion on this can be found here :ref:`environments` Now you can use ""OS::Nova::Server"" in our top level template (main.yaml).To create the stack, run::Getting access to nested attributes -----------------------------------",55,45
openstack%2Fceilometer~master~Iaeed85104fa3da259bc132c907a34fa388a3431f,openstack/ceilometer,master,Iaeed85104fa3da259bc132c907a34fa388a3431f,Imported Translations from Transifex,MERGED,2015-01-09 06:08:56.000000000,2015-01-12 21:24:33.000000000,2015-01-12 21:24:32.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-09 06:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/242260172ee6cdbc3a2f40ba157b33539f7ce3e3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaeed85104fa3da259bc132c907a34fa388a3431f\n'}, {'number': 2, 'created': '2015-01-10 06:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b4f6d4df8952bc11af530aac011333eac61740f4', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaeed85104fa3da259bc132c907a34fa388a3431f\n'}, {'number': 3, 'created': '2015-01-11 06:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/105187fa9179da7e3ed14b3d9d046e6f5abb7d48', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaeed85104fa3da259bc132c907a34fa388a3431f\n'}, {'number': 4, 'created': '2015-01-12 06:08:49.000000000', 'files': ['ceilometer/locale/ceilometer-log-warning.pot', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ceilometer.pot'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/524e2707ab3dc8ffeca7795b2160b2bd040cc2ac', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaeed85104fa3da259bc132c907a34fa388a3431f\n'}]",0,146021,524e2707ab3dc8ffeca7795b2160b2bd040cc2ac,24,7,4,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iaeed85104fa3da259bc132c907a34fa388a3431f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/21/146021/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/locale/ceilometer.pot']",2,242260172ee6cdbc3a2f40ba157b33539f7ce3e3,transifex/translations,"""Project-Id-Version: ceilometer 2015.1.dev35\n""""POT-Creation-Date: 2015-01-09 06:08+0000\n""#: ceilometer/agent/base.py:133 #, python-format msgid ""Skip polling pollster %s, no resources found"" msgstr """" #: ceilometer/agent/base.py:145#: ceilometer/agent/base.py:285#: ceilometer/agent/base.py:287","""Project-Id-Version: ceilometer 2015.1.dev32\n""""POT-Creation-Date: 2015-01-07 06:11+0000\n""#: ceilometer/agent/base.py:140#: ceilometer/agent/base.py:280#: ceilometer/agent/base.py:282",20,10
openstack%2Fheat~master~Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9,openstack/heat,master,Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9,Make StackResource less strict on initial validation,MERGED,2015-01-02 15:44:23.000000000,2015-01-12 21:24:22.000000000,2015-01-12 21:24:21.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 8289}, {'_account_id': 10486}]","[{'number': 1, 'created': '2015-01-02 15:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2bd498f6e772a0084376fde7382f0d5ba92a9ef5', 'message': ""Don't eagerly validate StackResource objects\n\nCurrently, we do a full validation in the validate(), which means any\nresource which defines value-sensitive constraints (e.g where we\ncare about the value, such as the various custom constraints added\nto properties schemas recently via the nova-custom-constraints bp)\nwill fail validation, even if the subsequent create operation would\nsucceed.\n\nInstead, stick to validating the structural correctness, and save the\nactual nested stack validation the create/update (which already do\nvalidation).\n\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\n""}, {'number': 2, 'created': '2015-01-02 21:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ea5c8740e3c6736964d4070a4e37b5d00a799344', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\n'}, {'number': 3, 'created': '2015-01-06 09:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2fd08b07330785d3a2dafafcd99b36b2dc8ac838', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-bug: #1407877\n'}, {'number': 4, 'created': '2015-01-06 12:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/963034f0d078e639e81f8a45e17c5edf67fe70c2', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-bug: #1407877\n'}, {'number': 5, 'created': '2015-01-07 21:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ffdc54a177cbdbf8f3f8a90c303a3aef023c91b5', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-bug: #1407877\n'}, {'number': 6, 'created': '2015-01-07 21:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f247295b77ef696b8553f5def970e0f4bec2dd9c', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}, {'number': 7, 'created': '2015-01-09 11:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e191fb03c3ac15caeb4aa629d2192a11e6fca4cb', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}, {'number': 8, 'created': '2015-01-09 17:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/183243ee8b96cd1382092186a90142dd62753b36', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}, {'number': 9, 'created': '2015-01-12 09:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e5e37c36e46f548a29e4a692c602f403465a4020', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}, {'number': 10, 'created': '2015-01-12 11:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/77a50fd420a63f73070c907b997d74743f4151c9', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}, {'number': 11, 'created': '2015-01-12 16:39:54.000000000', 'files': ['heat_integrationtests/common/test.py', 'heat/engine/stack_resource.py', 'heat_integrationtests/functional/test_validation.py', 'heat/tests/test_stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f3f9d68fc13d192650f1e4dca484da2efa635a38', 'message': 'Make StackResource less strict on initial validation\n\nWhen doing the initial validate(), skip validating values by setting\nthe stack strict_validate to False, otherwise we incorrectly fail\nvalidation when values are passed in via properties/parameters which\nrefer to resources in the parent stack.\n\nCo-Authored-by: Angus Salkeld <asalkeld@mirantis.com>\nChange-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9\nCloses-Bug: #1407100\nCloses-Bug: #1407877\nCloses-Bug: #1405446\n'}]",5,144766,f3f9d68fc13d192650f1e4dca484da2efa635a38,50,8,11,4328,,,0,"Make StackResource less strict on initial validation

When doing the initial validate(), skip validating values by setting
the stack strict_validate to False, otherwise we incorrectly fail
validation when values are passed in via properties/parameters which
refer to resources in the parent stack.

Co-Authored-by: Angus Salkeld <asalkeld@mirantis.com>
Change-Id: Ib75c2de6c32373de72901b9f7c5e3828bd9ee7d9
Closes-Bug: #1407100
Closes-Bug: #1407877
Closes-Bug: #1405446
",git fetch https://review.opendev.org/openstack/heat refs/changes/66/144766/10 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/stack_resource.py'],1,2bd498f6e772a0084376fde7382f0d5ba92a9ef5,bug/1402894,, nested_stack.validate(),0,1
openstack%2Ffuel-library~stable%2F4.1~I146f96c2215aff95af9fd53682f501f3a1b90349,openstack/fuel-library,stable/4.1,I146f96c2215aff95af9fd53682f501f3a1b90349,Set neutron OCF scripts umask to 0022,MERGED,2014-12-08 15:07:35.000000000,2015-01-12 21:14:27.000000000,2015-01-12 21:14:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7604}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-08 15:07:35.000000000', 'files': ['deployment/puppet/neutron/files/ocf/neutron-agent-ovs', 'deployment/puppet/neutron/files/ocf/neutron-agent-dhcp', 'deployment/puppet/neutron/files/ocf/neutron-agent-l3', 'deployment/puppet/neutron/files/ocf/neutron-agent-metadata'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/227eee1c3c02c12302b8dfb1b6a64f4be600cd80', 'message': 'Set neutron OCF scripts umask to 0022\n\nFor some reason pacemaker sets umask to 0026\nwhich leads to 0751 rights set for neutron\nagents scripts, which in turn create\nsome of files with these rights set, which\nin turn can make metadata proxy process\nunmanagable, making router hang.\n\nChange-Id: I146f96c2215aff95af9fd53682f501f3a1b90349\n'}]",0,140024,227eee1c3c02c12302b8dfb1b6a64f4be600cd80,11,6,1,7604,,,0,"Set neutron OCF scripts umask to 0022

For some reason pacemaker sets umask to 0026
which leads to 0751 rights set for neutron
agents scripts, which in turn create
some of files with these rights set, which
in turn can make metadata proxy process
unmanagable, making router hang.

Change-Id: I146f96c2215aff95af9fd53682f501f3a1b90349
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/24/140024/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/neutron/files/ocf/neutron-agent-ovs', 'deployment/puppet/neutron/files/ocf/neutron-agent-dhcp', 'deployment/puppet/neutron/files/ocf/neutron-agent-l3', 'deployment/puppet/neutron/files/ocf/neutron-agent-metadata']",4,227eee1c3c02c12302b8dfb1b6a64f4be600cd80,stable/4.1,umask 0022,,5,0
openstack%2Fpython-openstackclient~master~Iad84313636ee2f53777cdf05d60a322f7a252f27,openstack/python-openstackclient,master,Iad84313636ee2f53777cdf05d60a322f7a252f27,Updated from global requirements,MERGED,2015-01-09 18:35:55.000000000,2015-01-12 21:12:41.000000000,2015-01-12 21:12:39.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-01-09 18:35:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/80499dc5a196ebc1ecffd56d2a776c9efc401998', 'message': 'Updated from global requirements\n\nChange-Id: Iad84313636ee2f53777cdf05d60a322f7a252f27\n'}]",0,146169,80499dc5a196ebc1ecffd56d2a776c9efc401998,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Iad84313636ee2f53777cdf05d60a322f7a252f27
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/69/146169/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,80499dc5a196ebc1ecffd56d2a776c9efc401998,openstack/requirements,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Foslotest~master~Id3095e96d883270d0a1d61cd72ab534837d819cb,openstack/oslotest,master,Id3095e96d883270d0a1d61cd72ab534837d819cb,custom context manger for py27/py3x compatability,ABANDONED,2015-01-09 21:46:46.000000000,2015-01-12 20:55:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-01-09 21:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/f57e44a9a496b4271201d0af129633b0dc88ab49', 'message': 'WIP: custom context manger\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 2, 'created': '2015-01-10 20:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/83dafe89a92a60533485cfaed59805d5b2f04593', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 3, 'created': '2015-01-11 03:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/9a53eec465f352b25edb5eea9099d8e61d8e8041', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 4, 'created': '2015-01-11 03:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/7f5229f9db65c695909268d608261eb799c63d1d', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 5, 'created': '2015-01-11 03:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/9a8743683f1a0423387cefd64fabae06ca338aa4', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 6, 'created': '2015-01-11 03:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/702b06fe6a20229baa0ba54ea214bb16937b439c', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 7, 'created': '2015-01-11 03:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslotest/commit/c247bdc7df29ad33a4ad8510578b71f6f0755b9c', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}, {'number': 8, 'created': '2015-01-11 04:03:53.000000000', 'files': ['oslotest/context.py', 'tests/unit/test_context.py'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/1957d659153c1c662d91d4f039727ba0ec9c396a', 'message': 'custom context manger for py27/py3x compatability\n\ncontextlib.nested logs a DeprecationWarning which fills up the logs\n(example in Nova) as py3x does not support this. One alternative as\nproposed by the DeprecationWarning is ""With-statements now directly\nsupport multiple context managers"". However this means we\'ll add\na lot of \'\\\' as the with statement cannot span lines.\n\nThe nested() implementation in this review is a drop-in replacement\nfor contextlib.nested() and we can avoid a lot of unnecessary code\nchanges. This implementation has been tested with the Nova unit\ntests in review:\nIf92dc85aa6f9162a1bdec2201bc4a8895f6e8566\n\nChange-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb\n'}]",0,146205,1957d659153c1c662d91d4f039727ba0ec9c396a,19,4,8,5638,,,0,"custom context manger for py27/py3x compatability

contextlib.nested logs a DeprecationWarning which fills up the logs
(example in Nova) as py3x does not support this. One alternative as
proposed by the DeprecationWarning is ""With-statements now directly
support multiple context managers"". However this means we'll add
a lot of '\' as the with statement cannot span lines.

The nested() implementation in this review is a drop-in replacement
for contextlib.nested() and we can avoid a lot of unnecessary code
changes. This implementation has been tested with the Nova unit
tests in review:
If92dc85aa6f9162a1bdec2201bc4a8895f6e8566

Change-Id: Id3095e96d883270d0a1d61cd72ab534837d819cb
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/05/146205/2 && git format-patch -1 --stdout FETCH_HEAD,['oslotest/context.py'],1,f57e44a9a496b4271201d0af129633b0dc88ab49,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sys class _Stack(object): def __init__(self, *contexts): self._prepared = list(contexts) self._context_stack = [] def __call__(self, *contexts): vars = [] for ctx in contexts: value = self._append(ctx) vars.append(value) return vars def _append(self, ctx): if hasattr(ctx, '__enter__') and hasattr(ctx, '__exit__'): value = ctx.__enter__() self._context_stack[-1].append((ctx, value)) return value else: raise TypeError(""__enter__/__exit__ missing"") def __enter__(self): vars = [] self._context_stack.append([]) if self._context_stack == [[]]: for ctx in self._prepared: value = self._append(ctx) vars.append(value) return vars def __exit__(self, *exc): contexts = self._context_stack.pop() for ctx, value in contexts[::-1]: try: if hasattr(ctx, '__exit__'): if (ctx.__exit__(*exc)): exc = (None, None, None) else: raise TypeError(""__enter__/__exit__ missing"") except: # noqa exc = sys.exc_info() if exc != (None, None, None): raise exc[0], exc[1], exc[2] def close(self): self.__exit__(None, None, None) def nested(*args): return _Stack(*args) ",,65,0
openstack%2Fswift~master~Ia70228f2c99595501271765286431f68e82e800b,openstack/swift,master,Ia70228f2c99595501271765286431f68e82e800b,Mark the --region as mandatory,MERGED,2015-01-10 05:25:36.000000000,2015-01-12 20:52:33.000000000,2015-01-12 20:52:32.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-01-10 05:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/814b512bfd2210a076aacaddb09a41d57c491261', 'message': ""Mark the --region as mandatory\n\nWe used to permit to omit region in the old parameter syntax, although\nwe now throw a warning if it's missing. In the new parameter syntax,\n--region is mandatory. It's enforded by build_dev_from_opts in\nswift/common/ring/utils.py.\n\nChange-Id: Ia70228f2c99595501271765286431f68e82e800b\n""}, {'number': 2, 'created': '2015-01-10 15:21:42.000000000', 'files': ['swift/cli/ringbuilder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c65bc49e099928801b80dce399d6098f7e10e137', 'message': ""Mark the --region as mandatory\n\nWe used to permit to omit region in the old parameter syntax, although\nwe now throw a warning if it's missing. In the new parameter syntax,\n--region is mandatory. It's enforced by build_dev_from_opts in\nswift/common/ring/utils.py.\n\nOn the other hand, --replication-ip, --replication-port, and --meta\nare not obligatory.\n\nChange-Id: Ia70228f2c99595501271765286431f68e82e800b\n""}]",2,146266,c65bc49e099928801b80dce399d6098f7e10e137,13,6,2,597,,,0,"Mark the --region as mandatory

We used to permit to omit region in the old parameter syntax, although
we now throw a warning if it's missing. In the new parameter syntax,
--region is mandatory. It's enforced by build_dev_from_opts in
swift/common/ring/utils.py.

On the other hand, --replication-ip, --replication-port, and --meta
are not obligatory.

Change-Id: Ia70228f2c99595501271765286431f68e82e800b
",git fetch https://review.opendev.org/openstack/swift refs/changes/66/146266/2 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/ringbuilder.py'],1,814b512bfd2210a076aacaddb09a41d57c491261,builder/region_argument, --region <region> --zone <zone> --ip <ip> --port <port>, [--region <region>] --zone <zone> --ip <ip> --port <port>,1,1
openstack%2Fswift~master~Ia28fa923a65ad7d85804cbf6f7acef244741bab1,openstack/swift,master,Ia28fa923a65ad7d85804cbf6f7acef244741bab1,Removing commented out test in test_db_replicator,MERGED,2015-01-10 09:11:39.000000000,2015-01-12 20:52:25.000000000,2015-01-12 20:52:24.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 6968}, {'_account_id': 10068}, {'_account_id': 13052}, {'_account_id': 14575}]","[{'number': 1, 'created': '2015-01-10 09:11:39.000000000', 'files': ['test/unit/common/test_db_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/99fa8b3f8e4dc024bab68899736a2881cc9fedf4', 'message': 'Removing commented out test in test_db_replicator\n\nIt removes test_dispatch test from test_db_replicator\nwhich has been commented out for a while.\n\nChange-Id: Ia28fa923a65ad7d85804cbf6f7acef244741bab1\nCloses-Bug: #1408502\n'}]",0,146273,99fa8b3f8e4dc024bab68899736a2881cc9fedf4,11,6,1,14575,,,0,"Removing commented out test in test_db_replicator

It removes test_dispatch test from test_db_replicator
which has been commented out for a while.

Change-Id: Ia28fa923a65ad7d85804cbf6f7acef244741bab1
Closes-Bug: #1408502
",git fetch https://review.opendev.org/openstack/swift refs/changes/73/146273/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_db_replicator.py'],1,99fa8b3f8e4dc024bab68899736a2881cc9fedf4,remove_fix,,"# def test_dispatch(self): # rpc = db_replicator.ReplicatorRpc('/', '/', FakeBroker, False) # no_op = lambda *args, **kwargs: True # self.assertEquals(rpc.dispatch(('drv', 'part', 'hash'), ('op',) # ).status_int, 400) # rpc.mount_check = True # self.assertEquals(rpc.dispatch(('drv', 'part', 'hash'), ['op',] # ).status_int, 507) # rpc.mount_check = False # rpc.rsync_then_merge = lambda drive, db_file, # args: self.assertEquals(args, ['test1']) # rpc.complete_rsync = lambda drive, db_file, # args: self.assertEquals(args, ['test2']) # rpc.dispatch(('drv', 'part', 'hash'), ['rsync_then_merge','test1']) # rpc.dispatch(('drv', 'part', 'hash'), ['complete_rsync','test2']) # rpc.dispatch(('drv', 'part', 'hash'), ['other_op',]) ",0,17
openstack%2Fpython-barbicanclient~master~Id6162b57b1f55b972037dee2e58574dfcb04e57f,openstack/python-barbicanclient,master,Id6162b57b1f55b972037dee2e58574dfcb04e57f,Updated from global requirements,MERGED,2015-01-09 18:35:27.000000000,2015-01-12 20:36:43.000000000,2015-01-12 20:36:42.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7789}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-01-09 18:35:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/0d2200f47722c0533194b6e102d03b0774cbdea7', 'message': 'Updated from global requirements\n\nChange-Id: Id6162b57b1f55b972037dee2e58574dfcb04e57f\n'}]",0,146163,0d2200f47722c0533194b6e102d03b0774cbdea7,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: Id6162b57b1f55b972037dee2e58574dfcb04e57f
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/63/146163/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0d2200f47722c0533194b6e102d03b0774cbdea7,openstack/requirements,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e,openstack/openstack-manuals,master,I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e,Fix formatting of nova-api service text,MERGED,2015-01-12 18:12:20.000000000,2015-01-12 20:23:33.000000000,2015-01-12 20:23:31.000000000,"[{'_account_id': 3}, {'_account_id': 3114}, {'_account_id': 6772}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-01-12 18:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ffed4d1ebe3f73d82840702d881dbc97f4f5385b', 'message': 'Fix formatting of nova-api service text\n\nFor ""nova-api service"" moved ""service"" to be outside of </systemitem> as to align with the formatting of other system-related items/terms.\n\nChange-Id: I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e\nCloses-Bug: #1408852\n'}, {'number': 2, 'created': '2015-01-12 18:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e226ea454443334d38281bb8b134b7b4f0cdd35', 'message': 'Fix formatting of nova-api service text\n\nFor ""nova-api service"" moved ""service"" to be outside of </systemitem> as to align with the formatting of other system-related items/terms.\nCloses-Bug: #1408852\n\nChange-Id: I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e\n'}, {'number': 3, 'created': '2015-01-12 18:17:25.000000000', 'files': ['doc/common/section_getstart_compute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/54b1b6c8963a9d21e9a8a2050c8c830cbcd1a8c6', 'message': 'Fix formatting of nova-api service text\n\nFor ""nova-api service"" moved ""service"" to be outside of </systemitem> as to align with the formatting of other system-related items/terms.\n\nCloses-Bug: #1408852\n\nChange-Id: I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e\n'}]",0,146590,54b1b6c8963a9d21e9a8a2050c8c830cbcd1a8c6,10,4,3,8804,,,0,"Fix formatting of nova-api service text

For ""nova-api service"" moved ""service"" to be outside of </systemitem> as to align with the formatting of other system-related items/terms.

Closes-Bug: #1408852

Change-Id: I1d530bfc616fab2aed7aa1e9ca3b8dde9041ae3e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/146590/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_getstart_compute.xml'],1,ffed4d1ebe3f73d82840702d881dbc97f4f5385b,bug/1408852," <term><systemitem class=""service"">nova-api</systemitem> service</term>"," <term><systemitem class=""service"">nova-api service</systemitem></term>",2,2
openstack%2Fswift~master~Ib5f8e3a692fddbe8b1f4994787b2883130e9536f,openstack/swift,master,Ib5f8e3a692fddbe8b1f4994787b2883130e9536f,Drop redundant index output,MERGED,2015-01-10 05:17:34.000000000,2015-01-12 20:21:26.000000000,2015-01-12 20:21:21.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-01-10 05:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2b7f8a2a26ede5a56270341df10d16946320db2f', 'message': 'Drop redundant index output\n\nThe output of format_device() now includes index as the first ""dX""\nelement, for example d1r1z2-127.0.0.1:6200R127.0.0.1:6200/db_"""".\n\nChange-Id: Ib5f8e3a692fddbe8b1f4994787b2883130e9536f\n'}, {'number': 2, 'created': '2015-01-10 15:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/da031b77adb3dbcdd6691592f32b492137c00939', 'message': 'Drop redundant index from console output\n\nThe output of format_device() now includes index as the first ""dX""\nelement, for example d1r1z2-127.0.0.1:6200R127.0.0.1:6200/db_"""".\n\nChange-Id: Ib5f8e3a692fddbe8b1f4994787b2883130e9536f\n'}, {'number': 3, 'created': '2015-01-11 00:27:43.000000000', 'files': ['swift/common/ring/builder.py', 'swift/cli/ringbuilder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b5586427e503ee22c0b20b109cad83e166ed3fd8', 'message': 'Drop redundant index output\n\nThe output of format_device() now includes index as the first ""dX""\nelement, for example d1r1z2-127.0.0.1:6200R127.0.0.1:6200/db_"""".\n\nChange-Id: Ib5f8e3a692fddbe8b1f4994787b2883130e9536f\n'}]",3,146265,b5586427e503ee22c0b20b109cad83e166ed3fd8,20,6,3,597,,,0,"Drop redundant index output

The output of format_device() now includes index as the first ""dX""
element, for example d1r1z2-127.0.0.1:6200R127.0.0.1:6200/db_"""".

Change-Id: Ib5f8e3a692fddbe8b1f4994787b2883130e9536f
",git fetch https://review.opendev.org/openstack/swift refs/changes/65/146265/2 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/ringbuilder.py'],1,2b7f8a2a26ede5a56270341df10d16946320db2f,builder/output," print('Device %s weight %s' % (format_device(new_dev), new_dev['weight']))"," print('Device %s with %s weight got id %s' % (format_device(new_dev), new_dev['weight'], dev_id))",2,2
openstack%2Fhorizon~master~I4600ed1a290976b9ab1f5a4f4f5287392c018d30,openstack/horizon,master,I4600ed1a290976b9ab1f5a4f4f5287392c018d30,Fix UncompressableFileError for latest horizon code,MERGED,2015-01-11 11:45:13.000000000,2015-01-12 20:13:45.000000000,2015-01-12 20:13:44.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 13276}]","[{'number': 1, 'created': '2015-01-11 11:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bc1723c1c809844afa6a85c82bf8cd927725037f', 'message': 'Fix UncompressableFileError\n\nWhen pulling the latest horizon code and update required packages,\nthen login it, it will raise UncompressableFileError because of the\nincorrect smart-table.js path, the patch will fix it.\n\nChange-Id: I4600ed1a290976b9ab1f5a4f4f5287392c018d30\n'}, {'number': 2, 'created': '2015-01-11 11:51:00.000000000', 'files': ['horizon/templates/horizon/_conf.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/12c37e3af0a95cb793ad1fb7e055276da049e5ac', 'message': 'Fix UncompressableFileError for latest horizon code\n\nWhen pulling the latest horizon code and update required packages,\nthen login it, it will raise UncompressableFileError because of the\nincorrect smart-table.js path, the patch will fix it.\n\nChange-Id: I4600ed1a290976b9ab1f5a4f4f5287392c018d30\nCloses-Bug: 1409420\n'}]",0,146316,12c37e3af0a95cb793ad1fb7e055276da049e5ac,9,4,2,6763,,,0,"Fix UncompressableFileError for latest horizon code

When pulling the latest horizon code and update required packages,
then login it, it will raise UncompressableFileError because of the
incorrect smart-table.js path, the patch will fix it.

Change-Id: I4600ed1a290976b9ab1f5a4f4f5287392c018d30
Closes-Bug: 1409420
",git fetch https://review.opendev.org/openstack/horizon refs/changes/16/146316/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/_conf.html'],1,bc1723c1c809844afa6a85c82bf8cd927725037f,bug/1409420,"<script src=""{{ STATIC_URL }}horizon/lib/smart-table/smart-table.js"" type=""text/javascript"" charset=""utf-8""></script>","<script src=""{{ STATIC_URL }}horizon/lib/smart-table/dist/smart-table.min.js"" type=""text/javascript"" charset=""utf-8""></script>",1,1
openstack%2Fnova~master~Id3cd1311c91c21a50f43ea46cc8451b349fb5862,openstack/nova,master,Id3cd1311c91c21a50f43ea46cc8451b349fb5862,libvirt: Use arch.from_host instead of platform.processor,MERGED,2015-01-07 22:54:45.000000000,2015-01-12 20:13:08.000000000,2015-01-12 20:13:05.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 475}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14384}]","[{'number': 1, 'created': '2015-01-07 22:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c74a093fa4ae894abd3bf989f0f06c412f972df', 'message': 'libvirt: Mock get_arch for Windows timer tests\n\nThe existing tests did not mock `get_arch`, so the test depended on the actual\nresult of `platform.processor`. On a Mac, this return `i386` which causes the\ntest to fail.\n\nThe solution is to mock the function so that it return `i686` across the\nboard.\n\nChange-Id: Id3cd1311c91c21a50f43ea46cc8451b349fb5862\nCloses-Bug: 1408484\n'}, {'number': 2, 'created': '2015-01-08 20:50:04.000000000', 'files': ['nova/virt/libvirt/utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/10acedd704f9cb5bc5ca62769c98c23fa1cbdb6f', 'message': 'libvirt: Use arch.from_host instead of platform.processor\n\nThe Windows timer tests would fail on a Mac because it would return `i386`\nfrom `get_arch` instead of one of the canonicalized architecture names.\n\nThe solution is to use the standardized `arch.from_host` function instead.\n\nWe still mock out the `get_arch` function so the tests pass on PPC/ARM/s390\nprocessors.\n\nCo-Authored-By: Daniel Berrange <berrange@redhat.com>\nChange-Id: Id3cd1311c91c21a50f43ea46cc8451b349fb5862\nCloses-Bug: 1408484\n'}]",1,145618,10acedd704f9cb5bc5ca62769c98c23fa1cbdb6f,30,13,2,475,,,0,"libvirt: Use arch.from_host instead of platform.processor

The Windows timer tests would fail on a Mac because it would return `i386`
from `get_arch` instead of one of the canonicalized architecture names.

The solution is to use the standardized `arch.from_host` function instead.

We still mock out the `get_arch` function so the tests pass on PPC/ARM/s390
processors.

Co-Authored-By: Daniel Berrange <berrange@redhat.com>
Change-Id: Id3cd1311c91c21a50f43ea46cc8451b349fb5862
Closes-Bug: 1408484
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/145618/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_driver.py'],1,4c74a093fa4ae894abd3bf989f0f06c412f972df,bug/1408484," @mock.patch.object(libvirt_utils, 'get_arch') def test_get_guest_config_windows(self, mock_flavor, mock_version, mock_get_arch): mock_get_arch.return_value = arch.I686 @mock.patch.object(libvirt_utils, 'get_arch') def test_get_guest_config_windows_timer(self, mock_flavor, mock_version, mock_get_arch): mock_get_arch.return_value = arch.I686"," def test_get_guest_config_windows(self, mock_flavor, mock_version): def test_get_guest_config_windows_timer(self, mock_flavor, mock_version):",8,2
openstack%2Foslo.messaging~master~I0364f1c8235c3dd6846810beb5b2fd2a1c605350,openstack/oslo.messaging,master,I0364f1c8235c3dd6846810beb5b2fd2a1c605350,Import workaround,ABANDONED,2015-01-12 16:23:42.000000000,2015-01-12 20:08:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-01-12 16:23:42.000000000', 'files': ['oslo/messaging/rpc/__init__.py', 'oslo/messaging/__init__.py', 'oslo/messaging/notify/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1200a67a948644d4b9554cc944071cb189713a8b', 'message': 'Import workaround\n\nChange-Id: I0364f1c8235c3dd6846810beb5b2fd2a1c605350\n'}]",0,146547,1200a67a948644d4b9554cc944071cb189713a8b,3,1,1,2813,,,0,"Import workaround

Change-Id: I0364f1c8235c3dd6846810beb5b2fd2a1c605350
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/47/146547/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/rpc/__init__.py', 'oslo/messaging/__init__.py', 'oslo/messaging/notify/__init__.py']",3,1200a67a948644d4b9554cc944071cb189713a8b,bp/drop-namespace-packages," # Copyright 2013 Red Hat, Inc. #__all__ = ['Notifier', 'LoggingNotificationHandler', 'get_notification_listener', 'NotificationResult', 'PublishErrorsHandler', 'LoggingErrorNotificationHandler'] from .notifier import * from .listener import * from .log_handler import * from .logger import * from .dispatcher import NotificationResult",from oslo_messaging.notify import *,58,9
openstack%2Fhorizon~master~I243a416588d9d458a9b0ba54421f15c2f1c72750,openstack/horizon,master,I243a416588d9d458a9b0ba54421f15c2f1c72750,Imported Translations from Transifex,MERGED,2015-01-12 06:06:36.000000000,2015-01-12 20:06:27.000000000,2015-01-12 20:06:26.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-01-12 06:06:36.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/48651a24f071524fbc3c8331a2e604ec0205fc29', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I243a416588d9d458a9b0ba54421f15c2f1c72750\n'}]",0,146380,48651a24f071524fbc3c8331a2e604ec0205fc29,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I243a416588d9d458a9b0ba54421f15c2f1c72750
",git fetch https://review.opendev.org/openstack/horizon refs/changes/80/146380/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,48651a24f071524fbc3c8331a2e604ec0205fc29,transifex/translations,"""POT-Creation-Date: 2015-01-11 02:22-0600\n"" ""PO-Revision-Date: 2015-01-11 06:53+0000\n""#: dashboards/admin/metering/views.py:199#: dashboards/admin/metering/views.py:198#: dashboards/admin/metering/views.py:198#: dashboards/admin/metering/views.py:199#: dashboards/admin/metering/tabs.py:62 dashboards/admin/metering/views.py:216#: dashboards/admin/metering/tabs.py:63 dashboards/admin/metering/views.py:217#: dashboards/admin/metering/tabs.py:64 dashboards/admin/metering/views.py:218#: dashboards/admin/metering/tabs.py:65 dashboards/admin/metering/views.py:219#: dashboards/admin/metering/tabs.py:66 dashboards/admin/metering/views.py:220#: dashboards/admin/metering/tabs.py:67 dashboards/admin/metering/views.py:221#: dashboards/admin/metering/tabs.py:80 dashboards/admin/metering/views.py:159#: dashboards/admin/metering/tabs.py:88 dashboards/admin/metering/views.py:240#: dashboards/admin/metering/views.py:76 #, python-format msgid ""Failed to get the resource name: %s"" msgstr """" #: dashboards/admin/metering/views.py:198#: dashboards/admin/metering/views.py:199#: dashboards/admin/metering/views.py:232","""POT-Creation-Date: 2015-01-10 23:12-0600\n"" ""PO-Revision-Date: 2015-01-10 23:01+0000\n""#: dashboards/admin/metering/views.py:161#: dashboards/admin/metering/views.py:160#: dashboards/admin/metering/views.py:160#: dashboards/admin/metering/views.py:161#: dashboards/admin/metering/tabs.py:62 dashboards/admin/metering/views.py:178#: dashboards/admin/metering/tabs.py:63 dashboards/admin/metering/views.py:179#: dashboards/admin/metering/tabs.py:64 dashboards/admin/metering/views.py:180#: dashboards/admin/metering/tabs.py:65 dashboards/admin/metering/views.py:181#: dashboards/admin/metering/tabs.py:66 dashboards/admin/metering/views.py:182#: dashboards/admin/metering/tabs.py:67 dashboards/admin/metering/views.py:183#: dashboards/admin/metering/tabs.py:80 dashboards/admin/metering/views.py:120#: dashboards/admin/metering/tabs.py:88 dashboards/admin/metering/views.py:202#: dashboards/admin/metering/views.py:160#: dashboards/admin/metering/views.py:161#: dashboards/admin/metering/views.py:194",380,295
openstack%2Fopenstack-manuals~master~I5cbdfdee7c8c9137158607994f91e65a022fc799,openstack/openstack-manuals,master,I5cbdfdee7c8c9137158607994f91e65a022fc799,Rename directories 'images' to 'figures',MERGED,2015-01-12 16:54:35.000000000,2015-01-12 19:56:47.000000000,2015-01-12 19:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-01-12 16:54:35.000000000', 'files': ['doc/arch-design/figures/Multi-Site_shared_keystone_horizon_swift1.png', 'doc/arch-design/figures/Multi-Cloud_Priv-Pub2.png', 'doc/arch-design/figures/openstack_fullcover2014_1.jpg', 'doc/arch-design/figures/Multi-Cloud_Priv-Pub3.png', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/figures/Network_Cloud_Storage2.png', 'doc/arch-design/figures/Generic_CERN_Architecture.png', 'doc/arch-design/specialized/section_desktop_as_a_service_specialized.xml', 'doc/arch-design/figures/Generic_CERN_Example.png', 'doc/arch-design/figures/Compute_NSX.png', 'doc/arch-design/figures/Specialized_Hardware2.png', 'doc/arch-design/figures/General_Architecture1.png', 'doc/arch-design/figures/Multi-Site_Location_Local.png', 'doc/arch-design/figures/Storage_Hadoop.png', 'doc/arch-design/figures/Methodology.png', 'doc/arch-design/figures/Compute_Tech_Bin_Packing_General1.png', 'doc/arch-design/figures/Specialized_VDI1.png', 'doc/arch-design/figures/General_Architecture2.png', 'doc/arch-design/storage_focus/section_prescriptive_examples_storage_focus.xml', 'doc/arch-design/figures/Storage_Hadoop3.png', 'doc/arch-design/figures/Storage_Object.png', 'doc/arch-design/hybrid/section_prescriptive_examples_hybrid.xml', 'doc/arch-design/figures/Multi-Cloud_DR2.png', 'doc/arch-design/figures/Storage_Database_+_Object2.png', 'doc/arch-design/figures/Massively_Scalable_Cells_+_regions_+_azs.png', 'doc/arch-design/figures/Multi-Cloud_failover.png', 'doc/arch-design/multi_site/section_prescriptive_examples_multi_site.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/networking-guide/figures/dvr_diagram.png', 'doc/arch-design/massively_scalable/section_tech_considerations_massively_scalable.xml', 'doc/arch-design/specialized/section_multi_hypervisor_specialized.xml', 'doc/arch-design/figures/Multi-Cloud_failover2.png', 'doc/arch-design/figures/Multi-Cloud_Priv-AWS3.png', 'doc/arch-design/hybrid/section_architecture_hybrid.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone_horizon.png', 'doc/networking-guide/figures/deployment_architecture.png', 'doc/arch-design/figures/Storage_Database_+_Object3.png', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/figures/Multi-site_Geo_Redundant_LB.png', 'doc/arch-design/figures/region-example.png', 'doc/arch-design/specialized/section_openstack_on_openstack_specialized.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone1.png', 'doc/networking-guide/section_ha-dvr.xml', 'doc/arch-design/figures/Special_case_SDN_hosted.png', 'doc/arch-design/figures/Multi-Cloud_Priv-AWS4.png', 'doc/arch-design/figures/OPST_0008_Compute_12015337_0314cd-compute_cells_high.png', 'doc/arch-design/generalpurpose/section_prescriptive_example_general_purpose.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone.png', 'doc/arch-design/figures/Network_Web_Services1.png', 'doc/arch-design/figures/design-methodology.png', 'doc/arch-design/figures/General_Architecture3.png', 'doc/arch-design/multi_site/section_architecture_multi_site.xml', 'doc/arch-design/figures/Specialized_OOO.png', 'doc/arch-design/figures/Multi-Site_Customer_Edge.png', 'doc/arch-design/figures/packingexample-2.png', 'doc/arch-design/figures/Multi-Site_shared_keystone_horizon_swift.png', 'doc/arch-design/figures/arch-design.graffle', 'doc/arch-design/figures/Network_Cloud_Storage1.png', 'doc/arch-design/figures/Compute_Tech_Bin_Packing_CPU_optimized1.png', 'doc/arch-design/figures/Storage_Database_+_Object5.png', 'doc/arch-design/introduction/section_methodology.xml', 'doc/arch-design/specialized/section_hardware_specialized.xml', 'doc/arch-design/figures/Example_Compute_Heavy_Multi-Hypervisor_-_Architecture_4.png', 'doc/arch-design/figures/Example_General_Purpose_Architecture_w_Swift.png', 'doc/arch-design/figures/Special_case_SDN_external.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/96dcda0406dc5b093887464ef6800bcc566b73cf', 'message': ""Rename directories 'images' to 'figures'\n\nTo unify the directory structure used inside the DocBook directories\nall image files should be located inside a directory called 'figures'.\n\nChange-Id: I5cbdfdee7c8c9137158607994f91e65a022fc799\n""}]",0,146571,96dcda0406dc5b093887464ef6800bcc566b73cf,7,3,1,167,,,0,"Rename directories 'images' to 'figures'

To unify the directory structure used inside the DocBook directories
all image files should be located inside a directory called 'figures'.

Change-Id: I5cbdfdee7c8c9137158607994f91e65a022fc799
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/71/146571/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design/figures/Multi-Site_shared_keystone_horizon_swift1.png', 'doc/arch-design/figures/Multi-Cloud_Priv-Pub2.png', 'doc/arch-design/figures/openstack_fullcover2014_1.jpg', 'doc/arch-design/figures/Multi-Cloud_Priv-Pub3.png', 'doc/arch-design/specialized/section_software_defined_networking_specialized.xml', 'doc/arch-design/compute_focus/section_tech_considerations_compute_focus.xml', 'doc/arch-design/figures/Network_Cloud_Storage2.png', 'doc/arch-design/figures/Generic_CERN_Architecture.png', 'doc/arch-design/specialized/section_desktop_as_a_service_specialized.xml', 'doc/arch-design/figures/Generic_CERN_Example.png', 'doc/arch-design/figures/Compute_NSX.png', 'doc/arch-design/figures/Specialized_Hardware2.png', 'doc/arch-design/figures/General_Architecture1.png', 'doc/arch-design/figures/Multi-Site_Location_Local.png', 'doc/arch-design/figures/Storage_Hadoop.png', 'doc/arch-design/figures/Methodology.png', 'doc/arch-design/figures/Compute_Tech_Bin_Packing_General1.png', 'doc/arch-design/figures/Specialized_VDI1.png', 'doc/arch-design/figures/General_Architecture2.png', 'doc/arch-design/storage_focus/section_prescriptive_examples_storage_focus.xml', 'doc/arch-design/figures/Storage_Hadoop3.png', 'doc/arch-design/figures/Storage_Object.png', 'doc/arch-design/hybrid/section_prescriptive_examples_hybrid.xml', 'doc/arch-design/figures/Multi-Cloud_DR2.png', 'doc/arch-design/figures/Storage_Database_+_Object2.png', 'doc/arch-design/figures/Massively_Scalable_Cells_+_regions_+_azs.png', 'doc/arch-design/figures/Multi-Cloud_failover.png', 'doc/arch-design/multi_site/section_prescriptive_examples_multi_site.xml', 'doc/arch-design/compute_focus/section_prescriptive_examples_compute_focus.xml', 'doc/networking-guide/figures/dvr_diagram.png', 'doc/arch-design/massively_scalable/section_tech_considerations_massively_scalable.xml', 'doc/arch-design/specialized/section_multi_hypervisor_specialized.xml', 'doc/arch-design/figures/Multi-Cloud_failover2.png', 'doc/arch-design/figures/Multi-Cloud_Priv-AWS3.png', 'doc/arch-design/hybrid/section_architecture_hybrid.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone_horizon.png', 'doc/networking-guide/figures/deployment_architecture.png', 'doc/arch-design/figures/Storage_Database_+_Object3.png', 'doc/arch-design/network_focus/section_prescriptive_examples_network_focus.xml', 'doc/arch-design/figures/Multi-site_Geo_Redundant_LB.png', 'doc/arch-design/figures/region-example.png', 'doc/arch-design/specialized/section_openstack_on_openstack_specialized.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone1.png', 'doc/networking-guide/section_ha-dvr.xml', 'doc/arch-design/figures/Special_case_SDN_hosted.png', 'doc/arch-design/figures/Multi-Cloud_Priv-AWS4.png', 'doc/arch-design/figures/OPST_0008_Compute_12015337_0314cd-compute_cells_high.png', 'doc/arch-design/generalpurpose/section_prescriptive_example_general_purpose.xml', 'doc/arch-design/figures/Multi-Site_shared_keystone.png', 'doc/arch-design/figures/Network_Web_Services1.png', 'doc/arch-design/figures/design-methodology.png', 'doc/arch-design/figures/General_Architecture3.png', 'doc/arch-design/multi_site/section_architecture_multi_site.xml', 'doc/arch-design/figures/Specialized_OOO.png', 'doc/arch-design/figures/Multi-Site_Customer_Edge.png', 'doc/arch-design/figures/packingexample-2.png', 'doc/arch-design/figures/Multi-Site_shared_keystone_horizon_swift.png', 'doc/arch-design/figures/arch-design.graffle', 'doc/arch-design/figures/Network_Cloud_Storage1.png', 'doc/arch-design/figures/Compute_Tech_Bin_Packing_CPU_optimized1.png', 'doc/arch-design/figures/Storage_Database_+_Object5.png', 'doc/arch-design/introduction/section_methodology.xml', 'doc/arch-design/specialized/section_hardware_specialized.xml', 'doc/arch-design/figures/Example_Compute_Heavy_Multi-Hypervisor_-_Architecture_4.png', 'doc/arch-design/figures/Example_General_Purpose_Architecture_w_Swift.png', 'doc/arch-design/figures/Special_case_SDN_external.png']",66,96dcda0406dc5b093887464ef6800bcc566b73cf,images_to_figures,,,27,27
openstack%2Fmonasca-api~master~I5f4600e2311c78823cfe0e31032d55047b4ce4b7,openstack/monasca-api,master,I5f4600e2311c78823cfe0e31032d55047b4ce4b7,URL encode metric name when it is used as offset for metric list,MERGED,2015-01-12 18:22:37.000000000,2015-01-12 19:54:15.000000000,2015-01-12 19:54:15.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2015-01-12 18:22:37.000000000', 'files': ['src/main/java/monasca/api/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0a4f77e1b5ecfcb3a5b13cc8a6f334d3a4ade718', 'message': 'URL encode metric name when it is used as offset for metric list\n\nChange-Id: I5f4600e2311c78823cfe0e31032d55047b4ce4b7\n'}]",0,146594,0a4f77e1b5ecfcb3a5b13cc8a6f334d3a4ade718,7,4,1,12512,,,0,"URL encode metric name when it is used as offset for metric list

Change-Id: I5f4600e2311c78823cfe0e31032d55047b4ce4b7
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/94/146594/1 && git format-patch -1 --stdout FETCH_HEAD,['src/main/java/monasca/api/infrastructure/persistence/influxdb/MetricDefinitionInfluxDbRepositoryImpl.java'],1,0a4f77e1b5ecfcb3a5b13cc8a6f334d3a4ade718,,import static monasca.api.infrastructure.persistence.influxdb.Utils.urlDecodeUTF8; import static monasca.api.infrastructure.persistence.influxdb.Utils.urlEncodeUTF8; // offset comes in as url encoded. String decodedOffset = urlDecodeUTF8(offset); if (offset != null) { if (encodedMetricName.compareTo(decodedOffset) <= 0) { // Must url encode offset because it is part of a url. metricDefinition.setId(urlEncodeUTF8(encodedMetricName));, if (offset != null) { if (encodedMetricName.compareTo(offset) <= 0) { metricDefinition.setId(encodedMetricName);,10,2
openstack%2Fopenstack-manuals~master~I72465dc5ad41d7d24ea304630b70f51335133b86,openstack/openstack-manuals,master,I72465dc5ad41d7d24ea304630b70f51335133b86,Fix the hyperlink to the OpenStack Configuration Reference,MERGED,2015-01-09 22:33:31.000000000,2015-01-12 19:48:51.000000000,2015-01-12 19:48:50.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 8804}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-01-09 22:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e5dbdf527a5aadda2d7dd1e843ae9b77916034a6', 'message': 'Fixes bad link to the OpenStack Configuration Reference\nCloses-Bug:1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}, {'number': 2, 'created': '2015-01-12 16:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/659b972afa55688962bbe7c25ba5b017d05c3b9d', 'message': 'Fixes bad link to the OpenStack Configuration Reference\n\nCloses-Bug:1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}, {'number': 3, 'created': '2015-01-12 17:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cdbe975c5192118938a9bc8f35717032662dce67', 'message': 'This patch corrects the hyperlink to the OpenStack Configuration Reference as the current link is to the trunk version of the document but needs to link to the Juno version.\n\nCloses-Bug: #1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}, {'number': 4, 'created': '2015-01-12 17:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8c96f93db4baedf0e77a97361a308969c821d387', 'message': 'This patch corrects the hyperlink to the OpenStack Configuration Reference\n\nThe current link to the OpenStack Configuration Reference is to the trunk version of the document but needs to link to the Juno version.\n\nCloses-Bug: #1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}, {'number': 5, 'created': '2015-01-12 17:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b700684be0e973ee551a009ab16d10af007eae28', 'message': 'Fix the hyperlink to the OpenStack Configuration Reference\n\nThe current link to the OpenStack Configuration Reference is to the trunk version of the document but needs to link to the Juno version.\n\nCloses-Bug: #1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}, {'number': 6, 'created': '2015-01-12 18:44:14.000000000', 'files': ['doc/common/app_support.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4dd3183b204799511af8cd7dee1b2814a0966ec0', 'message': 'Fix the hyperlink to the OpenStack Configuration Reference\n\nThe current link to the OpenStack Configuration Reference is to the\ntrunk version of the document but needs to link to the Juno version.\n\nCloses-Bug: #1409145\n\nChange-Id: I72465dc5ad41d7d24ea304630b70f51335133b86\n'}]",2,146218,4dd3183b204799511af8cd7dee1b2814a0966ec0,23,6,6,8804,,,0,"Fix the hyperlink to the OpenStack Configuration Reference

The current link to the OpenStack Configuration Reference is to the
trunk version of the document but needs to link to the Juno version.

Closes-Bug: #1409145

Change-Id: I72465dc5ad41d7d24ea304630b70f51335133b86
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/146218/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/app_support.xml'],1,e5dbdf527a5aadda2d7dd1e843ae9b77916034a6,bug/1409145," xlink:href=""http://docs.openstack.org/juno/config-reference/content/"""," xlink:href=""http://docs.openstack.org/trunk/config-reference/content/""",1,1
openstack%2Fqa-specs~master~I97bc357e9b31bdde08506f38ff5bc399ac456f7f,openstack/qa-specs,master,I97bc357e9b31bdde08506f38ff5bc399ac456f7f,add bp:test-accounts-continued,MERGED,2014-12-05 09:35:35.000000000,2015-01-12 19:47:57.000000000,2015-01-12 19:47:55.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 8859}]","[{'number': 1, 'created': '2014-12-05 09:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/c6f082ba4ca0c599163d7fb5d746146e13c045ce', 'message': 'add bp:test-accounts-continued.rst\n\nChange-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f\n'}, {'number': 2, 'created': '2014-12-05 20:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/1efa2850d5f7f61265afdc2fd73a14f9557c6175', 'message': 'add bp:test-accounts-continued\n\nChange-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f\n'}, {'number': 3, 'created': '2014-12-05 20:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/d5cd63bfe3ad5a641f1d7de7cee078e67aadaa11', 'message': 'add bp:test-accounts-continued\n\nChange-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f\n'}, {'number': 4, 'created': '2014-12-08 20:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/28c0fd88bc78af8ca9acd56d53db909e30cbcb33', 'message': 'add bp:test-accounts-continued\n\nChange-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f\n'}, {'number': 5, 'created': '2014-12-11 16:48:16.000000000', 'files': ['specs/test-accounts-continued.rst'], 'web_link': 'https://opendev.org/openstack/qa-specs/commit/9bc2974f558b059252f7ecfbafb90833aa0353af', 'message': 'add bp:test-accounts-continued\n\nChange-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f\n'}]",13,139578,9bc2974f558b059252f7ecfbafb90833aa0353af,24,6,5,1921,,,0,"add bp:test-accounts-continued

Change-Id: I97bc357e9b31bdde08506f38ff5bc399ac456f7f
",git fetch https://review.opendev.org/openstack/qa-specs refs/changes/78/139578/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/test-accounts-continued.rst'],1,c6f082ba4ca0c599163d7fb5d746146e13c045ce,bp/test-accounts-continued,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ======================= Test accounts Continued ======================= https://blueprints.launchpad.net/tempest/+spec/test-accounts-continued Tempest test accounts management Problem description =================== The ""Test accounts"" spec provided support for preprovisioned accounts, as well as for those accounts to be configured in YAML format. There are a few limitations to the existing limitations: - all accounts must belong to the same network - all accounts must be of the same type, so we have a combination of accounts configured in tempest.conf and in accounts.yaml Proposed change =============== Extend the format of the accounts YAML file to support specifying the name and type of resources pre-provisioned for an account. Such resources are intended to be reused by tests, and shall not be cleaned-up. :: - credentials: username: 'user_1' tenant_name: 'test_tenant_1' password: 'test_password' resources: network: 'my_network' subnet: 'my_subnet' - credentials: username: 'user_2' (...) .. Extend the format of the accounts YAML file to support specifying the account type of an account. We may have an account type identifier, as well a list of roles. :: - credentials: username: 'admin' tenant_name: 'admin_tenant' password: 'admin_password' type: 'admin' roles: - admin - reseller .. Adapt the non pre-provisioned account scenario to also read accounts from the accounts YAML file, and deprecate any account information in tempest.conf beyond the name of account file. Provide a tool to be consumed by devstack to generate the pre-provisioned accounts and the corresponding YAML file. Alternatives ------------ The current implementation is functional but incomplete, so the only alternative is not to use it. Implementation ============== Assignee(s) ----------- Andrea Frittoli <andrea.frittoli@hp.com> Milestones ---------- Target Milestone for completion: Kilo-final Work Items ---------- - Extend the YAML file parser - Implement the non-cleanup of configure resources - Deprecate account configuration options - Read account info from YAML, with fallback to deprecated configuration options - Implement provisioning tool - Switch devstack and job definition to accounts YAML file Dependencies ============ None ",,107,0
openstack%2Fpython-solumclient~master~I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d,openstack/python-solumclient,master,I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d,"Adds ""solum assembly logs <assembly_id>"" command",MERGED,2014-10-27 22:09:38.000000000,2015-01-12 19:45:23.000000000,2015-01-12 19:45:22.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-10-27 22:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/f069f35dd0516f59afdb50432e7c140045cc8115', 'message': 'Adds ""solum assembly logs <assembly_id>"" command\n\nFields displayed in the table vary depending on the\nstorage method Solum is using for logs.\n\nChange-Id: I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d\n'}, {'number': 2, 'created': '2014-10-30 19:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/b50527e8b1a5d25351107090cd314da62416fd40', 'message': 'Adds ""solum assembly logs <assembly_id>"" command\n\nFields displayed in the table vary depending on the\nstorage method Solum is using for logs.\n\nChange-Id: I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d\n'}, {'number': 3, 'created': '2014-11-04 21:22:47.000000000', 'files': ['solumclient/solum.py', 'solumclient/tests/v1/test_assembly.py', 'solumclient/v1/assembly.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/70b3fb4eedceb98d9872876cf471019666428cc5', 'message': 'Adds ""solum assembly logs <assembly_id>"" command\n\nFields displayed in the table vary depending on the\nstorage method Solum is using for logs.\n\nChange-Id: I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d\n'}]",0,131292,70b3fb4eedceb98d9872876cf471019666428cc5,17,5,3,1375,,,0,"Adds ""solum assembly logs <assembly_id>"" command

Fields displayed in the table vary depending on the
storage method Solum is using for logs.

Change-Id: I4ff952483ad77640c9d6d6e0f61d243e4a3a5d7d
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/92/131292/2 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/solum.py', 'solumclient/v1/assembly.py']",2,f069f35dd0516f59afdb50432e7c140045cc8115,list-logs-calls, return self._list(url), return self._get(url),21,8
openstack%2Fpython-solumclient~master~Id381e164b55b2edd0342d782523f31426e857682,openstack/python-solumclient,master,Id381e164b55b2edd0342d782523f31426e857682,Added solum assembly logs command,MERGED,2014-09-17 18:53:38.000000000,2015-01-12 19:44:54.000000000,2015-01-12 19:44:54.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-09-17 18:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/4fc5f5945effc6c03c62a49179514a09539adab9', 'message': 'Added solum assembly logs command\n\nRelated-Bug: #1367902\n\nChange-Id: Id381e164b55b2edd0342d782523f31426e857682\n'}, {'number': 2, 'created': '2014-09-17 19:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/731f70597970acd65c872d5fd00ccbf94cc0d494', 'message': 'Added solum assembly logs command\n\nRelated-Bug: #1367902\n\nChange-Id: Id381e164b55b2edd0342d782523f31426e857682\n'}, {'number': 3, 'created': '2014-09-24 18:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/5d1ffa29b20315962ae80449be04b14c050fb78b', 'message': 'Added solum assembly logs command\n\nRelated-Bug: #1367902\n\nChange-Id: Id381e164b55b2edd0342d782523f31426e857682\n'}, {'number': 4, 'created': '2014-11-04 21:22:47.000000000', 'files': ['solumclient/solum.py', 'solumclient/tests/v1/test_assembly.py', 'solumclient/v1/assembly.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/15a6b7c6541585475500395ee208332e1e55d971', 'message': 'Added solum assembly logs command\n\nRelated-Bug: #1367902\n\nChange-Id: Id381e164b55b2edd0342d782523f31426e857682\n'}]",2,122222,15a6b7c6541585475500395ee208332e1e55d971,19,6,4,2506,,,0,"Added solum assembly logs command

Related-Bug: #1367902

Change-Id: Id381e164b55b2edd0342d782523f31426e857682
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/22/122222/4 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/solum.py', 'solumclient/tests/v1/test_assembly.py', 'solumclient/v1/assembly.py']",3,4fc5f5945effc6c03c62a49179514a09539adab9,list-logs-calls," def logs(self, **kwargs): url = self.build_url(base_url=""/v1"", **kwargs) url += '/logs/' return self._get(url) ",,87,0
openstack%2Fheat~stable%2Fjuno~Iac43aac547b602bf1689cd5000307abaacd65fca,openstack/heat,stable/juno,Iac43aac547b602bf1689cd5000307abaacd65fca,Remove mocking of timeutils.utcnow,MERGED,2015-01-12 16:52:02.000000000,2015-01-12 19:43:11.000000000,2015-01-12 19:43:10.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 4328}, {'_account_id': 7385}, {'_account_id': 9542}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-01-12 16:52:02.000000000', 'files': ['heat/tests/test_autoscaling.py', 'heat/tests/test_watch.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c5346cd70e79d6eb03dae8dadd08e477ba1f3e9c', 'message': ""Remove mocking of timeutils.utcnow\n\nWith the move out of the namespace package of oslo.utils, it seems that\nmocking utcnow doesn't work as expected. Fortunately there is a\nset_time_override function that can be used to replace time during\ntests.\n\nConflicts:\n        heat/tests/test_watch.py\n\nNOTE(mriedem): This also fixes another instance in test_autoscaling\nwhich is only on stable/juno (not master).\n\nChange-Id: Iac43aac547b602bf1689cd5000307abaacd65fca\nCloses-Bug: #1408704\n(cherry picked from commit 15c18a7e33e0339074360da3b70d58d914e0766a)\n""}]",0,146570,c5346cd70e79d6eb03dae8dadd08e477ba1f3e9c,11,6,1,6873,,,0,"Remove mocking of timeutils.utcnow

With the move out of the namespace package of oslo.utils, it seems that
mocking utcnow doesn't work as expected. Fortunately there is a
set_time_override function that can be used to replace time during
tests.

Conflicts:
        heat/tests/test_watch.py

NOTE(mriedem): This also fixes another instance in test_autoscaling
which is only on stable/juno (not master).

Change-Id: Iac43aac547b602bf1689cd5000307abaacd65fca
Closes-Bug: #1408704
(cherry picked from commit 15c18a7e33e0339074360da3b70d58d914e0766a)
",git fetch https://review.opendev.org/openstack/heat refs/changes/70/146570/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_autoscaling.py', 'heat/tests/test_watch.py']",2,c5346cd70e79d6eb03dae8dadd08e477ba1f3e9c,bug/1408704, timeutils.set_time_override(now) self.addCleanup(timeutils.clear_time_override) timeutils.set_time_override(now) self.addCleanup(timeutils.clear_time_override) timeutils.set_time_override(now) self.addCleanup(timeutils.clear_time_override)," self.m.StubOutWithMock(timeutils, 'utcnow') timeutils.utcnow().MultipleTimes().AndReturn(now) self.m.StubOutWithMock(timeutils, 'utcnow') timeutils.utcnow().MultipleTimes().AndReturn(now) self.m.ReplayAll() self.m.StubOutWithMock(timeutils, 'utcnow') timeutils.utcnow().MultipleTimes().AndReturn(now) self.m.ReplayAll()",12,14
openstack%2Fnova~master~I161eccc4ea48a21a80d689f6a328ca95cace2e6e,openstack/nova,master,I161eccc4ea48a21a80d689f6a328ca95cace2e6e,Make ec2 auth support v4 signature format,MERGED,2015-01-09 16:07:51.000000000,2015-01-12 19:36:30.000000000,2015-01-12 17:27:02.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 5170}, {'_account_id': 6661}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-09 16:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/049a4c5a457a562e24920c4f468a3c2adb49d8fa', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nPartial-Bug: #1408987\n'}, {'number': 2, 'created': '2015-01-09 16:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45ebd08a13ed0d373bc6670cedfac27012133320', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nPartial-Bug: #1408987\n'}, {'number': 3, 'created': '2015-01-09 16:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d4fe2ef0d6245d21a417cf5ec0d22e8c9501722', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nPartial-Bug: #1408987\n'}, {'number': 4, 'created': '2015-01-09 16:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e84fe8b26f0b61ba27b7b2251d6390a1e8d669f2', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 5, 'created': '2015-01-09 16:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c90f001554b8e075dad8f8e1cbd66bf2c8bb940d', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 6, 'created': '2015-01-09 16:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cf41c82c70dea338925e8ab9dcf7e2ef6a98348', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 7, 'created': '2015-01-09 17:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5594aaa307c6469e5e7a03f7e2a271a98590377', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nRemoves the boto requirements pin so we can prove the fix works.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 8, 'created': '2015-01-09 22:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eea6afa5fa355aeb5300afa7c37eefab88325e53', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nRemoves the boto requirements pin so we can prove the fix works.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 9, 'created': '2015-01-10 00:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bfda2534b319a7a044696f71efb0afc3ffe5621', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nRemoves the boto requirements pin so we can prove the fix works.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 10, 'created': '2015-01-11 06:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ced009e96c573640240c15a40bbe79bbf3ac5dd2', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nRemoves the boto requirements pin so we can prove the fix works.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}, {'number': 11, 'created': '2015-01-12 15:00:05.000000000', 'files': ['nova/api/ec2/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f7b1af9e13df728d086047f6763bd98cb2cad1b2', 'message': 'Make ec2 auth support v4 signature format\n\nExtract the signature and access key via whatever method is needed\nfor the version of the request (e.g headers for v4), and add the\nheaders and hashed body, which is required for keystone to calculate\nthe correct v4 signature when validating the request.\n\nChange-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e\nCloses-Bug: #1408987\n'}]",2,146124,f7b1af9e13df728d086047f6763bd98cb2cad1b2,60,12,11,4328,,,0,"Make ec2 auth support v4 signature format

Extract the signature and access key via whatever method is needed
for the version of the request (e.g headers for v4), and add the
headers and hashed body, which is required for keystone to calculate
the correct v4 signature when validating the request.

Change-Id: I161eccc4ea48a21a80d689f6a328ca95cace2e6e
Closes-Bug: #1408987
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/146124/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/ec2/__init__.py'],1,049a4c5a457a562e24920c4f468a3c2adb49d8fa,bug/1408987,"import hashlib def _get_signature(self, req): """""" Extract the signature from the request, this can be a get/post variable or for v4 also in a header called 'Authorization' - params['Signature'] == version 0,1,2,3 - params['X-Amz-Signature'] == version 4 - header 'Authorization' == version 4 """""" sig = req.params.get('Signature') or req.params.get('X-Amz-Signature') if sig is None and 'Authorization' in req.headers: auth_str = req.headers['Authorization'] sig = auth_str.partition(""Signature="")[2].split(',')[0] return sig def _get_access(self, req): """""" Extract the access key identifier, for v 0/1/2/3 this is passed as the AccessKeyId parameter, for version4 it is either and X-Amz-Credential parameter or a Credential= field in the 'Authorization' header string """""" access = req.params.get('AWSAccessKeyId') if access is None: cred_param = req.params.get('X-Amz-Credential') if cred_param: access = cred_param.split(""/"")[0] if access is None and 'Authorization' in req.headers: auth_str = req.headers['Authorization'] cred_str = auth_str.partition(""Credential="")[2].split(',')[0] access = cred_str.split(""/"")[0] return access signature = self._get_signature(req) access = self._get_access(req) auth_params.pop('Signature', None) body_hash = hashlib.sha256(req.body).hexdigest() 'headers': req.headers, 'body_hash': body_hash", signature = req.params.get('Signature') access = req.params.get('AWSAccessKeyId') auth_params.pop('Signature') ,43,3
openstack%2Fsolum~master~Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1,openstack/solum,master,Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1,Prep work for converting code from shell to python,ABANDONED,2014-11-01 01:05:54.000000000,2015-01-12 19:33:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-11-01 01:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ab925bc15ff7e3e4cb2d321e7e38b6a578dd2ecb', 'message': 'Prep work for converting code from shell to python\n\nIncludes some work to make language pack handlers pluggable.\n\nChange-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1\n'}, {'number': 2, 'created': '2014-11-04 20:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/12469fd7655a022fc7927c3986fe9c36f9454a5f', 'message': 'Prep work for converting code from shell to python\n\nIncludes some work to make language pack handlers pluggable.\n\nChange-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1\n'}, {'number': 3, 'created': '2014-11-06 01:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/bbe0c8eea75d6672c97ecb1361367f202d86f9dc', 'message': 'Prep work for converting code from shell to python\n\nIncludes some work to make language pack handlers pluggable.\n\nChange-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1\n'}, {'number': 4, 'created': '2014-11-06 20:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/94367fb0a29f8cca9e6a93be8dc09231d977d11a', 'message': 'Prep work for converting code from shell to python\n\nIncludes some work to make language pack handlers pluggable.\n\nChange-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1\n'}, {'number': 5, 'created': '2014-11-07 02:19:52.000000000', 'files': ['contrib/lp_builders/common/base_lp_plugin.py', 'contrib/lp_builders/common/utils.py', 'functionaltests/contrib/lp_builders/common/test_shell.py', 'functionaltests/contrib/lp_builders/common/test_utils.py', 'contrib/lp_builders/__init__.py', 'functionaltests/contrib/lp_builders/common/__init__.py', 'solum/common/app_info.py', 'contrib/lp_builders/common/shell.py', 'contrib/__init__.py', 'contrib/lp_builders/common/__init__.py', 'functionaltests/contrib/__init__.py', 'functionaltests/contrib/lp_builders/__init__.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/c0090121daf9f1e0af366db3cfe4f2a2ab467a74', 'message': 'Prep work for converting code from shell to python\n\nIncludes some work to make language pack handlers pluggable.\n\nChange-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1\n'}]",39,132381,c0090121daf9f1e0af366db3cfe4f2a2ab467a74,21,5,5,11324,,,0,"Prep work for converting code from shell to python

Includes some work to make language pack handlers pluggable.

Change-Id: Ifa938e323f7fd92b5dd1912ae1359da4bd0347b1
",git fetch https://review.opendev.org/openstack/solum refs/changes/81/132381/4 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp_builders/common/base_lp_plugin.py', 'contrib/lp_builders/common/utils.py', 'functionaltests/contrib/lp_builders/common/test_shell.py', 'functionaltests/contrib/lp_builders/common/test_utils.py', 'contrib/lp_builders/__init__.py', 'functionaltests/contrib/lp_builders/common/__init__.py', 'solum/common/app_info.py', 'contrib/lp_builders/common/shell.py', 'contrib/__init__.py', 'contrib/lp_builders/common/__init__.py', 'functionaltests/contrib/__init__.py', 'functionaltests/contrib/lp_builders/__init__.py']",12,ab925bc15ff7e3e4cb2d321e7e38b6a578dd2ecb,prep-shell-to-py,,,538,0
openstack%2Foctavia~master~Iba7c99f5c824018ab78df6aca482955c32b03a40,openstack/octavia,master,Iba7c99f5c824018ab78df6aca482955c32b03a40,Spec defining the networking driver interface,MERGED,2014-11-19 03:39:48.000000000,2015-01-12 19:29:49.000000000,2015-01-12 19:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 10273}, {'_account_id': 10806}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-11-19 03:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/33a281b7809f9b7892eab4c646b7d8ff233f585f', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 2, 'created': '2014-11-20 23:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7f71420e5d79191e13c77d658e0103e5153ea47f', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 3, 'created': '2014-12-03 19:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/63a427ea49e3ed9474f108e062e444a9b69de3c4', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 4, 'created': '2014-12-17 20:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e342d3d855fbc6170d8f7a4d9c30cf5918ed341e', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 5, 'created': '2014-12-17 23:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3e92620e20fea94d2edf6e1422998348d9b38a16', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 6, 'created': '2014-12-18 00:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/becb327383f19f9a733d975aed8a0e7214a10d0e', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 7, 'created': '2014-12-18 05:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b60ccf5cd11c6ad24a2d734b131f8efc6a1a7e55', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 8, 'created': '2014-12-21 06:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/15340763581affae38a4ffed89e9cc683fc44d2b', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 9, 'created': '2014-12-27 00:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cc3a13fbc67c610d3aa3c4077b6c313b5fbba22b', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 10, 'created': '2015-01-09 21:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/06ede5f91e2187b4e7bc2031518d21418e980741', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 11, 'created': '2015-01-10 06:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ae42bca35417331c9920dc04d38c60708464cb88', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 12, 'created': '2015-01-10 07:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4e383b943ba99b0aa77421500bbad9cdd51b1c4f', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}, {'number': 13, 'created': '2015-01-11 06:43:02.000000000', 'files': ['specs/version0.5/network-driver-interface.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/8721189947d7702b56700902e3b3c174a6fce7a0', 'message': 'Spec defining the networking driver interface\n\nChange-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40\nImplements: bp/network-driver-interface\n'}]",40,135495,8721189947d7702b56700902e3b3c174a6fce7a0,76,9,13,6951,,,0,"Spec defining the networking driver interface

Change-Id: Iba7c99f5c824018ab78df6aca482955c32b03a40
Implements: bp/network-driver-interface
",git fetch https://review.opendev.org/openstack/octavia refs/changes/95/135495/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/version0.5/network-driver-interface.rst'],1,33a281b7809f9b7892eab4c646b7d8ff233f585f,135495,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================== Network Driver Interface ======================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/octavia/+spec/network-driver-interface We need a generic interface in which to create networking resources. Octavia cannot just assume Neutron will be used, it must also support nova-network as much as possible. Problem description =================== There is a need to define a generic interface for a networking service. An Octavia controller should not know what networking service is being used underneath. It should only know an interface. This interface is needed to support neutron, nova-network, and any other networking service. Proposed change =============== New data model classes defined in octavia.common.data_models module * class Network * id * name * cidr * class Port * id * network_id * name * sec_groups * fixed_ips * class FloatingIp * id * network_id * port_id * ip_address * class SharedIp * id * network_id * port_ids * ip_address New Exceptions defined in the octavia.network package: * NetworkException - Base Exception * NetworkCreationException * NetworkNotFoundException * PortCreationException * PortNotFoundException * FloatingIpCreationException * FloatingIpNotFoundException * SharedIpCreationException * SharedIpNotFoundException The interface will be the following: class AbstractNetworkDriver * create_network(name, cidr) * name = user friendly name * cidr = ip allocation range in cidr format * returns Network instance * raises NetworkCreationException * create_port(network_id, name=None, sec_groups=None, fixed_ips=None) * network_id = the id of the network to create the port * name = user friendly name of port * sec_groups = security groups that should be on this port * fixed_ips = specifically define the fixed_ips wanted on this port * returns Port instance * raises PortCreationException * create_floating_ip(network_id, port_id=None) * network_id = id of network to create the floating ip on. Must be an external network. * port_id = id of port to forward traffic to * returns FloatingIp instance * raises FloatingIpCreationException * create_shared_ip(network_id, port_ids) * network_id = id of network to create the shared ip on * port_ids = list of port ids that will share the ip * returns SharedIp instance * raises SharedIpCreationException * get_network(network_id) * network_id = id of network to retrieve * returns Network instance * raises NetworkNotFoundException * get_port(port_id) * port_id = id of port to retrieve * returns Port instance * raises PortNotFoundException * get_floating_ip(floating_ip_id): * floating_ip_id = id of floating ip to retrieve * returns FloatingIp instance * raises FloatingIpNotFoundException * get_shared_ip(shared_ip_id): * shared_ip_id = id of shared ip to retrieve * returns SharedIp instance * raises SharedIpNotFoundException Unresolved: * Should there be methods to attach Amphorae to the subnets of pool members in this interface or should that be the job of compute/nova? * Who owns these network resources? Service account or the user? * Can a service account created resource link itself to a user created resource? * Example: user creates subnet, wants to add pool member on that subnet to be load balanced. Can Octavia create a port on this user's subnet if Octavia is using a service account? * Does Octavia create and link floating ips to neutron ports to public connectivity? What is the limit on orchestration? What if a user doesn't want to relinquish the ip on the floating ip? Alternatives ------------ * Straight Neutron Interface (networks, subnets, ports, floatingips) * Straight Nova-Network Interface (network, fixed_ips, floatingips) Data model impact ----------------- There will probably be some database changes once this is finalized. I will update this section when that happens. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- This may require a service account to create network resources. Then again, it might be best to create these network resources on behalf of the user. Developer impact ---------------- This will be creating an interface in which other code will be creating network resources. Implementation ============== Assignee(s) ----------- brandon-logan Work Items ---------- Define interface Dependencies ============ None Testing ======= None Documentation Impact ==================== Just docstrings on methods. References ========== None ",,204,0
openstack%2Fsolum~master~Ieee6b4214d084e2c73e649674de4370fafdb93db,openstack/solum,master,Ieee6b4214d084e2c73e649674de4370fafdb93db,Dynamically load language pack plugins,ABANDONED,2014-11-04 20:03:00.000000000,2015-01-12 19:21:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-11-04 20:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4f299611cf41f9beeaab0189db5f535f1dc929bd', 'message': 'Dynamically load language pack plugins\n\nChange-Id: Ieee6b4214d084e2c73e649674de4370fafdb93db\n'}, {'number': 2, 'created': '2014-11-06 01:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8b32136510b66d9c4755d990277927f0a9e158b5', 'message': 'Dynamically load language pack plugins\n\nChange-Id: Ieee6b4214d084e2c73e649674de4370fafdb93db\n'}, {'number': 3, 'created': '2014-11-06 20:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/69798033cf3bfa81085e175aad365c50ffc357a7', 'message': 'Dynamically load language pack plugins\n\nChange-Id: Ieee6b4214d084e2c73e649674de4370fafdb93db\n'}, {'number': 4, 'created': '2014-11-07 02:19:52.000000000', 'files': ['solum/worker/lp_handler.py', 'functionaltests/worker/test_lp_handler.py', 'functionaltests/worker/__init__.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/4cbbbd991067cfd7b425a8e53eee3d7b47d9e1ae', 'message': 'Dynamically load language pack plugins\n\nChange-Id: Ieee6b4214d084e2c73e649674de4370fafdb93db\n'}]",3,132718,4cbbbd991067cfd7b425a8e53eee3d7b47d9e1ae,13,4,4,11324,,,0,"Dynamically load language pack plugins

Change-Id: Ieee6b4214d084e2c73e649674de4370fafdb93db
",git fetch https://review.opendev.org/openstack/solum refs/changes/18/132718/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/lp_handler.py', 'functionaltests/worker/test_lp_handler.py', 'functionaltests/worker/__init__.py']",3,4f299611cf41f9beeaab0189db5f535f1dc929bd,prep-shell-to-py,,,252,0
openstack%2Fsolum~master~Ia229e03454e8bad5996f153c48e9696dde62ef09,openstack/solum,master,Ia229e03454e8bad5996f153c48e9696dde62ef09,WIP: Dockerfile/docker and Cedarish/docker LP plugins,ABANDONED,2014-11-06 01:48:25.000000000,2015-01-12 18:56:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-11-06 01:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/a3d47a74ed2b1c5f8a70191b0bc949fa83e5f04d', 'message': 'WIP: Dockerfile/docker and Cedarish/docker LP plugins\n\nChange-Id: Ia229e03454e8bad5996f153c48e9696dde62ef09\n'}, {'number': 2, 'created': '2014-11-06 20:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e4baa786cccfe1c2138d1f991f757c14669e76d1', 'message': 'WIP: Dockerfile/docker and Cedarish/docker LP plugins\n\nChange-Id: Ia229e03454e8bad5996f153c48e9696dde62ef09\n'}, {'number': 3, 'created': '2014-11-07 02:19:52.000000000', 'files': ['contrib/lp_builders/plugins/cedarish-docker/prepare', 'contrib/lp_builders/plugins/cedarish-docker/__init__.py', 'contrib/lp_builders/plugins/cedarish-docker/cedarish_docker_plugin.py', 'contrib/lp_builders/plugins/dockerfile-docker/prepare', 'contrib/lp_builders/plugins/dockerfile-docker/docker_plugin.py', 'contrib/lp_builders/plugins/__init__.py', 'contrib/lp_builders/plugins/dockerfile-docker/__init__.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/a7a728507b138a63684795d5c197864a57880c44', 'message': 'WIP: Dockerfile/docker and Cedarish/docker LP plugins\n\nChange-Id: Ia229e03454e8bad5996f153c48e9696dde62ef09\n'}]",8,132933,a7a728507b138a63684795d5c197864a57880c44,10,3,3,11324,,,0,"WIP: Dockerfile/docker and Cedarish/docker LP plugins

Change-Id: Ia229e03454e8bad5996f153c48e9696dde62ef09
",git fetch https://review.opendev.org/openstack/solum refs/changes/33/132933/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp_builders/plugins/cedarish-docker/prepare', 'contrib/lp_builders/plugins/cedarish-docker/__init__.py', 'contrib/lp_builders/plugins/cedarish-docker/cedarish_docker_plugin.py', 'contrib/lp_builders/plugins/dockerfile-docker/prepare', 'contrib/lp_builders/plugins/dockerfile-docker/docker_plugin.py', 'contrib/lp_builders/plugins/__init__.py', 'contrib/lp_builders/plugins/dockerfile-docker/__init__.py']",7,a3d47a74ed2b1c5f8a70191b0bc949fa83e5f04d,prep-shell-to-py,,,218,0
openstack%2Fopenstack-manuals~master~If5d561c0e7e10c9245946f5968ff0f3997bbd50b,openstack/openstack-manuals,master,If5d561c0e7e10c9245946f5968ff0f3997bbd50b,change to layer 2 in OpenStack networking guide,MERGED,2015-01-12 17:46:21.000000000,2015-01-12 18:48:27.000000000,2015-01-12 18:48:26.000000000,"[{'_account_id': 3}, {'_account_id': 3114}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2015-01-12 17:46:21.000000000', 'files': ['doc/networking-guide/section_intro-tunnel.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3de8d30f7beb8936041381415a1cf751901401d7', 'message': 'change to layer 2 in OpenStack networking guide\n\ntypo\n\nChange-Id: If5d561c0e7e10c9245946f5968ff0f3997bbd50b\nCloses-Bug: #1409823\n'}]",0,146582,3de8d30f7beb8936041381415a1cf751901401d7,8,4,1,9382,,,0,"change to layer 2 in OpenStack networking guide

typo

Change-Id: If5d561c0e7e10c9245946f5968ff0f3997bbd50b
Closes-Bug: #1409823
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/146582/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/section_intro-tunnel.xml'],1,3de8d30f7beb8936041381415a1cf751901401d7,layer2, <para>A VLAN partitions a single layer-2 network into multiple isolated, <para>A VLAN paritions a single layer-2 network into multiple isolated,1,1
openstack%2Frally~master~I61c3b948c76f95b46194141de31861056153bcfc,openstack/rally,master,I61c3b948c76f95b46194141de31861056153bcfc,fix devstack URL,MERGED,2015-01-12 14:48:44.000000000,2015-01-12 18:48:12.000000000,2015-01-12 18:48:05.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8367}, {'_account_id': 14135}]","[{'number': 1, 'created': '2015-01-12 14:48:44.000000000', 'files': ['doc/source/installation.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/cfac0e012afc2cdbb458912f0604970e38b7f6a6', 'message': ""fix devstack URL\n\nfix the following error\nfatal: repository 'https://git.openstack.org/cgit/openstack-dev/devstack/' not found\n\nChange-Id: I61c3b948c76f95b46194141de31861056153bcfc\n""}]",0,146480,cfac0e012afc2cdbb458912f0604970e38b7f6a6,14,5,1,8108,,,0,"fix devstack URL

fix the following error
fatal: repository 'https://git.openstack.org/cgit/openstack-dev/devstack/' not found

Change-Id: I61c3b948c76f95b46194141de31861056153bcfc
",git fetch https://review.opendev.org/openstack/rally refs/changes/80/146480/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/installation.rst'],1,cfac0e012afc2cdbb458912f0604970e38b7f6a6,fix-devstack-url, git clone https://git.openstack.org/openstack-dev/devstack, git clone https://git.openstack.org/cgit/openstack-dev/devstack,1,1
openstack%2Fopenstack-manuals~master~Ib65dd1dc746b0c52ca24c4ad4b08e99b9327dd8b,openstack/openstack-manuals,master,Ib65dd1dc746b0c52ca24c4ad4b08e99b9327dd8b,change to ch_intro in networking guide,MERGED,2015-01-12 18:13:45.000000000,2015-01-12 18:47:14.000000000,2015-01-12 18:47:13.000000000,"[{'_account_id': 3}, {'_account_id': 3114}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 8804}]","[{'number': 1, 'created': '2015-01-12 18:13:45.000000000', 'files': ['doc/networking-guide/ch_intro.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/121fd9080c62a332912f50ce795321cc129627de', 'message': ""change to ch_intro in networking guide\n\nremoved however, didn't make sense\n\nChange-Id: Ib65dd1dc746b0c52ca24c4ad4b08e99b9327dd8b\n""}]",0,146591,121fd9080c62a332912f50ce795321cc129627de,9,5,1,9382,,,0,"change to ch_intro in networking guide

removed however, didn't make sense

Change-Id: Ib65dd1dc746b0c52ca24c4ad4b08e99b9327dd8b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/91/146591/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_intro.xml'],1,121fd9080c62a332912f50ce795321cc129627de,ch_intro_net," host to run centralized Compute components, you can"," host to run centralized Compute components, however, you can",1,1
openstack%2Fsolum~master~I65fe7c5bf7d69980b2d52334e574e6647b5d6a98,openstack/solum,master,I65fe7c5bf7d69980b2d52334e574e6647b5d6a98,WIP: Solum worker changes to use LP plugins,ABANDONED,2014-11-06 20:44:05.000000000,2015-01-12 18:45:14.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-11-06 20:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/051aecd26e912b5bf66bd63121720f012ac664ab', 'message': 'WIP: Solum worker changes to use LP plugins\n\nChange-Id: I65fe7c5bf7d69980b2d52334e574e6647b5d6a98\n'}, {'number': 2, 'created': '2014-11-07 02:19:52.000000000', 'files': ['solum/worker/api.py', 'solum/worker/handlers/shell.py', 'solum/builder/handlers/image_handler.py', 'solum/worker/handlers/noop.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/api/handlers/assembly_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/14f1789c04e379bf27b5101aae23203c23d0212d', 'message': 'WIP: Solum worker changes to use LP plugins\n\nChange-Id: I65fe7c5bf7d69980b2d52334e574e6647b5d6a98\n'}]",5,133111,14f1789c04e379bf27b5101aae23203c23d0212d,9,4,2,11324,,,0,"WIP: Solum worker changes to use LP plugins

Change-Id: I65fe7c5bf7d69980b2d52334e574e6647b5d6a98
",git fetch https://review.opendev.org/openstack/solum refs/changes/11/133111/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/worker/api.py', 'solum/worker/handlers/shell.py', 'solum/builder/handlers/image_handler.py', 'solum/worker/handlers/noop.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/api/handlers/assembly_handler.py']",6,051aecd26e912b5bf66bd63121720f012ac664ab,prep-shell-to-py,"from solum.common import app_info def _build_artifact(self, assem, artifact, commit_sha='', app_obj = app_info.AppInfo( api.API(context=self.context).build(app_obj)"," def _build_artifact(self, assem, artifact, verb='build', commit_sha='', api.API(context=self.context).perform_action( verb=verb,",97,268
openstack%2Fironic~master~Ib78a761de9b54ae2ef16301942b0534c89f90de3,openstack/ironic,master,Ib78a761de9b54ae2ef16301942b0534c89f90de3,Updated from global requirements,MERGED,2015-01-09 18:27:59.000000000,2015-01-12 18:37:05.000000000,2015-01-12 18:37:02.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6618}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-01-09 18:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/205ad869dc7acc974d0755410ec1441f0bb21e4e', 'message': 'Updated from global requirements\n\nChange-Id: Ib78a761de9b54ae2ef16301942b0534c89f90de3\n'}, {'number': 2, 'created': '2015-01-10 22:42:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/15fe4b0421fdf79b4663208f82cca2690a12db94', 'message': 'Updated from global requirements\n\nChange-Id: Ib78a761de9b54ae2ef16301942b0534c89f90de3\n'}]",0,146156,15fe4b0421fdf79b4663208f82cca2690a12db94,15,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ib78a761de9b54ae2ef16301942b0534c89f90de3
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/146156/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,205ad869dc7acc974d0755410ec1441f0bb21e4e,openstack/requirements,oslo.utils>=1.2.0 # Apache-2.0,oslo.utils>=1.1.0 # Apache-2.0,1,1
openstack%2Fneutron-lbaas~master~I0646a26baf581019177e8ac18122faf1667fe356,openstack/neutron-lbaas,master,I0646a26baf581019177e8ac18122faf1667fe356,Rename array of LB constants to better align with usage,MERGED,2015-01-08 00:55:33.000000000,2015-01-12 18:25:14.000000000,2015-01-12 18:25:12.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 10850}, {'_account_id': 11302}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2015-01-08 00:55:33.000000000', 'files': ['neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/99c03513c5f037b735623b4eca94d10e0dd224b5', 'message': 'Rename array of LB constants to better align with usage\n\nThis is a promised follow-up due to review feedback\n\nChange-Id: I0646a26baf581019177e8ac18122faf1667fe356\n'}]",0,145648,99c03513c5f037b735623b4eca94d10e0dd224b5,11,8,1,10980,,,0,"Rename array of LB constants to better align with usage

This is a promised follow-up due to review feedback

Change-Id: I0646a26baf581019177e8ac18122faf1667fe356
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/48/145648/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py'],1,99c03513c5f037b735623b4eca94d10e0dd224b5,fix_constants_naming,MEMBER_STATUSES = plugin_constants.ACTIVE_PENDING_STATUSES + ( return member.status in MEMBER_STATUSES and member.admin_state_up,ACTIVE_PENDING_STATUSES = plugin_constants.ACTIVE_PENDING_STATUSES + ( return member.status in ACTIVE_PENDING_STATUSES and member.admin_state_up,2,2
openstack%2Fpython-saharaclient~master~Ica8cf4e8ec058fa0764e69945609f2a19effb840,openstack/python-saharaclient,master,Ica8cf4e8ec058fa0764e69945609f2a19effb840,Fix for sahara CLI,MERGED,2015-01-11 12:25:58.000000000,2015-01-12 18:20:26.000000000,2015-01-12 18:20:23.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 12039}]","[{'number': 1, 'created': '2015-01-11 12:25:58.000000000', 'files': ['saharaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/388ba75fb6b42e385151b29f24a1f0f180bd8260', 'message': ""Fix for sahara CLI\n\nSahara CLI did not work because 'safe_encode' and 'safe_decode'\nmethods have been moved from 'oslo.utils.strutils' module\nto 'oslo.utils.encodeutils' module\n\nChange-Id: Ica8cf4e8ec058fa0764e69945609f2a19effb840\nCloses-bug: #1409432\n""}]",0,146317,388ba75fb6b42e385151b29f24a1f0f180bd8260,9,5,1,7710,,,0,"Fix for sahara CLI

Sahara CLI did not work because 'safe_encode' and 'safe_decode'
methods have been moved from 'oslo.utils.strutils' module
to 'oslo.utils.encodeutils' module

Change-Id: Ica8cf4e8ec058fa0764e69945609f2a19effb840
Closes-bug: #1409432
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/17/146317/1 && git format-patch -1 --stdout FETCH_HEAD,['saharaclient/shell.py'],1,388ba75fb6b42e385151b29f24a1f0f180bd8260,bug/1409432,"from oslo_utils import encodeutils from oslo_utils import strutils OpenStackSaharaShell().main(map(encodeutils.safe_decode, sys.argv[1:])) print(""ERROR: %s"" % encodeutils.safe_encode(six.text_type(e)),","from oslo.utils import strutils OpenStackSaharaShell().main(map(strutils.safe_decode, sys.argv[1:])) print(""ERROR: %s"" % strutils.safe_encode(six.text_type(e)),",5,3
openstack%2Fpython-openstackclient~master~I9fce66677affa396b6a12afea76e87cab9215a58,openstack/python-openstackclient,master,I9fce66677affa396b6a12afea76e87cab9215a58,fix some small issues in catalog show,MERGED,2015-01-12 04:54:33.000000000,2015-01-12 18:14:44.000000000,2015-01-12 18:14:44.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-12 04:54:33.000000000', 'files': ['openstackclient/identity/v2_0/catalog.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a8f60a8aa1c8cbbf0d1384131854a422705e7c78', 'message': ""fix some small issues in catalog show\n\nI think there are three issues we should fix:\n1. wrong indentation of 'continue'\n2. currently, name is optional for service, but according to the\n   currrent logic, if a service doesn't have name attribute we will\n   select it anyway\n3. we always loop all catalogs\n\nChange-Id: I9fce66677affa396b6a12afea76e87cab9215a58\n""}]",0,146371,a8f60a8aa1c8cbbf0d1384131854a422705e7c78,9,4,1,9101,,,0,"fix some small issues in catalog show

I think there are three issues we should fix:
1. wrong indentation of 'continue'
2. currently, name is optional for service, but according to the
   currrent logic, if a service doesn't have name attribute we will
   select it anyway
3. we always loop all catalogs

Change-Id: I9fce66677affa396b6a12afea76e87cab9215a58
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/71/146371/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/identity/v2_0/catalog.py'],1,a8f60a8aa1c8cbbf0d1384131854a422705e7c78,catalog_show, if (service.get('name') == parsed_args.service or service.get('type') == parsed_args.service): data = service data['endpoints'] = _format_endpoints(data['endpoints']) if 'endpoints_links' in data: data.pop('endpoints_links') break, if ( 'name' in service and service['name'] != parsed_args.service and 'type' in service and service['type'] != parsed_args.service ): continue data = service data['endpoints'] = _format_endpoints(data['endpoints']) if 'endpoints_links' in data: data.pop('endpoints_links'),7,12
openstack%2Fpython-openstackclient~master~I8cb90e0d5aca58c4992271e007af91f8cf782643,openstack/python-openstackclient,master,I8cb90e0d5aca58c4992271e007af91f8cf782643,Add versioning to the docs that missed it,MERGED,2015-01-10 00:13:28.000000000,2015-01-12 18:14:32.000000000,2015-01-12 18:14:31.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 9101}]","[{'number': 1, 'created': '2015-01-10 00:13:28.000000000', 'files': ['doc/source/command-objects/limits.rst', 'doc/source/command-objects/server-image.rst', 'doc/source/command-objects/console-log.rst', 'doc/source/command-objects/credentials.rst', 'doc/source/command-objects/server.rst', 'doc/source/command-objects/quota.rst', 'doc/source/command-objects/keypair.rst', 'doc/source/command-objects/flavor.rst', 'doc/source/command-objects/aggregate.rst', 'doc/source/command-objects/console-url.rst', 'doc/source/command-objects/user-role.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3b99c178949bc0864f927ac610a12fc666537162', 'message': 'Add versioning to the docs that missed it\n\nChange-Id: I8cb90e0d5aca58c4992271e007af91f8cf782643\n'}]",0,146230,3b99c178949bc0864f927ac610a12fc666537162,7,3,1,6482,,,0,"Add versioning to the docs that missed it

Change-Id: I8cb90e0d5aca58c4992271e007af91f8cf782643
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/30/146230/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/command-objects/limits.rst', 'doc/source/command-objects/server-image.rst', 'doc/source/command-objects/console-log.rst', 'doc/source/command-objects/credentials.rst', 'doc/source/command-objects/server.rst', 'doc/source/command-objects/quota.rst', 'doc/source/command-objects/keypair.rst', 'doc/source/command-objects/flavor.rst', 'doc/source/command-objects/aggregate.rst', 'doc/source/command-objects/console-url.rst', 'doc/source/command-objects/user-role.rst']",11,3b99c178949bc0864f927ac610a12fc666537162,another,Identity v2 ,,21,0
openstack%2Foctavia~master~I57d0192248911d9cb87b04c1919b4002c5fb59bf,openstack/octavia,master,I57d0192248911d9cb87b04c1919b4002c5fb59bf,Octavia Controller specification,MERGED,2014-11-22 00:44:49.000000000,2015-01-12 18:10:00.000000000,2014-12-20 01:03:54.000000000,"[{'_account_id': 3}, {'_account_id': 6437}, {'_account_id': 6951}, {'_account_id': 8179}, {'_account_id': 10273}, {'_account_id': 10750}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-11-22 00:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7536e0baca5b5bee7ec408a530d81abeb49cdc90', 'message': 'Octavia Controller specification\n\nVery, very, work-in-progress\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 2, 'created': '2014-12-11 00:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f708b09ea16a077182097a628070a5738d7ebf30', 'message': 'Octavia Controller specification\n\nVery, very, work-in-progress\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 3, 'created': '2014-12-17 00:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e31172d4bdbf31d76ba356dd9de9c641d7d03d59', 'message': 'Octavia Controller specification\n\nVery, very, work-in-progress\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 4, 'created': '2014-12-17 19:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/eb7dfe6878e055e6ff909874f9bc536a8831433b', 'message': 'Octavia Controller specification\n\nVery, very, work-in-progress\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 5, 'created': '2014-12-17 23:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/caa4af90aaff7f926f79d45952f833e57761ed73', 'message': 'Octavia Controller specification\n\nVery, very, work-in-progress\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 6, 'created': '2014-12-18 20:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9fa87696dbab19c541b651dde87cc572f6494bcf', 'message': 'Octavia Controller specification\n\nThe specification is the overarching document for the Octavia controller\ncomponents.\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 7, 'created': '2014-12-19 00:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8f5b81c1b739948ceec9cb19d48663257d208b1b', 'message': 'Octavia Controller specification\n\nThe specification is the overarching document for the Octavia controller\ncomponents.\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 8, 'created': '2014-12-19 00:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/65897533d1a72bec9fe59dc736990e05fed9021f', 'message': 'Octavia Controller specification\n\nThe specification is the overarching document for the Octavia controller\ncomponents.\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}, {'number': 9, 'created': '2014-12-19 19:38:24.000000000', 'files': ['specs/version0.5/controller.rst', 'specs/version0.5/controller.dot'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6ab85b6db9759b608af1e697b8dd2698e8f4c2dc', 'message': 'Octavia Controller specification\n\nThe specification is the overarching document for the Octavia controller\ncomponents.\n\nChange-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf\n'}]",85,136540,6ab85b6db9759b608af1e697b8dd2698e8f4c2dc,48,9,9,11628,,,0,"Octavia Controller specification

The specification is the overarching document for the Octavia controller
components.

Change-Id: I57d0192248911d9cb87b04c1919b4002c5fb59bf
",git fetch https://review.opendev.org/openstack/octavia refs/changes/40/136540/5 && git format-patch -1 --stdout FETCH_HEAD,"['controller.rst', 'controller.png']",2,7536e0baca5b5bee7ec408a530d81abeb49cdc90,bp/controller,,,247,0
openstack%2Fheat~master~I8119ef2fd2b8d32057f77230d93363c9332d4b52,openstack/heat,master,I8119ef2fd2b8d32057f77230d93363c9332d4b52,Split AWS/OS volume tests,MERGED,2014-12-23 09:29:50.000000000,2015-01-12 18:07:18.000000000,2015-01-12 18:07:17.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6488}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-23 09:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/987c2bdfde0dc9a43ec5ad02f3217a391ec59627', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/test_os_volume.py, and move the\nutils to heat/tests/test_volume_utils.py\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint test_description\n'}, {'number': 2, 'created': '2014-12-23 09:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb85158091bef30e1896c3839a8c755c6dc0fe0e', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/test_os_volume.py, and move the\nutils to heat/tests/test_volume_utils.py\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 3, 'created': '2014-12-24 01:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/98da7a4d999efd3fd147d47b1cf6bea840392892', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/test_os_volume.py, and move the\nutils to heat/tests/test_volume_utils.py\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 4, 'created': '2014-12-24 07:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/843b5246aae7e0836f4f77bca36146f54e4292e9', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/openstack/test_volume.py, and move the\naws volume tests to heat/tests/aws/test_volume.py and\nmove the utils to heat/tests/test_volume_utils.py.\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 5, 'created': '2014-12-26 03:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1d11647d60252451b8f66b82f07bfb55703121ab', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/openstack/test_volume.py, and move the\naws volume tests to heat/tests/aws/test_volume.py and\nmove the utils to heat/tests/test_volume_utils.py.\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 6, 'created': '2014-12-30 03:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/644e48846ee4a2a57101449a71c227082a8502d9', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/openstack/test_volume.py, and move the\naws volume tests to heat/tests/aws/test_volume.py and\nmove the utils to heat/tests/test_volume_utils.py.\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 7, 'created': '2015-01-04 04:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed589b0c144c11c2e3370977709f018f8311423a', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/openstack/test_volume.py, and move the\naws volume tests to heat/tests/aws/test_volume.py and\nmove the utils to heat/tests/test_volume_utils.py.\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}, {'number': 8, 'created': '2015-01-08 03:25:03.000000000', 'files': ['heat/tests/aws/test_volume.py', 'heat/tests/test_volume.py', 'heat/tests/test_volume_utils.py', 'heat/tests/openstack/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b5f5458cd8ed6976dbc4448a8739bfd99b8b7c64', 'message': 'Split AWS/OS volume tests\n\nSplit AWS and OS volume tests, move OS volume tests\nto heat/tests/openstack/test_volume.py, and move the\naws volume tests to heat/tests/aws/test_volume.py and\nmove the utils to heat/tests/test_volume_utils.py.\n\nChange-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52\nImplements: blueprint decouple-aws-os-resources\n'}]",0,143634,b5f5458cd8ed6976dbc4448a8739bfd99b8b7c64,39,9,8,8289,,,0,"Split AWS/OS volume tests

Split AWS and OS volume tests, move OS volume tests
to heat/tests/openstack/test_volume.py, and move the
aws volume tests to heat/tests/aws/test_volume.py and
move the utils to heat/tests/test_volume_utils.py.

Change-Id: I8119ef2fd2b8d32057f77230d93363c9332d4b52
Implements: blueprint decouple-aws-os-resources
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/143634/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_os_volume.py', 'heat/tests/test_volume.py', 'heat/tests/test_volume_utils.py']",3,987c2bdfde0dc9a43ec5ad02f3217a391ec59627,bp/decouple-aws-os-resources,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import collections import copy import json import mock from cinderclient import exceptions as cinder_exp from cinderclient.v2 import client as cinderclient import mox from oslo.config import cfg import six from heat.common import exception from heat.common import template_format from heat.db import api as db_api from heat.engine.clients.os import cinder from heat.engine.clients.os import glance from heat.engine.clients.os import nova from heat.engine.resources.aws import volume as aws_vol from heat.engine.resources import instance from heat.engine.resources.openstack import volume as os_vol from heat.engine import rsrc_defn from heat.engine import scheduler from heat.tests import common from heat.tests import utils from heat.tests.v1_1 import fakes as fakes_v1_1 class BaseVolumeTest(common.HeatTestCase): def setUp(self): super(BaseVolumeTest, self).setUp() self.fc = fakes_v1_1.FakeClient() self.cinder_fc = cinderclient.Client('username', 'password') self.cinder_fc.volume_api_version = 2 self.m.StubOutWithMock(cinder.CinderClientPlugin, '_create') self.m.StubOutWithMock(nova.NovaClientPlugin, '_create') self.m.StubOutWithMock(self.cinder_fc.volumes, 'create') self.m.StubOutWithMock(self.cinder_fc.volumes, 'get') self.m.StubOutWithMock(self.cinder_fc.volumes, 'delete') self.m.StubOutWithMock(self.cinder_fc.volumes, 'extend') self.m.StubOutWithMock(self.cinder_fc.volumes, 'update') self.m.StubOutWithMock(self.cinder_fc.volumes, 'update_all_metadata') self.m.StubOutWithMock(self.fc.volumes, 'create_server_volume') self.m.StubOutWithMock(self.fc.volumes, 'delete_server_volume') self.m.StubOutWithMock(self.fc.volumes, 'get_server_volume') self.use_cinder = False def _mock_delete_volume(self, fv): self.m.StubOutWithMock(fv, 'delete') fv.delete().AndReturn(True) self.m.StubOutWithMock(fv, 'get') fv.get().AndReturn(None) fv.get().AndRaise(cinder_exp.NotFound('Not found')) self.m.ReplayAll() def _mock_create_server_volume_script(self, fva, server=u'WikiDatabase', volume='vol-123', device=u'/dev/vdc', update=False): if not update: nova.NovaClientPlugin._create().MultipleTimes().AndReturn(self.fc) self.fc.volumes.create_server_volume( device=device, server_id=server, volume_id=volume).AndReturn(fva) self.cinder_fc.volumes.get(volume).AndReturn(fva) def create_volume(self, t, stack, resource_name): if self.use_cinder: Volume = os_vol.CinderVolume else: data = t['Resources'][resource_name] data['Properties']['AvailabilityZone'] = 'nova' Volume = aws_vol.Volume rsrc = Volume(resource_name, stack.t.resource_definitions(stack)[resource_name], stack) self.assertIsNone(rsrc.validate()) scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) return rsrc def create_attachment(self, t, stack, resource_name): if self.use_cinder: Attachment = os_vol.CinderVolumeAttachment else: Attachment = aws_vol.VolumeAttachment resource_defns = stack.t.resource_definitions(stack) rsrc = Attachment(resource_name, resource_defns[resource_name], stack) self.assertIsNone(rsrc.validate()) scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) return rsrc class FakeVolume(object): status = 'attaching' id = 'vol-123' def __init__(self, initial_status, final_status, **attrs): self.status = initial_status self.final_status = final_status for key, value in six.iteritems(attrs): setattr(self, key, value) def get(self): self.status = self.final_status def update(self, **kw): pass def delete(self): pass class FakeLatencyVolume(object): status = 'attaching' id = 'vol-123' def __init__(self, life_cycle=('creating', 'available'), **attrs): if not isinstance(life_cycle, tuple): raise exception.Error('life_cycle need to be a tuple.') if not len(life_cycle): raise exception.Error('life_cycle should not be an empty tuple.') self.life_cycle = iter(life_cycle) self.status = next(self.life_cycle) for key, value in six.iteritems(attrs): setattr(self, key, value) def get(self): self.status = next(self.life_cycle) def update(self, **kw): pass class FakeBackup(FakeVolume): status = 'creating' id = 'backup-123' class FakeBackupRestore(object): volume_id = 'vol-123' def __init__(self, volume_id): self.volume_id = volume_id class FakeVolumeWithStateTransition(FakeVolume): status = 'restoring-backup' get_call_count = 0 def get(self): # Allow get to be called once without changing the status # This is to allow the check_create_complete method to # check the initial status. if self.get_call_count < 1: self.get_call_count += 1 else: self.status = self.final_status ",,1064,1008
openstack%2Fproject-config~master~I4208637457bbf1e7562f358913ff71b9f3b0732d,openstack/project-config,master,I4208637457bbf1e7562f358913ff71b9f3b0732d,Correct tempest clone location in node prep,MERGED,2015-01-12 17:25:30.000000000,2015-01-12 17:55:52.000000000,2015-01-12 17:55:51.000000000,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-01-12 17:25:30.000000000', 'files': ['nodepool/elements/cache-devstack/extra-data.d/51-cache-testrepository-db', 'nodepool/scripts/prepare_node_devstack.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/05e6bfaa103807177a83196e35a2b4b4b32868f5', 'message': 'Correct tempest clone location in node prep\n\nChange-Id: I4208637457bbf1e7562f358913ff71b9f3b0732d\n'}]",0,146581,05e6bfaa103807177a83196e35a2b4b4b32868f5,6,2,1,5263,,,0,"Correct tempest clone location in node prep

Change-Id: I4208637457bbf1e7562f358913ff71b9f3b0732d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/146581/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/cache-devstack/extra-data.d/51-cache-testrepository-db', 'nodepool/scripts/prepare_node_devstack.sh']",2,05e6bfaa103807177a83196e35a2b4b4b32868f5,prepare-devstack,TEMPEST_DIR=${TEMPEST_DIR:-/opt/git/openstack/tempest},TEMPEST_DIR=${TEMPEST_DIR:-/opt/git/tempest},2,2
openstack%2Ftripleo-image-elements~master~Iacd361de9d4d4fd20e4c154192de7d31251a87fa,openstack/tripleo-image-elements,master,Iacd361de9d4d4fd20e4c154192de7d31251a87fa,Longer upstart sleep for neutron-ovs-agent,ABANDONED,2014-11-25 20:23:16.000000000,2015-01-12 17:53:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 8449}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-11-25 20:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e5d89b68f0a609411a2f215754dbe6267356c9f9', 'message': 'Longer upstart sleep for neutron-ovs-agent\n\nThe upstart job for neutron-ovs-agent does not currently detect that\nthis service fails to start. The error in the referenced bug happens in\na forked subproces so solutions like expect daemon do not work. Adding\nsupport for modifying our upstart respawn limit lines so we can support\na longer post-start exec sleep for this job.\n\nChange-Id: Iacd361de9d4d4fd20e4c154192de7d31251a87fa\nRelated-Bug: #1394956\n'}, {'number': 2, 'created': '2014-11-25 20:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/339374f9c52ebff2a93ad2be9f4bbccb73aa637b', 'message': 'Longer upstart sleep for neutron-ovs-agent\n\nThe upstart job for neutron-ovs-agent does not currently detect that\nthis service fails to start. The error in the referenced bug happens in\na forked subproces so solutions like expect daemon do not work. Adding\nsupport for modifying our upstart respawn limit lines so we can support\na longer post-start exec sleep for this job.\n\nChange-Id: Iacd361de9d4d4fd20e4c154192de7d31251a87fa\nRelated-Bug: #1394956\n'}, {'number': 3, 'created': '2014-11-25 22:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6e4e5a2ec2f6b4da9f57a9467b6984526daab2e4', 'message': 'Longer upstart sleep for neutron-ovs-agent\n\nThe upstart job for neutron-ovs-agent does not currently detect that\nthis service fails to start. The error in the referenced bug happens in\na forked subproces so solutions like expect daemon do not work. Adding\nsupport for modifying our upstart respawn limit lines so we can support\na longer post-start exec sleep for this job.\n\nChange-Id: Iacd361de9d4d4fd20e4c154192de7d31251a87fa\nRelated-Bug: #1394956\n'}, {'number': 4, 'created': '2014-11-26 20:51:23.000000000', 'files': ['elements/os-svc-install/bin/os-svc-daemon', 'elements/neutron-openvswitch-agent/install.d/neutron-source-install/80-neutron-openvswitch-agent'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6193ea3d190fe7b789920f686cd603de25242126', 'message': 'Longer upstart sleep for neutron-ovs-agent\n\nThe upstart job for neutron-ovs-agent does not currently detect that\nthis service fails to start. The error in the referenced bug happens in\na forked subproces so solutions like expect daemon do not work. Adding\nsupport for modifying our upstart respawn limit lines so we can support\na longer post-start exec sleep for this job.\n\nChange-Id: Iacd361de9d4d4fd20e4c154192de7d31251a87fa\nRelated-Bug: #1394956\n'}]",6,137195,6193ea3d190fe7b789920f686cd603de25242126,21,4,4,10035,,,0,"Longer upstart sleep for neutron-ovs-agent

The upstart job for neutron-ovs-agent does not currently detect that
this service fails to start. The error in the referenced bug happens in
a forked subproces so solutions like expect daemon do not work. Adding
support for modifying our upstart respawn limit lines so we can support
a longer post-start exec sleep for this job.

Change-Id: Iacd361de9d4d4fd20e4c154192de7d31251a87fa
Related-Bug: #1394956
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/95/137195/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/os-svc-install/bin/os-svc-daemon', 'elements/neutron-openvswitch-agent/install.d/neutron-source-install/80-neutron-openvswitch-agent']",2,e5d89b68f0a609411a2f215754dbe6267356c9f9,fix/neutron-ovs-agent-upstart,"os-svc-daemon -i ""$NEUTRON_VENV_DIR"" -s ""exec sleep 10"" -r ""2 20"" neutron-openvswitch-agent neutron neutron-openvswitch-agent \","os-svc-daemon -i ""$NEUTRON_VENV_DIR"" neutron-openvswitch-agent neutron neutron-openvswitch-agent \",8,4
openstack%2Fsahara-image-elements~master~I6d71ac1da3e0125639020199e4eb87fe716261b8,openstack/sahara-image-elements,master,I6d71ac1da3e0125639020199e4eb87fe716261b8,Migrate to openjdk - part 1,MERGED,2015-01-12 10:38:10.000000000,2015-01-12 17:35:43.000000000,2015-01-12 17:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-01-12 10:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d3573fac8326cceb7b77619d4d43fb6ee8e7ee28', 'message': 'Migrate to openjdk - part 1\n\nAdd elements to install openjdk\n\nChange-Id: I6d71ac1da3e0125639020199e4eb87fe716261b8\npartial-bug: #1204957\n'}, {'number': 2, 'created': '2015-01-12 11:08:33.000000000', 'files': ['elements/openjdk/install.d/33-java'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/879ee8d6f2417c08fd1f12fac03c6fceb9b427ca', 'message': 'Migrate to openjdk - part 1\n\nAdd elements to install openjdk\n\nChange-Id: I6d71ac1da3e0125639020199e4eb87fe716261b8\npartial-bug: #1204957\n'}]",0,146412,879ee8d6f2417c08fd1f12fac03c6fceb9b427ca,11,6,2,7710,,,0,"Migrate to openjdk - part 1

Add elements to install openjdk

Change-Id: I6d71ac1da3e0125639020199e4eb87fe716261b8
partial-bug: #1204957
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/12/146412/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/openjdk/install.d/33-java'],1,d3573fac8326cceb7b77619d4d43fb6ee8e7ee28,bug/1204957,"#!/bin/bash echo ""Installing OpenJDK"" distro=$(lsb_release -is || :) case ""$distro"" in Ubuntu ) install-packages openjdk-7-jre JAVA_PATH=$(update-alternatives --list java) JAVA_HOME=${JAVA_PATH%/bin/java} ;; Fedora | RedHatEnterpriseServer | CentOS ) install-packages java-1.7.0-openjdk JAVA_HOME=$(rpm -E ""%{java_home}"") ;; esac echo ""JAVA_HOME=$JAVA_HOME"" >> $TARGET_ROOT/etc/environment echo ""OpenJDK has been installed"" ",,21,0
openstack%2Fopenstacksdk~master~I94facb4d6c4e8d446e8e696afb75f1a3268d3722,openstack/openstacksdk,master,I94facb4d6c4e8d446e8e696afb75f1a3268d3722,Complete the Resource class documentation,MERGED,2014-11-23 19:53:05.000000000,2015-01-12 17:22:50.000000000,2015-01-12 17:22:49.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-11-23 19:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/01f548ec543b41b9e36240798a1543859098e2dd', 'message': 'Complete the Resource class documentation\n\nDocument the CRUD methods with explanations of arguments, return value,\nand exceptions that could be raised. This also introduces a change to\nthe autoclass setting so that it orders the members by how they are\nwritten in the source, instead of alphabetical order.\n\nA second change is going to be submitted that does some reordering\nof methods so that more common methods will be near the top and the more\ninternal (but still public) methods near the bottom.\n\nChange-Id: I94facb4d6c4e8d446e8e696afb75f1a3268d3722\n'}, {'number': 2, 'created': '2015-01-12 15:57:11.000000000', 'files': ['openstack/resource.py', 'doc/source/resource.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0d8be32a1e872cf31769d04c58fd57f59b2ea851', 'message': 'Complete the Resource class documentation\n\nDocument the CRUD methods with explanations of arguments, return value,\nand exceptions that could be raised. This also introduces a change to\nthe autoclass setting so that it orders the members by how they are\nwritten in the source, instead of alphabetical order.\n\nA second change is going to be submitted that does some reordering\nof methods so that more common methods will be near the top and the more\ninternal (but still public) methods near the bottom.\n\nChange-Id: I94facb4d6c4e8d446e8e696afb75f1a3268d3722\n'}]",8,136648,0d8be32a1e872cf31769d04c58fd57f59b2ea851,13,4,2,8257,,,0,"Complete the Resource class documentation

Document the CRUD methods with explanations of arguments, return value,
and exceptions that could be raised. This also introduces a change to
the autoclass setting so that it orders the members by how they are
written in the source, instead of alphabetical order.

A second change is going to be submitted that does some reordering
of methods so that more common methods will be near the top and the more
internal (but still public) methods near the bottom.

Change-Id: I94facb4d6c4e8d446e8e696afb75f1a3268d3722
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/48/136648/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/resource.py', 'doc/source/resource.rst']",2,01f548ec543b41b9e36240798a1543859098e2dd,resource-docs,"========The prop class --------------The Resource class ------------------ :member-order: bysource How path_args are used ********************** As :class:`Resource`\s often contain compound :data:`Resource.base_path`\s, meaning the path is constructed from more than just that string, the various request methods need a way to fill in the missing parts. That's where ``path_args`` come in. For example: :: class ServerIP(resource.Resource): base_path = ""/servers/%(server_id)s/ips"" Making a GET request to obtain server IPs requires the ID of the server to check. This is handled by passing ``{""server_id"": ""12345""}`` as the ``path_args`` argument when calling :meth:`Resource.get_by_id`. From there, the method uses Python's string interpolation to fill in the ``server_id`` piece of the URL, and then makes the request.",==============The prop object ---------------Resource object ---------------,244,22
openstack%2Fproject-config~master~I04404a55baf4da2745760246b8606ed3db52c03a,openstack/project-config,master,I04404a55baf4da2745760246b8606ed3db52c03a,Add nodepool script to preseed testrepository from subunit2sql,MERGED,2014-11-21 05:07:17.000000000,2015-01-12 17:22:41.000000000,2015-01-12 14:14:45.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-11-21 05:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5c4bc7f8e3029c2ad01d348485b99a2d73e74a6c', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nFor the first pass on this tool it takes the 10 most recent results\nfrom the database and uses that preseed testr. After further\nimprovements are made to subunit2sql this will likely be changed to\nuse the aggregate data from all the test runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 2, 'created': '2014-11-23 02:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fa5a862e578f6999a13bb6ebfc8c8a9479b9693a', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nFor the first pass on this tool it takes the 10 most recent results\nfrom the database and uses that preseed testr. After further\nimprovements are made to subunit2sql this will likely be changed to\nuse the aggregate data from all the test runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 3, 'created': '2014-12-11 20:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ed60b56489bfc7c00d6d95bb0c85f012afc32b97', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nFor the first pass on this tool it takes the 10 most recent results\nfrom the database and uses that preseed testr. After further\nimprovements are made to subunit2sql this will likely be changed to\nuse the aggregate data from all the test runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 4, 'created': '2014-12-12 22:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fef55949e73c1e793c8419041f1fc4c316924023', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nFor the first pass on this tool it takes the 10 most recent results\nfrom the database and uses that preseed testr. After further\nimprovements are made to subunit2sql this will likely be changed to\nuse the aggregate data from all the test runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 5, 'created': '2014-12-17 21:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ab25e400f13f79b10b1f9c043f5aad50e89bad18', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 6, 'created': '2014-12-18 01:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d8616a156003aca8fb0bb31fb7768055578d5636', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 7, 'created': '2014-12-18 16:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fbbd72441748b4978af7a15dcc02802c63fdbcbf', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 8, 'created': '2014-12-18 18:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d55b1aed4a4bde2efec1cd782b188ba935b7e880', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 9, 'created': '2014-12-18 20:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/31166dd76676e7477b8751b89459488f103c1e34', 'message': 'Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n'}, {'number': 10, 'created': '2014-12-23 21:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f83a915ec0c253af3993205bdbbe78f7534e8a72', 'message': ""Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nThis also adds a call out to the new prepare_tempest_testrepository\nscript in order to pre-seed tempest's testrepository with data from\nthe subunit2sql DB. This will enable the testr scheduler to perform\nsome worker balance optimization based on the average run_times from\nall the previous gate runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n""}, {'number': 11, 'created': '2015-01-07 17:25:41.000000000', 'files': ['nodepool/elements/cache-devstack/extra-data.d/51-cache-testrepository-db', 'nodepool/scripts/prepare_tempest_testrepository.py', 'nodepool/scripts/prepare_node_devstack.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8fdd1ce943a26dc15b98f391ef536ac04e84d284', 'message': ""Add nodepool script to preseed testrepository from subunit2sql\n\nThis commit adds a new nodepool script to use subunit2sql to preseed\ntestrepository with timing data to use for scheduler optimization.\nThis uses aggregate data from all the tests stored in the subunit2sql\ndb from all the test runs to generate a subunit stream with test\nexecute times which equal the rolling average stored in the tests\ntable.\n\nThis also adds a call out to the new prepare_tempest_testrepository\nscript in order to pre-seed tempest's testrepository with data from\nthe subunit2sql DB. This will enable the testr scheduler to perform\nsome worker balance optimization based on the average run_times from\nall the previous gate runs.\n\nChange-Id: I04404a55baf4da2745760246b8606ed3db52c03a\n""}]",12,136234,8fdd1ce943a26dc15b98f391ef536ac04e84d284,47,10,11,5196,,,0,"Add nodepool script to preseed testrepository from subunit2sql

This commit adds a new nodepool script to use subunit2sql to preseed
testrepository with timing data to use for scheduler optimization.
This uses aggregate data from all the tests stored in the subunit2sql
db from all the test runs to generate a subunit stream with test
execute times which equal the rolling average stored in the tests
table.

This also adds a call out to the new prepare_tempest_testrepository
script in order to pre-seed tempest's testrepository with data from
the subunit2sql DB. This will enable the testr scheduler to perform
some worker balance optimization based on the average run_times from
all the previous gate runs.

Change-Id: I04404a55baf4da2745760246b8606ed3db52c03a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/136234/10 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/scripts/preseed-testrepository.py'],1,5c4bc7f8e3029c2ad01d348485b99a2d73e74a6c,136234,"#!/usr/bin/python2 # # Copyright 2014 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import sys from subunit2sql.db import api from subunit2sql.db import models from subunit2sql import shell from oslo.db.sqlalchemy import utils as db_utils from common import run_local DB_URI = 'mysql://user:pass@logstash.openstack.org:4040/subunit2sql' if len(sys.argv) > 1: TEMPEST_PATH = sys.argv[1] else: TEMPEST_PATH = '/opt/stack/new/tempest' def init_testr(): (status, out) = run_local(['testr', 'init'], status=True, cwd=TEMPEST_PATH) if status != 0: print(""testr init failed with:\n%s' % out"") exit(status) def get_run_ids(session): results = db_utils.model_query(models.Run, session).order_by( models.Run.run_at.desc()).limit(10).all() results = query.all() results = map(lambda x: x.id, results) return results def populate_testrepository(run_ids): for run in run_ids: out = run_local(['sql2subunit', '--database-connection %s' %DB_URI, '-o %s' % run, run], cwd=TEMPEST_PATH) out = run_local(['testr', 'load', run], cwd=TEMPEST_PATH) out = run_local(['rm', run]) def main(): init_testr() shell.parse_args([]) shell.CONF.set_override('connection', DB_URI, group='database') session = api.get_session() run_ids = get_run_ids(session) session.close() populate_testrepository(run_ids) if __name__ == '__main__': main() ",,64,0
openstack%2Foslo.vmware~master~I5d4ec87e84c95050587e436a42727d428ab01408,openstack/oslo.vmware,master,I5d4ec87e84c95050587e436a42727d428ab01408,Use ToggleLazy fixture from oslo.i18n,MERGED,2015-01-08 20:28:24.000000000,2015-01-12 17:21:38.000000000,2015-01-12 17:21:37.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9008}, {'_account_id': 9171}]","[{'number': 1, 'created': '2015-01-08 20:28:24.000000000', 'files': ['tests/test_vim.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/bc6477ab79b8a7ffb9e46dfcf1df92c9c9aa9b2f', 'message': 'Use ToggleLazy fixture from oslo.i18n\n\nUse the ToggleLazy fixture from oslo.i18n instead of managing\nthe internal flag ourselves.\n\nChange-Id: I5d4ec87e84c95050587e436a42727d428ab01408\n'}]",1,145923,bc6477ab79b8a7ffb9e46dfcf1df92c9c9aa9b2f,11,7,1,2472,,,0,"Use ToggleLazy fixture from oslo.i18n

Use the ToggleLazy fixture from oslo.i18n instead of managing
the internal flag ourselves.

Change-Id: I5d4ec87e84c95050587e436a42727d428ab01408
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/23/145923/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_vim.py'],1,bc6477ab79b8a7ffb9e46dfcf1df92c9c9aa9b2f,bp/drop-namespace-packages,from oslo_i18n import fixture as i18n_fixture self.useFixture(i18n_fixture.ToggleLazy(True))," from oslo import i18n back_use_lazy = i18n._lazy.USE_LAZY i18n.enable_lazy() self.addCleanup(self._restore_use_lazy, back_use_lazy) def _restore_use_lazy(self, back_use_lazy): i18n._lazy.USE_LAZY = back_use_lazy",2,7
openstack%2Foslo.db~master~I4e23cb3c3773e58a297416c1f51996fef059330a,openstack/oslo.db,master,I4e23cb3c3773e58a297416c1f51996fef059330a,Fix slowest test output after test run,MERGED,2015-01-11 21:55:33.000000000,2015-01-12 17:21:03.000000000,2015-01-12 17:21:02.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6849}, {'_account_id': 11816}]","[{'number': 1, 'created': '2015-01-11 21:55:33.000000000', 'files': ['tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9a510e85ce38b58f6de771de84a10db2bbe60c1c', 'message': 'Fix slowest test output after test run\n\nThis commit fixes the output from pretty_tox.sh so that the testr\nslowest output is gobbled up by the pipe into subunit-trace.\n\nChange-Id: I4e23cb3c3773e58a297416c1f51996fef059330a\n'}]",0,146349,9a510e85ce38b58f6de771de84a10db2bbe60c1c,8,4,1,5196,,,0,"Fix slowest test output after test run

This commit fixes the output from pretty_tox.sh so that the testr
slowest output is gobbled up by the pipe into subunit-trace.

Change-Id: I4e23cb3c3773e58a297416c1f51996fef059330a
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/49/146349/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/pretty_tox.sh'],1,9a510e85ce38b58f6de771de84a10db2bbe60c1c,fix-slowest,"python setup.py testr --testr-args=""--subunit $TESTRARGS"" | subunit-trace -f retval=$? # NOTE(mtreinish) The pipe above would eat the slowest display from pbr's testr # wrapper so just manually print the slowest tests echo -e ""\nSlowest Tests:\n"" testr slowest exit $retval","python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit-trace -f ",7,2
openstack%2Fdevstack~master~Idd05c31b9eec9e6209666fa16fa425cdf1f35aa2,openstack/devstack,master,Idd05c31b9eec9e6209666fa16fa425cdf1f35aa2,Fix get_packages when $DISTRO is not set,MERGED,2015-01-09 13:38:50.000000000,2015-01-12 17:17:43.000000000,2015-01-12 17:17:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 7118}, {'_account_id': 8074}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-01-09 13:38:50.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/13519e8a5b8bb9141ecff09f5273d5c2896a8082', 'message': ""Fix get_packages when $DISTRO is not set\n\nSourcing the tools/install-prereqs.sh script with TOP_DIR set results\nin GetDistro being called in get_packages and echoing the result.\nSince all output from get_packages is assumed to be package names,\nthis results in the attempted installation of the non-existant 'Found'\n'Distro' and '[distro name]' packages.  This change removes the echo\nstatement to avoid this problem.\n\nChange-Id: Idd05c31b9eec9e6209666fa16fa425cdf1f35aa2\n""}]",0,146084,13519e8a5b8bb9141ecff09f5273d5c2896a8082,12,7,1,2035,,,0,"Fix get_packages when $DISTRO is not set

Sourcing the tools/install-prereqs.sh script with TOP_DIR set results
in GetDistro being called in get_packages and echoing the result.
Since all output from get_packages is assumed to be package names,
this results in the attempted installation of the non-existant 'Found'
'Distro' and '[distro name]' packages.  This change removes the echo
statement to avoid this problem.

Change-Id: Idd05c31b9eec9e6209666fa16fa425cdf1f35aa2
",git fetch https://review.opendev.org/openstack/devstack refs/changes/84/146084/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,13519e8a5b8bb9141ecff09f5273d5c2896a8082,,," echo ""Found Distro $DISTRO""",0,1
openstack%2Foslo.db~master~I8a3eb08ab3469ec08e05bfce754b664943d65c83,openstack/oslo.db,master,I8a3eb08ab3469ec08e05bfce754b664943d65c83,Make sure sort_key_attr is QueryableAttribute when query,MERGED,2014-12-23 09:12:51.000000000,2015-01-12 17:17:26.000000000,2015-01-12 17:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 11189}, {'_account_id': 11816}, {'_account_id': 12175}]","[{'number': 1, 'created': '2014-12-23 09:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/6d5cbba911bb67d42a4201ca514a585c21b4a3a9', 'message': 'Make sure sort_key_attr is InstrumentedAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really an InstrumentedAttribute\ntype instance before we do the query or it will casue errors\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 2, 'created': '2014-12-24 05:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/f596fcffdc04053a458ce1e29b8a67697f0ec184', 'message': 'Make sure sort_key_attr is InstrumentedAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really an InstrumentedAttribute\ntype instance before we do the query or it will casue errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 3, 'created': '2014-12-31 02:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5b14fbffb3c65c438b61aa5d38901ad749c220c2', 'message': 'Make sure sort_key_attr is InstrumentedAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really an InstrumentedAttribute\ntype instance before we do the query or it will casue errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 4, 'created': '2014-12-31 03:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/225c0e60437f1fa35947282f4a670e3505734f34', 'message': 'Make sure sort_key_attr is InstrumentedAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really an InstrumentedAttribute\ntype instance before we do the query or it will casue errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 5, 'created': '2015-01-06 02:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/8b61920a7378ee3ce23fcf41ce8aef423fda3243', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 6, 'created': '2015-01-06 08:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/05ddf630ed63abf9e36edb1a849135426615a09d', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 7, 'created': '2015-01-08 05:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/78280cb3a8d2a3c9133fae5ea1d6ea8f45689a51', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 8, 'created': '2015-01-08 10:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/94db44ca256eb47a8417122301da5a1c3d9da975', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 9, 'created': '2015-01-08 10:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/f7bea7335598783ac77671247bac9c780e003b9b', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}, {'number': 10, 'created': '2015-01-08 22:12:09.000000000', 'files': ['oslo_db/sqlalchemy/utils.py', 'oslo_db/tests/old_import_api/sqlalchemy/test_utils.py', 'oslo_db/tests/sqlalchemy/test_utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/bce8ed304274f767b0a12eadfdf07e220495c160', 'message': 'Make sure sort_key_attr is QueryableAttribute when query\n\nWhen doing query.order_by, sort_key_attr is get from model class,\nwe need to make sure sort_key_attr is really a QueryableAttribute\ntype instance before we do the query or it will cause errors.\nThis will prevent if there IS a function which name is same as sort_key.\n\nCloses-Bug: 1405069\nChange-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83\n'}]",17,143632,bce8ed304274f767b0a12eadfdf07e220495c160,39,7,10,12175,,,0,"Make sure sort_key_attr is QueryableAttribute when query

When doing query.order_by, sort_key_attr is get from model class,
we need to make sure sort_key_attr is really a QueryableAttribute
type instance before we do the query or it will cause errors.
This will prevent if there IS a function which name is same as sort_key.

Closes-Bug: 1405069
Change-Id: I8a3eb08ab3469ec08e05bfce754b664943d65c83
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/32/143632/8 && git format-patch -1 --stdout FETCH_HEAD,['oslo/db/sqlalchemy/utils.py'],1,6d5cbba911bb67d42a4201ca514a585c21b4a3a9,bug/1405069,"from sqlalchemy.orm.attributes import InstrumentedAttribute # Make sure it is InstrumentedAttribute if not isinstance(sort_key_attr, InstrumentedAttribute): raise AttributeError",,4,0
openstack%2Fswift~master~I920c0aee38e4e16c49bd84a3b772308a00794fa7,openstack/swift,master,I920c0aee38e4e16c49bd84a3b772308a00794fa7,Test that SLO disallows too small first segment if other segments,MERGED,2015-01-09 14:51:14.000000000,2015-01-12 17:11:05.000000000,2015-01-12 17:11:04.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 6968}, {'_account_id': 9625}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-01-09 14:51:14.000000000', 'files': ['test/unit/common/middleware/test_slo.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/7958729198045a2fc95480e9713a4dde2f86ad01', 'message': 'Test that SLO disallows too small first segment if other segments\n\nSLO allows the first segment to be less than min_segment_size if\nit is the only segment. Current tests verify that a single small\nsegment is allowed, and that multiple small segments are disallowed.\nThis patch adds a test to verify that SLO will disallow a manifest\nwith a small first segment followed by another correctly sized\nsegment.\n\nChange-Id: I920c0aee38e4e16c49bd84a3b772308a00794fa7\n'}]",0,146101,7958729198045a2fc95480e9713a4dde2f86ad01,9,5,1,7847,,,0,"Test that SLO disallows too small first segment if other segments

SLO allows the first segment to be less than min_segment_size if
it is the only segment. Current tests verify that a single small
segment is allowed, and that multiple small segments are disallowed.
This patch adds a test to verify that SLO will disallow a manifest
with a small first segment followed by another correctly sized
segment.

Change-Id: I920c0aee38e4e16c49bd84a3b772308a00794fa7
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/146101/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/middleware/test_slo.py'],1,7958729198045a2fc95480e9713a4dde2f86ad01,slo_middleware," def test_handle_multipart_put_disallow_small_first_segment(self): with patch.object(self.slo, 'min_segment_size', 50): test_json_data = json.dumps([{'path': '/cont/object', 'etag': 'etagoftheobjectsegment', 'size_bytes': 10}, {'path': '/cont/small_object', 'etag': 'etagoftheobjectsegment', 'size_bytes': 100}]) req = Request.blank('/v1/a/c/o', body=test_json_data) try: self.slo.handle_multipart_put(req, fake_start_response) except HTTPException as e: pass self.assertEquals(e.status_int, 400) ",,15,0
openstack%2Ftempest~master~Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d,openstack/tempest,master,Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d,Change v2 identity client methods to return one value,MERGED,2014-12-30 15:58:09.000000000,2015-01-12 17:10:56.000000000,2015-01-12 17:10:54.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-30 15:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/60c81ef2d5086ae918b5957c212787f8d0623c43', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}, {'number': 2, 'created': '2014-12-30 16:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f94ba2fb0ad005a6af2dca5f8f4f10ca1c1c4486', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}, {'number': 3, 'created': '2014-12-30 17:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/435626cdeb9a2830ac17d49608bc0a4a7ef98e55', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}, {'number': 4, 'created': '2015-01-05 18:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d804c43ffc03507bb45ffc6510484bd9d0671b34', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}, {'number': 5, 'created': '2015-01-06 03:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/987460a58b485ffa2410d9b20ab627970b1816ea', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}, {'number': 6, 'created': '2015-01-06 14:11:45.000000000', 'files': ['tempest/api/identity/test_extension.py', 'tempest/cmd/cleanup.py', 'tempest/api/network/admin/test_quotas.py', 'tempest/cmd/cleanup_service.py', 'tempest/api/identity/admin/test_tenant_negative.py', 'tempest/api/identity/admin/test_services.py', 'tempest/api/network/test_routers.py', 'tempest/api/compute/admin/test_quotas.py', 'tempest/api/identity/admin/test_tenants.py', 'tempest/stress/cleanup.py', 'tempest/cmd/javelin.py', 'tempest/api/object_storage/base.py', 'tempest/common/isolated_creds.py', 'tempest/api/volume/admin/test_volume_quotas.py', 'tempest/services/identity/json/identity_client.py', 'tempest/api/identity/admin/test_roles.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/api/identity/admin/test_users.py', 'tempest/stress/driver.py', 'tempest/api/identity/admin/test_roles_negative.py', 'tempest/api/identity/admin/test_tokens.py', 'tempest/api/identity/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7afa925909d077c7f35e104227f4afd43db96ee', 'message': 'Change v2 identity client methods to return one value\n\nTests were updated along with verify_tempest, stress, cleanup, javelin.\n\nPartially implements: blueprint clients-return-one-value\n\nChange-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d\n'}]",1,144473,b7afa925909d077c7f35e104227f4afd43db96ee,33,5,6,1192,,,0,"Change v2 identity client methods to return one value

Tests were updated along with verify_tempest, stress, cleanup, javelin.

Partially implements: blueprint clients-return-one-value

Change-Id: Ia6c8d0df5fbf0ea69aad2cc9995928f3d329724d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/144473/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/test_extension.py', 'tempest/cmd/cleanup.py', 'tempest/api/network/admin/test_quotas.py', 'tempest/cmd/cleanup_service.py', 'tempest/api/identity/admin/test_tenant_negative.py', 'tempest/api/identity/admin/test_services.py', 'tempest/api/network/test_routers.py', 'tempest/api/compute/admin/test_quotas.py', 'tempest/api/identity/admin/test_tenants.py', 'tempest/stress/cleanup.py', 'tempest/cmd/javelin.py', 'tempest/api/object_storage/base.py', 'tempest/common/isolated_creds.py', 'tempest/services/identity/json/identity_client.py', 'tempest/api/identity/admin/test_roles.py', 'tempest/tests/test_tenant_isolation.py', 'tempest/api/identity/admin/test_users.py', 'tempest/stress/driver.py', 'tempest/api/identity/admin/test_roles_negative.py', 'tempest/api/identity/admin/test_tokens.py', 'tempest/api/identity/base.py']",21,60c81ef2d5086ae918b5957c212787f8d0623c43,bp/clients-return-one-value," users = cls.client.get_users() tenants = cls.client.list_tenants() except AttributeError: tenants = cls.client.list_projects() roles = cls.client.list_roles() self.user = self.client.create_user(self.test_user, self.test_password, self.tenant['id'], self.test_email) self.tenant = self.client.create_tenant( self.role = self.client.create_role(self.test_role)"," _, users = cls.client.get_users() _, tenants = cls.client.list_tenants() except AttributeError: _, tenants = cls.client.list_projects() _, roles = cls.client.list_roles() _, self.user = self.client.create_user(self.test_user, self.test_password, self.tenant['id'], self.test_email) _, self.tenant = self.client.create_tenant( _, self.role = self.client.create_role(self.test_role)",185,190
openstack%2Fneutron~stable%2Ficehouse~If0502f57382441fdb4510c81a89794f57a38e696,openstack/neutron,stable/icehouse,If0502f57382441fdb4510c81a89794f57a38e696,Race for l2pop when ports go up/down on same host,MERGED,2014-10-15 13:13:26.000000000,2015-01-12 17:09:04.000000000,2015-01-12 17:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6502}, {'_account_id': 6854}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9361}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-10-15 13:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eef5cc81ecbb5a736a35d0b87ea1acee72210d1b', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.\n\nIcehouse changes:\n- dropped DVR related changes;\n- L2populationMechanismDriver does not have attribute\n  L2populationAgentNotify.\n\nConflicts:\n\tneutron/plugins/ml2/drivers/l2pop/mech_driver.py\n\tneutron/plugins/ml2/plugin.py\n\tneutron/tests/unit/ml2/drivers/test_l2population.py\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n(cherry picked from commit 3cd2163d5105faad389bee5175ef446f0bb90289)\n'}, {'number': 2, 'created': '2014-10-15 14:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08b0560ca5d4f494736a4954df30eaeb81b59416', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.\n\nIcehouse changes:\n- dropped DVR related changes;\n- L2populationMechanismDriver does not have attribute\n  L2populationAgentNotify.\n- some minor pep8 changes.\n\nConflicts:\n\tneutron/plugins/ml2/drivers/l2pop/mech_driver.py\n\tneutron/plugins/ml2/plugin.py\n\tneutron/tests/unit/ml2/drivers/test_l2population.py\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n(cherry picked from commit 3cd2163d5105faad389bee5175ef446f0bb90289)\n'}, {'number': 3, 'created': '2015-01-05 11:27:54.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/acb37285ccdd9caa3133188b738ae09fa1bc5913', 'message': 'Race for l2pop when ports go up/down on same host\n\nWith l2pop enabled, race exists in delete_port_postcommit\nwhen both create/update_port and delete_port deal with\ndifferent ports on the same host, where such ports are\neither the first (or) last on same network for that host.\nThis race happens outside the DB locking zones in\nthe respective methods of ML2 plugin.\n\nTo fix this, we have moved determination of\nfdb_entries back to delete_port_postcommit and removed\ndelete_port_precommit altogether from l2pop mechanism\ndriver.\n\nIcehouse changes:\n- dropped DVR related changes;\n- L2populationMechanismDriver does not have attribute\n  L2populationAgentNotify.\n- some minor pep8 changes.\n\nConflicts:\n\tneutron/plugins/ml2/drivers/l2pop/mech_driver.py\n\tneutron/plugins/ml2/plugin.py\n\tneutron/tests/unit/ml2/drivers/test_l2population.py\n\nCloses-Bug: #1372438\nChange-Id: If0502f57382441fdb4510c81a89794f57a38e696\n(cherry picked from commit 3cd2163d5105faad389bee5175ef446f0bb90289)\n'}]",0,128642,acb37285ccdd9caa3133188b738ae09fa1bc5913,61,29,3,9656,,,0,"Race for l2pop when ports go up/down on same host

With l2pop enabled, race exists in delete_port_postcommit
when both create/update_port and delete_port deal with
different ports on the same host, where such ports are
either the first (or) last on same network for that host.
This race happens outside the DB locking zones in
the respective methods of ML2 plugin.

To fix this, we have moved determination of
fdb_entries back to delete_port_postcommit and removed
delete_port_precommit altogether from l2pop mechanism
driver.

Icehouse changes:
- dropped DVR related changes;
- L2populationMechanismDriver does not have attribute
  L2populationAgentNotify.
- some minor pep8 changes.

Conflicts:
	neutron/plugins/ml2/drivers/l2pop/mech_driver.py
	neutron/plugins/ml2/plugin.py
	neutron/tests/unit/ml2/drivers/test_l2population.py

Closes-Bug: #1372438
Change-Id: If0502f57382441fdb4510c81a89794f57a38e696
(cherry picked from commit 3cd2163d5105faad389bee5175ef446f0bb90289)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/128642/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/ml2/drivers/test_l2population.py']",2,eef5cc81ecbb5a736a35d0b87ea1acee72210d1b,bug/1372438,"import contextlibfrom neutron.plugins.ml2.drivers.l2pop import mech_driver as l2pop_mech_driver def test_delete_port_invokes_update_device_down(self): l2pop_mech = l2pop_mech_driver.L2populationMechanismDriver() l2pop_mech.L2PopulationAgentNotify = mock.Mock() l2pop_mech.rpc_ctx = mock.Mock() with contextlib.nested( mock.patch.object(l2pop_mech, '_update_port_down', return_value=None), mock.patch.object(l2pop_mech.L2PopulationAgentNotify, 'remove_fdb_entries')) as (upd_port_down, rem_fdb_entries): l2pop_mech.delete_port_postcommit(mock.Mock()) self.assertTrue(upd_port_down.called)",,22,17
openstack%2Ffuel-main~master~I7f213a0299752a7b85feeccb21a61603538caee7,openstack/fuel-main,master,I7f213a0299752a7b85feeccb21a61603538caee7,packages/deb: disable starting services in the staging chroots,MERGED,2014-12-25 12:01:51.000000000,2015-01-12 17:02:56.000000000,2015-01-12 17:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/024313993ec517cf5e34aad30745fdbd296842cd', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 2, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/19b791f28ddbb97fce7799d00a77b73a50e19c0d', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 3, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4fdd4a5d8078e0d4a53c28a1999aa2d2e78e7977', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 4, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/02f00525fecaf2e1ddaf6ba9f022f14c48e98480', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 5, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6edbaa1c72819a1dff842edf0bf76cab95aabdcd', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 6, 'created': '2014-12-31 06:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f03e37ba413d27448c9f94beec9c02b824cb93df', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 7, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/95ef5328c81a8f2796146c38d9ce5ea5bdadbe7c', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}, {'number': 8, 'created': '2015-01-02 15:48:37.000000000', 'files': ['sandbox.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/be1e0a689faf2bd3950fd80400221a017b3baf12', 'message': 'packages/deb: disable starting services in the staging chroots\n\nWithout this patch a copy of udevd gets started in the staging chroot (where\nthe Debian packages are built), and that udevd process starts hogging CPU\nafter the chroot gets removed. To solve the problem prevent services from\nbeing started in the staging chroot.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: I7f213a0299752a7b85feeccb21a61603538caee7\n'}]",0,143971,be1e0a689faf2bd3950fd80400221a017b3baf12,38,6,8,13194,,,0,"packages/deb: disable starting services in the staging chroots

Without this patch a copy of udevd gets started in the staging chroot (where
the Debian packages are built), and that udevd process starts hogging CPU
after the chroot gets removed. To solve the problem prevent services from
being started in the staging chroot.

blueprint support-ubuntu-trusty

Change-Id: I7f213a0299752a7b85feeccb21a61603538caee7
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/71/143971/4 && git format-patch -1 --stdout FETCH_HEAD,['sandbox.mk'],1,024313993ec517cf5e34aad30745fdbd296842cd,support-ubuntu-trusty,mkdir -p $(SANDBOX_UBUNTU)/usr/sbin cat > $(SANDBOX_UBUNTU)/usr/sbin/policy-rc.d <<EOF #!/bin/sh # suppress services start in the staging chroots exit 101 EOF chmod 755 $(SANDBOX_UBUNTU)/usr/sbin/policy-rc.d mkdir -p $(SANDBOX_UBUNTU)/etc/init.d touch $(SANDBOX_UBUNTU)/etc/init.d/.legacy-bootordering,,9,0
openstack%2Ffuel-main~master~I1a9d94cbfd43e7778296b20434f5504f4bf7577d,openstack/fuel-main,master,I1a9d94cbfd43e7778296b20434f5504f4bf7577d,image/ubuntu: make list of packages less verbose,MERGED,2014-12-25 12:01:51.000000000,2015-01-12 17:02:37.000000000,2015-01-12 17:02:36.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5ec72a4669c0e7e6bc4869fcb564572fd79cb844', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 2, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/702dcbd5609b9d8fb5b8a4be7e5744c02b82bcd0', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 3, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4b61e42e1764ff84f2f1b3f2ee1fb2416ea62516', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 4, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c1385ac1d35e78f0a646e6f4cd421d741599719a', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 5, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a2a0c45aa62a079c82df567e9eb584628149bbc6', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 6, 'created': '2014-12-31 06:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/14cc99f25d3b533f1acbc9514ec9888b408c421c', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 7, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9f374fbcb31bcd52ac3c543e4e6c9b11fb5ac7bd', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}, {'number': 8, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/95b66909fe49c5bfe3530a994caf4c55bef9f8cd', 'message': 'image/ubuntu: make list of packages less verbose\n\nNow that all packages are installed with APT dependencies are handled\nproperly, so listing the dependencies manually is not necessary. Also use\nmeta-packages to get basic utilities (gcc, make, wget, etc) installed.\n\nblueprint support-ubuntu-trusty\nChange-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d\n'}]",0,143970,95b66909fe49c5bfe3530a994caf4c55bef9f8cd,38,7,8,13194,,,0,"image/ubuntu: make list of packages less verbose

Now that all packages are installed with APT dependencies are handled
properly, so listing the dependencies manually is not necessary. Also use
meta-packages to get basic utilities (gcc, make, wget, etc) installed.

blueprint support-ubuntu-trusty
Change-Id: I1a9d94cbfd43e7778296b20434f5504f4bf7577d
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/70/143970/8 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/module.mk'],1,5ec72a4669c0e7e6bc4869fcb564572fd79cb844,support-ubuntu-trusty,build-essential\ubuntu-standard\,wget\bind9-host\ cron\dnsutils\ file\ gcc\grub-pc-bin\ iptables\make\mlocate\perl\ rsync\util-linux\,2,13
openstack%2Fkeystone~master~I886d1ed2d2c67d779bad5425d4f40ab33eca0675,openstack/keystone,master,I886d1ed2d2c67d779bad5425d4f40ab33eca0675,Role revocation invalidates too many tokens,ABANDONED,2014-12-12 15:09:23.000000000,2015-01-12 17:02:28.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2014-12-12 15:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7cda9a44c0f6b5e376b93270c3b0fca3bc3396a5', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nFailing test case here. Work in progress.\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 2, 'created': '2014-12-12 15:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7933fc13340a77226f2817f8f2ab21e49d0fa4ff', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nFailing test case here. Work in progress.\n\nCloses-Bug: #1401926\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 3, 'created': '2014-12-12 16:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bee20e84dfc130d4dfa08d3e3c14f7eb7f493bef', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 4, 'created': '2014-12-12 17:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/800c371fca4054b58b6910ee94afed6727458e1c', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 5, 'created': '2014-12-12 17:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a5eb871b5fe2c5ee06d8d70b5964e2f3a7616b11', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 6, 'created': '2014-12-15 12:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9cf186b698cd7e9d4751c1df3e54020ab34e62b2', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 7, 'created': '2014-12-15 13:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b63229a9e378917f5ea9f131d04361b91b75f8d1', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 8, 'created': '2014-12-15 17:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b76bf98842a5d9eebd8b4f78199a464f46477eb', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 9, 'created': '2014-12-15 17:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/58db70890df19136fefa9d549884f2a2c3471dc8', 'message': 'Group role revocation invalidates all user tokens\n\nKeystone invalidates every token for a user after revoking one group role\nwithin one project.\n\nCloses-Bug: #1402760\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 10, 'created': '2014-12-15 17:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3d5398da1d7dc32b18ef4eefa3f1d79ac828e89', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nCloses-Bug: #1401926\n\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675\n'}, {'number': 11, 'created': '2014-12-16 23:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/11df7eb62d490c215517abd96b786e5ae64d5a47', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nRelated-Bug: #1401926\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675'}, {'number': 12, 'created': '2014-12-18 15:00:44.000000000', 'files': ['keystone/assignment/core.py', 'keystone/tests/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d83d173392414bad24248a9e7a90510b9d03aee8', 'message': 'Role revocation invalidates too many tokens\n\nKeystone invalidates every token for a user after changing its roles\nwithin one project.\n\nRemoved _emit_invalidate_user_token_persistence at the end of assignment\ndeletion operation which resulted in 2 excessive events matching all user\ntokens what caused all user tokens to become invalid.\n\nRelated-Bug: #1401926\nChange-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675'}]",1,141397,d83d173392414bad24248a9e7a90510b9d03aee8,31,4,12,13055,,,0,"Role revocation invalidates too many tokens

Keystone invalidates every token for a user after changing its roles
within one project.

Removed _emit_invalidate_user_token_persistence at the end of assignment
deletion operation which resulted in 2 excessive events matching all user
tokens what caused all user tokens to become invalid.

Related-Bug: #1401926
Change-Id: I886d1ed2d2c67d779bad5425d4f40ab33eca0675",git fetch https://review.opendev.org/openstack/keystone refs/changes/97/141397/12 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_v3_auth.py'],1,7cda9a44c0f6b5e376b93270c3b0fca3bc3396a5,bug/1401926," def test_removing_role_assignment_keeps_other_project_token(self): # Keystone invalidates _every_ token for a User after changing its roles within _one_ tenant self.assignment_api.create_grant(self.role1['id'], user_id=self.user1['id'], project_id=self.projectB['id']) project_token = self.get_requested_token( self.build_authentication_request( user_id=self.user1['id'], password=self.user1['password'], project_id=self.projectB['id'])) other_project_token = self.get_requested_token( self.build_authentication_request( user_id=self.user1['id'], password=self.user1['password'], project_id=self.projectA['id'])) self.assignment_api.delete_grant(self.role1['id'], user_id=self.user1['id'], project_id=self.projectB['id']) # authorization for the projectA should still succeed self.head('/auth/tokens', headers={'X-Subject-Token': other_project_token}, expected_status=200) ",,27,0
openstack%2Ffuel-main~master~I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8,openstack/fuel-main,master,I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8,mirror/ubuntu: avoid the base packages configuration failure,MERGED,2014-12-25 12:01:51.000000000,2015-01-12 17:02:18.000000000,2015-01-12 17:02:18.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/65fbe6a6b4803bbd5e9818f14bc395e55821e47d', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 2, 'created': '2014-12-26 10:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/071ceb89460d2c52a5ee86c3e2eeed3907b2f7ed', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare eliminated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8'}, {'number': 3, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c1336850d6f06d953875230130d7012ebdfcc2f7', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 4, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/234863ba7573adac34efd483f8259b5164b594ec', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 5, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/56e0d54bdce4a090ace6e2d08aea2ffb6ac9cd21', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 6, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/993fb63d2b0730daf7c863e1fea4784a1eb47297', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 7, 'created': '2014-12-31 06:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5a4cc42a8c678fa5a5e9e83381ff7b69bde3d457', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 8, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/51a7f20ffb308c14a7f79d03eab9654c56a5035b', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}, {'number': 9, 'created': '2015-01-02 15:48:37.000000000', 'files': ['mirror/ubuntu/createchroot.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/031fa47068602717edd2003c3de02e8cb4a2bd5d', 'message': 'mirror/ubuntu: avoid the base packages configuration failure\n\nSuppress setting the services startup order in the temporary chroot so\nthe base packages get configured properly. Makes it possible to install\nnon-trivial packages in the chroot. As a side effect the scary error\nmessages ""Errors were while processing: <long-list-of-base-packages>""\nare elimitated.\n\nblueprint support-ubuntu-trusty\nChange-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8\n'}]",3,143969,031fa47068602717edd2003c3de02e8cb4a2bd5d,45,8,9,13194,,,0,"mirror/ubuntu: avoid the base packages configuration failure

Suppress setting the services startup order in the temporary chroot so
the base packages get configured properly. Makes it possible to install
non-trivial packages in the chroot. As a side effect the scary error
messages ""Errors were while processing: <long-list-of-base-packages>""
are elimitated.

blueprint support-ubuntu-trusty
Change-Id: I558dbc7aff4de54d9295345d9ca3d4dc65c9fea8
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/69/143969/8 && git format-patch -1 --stdout FETCH_HEAD,['mirror/ubuntu/createchroot.mk'],1,65fbe6a6b4803bbd5e9818f14bc395e55821e47d,support-ubuntu-trusty," mkdir -p $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/init.d # Avoid base packages' configuration errors by preventing the postinst # scripts from fiddling with the services' start order. # Suppresses the scary error messages # ""Errors were while processing: <long-list-of-base-packages>' # and makes it possible to install non-trivial packages in the chroot touch $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/init.d/.legacy-bootordering",,7,0
openstack%2Ffuel-main~master~I6846b7d7107260125291efee27f6205b8e48969f,openstack/fuel-main,master,I6846b7d7107260125291efee27f6205b8e48969f,image/ubuntu: fix packages installation failures due to missing /proc,MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:02:06.000000000,2015-01-12 17:02:05.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ea3c2a4501d4184b5aa96cdd605e90bf753954f0', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f68a9cfeb98021ecf918ee961fb04739faa51711', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3a2efff5ccad95331523e8d77b9ba2333f679508', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/24c7d88b99d6ea9d46f1903454e57371724283ea', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/537116f5d4676f9a51feda5f33d9f1f4f69fcdb3', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cc0eaf47227341b119d59ab6d0ea8b6e6e1add07', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8a25bcd3fdcdaaf33be02d7016186034cf09b9bb', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6dd03af588f5aaf2af5befa5bfdbf064a758953f', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/72a803d70dc42a3742d67f4a68934837f2a3aa4e', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 10, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3b3e48acc709737a537b4e7269e5c985b47a952b', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}, {'number': 11, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/create_separate_images.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2c7395dae943e3098660653ecf7c0fb1dfb40d07', 'message': 'image/ubuntu: fix packages installation failures due to missing /proc\n\nThe configuration scripts of some packages (in particular linux-image)\nfail if /proc is not mounted. Mount /proc in the chroot before installing\npackages (and umount it afterwards).\n\nRelated-bug: #1383641\nCloses-bug: #1403435\nblueprint support-ubuntu-trusty\nChange-Id: I6846b7d7107260125291efee27f6205b8e48969f\n'}]",1,142409,2c7395dae943e3098660653ecf7c0fb1dfb40d07,52,7,11,13194,,,0,"image/ubuntu: fix packages installation failures due to missing /proc

The configuration scripts of some packages (in particular linux-image)
fail if /proc is not mounted. Mount /proc in the chroot before installing
packages (and umount it afterwards).

Related-bug: #1383641
Closes-bug: #1403435
blueprint support-ubuntu-trusty
Change-Id: I6846b7d7107260125291efee27f6205b8e48969f
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/09/142409/8 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/create_separate_images.sh'],1,ea3c2a4501d4184b5aa96cdd605e90bf753954f0,support-ubuntu-trusty,sudo chroot ${TMP_CHROOT_DIR} mount -t proc proc /procif mountpoint -q ${TMP_CHROOT_DIR}/proc; then sudo umount -l ${TMP_CHROOT_DIR}/proc || true fi ,,5,0
openstack%2Ffuel-main~master~I944ac00f8d95ada2a7920a0e4797fb0e187becb0,openstack/fuel-main,master,I944ac00f8d95ada2a7920a0e4797fb0e187becb0,image/ubuntu: umount the image properly,MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:01:57.000000000,2015-01-12 17:01:55.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/daa97c7e86c73fc7af3de147bf5bb7706cd261de', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7aecff5b2ac2172bc135068447bf31d94df040b6', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/39c6ce9f8ed18fb2020706462eb326efd874e237', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/785abb85b7bb19e93994a71687f8d64e5bd9c747', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2231af3310154b89a3af53311ea0b4f299c63c95', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d626faf13b4d5ec8c411e69bd5dc6242831d2647', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/09b09bf7b0d74c6d2efb19bb0475046fb4c8e8b7', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d93873987e36a3341a55f457752533348f73c889', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cc44b9fe54f46d1624441d9f6c109bd9a2306647', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 10, 'created': '2014-12-31 14:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/55acc5d434326785a1d2dd953bd4865b6f119d01', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}, {'number': 11, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/module.mk', 'image/ubuntu/create_separate_images.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ee6a2c53808d6aaa51512cbc98ef84b9f3124c90', 'message': 'image/ubuntu: umount the image properly\n\nTerminate any processes started in the chroot (by a sloppy postinst script,\netc) before umounting the image.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0\n'}]",1,142407,ee6a2c53808d6aaa51512cbc98ef84b9f3124c90,55,8,11,13194,,,0,"image/ubuntu: umount the image properly

Terminate any processes started in the chroot (by a sloppy postinst script,
etc) before umounting the image.

Related-bug: #1401764
blueprint support-ubuntu-trusty
Change-Id: I944ac00f8d95ada2a7920a0e4797fb0e187becb0
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/07/142407/1 && git format-patch -1 --stdout FETCH_HEAD,"['image/ubuntu/module.mk', 'image/ubuntu/create_separate_images.sh']",2,daa97c7e86c73fc7af3de147bf5bb7706cd261de,support-ubuntu-trusty,"# kill any stray process in chroot (just in a case some sloppy postinst # script still hanging around) signal_chrooted_processes() { local chroot_dir=""$1"" local signal=""$2"" local proc_root for p in `sudo fuser -v ""$chroot_dir""`; do proc_root=""`readlink -f /proc/$p/root || true`"" if [ ""$proc_root"" = ""$chroot_dir"" ]; then sudo kill -s ""$signal"" $p fi done } signal_chrooted_processes $TMP_CHROOT_DIR TERM sleep 1 signal_chrooted_processes $TMP_CHROOT_DIR KILL ",,23,0
openstack%2Ffuel-main~master~I8746637a03515868d6a568165fdce150b91c6844,openstack/fuel-main,master,I8746637a03515868d6a568165fdce150b91c6844,"image/ubuntu: don't install packages with debootstrap, use apt instead",MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:01:23.000000000,2015-01-12 17:01:23.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}, {'_account_id': 13895}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/990495cf4cde04f777ae72734f0d58f598b041a3', 'message': ""ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e21919d973c117cb6f054e296f26b5575c8e6e5b', 'message': ""ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/860ad358c6defe241a75f140a99681edf5970f4d', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1bad0cdde56b77465539a9275278a948e03a6a7f', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9afeb62b47552457d8582af01315a3afa0a64461', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fa6ea8211596fb8e99358fe4ff8d19238ae012a7', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4a612170d2d5c12c1b2f44f9e6ae9c3c3010c8e9', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4f63b8fee6b144e2e1eac2b595e4a73007bcf9d1', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/807991106522453707258c9bc5131864853749e7', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}, {'number': 10, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5bee58befdb8f8da23f6b52cfbb3022fbc00a62c', 'message': ""image/ubuntu: don't install packages with debootstrap, use apt instead\n\nDependency handling in debootstrap is very primitive. For instance,\ndebootstrap happily picks an i386 version of a shared library if\nthe corresponding amd64 package is not available.\nAlso debootstrap does not obey the policy regarding (not) starting\nservices which breaks the ISO build.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I8746637a03515868d6a568165fdce150b91c6844\n""}]",0,142406,5bee58befdb8f8da23f6b52cfbb3022fbc00a62c,57,8,10,13194,,,0,"image/ubuntu: don't install packages with debootstrap, use apt instead

Dependency handling in debootstrap is very primitive. For instance,
debootstrap happily picks an i386 version of a shared library if
the corresponding amd64 package is not available.
Also debootstrap does not obey the policy regarding (not) starting
services which breaks the ISO build.

Related-bug: #1401764
blueprint support-ubuntu-trusty
Change-Id: I8746637a03515868d6a568165fdce150b91c6844
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/06/142406/7 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/module.mk'],1,990495cf4cde04f777ae72734f0d58f598b041a3,support-ubuntu-trusty, PKGS_APTGET:=\ wget\$(BUILD_DIR)/images/$(TARGET_UBUNTU_IMG_ART_NAME): export DEBOOTSTRAP_PARAMS=--no-check-gpg --arch=$(UBUNTU_ARCH) $(UBUNTU_RELEASE) $(TMP_CHROOT) file://$(LOCAL_MIRROR)/ubuntu,"PKGS_INCLUDE:=\wget PKGS_APTGET:=\$(BUILD_DIR)/images/$(TARGET_UBUNTU_IMG_ART_NAME): export DEBOOTSTRAP_PARAMS=--no-check-gpg --arch=$(UBUNTU_ARCH) --include=$(subst $(space),$(comma),$(PKGS_INCLUDE)) $(UBUNTU_RELEASE) $(TMP_CHROOT) file://$(LOCAL_MIRROR)/ubuntu",4,5
openstack%2Ffuel-main~master~I8c104a41d267e30feea72619ae4ad27b6d59a562,openstack/fuel-main,master,I8c104a41d267e30feea72619ae4ad27b6d59a562,image/ubuntu: suppress the packages' configuration dialogs,MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:01:11.000000000,2015-01-12 17:01:10.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6bab61f4dd41c1b3ab86ca70d2ff43b5737ff5f2', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e77bd4b4ee193e1c1c728eeca7e0e6027cf908ff', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a6703e199d3c95b422c81257b4a2459f38123d57', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f6bdde5f05042f54b9e7befcda105c0dbb982e2c', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9ec6beef001b8963c0fabd3ae093e66e44a523da', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/44cebfbc6a81b2affc132129345c6c8f12bb0401', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e17f5566c990f52e033f7d241db0ba5250e16e44', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/efbccb1735706463f3ed9cf32fbc9568409fdca2', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/aba454f721f6bf6faa84e3a8e38004edcdd188b2', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}, {'number': 10, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/create_separate_images.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1efbeeb69df3f508be3c881b6fbb01ae4e1a56ef', 'message': ""image/ubuntu: suppress the packages' configuration dialogs\n\nmake iso stops during creation of the Ubuntu chroot (intended for image\nbased provisioning) and displays packages' configuration dialogs\n(in particular postfix). Force a non-interactive packages installation.\nWhile at it suppress the warnings regarding an unsupported locale.\n\nCloses-bug: #1403390\nRelated-bug: #1383641\nblueprint support-ubuntu-trusty\nChange-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562\n""}]",0,142408,1efbeeb69df3f508be3c881b6fbb01ae4e1a56ef,48,8,10,13194,,,0,"image/ubuntu: suppress the packages' configuration dialogs

make iso stops during creation of the Ubuntu chroot (intended for image
based provisioning) and displays packages' configuration dialogs
(in particular postfix). Force a non-interactive packages installation.
While at it suppress the warnings regarding an unsupported locale.

Closes-bug: #1403390
Related-bug: #1383641
blueprint support-ubuntu-trusty
Change-Id: I8c104a41d267e30feea72619ae4ad27b6d59a562
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/08/142408/8 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/create_separate_images.sh'],1,6bab61f4dd41c1b3ab86ca70d2ff43b5737ff5f2,support-ubuntu-trusty,"sudo chroot ${TMP_CHROOT_DIR} \ env DEBIAN_FRONTEND=noninteractive \ apt-get -y install ${INSTALL_PACKAGES} || die ""Couldn't install the rest of packages successfully""","sudo chroot ${TMP_CHROOT_DIR} apt-get -y install ${INSTALL_PACKAGES} || die ""Couldn't install the rest of packages successfully""",3,1
openstack%2Fhorizon~stable%2Fjuno~Ic628772112aae2d320d8d8342305c33d7ada6822,openstack/horizon,stable/juno,Ic628772112aae2d320d8d8342305c33d7ada6822,Remove glyphicon-eye-open icon from Description,MERGED,2014-10-25 13:45:49.000000000,2015-01-12 17:00:53.000000000,2015-01-12 17:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 979}, {'_account_id': 1420}, {'_account_id': 1941}, {'_account_id': 1955}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 8040}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10295}, {'_account_id': 11592}, {'_account_id': 11941}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-10-25 13:45:49.000000000', 'files': ['horizon/templates/horizon/common/_modal_form.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b2dc30d23c8a7adffe048d8cd0775ba2dc97966f', 'message': 'Remove glyphicon-eye-open icon from Description\n\nThe glyphicon-eye-open icon is displayed in the Description section\nof the \'Create User\' and \'Update User\' form under the Identify->Users\npanel. This is because the no_autocomplete field has been set to\n\'True\' for both the \'Create User\' and \'Update User\' forms. Enabling\nthis field causes an input of type=""password"" and name=""fake_password""\nto be added inorder to prevent Chrome v34+ from autofilling the form.\n\nChange-Id: Ic628772112aae2d320d8d8342305c33d7ada6822\nCloses-Bug: #1371787\n(cherry picked from commit 05fda729233c5db49b01eff754c7a36f40595d92)\n'}]",0,130946,b2dc30d23c8a7adffe048d8cd0775ba2dc97966f,29,18,1,841,,,0,"Remove glyphicon-eye-open icon from Description

The glyphicon-eye-open icon is displayed in the Description section
of the 'Create User' and 'Update User' form under the Identify->Users
panel. This is because the no_autocomplete field has been set to
'True' for both the 'Create User' and 'Update User' forms. Enabling
this field causes an input of type=""password"" and name=""fake_password""
to be added inorder to prevent Chrome v34+ from autofilling the form.

Change-Id: Ic628772112aae2d320d8d8342305c33d7ada6822
Closes-Bug: #1371787
(cherry picked from commit 05fda729233c5db49b01eff754c7a36f40595d92)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/130946/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_modal_form.html'],1,b2dc30d23c8a7adffe048d8cd0775ba2dc97966f,bug/1371787," <div class=""fake_credentials"" style=""display: none""> <input type=""text"" name=""fake_email"" value="""" /> <input type=""password"" name=""fake_password"" value="""" /> </div>"," <input type=""text"" name=""fake_email"" value="""" style=""display: none"" /> <input type=""password"" name=""fake_password"" value="""" style=""display: none"" />",4,2
openstack%2Ffuel-main~master~Ie22009923acd7a84ecf2435a0294560e47dce3cc,openstack/fuel-main,master,Ie22009923acd7a84ecf2435a0294560e47dce3cc,image/ubuntu: prevent services from being started in a staging chroot,MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:00:43.000000000,2015-01-12 17:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/008e35f55c33691fc254ee952d42953eef45005f', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/95f781a512491e99ccbd722ed1c00feacac7693c', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/61cd1ae4b2f08ed52991fa9ebb45dbbc591be69f', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ca2651ac7feba69ed4d35837f48fed89eae8020f', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4b5ccc68df9ba76121a432d2e960b2262b767a13', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1de2b6dc1b5e9fd7fcc82cb56e42f605c96b707f', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c2e8655f903b147bfffa8105ddec3d34438da2a6', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/507f077e8e4cbaf832aa3e8ed8baf1af6890fcfd', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/31f9643b51b0a4a2e174effb8f70954d70aa2af6', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}, {'number': 10, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/create_separate_images.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1538da8a7c7db620d361eb973df1328c760ad67c', 'message': 'image/ubuntu: prevent services from being started in a staging chroot\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc\n'}]",0,142405,1538da8a7c7db620d361eb973df1328c760ad67c,47,7,10,13194,,,0,"image/ubuntu: prevent services from being started in a staging chroot

Related-bug: #1401764
blueprint support-ubuntu-trusty
Change-Id: Ie22009923acd7a84ecf2435a0294560e47dce3cc
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/05/142405/9 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/create_separate_images.sh'],1,008e35f55c33691fc254ee952d42953eef45005f,support-ubuntu-trusty,# inhibit service startup in the chroot cat > policy-rc.d << EOF #!/bin/sh # prevent any service from being started exit 101 EOF chmod 755 policy-rc.d sudo cp policy-rc.d ${TMP_CHROOT_DIR}/usr/sbin # re-enable services sudo rm ${TMP_CHROOT_DIR}/usr/sbin/policy-rc.d ,,12,0
openstack%2Ffuel-main~master~I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21,openstack/fuel-main,master,I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21,image/ubuntu: depend on Ubuntu mirror only,MERGED,2014-12-17 10:13:18.000000000,2015-01-12 17:00:17.000000000,2015-01-12 17:00:15.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-17 10:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d730d1d81dc98b5765efab1548048443da86b1d7', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror.\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 2, 'created': '2014-12-18 06:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/62f7f4defb9e0b145d7c929c061fb423ecd018f2', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror.\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 3, 'created': '2014-12-22 09:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/90277ee9d4ba911d47946a3ab66a95b1f903f07d', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fc834ef0c26e58d63c571bd31bed0a9a9f5230a5', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0a4712ef1cb10f6224beedeef99e345fed411227', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4edc5b7e543238f183609a6b7a1d24bb288a1d6a', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/15c0c69a9b5c24919453b78d39c2ca4e56dc1d72', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fe69ad01d5f95d64bb9dd6a46c99def15fa9a2a6', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/65995f334c506d19b95af26649b853603dd9c2c4', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}, {'number': 10, 'created': '2015-01-02 15:48:37.000000000', 'files': ['image/ubuntu/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d118a1ed69825e154652b6b508d44091391e6c59', 'message': 'image/ubuntu: depend on Ubuntu mirror only\n\nCreating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at\nit add a dependency on locally built packages (packages/deb).\nMakes debugging of Ubuntu related problems much faster.\n\nRelated-bug: #1401764\nblueprint support-ubuntu-trusty\nChange-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21\n'}]",0,142404,d118a1ed69825e154652b6b508d44091391e6c59,48,7,10,13194,,,0,"image/ubuntu: depend on Ubuntu mirror only

Creating an Ubuntu chroot does not use the rpm (CentOS) mirror. While at
it add a dependency on locally built packages (packages/deb).
Makes debugging of Ubuntu related problems much faster.

Related-bug: #1401764
blueprint support-ubuntu-trusty
Change-Id: I10419bd930e58da7b99c1f2e8c6ddaf6c9eb0b21
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/04/142404/10 && git format-patch -1 --stdout FETCH_HEAD,['image/ubuntu/module.mk'],1,d730d1d81dc98b5765efab1548048443da86b1d7,support-ubuntu-trusty,$(BUILD_DIR)/images/$(TARGET_UBUNTU_IMG_ART_NAME): $(BUILD_DIR)/mirror/ubuntu/build.done,$(BUILD_DIR)/images/$(TARGET_UBUNTU_IMG_ART_NAME): $(BUILD_DIR)/mirror/build.done,1,1
openstack%2Ffuel-main~master~Ie683dc0d03e253dc6986ba3650e529796ffd5dc7,openstack/fuel-main,master,Ie683dc0d03e253dc6986ba3650e529796ffd5dc7,Add mirror-ubuntu and mirror-centos targets,MERGED,2014-09-25 12:33:19.000000000,2015-01-12 17:00:05.000000000,2015-01-12 17:00:04.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-09-25 12:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/af992d90283be6a1b5047773381fbe1049e6d0bb', 'message': ""Add mirror-ubuntu target\n\nSo it's easy to rebuild the Ubuntu mirror without rebuilding the whole ISO\n\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n""}, {'number': 2, 'created': '2014-11-14 13:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/50a871740443d9289e6e7db70660963564801357', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 3, 'created': '2014-12-17 17:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7e6c1d582f9463c1333881de304d95a7d14be362', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 4, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/604c17472d9bcd2650cefaa7ab263c5cd87de286', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 5, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c611e030d5d18d69a073a09a36fbb1808b5a5180', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 6, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9b6ee59e3457c1195c169873ee883326c94e92eb', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 7, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d322a9a0ebe92b0372915edadf55894f6845bd8c', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 8, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1eceaba2336ed9ce463f732ff1549b74631c27de', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 9, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/82af83652b4831816a1e8c52d27ea7fedff2443e', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}, {'number': 10, 'created': '2015-01-02 15:48:37.000000000', 'files': ['mirror/centos/module.mk', 'mirror/ubuntu/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/872b4395f178709f75c7678e36abaa95330914a1', 'message': 'Add mirror-ubuntu and mirror-centos targets\n\nUseful for updating the Ubuntu (CentOS) packages mirror without rebuilding\nthe whole ISO (and without re-deploying the Fuel master node).\n\nblueprint support-ubuntu-trusty\nChange-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7\n'}]",4,124033,872b4395f178709f75c7678e36abaa95330914a1,50,8,10,13194,,,0,"Add mirror-ubuntu and mirror-centos targets

Useful for updating the Ubuntu (CentOS) packages mirror without rebuilding
the whole ISO (and without re-deploying the Fuel master node).

blueprint support-ubuntu-trusty
Change-Id: Ie683dc0d03e253dc6986ba3650e529796ffd5dc7
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/124033/4 && git format-patch -1 --stdout FETCH_HEAD,['mirror/ubuntu/module.mk'],1,af992d90283be6a1b5047773381fbe1049e6d0bb,support-ubuntu-trusty,mirror-ubuntu: $(BUILD_DIR)/mirror/ubuntu/build.done,,1,0
openstack%2Ffuel-main~master~Ib43c015ed953c80a73a8269168cc4d3f89b08e7a,openstack/fuel-main,master,Ib43c015ed953c80a73a8269168cc4d3f89b08e7a,ubuntu: use security updates APT repository,MERGED,2014-12-01 16:06:53.000000000,2015-01-12 16:59:35.000000000,2015-01-12 16:59:35.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-12-01 16:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5fd505aa7deae97b619244dfde5036cbc1c64f3f', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 2, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/67d9de583583e7cbe8a43cbbf31bc73a0608d16e', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 3, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/57d3b2c1b477f3ae66fa955e9a58f2cdcd89de02', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 4, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/58e4996f1181d68bcda47e12eac721153e083551', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 5, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/937827b41f609ac2a0cd06a3e99f4425c2d16696', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 6, 'created': '2014-12-30 13:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/adf2c2e55ff91ffcd2472fdc5efc7f65a1b1b76e', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 7, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/41db2f17df8e596b4b04777e0060c55151673c71', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}, {'number': 8, 'created': '2015-01-02 15:48:37.000000000', 'files': ['mirror/ubuntu/multistrap.conf', 'config.mk', 'mirror/ubuntu/createchroot.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a9e0429446b47f5b9097799b37ec97546bd7370c', 'message': 'ubuntu: use security updates APT repository\n\nMirantis mirror has a separate APT repository with security updates instead\nof the common ${ubuntu_release}-updates component (which is assumed by apt\nand friends). Use that repository when building the ISO with USE_MIRROR=none\n\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a\n'}]",0,138110,a9e0429446b47f5b9097799b37ec97546bd7370c,42,8,8,13194,,,0,"ubuntu: use security updates APT repository

Mirantis mirror has a separate APT repository with security updates instead
of the common ${ubuntu_release}-updates component (which is assumed by apt
and friends). Use that repository when building the ISO with USE_MIRROR=none

DocImpact
blueprint support-ubuntu-trusty
Change-Id: Ib43c015ed953c80a73a8269168cc4d3f89b08e7a
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/10/138110/8 && git format-patch -1 --stdout FETCH_HEAD,"['mirror/ubuntu/multistrap.conf', 'config.mk', 'mirror/ubuntu/createchroot.mk']",3,5fd505aa7deae97b619244dfde5036cbc1c64f3f,support-ubuntu-trusty," -e 's|@@MIRROR_UBUNTU_SECURITY@@|$(MIRROR_UBUNTU_SECURITY)|g' \ ubuntu_lst=""$(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/apt/sources.list.d/ubuntu.list""; \ echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE) universe multiverse restricted | sudo tee -a ""$$ubuntu_lst""; \ echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE)-updates main universe multiverse restricted | sudo tee -a ""$$ubuntu_lst""; \ echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE)-security main universe multiverse restricted | sudo tee -a ""$$ubuntu_lst""; \ echo deb $(MIRROR_UBUNTU_SECURITY) $(UBUNTU_RELEASE)-security main universe multiverse restricted | sudo tee -a ""$$ubuntu_lst""; \", echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE) universe multiverse restricted | sudo tee -a $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/apt/sources.list.d/ubuntu.list; \ echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE)-updates main universe multiverse restricted | sudo tee -a $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/apt/sources.list.d/ubuntu.list; \ echo deb $(MIRROR_UBUNTU) $(UBUNTU_RELEASE)-security main universe multiverse restricted | sudo tee -a $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/apt/sources.list.d/ubuntu.list; \,16,3
openstack%2Ffuel-main~master~Idbd86e0edab3531d098f7fef0dd0c4abe1798e81,openstack/fuel-main,master,Idbd86e0edab3531d098f7fef0dd0c4abe1798e81,mirror/ubuntu: use HTTP proxy for downloading the packages,MERGED,2014-12-25 12:01:51.000000000,2015-01-12 16:58:21.000000000,2015-01-12 16:58:19.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fab944a148c901a221618dd5a3776a1df2cde9fc', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}, {'number': 2, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/99659795562d7d77ae7bd4d76642c3796f4e7e92', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}, {'number': 3, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/37af4f3a7eb5c4734fed4f3d645034975bde053f', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}, {'number': 4, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b488931afc181e544fd5ffd32acba956db078e52', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}, {'number': 5, 'created': '2014-12-31 06:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/58740ab939b239d3c4374409855997efafcd19e9', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}, {'number': 6, 'created': '2015-01-02 15:48:37.000000000', 'files': ['mirror/ubuntu/createchroot.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/af85b38ff9d23de4af5311bb3832edcd820f1475', 'message': 'mirror/ubuntu: use HTTP proxy for downloading the packages\n\nPass the http_proxy/HTTP_PROXY environment variables (if set) to\nthe temporary chroot where the packages get actually downloaded.\n\nblueprint support-ubuntu-trusty\n\nChange-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81\n'}]",0,143968,af85b38ff9d23de4af5311bb3832edcd820f1475,31,7,6,13194,,,0,"mirror/ubuntu: use HTTP proxy for downloading the packages

Pass the http_proxy/HTTP_PROXY environment variables (if set) to
the temporary chroot where the packages get actually downloaded.

blueprint support-ubuntu-trusty

Change-Id: Idbd86e0edab3531d098f7fef0dd0c4abe1798e81
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/68/143968/6 && git format-patch -1 --stdout FETCH_HEAD,['mirror/ubuntu/createchroot.mk'],1,fab944a148c901a221618dd5a3776a1df2cde9fc,support-ubuntu-trusty," extra_env=""""; \ if [ -n ""$$HTTP_PROXY"" ] || [ -n ""$$http_proxy"" ]; then \ HTTP_PROXY=""$${HTTP_PROXY:-$${http_proxy}}""; \ echo ""Acquire::http { Proxy \""$$HTTP_PROXY\""; };"" | sudo tee $(LOCAL_MIRROR_UBUNTU_OS_BASEURL)/chroot/etc/apt/apt.conf.d/03-use-proxy; \ extra_env=""HTTP_PROXY=$${HTTP_PROXY} http_proxy=$${HTTP_PROXY}""; \ fi; \ $$extra_env \",,7,0
openstack%2Ffuel-main~master~I93aeeca045a41e6e4e5654ac61bba4cbf6917066,openstack/fuel-main,master,I93aeeca045a41e6e4e5654ac61bba4cbf6917066,mirror/ubuntu: download the base packages properly,MERGED,2014-12-25 12:01:51.000000000,2015-01-12 16:58:08.000000000,2015-01-12 16:58:07.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 11090}, {'_account_id': 13194}]","[{'number': 1, 'created': '2014-12-25 12:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4b0e4a7917be554b03f56f39b6b136a8969f7736', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}, {'number': 2, 'created': '2014-12-30 10:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/34af8cfda6c66a33762010ba6937ae0095949f3b', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}, {'number': 3, 'created': '2014-12-30 12:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/87cc0378eae3af07d89bb1fb9a8328512fa4e297', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}, {'number': 4, 'created': '2014-12-30 13:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4a2292516bf8713de1c2ef230d993a471643057f', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}, {'number': 5, 'created': '2014-12-31 06:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9d971cfc13165af21d9098ee6e5215bced95656b', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}, {'number': 6, 'created': '2015-01-02 15:48:37.000000000', 'files': ['mirror/ubuntu/files/mkrepo.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2e1ed23de78cc905354f4ede7a6e1b68e9c2b361', 'message': 'mirror/ubuntu: download the base packages properly\n\nCreate an empty dpkg/apt state so the base packages get download just like\nany others (instead of picking the base packages from the APT cache).\n\nWhile at it stop installing the kernel in the staging chroot (the chroot\ngets erased after downloading the packages, so installing kernel makes no\nsense), and remove the obsolete (and misleading) comments.\n\nCloses-bug: #1405160\nDocImpact\nblueprint support-ubuntu-trusty\nChange-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066\n'}]",7,143967,2e1ed23de78cc905354f4ede7a6e1b68e9c2b361,39,8,6,13194,,,0,"mirror/ubuntu: download the base packages properly

Create an empty dpkg/apt state so the base packages get download just like
any others (instead of picking the base packages from the APT cache).

While at it stop installing the kernel in the staging chroot (the chroot
gets erased after downloading the packages, so installing kernel makes no
sense), and remove the obsolete (and misleading) comments.

Closes-bug: #1405160
DocImpact
blueprint support-ubuntu-trusty
Change-Id: I93aeeca045a41e6e4e5654ac61bba4cbf6917066
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/67/143967/5 && git format-patch -1 --stdout FETCH_HEAD,['mirror/ubuntu/files/mkrepo.sh'],1,4b0e4a7917be554b03f56f39b6b136a8969f7736,support-ubuntu-trusty,"requirements_add_essential_pkgs () { # All essential packages are already installed, so ask dpkg for a list dpkg-query -W -f='${Package} ${Essential}\n' > /tmp/essential.pkgs sed -i /tmp/essential.pkgs -n -e 's/\([^ ]\+\).*yes$/\1/p' cat /tmp/essential.pkgs >> /requirements-deb.txt } # Note: apt-get install --print-uris package # is not going to print anything if the package is already installed. Thus # the base packages will be omitted if we use the main APT/dpkg settings. # Pretend that no package has been installed by creating an alternative APT # state and configuration directories. # Previously we used to copy all debs from the APT cache which is unreliable: # - a wrong version of the package might be included # - multiple revisions of the same package might be included apt_altstate=""/apt-altstate"" rm -rf ""$apt_altstate"" apt_lists_dir=""$apt_altstate/var/lib/apt/lists"" apt_cache_dir=""$apt_altstate/var/cache/apt"" null_dpkg_status=""$apt_altstate/var/lib/dpkg/status"" mkdir -p ""$apt_lists_dir"" mkdir -p ""$apt_cache_dir"" mkdir -p ""${null_dpkg_status%/*}"" touch ""${null_dpkg_status}"" apt_altstate_opts=""-o APT::Get::AllowUnauthenticated=1"" apt_altstate_opts=""${apt_altstate_opts} -o Dir::State::Lists=${apt_lists_dir}"" apt_altstate_opts=""${apt_altstate_opts} -o Dir::State::status=${null_dpkg_status}"" apt_altstate_opts=""${apt_altstate_opts} -o Dir::Cache=${apt_cache_dir}"" if ! apt-get $apt_altstate_opts update; then echo ""mkrepo.sh: failed to populate alt apt state"" exit 1 fi requirements_add_essential_pkgs if ! apt-get $apt_altstate_opts --print-uris --yes -qq install $pkg >""${downloads_list}"" 2>>""/apt-errors.log""; then apt-get $apt_altstate_opts --print-uris --yes install $pkg >>/apt-errors.log 2>&1 || truerm -rf ""$apt_altstate"" ","apt-get update #for pkg in $(cat /requirements-deb.txt | grep -Ev ""^#""); do # apt-get -dy install $pkg || exit 1 #done if ! apt-get --print-uris --yes -qq install $pkg >""${downloads_list}"" 2>>""/apt-errors.log""; then apt-get --print-uris --yes install $pkg >>/apt-errors.log 2>&1 || truemv /var/cache/apt/archives/*deb /repo/download/apt-get -dy install linux-image-${UBUNTU_INSTALLER_KERNEL_VERSION} || exit 1 ## Get latest kernel version ## Exact kernel version specified in requirements-deb.txt ## and preseed template ubuntu-1204.preseed.erb #kernelver=`cat ${wrkdir}/override.${UBUNTU_RELEASE}.main | egrep ""^linux\-image\-[0-9]+"" | awk '{print $1}' | sort -rV | head -1 | egrep -o ""[0-9]+\.[0-9]+\.[0-9]+\-[0-9]+""` #apt-get -dy install --reinstall linux-image-$kernelver || exit 1 #apt-get -dy install --reinstall linux-headers-$kernelver || exit 1 ",41,17
openstack%2Fapi-sig~master~I9dc97a7aa369198ba0408452004da7ba4a73559a,openstack/api-sig,master,I9dc97a7aa369198ba0408452004da7ba4a73559a,Add a general proposal for usable-with-curl,ABANDONED,2014-10-29 12:51:13.000000000,2015-01-12 16:55:49.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 261}, {'_account_id': 668}, {'_account_id': 970}, {'_account_id': 1063}, {'_account_id': 2284}, {'_account_id': 5292}, {'_account_id': 6773}, {'_account_id': 8505}, {'_account_id': 10670}, {'_account_id': 11564}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-10-29 12:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/8ed722af476943b4228b0695cc6e2b594fcb0e90', 'message': 'Add a general proposal for usable-with-curl\n\nIf an API cannot be driven by hand with curl, then it\nis too complex and probably suffers from poor resource design.\n\nChange-Id: I9dc97a7aa369198ba0408452004da7ba4a73559a\n'}, {'number': 2, 'created': '2014-11-17 18:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-sig/commit/132ad68f547b5ae6e9d4a7445cc5eff0c31c70a4', 'message': 'Add a general proposal for usable-with-curl\n\nIf an API cannot be driven by hand with curl, then it\nis too complex and probably suffers from poor resource design.\n\nChange-Id: I9dc97a7aa369198ba0408452004da7ba4a73559a\n'}, {'number': 3, 'created': '2015-01-06 14:45:10.000000000', 'files': ['guidelines/general.rst'], 'web_link': 'https://opendev.org/openstack/api-sig/commit/24452c2fdc6ffce727bb2a340ad1b3f4c1807ddf', 'message': 'Add a general proposal for usable-with-curl\n\nIf an API cannot be driven by hand with curl, then it\nis too complex and probably suffers from poor resource design.\n\nChange-Id: I9dc97a7aa369198ba0408452004da7ba4a73559a\n'}]",5,131736,24452c2fdc6ffce727bb2a340ad1b3f4c1807ddf,26,14,3,11564,,,0,"Add a general proposal for usable-with-curl

If an API cannot be driven by hand with curl, then it
is too complex and probably suffers from poor resource design.

Change-Id: I9dc97a7aa369198ba0408452004da7ba4a73559a
",git fetch https://review.opendev.org/openstack/api-sig refs/changes/36/131736/1 && git format-patch -1 --stdout FETCH_HEAD,['guidelines/general.rst'],1,8ed722af476943b4228b0695cc6e2b594fcb0e90,cd/usable-by-curl," 2. Where possible an HTTP API should strive to be simple and readable enough that it is possible to interact with the API with curl or other, similar, command line tools. This is not because we wish to encourage people to use curl to interact with the API but rather that an API which can be used with curl is: * An API for which it is easy to create a client implementation. * An API that is easy to demonstrate in documentation.",,10,0
openstack%2Fkeystone~master~I18d863080e653c95f31e2f672e18c8ea857980b2,openstack/keystone,master,I18d863080e653c95f31e2f672e18c8ea857980b2,Expose bug in token revocation for projects,ABANDONED,2014-12-16 13:27:18.000000000,2015-01-12 16:55:00.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-12-16 13:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c4e25194a60feb6ce645bfb9a2053fe4257c1e8c', 'message': 'Expose bug in token revocation for projects\n\nWhen a user has tokens scoped to different projects and a role assignment\nfor the user is removed from one of the projects, all tokens are revoked.\nThis commit exposes the bug.\n\nChange-Id: I18d863080e653c95f31e2f672e18c8ea857980b2\nRelated-Bug: #1401926\n'}, {'number': 2, 'created': '2015-01-02 18:32:49.000000000', 'files': ['keystone/tests/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/94cef51bc5738d3990c97585a87892d8d690fc79', 'message': 'Expose bug in token revocation for projects\n\nWhen a user has tokens scoped to different projects and a role assignment\nfor the user is removed from one of the projects, all tokens are revoked.\nThis commit exposes the bug.\n\nChange-Id: I18d863080e653c95f31e2f672e18c8ea857980b2\nRelated-Bug: #1401926\n'}]",0,142099,94cef51bc5738d3990c97585a87892d8d690fc79,14,3,2,5046,,,0,"Expose bug in token revocation for projects

When a user has tokens scoped to different projects and a role assignment
for the user is removed from one of the projects, all tokens are revoked.
This commit exposes the bug.

Change-Id: I18d863080e653c95f31e2f672e18c8ea857980b2
Related-Bug: #1401926
",git fetch https://review.opendev.org/openstack/keystone refs/changes/99/142099/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_v3_auth.py'],1,c4e25194a60feb6ce645bfb9a2053fe4257c1e8c,bug/1401926," def test_delete_role_assignment_from_user_revokes_all_tokens(self): # Assign user1 a role on projectA self.assignment_api.create_grant(self.role1['id'], user_id=self.user1['id'], project_id=self.projectA['id']) # Assign user1 a role on projectB self.assignment_api.create_grant(self.role1['id'], user_id=self.user1['id'], project_id=self.projectB['id']) # Get a token scoped to projectA projectA_token = self.get_requested_token( self.build_authentication_request( user_id=self.user1['id'], password=self.user1['password'], project_id=self.projectA['id'])) # Get a token scoped to projectB projectB_token = self.get_requested_token( self.build_authentication_request( user_id=self.user1['id'], password=self.user1['password'], project_id=self.projectB['id'])) # Remove user1's role assignment from projectB self.assignment_api.delete_grant(self.role1['id'], user_id=self.user1['id'], project_id=self.projectB['id']) # FIXME(lbragstad): This token shouldn't be revoked, see bug #1401926 self.head('/auth/tokens', headers={'X-Subject-Token': projectA_token}, expected_status=404) # The projectB token should be revoked self.head('/auth/tokens', headers={'X-Subject-Token': projectB_token}, expected_status=404) ",,40,0
openstack%2Ffuel-main~master~Ifedbae029ec5183e99e78b998638a225eb1bcab4,openstack/fuel-main,master,Ifedbae029ec5183e99e78b998638a225eb1bcab4,Fix double import settings,MERGED,2015-01-12 16:06:11.000000000,2015-01-12 16:42:19.000000000,2015-01-12 16:42:17.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11577}, {'_account_id': 11969}]","[{'number': 1, 'created': '2015-01-12 16:06:11.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/9c2ff786daec24e3f9128cb0566e1e91901cd816', 'message': 'Fix double import settings\n\nChange-Id: Ifedbae029ec5183e99e78b998638a225eb1bcab4\n'}]",0,146539,9c2ff786daec24e3f9128cb0566e1e91901cd816,11,6,1,13306,,,0,"Fix double import settings

Change-Id: Ifedbae029ec5183e99e78b998638a225eb1bcab4
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/146539/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,9c2ff786daec24e3f9128cb0566e1e91901cd816,," mode=DEPLOYMENT_MODE_SIMPLE, 'host_ip': VCENTER_IP, 'vc_user': VCENTER_USERNAME, 'vc_password': VCENTER_PASSWORD, 'cluster': VCENTER_CLUSTERS, mode=DEPLOYMENT_MODE_HA, 'host_ip': VCENTER_IP, 'vc_user': VCENTER_USERNAME, 'vc_password': VCENTER_PASSWORD, 'cluster': VCENTER_CLUSTERS,"," mode=settings.DEPLOYMENT_MODE_SIMPLE, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, mode=settings.DEPLOYMENT_MODE_HA, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS,",10,10
openstack%2Fnova~master~I270cbd8fb78498f5ed415dd183a80b3fbfd683b2,openstack/nova,master,I270cbd8fb78498f5ed415dd183a80b3fbfd683b2,Add delete_member method to instance group object,ABANDONED,2014-11-21 20:59:19.000000000,2015-01-12 16:28:52.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 7166}, {'_account_id': 7221}, {'_account_id': 7664}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-21 20:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f80e3427a267128d99d0e3b234f20791d1fc539', 'message': ""Add 'remove server from server group' API\n\nAdds a new remove_server action to the server group APIs. Adds\na delete_member method to the InstanceGroup Nova object. Updates\npolicy with remove_server action.\n\nblueprint dynamic-server-groups-remove\n\nChange-Id: I270cbd8fb78498f5ed415dd183a80b3fbfd683b2\n""}, {'number': 2, 'created': '2014-11-24 22:52:32.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_instance_group.py', 'nova/objects/instance_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/32902a191b955d409ee513e88cc459f64a8bbad1', 'message': 'Add delete_member method to instance group object\n\nAdds a new delete_member method to the InstanceGroup Nova object. This method\ncalls the database instance_group_member_delete API which does a soft delete\nof the instance in the instance group members table.\n\nblueprint dynamic-server-groups-remove\n\nChange-Id: I270cbd8fb78498f5ed415dd183a80b3fbfd683b2\n'}]",2,136488,32902a191b955d409ee513e88cc459f64a8bbad1,20,15,2,7221,,,0,"Add delete_member method to instance group object

Adds a new delete_member method to the InstanceGroup Nova object. This method
calls the database instance_group_member_delete API which does a soft delete
of the instance in the instance group members table.

blueprint dynamic-server-groups-remove

Change-Id: I270cbd8fb78498f5ed415dd183a80b3fbfd683b2
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/136488/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_instance_group.py', 'nova/tests/unit/fake_policy.py', 'nova/api/openstack/compute/contrib/server_groups.py', 'nova/objects/instance_group.py', 'etc/nova/policy.json', 'nova/tests/unit/api/openstack/compute/contrib/test_server_groups.py']",6,5f80e3427a267128d99d0e3b234f20791d1fc539,bp/dynamic-server-groups-remove_object-changes," def test_invalid_action(self): body = {""upate_server"": {""server_id"": ""fake_id""}} req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123') self.assertRaises(webob.exc.HTTPBadRequest, self.controller.action, req, ""1"", body=body) def test_invalid_action_empty_body(self): body = {} req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123') self.assertRaises(webob.exc.HTTPBadRequest, self.controller.action, req, ""1"", body=body) def test_remove_server(self): ctx = context.RequestContext('fake_user', 'fake') (ig_uuid, instances, members) = self._create_groups_and_instances(ctx) sg = server_group_template(id=ig_uuid, members=members) member_to_remove = members[0] num_members = len(members) def delete_server(context, group_id, member_id): self.assertEqual(member_to_remove, member_id) sg['members'].remove(member_id) def return_server_group(context, group_id): self.assertEqual(ig_uuid, group_id) return server_group_db(sg) self.stubs.Set(nova.db, 'instance_group_member_delete', delete_server) self.stubs.Set(nova.db, 'instance_group_get', return_server_group) req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123/action') resp = self.controller._remove_server( req, sg['id'], body={""server_id"": member_to_remove}) response_members = resp['server_group']['members'] self.assertEqual(len(response_members), num_members - 1) self.assertNotIn(member_to_remove, response_members) def test_remove_server_with_group_not_found(self): def delete_server(context, group_id, member_id): raise exception.InstanceGroupNotFound(group_uuid=group_id) self.stubs.Set(nova.db, 'instance_group_member_delete', delete_server) req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123/action') self.assertRaises(webob.exc.HTTPNotFound, self.controller._remove_server, req, ""123"", body={""server_id"": ""321""}) def test_remove_server_with_server_not_found(self): def delete_server(context, group_id, member_id): raise exception.InstanceGroupMemberNotFound(group_uuid=group_id, instance_id=member_id) self.stubs.Set(nova.db, 'instance_group_member_delete', delete_server) req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123/action') self.assertRaises(webob.exc.HTTPNotFound, self.controller._remove_server, req, ""123"", body={""server_id"": ""321""}) def test_remove_server_with_invalid_body(self): req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/123/action') # server_id missing from body body = {""id"": ""321""} self.assertRaises(webob.exc.HTTPBadRequest, self.controller._remove_server, req, '123', body=body) # extra parameters in body body = {""id"": ""321"", ""server_id"": ""321""} self.assertRaises(webob.exc.HTTPBadRequest, self.controller._remove_server, req, '123', body=body) # server_id invalid body = {""server_id"": """"} self.assertRaises(webob.exc.HTTPBadRequest, self.controller._remove_server, req, '123', body=body) "," def test_delete_non_existing_server_group(self): req = fakes.HTTPRequest.blank(self._get_url() + '/os-server-groups/invalid') self.assertRaises(webob.exc.HTTPNotFound, self.controller.delete, req, 'invalid') ",179,9
openstack%2Fnova~master~I5f49f8d049edf20464ea610764f9336de15358bb,openstack/nova,master,I5f49f8d049edf20464ea610764f9336de15358bb,Adds remove_server action to the server group APIs.,ABANDONED,2014-11-24 23:50:43.000000000,2015-01-12 16:28:34.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 7166}, {'_account_id': 7221}, {'_account_id': 7664}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-24 23:50:43.000000000', 'files': ['nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-resp.json.tpl', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-resp.xml.tpl', 'doc/api_samples/os-server-groups/server-groups-remove-server-post-resp.xml', 'nova/tests/unit/fake_policy.py', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-req.xml.tpl', 'nova/api/openstack/compute/contrib/server_groups.py', 'doc/api_samples/os-server-groups/server-groups-remove-server-post-resp.json', 'etc/nova/policy.json', 'nova/tests/unit/api/openstack/compute/contrib/test_server_groups.py', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-req.json.tpl', 'nova/tests/unit/integrated/test_api_samples.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7deb1abc7d4cc1cc263bb506100cd572a8505cba', 'message': 'Adds remove_server action to the server group APIs.\n\nAdds a remove_server action to the server group APIs to\nallow a user to remove a specified server from the server group.\nUpdates policy with remove_server action.\n\nblueprint dynamic-server-groups-remove\n\nChange-Id: I5f49f8d049edf20464ea610764f9336de15358bb\n'}]",0,136928,7deb1abc7d4cc1cc263bb506100cd572a8505cba,9,14,1,7221,,,0,"Adds remove_server action to the server group APIs.

Adds a remove_server action to the server group APIs to
allow a user to remove a specified server from the server group.
Updates policy with remove_server action.

blueprint dynamic-server-groups-remove

Change-Id: I5f49f8d049edf20464ea610764f9336de15358bb
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/136928/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-resp.json.tpl', 'doc/api_samples/os-server-groups/server-groups-remove-server-post-resp.xml', 'nova/tests/unit/fake_policy.py', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-resp.xml.tpl', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-req.xml.tpl', 'doc/api_samples/os-server-groups/server-groups-remove-server-post-resp.json', 'nova/api/openstack/compute/contrib/server_groups.py', 'etc/nova/policy.json', 'nova/tests/unit/api/openstack/compute/contrib/test_server_groups.py', 'nova/tests/unit/integrated/api_samples/os-server-groups/server-groups-remove-server-post-req.json.tpl', 'nova/tests/unit/integrated/test_api_samples.py']",11,7deb1abc7d4cc1cc263bb506100cd572a8505cba,bp/dynamic-server-groups-remove," def test_remove_server(self): uuid = self._post_server_group() server_id = '1' # Add a server to the server group db.instance_group_members_add(context.get_admin_context(), uuid, [server_id], set_delete=False) subs = {""server_id"": server_id} response = self._do_post('os-server-groups/%s/action' % uuid, 'server-groups-remove-server-post-req', subs) subs.update(self._get_regexes()) subs['name'] = 'test' subs['id'] = uuid self._verify_response('server-groups-remove-server-post-resp', subs, response, 200) ",,178,2
openstack%2Fheat~master~Ib20fd999237ed9fa437cced9962ca4528af20e0a,openstack/heat,master,Ib20fd999237ed9fa437cced9962ca4528af20e0a,Transparent stack_id only works on get_resource,MERGED,2015-01-08 12:22:52.000000000,2015-01-12 16:22:48.000000000,2015-01-12 16:22:45.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 7256}, {'_account_id': 8246}, {'_account_id': 9542}]","[{'number': 1, 'created': '2015-01-08 12:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5933c9a8fc3701f031cc0888aaf4894eb4f3bafb', 'message': ""Transparent stack_id only works on get_resource\n\nThe docs are incorrect, and when you add OS::stack_id to a nested\nstack you can't use get_attr on the parent resource, just get_resource.\n\nChange-Id: Ib20fd999237ed9fa437cced9962ca4528af20e0a\n""}, {'number': 2, 'created': '2015-01-12 12:51:26.000000000', 'files': ['doc/source/template_guide/composition.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/8a167387e5b5786bccf92c718664343c0408219b', 'message': ""Transparent stack_id only works on get_resource\n\nThe docs are incorrect, and when you add OS::stack_id to a nested\nstack you can't use get_attr on the parent resource, just get_resource.\n\nChange-Id: Ib20fd999237ed9fa437cced9962ca4528af20e0a\n""}]",0,145765,8a167387e5b5786bccf92c718664343c0408219b,20,6,2,4715,,,0,"Transparent stack_id only works on get_resource

The docs are incorrect, and when you add OS::stack_id to a nested
stack you can't use get_attr on the parent resource, just get_resource.

Change-Id: Ib20fd999237ed9fa437cced9962ca4528af20e0a
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/145765/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/template_guide/composition.rst'],1,5933c9a8fc3701f031cc0888aaf4894eb4f3bafb,comp-docs,"Now when you use ""get_resource"" from the outer template heat will use the nova server id and not the template resource.","Now when you use ""get_resource"" or ""get_attr"" from the outer template heat will use nova server and not the template resource.",2,2
openstack%2Fceilometer~master~Ib94f5d4f90956342d5b1ac183ca70179de0505f7,openstack/ceilometer,master,Ib94f5d4f90956342d5b1ac183ca70179de0505f7,Add an exchange for Zaqar in profiler notification plugin,MERGED,2014-12-12 12:57:42.000000000,2015-01-12 16:22:38.000000000,2015-01-12 16:22:35.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6172}, {'_account_id': 6537}, {'_account_id': 6549}, {'_account_id': 6676}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-12-12 12:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/300ed123a706b242cd20a061e358a6f6199d1b82', 'message': 'Add an exchange for Zaqar in profiler notification plugin\n\nTo enable Zaqar to use ceilometer as trace info storage.\nMain patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820\n\nChange-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-12-26 09:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/17eb7b22d1b4d0be161d844086c7f5ef5beeeaa8', 'message': 'Add an exchange for Zaqar in profiler notification plugin\n\nTo enable Zaqar to use ceilometer as trace info storage.\nMain patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820\n\nChange-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 3, 'created': '2014-12-30 04:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5facb7c9bf26c40e372e605718911eab28117855', 'message': 'Add an exchange for Zaqar in profiler notification plugin\n\nTo enable Zaqar to use ceilometer as trace info storage.\nMain patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820\n\nDocImpact\n\nChange-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 4, 'created': '2015-01-08 10:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3ab48ebbc87636dc4a8e95593dd051f01fd7cc98', 'message': ""Add an exchange for Zaqar in profiler notification plugin\n\nTo enable Zaqar to use ceilometer as trace info storage.\nMain patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820\n\nNew option 'zaqar_control_exchange' is added to allow operator\nconfigures exchange name base on zaqar deployment for its trace\ndata pushing up.\n\nDocImpact\n\nChange-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}, {'number': 5, 'created': '2015-01-12 04:59:04.000000000', 'files': ['ceilometer/profiler/notifications.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/96180c8b1191834bb95caee37f384c8cf9ce2418', 'message': ""Add an exchange for Zaqar in profiler notification plugin\n\nTo enable Zaqar to use ceilometer as trace info storage.\nMain patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820\n\nNew option 'zaqar_control_exchange' is added to allow operator\nconfigures exchange name base on zaqar deployment for its trace\ndata pushing up.\n\nDocImpact\n\nWe prepared a common BP in oslo-spec due to integration change is\nsimilar to all projects: I29a2a59ded9e260a3d3bf79957bd49f403d8e83a\n\nThe spec of osprofiler integration for zaqar is:\nhttps://review.openstack.org/#/c/135612/\n\nChange-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n""}]",4,141355,96180c8b1191834bb95caee37f384c8cf9ce2418,31,11,5,6549,,,0,"Add an exchange for Zaqar in profiler notification plugin

To enable Zaqar to use ceilometer as trace info storage.
Main patch in Zaqar is: I32565de6c447cd5e95a0ef54a9fbd4e571c2d820

New option 'zaqar_control_exchange' is added to allow operator
configures exchange name base on zaqar deployment for its trace
data pushing up.

DocImpact

We prepared a common BP in oslo-spec due to integration change is
similar to all projects: I29a2a59ded9e260a3d3bf79957bd49f403d8e83a

The spec of osprofiler integration for zaqar is:
https://review.openstack.org/#/c/135612/

Change-Id: Ib94f5d4f90956342d5b1ac183ca70179de0505f7
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/55/141355/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/profiler/notifications.py'],1,300ed123a706b242cd20a061e358a6f6199d1b82,," cfg.StrOpt('zaqar_control_exchange', default='zaqar', help=""Exchange name for Messaging service notifications.""), conf.zaqar_control_exchange,",,4,0
openstack%2Fdiskimage-builder~master~I2f35b8d7d8749d44d88f06e9e2c3116ff93b88fe,openstack/diskimage-builder,master,I2f35b8d7d8749d44d88f06e9e2c3116ff93b88fe,Fix for RHEL6,MERGED,2014-12-22 21:19:53.000000000,2015-01-12 16:22:18.000000000,2015-01-12 16:22:17.000000000,"[{'_account_id': 3}, {'_account_id': 6449}, {'_account_id': 6928}, {'_account_id': 8399}, {'_account_id': 8532}]","[{'number': 1, 'created': '2014-12-22 21:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5f06c098d43c3523a69d3f832531df5839a41056', 'message': 'Fix for RHEL6\n\nThe correct workflow for building RHEL6 images includes not using\nthe rhel-registration scripts in this element, but rather the 00-rhsm\nscript.  This patch updates the return value from 1 to 0 for the case\nwhen the REG_METHOD is left unset.  This will allow the RHEL6 images\nto build without needing to set REG_METHOD. This patch also improves\nthe note about RHEL6 image building.\n\nThis patch is the result of the discussion in the comments of [1].\n\n[1] Iff7b9fc30d5a36231598a977a9edcd55229766c5\n\nChange-Id: I2f35b8d7d8749d44d88f06e9e2c3116ff93b88fe\nCloses-Bug: 1404364\n'}, {'number': 2, 'created': '2015-01-07 15:28:07.000000000', 'files': ['elements/rhel-common/README.md', 'elements/rhel-common/pre-install.d/00-rhel-registration'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d669d785287db303d4201205875f2c59ec2e1f28', 'message': 'Fix for RHEL6\n\nThe correct workflow for building RHEL6 images includes not using\nthe rhel-registration scripts in this element, but rather the 00-rhsm\nscript.  This patch updates the return value from 1 to 0 for the case\nwhen the REG_METHOD is left unset.  This will allow the RHEL6 images\nto build without needing to set REG_METHOD. This patch also improves\nthe note about RHEL6 image building.\n\nThis patch is the result of the discussion in the comments of [1].\n\n[1] Iff7b9fc30d5a36231598a977a9edcd55229766c5\n\nChange-Id: I2f35b8d7d8749d44d88f06e9e2c3116ff93b88fe\nCloses-Bug: 1404364\n'}]",0,143544,d669d785287db303d4201205875f2c59ec2e1f28,29,5,2,8532,,,0,"Fix for RHEL6

The correct workflow for building RHEL6 images includes not using
the rhel-registration scripts in this element, but rather the 00-rhsm
script.  This patch updates the return value from 1 to 0 for the case
when the REG_METHOD is left unset.  This will allow the RHEL6 images
to build without needing to set REG_METHOD. This patch also improves
the note about RHEL6 image building.

This patch is the result of the discussion in the comments of [1].

[1] Iff7b9fc30d5a36231598a977a9edcd55229766c5

Change-Id: I2f35b8d7d8749d44d88f06e9e2c3116ff93b88fe
Closes-Bug: 1404364
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/44/143544/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/rhel-common/README.md', 'elements/rhel-common/pre-install.d/00-rhel-registration']",2,5f06c098d43c3523a69d3f832531df5839a41056,bug/1404364, exit 0, exit 1,2,1
openstack%2Fceilometer~master~Id95865c51dc4ffe2d7089a3ff4fa5b73bd93ae76,openstack/ceilometer,master,Id95865c51dc4ffe2d7089a3ff4fa5b73bd93ae76,Catch exception when evaluate single alarm,MERGED,2015-01-08 12:59:41.000000000,2015-01-12 16:22:07.000000000,2015-01-12 16:22:05.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 7478}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-01-08 12:59:41.000000000', 'files': ['ceilometer/alarm/service.py', 'ceilometer/tests/alarm/test_singleton_alarm_svc.py', 'ceilometer/tests/alarm/test_alarm_svc.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f88f6863eaf70de74e63a11fbce1c23033141aea', 'message': 'Catch exception when evaluate single alarm\n\nCurrently, if we raise exception when evaluate alarms, the outside\nmethod will not catch it, so the higher _evaluate_assigned_alarms\ncatches it, but this will stop evaluating the rest alarms. Alarm\nshould be evaluated no matter whether other alarms succeed or not.\n\nThis patch adds a try...except block in _evaluate_alarm, it will\nlog exception when it is raised, and the higher method can move\non next alarm.\n\nChange-Id: Id95865c51dc4ffe2d7089a3ff4fa5b73bd93ae76\nCloses-Bug: #1408620\n'}]",0,145771,f88f6863eaf70de74e63a11fbce1c23033141aea,9,4,1,6676,,,0,"Catch exception when evaluate single alarm

Currently, if we raise exception when evaluate alarms, the outside
method will not catch it, so the higher _evaluate_assigned_alarms
catches it, but this will stop evaluating the rest alarms. Alarm
should be evaluated no matter whether other alarms succeed or not.

This patch adds a try...except block in _evaluate_alarm, it will
log exception when it is raised, and the higher method can move
on next alarm.

Change-Id: Id95865c51dc4ffe2d7089a3ff4fa5b73bd93ae76
Closes-Bug: #1408620
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/71/145771/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/service.py', 'ceilometer/tests/alarm/test_singleton_alarm_svc.py', 'ceilometer/tests/alarm/test_alarm_svc.py']",3,f88f6863eaf70de74e63a11fbce1c23033141aea,bug/1408620," def test_evaluation_cycle_with_bad_alarm(self): alarms = [ mock.Mock(type='threshold', name='bad'), mock.Mock(type='threshold', name='good'), ] self.api_client.alarms.list.return_value = alarms self.threshold_eval.evaluate.side_effect = [Exception('Boom!'), None] with mock.patch('ceilometerclient.client.get_client', return_value=self.api_client): p_coord_mock = self.svc.partition_coordinator p_coord_mock.extract_my_subset.return_value = alarms self.svc._evaluate_assigned_alarms() self.assertEqual([mock.call(alarms[0]), mock.call(alarms[1])], self.threshold_eval.evaluate.call_args_list) ",,33,1
openstack%2Fneutron~master~I60caaef56787f585e58d0ccf366e728ecf1954e8,openstack/neutron,master,I60caaef56787f585e58d0ccf366e728ecf1954e8,Enable rootwrap support for strongSwan driver,ABANDONED,2014-12-30 09:46:49.000000000,2015-01-12 16:13:03.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-30 09:46:49.000000000', 'files': ['etc/neutron/rootwrap.d/vpnaas.filters'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d283ec3db816bc6b779668e749c34a9ec01ac6a5', 'message': 'Enable rootwrap support for strongSwan driver\n\nstrongSwan driver[1] needs to update rootwrap file,\nsubmit it as a separate review based on comment of [2].\n\n[1] https://review.openstack.org/#/c/144391/\n[2] https://review.openstack.org/#/c/144388/\n\nChange-Id: I60caaef56787f585e58d0ccf366e728ecf1954e8\n'}]",0,144427,d283ec3db816bc6b779668e749c34a9ec01ac6a5,17,15,1,2711,,,0,"Enable rootwrap support for strongSwan driver

strongSwan driver[1] needs to update rootwrap file,
submit it as a separate review based on comment of [2].

[1] https://review.openstack.org/#/c/144391/
[2] https://review.openstack.org/#/c/144388/

Change-Id: I60caaef56787f585e58d0ccf366e728ecf1954e8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/144427/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/rootwrap.d/vpnaas.filters'],1,d283ec3db816bc6b779668e749c34a9ec01ac6a5,strongswan_rootwrap,"ipsec: CommandFilter, ipsec, root apparmor_parser: CommandFilter, apparmor_parser, root","openswan: CommandFilter, ipsec, root",2,1
openstack%2Fneutron~master~I184a10674b9203e565a10aee4bb5e08cd6d49b92,openstack/neutron,master,I184a10674b9203e565a10aee4bb5e08cd6d49b92,netns wrapper,ABANDONED,2014-12-30 00:18:15.000000000,2015-01-12 16:11:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2711}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-30 00:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03c7cf8aa7d0dfa83c52bb0ecc3572428ae90824', 'message': ""netns wrapper\n\nstrongSwan doesn't support namespace natively, so\nsubmit this wrapper as a separate reveiew from [1].\n\n[1] https://review.openstack.org/#/c/100791/\n\nImplements blueprint ipsec-strongswan-driver\n\nChange-Id: I184a10674b9203e565a10aee4bb5e08cd6d49b92\n""}, {'number': 2, 'created': '2014-12-30 00:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8c442d8107eea9717ab3824da6fdc974945bb6b', 'message': ""netns wrapper\n\nstrongSwan doesn't support namespace natively, so\nsubmit this wrapper as a separate reveiew from [1].\n\n[1] https://review.openstack.org/#/c/144391/\n\nImplements blueprint ipsec-strongswan-driver\n\nChange-Id: I184a10674b9203e565a10aee4bb5e08cd6d49b92\n""}, {'number': 3, 'created': '2014-12-30 09:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8d639e639f1b3c287e90831f5d39174f6bee91b', 'message': ""netns wrapper\n\nstrongSwan doesn't support namespace natively, so\nsubmit this wrapper as a separate reveiew from [1].\n\n[1] https://review.openstack.org/#/c/144391/\n\nImplements blueprint ipsec-strongswan-driver\n\nChange-Id: I184a10674b9203e565a10aee4bb5e08cd6d49b92\n""}, {'number': 4, 'created': '2014-12-30 09:38:00.000000000', 'files': ['neutron/tests/unit/test_agent_netns_wrapper.py', 'neutron/agent/linux/netns_wrapper.py', 'setup.cfg', 'etc/neutron/rootwrap.d/vpnaas.filters'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3062f266d3c443d5b3fd65213ce859ef7ff5897a', 'message': 'netns wrapper\n\nstrongSwan doesn\'t support namespace natively, this wrapper\nwill use ""mount --bind"" to simulate the ns like this:\n\nsudo neutron-rootwrap /etc/neutron/rootwrap.conf ip netns \\\nexec <namespace-id> neutron-netns-wrapper --mount_paths \\\n=/etc:/tmp/ipsec/<process-id>/etc, \\\n/var/run:/tmp/ipsec/<process-id>/var/run --cmd=ipsec,status\n\nsubmit this wrapper as a separate reveiew from [1].\n\n[1] https://review.openstack.org/#/c/144391/\n\nImplements blueprint ipsec-strongswan-driver\n\nChange-Id: I184a10674b9203e565a10aee4bb5e08cd6d49b92\n'}]",6,144388,3062f266d3c443d5b3fd65213ce859ef7ff5897a,71,18,4,2711,,,0,"netns wrapper

strongSwan doesn't support namespace natively, this wrapper
will use ""mount --bind"" to simulate the ns like this:

sudo neutron-rootwrap /etc/neutron/rootwrap.conf ip netns \
exec <namespace-id> neutron-netns-wrapper --mount_paths \
=/etc:/tmp/ipsec/<process-id>/etc, \
/var/run:/tmp/ipsec/<process-id>/var/run --cmd=ipsec,status

submit this wrapper as a separate reveiew from [1].

[1] https://review.openstack.org/#/c/144391/

Implements blueprint ipsec-strongswan-driver

Change-Id: I184a10674b9203e565a10aee4bb5e08cd6d49b92
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/144388/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_agent_netns_wrapper.py', 'neutron/agent/linux/netns_wrapper.py', 'setup.cfg', 'etc/neutron/rootwrap.d/vpnaas.filters']",4,03c7cf8aa7d0dfa83c52bb0ecc3572428ae90824,bp/ipsec-strongswan-driver,"neutron_netns_wrapper: CommandFilter, neutron-netns-wrapper, root neutron_netns_wrapper_local: CommandFilter, /usr/local/bin/neutron-netns-wrapper, root strongswan: CommandFilter, ipsec, root apparmor_parser: CommandFilter, apparmor_parser, root",,229,0
openstack%2Ffuel-docs~stable%2F5.1~I2ac78e2df69c66aa4d3b394cb28afa4e93c32ab2,openstack/fuel-docs,stable/5.1,I2ac78e2df69c66aa4d3b394cb28afa4e93c32ab2,updated Neutron agent rescheduling bug description in release notes,MERGED,2015-01-10 02:04:52.000000000,2015-01-12 16:10:17.000000000,2015-01-12 16:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}]","[{'number': 1, 'created': '2015-01-10 02:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/091882959dadfff625aa0ff40fc48d5e66ade34f', 'message': 'updated Neutron agent rescheduling bug description in release notes\n\nBug #1392330 description under known issues is updated based on more recent\nfindings about the bug.\n\nChange-Id: I2ac78e2df69c66aa4d3b394cb28afa4e93c32ab2\n'}, {'number': 2, 'created': '2015-01-10 02:31:20.000000000', 'files': ['pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/07aeab57943a4246dca8901fc3b1bcba0754f47d', 'message': 'updated Neutron agent rescheduling bug description in release notes\n\nBug #1392330 description under known issues is updated based on more recent\nfindings about the bug.\n\nChange-Id: I2ac78e2df69c66aa4d3b394cb28afa4e93c32ab2\n'}]",1,146250,07aeab57943a4246dca8901fc3b1bcba0754f47d,15,5,2,8787,,,0,"updated Neutron agent rescheduling bug description in release notes

Bug #1392330 description under known issues is updated based on more recent
findings about the bug.

Change-Id: I2ac78e2df69c66aa4d3b394cb28afa4e93c32ab2
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/50/146250/2 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v5-1/050-known-issues.rst'],1,091882959dadfff625aa0ff40fc48d5e66ade34f,bug/1392330,* Rescheduling a Neutron agent to a different controller may disrupt network connectivity to instances due to mismatching file permissions assumptions between Neutron and Pacemaker. The solution is to set umask to 0022 in the OCF init scripts for Neutron as implemented in the `Patch 139938 <https://review.openstack.org/139938>`_. See `LP1392330 <https://bugs.launchpad.net/bugs/1392330>`_.,"* Neutron on CentOS may create some files without read permissions, this makes it unable to manage metadata proxy. The solution is to set umask to 0022 in the OCF init scripts for Neutron as implemented in the `Patch 139938 <https://review.openstack.org/139938>`_.",6,4
openstack%2Ffuel-docs~stable%2F5.1~I038b6a2105bff5edd8d6da586392251cc4c4c261,openstack/fuel-docs,stable/5.1,I038b6a2105bff5edd8d6da586392251cc4c4c261,Add slow processing of iptables rules to 5.1 known issues,MERGED,2015-01-10 02:14:34.000000000,2015-01-12 16:09:52.000000000,2015-01-12 16:09:52.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}]","[{'number': 1, 'created': '2015-01-10 02:14:34.000000000', 'files': ['pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c74f99f2be8c79c49195cf048f587a5d8e203538', 'message': 'Add slow processing of iptables rules to 5.1 known issues\n\nBug #1399168 description added to known networking issues subsection of\n5.1 release notes.\n\nChange-Id: I038b6a2105bff5edd8d6da586392251cc4c4c261\n'}]",0,146251,c74f99f2be8c79c49195cf048f587a5d8e203538,9,4,1,8787,,,0,"Add slow processing of iptables rules to 5.1 known issues

Bug #1399168 description added to known networking issues subsection of
5.1 release notes.

Change-Id: I038b6a2105bff5edd8d6da586392251cc4c4c261
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/51/146251/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v5-1/050-known-issues.rst'],1,c74f99f2be8c79c49195cf048f587a5d8e203538,bug/1399168,"* In large scale environments, instances may fail to launch due to slow processing of iptables rules. Environments with many compute nodes running many VMs can lead to long iptables rules lists. Slow processing of long iptables rules lists can lead to service timeouts when launching new instances. The problem is fixed in python-neutron package from MOS 5.1.2. See `update instructions in LP1399168 <https://bugs.launchpad.net/mos/+bug/1399168/comments/16>`_. ",,8,0
openstack%2Fironic-python-agent~master~I30c65c9259acd4f200cb554e7d688344b7486a58,openstack/ironic-python-agent,master,I30c65c9259acd4f200cb554e7d688344b7486a58,Allow use of multiple simultaneous HW managers,MERGED,2014-12-19 21:22:58.000000000,2015-01-12 15:59:37.000000000,2015-01-09 17:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10380}, {'_account_id': 14228}]","[{'number': 1, 'created': '2014-12-19 21:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b79eda09e255772ef7351ec38d59f5cbeeeac374', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 2, 'created': '2014-12-30 23:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9bc582d81621001646abbe0c4458214cb9d7b056', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 3, 'created': '2014-12-31 19:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9d71f2046fb08d0b4a4be855a47367e9fd834c37', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 4, 'created': '2014-12-31 19:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/bb7134ac682be6aa7b96b10d619503864f8f2f3f', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 5, 'created': '2014-12-31 19:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5b7f91b0fcc3b1c0ea1533c318096c504f8b74f1', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 6, 'created': '2014-12-31 19:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/55091f4b8763f14a0baa4c6323f546941aeb8f71', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 7, 'created': '2014-12-31 19:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/33d8d20efa66f345f01e3e7a9c8d8317355fda7c', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 8, 'created': '2014-12-31 19:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d6c481449ecb74daa28e7e62560377383ee9c403', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 9, 'created': '2015-01-01 22:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c9f1f70b321b122bc3b649aaea6fecde2dfa1a88', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 10, 'created': '2015-01-01 23:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f54aac7f088e665a978d7b2303ec52935452c205', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 11, 'created': '2015-01-01 23:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8dd4b356382abddf61e754cf8ed6595b95afd3ce', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 12, 'created': '2015-01-06 03:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7b7f6682c9ec86dc80d5830f4f3339048164d00e', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 13, 'created': '2015-01-06 03:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/561ac4aa8b27d5979e6846f748ce8874d6207c70', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 14, 'created': '2015-01-06 19:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3b3e7bead89de1fb18cb6068250e2af0f6cd8b3c', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 15, 'created': '2015-01-06 23:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/eadc72676a0b73ed1d90ad88c6355d3c21425e81', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 16, 'created': '2015-01-07 22:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4f7215bfb8d0ad94f0a74e18d519c86c3d8fd6d6', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 17, 'created': '2015-01-07 23:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7e48792374a3108f38ce5834d219f4c0d6ee52ce', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 18, 'created': '2015-01-08 00:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6ec864a88f7494875d485b3344a6229964172e91', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 19, 'created': '2015-01-08 22:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/63ea932775c02528b6cbd9304f1c940501c77bee', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it doesn't throw.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 20, 'created': '2015-01-08 22:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d6c5dc25588c8524a097f5417f3487b602b2f1c4', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider it\nsuccessful if it exists and doesn't throw IncompatibleHardwareMethodError.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 21, 'created': '2015-01-08 22:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/93d92c2f7079a8efceec71a87ee2d217b59e18a2', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider the\ncall successful if the method exists and doesn't throw\nIncompatibleHardwareMethodError.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}, {'number': 22, 'created': '2015-01-08 23:15:18.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/decom.py', 'ironic_python_agent/tests/multi_hardware.py', 'ironic_python_agent/tests/extensions/standby.py', 'ironic_python_agent/tests/netutils.py', 'ironic_python_agent/agent.py', 'ironic_python_agent/extensions/standby.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/tests/agent.py', 'ironic_python_agent/tests/extensions/decom.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2bbec5770c459b339b0924e8ffcd1382e22d44df', 'message': ""Allow use of multiple simultaneous HW managers\n\nCurrently we pick the most specific manager and use it. Instead, call\neach method on each hardware manager in priority order, and consider the\ncall successful if the method exists and doesn't throw\nIncompatibleHardwareMethodError.\n\nThis is an API breaking change for anyone with out-of-tree\nHardwareManagers.\n\nCloses-bug: 1408469\nChange-Id: I30c65c9259acd4f200cb554e7d688344b7486a58\n""}]",80,143193,2bbec5770c459b339b0924e8ffcd1382e22d44df,72,8,22,10342,,,0,"Allow use of multiple simultaneous HW managers

Currently we pick the most specific manager and use it. Instead, call
each method on each hardware manager in priority order, and consider the
call successful if the method exists and doesn't throw
IncompatibleHardwareMethodError.

This is an API breaking change for anyone with out-of-tree
HardwareManagers.

Closes-bug: 1408469
Change-Id: I30c65c9259acd4f200cb554e7d688344b7486a58
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/93/143193/21 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/decom.py', 'ironic_python_agent/tests/extensions/standby.py', 'ironic_python_agent/tests/netutils.py', 'ironic_python_agent/agent.py', 'ironic_python_agent/extensions/standby.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/errors.py', 'ironic_python_agent/tests/extensions/decom.py']",9,b79eda09e255772ef7351ec38d59f5cbeeeac374,jay/BetterHWManager," @mock.patch('ironic_python_agent.hardware.call_method', autospec=True) def test_erase_devices(self, mocked_call_method): mocked_call_method.assert_called_once_with('erase_devices')"," @mock.patch('ironic_python_agent.hardware.get_manager', autospec=True) def test_erase_hardware(self, mocked_get_manager): hardware_manager = mocked_get_manager.return_value hardware_manager.erase_devices.assert_called_once_with()",85,72
openstack%2Fopenstacksdk~master~I27997de8caef866e8503f136efeec53b5e5ac2ae,openstack/openstacksdk,master,I27997de8caef866e8503f136efeec53b5e5ac2ae,Add object_store resource documentation,MERGED,2014-11-24 23:35:11.000000000,2015-01-12 15:47:53.000000000,2015-01-12 15:47:51.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2014-11-24 23:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c613419f863596f21b8ba9cca81a9849370f39aa', 'message': ""Add object_store resource documentation\n\nCurrently this is documentation pulled from\nhttp://developer.openstack.org/api-ref-objectstorage-v1.html\n\nLong term we may want to find a better way to handle this, but for now\nI'd like to make sure we can offer documentation from one spot rather\nthan point people to several places and put hurdles in place.\n\nChange-Id: I27997de8caef866e8503f136efeec53b5e5ac2ae\n""}, {'number': 2, 'created': '2014-12-03 21:43:16.000000000', 'files': ['openstack/object_store/v1/obj.py', 'doc/source/resources/object_store/v1/obj.rst', 'openstack/object_store/v1/container.py', 'doc/source/resources/object_store/v1/container.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7d12b8c3023f3a90c9ff29c977c114f3f7753f1b', 'message': ""Add object_store resource documentation\n\nCurrently this is documentation pulled from\nhttp://developer.openstack.org/api-ref-objectstorage-v1.html\n\nLong term we may want to find a better way to handle this, but for now\nI'd like to make sure we can offer documentation from one spot rather\nthan point people to several places and put hurdles in place.\n\nChange-Id: I27997de8caef866e8503f136efeec53b5e5ac2ae\n""}]",12,136926,7d12b8c3023f3a90c9ff29c977c114f3f7753f1b,12,4,2,8257,,,0,"Add object_store resource documentation

Currently this is documentation pulled from
http://developer.openstack.org/api-ref-objectstorage-v1.html

Long term we may want to find a better way to handle this, but for now
I'd like to make sure we can offer documentation from one spot rather
than point people to several places and put hurdles in place.

Change-Id: I27997de8caef866e8503f136efeec53b5e5ac2ae
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/26/136926/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/object_store/v1/obj.py', 'doc/source/resources/object_store/v1/obj.rst', 'openstack/object_store/v1/container.py', 'doc/source/resources/object_store/v1/container.rst']",4,c613419f863596f21b8ba9cca81a9849370f39aa,object_store-docs2,The ``Container`` class inherits from :class:`~openstack.resource.Resource`. ,,120,0
openstack%2Ffuel-web~master~Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34,openstack/fuel-web,master,Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34,BackboneViewWrapper,MERGED,2014-12-05 16:48:13.000000000,2015-01-12 15:36:17.000000000,2015-01-12 15:36:13.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-05 16:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f09f2f6b330c20910bfe6c71bb11464fd6b3aaca', 'message': 'BackboneViewWrapper PoC\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n'}, {'number': 2, 'created': '2014-12-05 16:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/23426586774642c9fcc73a84e16c3e09ad789ff6', 'message': 'BackboneViewWrapper PoC\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n'}, {'number': 3, 'created': '2014-12-05 17:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d5c4ff3df952a92136a27e6867694fc3655ba21f', 'message': 'BackboneViewWrapper PoC\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n'}, {'number': 4, 'created': '2014-12-08 12:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a94b7a3d10a817bccae55caaee890e21111edc64', 'message': ""BackboneViewWrapper PoC\n\nA wrapper which makes Backbone.View's useable inside\nReact component trees\n\nRelated to blueprint backbone-to-react\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n""}, {'number': 5, 'created': '2014-12-08 13:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/92e26760e4f77c841ded979cabf6982446c4e33b', 'message': ""BackboneViewWrapper PoC\n\nA wrapper which makes Backbone.View's useable inside\nReact component trees\n\nRelated to blueprint backbone-to-react\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n""}, {'number': 6, 'created': '2014-12-22 18:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e8f0607c901a68db6c6b563d97357e9fa1d98d06', 'message': ""BackboneViewWrapper PoC\n\nA wrapper which makes Backbone.View's useable inside\nReact component trees\n\nRelated to blueprint react-router\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n""}, {'number': 7, 'created': '2014-12-29 12:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f5235fd5045abaf7df3f459f56d87bbfe24b6b08', 'message': ""BackboneViewWrapper PoC\n\nA wrapper which makes Backbone.View's useable inside\nReact component trees\n\nRelated to blueprint react-router\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n""}, {'number': 8, 'created': '2014-12-29 12:27:25.000000000', 'files': ['nailgun/static/js/backbone_view_wrapper.jsx', 'nailgun/static/js/config.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bfe854f77b8da6a5c9319e00b6ef3900fc757950', 'message': 'BackboneViewWrapper\n\nA wrapper which makes Backbone.Views useable inside\nReact component trees\n\nRelated to blueprint react-router\n\nChange-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34\n'}]",4,139683,bfe854f77b8da6a5c9319e00b6ef3900fc757950,48,6,8,8735,,,0,"BackboneViewWrapper

A wrapper which makes Backbone.Views useable inside
React component trees

Related to blueprint react-router

Change-Id: Ibc19adb631c6f9b28d26174fa1749bdc28ea1b34
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/83/139683/8 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page.js'],1,f09f2f6b330c20910bfe6c71bb11464fd6b3aaca,bp/react-router," 'jsx!js/backbone_view_wrapper',function(React, utils, models, BackboneViewWrapper, commonViews, clusterPageSubviews, dialogViews, NodesTab, NetworkTab, SettingsTab, LogsTab, ActionsTab, HealthCheckTab, clusterPageTemplate) { network: BackboneViewWrapper(NetworkTab),","function(React, utils, models, commonViews, clusterPageSubviews, dialogViews, NodesTab, NetworkTab, SettingsTab, LogsTab, ActionsTab, HealthCheckTab, clusterPageTemplate) { network: NetworkTab,",3,2
