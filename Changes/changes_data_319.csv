id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftripleo-common~master~I6a9b2704a9c6c7c1c9903532a5423408ede8ffc9,openstack/tripleo-common,master,I6a9b2704a9c6c7c1c9903532a5423408ede8ffc9,Fix quoting for PYTHONWARNINGS,MERGED,2020-01-02 15:42:04.000000000,2020-01-03 04:05:06.000000000,2020-01-03 00:33:02.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-02 15:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0243177f83f3f06249f215e056aef0841fa1e104', 'message': 'Fix quoting for PYTHONWARNINGS\n\nThe fix for 1854868 introduced double quoting for the PYTHONWARNINGS\nvariable which leads to a message about an Invalid -W option being\ndisplayed.\n\nChange-Id: I6a9b2704a9c6c7c1c9903532a5423408ede8ffc9\nCloses-Bug: #1858113\n'}, {'number': 2, 'created': '2020-01-02 15:43:35.000000000', 'files': ['tripleo_common/tests/utils/test_overcloudrc.py', 'tripleo_common/utils/overcloudrc.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/45ab26770cff0c5672c8924ae93386b1e881b31b', 'message': 'Fix quoting for PYTHONWARNINGS\n\nThe fix for 1854868 introduced double quoting for the PYTHONWARNINGS\nvariable which leads to a message about an Invalid -W option being\ndisplayed.\n\nChange-Id: I6a9b2704a9c6c7c1c9903532a5423408ede8ffc9\nCloses-Bug: #1858113\n'}]",0,700905,45ab26770cff0c5672c8924ae93386b1e881b31b,14,5,2,14985,,,0,"Fix quoting for PYTHONWARNINGS

The fix for 1854868 introduced double quoting for the PYTHONWARNINGS
variable which leads to a message about an Invalid -W option being
displayed.

Change-Id: I6a9b2704a9c6c7c1c9903532a5423408ede8ffc9
Closes-Bug: #1858113
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/05/700905/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/utils/test_overcloudrc.py', 'tripleo_common/utils/overcloudrc.py']",2,0243177f83f3f06249f215e056aef0841fa1e104,bug/1858113," 'PYTHONWARNINGS': ('ignore:Certificate has no, ignore:A true ' 'SSLContext object is not available'),"," 'PYTHONWARNINGS': ('""ignore:Certificate has no, ignore:A true ' 'SSLContext object is not available""'),",5,2
openstack%2Fironic-python-agent-builder~master~Ibf9da9e0fe1f4411f045c832613dee7979e8bb01,openstack/ironic-python-agent-builder,master,Ibf9da9e0fe1f4411f045c832613dee7979e8bb01,Upgrade syslinux version,MERGED,2019-12-10 15:23:27.000000000,2020-01-03 03:36:46.000000000,2020-01-03 03:34:28.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-10 15:23:27.000000000', 'files': ['tinyipa/build-iso.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/021fe13239eb405ecf6f7f53871b571f88619127', 'message': 'Upgrade syslinux version\n\nLatest version of syslinux is 6.03\n\nChange-Id: Ibf9da9e0fe1f4411f045c832613dee7979e8bb01\n'}]",0,698272,021fe13239eb405ecf6f7f53871b571f88619127,11,5,1,23851,,,0,"Upgrade syslinux version

Latest version of syslinux is 6.03

Change-Id: Ibf9da9e0fe1f4411f045c832613dee7979e8bb01
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/72/698272/1 && git format-patch -1 --stdout FETCH_HEAD,['tinyipa/build-iso.sh'],1,021fe13239eb405ecf6f7f53871b571f88619127,syslinux-upgrade,"SYSLINUX_VERSION=""6.03""","SYSLINUX_VERSION=""4.06""",1,1
openstack%2Fironic-python-agent-builder~master~I54f0c027961f3ea46777cc0829ad80781e06c031,openstack/ironic-python-agent-builder,master,I54f0c027961f3ea46777cc0829ad80781e06c031,Use variables for syslinux in build-iso script,MERGED,2019-12-06 09:43:15.000000000,2020-01-03 03:35:46.000000000,2020-01-03 03:34:27.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-06 09:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3899eea5e88873929aa88754b80b5e35268487fd', 'message': 'Use variables for syslinux in build-iso script\n\nConverting syslinux related version and download path to variables.\n\nChange-Id: I54f0c027961f3ea46777cc0829ad80781e06c031\n'}, {'number': 2, 'created': '2019-12-06 09:46:07.000000000', 'files': ['tinyipa/build-iso.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/a44f84aeefb5766ab77df4cbbf5470f27934cbbb', 'message': 'Use variables for syslinux in build-iso script\n\nConverting syslinux related version and download path to variables.\n\nChange-Id: I54f0c027961f3ea46777cc0829ad80781e06c031\n'}]",3,697638,a44f84aeefb5766ab77df4cbbf5470f27934cbbb,12,5,2,23851,,,0,"Use variables for syslinux in build-iso script

Converting syslinux related version and download path to variables.

Change-Id: I54f0c027961f3ea46777cc0829ad80781e06c031
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/38/697638/1 && git format-patch -1 --stdout FETCH_HEAD,['tinyipa/build-iso.sh'],1,3899eea5e88873929aa88754b80b5e35268487fd,syslinux-variable,"SYSLINUX_VERSION=""4.06"" SYSLINUX_URL=""https://www.kernel.org/pub/linux/utils/boot/syslinux/syslinux-${SYSLINUX_VERSION}.tar.gz"" wget -N $SYSLINUX_URL && tar zxf syslinux-${SYSLINUX_VERSION}.tar.gzcp build_files/syslinux-${SYSLINUX_VERSION}/core/isolinux.bin newiso/boot/isolinux/.",wget -N https://www.kernel.org/pub/linux/utils/boot/syslinux/syslinux-4.06.tar.gz && tar zxf syslinux-4.06.tar.gzcp build_files/syslinux-4.06/core/isolinux.bin newiso/boot/isolinux/.,5,2
openstack%2Fpuppet-openstack-integration~master~I1de859f29c933d895fb5cd2b7f1897517e11385c,openstack/puppet-openstack-integration,master,I1de859f29c933d895fb5cd2b7f1897517e11385c,Add support for RDO CentOS8 repos and run CentOS8 jobs,MERGED,2019-12-18 16:47:52.000000000,2020-01-03 03:29:49.000000000,2020-01-03 03:29:49.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-18 16:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/62c8ebb5760f9fe71bac3f75bb280a1dce49b9c9', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 2, 'created': '2019-12-18 17:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c16810b14fa0719eb6305ee94e5cf6b47198f57a', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 3, 'created': '2019-12-19 06:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7773088194c3e93aab4673ce9061bb6e16beaa85', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 4, 'created': '2019-12-20 10:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c5952fd55da53c554af53225d41a328208b5a6ef', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 5, 'created': '2019-12-20 10:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/a66c8aa66290d694198b373e2fa2994ca00cbb31', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 6, 'created': '2019-12-20 11:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b1196e0c53e0abd690260de6831eb23cf734850c', 'message': '[DNM] Test CentOS8 jobs with temporary repos\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n'}, {'number': 7, 'created': '2019-12-31 06:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8741f7c9c2140ea9bce62f46ff4ccc56b334384f', 'message': ""[DNM] Add CentOS8 jobs with component repos\n\nInitially these jobs will be running as non-voting,\nonce stabilized will be moved to voting.\n\nRDO with CentOS8 has moved to component based repos[1],\nwhere for each component have it's own repo, the list\nof component can grow/shrink with time so instead of\nusing base path to configure repo, pull repo files\ndirectly and adjust proxy.\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n""}, {'number': 8, 'created': '2019-12-31 10:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b890ab1e0d54c79e472ce8b1bb982972b164290f', 'message': ""[DNM] Add CentOS8 jobs with component repos\n\nInitially these jobs will be running as non-voting,\nonce stabilized will be moved to voting.\n\nRDO with CentOS8 has moved to component based repos[1],\nwhere for each component have it's own repo, the list\nof component can grow/shrink with time so instead of\nusing base path to configure repo, pull repo files\ndirectly and adjust proxy.\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n""}, {'number': 9, 'created': '2020-01-02 10:56:33.000000000', 'files': ['run_tests.sh', 'configure_facts.sh', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8cb074420800d03c4faf020a67eae32aa7115919', 'message': ""Add support for RDO CentOS8 repos and run CentOS8 jobs\n\nInitially these jobs will be running as non-voting,\nonce stabilized will be moved to voting.\n\nRDO with CentOS8 has moved to component based repos[1],\nwhere for each component have it's own repo, the list\nof component can grow/shrink with time so instead of\nusing base path to configure repo, pull repo files\ndirectly and adjust proxy.\n\n[1] https://review.rdoproject.org/r/#/c/22394/\n\nChange-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c\n""}]",80,699731,8cb074420800d03c4faf020a67eae32aa7115919,31,5,9,13861,,,0,"Add support for RDO CentOS8 repos and run CentOS8 jobs

Initially these jobs will be running as non-voting,
once stabilized will be moved to voting.

RDO with CentOS8 has moved to component based repos[1],
where for each component have it's own repo, the list
of component can grow/shrink with time so instead of
using base path to configure repo, pull repo files
directly and adjust proxy.

[1] https://review.rdoproject.org/r/#/c/22394/

Change-Id: I1de859f29c933d895fb5cd2b7f1897517e11385c
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/31/699731/8 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'zuul.d/layout.yaml']",2,62c8ebb5760f9fe71bac3f75bb280a1dce49b9c9,rdo-centos8, - puppet-openstack-integration-5-scenario001-tempest-centos-8-luminous: voting: false - puppet-openstack-integration-5-scenario002-tempest-centos-8: voting: false - puppet-openstack-integration-5-scenario003-tempest-centos-8: voting: false - puppet-openstack-integration-5-scenario004-tempest-centos-8-nautilus: voting: false, - puppet-openstack-integration-5-scenario001-tempest-centos-7-luminous - puppet-openstack-integration-5-scenario002-tempest-centos-7 - puppet-openstack-integration-5-scenario003-tempest-centos-7 - puppet-openstack-integration-5-scenario004-tempest-centos-7-nautilus - puppet-openstack-integration-5-scenario001-tempest-ubuntu-bionic-mimic - puppet-openstack-integration-5-scenario002-tempest-ubuntu-bionic - puppet-openstack-integration-5-scenario003-tempest-ubuntu-bionic - puppet-openstack-integration-5-scenario004-tempest-ubuntu-bionic-mimic,11,9
openstack%2Fheat~master~I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010,openstack/heat,master,I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010,[TEST] check test change volume and flavor,ABANDONED,2019-06-10 07:28:50.000000000,2020-01-03 03:24:11.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-10 07:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c8d98a34f218fb76b119088c00c1bfc95eae7b33', 'message': '[TEST] check test change volume and flavor\n\nChange-Id: I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010\n'}, {'number': 2, 'created': '2019-06-11 06:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7550c18ed82e0c6cf1843a705ae8974db4e1493a', 'message': '[TEST] check test change volume and flavor\n\nChange-Id: I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010\n'}, {'number': 3, 'created': '2019-06-12 13:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb50b6db4edc574f9bb89130e8e0dd6c9329d956', 'message': '[TEST] check test change volume and flavor\n\nChange-Id: I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010\n'}, {'number': 4, 'created': '2019-06-13 04:41:36.000000000', 'files': ['heat_integrationtests/functional/test_create_update.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7babb54ecda64df7d55395bdabc1b92c6370eaf1', 'message': '[TEST] check test change volume and flavor\n\nChange-Id: I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010\n'}]",0,664213,7babb54ecda64df7d55395bdabc1b92c6370eaf1,14,2,4,12404,,,0,"[TEST] check test change volume and flavor

Change-Id: I8479bcb05ef9f3b92adccb52ab40bdfed2eb0010
",git fetch https://review.opendev.org/openstack/heat refs/changes/13/664213/3 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_create_update.py'],1,c8d98a34f218fb76b119088c00c1bfc95eae7b33,test_volume_flavor,"test_template_updatae_flavor_and_volume_size = ''' heat_template_version: 2013-05-23 parameters: volume_size: default: 10 type: number server_flavor: type: string network: type: string resources: my_instance: type: OS::Nova::Server properties: image: TestVM flavor: {get_param: server_flavor} admin_pass: 1 networks: - network: {get_param: network} data_volume_attachment: depends_on: my_instance type: 'OS::Cinder::VolumeAttachment' properties: instance_uuid: get_resource: my_instance volume_id: get_resource: data_volume data_volume: type: 'OS::Cinder::Volume' properties: name: myvolume size: {get_param: volume_size} ''' def test_stack_update_flavor_volume(self): parms = {'flavor': self.conf.minimal_instance_type, 'volume_size': 10, 'network': self.conf.fixed_network_name} stack_identifier = self.stack_create( template=test_template_updatae_flavor_and_volume_size, parameters=parms ) parms_updated = parms parms_updated['volume_size'] = 20 parms_updated['flavor'] = self.conf.instance_type self.update_stack( stack_identifier, template=test_template_updatae_flavor_and_volume_size, parameters=parms_updated) ",,56,0
openstack%2Fswift~master~I2624e113c9d945542f787e5f18f487bd7be3d32e,openstack/swift,master,I2624e113c9d945542f787e5f18f487bd7be3d32e,Use less responses from handoffs,MERGED,2019-12-20 20:30:35.000000000,2020-01-03 03:15:32.000000000,2020-01-03 03:13:57.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/38bf9028257598bf9b942a530910624f211ad109', 'message': 'WIP: a quick fix\n\nChange-Id: I2624e113c9d945542f787e5f18f487bd7be3d32e\n'}, {'number': 2, 'created': '2019-12-20 20:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d1340f74e0b018d6bde167c3e31b3da57a715075', 'message': ""Use less responses from handoffs\n\nSince we don't use 404s from handoffs anymore, we need to not let errors\non handoffs overwhelm primary responses either\n\nChange-Id: I2624e113c9d945542f787e5f18f487bd7be3d32e\n""}, {'number': 3, 'created': '2020-01-02 19:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d8a6bf8af389cbe5034139a321ad5d5d5e313aba', 'message': ""Use less responses from handoffs\n\nSince we don't use 404s from handoffs anymore, we need to not let errors\non handoffs overwhelm primary responses either\n\nChange-Id: I2624e113c9d945542f787e5f18f487bd7be3d32e\nCloses-Bug: #1857909\n""}, {'number': 4, 'created': '2020-01-03 00:45:14.000000000', 'files': ['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/286082222dc70da18bbca2e3d18a4e0aeb22cb2c', 'message': ""Use less responses from handoffs\n\nSince we don't use 404s from handoffs anymore, we need to not let errors\non handoffs overwhelm primary responses either\n\nChange-Id: I2624e113c9d945542f787e5f18f487bd7be3d32e\nCloses-Bug: #1857909\n""}]",6,700239,286082222dc70da18bbca2e3d18a4e0aeb22cb2c,17,3,4,1179,,,0,"Use less responses from handoffs

Since we don't use 404s from handoffs anymore, we need to not let errors
on handoffs overwhelm primary responses either

Change-Id: I2624e113c9d945542f787e5f18f487bd7be3d32e
Closes-Bug: #1857909
",git fetch https://review.opendev.org/openstack/swift refs/changes/39/700239/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/proxy/controllers/base.py']",3,38bf9028257598bf9b942a530910624f211ad109,404-errors, (possible_source.status == 507 or possible_source.status == HTTP_NOT_FOUND) and \, possible_source.status == HTTP_NOT_FOUND and \,20,1
openstack%2Fbifrost~master~I9a1e29d1c8bcc4f3cf00df81405f82c22fd10188,openstack/bifrost,master,I9a1e29d1c8bcc4f3cf00df81405f82c22fd10188,Disable bifrost jobs so CI can be fixed,MERGED,2020-01-02 23:37:48.000000000,2020-01-03 00:40:56.000000000,2020-01-03 00:39:07.000000000,"[{'_account_id': 5805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-02 23:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/34b59cca1e2a6b9e30612db8579771a0e0bfa95d', 'message': ""Disable bifrost jobs so CI can be fixed\n\ntl;dr: When ironic dropped py2 support, bifrost's\nCI reached a point where it could not be fixed without\na massive changeset being created with all required\nactions to purge all traces of python2.\n\nIn order to work through this, and hopefully make things\nbetter, this change disables the bulk of the CI jobs, marks\nthe existing primary jobs we want to succeed to be non-voting,\nand creates a bionic job as we should ideally already be on\nbionic.\n\nThe overall plan being to iterate through the jobs and get them\nworking one at a time as opposed to try and make them all\nfunctional in one changeset.\n\nChange-Id: I9a1e29d1c8bcc4f3cf00df81405f82c22fd10188\n""}, {'number': 2, 'created': '2020-01-02 23:52:25.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/bifrost-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3f74295a0d23203ec871ba5051d6ff52a4f85731', 'message': ""Disable bifrost jobs so CI can be fixed\n\ntl;dr: When ironic dropped py2 support, bifrost's\nCI reached a point where it could not be fixed without\na massive changeset being created with all required\nactions to purge all traces of python2.\n\nIn order to work through this, and hopefully make things\nbetter, this change disables the bulk of the CI jobs, marks\nthe existing primary jobs we want to succeed to be non-voting,\nand creates a bionic job as we should ideally already be on\nbionic.\n\nThe overall plan being to iterate through the jobs and get them\nworking one at a time as opposed to try and make them all\nfunctional in one changeset.\n\nChange-Id: I9a1e29d1c8bcc4f3cf00df81405f82c22fd10188\n""}]",1,700952,3f74295a0d23203ec871ba5051d6ff52a4f85731,9,2,2,11655,,,0,"Disable bifrost jobs so CI can be fixed

tl;dr: When ironic dropped py2 support, bifrost's
CI reached a point where it could not be fixed without
a massive changeset being created with all required
actions to purge all traces of python2.

In order to work through this, and hopefully make things
better, this change disables the bulk of the CI jobs, marks
the existing primary jobs we want to succeed to be non-voting,
and creates a bionic job as we should ideally already be on
bionic.

The overall plan being to iterate through the jobs and get them
working one at a time as opposed to try and make them all
functional in one changeset.

Change-Id: I9a1e29d1c8bcc4f3cf00df81405f82c22fd10188
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/52/700952/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/bifrost-jobs.yaml']",2,34b59cca1e2a6b9e30612db8579771a0e0bfa95d,, name: bifrost-integration-tinyipa-ubuntu-bionic parent: bifrost-integration-tinyipa nodeset: ubuntu-bionic - job:,,28,20
openstack%2Fironic-python-agent~master~I5856d1972619aea625a71119536075ec1629d9cb,openstack/ironic-python-agent,master,I5856d1972619aea625a71119536075ec1629d9cb,Retool UEFI nvram update,ABANDONED,2019-12-23 21:06:07.000000000,2020-01-03 00:39:51.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 21:06:07.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cf0e3a7323314fe7c0ac585a4e088b0afa38b4a6', 'message': ""Retool UEFI nvram update\n\nRetool nvram update so we don't absolutely need a UUID, and instead\ntrust what is located on the disk.\n\nChange-Id: I5856d1972619aea625a71119536075ec1629d9cb\n""}]",0,700447,cf0e3a7323314fe7c0ac585a4e088b0afa38b4a6,4,2,1,11655,,,0,"Retool UEFI nvram update

Retool nvram update so we don't absolutely need a UUID, and instead
trust what is located on the disk.

Change-Id: I5856d1972619aea625a71119536075ec1629d9cb
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/47/700447/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py']",2,cf0e3a7323314fe7c0ac585a4e088b0afa38b4a6,uefi_workflow,"def _manage_uefi(device, efi_system_part_uuid=None): # Trust the contents on the disk in the event of a whole disk image. efi_partition = utils.get_efi_part_on_device(device) if not efi_partition: # We shouldn't need to mount the base OS or even know about it # to update nvram firmware. # utils.execute('mount', '-r', root_partition, local_path) # utils.execute('mount', '-t', 'sysfs', 'none', local_path + # '/sys') # try: # utils.execute('umount', local_path + '/sys', attempts=3, # delay_on_retry=True) # except processutils.ProcessExecutionError as e: # LOG.warning(umount_warn_msg, # {'path': local_path + '/sys', 'error': e}) # utils.execute('umount', local_path, attempts=3, # delay_on_retry=True) # root_uuid=root_uuid,","def _manage_uefi(device, root_uuid, efi_system_part_uuid=None): :param root_uuid: the root uuid of the device. root_partition = _get_partition(device, uuid=root_uuid) if efi_system_part_uuid: else: efi_partition = utils.get_efi_part_on_device(device) utils.execute('mount', '-r', root_partition, local_path) utils.execute('mount', '-t', 'sysfs', 'none', local_path + '/sys') try: utils.execute('umount', local_path + '/sys', attempts=3, delay_on_retry=True) except processutils.ProcessExecutionError as e: LOG.warning(umount_warn_msg, {'path': local_path + '/sys', 'error': e}) utils.execute('umount', local_path, attempts=3, delay_on_retry=True) root_uuid=root_uuid,",61,45
openstack%2Fswift~master~If912f71d8b0d03369680374e8233da85d8d38f85,openstack/swift,master,If912f71d8b0d03369680374e8233da85d8d38f85,Allow internal clients to use reserved namespace,MERGED,2019-09-13 19:01:57.000000000,2020-01-03 00:36:29.000000000,2019-12-03 05:44:00.000000000,"[{'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-13 19:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dbf333009d822ff2b9a57e01f29ff274c5bbf411', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 2, 'created': '2019-09-19 17:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f16f398d589b4c22ef6b468e7a40a8bb06bfdc05', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 3, 'created': '2019-09-30 03:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6d8edcbe0715a16c9b92f0420a8d85a12ca73647', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 4, 'created': '2019-10-01 19:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2ec4f8c74d3a6b2ae9796913cc076e13c69edb2c', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 5, 'created': '2019-10-01 20:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1315de7b0e09b5c999e4161b12209732d2ed027f', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 6, 'created': '2019-10-02 17:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e9eed31655252071375aa7ff013d41b90de5c356', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 7, 'created': '2019-10-04 19:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/275b9a7712fa3be4600f0e5f6266ea583ba587e1', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 8, 'created': '2019-10-07 19:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8feb0856eec3d29301df59a8d08bd631e99b7ffb', 'message': 'Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 9, 'created': '2019-10-09 14:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0fc126531c9875251ee09c44f8a82b817f4871b9', 'message': 'WIP: Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 10, 'created': '2019-10-10 15:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f3a31eea820b0597d96caccb7bd4efe6fd2cdafa', 'message': 'WIP: Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 11, 'created': '2019-10-16 18:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30c8de00d5728a1d5fe818faaab6670e39ab3075', 'message': 'WIP: Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 12, 'created': '2019-10-17 19:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/16acdb9a0ff5df288ba33a1a0ac5f1a25c7ed147', 'message': 'WIP: Allow internal clients to use null namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 13, 'created': '2019-10-21 14:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2edd90f15450df9fe2f0fad844d67bd2f2a22230', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 14, 'created': '2019-10-21 16:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f5e00b096778c2a033f20130970003d78f40a574', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 15, 'created': '2019-10-21 19:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30df9499f77c9f7fa83f4a7f36756ade75eb19ef', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 16, 'created': '2019-10-21 20:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e9f590c6cbb103800efd4626360d34d15b185262', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 17, 'created': '2019-10-22 20:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a51fba887a1abbdb3e539bc19e0e0305562d643e', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 18, 'created': '2019-10-23 18:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d81dc8a7218d52407c7b3066fdf80a33f1562c7b', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 19, 'created': '2019-10-24 20:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d1760ef28dd06ecad8c32ee4e1574819ef6be3dc', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 20, 'created': '2019-10-28 22:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/198349a6f90f4d526e6594d96fba3f5500e481e8', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 21, 'created': '2019-10-29 13:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fda54714313c49ac7cbcbdba94aa773f39b94632', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 22, 'created': '2019-10-29 13:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/318794efb29c90cdf1e600756752dbda9cea7eea', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 23, 'created': '2019-11-13 20:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6c90f5c9679b70e7c7ef0e15efda800e4fc9d6d3', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 24, 'created': '2019-11-14 23:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2fe031457a1beaad9b539a84eaa188f5258fed36', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 25, 'created': '2019-11-15 00:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2fd9375553ed44b4bc5c7d0ed9d41448ec55d4c7', 'message': 'WIP: Allow internal clients to use reserved namespace\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n'}, {'number': 26, 'created': '2019-11-18 15:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eb8b6388adf337e7db5b15ffb337f230cb3f4005', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 27, 'created': '2019-11-19 18:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b24fd35a50f8081cd7b877cc3180765c86cc7f4c', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 28, 'created': '2019-11-19 23:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cc3ea64d18df2f400caf1f9f1e5bd6f7bec627fc', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 29, 'created': '2019-11-20 20:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ec8866610a64909ae366602141172396a1ff53cb', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 30, 'created': '2019-11-21 00:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/76231b227866a22fe148e199df17770c2d781b61', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 31, 'created': '2019-11-21 15:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ca135b85b67dafc2ab64d4bc285896f26f6bb713', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 32, 'created': '2019-11-21 16:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b995a3c7e5c77523d1294624c2bbfaf8b3474a13', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 33, 'created': '2019-11-22 00:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd60adca6f96ded395a97a3d788493375bd62d98', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 34, 'created': '2019-11-22 02:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/543e2a3cdd2c752de4790ae0f7825ede86eb0946', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 35, 'created': '2019-11-25 22:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/127cc83cc14d8335d7f4fb911e27df21d5d25380', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 36, 'created': '2019-11-26 00:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4d829ee32c997910ae79454365ac33ac6f5b1a4b', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}, {'number': 37, 'created': '2019-11-26 14:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5341c2270ae98b579a7fe99293150f9788e88904', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\n""}, {'number': 38, 'created': '2019-11-27 18:27:22.000000000', 'files': ['test/probe/common.py', 'swift/account/backend.py', 'swift/obj/server.py', 'test/probe/test_replication_servers_working.py', 'swift/common/middleware/listing_formats.py', 'test/unit/account/test_utils.py', 'test/unit/common/test_direct_client.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/helpers.py', 'swift/account/utils.py', 'swift/account/server.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_listing_formats.py', 'test/unit/container/test_backend.py', 'test/unit/account/test_backend.py', 'swift/proxy/controllers/obj.py', 'swift/container/server.py', 'swift/common/direct_client.py', 'swift/account/reaper.py', 'swift/common/constraints.py', 'test/unit/common/test_swob.py', 'swift/common/internal_client.py', 'test/unit/common/test_constraints.py', 'test/unit/account/test_reaper.py', 'test/unit/account/test_server.py', 'test/unit/common/test_request_helpers.py', 'test/unit/proxy/test_server.py', 'test/unit/obj/test_server.py', 'swift/proxy/server.py', 'swift/common/middleware/gatekeeper.py', 'swift/common/utils.py', 'test/unit/common/test_internal_client.py', 'test/probe/test_account_reaper.py', 'test/unit/common/middleware/test_gatekeeper.py', 'etc/proxy-server.conf-sample', 'swift/common/swob.py', 'test/probe/test_reserved_name.py', 'swift/common/request_helpers.py', 'swift/container/backend.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/698717d886b2b55ea9b490719851c85c20b57240', 'message': ""Allow internal clients to use reserved namespace\n\nReserve the namespace starting with the NULL byte for internal\nuse-cases.  Backend services will allow path names to include the NULL\nbyte in urls and validate names in the reserved namespace.  Database\nservices will filter all names starting with the NULL byte from\nresponses unless the request includes the header:\n\n    X-Backend-Allow-Reserved-Names: true\n\nThe proxy server will not allow path names to include the NULL byte in\nurls unless a middlware has set the X-Backend-Allow-Reserved-Names\nheader.  Middlewares can use the reserved namespace to create objects\nand containers that can not be directly manipulated by clients.  Any\nobjects and bytes created in the reserved namespace will be aggregated\nto the user's account totals.\n\nWhen deploying internal proxys developers and operators may configure\nthe gatekeeper middleware to translate the X-Allow-Reserved-Names header\nto the Backend header so they can manipulate the reserved namespace\ndirectly through the normal API.\n\nUpgradeImpact: it's not safe to rollback from this change\n\nChange-Id: If912f71d8b0d03369680374e8233da85d8d38f85\n""}]",136,682138,698717d886b2b55ea9b490719851c85c20b57240,127,4,38,1179,,,0,"Allow internal clients to use reserved namespace

Reserve the namespace starting with the NULL byte for internal
use-cases.  Backend services will allow path names to include the NULL
byte in urls and validate names in the reserved namespace.  Database
services will filter all names starting with the NULL byte from
responses unless the request includes the header:

    X-Backend-Allow-Reserved-Names: true

The proxy server will not allow path names to include the NULL byte in
urls unless a middlware has set the X-Backend-Allow-Reserved-Names
header.  Middlewares can use the reserved namespace to create objects
and containers that can not be directly manipulated by clients.  Any
objects and bytes created in the reserved namespace will be aggregated
to the user's account totals.

When deploying internal proxys developers and operators may configure
the gatekeeper middleware to translate the X-Allow-Reserved-Names header
to the Backend header so they can manipulate the reserved namespace
directly through the normal API.

UpgradeImpact: it's not safe to rollback from this change

Change-Id: If912f71d8b0d03369680374e8233da85d8d38f85
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/682138/33 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'swift/obj/server.py', 'test/unit/obj/test_server.py', 'test/unit/container/test_server.py', 'swift/common/swob.py', 'swift/common/constraints.py', 'swift/proxy/server.py']",7,dbf333009d822ff2b9a57e01f29ff274c5bbf411,rebase-s3api-object-versioning," if not check_utf8(wsgi_to_str(req.path_info), internal=req.allow_null_byte):", if not check_utf8(wsgi_to_str(req.path_info)):,14,8
openstack%2Ftripleo-common~stable%2Fstein~I081330c28c967aa000ec89f255876d5386599a78,openstack/tripleo-common,stable/stein,I081330c28c967aa000ec89f255876d5386599a78,Simplify octavia post deploy configs,MERGED,2019-10-21 21:04:06.000000000,2020-01-03 00:34:37.000000000,2020-01-03 00:32:48.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-21 21:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d87329fe6c5d503e4137e92d8b79d9a754097390', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 2, 'created': '2019-10-21 21:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e28ed3f725ed24696be053d908c9d5429a0418b2', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 3, 'created': '2019-10-29 07:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/af1f3e6e5fd29de27d80a5a805c83cd373b2c3b3', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 4, 'created': '2019-11-26 19:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6f73055eae33148b81ed314ce8ec9b830e4d8dda', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 5, 'created': '2019-12-23 10:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9abbf602770593ef9c9725092358b6ac223cf9e8', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of:\n- https://review.opendev.org/#/c/687311/\n- https://review.opendev.org/#/c/696727/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 6, 'created': '2019-12-23 12:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2fe1df1dbf07874d460fa4b54830a57f0a7c5545', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of:\n- https://review.opendev.org/#/c/687311/\n- https://review.opendev.org/#/c/696727/\n\nRelated-Bug: #1836074\n\nDepends-On: https://review.opendev.org/#/c/691825/\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 7, 'created': '2019-12-23 19:54:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/79dd41c7e3a8af7da3a5d7c7e3e0e1ebf2625e8a', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 8, 'created': '2019-12-23 22:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/da4acdb8fffdecb89711af22832892c8d40b0f31', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}, {'number': 9, 'created': '2020-01-02 11:28:41.000000000', 'files': ['releasenotes/notes/fix-scattered-octavia-configs-2ef4f66ed1e02b60.yaml', 'playbooks/roles/octavia-controller-config/tasks/octavia.yml', 'playbooks/roles/octavia-controller-config/templates/manager-post-deploy.conf.j2', 'playbooks/roles/octavia-controller-post-config/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1ecf1827d5dcacd561bd4dee65a4b772223ad63c', 'message': 'Simplify octavia post deploy configs\n\nOctavia shares config across multiple services in sometimes unexpected\nways. To avoid problems, this patch merges external deploy tasks\nconfiguration into a single file.\n\nNote: this is a semantic backport of https://review.opendev.org/#/c/687311/\n\nRelated-Bug: #1836074\n\nCo-Authored-By: Brent Eagles <beagles@redhat.com>\nChange-Id: I081330c28c967aa000ec89f255876d5386599a78\n'}]",0,689875,1ecf1827d5dcacd561bd4dee65a4b772223ad63c,45,6,9,6469,,,0,"Simplify octavia post deploy configs

Octavia shares config across multiple services in sometimes unexpected
ways. To avoid problems, this patch merges external deploy tasks
configuration into a single file.

Note: this is a semantic backport of https://review.opendev.org/#/c/687311/

Related-Bug: #1836074

Co-Authored-By: Brent Eagles <beagles@redhat.com>
Change-Id: I081330c28c967aa000ec89f255876d5386599a78
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/75/689875/9 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-scattered-octavia-configs-2ef4f66ed1e02b60.yaml', 'playbooks/roles/octavia-controller-config/tasks/octavia.yml', 'playbooks/roles/octavia-controller-config/templates/manager-post-deploy.conf.j2', 'playbooks/roles/octavia-controller-config/tasks/main.yml', 'playbooks/roles/octavia-controller-post-config/tasks/main.yml']",5,d87329fe6c5d503e4137e92d8b79d9a754097390,," awk -F '=' -e '/^controller_ip_port_list/ { print $2; }' ""{{octavia_confd_prefix}}/etc/octavia/post-deploy.conf"" - name: setting [health_manager]/controller_ip_port_list path: ""{{ octavia_confd_prefix }}/etc/octavia/post-deploy.conf"""," awk -F '=' -e '/^controller_ip_port_list/ { print $2; }' ""{{octavia_confd_prefix}}/etc/octavia/conf.d/octavia-worker/worker-post-deploy.conf"" - name: update octavia worker config file path: ""{{octavia_confd_prefix}}/etc/octavia/conf.d/octavia-worker/worker-post-deploy.conf""",21,37
openstack%2Ftripleo-heat-templates~stable%2Fstein~I32524f85ef6a0ca3e87fa9acc8c9e12776225717,openstack/tripleo-heat-templates,stable/stein,I32524f85ef6a0ca3e87fa9acc8c9e12776225717,Simplify octavia post deploy configs,MERGED,2019-10-29 08:52:47.000000000,2020-01-03 00:34:19.000000000,2020-01-03 00:32:55.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 7144}, {'_account_id': 11082}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-10-29 08:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/158d3319aa7b2e6026e3b39f0bdfa33bbf96ef92', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nConflicts:\n    deployment/octavia/octavia-health-manager-container-puppet.yaml\n    deployment/octavia/octavia-housekeeping-container-puppet.yaml\n    deployment/octavia/octavia-worker-container-puppet.yaml\n\nCloses-Bug: #1836074\nDepends-On: https://review.opendev.org/#/c/689875/\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n'}, {'number': 2, 'created': '2019-12-23 10:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/086ad979e82c8bfe33fcbc6ea976d67c48ff4433', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nConflicts:\n    deployment/octavia/octavia-health-manager-container-puppet.yaml\n    deployment/octavia/octavia-housekeeping-container-puppet.yaml\n    deployment/octavia/octavia-worker-container-puppet.yaml\n\nCloses-Bug: #1836074\nDepends-On: https://review.opendev.org/#/c/689875/\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n'}, {'number': 3, 'created': '2019-12-23 12:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e96d99456397fb5589ffab4fe46eacc36036e50', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nBackport notes:\n\n- This backport also includes https://review.opendev.org/#/c/696729/\n- Due to a circular dependency with https://review.opendev.org/#/c/689875/\n  we have to keep the old --config-dir for now. A follow-up patch will\n  remove it.\n\nCloses-Bug: #1836074\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n'}, {'number': 4, 'created': '2020-01-02 13:57:08.000000000', 'files': ['deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'releasenotes/notes/consolidate-octavia-post-deploy-configs-bc251a5446e5615d.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a45e9b37a9664e753125526211c253dee318368', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nBackport note: this backport also includes https://review.opendev.org/696729/\nDepends-On: https://review.opendev.org/#/c/689875/\nCloses-Bug: #1836074\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n'}]",0,691825,6a45e9b37a9664e753125526211c253dee318368,29,9,4,6469,,,0,"Simplify octavia post deploy configs

Consolidate post deploy configurations in a single file. Octavia
controller services share many configurations. It is best to consolidate
them in the same configuration file. This fixes problems seen like
amphorae not having the controller_ip_port_list config value set on
failover triggered by the Health Manager service as that config was only
being loaded for the Worker service.

Backport note: this backport also includes https://review.opendev.org/696729/
Depends-On: https://review.opendev.org/#/c/689875/
Closes-Bug: #1836074

Change-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717
(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)
(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/691825/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'releasenotes/notes/consolidate-octavia-post-deploy-configs-bc251a5446e5615d.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml']",4,158d3319aa7b2e6026e3b39f0bdfa33bbf96ef92,," command: /usr/bin/octavia-housekeeping --config-file /usr/share/octavia/octavia-dist.conf --config-file /etc/octavia/octavia.conf --config-file /etc/octavia/post-deploy.conf --log-file /var/log/octavia/housekeeping.log --config-dir /etc/octavia/conf.d/octavia-housekeeping tripleo_container_cli: ""docker"" - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent post_update_tasks: - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent", command: /usr/bin/octavia-housekeeping --config-file /usr/share/octavia/octavia-dist.conf --config-file /etc/octavia/octavia.conf --log-file /var/log/octavia/housekeeping.log --config-dir /etc/octavia/conf.d/common --config-dir /etc/octavia/conf.d/octavia-housekeeping,44,3
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I0c651d127cd2bb179f7592a0519a5fd5064faeb3,openstack/tripleo-heat-templates,stable/train,I0c651d127cd2bb179f7592a0519a5fd5064faeb3,Use async tasks for long running common tasks,MERGED,2019-12-30 18:39:51.000000000,2020-01-03 00:32:59.000000000,2020-01-03 00:32:59.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-30 18:39:51.000000000', 'files': ['common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7362626cabf4f6b77cb16c147f227d506974b64a', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n(cherry picked from commit 106ce3267fd1471cee184f697f7cb19c695ab36c)\n'}]",0,700787,7362626cabf4f6b77cb16c147f227d506974b64a,7,4,1,3153,,,0,"Use async tasks for long running common tasks

Use async with poll: 0 for the long running common tasks including:

- puppet host configuration
- container-puppet generate config
- container starting
- container-puppet bootstrap tasks

Executing the tasks in this manner and then polling for the results
causes all of the tasks to be started in parallel across all the nodes,
regardless of the number of ansible forks configured.

The behavior will be that ansible will start the task on the first count
of nodes that matches the configured forks value. Since poll:0, ansible
will immediately move on to the next batch, etc. Effectively, all the
tasks are started in parallel just as quickly as ansible can start them.

The polling tasks (async_status) will then execute in parallel up to the
configured number of forks. As tasks start to finish, ansible moves on
to checking the status of the next batch (again, up to the configured
number of forks). Since most nodes will configure around the same time,
the polling tasks finish roughly at the same time (except for
differences in roles, such as controllers taking much longer).

This behavior results in a signifcant performance improvement at scale,
or when deploying any number of nodes greater than the configured forks
value. Instead of waiting for the first batch to fully complete, all the
nodes are started in parallel.

For example, if puppet host configuration usually takes 5 minutes per
node, and there are 100 nodes, with 25 forks, previously this would have
taken 20 minutes. With this patch, it would now take closer to 5 minutes
for all 100 nodes, plus some overhead for polling.

This more closely matches the behavior previously used with Heat, when
all the nodes were operating in ""pull"" mode in parallel.

Change-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3
(cherry picked from commit 106ce3267fd1471cee184f697f7cb19c695ab36c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/87/700787/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-tasks.yaml'],1,7362626cabf4f6b77cb16c147f227d506974b64a,again/train," async: 3600 poll: 0 register: puppet_host_async_result - name: Wait for puppet host configuration to finish async_status: jid: ""{{ puppet_host_async_result.ansible_job_id }}"" register: puppet_host_outputs until: puppet_host_outputs.finished retries: 1200 delay: 3 failed_when: - (not puppet_host_outputs.finished) or (puppet_host_outputs.rc is defined and puppet_host_outputs.rc not in [0, 2]) tags: - host_config var: puppet_host_outputs.stdout_lines | default([]) | union(puppet_host_outputs.stderr_lines | default([])) - puppet_host_outputs.rc is defined changed_when: puppet_host_outputs.rc == 2 failed_when: puppet_host_outputs.rc not in [0, 2] async: 3600 poll: 0 register: generate_config_async_result tags: - container_config - name: Wait for container-puppet tasks (generate config) to finish async_status: jid: ""{{ generate_config_async_result.ansible_job_id }}"" register: generate_config_outputs until: generate_config_outputs.finished retries: 1200 delay: 3 when: step|int == 1 var: generate_config_outputs.stdout_lines | default([]) | union(generate_config_outputs.stderr_lines | default([])) when: generate_config_outputs.rc is defined failed_when: generate_config_outputs.rc != 0 async: 3600 poll: 0 register: start_containers_async_result tags: - container_startup_configs - name: Wait for containers to start for step {{ step }} using paunch async_status: jid: ""{{ start_containers_async_result.ansible_job_id }}"" register: start_containers_outputs until: start_containers_outputs.finished retries: 1200 delay: 3 var: start_containers_outputs.stdout_lines | default([]) | union(start_containers_outputs.stderr_lines | default([])) when: start_containers_outputs.rc is defined failed_when: start_containers_outputs.rc != 0 async: 3600 poll: 0 register: bootstrap_tasks_async_result - name: Wait for container-puppet tasks (bootstrap tasks) for step {{ step }} to finish async_status: jid: ""{{ bootstrap_tasks_async_result.ansible_job_id }}"" register: bootstrap_tasks_outputs until: bootstrap_tasks_outputs.finished retries: 1200 delay: 3 when: host_container_puppet_tasks is defined tags: - container_config_tasks var: bootstrap_tasks_outputs.stdout_lines | default([]) | union(bootstrap_tasks_outputs.stderr_lines | default([])) when: - host_container_puppet_tasks is defined - bootstrap_tasks_outputs.rc is defined failed_when: bootstrap_tasks_outputs.rc != 0"," changed_when: outputs.rc == 2 register: outputs failed_when: false var: outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([])) - outputs.rc is defined failed_when: outputs.rc not in [0, 2] changed_when: false register: outputs failed_when: false no_log: true var: outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([])) when: outputs.rc is defined failed_when: outputs.rc != 0 var: outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([])) when: - enable_paunch|default(true) - outputs.rc is defined failed_when: outputs.rc != 0 changed_when: false register: outputs failed_when: false var: outputs.stdout_lines | default([]) | union(outputs.stderr_lines | default([])) when: outputs.rc is defined failed_when: outputs.rc != 0",71,24
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I06ee04b9b47226433f25e3cff08c461462a907d9,openstack/tripleo-heat-templates,stable/train,I06ee04b9b47226433f25e3cff08c461462a907d9,Execute deploy_steps_tasks per step,MERGED,2019-12-30 18:36:07.000000000,2020-01-03 00:32:57.000000000,2020-01-03 00:32:57.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-30 18:36:07.000000000', 'files': ['common/deploy-steps.j2', 'common/deploy-steps-tasks-step-0.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/829cefa761ec12016bc11636f3aeb501485a4df9', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\n(cherry picked from commit 2a6336a742c05e2e6c5fd30a21cd1989823773a1)\n""}]",0,700786,829cefa761ec12016bc11636f3aeb501485a4df9,7,4,1,3153,,,0,"Execute deploy_steps_tasks per step

Instead of including the entire deploy_steps_tasks.yaml tasks file for
each role at each step, use the per-step files and only if they exist.

This cuts down on the amount of time that ansible has to spend skipping
tasks that don't get run at a certain step, which can be significant at
scale.

Change-Id: I06ee04b9b47226433f25e3cff08c461462a907d9
(cherry picked from commit 2a6336a742c05e2e6c5fd30a21cd1989823773a1)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/700786/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/deploy-steps.j2', 'common/deploy-steps-tasks-step-0.j2.yaml']",2,829cefa761ec12016bc11636f3aeb501485a4df9,train/steps," delegate_to: localhost run_once: true- name: Check for {{role.name}}/deploy_steps_tasks_step0.yaml delegate_to: localhost run_once: true become: false stat: path: ""{{ '{{' }} playbook_dir ~ '/' ~ '{{role.name}}' ~ '/' ~ 'deploy_steps_tasks_step0.yaml' {{ '}}' }}"" register: tasks_stat - include_tasks: {{role.name}}/deploy_steps_tasks_step0.yaml when: - tripleo_role_name == '{{role.name}}' - tasks_stat.stat.exists",- import_tasks: {{role.name}}/deploy_steps_tasks.yaml when: tripleo_role_name == '{{role.name}}',24,4
openstack%2Ftripleo-ci~master~Iacc2a015f25266b29feff68bc7ed81b27f9d6aec,openstack/tripleo-ci,master,Iacc2a015f25266b29feff68bc7ed81b27f9d6aec,Add log collection entry for new ansible file,MERGED,2019-11-19 20:05:28.000000000,2020-01-03 00:32:52.000000000,2020-01-03 00:32:52.000000000,"[{'_account_id': 7353}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-19 20:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3c490ade40208a4c05ce4eca4044b0e58211dc1d', 'message': ""Add log collection entry for new ansible file\n\nDurring the container image prepare process the ansible log file will now\nbe written to a separate file. This change ensures that we collect the file\nshould it exist. By default the file will be store in the same path as the\ncreated log handler, however in the event that the log handler is only\nstream processing the ansible log file will be writtent to /tmp. To ensure\nwe're collecting the logs correctly, both the /tmp and expected /var/log,\npath's have been added to log file array.\n\nDepends-On: Ib208e53619901421d785ca0883f65954f02e59be\nChange-Id: Iacc2a015f25266b29feff68bc7ed81b27f9d6aec\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 2, 'created': '2019-12-24 10:14:15.000000000', 'files': ['toci-quickstart/config/collect-logs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/253bd4303267c53a60ae7a0e2bbb72a377fd6ddc', 'message': ""Add log collection entry for new ansible file\n\nDurring the container image prepare process the ansible log file will now\nbe written to a separate file. This change ensures that we collect the file\nshould it exist. By default the file will be store in the same path as the\ncreated log handler, however in the event that the log handler is only\nstream processing the ansible log file will be writtent to /tmp. To ensure\nwe're collecting the logs correctly, both the /tmp and expected /var/log,\npath's have been added to log file array.\n\nDepends-On: Ib208e53619901421d785ca0883f65954f02e59be\nChange-Id: Iacc2a015f25266b29feff68bc7ed81b27f9d6aec\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",0,695072,253bd4303267c53a60ae7a0e2bbb72a377fd6ddc,33,5,2,7353,,,0,"Add log collection entry for new ansible file

Durring the container image prepare process the ansible log file will now
be written to a separate file. This change ensures that we collect the file
should it exist. By default the file will be store in the same path as the
created log handler, however in the event that the log handler is only
stream processing the ansible log file will be writtent to /tmp. To ensure
we're collecting the logs correctly, both the /tmp and expected /var/log,
path's have been added to log file array.

Depends-On: Ib208e53619901421d785ca0883f65954f02e59be
Change-Id: Iacc2a015f25266b29feff68bc7ed81b27f9d6aec
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/72/695072/1 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/collect-logs.yml'],1,3c490ade40208a4c05ce4eca4044b0e58211dc1d,ooo-ansible-logging, - /tmp/tripleo-container-image-prepare-ansible.log - /var/log/tripleo-container-image-prepare-ansible.log,,2,0
openstack%2Fpuppet-tripleo~stable%2Fqueens~I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,openstack/puppet-tripleo,stable/queens,I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,Add octavia::nova to Octavia services,MERGED,2019-12-20 11:32:58.000000000,2020-01-03 00:32:51.000000000,2020-01-03 00:32:50.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 11:32:58.000000000', 'files': ['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/72e62ba2664b5375200608b213f15f55914ba39c', 'message': 'Add octavia::nova to Octavia services\n\nChange-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c\n(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)\n(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)\n(cherry picked from commit 41764cbde131371f3b56b926f84ed7b1d6ab3789)\n(cherry picked from commit e242ba21ea7731da2d4af3d082ba462a17fef830)\n'}]",0,700159,72e62ba2664b5375200608b213f15f55914ba39c,8,5,1,6469,,,0,"Add octavia::nova to Octavia services

Change-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c
(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)
(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)
(cherry picked from commit 41764cbde131371f3b56b926f84ed7b1d6ab3789)
(cherry picked from commit e242ba21ea7731da2d4af3d082ba462a17fef830)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/59/700159/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp']",3,72e62ba2664b5375200608b213f15f55914ba39c,, include ::octavia::nova,,3,0
openstack%2Fpuppet-tripleo~stable%2Frocky~I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,openstack/puppet-tripleo,stable/rocky,I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,Add octavia::nova to Octavia services,MERGED,2019-12-20 11:32:33.000000000,2020-01-03 00:32:51.000000000,2020-01-03 00:32:51.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 11:32:33.000000000', 'files': ['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e242ba21ea7731da2d4af3d082ba462a17fef830', 'message': 'Add octavia::nova to Octavia services\n\nChange-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c\n(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)\n(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)\n(cherry picked from commit 41764cbde131371f3b56b926f84ed7b1d6ab3789)\n'}]",0,700158,e242ba21ea7731da2d4af3d082ba462a17fef830,8,5,1,6469,,,0,"Add octavia::nova to Octavia services

Change-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c
(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)
(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)
(cherry picked from commit 41764cbde131371f3b56b926f84ed7b1d6ab3789)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/58/700158/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp']",3,e242ba21ea7731da2d4af3d082ba462a17fef830,, include ::octavia::nova,,3,0
openstack%2Fpuppet-tripleo~stable%2Fstein~I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,openstack/puppet-tripleo,stable/stein,I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,Add octavia::nova to Octavia services,MERGED,2019-12-20 11:32:07.000000000,2020-01-03 00:32:50.000000000,2020-01-03 00:32:50.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 11:32:07.000000000', 'files': ['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/41764cbde131371f3b56b926f84ed7b1d6ab3789', 'message': 'Add octavia::nova to Octavia services\n\nChange-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c\n(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)\n(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)\n'}]",0,700157,41764cbde131371f3b56b926f84ed7b1d6ab3789,8,5,1,6469,,,0,"Add octavia::nova to Octavia services

Change-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c
(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)
(cherry picked from commit 14e31e6471e03b0fee727e874f3a724def861a86)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/57/700157/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp']",3,41764cbde131371f3b56b926f84ed7b1d6ab3789,, include ::octavia::nova,,3,0
openstack%2Fpuppet-tripleo~stable%2Ftrain~I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,openstack/puppet-tripleo,stable/train,I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c,Add octavia::nova to Octavia services,MERGED,2019-12-20 11:31:37.000000000,2020-01-03 00:32:49.000000000,2020-01-03 00:32:49.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 11:31:37.000000000', 'files': ['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/14e31e6471e03b0fee727e874f3a724def861a86', 'message': 'Add octavia::nova to Octavia services\n\nChange-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c\n(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)\n'}]",0,700156,14e31e6471e03b0fee727e874f3a724def861a86,9,6,1,6469,,,0,"Add octavia::nova to Octavia services

Change-Id: I2590e46d4fb0c2dff23cb0fa6cacee9d42759e5c
(cherry picked from commit 1dff3a811a1a0f712ef96bf7d7c29d8994e9abe7)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/56/700156/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/octavia/health_manager.pp']",3,14e31e6471e03b0fee727e874f3a724def861a86,, include ::octavia::nova,,3,0
openstack%2Fpuppet-tripleo~stable%2Ftrain~Iededba802be4b88e3b232a7b7474f2f981e40a08,openstack/puppet-tripleo,stable/train,Iededba802be4b88e3b232a7b7474f2f981e40a08,Make sure neutron [placement] config section is set,MERGED,2020-01-02 08:35:35.000000000,2020-01-03 00:32:47.000000000,2020-01-03 00:32:47.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-02 08:35:35.000000000', 'files': ['spec/classes/tripleo_profile_base_neutron_server_spec.rb', 'manifests/profile/base/neutron/server.pp', 'spec/fixtures/hieradata/default.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2df86b9879e126814b72898a07e0a383f622ce84', 'message': 'Make sure neutron [placement] config section is set\n\nEven if the hiera keys for the [placement] config section\nget created [1], the section is not being created/filles as the\n::neutron::server::placement class is not included anywhere.\n\nThis includes ::neutron::server::placement to have the section\ncreate in the neutron.conf\n\n[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400\n\nConflicts:\n  manifests/profile/base/neutron/server.pp\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n(cherry picked from commit efbdd0f21b53f4ed9137f463d6765dcc0ece9e41)\n'}]",0,700874,2df86b9879e126814b72898a07e0a383f622ce84,8,6,1,17216,,,0,"Make sure neutron [placement] config section is set

Even if the hiera keys for the [placement] config section
get created [1], the section is not being created/filles as the
::neutron::server::placement class is not included anywhere.

This includes ::neutron::server::placement to have the section
create in the neutron.conf

[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400

Conflicts:
  manifests/profile/base/neutron/server.pp

Change-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08
(cherry picked from commit efbdd0f21b53f4ed9137f463d6765dcc0ece9e41)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/74/700874/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/tripleo_profile_base_neutron_server_spec.rb', 'manifests/profile/base/neutron/server.pp', 'spec/fixtures/hieradata/default.yaml']",3,2df86b9879e126814b72898a07e0a383f622ce84,neutron_placement-train,neutron::server::placement::password: 'password',,8,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I2204b72e40a86892f7312b9af77754d9c11a6c63,openstack/tripleo-heat-templates,stable/train,I2204b72e40a86892f7312b9af77754d9c11a6c63,Fix Octavia to use correct Puppet class,MERGED,2019-12-17 09:58:23.000000000,2020-01-03 00:32:46.000000000,2020-01-03 00:32:46.000000000,"[{'_account_id': 6469}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 09:58:23.000000000', 'files': ['deployment/octavia/octavia-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8184b949720ff804635baa437649cc6e7067b83b', 'message': 'Fix Octavia to use correct Puppet class\n\nAddition of octavia::controller::enable_anti_affinity was reverted in\n[1] as code to handle that config option already exists in octavia::nova\nclass. This patch follows that revert and sets THT to use octavia::nova.\n\n[1] https://review.opendev.org/#/c/699067/\n\nDepends-On: https://review.opendev.org/#/c/699074/\nChange-Id: I2204b72e40a86892f7312b9af77754d9c11a6c63\n(cherry picked from commit e47e7db8a2ee3e59a7c6b71620ba540078f4f123)\n'}]",0,699379,8184b949720ff804635baa437649cc6e7067b83b,10,5,1,6469,,,0,"Fix Octavia to use correct Puppet class

Addition of octavia::controller::enable_anti_affinity was reverted in
[1] as code to handle that config option already exists in octavia::nova
class. This patch follows that revert and sets THT to use octavia::nova.

[1] https://review.opendev.org/#/c/699067/

Depends-On: https://review.opendev.org/#/c/699074/
Change-Id: I2204b72e40a86892f7312b9af77754d9c11a6c63
(cherry picked from commit e47e7db8a2ee3e59a7c6b71620ba540078f4f123)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/699379/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/octavia/octavia-base.yaml'],1,8184b949720ff804635baa437649cc6e7067b83b,octavia-anit-affinity, octavia::nova::enable_anti_affinity: {get_param: OctaviaAntiAffinity}, octavia::controller::enable_anti_affinity: {get_param: OctaviaAntiAffinity},1,1
openstack%2Ftripleo-common~stable%2Fqueens~I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,openstack/tripleo-common,stable/queens,I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,Incorrectly derives NeutronPhysnetNUMANodesMapping,MERGED,2019-12-24 04:21:29.000000000,2020-01-02 23:57:05.000000000,2020-01-02 23:57:05.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-24 04:21:29.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a1ff10abbb602df12e46060a4bcafd89ff331def', 'message': 'Incorrectly derives NeutronPhysnetNUMANodesMapping\n\nThis change is to derive the NeutronPhysnetNUMANodesMapping\nparameter as dictionary instead of list.\n\nChange-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f\nCloses-Bug: #1856068\n(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)\n(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)\n(cherry picked from commit 515eb554b48312f16c26a0d67df261454ec45df3)\n(cherry picked from commit a4aecaaca5e115b96d32b8307737d3da9d15d380)\n'}]",0,700468,a1ff10abbb602df12e46060a4bcafd89ff331def,8,6,1,22865,,,0,"Incorrectly derives NeutronPhysnetNUMANodesMapping

This change is to derive the NeutronPhysnetNUMANodesMapping
parameter as dictionary instead of list.

Change-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f
Closes-Bug: #1856068
(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)
(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)
(cherry picked from commit 515eb554b48312f16c26a0d67df261454ec45df3)
(cherry picked from commit a4aecaaca5e115b96d32b8307737d3da9d15d380)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/700468/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,a1ff10abbb602df12e46060a4bcafd89ff331def,incorrect-phy-nw-numa-mappings-stable/train-stable/stein-stable/rocky-stable/queens," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes)).sum()).sum() %>"," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes))).sum() %>",1,1
openstack%2Fneutron~master~I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f,openstack/neutron,master,I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f,DVR: Ignore DHCP port during DVR host query,MERGED,2016-09-02 09:35:26.000000000,2020-01-02 23:52:07.000000000,2019-08-23 12:27:45.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4187}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 10386}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2016-09-02 09:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5275da79f1c9f893261184c0d6f2a684e72d9c4', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nScenario 1, one neutron network has two subnets, and connected all\nthese subnets to one DVR router.\nIn the qdhcp-ns the tap-device has all subnets' IP address, and its\ndirectly connected in both subnets. So qrouter-namspace is not needed.\n\nScenario 2, two neutron networks each have a separate subnet, and\nalso connect these subnets to one DVR router.\nBecause this scenario has two different networks, then the DHCP will be\nnaturally isolated. No need to let all subnets get reachable in such\nscenario, aka East/West routing is no needed for DHCP. Let the DHCP\nrequest only process in its own isolated broadcast domain.\n\nScenario 3, What will happen if a host only run DHCP agent?\nqrouter-dvr-namspace will never get hosted, but everything goes fine.\n\nThis patch removed the DHCP port device_owner qeury filter during DVR\nhost query.\n\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\nCloses-Bug: #1609217\n""}, {'number': 2, 'created': '2016-09-09 23:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b00b4cbdd15b8152e5345bae94a4c8ab389f2a83', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nScenario 1, one neutron network has two subnets, and connected all\nthese subnets to one DVR router.\nIn the qdhcp-ns the tap-device has all subnets' IP address, and its\ndirectly connected in both subnets. So qrouter-namspace is not needed.\n\nScenario 2, two neutron networks each have a separate subnet, and\nalso connect these subnets to one DVR router.\nBecause this scenario has two different networks, then the DHCP will be\nnaturally isolated. No need to let all subnets get reachable in such\nscenario in a DHCP namespace, aka East/West routing is no needed.\nLet the DHCP request only process in its own isolated broadcast domain.\n\nScenario 3, What will happen if a host only run DHCP agent?\nqrouter-dvr-namspace will never get hosted, but everything goes fine.\nVM could get an IP without that redundant router namespace.\n\nScenario 4, any new design/implementation once related to DHCP should\nnot let DHCP broadcast traffic can go across the domain. Routed\nnetwork/subnet may face such concern.\n\nScenario 5, in order to make DHCP high available, then cloud admins\nmay aslo run DHCP agent in all/most compute hosts. Then DVR qrouter\nnamespace may be hosted to those scheduled DHCP agent hosts. Not\nneeded either.\n\nThis patch removed the DHCP port device_owner qeury filter during DVR\nhost query. Then it will not implicitly set the DVR router namespace\nin its connected networks' DHCP agent hosts anymoe. And traffic from\nVMs will still be routed due to the routes in dvr local router\n(compute node) namespace.\n\nIn the DHCP namespace, if that host is not a scheduled DVR router\nsnat/compute host, we limited the traffic from/to DHCP port to its\nown domain, for instace: a dvr router is connected to net1(subnet1)\nand net2(subnet2), the DVR snat router is scheduled to network node1,\nnet1 and net2 DHCP agents are scheduled to network node2, then in\nnetwork node2:\n1. ip netns exec qdhcp-net1-namesapce `ping net2 IPs is not reachable`;\n2. ip netns exec qdhcp-net2-namesapce `ping net1 IPs is not reachable`;\nthe traffic across DHCP domains will not be routed anymore.\n\nDocImpact\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\nCloses-Bug: #1609217\n""}, {'number': 3, 'created': '2019-05-24 15:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad7d456a8dc7480f679da2797ed8ef92dac33315', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nScenario 1, one neutron network has two subnets, and connected all\nthese subnets to one DVR router.\nIn the qdhcp-ns the tap-device has all subnets' IP address, and its\ndirectly connected in both subnets. So qrouter-namspace is not needed.\n\nScenario 2, two neutron networks each have a separate subnet, and\nalso connect these subnets to one DVR router.\nBecause this scenario has two different networks, then the DHCP will be\nnaturally isolated. No need to let all subnets get reachable in such\nscenario in a DHCP namespace, aka East/West routing is no needed.\nLet the DHCP request only process in its own isolated broadcast domain.\n\nScenario 3, What will happen if a host only run DHCP agent?\nqrouter-dvr-namspace will never get hosted, but everything goes fine.\nVM could get an IP without that redundant router namespace.\n\nScenario 4, any new design/implementation once related to DHCP should\nnot let DHCP broadcast traffic can go across the domain. Routed\nnetwork/subnet may face such concern.\n\nScenario 5, in order to make DHCP high available, then cloud admins\nmay aslo run DHCP agent in all/most compute hosts. Then DVR qrouter\nnamespace may be hosted to those scheduled DHCP agent hosts. Not\nneeded either.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts. And traffic\nfrom VMs will still be routed due to the routes in dvr local router\n(compute node) namespace.\n\nIn the DHCP namespace, if that host is not a scheduled DVR router\nsnat/compute host, we limited the traffic from/to DHCP port to its\nown domain, for instace: a dvr router is connected to net1(subnet1)\nand net2(subnet2), the DVR snat router is scheduled to network node1,\nnet1 and net2 DHCP agents are scheduled to network node2, then in\nnetwork node2:\n1. ip netns exec qdhcp-net1-namesapce `ping net2 IPs is not reachable`;\n2. ip netns exec qdhcp-net2-namesapce `ping net1 IPs is not reachable`;\nthe traffic across DHCP domains will not be routed anymore.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 4, 'created': '2019-05-29 14:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7555cfae37dc097a3159024ba40e2d5a709d3b41', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 5, 'created': '2019-07-02 16:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b7c5d4676b6968d7a9f44ab94ededbf4199d137', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 6, 'created': '2019-07-04 14:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d031e4d5b840e0ba7f677ca7251459ec68fe4b52', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 7, 'created': '2019-07-09 05:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cb1ace1fc7b6797d03ad8bd40a65ea683cb24277', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 8, 'created': '2019-07-10 18:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eef0803c86e43e4aca7ae6b842be55fb9b705eb4', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 9, 'created': '2019-07-11 02:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80c2ce98607beb981a8cc467fd97882d591f6483', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 10, 'created': '2019-08-16 15:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b686e42dcd8b6b21da0066a455cd75dfb5d42e2', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 11, 'created': '2019-08-16 18:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c55e1dfc25984fd56f25ed673317c23e0b6f1345', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}, {'number': 12, 'created': '2019-08-21 05:35:19.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/db/dvr_mac_db.py', 'releasenotes/notes/config-host_dvr_for_dhcp-f949aca5bd666e24.yaml', 'doc/source/admin/deploy-ovs-ha-dvr.rst', 'neutron/common/utils.py', 'neutron/conf/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7', 'message': ""DVR: Ignore DHCP port during DVR host query\n\nFor large scale deployment, the dvr router will be installed to\nthe scheduled DHCP host. This will definitely increase the l3\nagent service pressure, especially in large number of concurrent\nupdates, creation, or agent restart.\n\nThis patch adds a config ``host_dvr_for_dhcp`` for the DHCP port\ndevice_owner filter during DVR host query. Then if we set\n``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router\nnamespace in its connected networks' DHCP agent hosts.\n\nCloses-Bug: #1609217\nChange-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f\n""}]",47,364793,8f057fb49ac637bd0dbf60ca07b89f0e4a59c7b7,160,21,12,9531,,,0,"DVR: Ignore DHCP port during DVR host query

For large scale deployment, the dvr router will be installed to
the scheduled DHCP host. This will definitely increase the l3
agent service pressure, especially in large number of concurrent
updates, creation, or agent restart.

This patch adds a config ``host_dvr_for_dhcp`` for the DHCP port
device_owner filter during DVR host query. Then if we set
``host_dvr_for_dhcp = False``, L3-agent will not host the DVR router
namespace in its connected networks' DHCP agent hosts.

Closes-Bug: #1609217
Change-Id: I53e20be9b306bf9d3b34ec6a31e3afabd5a0fd6f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/364793/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/tests/functional/services/l3_router/test_l3_dvr_ha_router_plugin.py', 'neutron/tests/unit/db/test_dvr_mac_db.py', 'neutron/common/utils.py', 'neutron/tests/functional/services/l3_router/test_l3_dvr_router_plugin.py', 'neutron/tests/unit/common/test_utils.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",7,d5275da79f1c9f893261184c0d6f2a684e72d9c4,bug/1609217,," def test_port_bound_for_dvr_with_dhcp_ports(self): self._test_port_bound_for_dvr_on_vlan_network( device_owner=n_const.DEVICE_OWNER_DHCP) self._test_port_bound_for_dvr_on_vlan_network( device_owner=n_const.DEVICE_OWNER_DHCP, ip_version=6) self._test_port_bound_for_dvr_on_vxlan_network( device_owner=n_const.DEVICE_OWNER_DHCP) self._test_port_bound_for_dvr_on_vxlan_network( device_owner=n_const.DEVICE_OWNER_DHCP, ip_version=6) def test_treat_devices_removed_for_dvr_with_dhcp_ports(self): self._test_treat_devices_removed_for_dvr( device_owner=n_const.DEVICE_OWNER_DHCP) self._test_treat_devices_removed_for_dvr( device_owner=n_const.DEVICE_OWNER_DHCP, ip_version=6) ",7,44
openstack%2Ftripleo-common~stable%2Fstein~I571af51db0d21226bc42dc21925384f0129cd581,openstack/tripleo-common,stable/stein,I571af51db0d21226bc42dc21925384f0129cd581,image-uploader: allow an image without Labels to be uploaded,MERGED,2019-12-25 22:39:50.000000000,2020-01-02 23:48:07.000000000,2020-01-02 23:46:40.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-25 22:39:50.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d725569c44e438fcfa38fae0c2648c481da8789c', 'message': ""image-uploader: allow an image without Labels to be uploaded\n\nSome images, like grafana don't have Labels set; let's just set an empty\ndefault if an image has no Labels and continue the upload.\n\nChange-Id: I571af51db0d21226bc42dc21925384f0129cd581\nCloses-Bug: #1857012\n(cherry picked from commit 95b68c6d19119a022f94061ba98accc717ff6657)\n(cherry picked from commit 95f837bf1ecd563f4f49df1232015e52db72af77)\n""}]",0,700571,d725569c44e438fcfa38fae0c2648c481da8789c,8,3,1,3153,,,0,"image-uploader: allow an image without Labels to be uploaded

Some images, like grafana don't have Labels set; let's just set an empty
default if an image has no Labels and continue the upload.

Change-Id: I571af51db0d21226bc42dc21925384f0129cd581
Closes-Bug: #1857012
(cherry picked from commit 95b68c6d19119a022f94061ba98accc717ff6657)
(cherry picked from commit 95f837bf1ecd563f4f49df1232015e52db72af77)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/71/700571/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py']",2,d725569c44e438fcfa38fae0c2648c481da8789c,train/labels-stable/stein," labels = config['config'].get('Labels', {}) labels = config['config'].get('Labels', {})", labels = config['config']['Labels'] labels = config['config']['Labels'],45,2
openstack%2Fdevstack-gate~master~I49aa3d7b60f4df4f32a0a3dbef9b13a97404dbf4,openstack/devstack-gate,master,I49aa3d7b60f4df4f32a0a3dbef9b13a97404dbf4,Add --verbose option to test_matrix.py,MERGED,2019-12-20 20:24:43.000000000,2020-01-02 23:24:05.000000000,2020-01-02 23:24:05.000000000,"[{'_account_id': 4146}, {'_account_id': 6873}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/dfaf6c79b8950aae3a5dd7f12f3d0e3258586940', 'message': ""Add --verbose option to test_matrix.py\n\nThis allows getting the debug logging out of test_matrix.py\nfrom the command line which is useful when you're trying to\ndebug what is wrong with entries in the feature test matrix.\n\nChange-Id: I49aa3d7b60f4df4f32a0a3dbef9b13a97404dbf4\n""}, {'number': 2, 'created': '2019-12-20 20:28:02.000000000', 'files': ['roles/test-matrix/library/test_matrix.py'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2cd8f2907fd766c792f3cd073ae7591525236302', 'message': ""Add --verbose option to test_matrix.py\n\nThis allows getting the debug logging out of test_matrix.py\nfrom the command line which is useful when you're trying to\ndebug what is wrong with entries in the feature test matrix.\n\nChange-Id: I49aa3d7b60f4df4f32a0a3dbef9b13a97404dbf4\n""}]",1,700237,2cd8f2907fd766c792f3cd073ae7591525236302,15,4,2,6873,,,0,"Add --verbose option to test_matrix.py

This allows getting the debug logging out of test_matrix.py
from the command line which is useful when you're trying to
debug what is wrong with entries in the feature test matrix.

Change-Id: I49aa3d7b60f4df4f32a0a3dbef9b13a97404dbf4
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/37/700237/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-features.sh', 'roles/test-matrix/library/test_matrix.py']",2,dfaf6c79b8950aae3a5dd7f12f3d0e3258586940,bug/1844929," parser.add_argument('-v', '--verbose', default=False, action='store_true', help='Log verbose output') if opts.verbose: LOG.setLevel(logging.DEBUG)",,9,4
openstack%2Fdevstack-gate~master~I857fbeba2af4a0f038fd2c2a19bb29c2767227a2,openstack/devstack-gate,master,I857fbeba2af4a0f038fd2c2a19bb29c2767227a2,Remove 'cinder' service from feature test matrix,MERGED,2019-12-20 20:24:43.000000000,2020-01-02 23:23:43.000000000,2020-01-02 23:23:43.000000000,"[{'_account_id': 4146}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:24:43.000000000', 'files': ['test-features.sh', 'roles/test-matrix/files/features.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f0008986a14caf549cb777a1363424308d143654', 'message': 'Remove \'cinder\' service from feature test matrix\n\nThe cinder config is including the ""cinder"" devstack\nservice which would mean that anything removed explicitly,\nlike c-bak, is going to be trumped by the fact that \'cinder\'\nis in the enabled services list in a job.\n\nThis removes \'cinder\' the service from cinder the config so\nthat cinder services have to be explicitly enabled/disabled\nin the feature test matrix.\n\nChange-Id: I857fbeba2af4a0f038fd2c2a19bb29c2767227a2\n'}]",0,700236,f0008986a14caf549cb777a1363424308d143654,10,3,1,6873,,,0,"Remove 'cinder' service from feature test matrix

The cinder config is including the ""cinder"" devstack
service which would mean that anything removed explicitly,
like c-bak, is going to be trumped by the fact that 'cinder'
is in the enabled services list in a job.

This removes 'cinder' the service from cinder the config so
that cinder services have to be explicitly enabled/disabled
in the feature test matrix.

Change-Id: I857fbeba2af4a0f038fd2c2a19bb29c2767227a2
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/36/700236/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-features.sh', 'roles/test-matrix/files/features.yaml']",2,f0008986a14caf549cb777a1363424308d143654,bug/1844929," services: [c-api, c-vol, c-sch, c-bak]"," services: [cinder, c-api, c-vol, c-sch, c-bak]",5,5
openstack%2Fnova~master~Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d,openstack/nova,master,Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d,Add new default roles in os-services API policies,MERGED,2019-03-28 17:42:38.000000000,2020-01-02 21:28:55.000000000,2019-12-20 21:48:13.000000000,"[{'_account_id': 782}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-03-28 17:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b55dc358cd9fd93865c82fc16631aee291ce2533', 'message': 'WIP: Add new default roles in os-services API policies\n\nThis part of Nova RBAC improvement includes:\n\n1. Add new defaults roles in os-services API policies.\n\n2. Add releasenotes for os-servie API policies listing all\n   modification done in this policy.\n\nMigration Plan for Operator:\n\n- Backward compatibility:\n  Old rules are maintained with same defaults so that any deployement\n  overridden those policy rules will keep working as it is.\n\n- Deprecation Plan:\n  Because these policy updates are huge and almost effecting all the nova\n  policies, We are defining the two cycle transition plan which used to be\n  one cycle for policy and config option modification.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-default-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 2, 'created': '2019-03-28 17:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2f87dc1d7ac53ad30808298df0d5afbf5f8c60e', 'message': 'WIP: Add new default roles in os-services API policies\n\nThis part of Nova RBAC improvement includes:\n\n1. Add new defaults roles in os-services API policies.\n\n2. Add releasenotes for os-servie API policies listing all\n   modification done in this policy.\n\nMigration Plan for Operator:\n\n- Backward compatibility:\n  Old rules are maintained with same defaults so that any deployement\n  overridden those policy rules will keep working as it is.\n\n- Deprecation Plan:\n  Because these policy updates are huge and almost effecting all the nova\n  policies, We are defining the two cycle transition plan which used to be\n  one cycle for policy and config option modification.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-default-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 3, 'created': '2019-06-04 07:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd16cb0e2a9a78e4f17f0273fdcdbc275ee7072', 'message': 'WIP: Add new default roles in os-services API policies\n\nThis part of Nova RBAC improvement includes:\n\n1. Add new defaults roles in os-services API policies.\n\n2. Add releasenotes for os-servie API policies listing all\n   modification done in this policy.\n\nMigration Plan for Operator:\n\n- Backward compatibility:\n  Old rules are maintained with same defaults so that any deployement\n  overridden those policy rules will keep working as it is.\n\n- Deprecation Plan:\n  Because these policy updates are huge and almost effecting all the nova\n  policies, We are defining the two cycle transition plan which used to be\n  one cycle for policy and config option modification.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-default-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 4, 'created': '2019-06-04 07:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e16998763d6d1c33a34998935235bcb26f3ac4f3', 'message': 'WIP: Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- Backward compatibility:\n  Old rules are maintained as deprecated rule with same defaults\n  so that existing deployement will keep working as it is.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 5, 'created': '2019-08-07 21:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f17a640d32882b88ba080da9b257dafa1a99d42a', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- Backward compatibility:\n  Old rules are maintained as deprecated rule with same defaults\n  so that existing deployement will keep working as it is.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 6, 'created': '2019-08-08 06:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1711d408d76a4c939545af9d503404fe0526854', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- Backward compatibility:\n  Old rules are maintained as deprecated rule with same defaults\n  so that existing deployement will keep working as it is.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665: UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated in 19.0.0 in favor of ""compute:services:disable"":""rule:admin_api"". Reason:\n    Since Stein release, nova API policies are more granular and introducing\n    new default roles with scope_type capabilities. These new changes improve\n    the security level, manageability. New policies are more rich in term of\n    handling access at system and project level with read, write roles. Nova\n    APIs are consuming these new policies improvements and automatically\n    migrate the old overridden policies. Old policies are silently going to\n    be ignored in nova 21.0.0 (OpenStack U) release.\n    . Either ensure your deployment is ready for the new default or copy/paste the deprecated policy into your policy file and maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 7, 'created': '2019-08-08 13:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/470cfc0d125109f9dd7a35b2c8897fd73c512d82', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 8, 'created': '2019-08-09 07:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/caf601b9563ec77fbb835c808d18a6dcbda74dcd', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 9, 'created': '2019-08-15 08:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cf264f128f848a918b10f35158d9fb88d773085', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 10, 'created': '2019-08-15 09:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4bc2996b24ab5124af5bb443c35d726ecac0f6c', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 11, 'created': '2019-08-15 10:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68e0236a3133d248231131e4b8504b61cd8de4fb', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 12, 'created': '2019-08-15 10:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8f393f1b125b97b97f734701efc609445be7118', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 13, 'created': '2019-08-15 10:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d581f288ff17cdd784c0b7910748d068b244c72', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 14, 'created': '2019-08-15 11:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32341341bfdab0374aa8e8a466dfd71070f0e62f', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 15, 'created': '2019-08-20 15:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a15e54fc51499abb89cfc590f8bc96abff91d91', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system asmin role\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 16, 'created': '2019-08-22 02:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53cce6fa4dcc71117600f2adcc0b6372f05abe98', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 17, 'created': '2019-10-18 08:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/758b1ef5ee733df023342ac6f5a92b44caf6ed3f', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 18, 'created': '2019-10-29 20:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e05b750b32f0a8d05aaa28744186338f9d60258', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 19, 'created': '2019-11-26 01:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8620547d141890926f143413725f1786fe6f0bc', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 20, 'created': '2019-11-26 01:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b617bdc82d28a5d13e42a525e87043d9f5715d7', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 21, 'created': '2019-11-26 19:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0324ec58479d1a37ce868b8f57b10b33a789b057', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 22, 'created': '2019-11-26 22:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e3920f65a4a6a8020726d2647c34e47914d068b', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}, {'number': 23, 'created': '2019-12-03 23:40:39.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_services.py', 'nova/tests/unit/test_policy.py', 'nova/tests/unit/policies/test_services.py', 'nova/policies/services.py', 'nova/tests/unit/fake_policy.py', 'nova/tests/unit/policy_fixture.py', 'nova/api/openstack/compute/services.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/972218e6ae0af4de565b8b1e41a20c4db13b9e7d', 'message': 'Add new default roles in os-services API policies\n\nThis adds new defaults roles in os-services API policies.\n\n- GET is default with system reader role\n- Rest all APIs are system admin role\n\nTest cases have been added to cover new defaults as well as\nfor deprecated rules.\n\n- Backward compatibility:\n    Old Rules and Defaults will keep working as it is because they\n    are added as deprecated rules and marked for removal in future\n    release. This means Existing deployement will keep working till\n    deprecated rules are there.\n\n- Below warning can be seen by operator to migrate the old policies\n  to new one:\n\n   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:\nUserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated\nin 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".\nReason: Since Train release, nova API policies are introducing new default roles\nwith scope_type capabilities. These new changes improve the security level\nand manageability. New policies are more rich in term of handling access\nat system and project level token with read, write roles.\nStart using the new policies and enable the scope checks via config option\n``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.\nOld policies are marked as deprecated and silently going to be ignored\nin nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready\nfor the new default or copy/paste the deprecated policy into your policy file\nand maintain it manually.\n\nPartial implement blueprint policy-defaults-refresh\n\nChange-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d\n'}]",38,648480,972218e6ae0af4de565b8b1e41a20c4db13b9e7d,211,18,23,8556,,,0,"Add new default roles in os-services API policies

This adds new defaults roles in os-services API policies.

- GET is default with system reader role
- Rest all APIs are system admin role

Test cases have been added to cover new defaults as well as
for deprecated rules.

- Backward compatibility:
    Old Rules and Defaults will keep working as it is because they
    are added as deprecated rules and marked for removal in future
    release. This means Existing deployement will keep working till
    deprecated rules are there.

- Below warning can be seen by operator to migrate the old policies
  to new one:

   /opt/stack/nova/.tox/py27/local/lib/python2.7/site-packages/oslo_policy/policy.py:665:
UserWarning: Policy ""os_compute_api:os-services"":""rule:admin_api"" was deprecated
in 20.0.0 in favor of ""compute:services:list"":""role:reader and system_scope:all"".
Reason: Since Train release, nova API policies are introducing new default roles
with scope_type capabilities. These new changes improve the security level
and manageability. New policies are more rich in term of handling access
at system and project level token with read, write roles.
Start using the new policies and enable the scope checks via config option
``nova.conf [oslo_policy] enforce_scope=True`` which is False by default.
Old policies are marked as deprecated and silently going to be ignored
in nova 22.0.0 (OpenStack V) release. Either ensure your deployment is ready
for the new default or copy/paste the deprecated policy into your policy file
and maintain it manually.

Partial implement blueprint policy-defaults-refresh

Change-Id: Ia8537923ebe5ce43f48a6e5efefc0a890e6a087d
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/648480/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/policies/hypervisors.py', 'nova/policies/services.py', 'releasenotes/notes/new-service-policy-626a3742fe6336a1.yaml', 'nova/policies/base.py', 'nova/policies/lock_server.py']",5,b55dc358cd9fd93865c82fc16631aee291ce2533,bp/policy-defaults-refresh," # NOTE(gmann) Becasue this policy is scoped # to 'system' as well as to 'project', keeping # base.RULE_ADMIN_OR_OWNER stay same here. This means # either system-admin or project-admin or owner of server # should be able to lock the server/",,53,8
openstack%2Fgovernance-uc~master~Ic94b4d603857f6a98b7929f8ca6aa01676664ce3,openstack/governance-uc,master,Ic94b4d603857f6a98b7929f8ca6aa01676664ce3,There was no election so the two candidates won by default.,MERGED,2019-12-28 19:08:19.000000000,2020-01-02 21:24:34.000000000,2020-01-02 21:23:15.000000000,"[{'_account_id': 1063}, {'_account_id': 7272}, {'_account_id': 12393}, {'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 24100}, {'_account_id': 28738}, {'_account_id': 30855}]","[{'number': 1, 'created': '2019-12-28 19:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/20363998185733e79bdbb254acdd8c0c952e4812', 'message': 'There was no election so the two candidates won by default.\n\nChange-Id: Ic94b4d603857f6a98b7929f8ca6aa01676664ce3\n'}, {'number': 2, 'created': '2019-12-28 19:15:50.000000000', 'files': ['reference/uc-election-aug2018.rst'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/caad42e045f4952d863cacf95a5f72f6857d9e35', 'message': 'There was no election so the two candidates won by default.\n\nChange-Id: Ic94b4d603857f6a98b7929f8ca6aa01676664ce3\n'}]",0,700731,caad42e045f4952d863cacf95a5f72f6857d9e35,10,8,2,24100,,,0,"There was no election so the two candidates won by default.

Change-Id: Ic94b4d603857f6a98b7929f8ca6aa01676664ce3
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/31/700731/2 && git format-patch -1 --stdout FETCH_HEAD,[],0,20363998185733e79bdbb254acdd8c0c952e4812,August 2018 Election Results,,,0,0
openstack%2Fswift~master~Iaf86223ef80cc36d05fdf5104eb6d92ae4d39505,openstack/swift,master,Iaf86223ef80cc36d05fdf5104eb6d92ae4d39505,s3api DELETE request return version-id and marker,ABANDONED,2019-12-20 06:14:19.000000000,2020-01-02 21:00:03.000000000,,"[{'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 06:14:19.000000000', 'files': ['test/unit/common/middleware/test_object_versioning.py', 'swift/obj/server.py', 'swift/common/middleware/s3api/controllers/obj.py', 'test/unit/common/middleware/s3api/test_obj.py', 'test/unit/common/middleware/s3api/test_versioning.py', 'swift/common/middleware/s3api/s3response.py', 'test/functional/test_object_versioning.py', 'swift/common/middleware/versioned_writes/object_versioning.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f9b23534164dfe1fd67ae20a83580df61085052e', 'message': 's3api DELETE request return version-id and marker\n\nMake sure that DELETE requests with version-id return the\nversion-id and delete-marker headers on the response.\n\nAlso added some unit tests for checking 501 NotImplemented\nresponses when object_versioning is not in swift_info\n\nChange-Id: Iaf86223ef80cc36d05fdf5104eb6d92ae4d39505\n'}]",2,700114,f9b23534164dfe1fd67ae20a83580df61085052e,7,4,1,9625,,,0,"s3api DELETE request return version-id and marker

Make sure that DELETE requests with version-id return the
version-id and delete-marker headers on the response.

Also added some unit tests for checking 501 NotImplemented
responses when object_versioning is not in swift_info

Change-Id: Iaf86223ef80cc36d05fdf5104eb6d92ae4d39505
",git fetch https://review.opendev.org/openstack/swift refs/changes/14/700114/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_object_versioning.py', 'swift/obj/server.py', 'swift/common/middleware/s3api/controllers/obj.py', 'test/unit/common/middleware/s3api/test_obj.py', 'test/unit/common/middleware/s3api/test_versioning.py', 'swift/common/middleware/s3api/s3response.py', 'test/functional/test_object_versioning.py', 'swift/common/middleware/versioned_writes/object_versioning.py']",8,f9b23534164dfe1fd67ae20a83580df61085052e,rebase-async-delete, resp.headers['X-Backend-Content-Type'] = DELETE_MARKER_CONTENT_TYPE resp.headers['X-Object-Version-Id'] = version,,120,10
openstack%2Frequirements~master~I8e95dc48b8ba2a7e16f1d34eb5ad0e87a3e96f4f,openstack/requirements,master,I8e95dc48b8ba2a7e16f1d34eb5ad0e87a3e96f4f,Add neutron to upper-constraints,ABANDONED,2019-12-04 21:21:51.000000000,2020-01-02 20:46:03.000000000,,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-04 21:21:51.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ba81a34bfc7b1c84895d7d4dd5ea5236871c0d86', 'message': 'Add neutron to upper-constraints\n\nSome projects, notably neutron plugins, are using the neutron service as\na library. There is the neutron-lib package, but apparently they have\nnot moved everything needed over to there yet.\n\nChange-Id: I8e95dc48b8ba2a7e16f1d34eb5ad0e87a3e96f4f\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,697369,ba81a34bfc7b1c84895d7d4dd5ea5236871c0d86,7,4,1,11904,,,0,"Add neutron to upper-constraints

Some projects, notably neutron plugins, are using the neutron service as
a library. There is the neutron-lib package, but apparently they have
not moved everything needed over to there yet.

Change-Id: I8e95dc48b8ba2a7e16f1d34eb5ad0e87a3e96f4f
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/69/697369/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ba81a34bfc7b1c84895d7d4dd5ea5236871c0d86,neutron,neutron===15.0.0,,1,0
openstack%2Ftrove~master~Iabcd4f02927c462dde214de69922c8df68e91973,openstack/trove,master,Iabcd4f02927c462dde214de69922c8df68e91973,Speed up installing cassandra-driver,ABANDONED,2020-01-02 10:42:07.000000000,2020-01-02 20:25:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-02 10:42:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/4afc8d3e342d06087942975bfb09a4e2daa78e47', 'message': 'Speed up installing cassandra-driver\n\nInstalling cassandra-driver always takes a long time, this patch fixes\nthat based on\nhttps://docs.datastax.com/en/developer/python-driver/3.20/installation/#cython-based-extensions\n\nChange-Id: Iabcd4f02927c462dde214de69922c8df68e91973\n'}]",0,700885,4afc8d3e342d06087942975bfb09a4e2daa78e47,3,1,1,6732,,,0,"Speed up installing cassandra-driver

Installing cassandra-driver always takes a long time, this patch fixes
that based on
https://docs.datastax.com/en/developer/python-driver/3.20/installation/#cython-based-extensions

Change-Id: Iabcd4f02927c462dde214de69922c8df68e91973
",git fetch https://review.opendev.org/openstack/trove refs/changes/85/700885/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4afc8d3e342d06087942975bfb09a4e2daa78e47,test-disable-cython, CASS_DRIVER_NO_CYTHON=1,,1,1
openstack%2Frpm-packaging~master~Id04f6048083db7104057d220a00cc6a12ef98d2c,openstack/rpm-packaging,master,Id04f6048083db7104057d220a00cc6a12ef98d2c,pymod2pkg: Update to 0.22.2,MERGED,2019-12-26 06:29:29.000000000,2020-01-02 19:46:48.000000000,2020-01-02 19:46:48.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-26 06:29:29.000000000', 'files': ['openstack/pymod2pkg/pymod2pkg.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ffc91cd22878fad4712382ff4e5f92344171cd03', 'message': 'pymod2pkg: Update to 0.22.2\n\nChange-Id: Id04f6048083db7104057d220a00cc6a12ef98d2c\n'}]",0,700592,ffc91cd22878fad4712382ff4e5f92344171cd03,13,5,1,7102,,,0,"pymod2pkg: Update to 0.22.2

Change-Id: Id04f6048083db7104057d220a00cc6a12ef98d2c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/92/700592/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/pymod2pkg/pymod2pkg.spec.j2'],1,ffc91cd22878fad4712382ff4e5f92344171cd03,,{% set upstream_version = upstream_version('0.22.2') %},{% set upstream_version = upstream_version('0.22.1') %},1,1
openstack%2Frpm-packaging~master~Ic0e81412cf0ba3f029bc2f8be52ffdf1ba210b7b,openstack/rpm-packaging,master,Ic0e81412cf0ba3f029bc2f8be52ffdf1ba210b7b,Dont package .pickl file,MERGED,2019-12-31 14:27:24.000000000,2020-01-02 19:46:47.000000000,2020-01-02 19:46:47.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-31 14:27:24.000000000', 'files': ['openstack/debtcollector/debtcollector.spec.j2', 'openstack/python-keystoneclient/python-keystoneclient.spec.j2', 'openstack/mox3/mox3.spec.j2', 'openstack/ceilometermiddleware/ceilometermiddleware.spec.j2', 'openstack/os-resource-classes/os-resource-classes.spec.j2', 'openstack/castellan/castellan.spec.j2', 'openstack/ironic/ironic.spec.j2', 'openstack/automaton/automaton.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e977dbd33f0d6fd00c26bacf15087fecc6e70eaf', 'message': 'Dont package .pickl file\n\nbecause it is not needed and will cause packages to differ for every build.\n\nSee https://reproducible-builds.org/ for why this matters.\n\nSimilar to previous commit e1d730c2ad95559cb6a0948cf8e99b4eb6eca2c2\n\nChange-Id: Ic0e81412cf0ba3f029bc2f8be52ffdf1ba210b7b\n'}]",1,700810,e977dbd33f0d6fd00c26bacf15087fecc6e70eaf,9,5,1,1446,,,0,"Dont package .pickl file

because it is not needed and will cause packages to differ for every build.

See https://reproducible-builds.org/ for why this matters.

Similar to previous commit e1d730c2ad95559cb6a0948cf8e99b4eb6eca2c2

Change-Id: Ic0e81412cf0ba3f029bc2f8be52ffdf1ba210b7b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/10/700810/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/debtcollector/debtcollector.spec.j2', 'openstack/python-keystoneclient/python-keystoneclient.spec.j2', 'openstack/mox3/mox3.spec.j2', 'openstack/ceilometermiddleware/ceilometermiddleware.spec.j2', 'openstack/castellan/castellan.spec.j2', 'openstack/os-resource-classes/os-resource-classes.spec.j2', 'openstack/ironic/ironic.spec.j2', 'openstack/automaton/automaton.spec.j2']",8,e977dbd33f0d6fd00c26bacf15087fecc6e70eaf,sphinx,"rm -rf doc/build/html/.{doctrees,buildinfo}","rm -rf html/.{doctrees,buildinfo}",11,8
openstack%2Fkolla-ansible~master~Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b,openstack/kolla-ansible,master,Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b,Add AArch64 CI job,MERGED,2019-12-17 16:52:07.000000000,2020-01-02 19:43:58.000000000,2020-01-02 19:41:29.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-17 16:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d755db19b51413b820f7866d20b6d8b27c397c7a', 'message': 'Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 2, 'created': '2019-12-17 17:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5aab20dc898bc29d24d6389c1d444013ca82162a', 'message': 'WIP: Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nNOTE: other CI jobs are disabled\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 3, 'created': '2019-12-17 17:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/49f02b16200ff95151a45b01c42d3eca712c0eae', 'message': 'WIP: Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nNOTE: other CI jobs are disabled\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 4, 'created': '2019-12-17 18:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/63e0c6a5214d4628c38d4462d39c49768f660591', 'message': 'WIP: Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nNOTE: other CI jobs are disabled\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 5, 'created': '2019-12-18 09:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/56a2fb83ecc62df05d98fb16e43b757cbcf955b1', 'message': 'WIP: Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nNOTE: other CI jobs are disabled\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 6, 'created': '2019-12-18 14:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c88d34bc76013a8b565f5bba470aa6457381bd17', 'message': 'WIP: Add AArch64 CI job\n\nDebian/source as this is what we use at Linaro.\n\nNOTE: other CI jobs are disabled\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 7, 'created': '2019-12-18 14:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c8e831cc2a9d53a263f2ec3ba1aa14b52fa195c4', 'message': 'Add AArch64 CI job\n\nDebian/source to match Kolla CI test.\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 8, 'created': '2019-12-19 08:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bee97b96757cca745459a8bf45d0eb616d442d3c', 'message': 'Add AArch64 CI job\n\nDebian/source to match Kolla CI test.\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}, {'number': 9, 'created': '2019-12-19 08:37:25.000000000', 'files': ['tests/run.yml', 'zuul.d/project.yaml', 'zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4f8326a894ebacf18092d09366dfa908405af359', 'message': 'Add AArch64 CI job\n\nDebian/source to match Kolla CI test.\n\nChange-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b\n'}]",5,699464,4f8326a894ebacf18092d09366dfa908405af359,38,5,9,24072,,,0,"Add AArch64 CI job

Debian/source to match Kolla CI test.

Change-Id: Ica45d5673db8ba1ebd4bfeb6e3d37b5ad5dd412b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/64/699464/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml']",3,d755db19b51413b820f7866d20b6d8b27c397c7a,, name: kolla-ansible-debian-source-aarch64 parent: kolla-ansible-base nodeset: kolla-ansible-debian-aarch64 voting: false vars: base_distro: debian install_type: source - job:,,18,0
openstack%2Fopenstack-ansible-os_ironic~master~Ia3be67197e33df68709e1f04a927596dc88aac52,openstack/openstack-ansible-os_ironic,master,Ia3be67197e33df68709e1f04a927596dc88aac52,Restart ironic services after inspector post install,ABANDONED,2020-01-02 18:48:08.000000000,2020-01-02 19:15:26.000000000,,[{'_account_id': 28619}],"[{'number': 1, 'created': '2020-01-02 18:48:08.000000000', 'files': ['tasks/ironic_inspector_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/3eea4fa3db1f415f3e0e8e7d722f52efb070d833', 'message': 'Restart ironic services after inspector post install\n\nChange-Id: Ia3be67197e33df68709e1f04a927596dc88aac52\n'}]",0,700926,3eea4fa3db1f415f3e0e8e7d722f52efb070d833,3,1,1,21314,,,0,"Restart ironic services after inspector post install

Change-Id: Ia3be67197e33df68709e1f04a927596dc88aac52
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/26/700926/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ironic_inspector_post_install.yml'],1,3eea4fa3db1f415f3e0e8e7d722f52efb070d833,, notify: - Restart ironic services,,2,0
openstack%2Fcinder~master~Ie94ae59a29473ca906c6df58a2681714049b16a1,openstack/cinder,master,Ie94ae59a29473ca906c6df58a2681714049b16a1,Remove Sheepdog Driver,MERGED,2019-12-19 13:26:05.000000000,2020-01-02 19:12:34.000000000,2020-01-02 19:10:41.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-19 13:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/facee9d8c83dfbb6094834f0422429bc5cec9b2c', 'message': 'Remove Sheepdog Driver\n\nThe Sheepdog project is no longer active and the driver was marked as\nunsupported in the Train release. This completes the deprecation process\nand removes the driver.\n\nChange-Id: Ie94ae59a29473ca906c6df58a2681714049b16a1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2019-12-21 09:03:35.000000000', 'files': ['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'cinder/volume/manager.py', 'doc/source/reference/support-matrix.rst', 'releasenotes/notes/sheepdog-driver-removal-b63d12460e886c33.yaml', 'cinder/tests/unit/volume/drivers/test_sheepdog.py', 'cinder/volume/drivers/sheepdog.py', 'doc/source/configuration/block-storage/drivers/sheepdog-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0835b0862eb65998433a2dfb35f7489cf2f9badf', 'message': 'Remove Sheepdog Driver\n\nThe Sheepdog project is no longer active and the driver was marked as\nunsupported in the Train release. This completes the deprecation process\nand removes the driver.\n\nChange-Id: Ie94ae59a29473ca906c6df58a2681714049b16a1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",1,699985,0835b0862eb65998433a2dfb35f7489cf2f9badf,57,26,2,11904,,,0,"Remove Sheepdog Driver

The Sheepdog project is no longer active and the driver was marked as
unsupported in the Train release. This completes the deprecation process
and removes the driver.

Change-Id: Ie94ae59a29473ca906c6df58a2681714049b16a1
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/85/699985/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'cinder/volume/manager.py', 'doc/source/reference/support-matrix.rst', 'releasenotes/notes/sheepdog-driver-removal-b63d12460e886c33.yaml', 'cinder/tests/unit/volume/drivers/test_sheepdog.py', 'cinder/volume/drivers/sheepdog.py', 'doc/source/configuration/block-storage/drivers/sheepdog-driver.rst']",8,facee9d8c83dfbb6094834f0422429bc5cec9b2c,ci_unsupported,,"=============== Sheepdog driver =============== Sheepdog is an open-source distributed storage system that provides a virtual storage pool utilizing internal disk of commodity servers. Sheepdog scales to several hundred nodes, and has powerful virtual disk management features like snapshotting, cloning, rollback, and thin provisioning. More information can be found on `Sheepdog Project <http://sheepdog.github.io/sheepdog/>`__. This driver enables the use of Sheepdog through Qemu/KVM. Supported operations ~~~~~~~~~~~~~~~~~~~~ Sheepdog driver supports these operations: - Create, delete, attach, and detach volumes. - Create, list, and delete volume snapshots. - Create a volume from a snapshot. - Copy an image to a volume. - Copy a volume to an image. - Clone a volume. - Extend a volume. Configuration ~~~~~~~~~~~~~ Set the following option in the ``cinder.conf`` file: .. code-block:: ini volume_driver = cinder.volume.drivers.sheepdog.SheepdogDriver The following table contains the configuration options supported by the Sheepdog driver: .. config-table:: :config-target: Sheepdog cinder.volume.drivers.sheepdog ",10,2125
openstack%2Fkolla-ansible~master~Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6,openstack/kolla-ansible,master,Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6,Make fluentd-elasticsearch configuration more robust,MERGED,2019-05-28 12:26:15.000000000,2020-01-02 19:12:30.000000000,2019-12-10 21:01:32.000000000,"[{'_account_id': 14826}, {'_account_id': 16036}, {'_account_id': 17669}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27336}, {'_account_id': 29915}, {'_account_id': 30491}, {'_account_id': 30523}, {'_account_id': 31408}]","[{'number': 1, 'created': '2019-05-28 12:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1477a3a27409f4a22a03f201384e21532d09bf54', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\n(limited to 10 days) to guard against cluster failures.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 2, 'created': '2019-05-30 06:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c3825a86b3cefb575023e909933aa9bb6f25e419', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\n(limited to 10 days) to guard against cluster failures.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 3, 'created': '2019-05-30 13:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6b5d6e93fdaa50a4b0b1495e1c0a4e9f67d075e9', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 4, 'created': '2019-06-04 12:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3caa6dd4e92b905351d3c05a1efa1d957723f999', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 5, 'created': '2019-06-19 11:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/113c52baa326eccad99c2d073060a4796bcc01b3', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 6, 'created': '2019-06-26 17:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ede39b416cef36912f19128d0e0fc920d994caaa', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 7, 'created': '2019-06-27 08:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3f0a0cceb20cc44959d0c229f8207fbb70f25af2', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 8, 'created': '2019-08-05 10:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4e2e2a7d6310551ab4a2672626fc5c8bf9e26906', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 9, 'created': '2019-11-12 08:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/65901ae276b1be3543674d3471f63721d022448f', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 10, 'created': '2019-11-12 10:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a497f3f7d3efcb4cd7aa4638b8a561df93266886', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 11, 'created': '2019-11-12 12:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/af17cca383554a0fec365de0ee7504e7659ef8a3', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 12, 'created': '2019-11-13 15:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3e359db67cb5e28100ac4b2119680ead7e31d1af', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 13, 'created': '2019-11-13 17:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2c9f25ce54297cee8340d7cc7e1a4ae1cabd279a', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 14, 'created': '2019-11-15 12:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/baaf3ec52365d798ac147c91a8380a2890d0bbef', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 15, 'created': '2019-11-15 13:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/55a152996ac51ad31713609642d775e7ceef7483', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 16, 'created': '2019-12-07 14:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3b7bf68b92223961005e11611c7e9a279eedd5bf', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}, {'number': 17, 'created': '2019-12-09 13:41:36.000000000', 'files': ['ansible/roles/common/templates/conf/output/01-es.conf.j2', 'ansible/roles/common/defaults/main.yml', 'ansible/roles/common/templates/conf/output/00-local.conf.j2', 'ansible/roles/common/templates/fluentd.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0c573062fc25e208bfa1206146fb31b401c8b7e5', 'message': 'Make fluentd-elasticsearch configuration more robust\n\nEnable reconnect_on_error option so that ES plugin re-establishes\na new session to the ES cluster on errors. Also, enable buffering\nto the file, so that the buffer survives container restarts.\n\nCo-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nCo-Authored-By: Doug Szumski <doug@stackhpc.com>\nCloses-Bug: #1830724\nChange-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6\n'}]",37,661747,0c573062fc25e208bfa1206146fb31b401c8b7e5,90,11,17,16036,,,0,"Make fluentd-elasticsearch configuration more robust

Enable reconnect_on_error option so that ES plugin re-establishes
a new session to the ES cluster on errors. Also, enable buffering
to the file, so that the buffer survives container restarts.

Co-Authored-By: Michal Nasiadka <mnasiadka@gmail.com>
Co-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Co-Authored-By: Doug Szumski <doug@stackhpc.com>
Closes-Bug: #1830724
Change-Id: Ia40685b9d4fc02194e03c8791ddeb3d29d7f07f6
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/47/661747/9 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/templates/conf/output/01-es.conf.j2'],1,1477a3a27409f4a22a03f201384e21532d09bf54,bug/1830724, reload_on_failure true reconnect_on_error true <buffer> @type file flush_interval 10s retry_timeout 10d path /var/run/td-agent/elasticsearch.buffer </buffer>,,8,0
openstack%2Fopenstack-helm~master~I3243068dfe91ebb97b3885002296a0f454822ec5,openstack/openstack-helm,master,I3243068dfe91ebb97b3885002296a0f454822ec5,Add capability for using FQDN in nova compute,MERGED,2019-12-13 22:20:41.000000000,2020-01-02 19:05:09.000000000,2020-01-02 19:02:45.000000000,"[{'_account_id': 8898}, {'_account_id': 11934}, {'_account_id': 17591}, {'_account_id': 18538}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-12-13 22:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9b17b4391574e1b2eea2bd5f768537235b0b9ea0', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2019-12-16 20:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f30745d224218e32de7c90fdd115ae699533e46e', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2019-12-17 02:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/913a540aa5762c4289e1d2857e0e20ae5336dea5', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 4, 'created': '2019-12-17 18:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c7330cb4a46a034b3667d0e028945569e3ceff45', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 5, 'created': '2019-12-20 19:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d703ae3479c712af9023e5283138a1f4f72fe2bf', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 6, 'created': '2020-01-01 20:01:25.000000000', 'files': ['tools/deployment/component/compute-kit/compute-kit.sh', 'nova/templates/bin/_health-probe.py.tpl', 'nova/templates/bin/_nova-compute-init.sh.tpl', 'nova/values.yaml', 'zuul.d/project.yaml', 'nova/templates/daemonset-compute.yaml', 'nova/templates/bin/_nova-compute.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bf434ffd67cc550856d4325bab276d87fb0853a7', 'message': 'Add capability for using FQDN in nova compute\n\nThis patch set adds in a capability for the user to defaultly use a\nFQDN for the nova compute hostname and the hypervisor hostname when\nthe host is not explicitly specified in the .Values.conf override.\n\nChange-Id: I3243068dfe91ebb97b3885002296a0f454822ec5\nCo-authored-by: Drew Walters <andrew.walters@att.com>\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",4,699034,bf434ffd67cc550856d4325bab276d87fb0853a7,45,8,6,20466,,,0,"Add capability for using FQDN in nova compute

This patch set adds in a capability for the user to defaultly use a
FQDN for the nova compute hostname and the hypervisor hostname when
the host is not explicitly specified in the .Values.conf override.

Change-Id: I3243068dfe91ebb97b3885002296a0f454822ec5
Co-authored-by: Drew Walters <andrew.walters@att.com>
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/34/699034/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/component/compute-kit/compute-kit.sh', 'nova/templates/bin/_health-probe.py.tpl', 'nova/templates/bin/_nova-compute-init.sh.tpl', 'nova/values.yaml', 'nova/templates/daemonset-compute.yaml', 'nova/templates/bin/_nova-compute.sh.tpl']",6,9b17b4391574e1b2eea2bd5f768537235b0b9ea0,nova/fqdn,{{- if and ( empty .Values.conf.nova.DEFAULT.host ) ( .Values.pod.useFQDN.compute ) }} --config-file /tmp/pod-shared/nova-compute-fqdn.conf \ {{- end }} --config-file /tmp/pod-shared/nova-hypervisor.conf , --config-file /tmp/pod-shared/nova-hypervisor.conf,36,5
openstack%2Fkeystonemiddleware~master~I89648da5b9e8579d3ef40b840fb81c76596a785a,openstack/keystonemiddleware,master,I89648da5b9e8579d3ef40b840fb81c76596a785a,Update the constraints url,MERGED,2019-09-20 08:53:34.000000000,2020-01-02 19:00:58.000000000,2020-01-02 18:58:57.000000000,"[{'_account_id': 2}, {'_account_id': 8482}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-20 08:53:34.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f1856a0394af7c3301f0561e8ffa9e9cba54cabb', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I89648da5b9e8579d3ef40b840fb81c76596a785a\n'}]",0,683322,f1856a0394af7c3301f0561e8ffa9e9cba54cabb,10,5,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I89648da5b9e8579d3ef40b840fb81c76596a785a
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/22/683322/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f1856a0394af7c3301f0561e8ffa9e9cba54cabb,constraints, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt},1,1
openstack%2Fkeystonemiddleware~master~I1503b5a58c47beae9609dd3edc384b932cdf9445,openstack/keystonemiddleware,master,I1503b5a58c47beae9609dd3edc384b932cdf9445,Switch to Ussuri jobs,MERGED,2019-10-22 03:16:37.000000000,2020-01-02 18:59:42.000000000,2020-01-02 18:57:26.000000000,"[{'_account_id': 2}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-10-22 03:16:37.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/dbddbcc3c050be6e35eaa4e7c8dbf590a8ceb681', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I1503b5a58c47beae9609dd3edc384b932cdf9445\n'}]",0,689914,dbddbcc3c050be6e35eaa4e7c8dbf590a8ceb681,9,4,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: I1503b5a58c47beae9609dd3edc384b932cdf9445
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/14/689914/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,dbddbcc3c050be6e35eaa4e7c8dbf590a8ceb681,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fkeystonemiddleware~master~Ie00fc310728c319faf2cfdfb651f0c7a8f48d757,openstack/keystonemiddleware,master,Ie00fc310728c319faf2cfdfb651f0c7a8f48d757,Remove keystoneclient exception usage in tests,MERGED,2019-11-24 06:14:21.000000000,2020-01-02 18:58:56.000000000,2020-01-02 18:58:56.000000000,"[{'_account_id': 2}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-24 06:14:21.000000000', 'files': ['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d3090bfbc0adffff36b158785a1ecea73349045c', 'message': 'Remove keystoneclient exception usage in tests\n\nThis change replaces the usage of keystoneclient exceptions in the\nauth_token_middleware unit tests to use the ConnectFailure exception\nfrom keystoneauth.\n\nThis is part of the process of removing keystoneclient from\nkeystonemiddleware.\n\nChange-Id: Ie00fc310728c319faf2cfdfb651f0c7a8f48d757\n'}]",0,695809,d3090bfbc0adffff36b158785a1ecea73349045c,7,3,1,21420,,,0,"Remove keystoneclient exception usage in tests

This change replaces the usage of keystoneclient exceptions in the
auth_token_middleware unit tests to use the ConnectFailure exception
from keystoneauth.

This is part of the process of removing keystoneclient from
keystonemiddleware.

Change-Id: Ie00fc310728c319faf2cfdfb651f0c7a8f48d757
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/09/695809/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py'],1,d3090bfbc0adffff36b158785a1ecea73349045c,remove-ksc, raise ksa_exceptions.ConnectFailure(msg) raise ksa_exceptions.ConnectFailure(msg),from keystoneclient import exceptions as ksc_exceptions raise ksc_exceptions.ConnectionRefused(msg) raise ksc_exceptions.ConnectionRefused(msg),2,3
openstack%2Fkeystonemiddleware~master~I28ac26516bacab36578a5a7f6ec7f9dcf7d7eeb1,openstack/keystonemiddleware,master,I28ac26516bacab36578a5a7f6ec7f9dcf7d7eeb1,Fix DeprecationWarning: invalid escape sequence issues,MERGED,2019-11-13 13:17:40.000000000,2020-01-02 18:53:54.000000000,2020-01-02 18:52:32.000000000,"[{'_account_id': 2}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-11-13 13:17:40.000000000', 'files': ['keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4d6e9cb16228e21c551e0d894c45f2a137688cca', 'message': 'Fix DeprecationWarning: invalid escape sequence issues\n\nSome regex strings contain invalid escape sequences for normal strings,\ncausing newer version of Python to emit DeprecationWarning messages.\nThis updates those instances to raw strings so they are not interpreted\nas invalid.\n\nChange-Id: I28ac26516bacab36578a5a7f6ec7f9dcf7d7eeb1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",3,694067,4d6e9cb16228e21c551e0d894c45f2a137688cca,14,6,1,11904,,,0,"Fix DeprecationWarning: invalid escape sequence issues

Some regex strings contain invalid escape sequences for normal strings,
causing newer version of Python to emit DeprecationWarning messages.
This updates those instances to raw strings so they are not interpreted
as invalid.

Change-Id: I28ac26516bacab36578a5a7f6ec7f9dcf7d7eeb1
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/67/694067/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/__init__.py'],1,4d6e9cb16228e21c551e0d894c45f2a137688cca,deprecationwarning, r'(?P<wild>\*(?=$|[^\*]))|' # * r'(?P<rec_wild>\*\*)|' # ** r'(?P<literal>[^{}\*])') # anything else path_regex += r'[^\/]+', '(?P<wild>\*(?=$|[^\*]))|' # * '(?P<rec_wild>\*\*)|' # ** '(?P<literal>[^{}\*])') # anything else path_regex += '[^\/]+',4,4
openstack%2Fnetworking-generic-switch~master~Ia8a473c9e0282c5c83f595db6d37b41b52714b55,openstack/networking-generic-switch,master,Ia8a473c9e0282c5c83f595db6d37b41b52714b55,Allow network name format to be configured,MERGED,2019-09-19 15:31:26.000000000,2020-01-02 18:49:34.000000000,2020-01-02 18:47:55.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-09-19 15:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/c9794a1f6901181f879af9395b1286889d799c6b', 'message': ""Allow network name format to be configured\n\nCurrently, when supported, NGS assigns the network UUID as the name of\nVLANs in device configuration. Some devices, including Dell Force 10,\ndo not support VLAN names starting with a number. On Dell Force 10\ndevices this can result in the following message in neutron DEBUG logs:\n\nForce10-switch(conf-if-vl-3293)#name 555b9c5daccb4e87997fb2b5524cf95e\n    % Error: Vlan name should begin with an alphabetic character.\n\nThis change allows the format of the network name to be configured via\nthe 'ngs_network_name_format' configuration option.\n\nChange-Id: Ia8a473c9e0282c5c83f595db6d37b41b52714b55\nStory: 1737017\nTask: 11728\n""}, {'number': 2, 'created': '2019-09-20 09:59:23.000000000', 'files': ['networking_generic_switch/tests/unit/netmiko/test_arista_eos.py', 'doc/source/configuration.rst', 'networking_generic_switch/devices/netmiko_devices/__init__.py', 'networking_generic_switch/tests/unit/test_devices.py', 'networking_generic_switch/exceptions.py', 'networking_generic_switch/tests/unit/netmiko/test_juniper.py', 'networking_generic_switch/tests/unit/netmiko/test_brocade_fastiron.py', 'releasenotes/notes/network-name-format-075f5757d599ac92.yaml', 'networking_generic_switch/devices/netmiko_devices/juniper.py', 'networking_generic_switch/devices/netmiko_devices/brocade.py', 'networking_generic_switch/tests/unit/netmiko/test_dell.py', 'networking_generic_switch/devices/netmiko_devices/arista.py', 'networking_generic_switch/devices/netmiko_devices/ruijie.py', 'networking_generic_switch/tests/unit/netmiko/test_cisco_ios.py', 'networking_generic_switch/devices/netmiko_devices/cisco.py', 'networking_generic_switch/devices/__init__.py', 'networking_generic_switch/devices/netmiko_devices/dell.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/461def3e0b5a94bf7dbb6c08a263a4379ac9d2cf', 'message': ""Allow network name format to be configured\n\nCurrently, when supported, NGS assigns the network UUID as the name of\nVLANs in device configuration. Some devices, including Dell Force 10,\ndo not support VLAN names starting with a number. On Dell Force 10\ndevices this can result in the following message in neutron DEBUG logs:\n\nForce10-switch(conf-if-vl-3293)#name 555b9c5daccb4e87997fb2b5524cf95e\n    % Error: Vlan name should begin with an alphabetic character.\n\nThis change allows the format of the network name to be configured via\nthe 'ngs_network_name_format' configuration option.\n\nChange-Id: Ia8a473c9e0282c5c83f595db6d37b41b52714b55\nStory: 1737017\nTask: 36731\n""}]",9,683187,461def3e0b5a94bf7dbb6c08a263a4379ac9d2cf,18,5,2,14826,,,0,"Allow network name format to be configured

Currently, when supported, NGS assigns the network UUID as the name of
VLANs in device configuration. Some devices, including Dell Force 10,
do not support VLAN names starting with a number. On Dell Force 10
devices this can result in the following message in neutron DEBUG logs:

Force10-switch(conf-if-vl-3293)#name 555b9c5daccb4e87997fb2b5524cf95e
    % Error: Vlan name should begin with an alphabetic character.

This change allows the format of the network name to be configured via
the 'ngs_network_name_format' configuration option.

Change-Id: Ia8a473c9e0282c5c83f595db6d37b41b52714b55
Story: 1737017
Task: 36731
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/87/683187/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_generic_switch/tests/unit/netmiko/test_arista_eos.py', 'doc/source/configuration.rst', 'networking_generic_switch/devices/netmiko_devices/__init__.py', 'networking_generic_switch/tests/unit/test_devices.py', 'networking_generic_switch/exceptions.py', 'networking_generic_switch/tests/unit/netmiko/test_juniper.py', 'networking_generic_switch/tests/unit/netmiko/test_brocade_fastiron.py', 'releasenotes/notes/network-name-format-075f5757d599ac92.yaml', 'networking_generic_switch/devices/netmiko_devices/juniper.py', 'networking_generic_switch/devices/netmiko_devices/brocade.py', 'networking_generic_switch/tests/unit/netmiko/test_dell.py', 'networking_generic_switch/devices/netmiko_devices/arista.py', 'networking_generic_switch/devices/netmiko_devices/ruijie.py', 'networking_generic_switch/tests/unit/netmiko/test_cisco_ios.py', 'networking_generic_switch/devices/netmiko_devices/cisco.py', 'networking_generic_switch/devices/__init__.py', 'networking_generic_switch/devices/netmiko_devices/dell.py']",17,c9794a1f6901181f879af9395b1286889d799c6b,story/1737017," 'name {network_name}',"," 'name {network_id}',",152,25
openstack%2Fopenstack-ansible-os_nova~stable%2Frocky~Icd1fe43c9fa3ab16f9bdaf0a2cb60854c0e15e97,openstack/openstack-ansible-os_nova,stable/rocky,Icd1fe43c9fa3ab16f9bdaf0a2cb60854c0e15e97,Make nova_novncproxy use BUMPs,MERGED,2019-12-15 10:44:25.000000000,2020-01-02 18:39:07.000000000,2019-12-27 14:40:35.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-12-15 10:44:25.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/844500e174084aff53c3d77f584e715b31e70ea8', 'message': 'Make nova_novncproxy use BUMPs\n\nWe have a lock of VNC version inside repo_packages [1]. We should\ntry using it as otherwise this may result in broken console\n\n[1] https://opendev.org/openstack/openstack-ansible/src/branch/stable/stein/playbooks/defaults/repo_packages/nova_consoles.yml#L33\n\nChange-Id: Icd1fe43c9fa3ab16f9bdaf0a2cb60854c0e15e97\n(cherry picked from commit 1de7b24e701bda75e0fc1d019510f71f16608502)\n'}]",0,699114,844500e174084aff53c3d77f584e715b31e70ea8,10,4,1,28619,,,0,"Make nova_novncproxy use BUMPs

We have a lock of VNC version inside repo_packages [1]. We should
try using it as otherwise this may result in broken console

[1] https://opendev.org/openstack/openstack-ansible/src/branch/stable/stein/playbooks/defaults/repo_packages/nova_consoles.yml#L33

Change-Id: Icd1fe43c9fa3ab16f9bdaf0a2cb60854c0e15e97
(cherry picked from commit 1de7b24e701bda75e0fc1d019510f71f16608502)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/14/699114/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,844500e174084aff53c3d77f584e715b31e70ea8,,"nova_novncproxy_git_repo: ""{{ novncproxy_git_repo | default('https://github.com/novnc/noVNC') }}"" nova_novncproxy_git_install_branch: ""{{ novncproxy_git_install_branch | default('master') }}""",nova_novncproxy_git_repo: https://github.com/novnc/noVNC nova_novncproxy_git_install_branch: master,2,2
openstack%2Fansible-hardening~stable%2Fstein~I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,openstack/ansible-hardening,stable/stein,I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,Fix ignoring of packages in 'latest' state,MERGED,2019-12-27 15:27:27.000000000,2020-01-02 18:20:38.000000000,2020-01-02 18:19:14.000000000,"[{'_account_id': 1004}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 15:27:27.000000000', 'files': ['tasks/rhel7stig/packages.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/66494b8736aea83ed8b8c03db30046e8ae31f425', 'message': ""Fix ignoring of packages in 'latest' state\n\nChange-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae\n(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)\n""}]",0,700703,66494b8736aea83ed8b8c03db30046e8ae31f425,8,3,1,28619,,,0,"Fix ignoring of packages in 'latest' state

Change-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae
(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/03/700703/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/packages.yml'],1,66494b8736aea83ed8b8c03db30046e8ae31f425,fix_packages-stable/stein," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'in', ['present', 'latest']) | map(attribute='state') | unique | list }}"""," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'equalto', 'present') | map(attribute='state') | unique | list }}""",1,1
openstack%2Fansible-hardening~stable%2Ftrain~I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,openstack/ansible-hardening,stable/train,I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,Fix ignoring of packages in 'latest' state,MERGED,2019-12-27 15:24:37.000000000,2020-01-02 18:19:18.000000000,2020-01-02 18:17:58.000000000,"[{'_account_id': 1004}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 15:24:37.000000000', 'files': ['tasks/rhel7stig/packages.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/6a829426f65085248bc6b93add725fcbf71070af', 'message': ""Fix ignoring of packages in 'latest' state\n\nChange-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae\n(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)\n""}]",0,700701,6a829426f65085248bc6b93add725fcbf71070af,8,3,1,28619,,,0,"Fix ignoring of packages in 'latest' state

Change-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae
(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/01/700701/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/packages.yml'],1,6a829426f65085248bc6b93add725fcbf71070af,fix_packages-stable/train," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'in', ['present', 'latest']) | map(attribute='state') | unique | list }}"""," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'equalto', 'present') | map(attribute='state') | unique | list }}""",1,1
openstack%2Fansible-hardening~stable%2Frocky~I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,openstack/ansible-hardening,stable/rocky,I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,Fix ignoring of packages in 'latest' state,MERGED,2019-12-27 15:27:10.000000000,2020-01-02 18:19:15.000000000,2020-01-02 18:19:15.000000000,"[{'_account_id': 1004}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 15:27:10.000000000', 'files': ['tasks/rhel7stig/packages.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/ea2c68945e26cf46e551e45286810362e3e97068', 'message': ""Fix ignoring of packages in 'latest' state\n\nChange-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae\n(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)\n""}]",0,700702,ea2c68945e26cf46e551e45286810362e3e97068,7,3,1,28619,,,0,"Fix ignoring of packages in 'latest' state

Change-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae
(cherry picked from commit 2093f503a64f213f58f9cab97a10a6f915a02ce9)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/02/700702/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/packages.yml'],1,ea2c68945e26cf46e551e45286810362e3e97068,fix_packages-stable/rocky," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'in', ['present', 'latest']) | map(attribute='state') | unique | list }}"""," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'equalto', 'present') | map(attribute='state') | unique | list }}""",1,1
openstack%2Fbifrost~stable%2Ftrain~I09018e451e698a7c6b99106b64c87a526cc959d5,openstack/bifrost,stable/train,I09018e451e698a7c6b99106b64c87a526cc959d5,Switch to IPA-builder for building ironic-python-agent,MERGED,2019-10-30 17:59:10.000000000,2020-01-02 17:47:27.000000000,2019-10-31 14:37:19.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-30 17:59:10.000000000', 'files': ['playbooks/inventory/group_vars/baremetal', 'playbooks/inventory/baremetal.json.example', 'playbooks/inventory/group_vars/localhost', 'playbooks/inventory/group_vars/target', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-create-dib-image/tasks/main.yml', 'doc/source/user/howto.rst', 'doc/source/user/troubleshooting.rst', 'playbooks/inventory/baremetal.yml.example', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'zuul.d/bifrost-jobs.yaml', 'playbooks/roles/ironic-enroll-dynamic/defaults/main.yml', 'releasenotes/notes/ipa-builder-29d3db174048f1b4.yaml', 'playbooks/roles/bifrost-ironic-install/tasks/install.yml', 'playbooks/install.yaml', 'playbooks/roles/bifrost-create-dib-image/defaults/main.yml', 'doc/source/install/offline-install.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1715b538e72d27ddfc70ae78ad3829f9d5bd2141', 'message': 'Switch to IPA-builder for building ironic-python-agent\n\nAlso update the documentation to purge any mentions of CoreOS images\nand the deprecated ironic-agent element.\n\nChange-Id: I09018e451e698a7c6b99106b64c87a526cc959d5\n(cherry picked from commit dc3f7c3f39779558d10d03ba38103261d5d1277a)\n'}]",1,692200,1715b538e72d27ddfc70ae78ad3829f9d5bd2141,8,2,1,10239,,,0,"Switch to IPA-builder for building ironic-python-agent

Also update the documentation to purge any mentions of CoreOS images
and the deprecated ironic-agent element.

Change-Id: I09018e451e698a7c6b99106b64c87a526cc959d5
(cherry picked from commit dc3f7c3f39779558d10d03ba38103261d5d1277a)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/00/692200/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/group_vars/baremetal', 'playbooks/inventory/baremetal.json.example', 'playbooks/inventory/group_vars/localhost', 'playbooks/inventory/group_vars/target', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-create-dib-image/tasks/main.yml', 'doc/source/user/howto.rst', 'doc/source/user/troubleshooting.rst', 'playbooks/inventory/baremetal.yml.example', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'zuul.d/bifrost-jobs.yaml', 'playbooks/roles/ironic-enroll-dynamic/defaults/main.yml', 'releasenotes/notes/ipa-builder-29d3db174048f1b4.yaml', 'playbooks/roles/bifrost-ironic-install/tasks/install.yml', 'playbooks/install.yaml', 'playbooks/roles/bifrost-create-dib-image/defaults/main.yml', 'doc/source/install/offline-install.rst']",18,1715b538e72d27ddfc70ae78ad3829f9d5bd2141,zuulv3-stable/train, ipa_kernel_upstream_url: file:///vagrant/ipa-centos7-master.kernel ipa_ramdisk_upstream_url: file:///vagrant/ipa-centos7-master.initramfs, ipa_kernel_upstream_url: file:///vagrant/coreos_production_pxe.vmlinuz ipa_ramdisk_upstream_url: file:///vagrant/coreos_production_pxe_image-oem.cpio.gz,85,97
openstack%2Ftripleo-ansible~master~I15658fb1b714a37130e8c367956ae993a4cdb697,openstack/tripleo-ansible,master,I15658fb1b714a37130e8c367956ae993a4cdb697,fix a typo in netport.yml,MERGED,2019-12-26 03:20:52.000000000,2020-01-02 17:46:59.000000000,2020-01-02 17:46:59.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27383}]","[{'number': 1, 'created': '2019-12-26 03:20:52.000000000', 'files': ['tripleo_ansible/roles/octavia-controller-config/tasks/netport.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b091fc55d2c62cd401fb266b3b21e940f4497dd0', 'message': 'fix a typo in netport.yml\n\nChange-Id: I15658fb1b714a37130e8c367956ae993a4cdb697\n'}]",0,700581,b091fc55d2c62cd401fb266b3b21e940f4497dd0,11,7,1,27383,,,0,"fix a typo in netport.yml

Change-Id: I15658fb1b714a37130e8c367956ae993a4cdb697
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/81/700581/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/octavia-controller-config/tasks/netport.yml'],1,b091fc55d2c62cd401fb266b3b21e940f4497dd0,,- name: get MTU for management port,- name: get MTU for managment port,1,1
openstack%2Ftempest~master~If6493ec4c849618fdd52a7e725f44537ab33d16a,openstack/tempest,master,If6493ec4c849618fdd52a7e725f44537ab33d16a,Add host validation after live migration,MERGED,2019-12-05 20:44:29.000000000,2020-01-02 17:45:04.000000000,2020-01-02 17:43:22.000000000,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 19118}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 29350}]","[{'number': 1, 'created': '2019-12-05 20:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c2e0073739440a99651b04cd27d8ab13d64099f7', 'message': 'Add host validation after live migration\n\ntest_server_connectivity_live_migration was passing even in case\nlive migration was aborted e.g. like in case documented in [1].\nThis patch adds validation that server actually migrated.\n\n[1] https://bugs.launchpad.net/tripleo/+bug/1852064\n\nChange-Id: If6493ec4c849618fdd52a7e725f44537ab33d16a\n'}, {'number': 2, 'created': '2019-12-08 11:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7833c65127a945f2b3390d7c928af6f5ffaee2dc', 'message': 'Add host validation after live migration\n\ntest_server_connectivity_live_migration was passing even in case\nlive migration was aborted e.g. like in case documented in [1].\nThis patch adds validation that server actually migrated.\n\n[1] https://bugs.launchpad.net/tripleo/+bug/1852064\n\nChange-Id: If6493ec4c849618fdd52a7e725f44537ab33d16a\n'}, {'number': 3, 'created': '2019-12-09 10:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd3f3b65c9c2b17b477aa2c180016c12f6923c5d', 'message': 'Add host validation after live migration\n\ntest_server_connectivity_live_migration was passing even in case\nlive migration was aborted e.g. like in case documented in [1].\nThis patch adds validation that server actually migrated.\n\n[1] https://bugs.launchpad.net/tripleo/+bug/1852064\n\nChange-Id: If6493ec4c849618fdd52a7e725f44537ab33d16a\n'}, {'number': 4, 'created': '2019-12-09 10:23:48.000000000', 'files': ['tempest/scenario/test_network_advanced_server_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/67fc60835561311068fc470e0bffb5519f2f0c7f', 'message': 'Add host validation after live migration\n\ntest_server_connectivity_live_migration was passing even in case\nlive migration was aborted e.g. like in case documented in [1].\nThis patch adds validation that server actually migrated.\n\n[1] https://bugs.launchpad.net/tripleo/+bug/1852064\n\nChange-Id: If6493ec4c849618fdd52a7e725f44537ab33d16a\n'}]",1,697562,67fc60835561311068fc470e0bffb5519f2f0c7f,31,7,4,29350,,,0,"Add host validation after live migration

test_server_connectivity_live_migration was passing even in case
live migration was aborted e.g. like in case documented in [1].
This patch adds validation that server actually migrated.

[1] https://bugs.launchpad.net/tripleo/+bug/1852064

Change-Id: If6493ec4c849618fdd52a7e725f44537ab33d16a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/697562/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_advanced_server_ops.py'],1,c2e0073739440a99651b04cd27d8ab13d64099f7,validate_that_server_migrated,"from oslo_log import logLOG = log.getLogger(__name__) src_host = self.get_host_for_server(server['id']) hosts = ( self.os_admin.hypervisor_client.list_hypervisors()['hypervisors']) dst_host = next( host['hypervisor_hostname'] for host in hosts if host['hypervisor_hostname'] != src_host) self.assertNotEqual(src_host, dst_host) server['id'], host=dst_host, block_migration=block_migration, current_host = self.get_host_for_server(server['id']) LOG.debug(""src_host = {}, dst_host = {}, current_host = {}"".format( src_host, dst_host, current_host)) self.assertEqual(dst_host, current_host) "," server['id'], host=None, block_migration=block_migration,",17,1
openstack%2Fheat~master~I14d64dd57d0e47c5ac3d3ad1e750191493a850e4,openstack/heat,master,I14d64dd57d0e47c5ac3d3ad1e750191493a850e4,Allow load heat test image from mirror,ABANDONED,2020-01-02 02:43:35.000000000,2020-01-02 17:42:20.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-02 02:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/234ac373fc6453b2cc021139a8c61b605b3ebf77', 'message': 'Allow load IMAGE_URL fromm mirror\n\nChange-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4\n'}, {'number': 2, 'created': '2020-01-02 03:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e84d097346619e65bdf6c166253320145cd1fae8', 'message': 'Allow load IMAGE_URL fromm mirror\n\nChange-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4\n'}, {'number': 3, 'created': '2020-01-02 04:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/15023646e86a6b4c30d1e4e198dae9fa0d1d3a0a', 'message': 'Allow load heat test image fromm mirror\n\nChange-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4\n'}, {'number': 4, 'created': '2020-01-02 06:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3dab9bc42644ae61b9944df2b52eb270d292c8c', 'message': 'Allow load heat test image fromm mirror\n\nChange-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4\n'}, {'number': 5, 'created': '2020-01-02 08:08:46.000000000', 'files': ['.zuul.yaml', 'devstack/lib/heat', 'playbooks/devstack/functional/pre-run.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/c4de35943ef3b5166eaa4a52adb8851b71bce3e9', 'message': 'Allow load heat test image from mirror\n\nChange-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4\n'}]",1,700858,c4de35943ef3b5166eaa4a52adb8851b71bce3e9,10,2,5,12404,,,0,"Allow load heat test image from mirror

Change-Id: I14d64dd57d0e47c5ac3d3ad1e750191493a850e4
",git fetch https://review.opendev.org/openstack/heat refs/changes/58/700858/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'playbooks/devstack/functional/pre-run.yaml']",2,234ac373fc6453b2cc021139a8c61b605b3ebf77,story/2007056," localconf=$BASE/new/devstack/local.conf echo ""IMAGE_URLS+=https://download.fedoraproject.org/pub/fedora/linux/releases/29/Cloud/x86_64/images/Fedora-Cloud-Base-29-1.2.x86_64.qcow2"" >> $localconf", export IMAGE_URLS=${NODEPOOL_FEDORA_MIRROR}/releases/29/Cloud/x86_64/images/Fedora-Cloud-Base-29-1.2.x86_64.qcow2,3,2
openstack%2Fopenstack-helm-infra~master~I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01,openstack/openstack-helm-infra,master,I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01,Ingress: k8s and ingress version compatibility,MERGED,2019-12-14 02:07:23.000000000,2020-01-02 16:49:56.000000000,2020-01-02 16:48:23.000000000,"[{'_account_id': 8898}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 28719}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-12-14 02:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/911d6848cbe72fa580f8408f37dca24ac9f88a0f', 'message': 'Ingress: k8s API transition support\n\nUpdates the ClusterRole used by the ingress service account to grant\naccess to Ingress resources via either the extensions/v1beta1 or\nnetworking.k8s.io/v1beta1 API. Does not change the apiVersion used\nwhen creating Ingress resources.\n\nReference:\nhttps://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n\nThe v1.20 release will stop serving the following deprecated\nAPI versions in favor of newer and more stable API versions:\nIngress (in the extensions/v1beta1 API group)\n\nMigrate to use the networking.k8s.io/v1beta1 API, serving Ingress since\nv1.14. Existing persisted data can be retrieved/updated via the\nnetworking.k8s.io/v1beta1 API.\n\nChange-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01\n'}, {'number': 2, 'created': '2019-12-18 03:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ac685530e8ddec46333f8f28b0d47e7094d2d431', 'message': 'Ingress: k8s and ingress version compatibility\n\nk8s 1.14 enabled Ingress on the networking.k8s.io/v1beta1 API, while\nstill serving it via extensions/v1beta1. [0]\n\ningress-nginx 0.25.0 actually uses the networking.k8s.io/v1beta1 API,\nwhich requires updated RBAC rules. [1]\n\nThis change updates the ClusterRole used by the ingress service account\nto grant access to Ingress resources via either the extensions/v1beta1\nor networking.k8s.io/v1beta1 API, aligning with the static manifests\nfrom the kubernetes/ingress-nginx repo [2]. It does not change the\napiVersion used when creating Ingress resources.\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://github.com/kubernetes/ingress-nginx/releases/tag/nginx-0.25.0\n[2] https://github.com/kubernetes/ingress-nginx/blob/870be3bcd88c267f14fd82da82303472f383cd14/deploy/static/mandatory.yaml#L50-L106\n\nChange-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01\n'}, {'number': 3, 'created': '2019-12-18 04:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/056589fc5fe713445ec52f9814b9e72201a47c93', 'message': 'Ingress: k8s and ingress version compatibility\n\nk8s 1.14 first enabled Ingress in the networking.k8s.io/v1beta1 API\ngroup, while still serving it in the extensions/v1beta1 API group. The\nextensions/v1beta1 API endpoint is deprecated in 1.16 and scheduled for\nremoval in 1.20. [0]\n\ningress-nginx 0.25.0 actually uses the networking.k8s.io/v1beta1 API,\nwhich requires updated RBAC rules. [1]\n\nThis change updates the ClusterRole used by the ingress service account\nto grant access to Ingress resources via either the extensions/v1beta1\nor networking.k8s.io/v1beta1 API, aligning with the static manifests\nfrom the kubernetes/ingress-nginx repo [2]. It does not change the\napiVersion used when creating Ingress resources.\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://github.com/kubernetes/ingress-nginx/releases/tag/nginx-0.25.0\n[2] https://github.com/kubernetes/ingress-nginx/blob/870be3bcd88c267f14fd82da82303472f383cd14/deploy/static/mandatory.yaml#L50-L106\n\nChange-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01\n'}, {'number': 4, 'created': '2019-12-20 23:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3060b8892a945e46f9ee73d1ae927d02d6ac5cd6', 'message': 'Ingress: k8s and ingress version compatibility\n\nk8s 1.14 first enabled Ingress in the networking.k8s.io/v1beta1 API\ngroup, while still serving it in the extensions/v1beta1 API group. The\nextensions/v1beta1 API endpoint is deprecated in 1.16 and scheduled for\nremoval in 1.20. [0]\n\ningress-nginx 0.25.0 actually uses the networking.k8s.io/v1beta1 API,\nwhich requires updated RBAC rules. [1]\n\nThis change updates the ClusterRole used by the ingress service account\nto grant access to Ingress resources via either the extensions/v1beta1\nor networking.k8s.io/v1beta1 API, aligning with the static manifests\nfrom the kubernetes/ingress-nginx repo [2]. It does not change the\napiVersion used when creating Ingress resources.\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://github.com/kubernetes/ingress-nginx/releases/tag/nginx-0.25.0\n[2] https://github.com/kubernetes/ingress-nginx/blob/870be3bcd88c267f14fd82da82303472f383cd14/deploy/static/mandatory.yaml#L50-L106\n\nChange-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01\n'}, {'number': 5, 'created': '2020-01-01 21:35:19.000000000', 'files': ['ingress/templates/deployment-ingress.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bcecbad65232713d1b5199891f2224e2c8711eb7', 'message': 'Ingress: k8s and ingress version compatibility\n\nk8s 1.14 first enabled Ingress in the networking.k8s.io/v1beta1 API\ngroup, while still serving it in the extensions/v1beta1 API group. The\nextensions/v1beta1 API endpoint is deprecated in 1.16 and scheduled for\nremoval in 1.20. [0]\n\ningress-nginx 0.25.0 actually uses the networking.k8s.io/v1beta1 API,\nwhich requires updated RBAC rules. [1]\n\nThis change updates the ClusterRole used by the ingress service account\nto grant access to Ingress resources via either the extensions/v1beta1\nor networking.k8s.io/v1beta1 API, aligning with the static manifests\nfrom the kubernetes/ingress-nginx repo [2]. It does not change the\napiVersion used when creating Ingress resources.\n\n[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\n[1] https://github.com/kubernetes/ingress-nginx/releases/tag/nginx-0.25.0\n[2] https://github.com/kubernetes/ingress-nginx/blob/870be3bcd88c267f14fd82da82303472f383cd14/deploy/static/mandatory.yaml#L50-L106\n\nChange-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01\n'}]",1,699056,bcecbad65232713d1b5199891f2224e2c8711eb7,21,7,5,28719,,,0,"Ingress: k8s and ingress version compatibility

k8s 1.14 first enabled Ingress in the networking.k8s.io/v1beta1 API
group, while still serving it in the extensions/v1beta1 API group. The
extensions/v1beta1 API endpoint is deprecated in 1.16 and scheduled for
removal in 1.20. [0]

ingress-nginx 0.25.0 actually uses the networking.k8s.io/v1beta1 API,
which requires updated RBAC rules. [1]

This change updates the ClusterRole used by the ingress service account
to grant access to Ingress resources via either the extensions/v1beta1
or networking.k8s.io/v1beta1 API, aligning with the static manifests
from the kubernetes/ingress-nginx repo [2]. It does not change the
apiVersion used when creating Ingress resources.

[0] https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/
[1] https://github.com/kubernetes/ingress-nginx/releases/tag/nginx-0.25.0
[2] https://github.com/kubernetes/ingress-nginx/blob/870be3bcd88c267f14fd82da82303472f383cd14/deploy/static/mandatory.yaml#L50-L106

Change-Id: I67d4dbdb3834ca4ac8ce90ec51c8d6414ce80a01
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/56/699056/4 && git format-patch -1 --stdout FETCH_HEAD,['ingress/templates/deployment-ingress.yaml'],1,911d6848cbe72fa580f8408f37dca24ac9f88a0f,," - ""networking.k8s.io""",,1,0
openstack%2Fironic~master~Ifd97eeebc95845a32c2d3ece513c25fdb52812d3,openstack/ironic,master,Ifd97eeebc95845a32c2d3ece513c25fdb52812d3,redfish-vmedia: correctly pass ipa-debug,MERGED,2019-12-04 10:29:02.000000000,2020-01-02 16:48:33.000000000,2019-12-13 22:30:47.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 26340}]","[{'number': 1, 'created': '2019-12-04 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0188547e0e369cc68dd1b834bd1e3812a7ee12c2', 'message': 'redfish-vmedia: correctly pass ipa-debug\n\nThe PXE/iPXE boot interfaces pass ipa-debug=1 when debugging is\nenabled in ironic. The vmedia boot interface should do the same.\n\nChange-Id: Ifd97eeebc95845a32c2d3ece513c25fdb52812d3\n'}, {'number': 2, 'created': '2019-12-04 14:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/28622ec4fbc2ec97a1511e2c9a51d225a480ed74', 'message': 'redfish-vmedia: correctly pass ipa-debug\n\nThe PXE/iPXE boot interfaces pass ipa-debug=1 when debugging is\nenabled in ironic. The vmedia boot interface should do the same.\n\nChange-Id: Ifd97eeebc95845a32c2d3ece513c25fdb52812d3\n'}, {'number': 3, 'created': '2019-12-13 00:32:11.000000000', 'files': ['ironic/tests/unit/drivers/modules/redfish/test_boot.py', 'ironic/drivers/modules/redfish/boot.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2e33669b4157cb3e55cd775f950981f059db7394', 'message': 'redfish-vmedia: correctly pass ipa-debug\n\nThe PXE/iPXE boot interfaces pass ipa-debug=1 when debugging is\nenabled in ironic. The vmedia boot interface should do the same.\n\nChange-Id: Ifd97eeebc95845a32c2d3ece513c25fdb52812d3\n'}]",0,697258,2e33669b4157cb3e55cd775f950981f059db7394,48,9,3,10239,,,0,"redfish-vmedia: correctly pass ipa-debug

The PXE/iPXE boot interfaces pass ipa-debug=1 when debugging is
enabled in ironic. The vmedia boot interface should do the same.

Change-Id: Ifd97eeebc95845a32c2d3ece513c25fdb52812d3
",git fetch https://review.opendev.org/openstack/ironic refs/changes/58/697258/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/redfish/test_boot.py', 'ironic/drivers/modules/redfish/boot.py']",2,0188547e0e369cc68dd1b834bd1e3812a7ee12c2,story/1528920, if CONF.debug and 'ipa-debug' not in ramdisk_params: ramdisk_params['ipa-debug'] = '1',,49,0
openstack%2Fbifrost~master~I6b0f63df248cfd55f14b284e3fa35db8d194f364,openstack/bifrost,master,I6b0f63df248cfd55f14b284e3fa35db8d194f364,DNM: testing ci,NEW,2019-09-20 20:58:28.000000000,2020-01-02 16:47:34.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-20 20:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/df58b7b7c8a1490745431f0ad78f62bc0524467c', 'message': 'DNM: testing ci\n\nChange-Id: I6b0f63df248cfd55f14b284e3fa35db8d194f364\n'}, {'number': 2, 'created': '2020-01-02 16:25:55.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/01df9f628982050f2df24ebe3737f0b7ef7aa504', 'message': 'DNM: testing ci\n\nChange-Id: I6b0f63df248cfd55f14b284e3fa35db8d194f364\n'}]",0,683729,01df9f628982050f2df24ebe3737f0b7ef7aa504,4,1,2,11655,,,0,"DNM: testing ci

Change-Id: I6b0f63df248cfd55f14b284e3fa35db8d194f364
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/29/683729/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-ironic-install/defaults/main.yml'],1,df58b7b7c8a1490745431f0ad78f62bc0524467c,,"ironic_inspector_api_url: ""http://localhost:5050/""","ironic_inspector_api_url: ""http://localhost:5050""",1,1
openstack%2Fpuppet-openstack-integration~stable%2Ftrain~I98fc088cd87c1412544f9590ce7a925b413297e2,openstack/puppet-openstack-integration,stable/train,I98fc088cd87c1412544f9590ce7a925b413297e2,Add CentOS8 support and jobs,MERGED,2019-12-16 13:05:04.000000000,2020-01-02 16:34:04.000000000,2020-01-02 16:34:04.000000000,"[{'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-16 13:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/09c27bf14047a73ef707a75d5098c3f1d38a0fd5', 'message': '[DNM] Test CentOS8\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit c7f2a048be27c230b6def6af8b01d51cb6738622)\n'}, {'number': 2, 'created': '2019-12-16 14:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/026de0dd580e9ba386b5d670d8d5422dcaa971eb', 'message': '[DNM] Test CentOS8\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit c7f2a048be27c230b6def6af8b01d51cb6738622)\n'}, {'number': 3, 'created': '2019-12-19 07:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/533c139c4f2e371a36c7d7a18370c4ab92942549', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 4, 'created': '2019-12-19 08:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/2b573bba2a7db9a1f202c7251f9664a010ecb171', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 5, 'created': '2019-12-20 05:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/f0eddde6492f2b1606bf18d97bfac018ed91c62f', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 6, 'created': '2019-12-20 07:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/50a30a3c32fd8647512f4793731e54e866782721', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 7, 'created': '2019-12-20 07:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b2ed95be340e390acbf60453b354ec77e9c96eb9', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 8, 'created': '2019-12-30 14:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/efade8f369c1b1175e06a96f1aa386e299366729', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql\n  needs to be different, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}, {'number': 9, 'created': '2019-12-30 14:09:23.000000000', 'files': ['manifests/neutron.pp', 'Puppetfile_centos8', 'fixtures/scenario001.pp', 'functions', 'fixtures/scenario003.pp', 'configure_facts.sh', 'fixtures/scenario004.pp', 'zuul.d/integration.yaml', 'manifests/mysql.pp', 'manifests/rabbitmq.pp', 'manifests/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/99a135bfdf59a3222c84512e34f7466cb11e7f1b', 'message': ""Add CentOS8 support and jobs\n\n- scenario001 and 004 will be running without ceph\n  until ceph repos get available for CentOS8\n- scenario003 will run not run with linuxbridge until next CentOS\n  minor version as it has issues:-\n    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637\n- Add Puppetfile_centos8 to have different puppet modules\n  as compared to other distros. Currently only puppet-mysql and\n  puppet-rabbitmq needs to be different due to older versions of\n  mariadb and rabbitmq-server, but it's done keeping in mind in future\n  we may need to use different versions for other modules.\n- check for rdo_dlrn url existence only for RedHat distros.\n\nChange-Id: I98fc088cd87c1412544f9590ce7a925b413297e2\n(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)\n""}]",0,699204,99a135bfdf59a3222c84512e34f7466cb11e7f1b,26,4,9,13861,,,0,"Add CentOS8 support and jobs

- scenario001 and 004 will be running without ceph
  until ceph repos get available for CentOS8
- scenario003 will run not run with linuxbridge until next CentOS
  minor version as it has issues:-
    - https://bugzilla.redhat.com/show_bug.cgi?id=1720637
- Add Puppetfile_centos8 to have different puppet modules
  as compared to other distros. Currently only puppet-mysql and
  puppet-rabbitmq needs to be different due to older versions of
  mariadb and rabbitmq-server, but it's done keeping in mind in future
  we may need to use different versions for other modules.
- check for rdo_dlrn url existence only for RedHat distros.

Change-Id: I98fc088cd87c1412544f9590ce7a925b413297e2
(cherry picked from commit 5387d04e28f60403e36fa723c9bb2679932b39ef)
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/04/699204/2 && git format-patch -1 --stdout FETCH_HEAD,"['fixtures/scenario001.pp', 'functions', 'fixtures/scenario003.pp', 'manifests/rabbitmq.pp', 'manifests/config.pp', 'manifests/neutron.pp', 'run_tests.sh', 'Puppetfile', 'fixtures/scenario004.pp', 'zuul.d/integration.yaml', 'manifests/mysql.pp', 'zuul.d/layout.yaml']",12,09c27bf14047a73ef707a75d5098c3f1d38a0fd5,rdo-centos8, - puppet-openstack-integration-5-scenario001-tempest-centos-8-luminous - puppet-openstack-integration-5-scenario002-tempest-centos-8 - puppet-openstack-integration-5-scenario003-tempest-centos-8 - puppet-openstack-integration-5-scenario004-tempest-centos-8-nautilus, - puppet-openstack-integration-5-scenario001-tempest-centos-7-luminous - puppet-openstack-integration-5-scenario002-tempest-centos-7 - puppet-openstack-integration-5-scenario003-tempest-centos-7 - puppet-openstack-integration-5-scenario004-tempest-centos-7-nautilus - puppet-openstack-integration-5-scenario001-tempest-ubuntu-bionic-mimic - puppet-openstack-integration-5-scenario002-tempest-ubuntu-bionic - puppet-openstack-integration-5-scenario003-tempest-ubuntu-bionic - puppet-openstack-integration-5-scenario004-tempest-ubuntu-bionic-mimic,77,25
openstack%2Fopenstack-helm~master~I9faab36a114e28fe8f4c312e7cd64a582333033b,openstack/openstack-helm,master,I9faab36a114e28fe8f4c312e7cd64a582333033b,Update proxy documentation for AIO,MERGED,2019-12-12 19:33:42.000000000,2020-01-02 16:21:58.000000000,2020-01-02 16:19:56.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-12 19:33:42.000000000', 'files': ['doc/source/install/common-requirements.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/13b0a3ffd98df277f4aaa300b2b770ab0869b487', 'message': 'Update proxy documentation for AIO\n\nThis change adds in information about overriding the dns entries\nthat can end up overwriting the existing ones in resolv.conf\nand resulting in a lack of network connectivity when deploying\nAIO behind a proxy.\n\nChange-Id: I9faab36a114e28fe8f4c312e7cd64a582333033b\n'}]",0,698792,13b0a3ffd98df277f4aaa300b2b770ab0869b487,8,3,1,21420,,,0,"Update proxy documentation for AIO

This change adds in information about overriding the dns entries
that can end up overwriting the existing ones in resolv.conf
and resulting in a lack of network connectivity when deploying
AIO behind a proxy.

Change-Id: I9faab36a114e28fe8f4c312e7cd64a582333033b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/92/698792/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/common-requirements.rst'],1,13b0a3ffd98df277f4aaa300b2b770ab0869b487,proxy-guide-update,"By default, this installation will use Google DNS Server IPs (8.8.8.8, 8.8.4.4) and will update resolv.conf as a result. If those IPs are blocked by the proxy, this will overwrite the original DNS entries and result in the inability to connect to anything on the network behind the proxy. These DNS nameserver entries can be changed by updating the ``external_dns_nameservers`` entry in this file: .. code-block:: bash openstack-helm-infra/tools/images/kubeadm-aio/assets/opt/playbooks/vars.yaml It is recommended to add your own existing DNS nameserver entries to avoid losing connection.",,12,0
openstack%2Fkolla-ansible~master~If485d1741196bf3e60bf73711fa1e8491b4ad2e3,openstack/kolla-ansible,master,If485d1741196bf3e60bf73711fa1e8491b4ad2e3,DNM: CentOS IPv6 (single-node),ABANDONED,2019-12-26 11:51:04.000000000,2020-01-02 16:19:28.000000000,,"[{'_account_id': 7488}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-26 11:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d3a3c5e4f6f1943cd184499795d72508b02b0979', 'message': 'DNM: CentOS IPv6 (single-node)\n\nDepends-on: https://review.opendev.org/699172\nChange-Id: If485d1741196bf3e60bf73711fa1e8491b4ad2e3\n'}, {'number': 2, 'created': '2019-12-26 14:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9f76fc89bb7cff3c07984f179453f1021d76499f', 'message': 'DNM: CentOS IPv6 (single-node)\n\nDepends-on: https://review.opendev.org/699172\nChange-Id: If485d1741196bf3e60bf73711fa1e8491b4ad2e3\n'}, {'number': 3, 'created': '2019-12-26 15:00:35.000000000', 'files': ['tests/run.yml', 'zuul.d/project.yaml', 'tests/test-dashboard.sh', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b9268f1e8327ac5b7989d321cd2ab2bea4905926', 'message': 'DNM: CentOS IPv6 (single-node)\n\nDepends-on: https://review.opendev.org/699172\nChange-Id: If485d1741196bf3e60bf73711fa1e8491b4ad2e3\n'}]",0,700618,b9268f1e8327ac5b7989d321cd2ab2bea4905926,11,3,3,30491,,,0,"DNM: CentOS IPv6 (single-node)

Depends-on: https://review.opendev.org/699172
Change-Id: If485d1741196bf3e60bf73711fa1e8491b4ad2e3
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/18/700618/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,d3a3c5e4f6f1943cd184499795d72508b02b0979,dnm-centos-ipv6-singlenode, name: kolla-ansible-centos-source-ipv6 parent: kolla-ansible-ipv6-base nodeset: kolla-ansible-centos vars: base_distro: centos install_type: source - job:,,9,94
openstack%2Fkolla-ansible~stable%2Ftrain~I466e4473fed0a150e5babafbb0d6e9f89e735e01,openstack/kolla-ansible,stable/train,I466e4473fed0a150e5babafbb0d6e9f89e735e01,DNM: CI: Test Swift upgrade,ABANDONED,2019-12-21 09:48:14.000000000,2020-01-02 16:18:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-21 09:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/672d2f308b4398eb9e781ee0b8b19193d0bedfa1', 'message': 'DNM: CI: Test Swift upgrade\n\nChange-Id: I466e4473fed0a150e5babafbb0d6e9f89e735e01\n'}, {'number': 2, 'created': '2019-12-21 09:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1befc3c9a1bfe5035d17650905d685ffd7a504ad', 'message': 'DNM: CI: Test Swift upgrade\n\nChange-Id: I466e4473fed0a150e5babafbb0d6e9f89e735e01\n'}, {'number': 3, 'created': '2019-12-21 09:52:27.000000000', 'files': ['tests/run.yml', 'zuul.d/base.yaml', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b70a1d53bc876946ed7235b0b561bb3d2434d131', 'message': 'DNM: CI: Test Swift upgrade\n\nChange-Id: I466e4473fed0a150e5babafbb0d6e9f89e735e01\n'}]",0,700268,b70a1d53bc876946ed7235b0b561bb3d2434d131,6,2,3,30491,,,0,"DNM: CI: Test Swift upgrade

Change-Id: I466e4473fed0a150e5babafbb0d6e9f89e735e01
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/68/700268/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base.yaml', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml']",3,672d2f308b4398eb9e781ee0b8b19193d0bedfa1,kolla-deployment-scenario-testing, name: kolla-ansible-centos-source-upgrade-swift parent: kolla-ansible-centos-source-swift timeout: 9000 vars: is_upgrade: yes - job: name: kolla-ansible-ubuntu-source-upgrade-swift parent: kolla-ansible-ubuntu-source-swift timeout: 9000 vars: is_upgrade: yes - job:,,17,1
openstack%2Fopenstack-helm~master~I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa,openstack/openstack-helm,master,I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa,WIP - Change /etc/keystone dir permissions to 400,ABANDONED,2019-11-13 20:58:37.000000000,2020-01-02 15:34:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-11-13 20:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d48610fa6b41cbab4b0eb4c052191691e5e2e49e', 'message': 'WIP - Change /etc/keystone dir permissions to 400\n\nThis change introduces an init-container to change the permissions\nof the keystone config directory to 400 to remove the world-readable\nflag from any existing files.\n\nChange-Id: I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa\n'}, {'number': 2, 'created': '2019-12-02 00:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1a72e2bb0da1626c95e774557ff77e1104d057bd', 'message': 'WIP - Change /etc/keystone dir permissions to 400\n\nThis change introduces an init-container to change the permissions\nof the keystone config directory to 400 to remove the world-readable\nflag from any existing files.\n\nChange-Id: I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa\n'}, {'number': 3, 'created': '2019-12-02 18:57:28.000000000', 'files': ['keystone/templates/deployment-api.yaml', 'keystone/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/16a7e162b7c3405ab5c906f6e7e4a9b398956707', 'message': 'WIP - Change /etc/keystone dir permissions to 400\n\nThis change introduces an init-container to change the permissions\nof the keystone config directory to 400 to remove the world-readable\nflag from any existing files.\n\nChange-Id: I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa\n'}]",0,694166,16a7e162b7c3405ab5c906f6e7e4a9b398956707,7,1,3,21420,,,0,"WIP - Change /etc/keystone dir permissions to 400

This change introduces an init-container to change the permissions
of the keystone config directory to 400 to remove the world-readable
flag from any existing files.

Change-Id: I94c6dff1a89bd158e6aa7282c2ef0d9927ffd3aa
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/66/694166/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/templates/deployment-api.yaml', 'keystone/values.yaml']",2,d48610fa6b41cbab4b0eb4c052191691e5e2e49e,keystone-perms, keystone_perms: readOnlyRootFilesystem: true runAsUser: 0,,22,0
openstack%2Fnetworking-generic-switch~master~I8265a57695739585760047c15eedae833c7c3653,openstack/networking-generic-switch,master,I8265a57695739585760047c15eedae833c7c3653,Enforce running tox with correct python version based on env,MERGED,2019-12-23 10:26:40.000000000,2020-01-02 15:12:55.000000000,2020-01-02 15:11:19.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 10:26:40.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/87061f1f8439f2baa33effe0cc17a712b149de97', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I8265a57695739585760047c15eedae833c7c3653\n'}]",0,700413,87061f1f8439f2baa33effe0cc17a712b149de97,8,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I8265a57695739585760047c15eedae833c7c3653
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/13/700413/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,87061f1f8439f2baa33effe0cc17a712b149de97,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fkeystone-specs~master~I97f7a34d398ba673d7733fb2aaa490ebc9298afd,openstack/keystone-specs,master,I97f7a34d398ba673d7733fb2aaa490ebc9298afd,OpenID Connect improved support,MERGED,2016-09-21 09:58:56.000000000,2020-01-02 15:09:50.000000000,2020-01-02 15:08:26.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 7191}, {'_account_id': 8119}, {'_account_id': 8482}, {'_account_id': 8978}, {'_account_id': 16465}, {'_account_id': 17860}, {'_account_id': 18338}, {'_account_id': 22348}]","[{'number': 1, 'created': '2016-09-21 09:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/37aa0a70182dddd6bc07a1fda245847f5166bff7', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools.  This blueprint aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: oidc-improved-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}, {'number': 2, 'created': '2016-09-21 10:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/56a30228199d4e8cf4f2f0508c51c4d8ead3dca2', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools.  This blueprint aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: oidc-improved-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}, {'number': 3, 'created': '2016-09-21 10:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/74ba5fa35226955dd6c5b1d28e686a6fe9c2f320', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools.  This blueprint aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: improved-oidc-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}, {'number': 4, 'created': '2016-10-17 14:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/8214762e59ddf226ce906fa6d8d09d0db8036435', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools. This spec aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: improved-oidc-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}, {'number': 5, 'created': '2018-03-15 16:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e61b28821f79d46258a23c72f01addea3b45dfae', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools. This spec aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: improved-oidc-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}, {'number': 6, 'created': '2018-03-16 10:27:00.000000000', 'files': ['specs/keystone/backlog/oidc-improved-support.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/1d246348112cc890db5d0d6fe8d091161e05d831', 'message': 'OpenID Connect improved support\n\nOpenID Connect is supported in Keystone by leveraging the Apache\nmod_auth_oidc module and the Keystone Federation plugin. OpenID Connect\nworks fine when accessing OpenStack thorugh the dashboard, but it\nrequires additional configuration steps to make it work when using the\nOpenStack CLI tools. This spec aims at improving the support, so\nthat the same outcome is obtained, regardless of the way the user\naccesses the cloud.\n\nImplements blueprint: improved-oidc-support\n\nChange-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd\n'}]",42,373983,1d246348112cc890db5d0d6fe8d091161e05d831,27,12,6,91,,,0,"OpenID Connect improved support

OpenID Connect is supported in Keystone by leveraging the Apache
mod_auth_oidc module and the Keystone Federation plugin. OpenID Connect
works fine when accessing OpenStack thorugh the dashboard, but it
requires additional configuration steps to make it work when using the
OpenStack CLI tools. This spec aims at improving the support, so
that the same outcome is obtained, regardless of the way the user
accesses the cloud.

Implements blueprint: improved-oidc-support

Change-Id: I97f7a34d398ba673d7733fb2aaa490ebc9298afd
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/83/373983/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/keystone/ocata/oidc-improved-support.rst'],1,37aa0a70182dddd6bc07a1fda245847f5166bff7,bp/improved-oidc-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Improved OpenID Connect Support =============================== `bp improved-oidc-support <https://blueprints.launchpad.net/keystone/+spec/improved-oidc-support>`_ OpenID Connect is supported in Keystone by leveraging the Apache module ``mod_auth_oidc`` module and the Keystone Federation plugin. OpenID Connect works fine when accessing OpenStack thorugh the dashboard, but it requires additional configuration steps to make it work when using the OpenStack CLI tools. This blueprint aims at improving the support, so that the same outcome is obtained, regardless of the way the user accesses the cloud. Problem Description =================== Currently OpenID Connect Provider (OP) as an external Identity Provider (IdP) is supported by using: * Apache + mod_auth_oidc configured as an OpenID Connect Relying Party (RP). * Keystone with the Federation drivers enabled, using the ``keystone.auth.plugins.mapped.Mapped`` auth plugin. According to OpenID Connect specification, the Relying Party should be the OpenID client application that will contact the OP in order to get the access/id tokens and eventually the additional user info from the corresponding endpoint. In the dashboard case mentioned above, the OpenID RP is the Apache server, therefore Apache is configured with the OpenID Connect client id and secret that will be used for any of the OP grant types supported. Therefore, the Keystone administrator would register an OpenID Client in the OP, and add its client id/secret to the ``mod_auth_openidc`` configuration. In this case, since everything is handled within Apache and ``mod_auth_openidc``, Keystone receives the access_token, id_token and all the additional grants obtained from the userinfo endpoint in the HTTPD environment variables. The user does not need to do anything with the OP, apart from the usual confirmation that she is autenticating against the RP. However, we the OpenStack CLIs are being used the RP is not the Apache server, but the CLI (actually, keystoneauth1). In this case, the user has to feed the client id and secret to the libraty, therefore the user has to go to the OP and create a new OpenID Connect client, fetch the discovery document endpoint, client id and client secret and pass all to the library. Then through keystoneauth performingas the authentication flow using the requrested grant type against the OP, eventually obtaining an access_token. This access_token is then exchanged with an ``oauth20`` protected url, that needs to be configured to do token introspection against the RP, as in this `configuration guide`_. Since this endpoint is an OAuth 2.0 endpoint it is not able to fetch any additional claims from the userinfo endpoint, as this is something specific to OpenID Connect. .. _configuiration guide: https://developer.ibm.com/opentech/2015/06/17/use-websphere-liberty-as-an-openid-connect-provider-for-openstack Therefore, the Keystone server does not have any additional claims obtained from the userinfo endpoint apart from the ones that are already present in the token, so it is not possible to create any mapping based on this (for example group membership, email address, and so on). The tokens may include additional claims, but this is not mandatory in the standard, being dependant on the OP implementation. For example, Google's OAuth 2.0 introspection endpoint return these additional claims. Following the OpenID Connect terminology, the RP should be Keystone, and not the user client. If so, when a user wants to authenticate with OpenID Connect as an IdP the client should contact the federation URL that should be protected with OpenID Connect. Then the authentication flow should be the same as in the horizon+websso case, all handled by mod_auth_openidc and the Keystone app will get all the OpenID Connect claims (i.e from the id token and userinfo). This way keystoneauth should not implement any openid logic apart from maybe intercepting the redirect request to the login endpoint and popping out a browser (as in [2]). [2] https://review.openstack.org/#/c/330006/ However, there are several disadvantages in doing this: * Only one grant type can be configured per provider, therefore if a grant type of authz code is configured in the Keystone server (the RP) the user won't be able to use the client credentials grant, even if the OP allows to do so. * All the code in keystoneauth regarding OpenID connect (that has been released) becomes useless and should be deprecated, as it should not handle any oidc grant type anymore. * The interception of the redirection could be more complicated. But it has a big advantage: * The user does not need to create and manage OpenID Clients in the OP (thus it is not needed to handle the client id, secrets, etc.). Nevertheless, CLI users may be expecting a similar experience to the one obtained in other cloud providers (like Google Cloud Engine) where the behaviour is like the one we have in place right now (i.e. the user needs to create and OpenID Connect client and user the obtained client id and secret). However, if we continue with this design, we can leave everything as it is right now, but we need a specific OpenID Connect plugin in Keystone that is able to fetch the additional claims from the userinfo endpoint when it only receives an id token. This way Keystone will get all these additional claims and the mapping set by the administrator can be based on them. If we do so, operators should configure this plugin, instead of the current mapped plugin (``keystone.auth.plugins.mapped.Mapped``). Proposed Change =============== The proposed change is to implement a specific OpenID Connect plugin, that will be a subclass of the ``keystone.auth.plugins.mapped.Mapped`` plugin. When this plugin is used, it will: 1. Contact the OpenID Discovery Endpoint (based on the token issuer URL) to fetch the discovery document and obtain the userinfo endpoint. 2. Contact the userinfo endpoint, exchanging the user id token to get the additional claims. Afterwards the plugin will continue as the vanilla mapped plugin, but the additional claims will be present. The discovery document is defined in the `OpenID Connect Dicovery specification https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig` Alternatives ------------ The other alternative would be that all the OpenID Connect flow is done by the Apache server where Keystone is running. The advantages and disadvantages of this are described in the ""Problem Description"" section. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None, with the proposed solution. Performance Impact ------------------ Additional calls need to be made to the external endpoints, that may introduce a delay when responding to the user. Other Deployer Impact --------------------- None. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: * Alvaro Lopez (aloga) Other contributors: * None Work Items ---------- 1. Create an additional mapped plugin, implementing the described logic. 2. Implement missing OpenID Connect grant types in the client. Dependencies ============ None. Documentation Impact ==================== None. References ========== * `OpenID Connect Specifications https://openid.net/developers/specs/` * `OAuth 2.0 specification https://tools.ietf.org/html/rfc6749` * `Using Google OAuth 2.0 https://developers.google.com/identity/protocols/OAuth2` * `Using Google OpenID Connect https://developers.google.com/identity/protocols/OpenIDConnect` * `Using the Python client for GCE https://cloud.google.com/compute/docs/tutorials/python-guide` ",,207,0
openstack%2Ftripleo-ansible~master~Icdc5caf4cedc46291a807c39c0a31c74955a4a74,openstack/tripleo-ansible,master,Icdc5caf4cedc46291a807c39c0a31c74955a4a74,Add SyslogIdenfier to healthcheck systemd unit,MERGED,2019-12-16 14:30:02.000000000,2020-01-02 15:08:53.000000000,2020-01-02 15:08:52.000000000,"[{'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 5241}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-16 14:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6de47f24086eca09f8a0767360f0168a98e99ab3', 'message': ""Add SyslogIdenfier to healthcheck systemd unit\n\nAdding this new field will allow to filter all healthcheck logs using\nthe Idenfier value.\n\nFor instance, using journalctl, you would be able to run this:\n`journalctl -t container-healthcheck'\n\nIt will also allow to get a dedicated file out of (r)syslog if needed.\n\nChange-Id: Icdc5caf4cedc46291a807c39c0a31c74955a4a74\nCloses-Bug: #1856573\n""}, {'number': 2, 'created': '2019-12-17 15:10:20.000000000', 'files': ['tripleo_ansible/roles/tripleo-container-manage/templates/systemd-healthcheck.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/49858c5265310c8cdd1694ae389965370fd97abb', 'message': ""Add SyslogIdenfier to healthcheck systemd unit\n\nAdding this new field will allow to filter all healthcheck logs using\nthe Idenfier value.\n\nFor instance, using journalctl, you would be able to run this:\n`journalctl -t healthcheck_collectd'\n\nIt will also allow to get a dedicated file out of (r)syslog if needed.\n\nChange-Id: Icdc5caf4cedc46291a807c39c0a31c74955a4a74\nCloses-Bug: #1856573\n""}]",0,699215,49858c5265310c8cdd1694ae389965370fd97abb,13,8,2,28223,,,0,"Add SyslogIdenfier to healthcheck systemd unit

Adding this new field will allow to filter all healthcheck logs using
the Idenfier value.

For instance, using journalctl, you would be able to run this:
`journalctl -t healthcheck_collectd'

It will also allow to get a dedicated file out of (r)syslog if needed.

Change-Id: Icdc5caf4cedc46291a807c39c0a31c74955a4a74
Closes-Bug: #1856573
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/15/699215/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-container-manage/templates/systemd-healthcheck.j2'],1,6de47f24086eca09f8a0767360f0168a98e99ab3,healthcheck/SyslogIdentifier,SyslogIdentifier=container-healthcheck,,1,0
openstack%2Freleases~master~If9b60bbad1168517fcc1fa81712357b4f8e58aa5,openstack/releases,master,If9b60bbad1168517fcc1fa81712357b4f8e58aa5,Release cinderlib 1.0.1,MERGED,2019-12-19 18:54:51.000000000,2020-01-02 14:44:15.000000000,2020-01-02 14:44:15.000000000,"[{'_account_id': 9535}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-19 18:54:51.000000000', 'files': ['deliverables/train/cinderlib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ef19d33a034a5ddb2f160e232fc5839185c3d078', 'message': 'Release cinderlib 1.0.1\n\nRelease from stable/train\n\nChange-Id: If9b60bbad1168517fcc1fa81712357b4f8e58aa5\n'}]",0,700053,ef19d33a034a5ddb2f160e232fc5839185c3d078,9,3,1,5314,,,0,"Release cinderlib 1.0.1

Release from stable/train

Change-Id: If9b60bbad1168517fcc1fa81712357b4f8e58aa5
",git fetch https://review.opendev.org/openstack/releases refs/changes/53/700053/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/cinderlib.yaml'],1,ef19d33a034a5ddb2f160e232fc5839185c3d078,cinderproject-dec-2019, - version: 1.0.1 projects: - repo: openstack/cinderlib hash: 199ebd4f5a1984573877f582a2655f4171916761,,4,0
openstack%2Fglance-specs~master~I283dfdefbdf6604365fb3fb0209e8deba2c18eae,openstack/glance-specs,master,I283dfdefbdf6604365fb3fb0209e8deba2c18eae,Delete image from single store,MERGED,2019-12-09 14:18:09.000000000,2020-01-02 14:39:06.000000000,2020-01-02 14:36:32.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-09 14:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/e49c84b3bf19d849482d231194fabe9676c0e369', 'message': 'Delete image from single store\n\nChange-Id: I283dfdefbdf6604365fb3fb0209e8deba2c18eae\n'}, {'number': 2, 'created': '2019-12-11 15:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/5e60fb0417613c25fb3574dfcabfa7fd0f64cc7a', 'message': 'Delete image from single store\n\nChange-Id: I283dfdefbdf6604365fb3fb0209e8deba2c18eae\n'}, {'number': 3, 'created': '2019-12-19 13:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/c283119e9da2bf241014249a22fcfc8542a45119', 'message': 'Delete image from single store\n\nChange-Id: I283dfdefbdf6604365fb3fb0209e8deba2c18eae\n'}, {'number': 4, 'created': '2019-12-19 21:03:24.000000000', 'files': ['specs/ussuri/approved/glance/delete-image-from-single-store.rst', 'specs/ussuri/approved/index.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a5f88b9e5cd8add7ea9a90a7aba552b368b39fb1', 'message': 'Delete image from single store\n\nChange-Id: I283dfdefbdf6604365fb3fb0209e8deba2c18eae\n'}]",7,698018,a5f88b9e5cd8add7ea9a90a7aba552b368b39fb1,23,5,4,5202,,,0,"Delete image from single store

Change-Id: I283dfdefbdf6604365fb3fb0209e8deba2c18eae
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/18/698018/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/glance/delete-image-from-single-store.rst'],1,e49c84b3bf19d849482d231194fabe9676c0e369,delete-from-store,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Deleting image from single store ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/glance/+spec/delete-from-store New API feature to remove image from single store instead of whacking the whole image. Problem description =================== Currently onl way to remove image from single store is by exposing known problematic locations API and utilize that to remove the location. With multiple-stores support there is definitely more user oriented use-cases for removing image from specific store. Proposed change =============== Introduce new ""/v2/stores"" endpoint to Images API v2 to provide safe way to delete images from the specific store. New API call: 'DELETE /v2/stores/<StoreID>/<ImageID>' Alternatives ------------ We could consider utilizing the current ""v2/images/<ImageID>"" endpoint and append the store ID at the end of that. The risk with this approach is that it's way too easy for the API user to make a mistake dropping the StoreID and accidentally delete the whole image instead of just removing it from single store. Data model impact ----------------- None REST API impact --------------- New API endpoint ""v2/stores/<StoreID>/<ImageID>"" that accepts only DELETE http method. The request will fail if this is the only location indicating that the user should delete the image instead. Security impact --------------- This change does not have any know security impacts. Notifications impact -------------------- Notification of image being removed from the store can be considered. Other end user impact --------------------- python-glanceclient will have feature to support this API call. Performance Impact ------------------ This feature has no know performance impacts. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: jokke Work Items ---------- * API change for glance-api service * Testing for the new feature * python-glanceclient support * Documentation needs to be updated including the new workflow Dependencies ============ None Testing ======= The change will need unit and functional tests. Documentation Impact ==================== None References ========== None ",,131,0
openstack%2Ftripleo-heat-templates~master~I2204b72e40a86892f7312b9af77754d9c11a6c63,openstack/tripleo-heat-templates,master,I2204b72e40a86892f7312b9af77754d9c11a6c63,Fix Octavia to use correct Puppet class,MERGED,2019-12-17 09:50:10.000000000,2020-01-02 14:36:31.000000000,2020-01-02 14:36:30.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 09:50:10.000000000', 'files': ['deployment/octavia/octavia-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e47e7db8a2ee3e59a7c6b71620ba540078f4f123', 'message': 'Fix Octavia to use correct Puppet class\n\nAddition of octavia::controller::enable_anti_affinity was reverted in\n[1] as code to handle that config option already exists in octavia::nova\nclass. This patch follows that revert and sets THT to use octavia::nova.\n\n[1] https://review.opendev.org/#/c/699067/\n\nDepends-On: https://review.opendev.org/#/c/699074/\nChange-Id: I2204b72e40a86892f7312b9af77754d9c11a6c63\n'}]",0,699378,e47e7db8a2ee3e59a7c6b71620ba540078f4f123,11,7,1,6469,,,0,"Fix Octavia to use correct Puppet class

Addition of octavia::controller::enable_anti_affinity was reverted in
[1] as code to handle that config option already exists in octavia::nova
class. This patch follows that revert and sets THT to use octavia::nova.

[1] https://review.opendev.org/#/c/699067/

Depends-On: https://review.opendev.org/#/c/699074/
Change-Id: I2204b72e40a86892f7312b9af77754d9c11a6c63
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/699378/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/octavia/octavia-base.yaml'],1,e47e7db8a2ee3e59a7c6b71620ba540078f4f123,, octavia::nova::enable_anti_affinity: {get_param: OctaviaAntiAffinity}, octavia::controller::enable_anti_affinity: {get_param: OctaviaAntiAffinity},1,1
openstack%2Ftripleo-ci~master~I45a608150f054c5e5ae0a5109ab57d3d9963f434,openstack/tripleo-ci,master,I45a608150f054c5e5ae0a5109ab57d3d9963f434,Remove tempest fsoverrides in favor of featureset vars,MERGED,2019-12-10 10:49:38.000000000,2020-01-02 14:36:28.000000000,2020-01-02 14:36:28.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-10 10:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b0cfaeb4aa7ae68b5f025ec99af9d7d9f6b905f5', 'message': 'Remove tempest fsoverrides in favor of featureset vars\n\nhttps://review.opendev.org/#/c/698211/ moves the ostempest\nvars to featureset. So we are removing the same from here and\nreuse it from fs itself.\n\nDepends-On: https://review.opendev.org/#/c/698211/\n\nChange-Id: I45a608150f054c5e5ae0a5109ab57d3d9963f434\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 2, 'created': '2019-12-12 10:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8bc5c6ffff135973d41c5bc7849b1779b9981eec', 'message': 'Remove tempest fsoverrides in favor of featureset vars\n\nhttps://review.opendev.org/#/c/698211/ moves the ostempest\nvars to featureset. So we are removing the same from here and\nreuse it from fs itself.\n\nDepends-On: https://review.opendev.org/#/c/698211/\n\nChange-Id: I45a608150f054c5e5ae0a5109ab57d3d9963f434\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 3, 'created': '2019-12-16 11:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a6bd639ceb4512409efd074a168d90ce5ba0030f', 'message': 'Remove tempest fsoverrides in favor of featureset vars\n\nhttps://review.opendev.org/#/c/698211/ moves the ostempest\nvars to featureset. So we are removing the same from here and\nreuse it from fs itself.\n\nDepends-On: https://review.opendev.org/#/c/698211/\n\nChange-Id: I45a608150f054c5e5ae0a5109ab57d3d9963f434\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 4, 'created': '2019-12-17 12:37:42.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/aef068a1066278a67e3df48fec0f4b9969f1fdaa', 'message': 'Remove tempest fsoverrides in favor of featureset vars\n\nhttps://review.opendev.org/#/c/698211/ moves the ostempest\nvars to featureset. So we are removing the same from here and\nreuse it from fs itself.\n\nDepends-On: https://review.opendev.org/#/c/698211/\n\nChange-Id: I45a608150f054c5e5ae0a5109ab57d3d9963f434\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",3,698214,aef068a1066278a67e3df48fec0f4b9969f1fdaa,31,7,4,12393,,,0,"Remove tempest fsoverrides in favor of featureset vars

https://review.opendev.org/#/c/698211/ moves the ostempest
vars to featureset. So we are removing the same from here and
reuse it from fs itself.

Depends-On: https://review.opendev.org/#/c/698211/

Change-Id: I45a608150f054c5e5ae0a5109ab57d3d9963f434
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/14/698214/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,b0cfaeb4aa7ae68b5f025ec99af9d7d9f6b905f5,move_to_plain_standalone,, featureset_override: run_tempest: false tempest_format: container tempest_run_concurrency: 2 tempest_tempest_conf_overrides: auth.use_dynamic_credentials: true tempest_test_whitelist: - 'tempest.scenario.test_minimum_basic.TestMinimumBasicScenario' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' - 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern' - '\[.*\bsmoke\b.*\]' use_os_tempest: true,0,12
openstack%2Fglance-specs~master~If0a9b966ccb6e13537505004605fb2213e7cab5e,openstack/glance-specs,master,If0a9b966ccb6e13537505004605fb2213e7cab5e,Ussuri project priorities,MERGED,2019-11-26 06:01:51.000000000,2020-01-02 14:31:59.000000000,2020-01-02 14:30:27.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-26 06:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/85906b76b20859b88f4417963d2957cff5e71680', 'message': 'Ussuri project priorities\n\nChange-Id: If0a9b966ccb6e13537505004605fb2213e7cab5e\n'}, {'number': 2, 'created': '2019-12-03 05:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/59ba3744d28136a255bb1c0c61b6dfd88ac1a01a', 'message': 'Ussuri project priorities\n\nChange-Id: If0a9b966ccb6e13537505004605fb2213e7cab5e\n'}, {'number': 3, 'created': '2019-12-13 05:24:19.000000000', 'files': ['priorities/ussuri-priorities.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/e798d407b9914efaf064d7b6c260e9efb97cebf1', 'message': 'Ussuri project priorities\n\nChange-Id: If0a9b966ccb6e13537505004605fb2213e7cab5e\n'}]",2,696017,e798d407b9914efaf064d7b6c260e9efb97cebf1,18,5,3,9303,,,0,"Ussuri project priorities

Change-Id: If0a9b966ccb6e13537505004605fb2213e7cab5e
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/17/696017/3 && git format-patch -1 --stdout FETCH_HEAD,['priorities/ussuri-priorities.rst'],1,85906b76b20859b88f4417963d2957cff5e71680,ussuri/priorities,The Ussuri review priorities were discussed at the Shanghai PTG. The preliminary list was maintained on the `Shanghai PTG etherpad`_. This list is an estimate of what the Glance project team can accomplish during the Ussuri cycle based on our developers' estimates of how much time they can commit to Glance. The following list is roughly indicates milestonewise priorities. .. list-table:: :header-rows: 1 * - Priority Item - Owner(s) - Spec(s) - Target release milestone * - Import image in multiple stores - `Grgoire Unbekandt`_ - `multiple image import`_ - M1 * - Copy existing image in multiple stores - `Abhishek Kekane`_ - `copy image in multiple stores`_ - M1 * - S3 driver for glance_store - `Naohiro Sameshima`_ - `s3 driver`_ - M1 * - remove sheepdog driver from glance_store - `Abhishek Kekane`_ - None - M1 * - Permanent solution for Subunit parser error - `Abhishek Kekane`_ - None - M2 * - Nova - snapshot/backup upload to multiple stores - `Abhishek Kekane`_ - `nova snapshot`_ - M2 * - Cinder - volume upload to multiple stores - `Abhishek Kekane`_ - `cinder uploadtoimage`_ - M2 * - Cluster awareness of glance API nodes - `Erno Kuvaja`_ - `cluster awareness`_ - M2 * - remove registry code from glance - `Abhishek Kekane`_ - None - M2 * - Delete image from single store - `Abhishek Kekane`_ - None - M2 * - image-import.conf parsing issue with uwsgi - Unassigned - None - M2 * - Multiple cinder store support in glance_store - `Abhishek Kekane`_ - `cinder glance_store`_ - M3 * - Image encryption - `Josephine Seifert`_ - `image encryption`_ - M3 * - Tempest work - `Abhishek Kekane`_ - None - M3 .. _Shanghai PTG etherpad: https://etherpad.openstack.org/p/Glance-Ussuri-PTG-planning .. _Grgoire Unbekandt: https://launchpad.net/~yebinama .. _Erno Kuvaja: https://launchpad.net/~jokke .. _Abhishek Kekane: https://launchpad.net/~abhishek-kekane .. _Josephine Seifert: https://launchpad.net/~josei .. _Naohiro Sameshima: https://launchpad.net/~nao-shark .. _multiple image import: https://review.opendev.org/669201 .. _copy image in multiple stores: https://review.opendev.org/694724 .. _s3 driver: https://review.opendev.org/687390 .. _nova snapshot: https://review.opendev.org/641210 .. _cinder uploadtoimage: https://review.opendev.org/695630 .. _cluster awareness: https://review.opendev.org/664956 .. _cinder glance_store: https://review.opendev.org/695152 .. _image encryption: https://review.opendev.org/609667 Important dates --------------- This is an abbreviated list focused on dates relevant to Glance. See `Ussuri Release Schedule`_ for the complete list for OpenStack. .. _Ussuri Release Schedule: https://releases.openstack.org/ussuri/schedule.html .. list-table:: :header-rows: 1 * - R-22 - Dec 13 - U-1 milestone * - R-13 - Feb 14 - U-2 milestone * - R-6 - April 03 - glance_store Ussuri release (final release for non-client libraries) * - R-5 - April 22 - * U-3 milestone * **Glance feature freeze** * python-glanceclient Ussuri release (final release for client libraries); * - R-3 - April 24 - RC-1 release and **string freeze** * - R-1 - May 08 - final RCs * - R-0 - May 15 - **Ussuri release**,TODO(abhishekk): fill this in after the PTG,126,1
openstack%2Fkolla-ansible~master~I401a073eb6225e90b6f9d6b2a32f33d22d1d7a79,openstack/kolla-ansible,master,I401a073eb6225e90b6f9d6b2a32f33d22d1d7a79,Docs: remove some bad recommendations,MERGED,2019-10-29 07:39:53.000000000,2020-01-02 14:29:32.000000000,2020-01-02 14:28:10.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-29 07:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a900f27bb1413e6e653787f5b09cd2a012d2d086', 'message': 'Docs: remove some bad recommendations\n\nChange-Id: I401a073eb6225e90b6f9d6b2a32f33d22d1d7a79\n'}, {'number': 2, 'created': '2019-12-20 17:42:53.000000000', 'files': ['doc/source/admin/production-architecture-guide.rst', 'doc/source/reference/deployment-and-bootstrapping/bootstrap-servers.rst', 'doc/source/user/operating-kolla.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ede61e743b11755fdeb3df8742419e896cd5c11a', 'message': 'Docs: remove some bad recommendations\n\nChange-Id: I401a073eb6225e90b6f9d6b2a32f33d22d1d7a79\n'}]",3,691814,ede61e743b11755fdeb3df8742419e896cd5c11a,14,5,2,30491,,,0,"Docs: remove some bad recommendations

Change-Id: I401a073eb6225e90b6f9d6b2a32f33d22d1d7a79
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/14/691814/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/production-architecture-guide.rst', 'doc/source/user/operating-kolla.rst']",2,a900f27bb1413e6e653787f5b09cd2a012d2d086,docs-docker,, The Kolla community recommends the btrfs or aufs graph drivers for storing data as sometimes the LVM graph driver loses track of its reference counting and results in an unremovable container. .. note:: ,0,14
openstack%2Fkuryr-tempest-plugin~master~Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f,openstack/kuryr-tempest-plugin,master,Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f,Adjust initial ports list in port_pool test,MERGED,2019-12-10 11:50:21.000000000,2020-01-02 14:18:02.000000000,2020-01-02 14:16:37.000000000,"[{'_account_id': 4727}, {'_account_id': 11600}, {'_account_id': 21302}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-12-10 11:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/a8d7d8ba5002c65cc820871f1a759f74430cdc70', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 2, 'created': '2019-12-10 12:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/9e4b7c55ef54f9901ca6ae0c0f91cddb4b143708', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 3, 'created': '2019-12-10 14:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/b5929f4eb3a09b07c5a32f80ef9f6dd125c0232d', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 4, 'created': '2019-12-11 07:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/d02743f25b1409b6ae1685431bd39bcdcfe71b3f', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 5, 'created': '2019-12-16 09:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/228866306f84d715706e55858d162dfba5248219', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 6, 'created': '2019-12-18 07:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/d3b6cec7e3c366d52fe9a97b50f66e8a96813673', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 7, 'created': '2019-12-19 12:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/136e8280993876556e4c82411ccef2f0fb641384', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 8, 'created': '2019-12-19 15:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/982e2fd79186014242d7ff4f641ee6a03e2cd75a', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 9, 'created': '2019-12-22 14:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/9ab7cecd9797fdeac0a24259dd5be6359b6b6902', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 10, 'created': '2019-12-22 14:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/f8ce0b1591afe1f9c13184acb710fb2ced424986', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 11, 'created': '2019-12-22 15:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/c44c7dfdf5fec892f851dec29fbc5c80fbd0e1dd', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 12, 'created': '2019-12-23 10:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/5c5a8ae183b2d9093841a58bf5436d0d429f925a', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 13, 'created': '2019-12-23 12:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/40a6459c71bbcc5e1594a8c7c5a0e919ee75fac6', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 14, 'created': '2019-12-23 13:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/cfdbce71aacec17f414761cf3439352307e369f9', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 15, 'created': '2019-12-23 23:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/0dfa6ed2078d3d6d989b520d9a35a8fd0a5d7c7b', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}, {'number': 16, 'created': '2019-12-24 10:08:23.000000000', 'files': ['kuryr_tempest_plugin/tests/scenario/test_port_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/e701961debfdd58e0999d79921f9d8c9574db43b', 'message': 'Adjust initial ports list in port_pool test\n\nAdjusting also test_port_pool_min_max_update,\nDue to prepopulation of ports when creating namespace.\n\nChange-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f\n'}]",27,698221,e701961debfdd58e0999d79921f9d8c9574db43b,78,6,16,4727,,,0,"Adjust initial ports list in port_pool test

Adjusting also test_port_pool_min_max_update,
Due to prepopulation of ports when creating namespace.

Change-Id: Id1720eaf94b3a278aa126e2ed3cb9bcdda8e631f
",git fetch https://review.opendev.org/openstack/kuryr-tempest-plugin refs/changes/21/698221/16 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_tempest_plugin/tests/scenario/test_port_pool.py'],1,a8d7d8ba5002c65cc820871f1a759f74430cdc70,port_pool," def check_initial_ports_num(self, subnet_id): # check the original length of list of ports for new ns if CONF.kuryr_kubernetes.prepopulation_enabled: num_ports_initial = num_nodes * (int(POOL_BATCH/2) + 1) return port_list_num @decorators.idempotent_id('bddf5441-1244-449d-a125-b5fddfb1a3aa') @lockutils.synchronized('port-pool-restarts') def test_port_pool(self): namespace_name, namespace = self.create_namespace() self.addCleanup(self.delete_namespace, namespace_name) subnet_id = self.get_subnet_id_for_ns(namespace_name) num_nodes = len(self.k8s_client.CoreV1Api().list_node().items) port_list_num = self.check_initial_ports_num(subnet_id) self.check_initial_ports_num(subnet_id)"," @decorators.idempotent_id('bddf5441-1244-449d-a125-b5fddfb1a3aa') @lockutils.synchronized('port-pool-restarts') def test_port_pool(self): namespace_name, namespace = self.create_namespace() self.addCleanup(self.delete_namespace, namespace_name) subnet_id = self.get_subnet_id_for_ns(namespace_name) num_nodes = len(self.k8s_client.CoreV1Api().list_node().items) if CONF.kuryr_kubernetes.prepopulation_enabled: num_ports_initial = num_nodes * (int(self.PORTS_POOL_DEFAULT_DICT[ 'ports_pool_batch'])/2) + 1 # Make sure we have the right number of ports after namespace creation # check the original length of list of ports for new ns",16,13
openstack%2Fvitrage-dashboard~master~I46c83bb08311608e2f999c3d9645967ec89b0418,openstack/vitrage-dashboard,master,I46c83bb08311608e2f999c3d9645967ec89b0418,Change README.rst with a better title,MERGED,2019-12-24 09:38:26.000000000,2020-01-02 14:12:38.000000000,2020-01-02 14:11:09.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 27386}, {'_account_id': 30562}]","[{'number': 1, 'created': '2019-12-24 09:38:26.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/b3efbd9527976592946c798d414f5f8a5914b8b4', 'message': 'Change README.rst with a better title\n\nChange-Id: I46c83bb08311608e2f999c3d9645967ec89b0418\n'}]",0,700500,b3efbd9527976592946c798d414f5f8a5914b8b4,10,5,1,27399,,,0,"Change README.rst with a better title

Change-Id: I46c83bb08311608e2f999c3d9645967ec89b0418
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/00/700500/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b3efbd9527976592946c798d414f5f8a5914b8b4,,================= Vitrage Dashboard =================,======================== Team and repository tags ========================================= Vitrage Dashboard ================= ,3,7
openstack%2Fironic-python-agent-builder~master~I6b23da21eab19c69f7b070adff76b35e1752bf8d,openstack/ironic-python-agent-builder,master,I6b23da21eab19c69f7b070adff76b35e1752bf8d,Replace CentOS 7 images with CentOS 8,MERGED,2019-11-27 18:31:25.000000000,2020-01-02 14:07:15.000000000,2020-01-02 14:04:14.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-11-27 18:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/f4a817b97ff86d9db8b7c2bea446023d113c012d', 'message': ""Start building CentOS 8 images\n\nCentOS 7 uses Python 2. Although it's possible to install Python 3\non it, we should rather switch to a distribution where Python 3\nis the default version.\n\nAs a nice side effect, the CentOS 8 images seem smaller.\n\nChange-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d\n""}, {'number': 2, 'created': '2019-12-12 13:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/c16087d2bfec96f83f29e380bdda9496deecc157', 'message': ""Replace CentOS 7 images with CentOS 8\n\nCentOS 7 uses Python 2. Although it's possible to install Python 3\non it, it not trivial with DIB. We should rather switch to\na distribution where Python 3 is the default version.\n\nAs a nice side effect, the CentOS 8 images seem smaller.\n\nThe CentOS 7 job definitions are kept around since they're used\non stable/train.\n\nChange-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d\n""}, {'number': 3, 'created': '2019-12-12 13:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/48171eb5ff4314a3ca27f21aa7c1a792d6cb8596', 'message': ""Replace CentOS 7 images with CentOS 8\n\nCentOS 7 uses Python 2. Although it's possible to install Python 3\non it, it not trivial with DIB. We should rather switch to\na distribution where Python 3 is the default version.\n\nAs a nice side effect, the CentOS 8 images seem smaller.\n\nThe CentOS 7 job definitions are kept around since they're used\non stable/train.\n\nChange-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d\n""}, {'number': 4, 'created': '2019-12-13 16:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/7566e6724cf0c455cd3fe3a4d25072e7ee6acb7e', 'message': ""Replace CentOS 7 images with CentOS 8\n\nCentOS 7 uses Python 2. Although it's possible to install Python 3\non it, it not trivial with DIB. We should rather switch to\na distribution where Python 3 is the default version.\n\nAs a nice side effect, the CentOS 8 images seem smaller.\n\nThe CentOS 7 job definitions are kept around since they're used\non stable/train.\n\nChange-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d\n""}, {'number': 5, 'created': '2019-12-26 11:38:03.000000000', 'files': ['roles/ipa-build-dib-image/tasks/main.yaml', 'doc/source/admin/dib.rst', '.zuul.yaml', 'releasenotes/notes/centos8-46a95956fd871c90.yaml', 'roles/ipa-build-dib-image/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3c78c29e94443ca2c169c6c2d065a2e57d3023b5', 'message': ""Replace CentOS 7 images with CentOS 8\n\nCentOS 7 uses Python 2. Although it's possible to install Python 3\non it, it not trivial with DIB. We should rather switch to\na distribution where Python 3 is the default version.\n\nAs a nice side effect, the CentOS 8 images seem smaller.\n\nThe CentOS 7 job definitions are kept around since they're used\non stable/train.\n\nChange-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d\n""}]",1,696383,3c78c29e94443ca2c169c6c2d065a2e57d3023b5,28,6,5,10239,,,0,"Replace CentOS 7 images with CentOS 8

CentOS 7 uses Python 2. Although it's possible to install Python 3
on it, it not trivial with DIB. We should rather switch to
a distribution where Python 3 is the default version.

As a nice side effect, the CentOS 8 images seem smaller.

The CentOS 7 job definitions are kept around since they're used
on stable/train.

Change-Id: I6b23da21eab19c69f7b070adff76b35e1752bf8d
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/83/696383/4 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f4a817b97ff86d9db8b7c2bea446023d113c012d,centos8, name: ironic-python-agent-build-image-dib-centos8 parent: ironic-python-agent-build-image-base required-projects: # NOTE(dtantsur): used for bindep only - openstack/diskimage-builder vars: image_type: 'dib' image_distro: 'centos-minimal' image_release: 8 - job: - ironic-python-agent-check-image-dib-centos8 - ironic-python-agent-check-image-dib-centos8 - ironic-python-agent-build-image-dib-centos8, - ironic-python-agent-check-image-dib-centos8: voting: false,14,2
openstack%2Ftripleo-common~master~Id11adaa426487ed4f3ce4148c84f750cba1c0c11,openstack/tripleo-common,master,Id11adaa426487ed4f3ce4148c84f750cba1c0c11,Using API instead yaql to get manageable nodes,MERGED,2019-12-11 12:40:07.000000000,2020-01-02 14:03:53.000000000,2020-01-02 14:02:16.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-12-11 12:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2e83fe5ea1797b369f7e38d13b2c948610e857d3', 'message': 'Using API instead yaql to get manageable nodes\n\nCurrently tripleo.baremetal.v1 workbook is using YAQL to filter\nnodes in manageable state for introspection workflow. Since there\nis a way to get manageable nodes using client parameter [1] using\nYAQL is suboptimal.\nMoreover this does not work in large environments because default\n`limit` argument [2] does not list all nodes and nodes in manageable\nstate might not detect in introspection.\n\n[1]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L75-L76\n[2]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L80-L87\n\nChange-Id: Id11adaa426487ed4f3ce4148c84f750cba1c0c11\nCloses-Bug: #1856031\n'}, {'number': 2, 'created': '2019-12-11 12:52:22.000000000', 'files': ['workbooks/baremetal.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/81145138adc2fbeda872debd2e17fe049c6fea0e', 'message': 'Using API instead yaql to get manageable nodes\n\nCurrently tripleo.baremetal.v1 workbook is using YAQL to filter\nnodes in manageable state for introspection workflow. Since there\nis a way to get manageable nodes using client parameter [1] using\nYAQL is suboptimal.\nMoreover this does not work in large environments because default\n`limit` argument [2] does not list all nodes and nodes in manageable\nstate might not detect in introspection.\n\n[1]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L75-L76\n[2]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L80-L87\n\nChange-Id: Id11adaa426487ed4f3ce4148c84f750cba1c0c11\nCloses-Bug: #1856031\n'}]",2,698469,81145138adc2fbeda872debd2e17fe049c6fea0e,22,7,2,30133,,,0,"Using API instead yaql to get manageable nodes

Currently tripleo.baremetal.v1 workbook is using YAQL to filter
nodes in manageable state for introspection workflow. Since there
is a way to get manageable nodes using client parameter [1] using
YAQL is suboptimal.
Moreover this does not work in large environments because default
`limit` argument [2] does not list all nodes and nodes in manageable
state might not detect in introspection.

[1]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L75-L76
[2]: https://github.com/openstack/python-ironicclient/blob/master/ironicclient/v1/node.py#L80-L87

Change-Id: Id11adaa426487ed4f3ce4148c84f750cba1c0c11
Closes-Bug: #1856031
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/69/698469/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/baremetal.yaml'],1,2e83fe5ea1797b369f7e38d13b2c948610e857d3,bug/1856031," action: ironic.node_list maintenance=False associated=False provision_state=""manageable"" managed_nodes: <% task().result.uuid %> action: ironic.node_list maintenance=False associated=False provision_state=""manageable"" managed_nodes: <% task().result.uuid %> action: ironic.node_list maintenance=False associated=False provision_state=""manageable"" managed_nodes: <% task().result.uuid %>", action: ironic.node_list maintenance=False associated=False managed_nodes: <% task().result.where($.provision_state = 'manageable').uuid %> action: ironic.node_list maintenance=False associated=False managed_nodes: <% task().result.where($.provision_state = 'manageable').uuid %> action: ironic.node_list maintenance=False associated=False managed_nodes: <% task().result.where($.provision_state = 'manageable').uuid %>,6,6
openstack%2Fopenstack-zuul-jobs~master~Ibc3aba9e5adffe7a3efab1f4b5bfe7ff48a179b8,openstack/openstack-zuul-jobs,master,Ibc3aba9e5adffe7a3efab1f4b5bfe7ff48a179b8,Add no-constraints job for py37,MERGED,2019-12-18 14:03:50.000000000,2020-01-02 13:31:38.000000000,2020-01-02 13:28:54.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 14:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ddc8c61039bf7d676c3f545a09bdfe70064d50a9', 'message': 'Add no-constraints job for py37\n\nSome repos, such as reviewstats, use no-constraints jobs since they are\nnot bound by the same constraints as official OpenStack projects.\n\nThis adds a variant using py37 to allow moving beyond the current max\nversion of py35.\n\nChange-Id: Ibc3aba9e5adffe7a3efab1f4b5bfe7ff48a179b8\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2019-12-18 14:16:37.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/f821782ad616886a535f7f5845e5cb8157f8c387', 'message': 'Add no-constraints job for py37\n\nSome repos, such as reviewstats, use no-constraints jobs since they are\nnot bound by the same constraints as official OpenStack projects.\n\nThis adds a variant using py37 to allow moving beyond the current max\nversion of py35.\n\nChange-Id: Ibc3aba9e5adffe7a3efab1f4b5bfe7ff48a179b8\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,699679,f821782ad616886a535f7f5845e5cb8157f8c387,12,3,2,11904,,,0,"Add no-constraints job for py37

Some repos, such as reviewstats, use no-constraints jobs since they are
not bound by the same constraints as official OpenStack projects.

This adds a variant using py37 to allow moving beyond the current max
version of py35.

Change-Id: Ibc3aba9e5adffe7a3efab1f4b5bfe7ff48a179b8
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/79/699679/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,ddc8c61039bf7d676c3f545a09bdfe70064d50a9,no-constraints," name: openstack-python37-jobs-no-constraints description: | Runs the OpenStack PTI jobs for python3.7, but uses the versions of them that do not use constraints. check: jobs: - tox-py37: nodeset: ubuntu-bionic gate: jobs: - tox-py37: nodeset: ubuntu-bionic post: jobs: - publish-openstack-python-branch-tarball - project-template:",,17,0
openstack%2Fopenstack-ansible~master~I1fecda5ef29892fea396a6d33f24aa14e7a4c531,openstack/openstack-ansible,master,I1fecda5ef29892fea396a6d33f24aa14e7a4c531,Add documentation for octavia (networking),ABANDONED,2019-12-31 08:45:29.000000000,2020-01-02 13:28:08.000000000,,"[{'_account_id': 21741}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-12-31 08:45:29.000000000', 'files': ['etc/openstack_deploy/conf.d/octavia.yml.example'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ebad536991f65bc046e3174a103a74ef1ab31e97', 'message': 'Add documentation for octavia (networking)\n\nCurrently there is no desciption or example how to deploy\noctavia.  This adds a small conf.d snipplet with the needed\ninformation.\n\nChange-Id: I1fecda5ef29892fea396a6d33f24aa14e7a4c531\nCloses-Bug: 1857960\nSigned-off-by: Andreas Florath <andreas.florath@telekom.de>\n'}]",0,700803,ebad536991f65bc046e3174a103a74ef1ab31e97,5,3,1,21741,,,0,"Add documentation for octavia (networking)

Currently there is no desciption or example how to deploy
octavia.  This adds a small conf.d snipplet with the needed
information.

Change-Id: I1fecda5ef29892fea396a6d33f24aa14e7a4c531
Closes-Bug: 1857960
Signed-off-by: Andreas Florath <andreas.florath@telekom.de>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/03/700803/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/openstack_deploy/conf.d/octavia.yml.example'],1,ebad536991f65bc046e3174a103a74ef1ab31e97,bug/1857960,"# When deplying octavia there is the need to set some configuration # parameters and setup a dedicated lbaas network. # In the `openstack_user_config.yml` there is the need to add the # `lbaas` network. Example: # # cidr_networks: # lbaas: 10.0.8.0/24 # # global_overrides: # provider_networks: # - network: # container_bridge: ""br-lbaas"" # container_type: ""veth"" # container_interface: ""eth14"" # host_bind_override: ""eth14"" # ip_from_q: ""lbaas"" # type: ""flat"" # net_name: ""lbaas"" # group_binds: # - neutron_linuxbridge_agent # - octavia-worker # - octavia-housekeeping # - octavia-health-manager # octavia needs the following additional network configuration: octavia_management_net_subnet_cidr: ""10.0.8.0/24"" octavia_management_net_subnet_allocation_pools: ""10.0.8.131-10.0.8.249"" ",,28,0
openstack%2Fmanila~master~I837b4afb66018dc96a338c93ce839216ec8f33d2,openstack/manila,master,I837b4afb66018dc96a338c93ce839216ec8f33d2,Fix a wrong comma in log message,MERGED,2020-01-02 05:59:50.000000000,2020-01-02 13:20:53.000000000,2020-01-02 13:19:20.000000000,"[{'_account_id': 9003}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 29291}]","[{'number': 1, 'created': '2020-01-02 05:59:50.000000000', 'files': ['manila/share/drivers/dell_emc/plugins/unity/client.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/73b0bccd9f0e3238a153cb9ee461bbaefd6aa6d4', 'message': 'Fix a wrong comma in log message\n\nThis is to remove a wrong comma in log message.\n\nChange-Id: I837b4afb66018dc96a338c93ce839216ec8f33d2\n'}]",2,700868,73b0bccd9f0e3238a153cb9ee461bbaefd6aa6d4,15,9,1,20190,,,0,"Fix a wrong comma in log message

This is to remove a wrong comma in log message.

Change-Id: I837b4afb66018dc96a338c93ce839216ec8f33d2
",git fetch https://review.opendev.org/openstack/manila refs/changes/68/700868/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/dell_emc/plugins/unity/client.py'],1,73b0bccd9f0e3238a153cb9ee461bbaefd6aa6d4,more_comma, LOG.debug('There are NAS servers belonging to the tenant %s. '," LOG.debug('There are NAS servers belonging to the tenant %s. ',",1,1
openstack%2Fironic-tempest-plugin~master~Ifcf0cab0b3f6a828a756ca8e5efe6e262c20fe30,openstack/ironic-tempest-plugin,master,Ifcf0cab0b3f6a828a756ca8e5efe6e262c20fe30,Enforce running tox with correct python version based on env,MERGED,2019-12-23 10:21:03.000000000,2020-01-02 13:20:49.000000000,2020-01-02 13:19:10.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 10:21:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/7825e28725516f3bae8950abb53748f0441de0ef', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: Ifcf0cab0b3f6a828a756ca8e5efe6e262c20fe30\n'}]",0,700410,7825e28725516f3bae8950abb53748f0441de0ef,8,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: Ifcf0cab0b3f6a828a756ca8e5efe6e262c20fe30
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/10/700410/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7825e28725516f3bae8950abb53748f0441de0ef,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fpython-openstackclient~master~I1bdb248ba677c41e456dcac3dd6f08151de4a9f8,openstack/python-openstackclient,master,I1bdb248ba677c41e456dcac3dd6f08151de4a9f8,Remove python2 from project-template,ABANDONED,2019-12-15 15:21:16.000000000,2020-01-02 13:20:12.000000000,,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-15 15:21:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3c341bbaf484cf708ec92738093eb3d5168fd0ee', 'message': ""Remove python2 from project-template\n\nWe're unwinding python2 testing. As part of doing that, remove\npython2 from our zuul project-template which other people are\nusing to add tips jobs to their project.\n\nChange-Id: I1bdb248ba677c41e456dcac3dd6f08151de4a9f8\n""}]",0,699131,3c341bbaf484cf708ec92738093eb3d5168fd0ee,8,3,1,2,,,0,"Remove python2 from project-template

We're unwinding python2 testing. As part of doing that, remove
python2 from our zuul project-template which other people are
using to add tips jobs to their project.

Change-Id: I1bdb248ba677c41e456dcac3dd6f08151de4a9f8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/31/699131/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3c341bbaf484cf708ec92738093eb3d5168fd0ee,,, - osc-tox-py27-tips - osc-tox-py27-tips,0,2
openstack%2Fnetworking-baremetal~master~Iba38c8acfc161988fe725008eb052b982bdb9c44,openstack/networking-baremetal,master,Iba38c8acfc161988fe725008eb052b982bdb9c44,Enforce running tox with correct python version based on env,MERGED,2019-12-23 10:25:39.000000000,2020-01-02 13:16:16.000000000,2020-01-02 13:14:53.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 10:25:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/b06ee1ce490120392851c507e2745d92ed6385df', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: Iba38c8acfc161988fe725008eb052b982bdb9c44\n'}]",0,700412,b06ee1ce490120392851c507e2745d92ed6385df,8,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: Iba38c8acfc161988fe725008eb052b982bdb9c44
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/12/700412/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b06ee1ce490120392851c507e2745d92ed6385df,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fpython-ironic-inspector-client~master~I1fb4f75c36bf8d9b93f3892627095b64c0522bf9,openstack/python-ironic-inspector-client,master,I1fb4f75c36bf8d9b93f3892627095b64c0522bf9,Enforce running tox with correct python version based on env,MERGED,2019-12-23 09:33:36.000000000,2020-01-02 13:13:30.000000000,2020-01-02 13:11:58.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 09:33:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/e0cda0a5b6b1c0f7e3fa159f9535db2b9fb64eeb', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I1fb4f75c36bf8d9b93f3892627095b64c0522bf9\n'}]",0,700401,e0cda0a5b6b1c0f7e3fa159f9535db2b9fb64eeb,9,4,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I1fb4f75c36bf8d9b93f3892627095b64c0522bf9
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/01/700401/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e0cda0a5b6b1c0f7e3fa159f9535db2b9fb64eeb,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Ftripleo-ansible~master~Iec86668d82280837b32c14c48668890c37b54435,openstack/tripleo-ansible,master,Iec86668d82280837b32c14c48668890c37b54435,"Revert ""Change drop action""",ABANDONED,2019-12-26 06:01:04.000000000,2020-01-02 13:13:20.000000000,,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-26 06:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/54e1eb51981628de6f211dcb609e1efef620eb38', 'message': 'Revert ""Change drop action""\n\nRHEL8 jobs failing, and this seems possible cause.\n\nRelated-Bug: #1857463\nThis reverts commit 8f11437b1c5173d3dda669b8b1d700837b33b245.\n\nChange-Id: Iec86668d82280837b32c14c48668890c37b54435\n'}, {'number': 2, 'created': '2019-12-26 06:01:38.000000000', 'files': ['tripleo_ansible/ansible_plugins/action/tripleo_iptables.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/27013ae35eec5f7ebb1e40349fcbba45eb7df3b4', 'message': 'Revert ""Change drop action""\n\nRHEL8 jobs failing, and this seems possible cause.\n\nRelated-Bug: #1857463\nThis reverts commit 8f11437b1c5173d3dda669b8b1d700837b33b245.\n\nChange-Id: Iec86668d82280837b32c14c48668890c37b54435\n'}]",0,700590,27013ae35eec5f7ebb1e40349fcbba45eb7df3b4,22,9,2,13861,,,0,"Revert ""Change drop action""

RHEL8 jobs failing, and this seems possible cause.

Related-Bug: #1857463
This reverts commit 8f11437b1c5173d3dda669b8b1d700837b33b245.

Change-Id: Iec86668d82280837b32c14c48668890c37b54435
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/90/700590/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/action/tripleo_iptables.py'],1,54e1eb51981628de6f211dcb609e1efef620eb38,fw-update," rule_data['action'] = 'insert' rule_data['state'] = 'absent' rule_data['jump'] = rule.get('jump', 'ACCEPT')"," rule_data['action'] = 'append' rule_data['jump'] = rule.get('jump', 'DROP') else: rule_data['jump'] = rule.get('jump', 'ACCEPT')",3,4
openstack%2Ftripleo-heat-templates~master~Ifd5db368d63e89150c5c46877cd20e1e4a65a08c,openstack/tripleo-heat-templates,master,Ifd5db368d63e89150c5c46877cd20e1e4a65a08c,Fix sshd firewall rule,MERGED,2020-01-01 07:40:18.000000000,2020-01-02 13:09:14.000000000,2020-01-02 13:09:14.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-01 07:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7a10571b9c61818c0bfa4b3a5b2ca8d8b102872', 'message': 'Fix sshd firewall rule\n\nAfter migration to tripleo-ansible firewall role with [1],\nfirwall rules for sshd were not applied correctly as value\nof heat param SshFirewallAllowAll was not being honored.\nThis patch fixes it by using conditions properly.\nIssue was not hit in CI in CentOS7 jobs as rule to allow\naccess to port 22 is done while creating nodepool images with\nnodepool-base element.\n\n[1] https://review.opendev.org/#/c/677237/\n\nCloses-Bug: #1857463\nChange-Id: Ifd5db368d63e89150c5c46877cd20e1e4a65a08c\n'}, {'number': 2, 'created': '2020-01-01 07:46:44.000000000', 'files': ['deployment/sshd/sshd-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/318ec87c362e5d45dae2288766c7539d7ec3e995', 'message': ""Fix sshd firewall rule\n\nAfter migration to tripleo-ansible firewall role with [1],\nfirwall rules for sshd were not applied correctly as value\nof heat param SshFirewallAllowAll was not being honored.\nThis patch fixes it by using conditions properly.\n\nIssue was not hit in CI in CentOS7 jobs as rule to allow\naccess to port 22 is done while creating nodepool images with\nnodepool-base element. Issue got visible in rhel8 jobs(rhel8\nnodepool images don't have nodepool-base element applied due\nto [3]) after [2] was merged which fixed apply of DROP rules.\n\n[1] https://review.opendev.org/#/c/677237/\n[2] https://review.opendev.org/#/c/699692/\n[3] https://softwarefactory-project.io/r/#/c/15863/\n\nCloses-Bug: #1857463\nChange-Id: Ifd5db368d63e89150c5c46877cd20e1e4a65a08c\n""}]",1,700829,318ec87c362e5d45dae2288766c7539d7ec3e995,9,8,2,13861,,,0,"Fix sshd firewall rule

After migration to tripleo-ansible firewall role with [1],
firwall rules for sshd were not applied correctly as value
of heat param SshFirewallAllowAll was not being honored.
This patch fixes it by using conditions properly.

Issue was not hit in CI in CentOS7 jobs as rule to allow
access to port 22 is done while creating nodepool images with
nodepool-base element. Issue got visible in rhel8 jobs(rhel8
nodepool images don't have nodepool-base element applied due
to [3]) after [2] was merged which fixed apply of DROP rules.

[1] https://review.opendev.org/#/c/677237/
[2] https://review.opendev.org/#/c/699692/
[3] https://softwarefactory-project.io/r/#/c/15863/

Closes-Bug: #1857463
Change-Id: Ifd5db368d63e89150c5c46877cd20e1e4a65a08c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/29/700829/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/sshd/sshd-baremetal-puppet.yaml'],1,f7a10571b9c61818c0bfa4b3a5b2ca8d8b102872,bug/1857463,"conditions: ssh_firewall_allow_all: {equals: [{get_param: SshFirewallAllowAll}, true]} firewall_rules: '003 accept ssh from all': proto: 'tcp' dport: 22 extras: ensure: {if: [ssh_firewall_allow_all, 'present', 'absent']}", if: - {get_param: SshFirewallAllowAll} - firewall_rules: '003 accept ssh from all': proto: 'tcp' dport: 22 - firewall_rules: '003 accept ssh from all': proto: 'tcp' dport: 22 extras: ensure: 'absent',9,12
openstack%2Fkolla~stable%2Fstein~I6f6b32e3858f793a4674967e3fa3fcec87d93e6e,openstack/kolla,stable/stein,I6f6b32e3858f793a4674967e3fa3fcec87d93e6e,Bump OpenStack versions for Stein,MERGED,2019-12-20 15:01:06.000000000,2020-01-02 13:03:10.000000000,2020-01-02 13:01:26.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-20 15:01:06.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/56772b04eaeb901cc3e796974a79a512cfa4cbce', 'message': 'Bump OpenStack versions for Stein\n\nChange-Id: I6f6b32e3858f793a4674967e3fa3fcec87d93e6e\n'}]",0,700184,56772b04eaeb901cc3e796974a79a512cfa4cbce,10,4,1,15197,,,0,"Bump OpenStack versions for Stein

Change-Id: I6f6b32e3858f793a4674967e3fa3fcec87d93e6e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/84/700184/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,56772b04eaeb901cc3e796974a79a512cfa4cbce,," 'neutron-14.0.4.tar.gz')},"," 'neutron-14.0.3.tar.gz')},",1,1
openstack%2Fironic-python-agent-builder~master~I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e,openstack/ironic-python-agent-builder,master,I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e,DNM try Restart=on-failure for dhcp-all-interfaces,ABANDONED,2019-11-28 12:19:53.000000000,2020-01-02 13:00:18.000000000,,"[{'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-11-28 12:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/b85bf46d577848c5d46b12f1ca7148a2c35adee6', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}, {'number': 2, 'created': '2019-11-28 14:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/f679f0cf3b462ba1bdea50f6cbe41d947bab5831', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}, {'number': 3, 'created': '2019-11-28 16:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/d84855399b8221e8625e8429499dd9117aa1ed19', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}, {'number': 4, 'created': '2019-11-28 16:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/35d5546ec46f29914e622f2a1bed6b551ea3c509', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}, {'number': 5, 'created': '2019-11-29 13:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/cc05f35f21d223b371e2a7d6c098171aecf890ef', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}, {'number': 6, 'created': '2019-11-29 16:31:53.000000000', 'files': ['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/5e3fd89c2c6177f9853f339d6b47278f26e07168', 'message': 'DNM try Restart=on-failure for dhcp-all-interfaces\n\nChange-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e\n'}]",0,696530,5e3fd89c2c6177f9853f339d6b47278f26e07168,13,2,6,10239,,,0,"DNM try Restart=on-failure for dhcp-all-interfaces

Change-Id: I5552f22cb45fe813b1ece7fea9afdca95a6d9e8e
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/30/696530/2 && git format-patch -1 --stdout FETCH_HEAD,['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'],1,b85bf46d577848c5d46b12f1ca7148a2c35adee6,test,UNIT=/usr/lib/systemd/system/dhcp-interface@.service sed -i '/\[Service\]/a\nRestart=on-failure' $UNIT cat $UNIT ,,4,0
openstack%2Ftempest~master~I82c7899a32bee0e714e71d703195085e10ea224f,openstack/tempest,master,I82c7899a32bee0e714e71d703195085e10ea224f,Tempest cleanup: improve iterating over projects,MERGED,2019-11-13 12:56:09.000000000,2020-01-02 12:56:39.000000000,2020-01-02 12:53:54.000000000,"[{'_account_id': 5690}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 12393}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 26458}, {'_account_id': 30742}]","[{'number': 1, 'created': '2019-11-13 12:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/652186e84edcbbca1983951875da07a6810c9d46', 'message': ""Tempest cleanup: improve iterating over projects\n\nCurrently cleanup iterates over projects and deletes all resources\ntied to a particular project. However, most of the resources can be\ndeleted all at once without iteration over the projects.\nThis will fix the mentioned bug and also make the tool much more\nefficient as we'll avoid many iterations and queries.\n\nCloses-bug: #1830943\nChange-Id: I82c7899a32bee0e714e71d703195085e10ea224f\n""}, {'number': 2, 'created': '2019-12-13 07:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dbe18b45dc59bce47dcb5ec2a8467361b1d670e0', 'message': ""Tempest cleanup: improve iterating over projects\n\nCurrently cleanup iterates over projects and deletes all resources\ntied to a particular project. However, most of the resources can be\ndeleted all at once without iteration over the projects.\nThis will fix the mentioned bug and also make the tool much more\nefficient as we'll avoid many iterations and queries.\n\nCloses-bug: #1830943\nChange-Id: I82c7899a32bee0e714e71d703195085e10ea224f\n""}, {'number': 3, 'created': '2019-12-13 11:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a282e03e369f023cdbb198dfea7be6b089ce9ab', 'message': ""Tempest cleanup: improve iterating over projects\n\nCurrently cleanup iterates over projects and deletes all resources\ntied to a particular project. However, most of the resources can be\ndeleted all at once without iteration over the projects.\nThis will fix the mentioned bug and also make the tool much more\nefficient as we'll avoid many iterations and queries.\n\nCloses-bug: #1830943\nChange-Id: I82c7899a32bee0e714e71d703195085e10ea224f\n""}, {'number': 4, 'created': '2019-12-20 09:01:23.000000000', 'files': ['tempest/cmd/cleanup.py', 'tempest/cmd/cleanup_service.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/56c0b2be78faea800af73596e868bdf0969b0544', 'message': ""Tempest cleanup: improve iterating over projects\n\nCurrently cleanup iterates over projects and deletes all resources\ntied to a particular project. However, most of the resources can be\ndeleted all at once without iteration over the projects.\nThis will fix the mentioned bug and also make the tool much more\nefficient as we'll avoid many iterations and queries.\n\nCloses-bug: #1830943\nChange-Id: I82c7899a32bee0e714e71d703195085e10ea224f\n""}]",4,694064,56c0b2be78faea800af73596e868bdf0969b0544,25,9,4,22873,,,0,"Tempest cleanup: improve iterating over projects

Currently cleanup iterates over projects and deletes all resources
tied to a particular project. However, most of the resources can be
deleted all at once without iteration over the projects.
This will fix the mentioned bug and also make the tool much more
efficient as we'll avoid many iterations and queries.

Closes-bug: #1830943
Change-Id: I82c7899a32bee0e714e71d703195085e10ea224f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/694064/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/cleanup.py', 'tempest/cmd/cleanup_service.py']",2,652186e84edcbbca1983951875da07a6810c9d46,region-cleanup," """"""Returns list of project service classes. The list contains services whose resources need to be deleted prior, the project they are associated with, deletion. The resources cannot be most likely deleted after the project is deleted first. """""" project_services = [] # TODO(gmann): Tempest should provide some plugin hook for cleanup # script extension to plugin tests also. if IS_NOVA: project_services.append(NovaQuotaService) if IS_CINDER: project_services.append(VolumeQuotaService) return project_services def get_project_related_cleanup_services(): """"""Returns list of project related classes. The list contains services whose resources are associated with a project, however, their deletion is possible also after the project is deleted first. """"""", project_services.append(NovaQuotaService) project_services.append(VolumeQuotaService),33,2
openstack%2Ftripleo-validations~master~Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c,openstack/tripleo-validations,master,Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c,Fix upper and lower constraints,MERGED,2019-12-17 20:52:21.000000000,2020-01-02 12:56:29.000000000,2020-01-02 12:55:02.000000000,"[{'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-12-17 20:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/8ed6723be8f794e5f9e9e0d01472dfa39e4ed1af', 'message': 'Fix tenancy lower constrain\n\nMistral is requiring a newer version of tenacity than what we define. We\nneed to increated our lower constraint to 5.0.1\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 2, 'created': '2019-12-17 21:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/81708356e283cbd077b4519fe102c7ff2962f9b9', 'message': 'Fix lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 3, 'created': '2019-12-17 22:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/a4a6dd7991c9335470afbcfa23a4962f1d2d65e3', 'message': 'Fix lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 4, 'created': '2019-12-17 22:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/777f723f658bff4a491a390c015e7014dcbde245', 'message': 'Fix lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 5, 'created': '2019-12-17 22:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/d2bef6ce93bb31acd7230ded9df16a2b856525ee', 'message': 'Fix lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 6, 'created': '2019-12-17 22:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1d5452e4ecfcf9fbe6d0d9185635890875d6eccf', 'message': 'Fix lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 7, 'created': '2019-12-18 09:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/710955a00596108539d2f02101f6c357bd9dd3b4', 'message': 'Fix upper and lower constraints\n\nMistral has some newer lower requirements.\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 8, 'created': '2019-12-18 10:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/48a622bbde259cb62de870c59133e1ff80da479a', 'message': 'Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Added back the upper contraints file in the tox.ini install_command\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n'}, {'number': 9, 'created': '2019-12-19 09:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/15e55af1c87de7749b6e5261a2ecaea274da1fb2', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 10, 'created': '2019-12-23 17:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1bf40f46a0ea0da63398a5c7c69cbf1cdafbd2f4', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 11, 'created': '2019-12-30 13:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/f9dc0c55fef79d0b82c9876805460c6cabdcc048', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 12, 'created': '2019-12-30 13:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/fd658f41f0ed174dd5aebfc78d0aac8a332411fd', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 13, 'created': '2019-12-30 14:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/f1f63e7d4bc119d97527339d068ccfcc5b391b55', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 14, 'created': '2019-12-30 15:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/c1029bbffc33ea1dfb4962403e33f552422e593d', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 15, 'created': '2019-12-30 15:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/09fd79393c46a628713aaca95825a4eb68f7613d', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 16, 'created': '2019-12-30 15:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/3723b6f8291fec24124e745035b1174d561ea222', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 17, 'created': '2019-12-30 16:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/df826a4b058dca7f38d2da9ad9bb4a609952dbb9', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}, {'number': 18, 'created': '2019-12-30 16:24:36.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/9b69f08a6f07785e11b3166df2f8c37ce1b005be', 'message': ""Fix upper and lower constraints\n\n- Mistral has some newer lower requirements.\n- Adds the upper contraints file in the 'deps' tox attribute.\n- Removes 'VIRTUAL_ENV' environment variable, which is useless here.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nCo-Authored-By: Daniel Bengtsson <dbengt@redhat.com>\nCo-Authored-By: Herv Beraud <hberaud@redhat.com>\n\nChange-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c\n""}]",2,699499,9b69f08a6f07785e11b3166df2f8c37ce1b005be,35,6,18,14985,,,0,"Fix upper and lower constraints

- Mistral has some newer lower requirements.
- Adds the upper contraints file in the 'deps' tox attribute.
- Removes 'VIRTUAL_ENV' environment variable, which is useless here.

Co-Authored-By: Alex Schultz <aschultz@redhat.com>
Co-Authored-By: Daniel Bengtsson <dbengt@redhat.com>
Co-Authored-By: Herv Beraud <hberaud@redhat.com>

Change-Id: Ia0c67c5980a7e6bc9006a24be775ea6fb815d23c
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/99/699499/2 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,8ed6723be8f794e5f9e9e0d01472dfa39e4ed1af,fix-lower-constrains,tenacity==5.0.1,tenacity==4.9.0,1,1
openstack%2Ftempest~master~I2c978a7b2151b37bb0a224bafd1be490f04950ee,openstack/tempest,master,I2c978a7b2151b37bb0a224bafd1be490f04950ee,Extend cleanup CLI to delete regions,MERGED,2019-11-12 11:39:19.000000000,2020-01-02 12:55:18.000000000,2020-01-02 12:53:52.000000000,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 30674}, {'_account_id': 30742}]","[{'number': 1, 'created': '2019-11-12 11:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c20f0ea721a83fac69a9a566505e5dea8d8bddfc', 'message': 'Delete regions (WIP)\n\nRegionService class enables deletion of regions which were\nneglected by tempest cleanup before.\n\nChange-Id: I2c978a7b2151b37bb0a224bafd1be490f04950ee\n'}, {'number': 2, 'created': '2019-11-18 10:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d012bcc89e44791670d8ca6e7bb5301e8f5d4e30', 'message': 'Delete regions\n\nRegionService class enables deletion of regions which were\nneglected by tempest cleanup before.\n\nChange-Id: I2c978a7b2151b37bb0a224bafd1be490f04950ee\nCloses-Bug: #1848672\n'}, {'number': 3, 'created': '2019-12-13 11:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ebcece175872b379e9a6383f4f563fc0fcef0ff5', 'message': 'Delete regions\n\nRegionService class enables deletion of regions which were\nneglected by tempest cleanup before.\n\nChange-Id: I2c978a7b2151b37bb0a224bafd1be490f04950ee\nCloses-Bug: #1848672\n'}, {'number': 4, 'created': '2019-12-20 00:53:09.000000000', 'files': ['tempest/cmd/cleanup_service.py', 'tempest/tests/cmd/test_cleanup_services.py', 'releasenotes/notes/Extend-cleanup-CLI-to-delete-regions-9f1dbda2c8de12e2.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3b1311f604d0beeadd17c031d314c080e3dc64c0', 'message': 'Extend cleanup CLI to delete regions\n\nRegionService class enables deletion of regions which were\nneglected by tempest cleanup before.\n\nChange-Id: I2c978a7b2151b37bb0a224bafd1be490f04950ee\nCloses-Bug: #1848672\n'}]",1,693818,3b1311f604d0beeadd17c031d314c080e3dc64c0,25,7,4,30674,,,0,"Extend cleanup CLI to delete regions

RegionService class enables deletion of regions which were
neglected by tempest cleanup before.

Change-Id: I2c978a7b2151b37bb0a224bafd1be490f04950ee
Closes-Bug: #1848672
",git fetch https://review.opendev.org/openstack/tempest refs/changes/18/693818/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cmd/cleanup_service.py', 'tempest/tests/cmd/test_cleanup_services.py']",2,c20f0ea721a83fac69a9a566505e5dea8d8bddfc,region-cleanup," ""subnetpools"": {u'8acf64c1-43fc': u'saved-subnet-pool'}, ""regions"": {}class TestRegionService(BaseCmdServiceTests): service_class = 'RegionService' service_name = 'regions' response = { ""regions"": [{ ""parent_region_id"": None, ""id"": ""RegionOne"", ""links"": { ""self"": ""http://10.0.145.61:5000/v3/regions/RegionOne"" }, ""description"": """" }], ""links"": { ""self"": ""http://10.0.145.61:5000/v3/regions"", ""next"": None, ""previous"": None } } def test_delete_pass(self): delete_mock = [(self.get_method, self.response, 200), (self.delete_method, None, 204), (self.log_method, ""exception"", None)] self._test_delete(delete_mock) def test_delete_fail(self): delete_mock = [(self.get_method, self.response, 200), (self.delete_method, 'error', None), (self.log_method, ""exception"", None)] self._test_delete(delete_mock, fail=True) def test_dry_run(self): dry_mock = [(self.get_method, self.response, 200), (self.delete_method, ""delete"", None)] self._test_dry_run_true(dry_mock) def test_save_state(self): self._test_saved_state_true([(self.get_method, self.response, 200)]) "," ""subnetpools"": {u'8acf64c1-43fc': u'saved-subnet-pool'}",83,1
openstack%2Fironic-ui~master~I6af7b37f310a8c76155c9686a78608cde0adccd8,openstack/ironic-ui,master,I6af7b37f310a8c76155c9686a78608cde0adccd8,translation: drop babel extractor definitions,MERGED,2019-12-26 17:08:03.000000000,2020-01-02 12:25:06.000000000,2020-01-02 12:23:40.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:08:03.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/412c3c87e91df08241f4a7526a31a83714f6e534', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I6af7b37f310a8c76155c9686a78608cde0adccd8\n'}]",0,700628,412c3c87e91df08241f4a7526a31a83714f6e534,12,4,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I6af7b37f310a8c76155c9686a78608cde0adccd8
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/28/700628/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,412c3c87e91df08241f4a7526a31a83714f6e534,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fproject-config~master~I514198005cc4a833319cacd8917a5ce75177e783,openstack/project-config,master,I514198005cc4a833319cacd8917a5ce75177e783,Move jjb jobs in-repo,MERGED,2019-12-22 16:50:17.000000000,2020-01-02 11:01:32.000000000,2020-01-02 11:01:31.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 16:50:17.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f90feba3a8b8ab944de130c11c6f588863f6dfac', 'message': 'Move jjb jobs in-repo\n\nremove jobs that are in jenkins-job-builder repository now.\n\nDepends-On: https://review.opendev.org/700355\nChange-Id: I514198005cc4a833319cacd8917a5ce75177e783\n'}]",0,700356,f90feba3a8b8ab944de130c11c6f588863f6dfac,9,4,1,6547,,,0,"Move jjb jobs in-repo

remove jobs that are in jenkins-job-builder repository now.

Depends-On: https://review.opendev.org/700355
Change-Id: I514198005cc4a833319cacd8917a5ce75177e783
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/700356/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,f90feba3a8b8ab944de130c11c6f588863f6dfac,jjb-publishing,, - docs-on-readthedocs - openstack-python-jobs-no-constraints - openstack-python35-jobs-no-constraints vars: rtd_webhook_id: '47271' check: jobs: - tox-cover,0,8
openstack%2Fironic-python-agent~master~I6a3b5a31eda66b122a310119539fad6f8600ed80,openstack/ironic-python-agent,master,I6a3b5a31eda66b122a310119539fad6f8600ed80,Remove deprecated ironic-agent element,MERGED,2019-12-12 07:14:08.000000000,2020-01-02 10:58:19.000000000,2020-01-02 10:56:55.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-12 07:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7427caaafe40814e7b34806e5178659db43e437f', 'message': 'Remove deprecated ironic-agent element\n\nironic-agent is deprecated. ironic-python-agent-ramdisk is the new\nelement to build a ramdisk with ironic-python-agent\n\nChange-Id: I6a3b5a31eda66b122a310119539fad6f8600ed80\n'}, {'number': 2, 'created': '2019-12-27 05:15:44.000000000', 'files': ['doc/source/admin/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/22ab827796406bd782afacdf2c3e47383383c8f4', 'message': 'Remove deprecated ironic-agent element\n\nironic-agent is deprecated. Also replace disk-image-create\nwith ironic-python-agent-builder.\n\nChange-Id: I6a3b5a31eda66b122a310119539fad6f8600ed80\n'}]",5,698637,22ab827796406bd782afacdf2c3e47383383c8f4,15,5,2,10206,,,0,"Remove deprecated ironic-agent element

ironic-agent is deprecated. Also replace disk-image-create
with ironic-python-agent-builder.

Change-Id: I6a3b5a31eda66b122a310119539fad6f8600ed80
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/37/698637/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/troubleshooting.rst'],1,7427caaafe40814e7b34806e5178659db43e437f,ipa_builder, disk-image-create -o /path/to/custom-ipa debian ironic-python-agent-ramdisk devuser, disk-image-create -o /path/to/custom-ipa debian ironic-agent devuser,1,1
openstack%2Fproject-config~master~I803dc997f713896f557ccd22ff358adb28c9bf6b,openstack/project-config,master,I803dc997f713896f557ccd22ff358adb28c9bf6b,REmove double docs jobs from jjb,MERGED,2019-12-22 16:42:47.000000000,2020-01-02 10:56:59.000000000,2020-01-02 10:54:21.000000000,"[{'_account_id': 1004}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 16:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/395313d0d9c28c12c6662eb55242af6c6d8d374f', 'message': 'REmove double docs jobs from jjb\n\njenkins-job-builder has two docs templates, since\nI5cbf7b5cfea349a0bd72d2abee40710175cf5b2f as newest change added\ndocs-on-readthedocs, remove the older publish-tox-docs-infra, jjb is not\nreally part of infra anymore and publishing to rtd works fine.\n\nChange-Id: I803dc997f713896f557ccd22ff358adb28c9bf6b\n'}, {'number': 2, 'created': '2019-12-22 16:47:06.000000000', 'files': ['docs-site/infra-documents.yaml', 'zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5d1f5851bfcf782921904a53ad7f7b1a38dcac68', 'message': 'REmove double docs jobs from jjb\n\njenkins-job-builder has two docs templates, since\nI5cbf7b5cfea349a0bd72d2abee40710175cf5b2f as newest change added\ndocs-on-readthedocs, remove the older publish-tox-docs-infra, jjb is not\nreally part of infra anymore and publishing to rtd works fine.\n\nRemove also link to it from our index page.\n\nChange-Id: I803dc997f713896f557ccd22ff358adb28c9bf6b\n'}]",0,700353,5d1f5851bfcf782921904a53ad7f7b1a38dcac68,9,3,2,6547,,,0,"REmove double docs jobs from jjb

jenkins-job-builder has two docs templates, since
I5cbf7b5cfea349a0bd72d2abee40710175cf5b2f as newest change added
docs-on-readthedocs, remove the older publish-tox-docs-infra, jjb is not
really part of infra anymore and publishing to rtd works fine.

Remove also link to it from our index page.

Change-Id: I803dc997f713896f557ccd22ff358adb28c9bf6b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/700353/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,395313d0d9c28c12c6662eb55242af6c6d8d374f,jjb-publishing,, - publish-tox-docs-infra,0,1
openstack%2Ftripleo-validations~master~I85d09955e839bab35cc06d2f0906f3012c8a1aa9,openstack/tripleo-validations,master,I85d09955e839bab35cc06d2f0906f3012c8a1aa9,Add a validation to fail if a Ceph dependency is not installed,MERGED,2019-12-05 11:52:22.000000000,2020-01-02 10:54:41.000000000,2019-12-19 17:12:04.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7353}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-05 11:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/828373a272003a37b298b9da059266edf3230396', 'message': 'Add validation to make the deployment fail if lvm2 is not installed\n\nWhen the overcloud is deployed with Ceph we need to install lvm2\npackage on the nodes.\nIf this package is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 2, 'created': '2019-12-05 11:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/802ff92c2764110dacb717ffa1960c0a5e8f71db', 'message': '[WIP] Add validation to make the deployment fail if lvm2 is not installed\n\nWhen the overcloud is deployed with Ceph we need to install lvm2\npackage on the nodes.\nIf this package is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 3, 'created': '2019-12-05 12:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/854f246ccc8acd72802af0216df98e356910e4b3', 'message': '[WIP] Add validation to make the deployment fail if lvm2 is not installed\n\nWhen the overcloud is deployed with Ceph we need to install lvm2\npackage on the nodes.\nIf this package is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 4, 'created': '2019-12-05 12:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/abf39d429da6db3b65da7cea2df73f60b9e7cfc4', 'message': 'Add validation to make the deployment fail if lvm2 is not installed\n\nWhen the overcloud is deployed with Ceph we need to install lvm2\npackage on the nodes.\nIf this package is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 5, 'created': '2019-12-05 12:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/28b7baeca1fc4bcd87813641d6bd1819e682d45d', 'message': 'Add validation to make the deployment fail if a ceph deps is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 6, 'created': '2019-12-05 12:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/c5fc8f60fea5dd3d296c1e98fd1dbc73790518d2', 'message': 'Add validation to make the deployment fail if a ceph deps is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 7, 'created': '2019-12-05 13:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/50e28f9bd21fd01574f8aae421319a474ba1c84f', 'message': 'Add validation to make the deployment fail if a ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 8, 'created': '2019-12-05 13:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/cd17e5df666353199405f401014f3df25e78bfd4', 'message': 'Add a validation to fail if a Ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 9, 'created': '2019-12-09 10:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/91e6e901d17c46cfa7529e2e6741551e98e3727a', 'message': 'Add a validation to fail if a Ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nCloses-Bug: 1855692\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 10, 'created': '2019-12-11 08:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/17a54c1bf9ea02f79854c368857f82573cbc0f53', 'message': 'Add a validation to fail if a Ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nCloses-Bug: 1855692\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 11, 'created': '2019-12-12 14:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/248513467d54bea5381c63e073719466f95f9014', 'message': 'Add a validation to fail if a Ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nCloses-Bug: 1855692\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}, {'number': 12, 'created': '2019-12-16 20:17:43.000000000', 'files': ['playbooks/ceph-dependencies-installed.yaml', 'roles/ceph/tasks/ceph-dependencies-installed.yaml', 'roles/ceph/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/7fe786039b77c03fdd984e161b7aeccb78be9f1e', 'message': 'Add a validation to fail if a Ceph dependency is not installed\n\nWhen the overcloud is deployed with Ceph we need to install all the\nceph dependencies on the overcloud nodes.\nIf a ceph dependency is missing, a warning message is displayed and we\ncan also let the playbook fail setting the related boolean.\nFurthermore, if the package is found, the playbook check if a new\nversion is available.\n\nCloses-Bug: 1855692\nChange-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9\n'}]",9,697453,7fe786039b77c03fdd984e161b7aeccb78be9f1e,39,10,12,25402,,,0,"Add a validation to fail if a Ceph dependency is not installed

When the overcloud is deployed with Ceph we need to install all the
ceph dependencies on the overcloud nodes.
If a ceph dependency is missing, a warning message is displayed and we
can also let the playbook fail setting the related boolean.
Furthermore, if the package is found, the playbook check if a new
version is available.

Closes-Bug: 1855692
Change-Id: I85d09955e839bab35cc06d2f0906f3012c8a1aa9
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/53/697453/7 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/ceph-lvm2-installed.yaml', 'roles/ceph/tasks/ceph-lvm2-installed.yaml', 'roles/ceph/defaults/main.yml']",3,828373a272003a37b298b9da059266edf3230396,ceph_lvm_package,fail_without_lvm2: false,,45,1
openstack%2Fkolla-ansible~master~I27eb5243eedb10260c49524a8cb36acc7459a7d2,openstack/kolla-ansible,master,I27eb5243eedb10260c49524a8cb36acc7459a7d2,"Fix ""deploy mariadb failed to reach primary node"" - short edition",ABANDONED,2020-01-02 08:48:19.000000000,2020-01-02 10:52:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-02 08:48:19.000000000', 'files': ['ansible/roles/mariadb/templates/galera.cnf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/89af339e8b42056d72faf6869e91220f543818e7', 'message': 'Fix ""deploy mariadb failed to reach primary node"" - short edition\n\nChange-Id: I27eb5243eedb10260c49524a8cb36acc7459a7d2\nCo-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nCloses-Bug: #1856532\n'}]",0,700875,89af339e8b42056d72faf6869e91220f543818e7,3,1,1,30491,,,0,"Fix ""deploy mariadb failed to reach primary node"" - short edition

Change-Id: I27eb5243eedb10260c49524a8cb36acc7459a7d2
Co-Authored-By: Jeffrey Zhang <jeffrey.zhang@99cloud.net>
Closes-Bug: #1856532
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/75/700875/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/mariadb/templates/galera.cnf.j2'],1,89af339e8b42056d72faf6869e91220f543818e7,bug/1856532,{% if api_address_family == 'ipv6' and kolla_base_distro == 'centos' -%} # FIXME(jeffrey4l): Revert when using C8 (CentOS+Ussuri) # Use [::] to avoid galera issue. # for more info see https://github.com/codership/galera/issues/534#issuecomment-472607544 wsrep_provider_options=gmcast.listen_addr=tcp://[::]:{{ mariadb_wsrep_port }};ist.recv_addr={{ api_interface_address | put_address_in_context('url') }}:{{ mariadb_ist_port }} {% else -%}{% endif -%},,7,0
openstack%2Fironic~master~Ia69a0760c7b206f9779870b635bb4465a8105e75,openstack/ironic,master,Ia69a0760c7b206f9779870b635bb4465a8105e75,[DNM] testing tox with Python 3.8,ABANDONED,2019-12-19 10:35:03.000000000,2020-01-02 10:32:08.000000000,,"[{'_account_id': 10118}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-19 10:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/83d114a0bfef12e090af106605f8f2ff54e801db', 'message': '[DNM] testing tox with Python 3.8\n\nBased on configuration from https://review.opendev.org/693401\n\nChange-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75\n'}, {'number': 2, 'created': '2019-12-19 11:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0c899f223fe322a88c7cdd3f81b08a61bddd583f', 'message': '[DNM] testing tox with Python 3.8\n\nBased on configuration from https://review.opendev.org/693401\n\nChange-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75\n'}, {'number': 3, 'created': '2019-12-19 11:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52732deddf823e9eeafbd0ffa009144c51a2bbe7', 'message': '[DNM] testing tox with Python 3.8\n\nBased on configuration from https://review.opendev.org/693401\n\nChange-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75\n'}, {'number': 4, 'created': '2019-12-19 11:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/968199779f43893e2e3617180fc90f2a790c4cc6', 'message': '[DNM] testing tox with Python 3.8\n\nBased on configuration from https://review.opendev.org/693401\n\nChange-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75\n'}, {'number': 5, 'created': '2019-12-19 11:42:29.000000000', 'files': ['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/94836d2a27921adf367a37c12f90195dd7f16249', 'message': '[DNM] testing tox with Python 3.8\n\nBased on configuration from https://review.opendev.org/693401\n\nChange-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75\n'}]",0,699950,94836d2a27921adf367a37c12f90195dd7f16249,11,3,5,23851,,,0,"[DNM] testing tox with Python 3.8

Based on configuration from https://review.opendev.org/693401

Change-Id: Ia69a0760c7b206f9779870b635bb4465a8105e75
",git fetch https://review.opendev.org/openstack/ironic refs/changes/50/699950/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml']",2,83d114a0bfef12e090af106605f8f2ff54e801db,py38-tox-test, - openstack-tox-py38 - openstack-tox-py38, templates: - check-requirements - openstack-cover-jobs - openstack-lower-constraints-jobs - openstack-python3-ussuri-jobs - periodic-stable-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 - ironic-tox-unit-with-driver-libs-python3 - ironic-standalone - ironic-tempest-functional-python3 - ironic-grenade-dsvm # Temporary disable voting because of end of cycle CI instability. - ironic-grenade-dsvm-multinode-multitenant: voting: false - ironic-tempest-partition-bios-redfish-pxe - ironic-tempest-partition-uefi-redfish-vmedia - ironic-tempest-ipa-partition-pxe_ipmitool-tinyipa - ironic-tempest-ipa-partition-uefi-pxe_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode: voting: false - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-ipa-partition-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-bfv - ironic-tempest-ipa-partition-uefi-pxe-grub2 # Non-voting jobs - ironic-tox-bandit: voting: false - ironic-tempest-ipa-wholedisk-bios-pxe_snmp-tinyipa: voting: false - ironic-inspector-tempest: voting: false - ironic-inspector-tempest-managed: voting: false - ironic-inspector-tempest-partition-bios-redfish-vmedia: voting: false - ironic-tempest-ipa-wholedisk-bios-ipmi-direct-dib-centos7: voting: false - bifrost-integration-tinyipa-ubuntu-xenial: voting: false - metalsmith-integration-glance-localboot-centos7: voting: false - ironic-tempest-pxe_ipmitool-postgres: voting: false - ironic-tox-unit-with-driver-libs-python3 - ironic-standalone - ironic-tempest-functional-python3 - ironic-grenade-dsvm # removing from voting due to end of cycle gate instability. # - ironic-grenade-dsvm-multinode-multitenant - ironic-tempest-partition-bios-redfish-pxe - ironic-tempest-partition-uefi-redfish-vmedia - ironic-tempest-ipa-partition-pxe_ipmitool-tinyipa - ironic-tempest-ipa-partition-uefi-pxe_ipmitool-tinyipa # removing from voting due to end of cycle gate instability. # - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-ipa-partition-bios-agent_ipmitool-tinyipa-indirect - ironic-tempest-bfv - ironic-tempest-ipa-partition-uefi-pxe-grub2 experimental: jobs: - ironic-inspector-tempest-discovery-fast-track: voting: false ,30,66
openstack%2Fopenstack-manuals~master~I2a1f768888ea5757038ec25bdfbf903512850961,openstack/openstack-manuals,master,I2a1f768888ea5757038ec25bdfbf903512850961,Imported Translations from Zanata,MERGED,2020-01-02 09:17:40.000000000,2020-01-02 10:15:26.000000000,2020-01-02 09:49:20.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-02 09:17:40.000000000', 'files': ['releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8f04e7bdeb320690e9463135db0c13c5ba114976', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I2a1f768888ea5757038ec25bdfbf903512850961\n'}]",0,700880,8f04e7bdeb320690e9463135db0c13c5ba114976,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I2a1f768888ea5757038ec25bdfbf903512850961
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/700880/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po'],1,8f04e7bdeb320690e9463135db0c13c5ba114976,zanata/translations,"# Jongwon Lee <tothebinaryworld@gmail.com>, 2020. #zanata""POT-Creation-Date: 2019-12-15 11:37+0000\n""""PO-Revision-Date: 2020-01-01 03:48+0000\n""msgid """" ""Improved Pacemaker/Corosync cluster installation and configuration details."" msgstr ""  Pacemaker/Corosync      "" msgid ""Improved the RabbitMQ section."" msgstr ""  RabbitMQ "" ","""POT-Creation-Date: 2019-05-22 15:58+0000\n""""PO-Revision-Date: 2018-11-05 01:27+0000\n""",10,2
openstack%2Fironic~master~I0e69277a841c01298a4680f84c97a59cfd170567,openstack/ironic,master,I0e69277a841c01298a4680f84c97a59cfd170567,change EFI binary filename of configuring pxe installation guide,NEW,2019-12-26 08:08:34.000000000,2020-01-02 09:33:18.000000000,,"[{'_account_id': 10068}, {'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 29071}, {'_account_id': 31456}]","[{'number': 1, 'created': '2019-12-26 08:08:34.000000000', 'files': ['doc/source/install/configure-pxe.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/24a47a0aeff8f6001736217794733e260e9fbb56', 'message': 'change EFI binary filename of configuring pxe installation guide\n\ncorrect the name of the shim bootloader from shim.efi.signed to shimx64.efi.signed\n\nChange-Id: I0e69277a841c01298a4680f84c97a59cfd170567\nTask: 37907\nStory: 2007055\n'}]",6,700599,24a47a0aeff8f6001736217794733e260e9fbb56,13,10,1,31456,,,0,"change EFI binary filename of configuring pxe installation guide

correct the name of the shim bootloader from shim.efi.signed to shimx64.efi.signed

Change-Id: I0e69277a841c01298a4680f84c97a59cfd170567
Task: 37907
Story: 2007055
",git fetch https://review.opendev.org/openstack/ironic refs/changes/99/700599/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/configure-pxe.rst'],1,24a47a0aeff8f6001736217794733e260e9fbb56,story/2007055, sudo cp /usr/lib/shim/shimx64.efi.signed /tftpboot/bootx64.efi, sudo cp /usr/lib/shim/shim.efi.signed /tftpboot/bootx64.efi,1,1
openstack%2Ftripleo-heat-templates~master~I4449c52b954c27e31553230cbdbd0949ae6413d6,openstack/tripleo-heat-templates,master,I4449c52b954c27e31553230cbdbd0949ae6413d6,Try deleting container for failures too,MERGED,2019-12-12 05:29:46.000000000,2020-01-02 08:59:35.000000000,2019-12-17 13:01:21.000000000,"[{'_account_id': 3153}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-12 05:29:46.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2f8964133883a5c795a88b521f2bb30818d448b2', 'message': ""Try deleting container for failures too\n\nWe currently retry when podman run returns with exit code 0 and 2.\nin container-puppet.py. It's possible that container storage bits\nare already created for failure. It's better to delete the container\nand it's storage before retrying.\n\nChange-Id: I4449c52b954c27e31553230cbdbd0949ae6413d6\nRelated-Bug: #1856086\n""}]",2,698622,2f8964133883a5c795a88b521f2bb30818d448b2,21,5,1,8833,,,0,"Try deleting container for failures too

We currently retry when podman run returns with exit code 0 and 2.
in container-puppet.py. It's possible that container storage bits
are already created for failure. It's better to delete the container
and it's storage before retrying.

Change-Id: I4449c52b954c27e31553230cbdbd0949ae6413d6
Related-Bug: #1856086
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/698622/1 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,2f8964133883a5c795a88b521f2bb30818d448b2,, rm_container(uname),,2,0
openstack%2Ftripleo-common~master~Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21,openstack/tripleo-common,master,Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21,Make upload workers faster on processing layers,MERGED,2019-10-08 12:55:44.000000000,2020-01-02 08:19:58.000000000,2019-11-18 23:18:57.000000000,"[{'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 11082}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-08 12:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f16224785ed3448db69ad6de66e6c17208ef2b2d', 'message': 'Track uploaded layers for for workers global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nLower level changes explained:\n* Make workers tracking the global view for the uploaded layers and\n  do not allow taking a lock for such layers. That prevents multiple\n  fetching of the same layer, which also exists in the image-serve\n  files and is ready for post-processing (like cross-linking it).\n* Make locks management universal for objects and move it to the base\n  image uploader class so we could access the global tracking state\n  of the uploaded layers in the _fetch_lock as well.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-10-08 12:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/17138504a8f8cd86087aa191d1a90143efefe442', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nLower level changes explained:\n* Make workers tracking the global view for the uploaded layers and\n  do not allow taking a lock for such layers. That prevents multiple\n  fetching of the same layer, which also exists in the image-serve\n  files and is ready for post-processing (like cross-linking it).\n* Make locks management universal for objects and move it to the base\n  image uploader class so we could access the global tracking state\n  of the uploaded layers in the _fetch_lock as well.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2019-10-08 13:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e2c1a150322b1c94dbdd94a6043dc423a90b8c06', 'message': 'Track uploaded layers for for workers global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nLower level changes explained:\n* Make workers tracking the global view for the uploaded layers and\n  do not allow taking a lock for such layers. That prevents multiple\n  fetching of the same layer, which also exists in the image-serve\n  files and is ready for post-processing (like cross-linking it).\n* Make locks management universal for objects and move it to the base\n  image uploader class so we could access the global tracking state\n  of the uploaded layers in the _fetch_lock as well.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2019-10-08 13:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7ce703ae97921bc2fc0394f018601863e760a5d7', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nLower level changes explained:\n* Make workers tracking the global view for the uploaded layers and\n  do not allow taking a lock for such layers. That prevents multiple\n  fetching of the same layer, which also exists in the image-serve\n  files and is ready for post-processing (like cross-linking it).\n* Make locks management universal for objects and move it to the base\n  image uploader class so we could access the global tracking state\n  of the uploaded layers in the _fetch_lock as well.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2019-10-09 12:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/908c7cd31dd87825b2725a1dd5129c57c19155e2', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers and\ndo not allow taking a lock for such layers. That prevents multiple\nfetching of the same layer, which also exists in the image-serve\nfiles and is ready for post-processing (like cross-linking it).\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 6, 'created': '2019-10-09 13:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/78302f8cfe98053780f873a08162eb5c75cb33ae', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers and\ndo not allow taking a lock for such layers. That prevents multiple\nfetching of the same layer, which also exists in the image-serve\nfiles and is ready for post-processing (like cross-linking it).\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 7, 'created': '2019-10-09 15:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/60ea53506b4e13b701e0031fc36e8436ff5b76d5', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers in the\nfast in-memory cache and do not allow taking a lock for such layers.\nThat prevents multiple fetching of the same layer, which also exists in\nthe image-serve files and is ready for post-processing (like\ncross-linking it). That also speeds up that if-layer-exists check\nexecuted against the in-memory cache firstly.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 8, 'created': '2019-10-09 15:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9f0681e08d30bbe7838930068f4fc2f114dbdde0', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers in the\nfast in-memory cache and do not allow taking a lock for such layers.\nThat prevents multiple fetching of the same layer, which also exists in\nthe image-serve files and is ready for post-processing (like\ncross-linking it). That also speeds up that if-layer-exists check\nexecuted against the in-memory cache firstly.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 9, 'created': '2019-10-09 15:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/18ca6141e1239ac5ca7a1403ddf44eda37ccb100', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers in the\nfast in-memory cache and do not allow taking a lock for such layers.\nThat prevents multiple fetching of the same layer, which also exists in\nthe image-serve files and is ready for post-processing (like\ncross-linking it). That also speeds up that if-layer-exists check\nexecuted against the in-memory cache firstly.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 10, 'created': '2019-10-10 09:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1dd8d2da72acc74fe59ff660dbd1d015112b217d', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into-serve registry\nyet.\n\nMake workers tracking the global view for the uploaded layers in the\nfast in-memory cache and do not allow taking a lock for such layers.\nThat prevents multiple fetching of the same layer, which also exists in\nthe image-serve files and is ready for post-processing (like\ncross-linking it). That also speeds up that if-layer-exists check\nexecuted against the in-memory cache firstly.\n\nAdditionally fix the exit conditions when ImageUploaderThreadException\nneeds to be processed by the locks manager or the caller side: reraise\nit by the locks manager after the retries limit has been reached so that\nthe caller process could react on it. It will wait until the locked\nlayer completed then skipped (ImageUploaderSkippedException), or\nunlocked, or other exception arrives.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 11, 'created': '2019-10-10 13:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1d892f13181692c2c724bdf20cf6e9271dc74ec5', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nMake workers tracking the global view for digests of the uploaded\nlayers in the fast in-memory metadata cache and do not allow taking a\nlock for such layers. That prevents multiple fetching of the same\nlayer, which also exists in the image-serve files and is ready for\npost-processing (like cross-linking it). That also speeds up that\nif-layer-exists check executed against the in-memory cache firstly.\n\nAdditionally fix the exit conditions when ImageUploaderThreadException\nneeds to be processed by the locks manager or the caller side: reraise\nit by the locks manager after the retries limit has been reached so that\nthe caller process could react on it. It will wait until the locked\nlayer completed then skipped (ImageUploaderSkippedException), or\nunlocked, or other exception arrives.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 12, 'created': '2019-10-10 13:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e4cd8e58142cd29cff8d9ff41b946cb03cdb673f', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nMake workers tracking the global view for digests of the uploaded\nlayers in the fast in-memory metadata cache and do not allow taking a\nlock for such layers. That prevents multiple fetching of the same\nlayer, which also exists in the image-serve files and is ready for\npost-processing (like cross-linking it). That also speeds up that\nif-layer-exists check executed against the in-memory cache firstly.\n\nAdditionally fix the exit conditions when ImageUploaderThreadException\nneeds to be processed by the locks manager or the caller side: reraise\nit by the locks manager after the retries limit has been reached so that\nthe caller process could react on it. It will wait until the locked\nlayer completed then skipped (ImageUploaderSkippedException), or\nunlocked, or other exception arrives.\n\nAlso make locks management universal for objects (not only layers\nspecific) - this is needed for follow-up work.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 13, 'created': '2019-10-11 09:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1d914cb5f0030178037d018fda4e24d0577e6eb2', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nThat opptimizes the amount of outbound HTTP requests to registries,\nwhen doing multiple fetching of the same cross-referenced layer\nthat also exists in the image-serve files. That also speeds up the\nif-layer-exists check executed against the in-memory cache\nfirstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 14, 'created': '2019-10-11 12:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/11faa5a1bc7de4c79c0ac72a6a22be289531f4d6', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nThat opptimizes the amount of outbound HTTP requests to registries,\nwhen doing multiple fetching of the same cross-referenced layer\nthat also exists in the image-serve files. That also speeds up the\nif-layer-exists check executed against the in-memory cache\nfirstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 15, 'created': '2019-10-11 13:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bea9d1fc13df0d68d1ef10de03ad5fa735bda0d0', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nThat opptimizes the amount of outbound HTTP requests to registries,\nwhen doing multiple fetching of the same cross-referenced layer\nthat also exists in the image-serve files. That also speeds up the\nif-layer-exists check executed against the in-memory cache\nfirstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 16, 'created': '2019-10-11 13:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b054b1c0941177f110669a617bbf63ac727f748e', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nThat opptimizes the amount of outbound HTTP requests to registries,\nwhen doing multiple fetching of the same cross-referenced layer\nthat also exists in the image-serve files. That also speeds up the\nif-layer-exists check executed against the in-memory cache\nfirstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 17, 'created': '2019-10-14 13:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f478f128a83cddf8afa35c142b3045d175d9decd', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path.\n\nThat opptimizes the amount of outbound HTTP requests to registries,\nwhen doing multiple fetching of the same cross-referenced layer\nthat also exists in the image-serve files. That also speeds up the\nif-layer-exists check executed against the in-memory cache\nfirstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 18, 'created': '2019-10-14 15:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/beac2aa13081897c21d4abcb14223cc5e5f9c380', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nAdditionally fix the waiting & exit conditions in the locks manager\nto really keep retrying until we no longer have collisions.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 19, 'created': '2019-10-14 15:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9f3cf0614638df715221d8a105bc0816c493ffa2', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 20, 'created': '2019-10-14 15:27:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2c7e0f75d26fde3d0e3043ac188c8c4fe65afaeb', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 21, 'created': '2019-10-14 16:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/35a51bee433c23fe9f69164fd58f054452609819', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 22, 'created': '2019-10-15 15:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d5e41cec263689904c0ba80e3d45405cafebf0e9', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nAdditionally, rework waiting for the locks stop colliding into tenacity\nretries issued with a larger period of time 0.5s -> 5s.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 23, 'created': '2019-10-16 13:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e4e6b02e09c68f8213f3c15030c9626780c10f90', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 24, 'created': '2019-10-16 13:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/abba1e8fab8ff974cf5c0973d93a6d6da89b2d7b', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 25, 'created': '2019-10-16 14:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/21af3158cf80456ae60678a704d34484d01cf3f8', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 26, 'created': '2019-10-17 15:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/820d7bc3a636472ac13547b01666408f9dc4abdc', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nRemove layers locking/unlocking logic as we track the uploaded images\nin the global view as of now and locks no longer have to be maintained\nfor that purpose.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 27, 'created': '2019-10-17 15:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c61d1e825ed4794706bc2bcd1e6dd631c788ea4c', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 28, 'created': '2019-10-18 08:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/022fa64304e599d2dbec01127ad13e2bb57e7244', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 29, 'created': '2019-10-18 10:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dde022f315ddc8e94f8e28eaa00d3b608a6986c4', 'message': 'Track uploaded layers for workers as global view\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 30, 'created': '2019-10-18 12:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0a556bbc986224ae9b29c90f3d625b083de51b2d', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 31, 'created': '2019-10-18 14:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/61ede7beb2a57973a7c709a52b8889e28d4a430e', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 32, 'created': '2019-10-21 09:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a0c93e9a4098779e488603920005cf2827e00036', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nUltimately, that opptimizes the amount of outbound HTTP requests to\nregistries, when doing multiple fetching of the same cross-referenced\nlayer that also exists in the image-serve files. That also speeds up\nthe if-layer-exists check executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 33, 'created': '2019-10-22 10:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cade80e955f732931f711042f55e856b7120992e', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nExtend the dynamic executor type selector for more cases, like when\ncopying layers from a registry to a registry. Given the added\nshared global view, we are no longer limited here to use only\nmulti-threading workers, nor should we longer execute the 1st task\nin the tasks list as a separate (and non-concurrent) job.\n\nAutomatically pick the best possible multi-workers mode as the\nfollowing:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads safe standard dictionary in the shared class\n  namespace to store the global view into uploaded layers of images\n* if it can do MP, pick processlock and the safe (from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n* also apply the dynamic selection if using tripleo CLI\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 34, 'created': '2019-10-22 10:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ba71695591f7c5b453ea45d52d58d501e62dd0c6', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nGiven the added shared global view we should no longer execute the 1st\ntask in the tasks list as a separate (and non-concurrent) job.\n\nAutomatically pick the best possible multi-workers mode as the\nfollowing:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads safe standard dictionary in the shared class\n  namespace to store the global view into uploaded layers of images\n* if it can do MP, pick processlock and the safe (from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n* also apply the dynamic selection if using tripleo CLI\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 35, 'created': '2019-10-22 11:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/03ab116305343e183947fa81a7a73e8e13c0a4ff', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nGiven the added shared global view we should no longer execute the 1st\ntask in the tasks list as a separate (and non-concurrent) job.\n\nAutomatically pick the best possible multi-workers mode as the\nfollowing:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads safe standard dictionary in the shared class\n  namespace to store the global view into uploaded layers of images\n* if it can do MP, pick processlock and the safe (from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n* also apply the dynamic selection if using tripleo CLI\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 36, 'created': '2019-10-22 11:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0b21e87ca81de43b17c63451200841f89ab70187', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nGiven the added shared global view we should no longer execute the 1st\ntask in the tasks list as a separate (and non-concurrent) job.\n\nAutomatically pick the best possible multi-workers mode as the\nfollowing:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads safe standard dictionary in the shared class\n  namespace to store the global view into uploaded layers of images\n* if it can do MP, pick processlock and the safe (from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n* also apply the dynamic selection if using tripleo CLI\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 37, 'created': '2019-10-22 12:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/58d9cb97c64851373c708e198b8d4057ce16cbfe', 'message': ""Track layers for upload workers to not repeat itself\n\nMake image upload workers processing only the 1st time seen layers,\nwhich is ones that have never been uploaded into the image-serve\nregistry yet. Later on, when trying to cross-reference that layer for\nanother images, leverage the in-memory cache of the global view to\nlocate that already processed image, had it been apparently stored\ninto the local registry and got the OS system path. The referenced\nimage name is also stored for the cached metadata of the known layer\nand is used as a complementing method of discovering the source image\nname from URL, when cross linking it with the target image layers.\nThis extends the logic built around image_layers.\n\nGiven the added shared global view we should no longer execute the 1st\ntask in the tasks list as a separate (and non-concurrent) job.\n\nAutomatically pick the best possible multi-workers mode as the\nfollowing:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads safe standard dictionary in the shared class\n  namespace to store the global view into uploaded layers of images\n* if it can do MP, pick processlock and the safe (from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n* also apply the dynamic selection if using tripleo CLI\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nPartial-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 38, 'created': '2019-10-22 12:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c3e6cbf3fa89ff314f98f05adc45c00ac608c7bc', 'message': ""Make upload workers never re-process image layers\n\nMake image upload workers processing each layer exactly once and\navoid re-fetching it from a registry.\n\nWhen cross-linking that known layer for another images, leverage the\nin-memory cache (the global view among all workers) to locate that\nalready processed image, had it been apparently stored into the local\nregistry and got the OS system path.\n\nThe cross-referenced image name is also stored for the cached metadata\nof that known layer and is used as a complementing method of\ndiscovering the source image name from URL, when cross linking it with\nthe target image layers. This extends the logic built around\nimage_layers.\n\nHaving that global view implemented we may no longer upload the 1st\nimage in the tasks list as a separate (and non-concurrent) job. Neither\nhave we to keep randomizing the images/layers scheduled for uploading\n(leaving reverting of the latter for follow-ups).\n\nBased on the dynamically picked multi-workers mode provide the global\nview state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 39, 'created': '2019-10-22 13:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6ba2e7a675224c4484a8ed8526f08a2fc75ea3ef', 'message': ""Make upload workers never re-process image layers\n\nMake image upload workers processing each layer exactly once and\navoid re-fetching it from a registry.\n\nWhen cross-linking that known layer for another images, leverage the\nin-memory cache (the global view among all workers) to locate that\nalready processed image, had it been apparently stored into the local\nregistry and got the OS system path.\n\nThe cross-referenced image name is also stored for the cached metadata\nof that known layer and is used as a complementing method of\ndiscovering the source image name from URL, when cross linking it with\nthe target image layers. This extends the logic built around\nimage_layers.\n\nHaving that global view implemented we may no longer upload the 1st\nimage in the tasks list as a separate (and non-concurrent) job. Neither\nhave we to keep randomizing the images/layers scheduled for uploading\n(leaving reverting of the latter for follow-ups).\n\nBased on the dynamically picked multi-workers mode provide the global\nview state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 40, 'created': '2019-10-22 13:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3e58fa8258b74a7cdd83b4dd374d86da24da9cb9', 'message': ""Make upload workers never re-process image layers\n\nMake image upload workers processing each layer exactly once and\navoid re-fetching it from a registry.\n\nWhen cross-linking that known layer for another images, leverage the\nin-memory cache (the global view among all workers) to locate that\nalready processed image, had it been apparently stored into the local\nregistry and got the OS system path.\n\nThe cross-referenced image name is also stored for the cached metadata\nof that known layer and is used as a complementing method of\ndiscovering the source image name from URL, when cross linking it with\nthe target image layers. This extends the logic built around\nimage_layers.\n\nHaving that global view implemented we may no longer upload the 1st\nimage in the tasks list as a separate (and non-concurrent) job. Neither\nhave we to keep randomizing the images/layers scheduled for uploading\n(leaving reverting of the latter for follow-ups).\n\nBased on the dynamically picked multi-workers mode provide the global\nview state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 41, 'created': '2019-10-23 10:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fa79ad56aba120e9fefbc76d98218384e1c42abf', 'message': ""Make upload workers never re-process image layers\n\nMake image upload workers processing each layer exactly once and\navoid re-fetching it from a registry.\n\nWhen cross-linking that known layer for another images, leverage the\nin-memory cache (the global view among all workers) to locate that\nalready processed image, had it been apparently stored into the local\nregistry and got the OS system path.\n\nThe cross-referenced image name is also stored for the cached metadata\nof that known layer and is used as a complementing method of\ndiscovering the source image name from URL, when cross linking it with\nthe target image layers. This extends the logic built around\nimage_layers.\n\nHaving that global view implemented we may no longer upload the 1st\nimage in the tasks list as a separate (and non-concurrent) job. Neither\nhave we to keep randomizing the images/layers scheduled for uploading\n(leaving reverting of the latter for follow-ups).\n\nBased on the dynamically picked multi-workers mode provide the global\nview state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 42, 'created': '2019-10-25 13:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bd2a6517fe639dda91eee574e02d5cfec412a3d8', 'message': ""Make upload workers never re-process image layers\n\nMake image upload workers processing each layer exactly once and\navoid re-fetching it from a registry.\n\nWhen cross-linking that known layer for another images, leverage the\nin-memory cache (the global view among all workers) to locate that\nalready processed image, had it been apparently stored into the local\nregistry and got the OS system path.\n\nThe cross-referenced image name is also stored for the cached metadata\nof that known layer and is used as a complementing method of\ndiscovering the source image name from URL, when cross linking it with\nthe target image layers. This extends the logic built around\nimage_layers.\n\nHaving that global view implemented we may no longer upload the 1st\nimage in the tasks list as a separate (and non-concurrent) job. Neither\nhave we to keep randomizing the images/layers scheduled for uploading\n(leaving reverting of the latter for follow-ups).\n\nBased on the dynamically picked multi-workers mode provide the global\nview state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that allows never re-fetching the already processed\nlayers, opptimizes the amount of outbound HTTP requests to registries\nissued for the same cross-referenced layer that exists in the local\nimage-serve registry files. That also speeds up the if-layer-exists\ncheck executed against the in-memory cache firstly.\n\nAddititional changes that should be in a single unit of work\n(otherwise it only makes things running much longer, if applied as\nseparate changes):\n\n* Add missing lock handler when locking a layer\n\nThe original change I477219b7dca1e6cfa02a278c55a0cc1a9833d007\nintroduced locking of layers. Later the dynamic split\nI60507eba9884a0660fe269da5ad27b0e57a70ca8 came for the multi-process vs\nmulti-threading execution pools and introduced the lock variable that\nmust be passed through all of the locking-mode (MP/MT) dependent\nplaces to never confuse it with the ongoing SMP work types.\n\nIf we loose that locking mode information, like when fetching\na layer lock, things might (and surely will) go awry. Let's fix that\nand always issue locks and unlocks passing the locking method\ninformation into it.\n\n* Always lock layers being checked for its existance\n\nWhen copying a local layer to registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 43, 'created': '2019-10-25 17:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e215389791171da99666e541f3c9734c2eb6848f', 'message': ""Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nknown path (local or remote) becomes a reference for future\ncross-references, which are also tracked in the global view graph.\n\nUse graf traversal to complete layers cross-linking or cross-repo\nblobs mounting (depending on the local/remote kind of the\nreferencing image).\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nGlobal view (graph) under-the-hood:\n\ngraf:\n  local: #scope\n    layer1:\n     ref: <im1> # the reference image details for the layer1\n     path: <>\n     targets: # other images referencing that layer1, by any scope\n       - im2: <kind> # either local or remote scope\n       - im6: <kind>\n  remote: #scope\n    layer42:\n      ref: <im2>\n      path: <>\n      targets:\n        - im1: <>\n        - im42: <>\n    layer1: # yes, it may be tracked for both scopes as well\n      ...\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAdditionally, always lock layers being checked for its existance.\nWhen copying a local layer to a registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 44, 'created': '2019-10-28 14:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/73da593c7154c998ebc5ff3d2d6ad53751f71c1d', 'message': ""Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nknown path (local or remote) becomes a reference for future\ncross-references, which are also tracked in the global view graph.\n\nUse graf traversal to complete layers cross-linking or cross-repo\nblobs mounting (depending on the local/remote kind of the\nreferencing image).\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nGlobal view (graph) under-the-hood:\n\ngraf:\n  local: #scope\n    layer1:\n     ref: <im1> # the reference image details for the layer1\n     path: <>\n     targets: # other images referencing that layer1, by any scope\n       - im2: <kind> # either local or remote scope\n       - im6: <kind>\n  remote: #scope\n    layer42:\n      ref: <im2>\n      path: <>\n      targets:\n        - im1: <>\n        - im42: <>\n    layer1: # yes, it may be tracked for both scopes as well\n      ...\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAdditionally, always lock layers being checked for its existance.\nWhen copying a local layer to a registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 45, 'created': '2019-10-29 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7a223873780e934d86f2e4676a9c81049b5370d2', 'message': ""Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nknown path (local or remote) becomes a reference for future\ncross-references, which are also tracked in the global view graph.\n\nUse graf traversal to complete layers cross-linking or cross-repo\nblobs mounting (depending on the local/remote kind of the\nreferencing image).\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nGlobal view (graph) under-the-hood:\n\ngraf:\n  local: #scope\n    layer1:\n     ref: <im1> # the reference image details for the layer1\n     path: <>\n     targets: # other images referencing that layer1, by any scope\n       - im2: <kind> # either local or remote scope\n       - im6: <kind>\n  remote: #scope\n    layer42:\n      ref: <im2>\n      path: <>\n      targets:\n        - im1: <>\n        - im42: <>\n    layer1: # yes, it may be tracked for both scopes as well\n      ...\n\nThe resulting graph will be also saved as\n./tripleo-container-image-prepare-graph.json for debugging purposes.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAdditionally, always lock layers being checked for its existance.\nWhen copying a local layer to a registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 46, 'created': '2019-10-29 11:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1fc2f452924631cabf598f9258b905aa59633d50', 'message': ""Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nknown path (local or remote) becomes a reference for future\ncross-references, which are also tracked in the global view graph.\n\nUse graf traversal to complete layers cross-linking or cross-repo\nblobs mounting (depending on the local/remote kind of the\nreferencing image).\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nGlobal view (graph) under-the-hood:\n\ngraf:\n  local: #scope\n    layer1:\n     ref: <im1> # the reference image details for the layer1\n     path: <>\n     targets: # other images referencing that layer1, by any scope\n       - im2: <kind> # either local or remote scope\n       - im6: <kind>\n  remote: #scope\n    layer42:\n      ref: <im2>\n      path: <>\n      targets:\n        - im1: <>\n        - im42: <>\n    layer1: # yes, it may be tracked for both scopes as well\n      ...\n\nThe resulting graph will be also saved as\n./tripleo-container-image-prepare-graph.json for debugging purposes.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAdditionally, always lock layers being checked for its existance.\nWhen copying a local layer to a registry we do not issue a lock\nfor the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nDepends-On: https://review.opendev.org/691851\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 47, 'created': '2019-10-29 15:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8e78c2e1f0440a450c0cb00a24088daca0530717', 'message': ""Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nknown path (local or remote) becomes a reference for future\ncross-references, which are also tracked in the global view graph.\n\nUse graf traversal to complete layers cross-linking or cross-repo\nblobs mounting (depending on the local/remote kind of the\nreferencing image).\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nGlobal view (graph) under-the-hood:\n\ngraf:\n  local: #scope\n    layer1:\n     ref: <im1> # the reference image details for the layer1\n     path: <>\n     targets: # other images referencing that layer1, by any scope\n       - im2: <kind> # either local or remote scope\n       - im6: <kind>\n  remote: #scope\n    layer42:\n      ref: <im2>\n      path: <>\n      targets:\n        - im1: <>\n        - im42: <>\n    layer1: # yes, it may be tracked for both scopes as well\n      ...\n\nThe resulting graph will be also saved as\n./tripleo-container-image-prepare-graph.json for debugging purposes.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAdditionally, acquire locks on all layers being collected for image\nmanifests to avoid data races and always lock layers being checked for\nexistance. When copying a local layer to a registry we do not issue a\nlock for the layer existance check. But we do, when copying a layer\nfrom registry to registry. This doesn't look like a consistent\nbehavior, therefore issue a lock for both cases.\n\nDepends-On: https://review.opendev.org/691851\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 48, 'created': '2019-10-30 16:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5b6c9b2342807de5f716d0a815414e82d80860ea', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 49, 'created': '2019-10-30 16:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ce476f5c346882eed36bcae8de8dff83645d096a', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort) and avoid re-fetching it from a registry.\n\nWhether cross-linking that known layer for another local images, or\nperforming cross-repo blobs patching, leverage the cached in memory\nglobal view shared for all workers to speed-up processing of that\nalready processed layer.\n\nThe 1st time a layer gets uploaded for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nHaving that global view implemented skip uploading the 1st image in\nthe tasks list as a separate (and non-concurrent) job.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview graf state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 50, 'created': '2019-10-31 11:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/35661392dc0e5e8828c72ba3e6f733c7427e8b11', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). When fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore information about already processed layers in global view shared\nfor all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 51, 'created': '2019-10-31 11:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5de01af86413bfe1b4f915f7aa04d9b3ededc869', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). When fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore information about already processed layers in global view shared\nfor all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 52, 'created': '2019-11-04 08:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ec5704fe03d200d934b0efb4621a2bb9431b7d1d', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). When fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore information about already processed layers in global view shared\nfor all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 53, 'created': '2019-11-04 14:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cf47ec67cf20acf464092dcc94ba16526191f7d7', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). When fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore information about already processed layers in global view shared\nfor all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 54, 'created': '2019-11-04 16:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a5b77dc462300ea3822ceb5c81a23709ec419937', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). When fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore information about already processed layers in global view shared\nfor all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* if it cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock and its (safe from data races)\n  Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 55, 'created': '2019-11-05 16:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7cb3b86362b537671e7a8aa0b9ad6f0dfd0a1ec6', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 56, 'created': '2019-11-05 18:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3a89df488dd8ebd1bd36b19213f4cd5140cce3fe', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 57, 'created': '2019-11-06 11:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a62582c3f0d84d3dadbf7cb8c3d599833ecace47', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 58, 'created': '2019-11-06 14:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/445ac2bae8680f797d66b49c30d1af09e1cbe777', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 59, 'created': '2019-11-06 14:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/23ff5f093fc64584ddec8d2f87860d806e9fd63e', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 60, 'created': '2019-11-06 15:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/495d18d9a1798e91050f2f940d49ffe4f554889c', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 61, 'created': '2019-11-06 17:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8c2b9e2e1b323d93dcc7e53411c7466e542fa59a', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 62, 'created': '2019-11-07 11:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/33431d033070dffe6f847d572668456e9b15b4f1', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 63, 'created': '2019-11-07 12:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cfd66a8dd12418e9c773fce5bf8851cf4a59c81f', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 64, 'created': '2019-11-07 12:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cefeb8f930984e81d63e0cd7c8c4b87806f6e9dc', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 65, 'created': '2019-11-07 16:01:40.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/kolla_builder.py', 'tripleo_common/image/image_export.py', 'tripleo_common/utils/locks/processlock.py', 'tripleo_common/utils/image.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/tests/image/test_image_export.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/46f81298948865a2c15c4a5035e95a0c77adb5d5', 'message': 'Make upload workers faster on processing layers\n\nMake upload workers processing image layers only once (as the best\neffort). This also reworks and simplifies locks management for\nindividual tasks now managed for the PythonImageUploader class\nnamespace only.\n\nWhen fetching source layer, cross-link it for the target\nlocal image, whenever that source is already exists. When pushing a\nlayer to a target registry, do not repeat transfering the same data,\nif already pushed earlier for another image.\n\nThe 1st time a layer gets uploaded/fetched for an image, that image and\nits known path (local or remote) becomes a reference for future\ncross-referencing by other images.\n\nStore such information about already processed layers in global view\nshared for all workers to speed-up data transfering jobs they execute.\n\nHaving that global view, uploading the 1st image in the tasks list as a\nseparate (and non-concurrent) job becomes redundant and now will be\nexecuted concurently with other images.\n\nBased on the dynamically picked multi-workers mode, provide the global\nview as a graf with its MP/MT state synchronization as the following:\n\n* use globally shared locking info also containing global layers view\n  for MP-workers. With the shared global view state we can no longer\n  use local locking objects individual for each task.\n* if cannot use multi-process workers, like when executing it via\n  Mistral by monkey patched eventlet greenthreads, choose threadinglock\n  and multi-threads-safe standard dictionary in the shared class\n  namespace to store the global view there\n* if it can do MP, pick processlock also containing a safe from data\n  races Manager().dict() as the global view shared among cooperating OS\n  processes.\n* use that global view in a transparent fashion, provided by a special\n  classmethod proxying access to the internal state shared for workers.\n\nUltimately, all that optimizes:\n\n* completion time\n* re-fetching of the already processed layers\n* local deduplication of layers\n* the amount of outbound HTTP requests to registries\n* if-layer-exists and other internal logic check executed against the\n  in-memory cache firstly.\n\nAs layers locking and unlocking becomes a popular action, reduce the\nnoise of the debug messages it produces.\n\nCloses-bug: #1847225\nRelated-bug: #1844446\n\nChange-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",18,687288,46f81298948865a2c15c4a5035e95a0c77adb5d5,246,12,65,6926,,,0,"Make upload workers faster on processing layers

Make upload workers processing image layers only once (as the best
effort). This also reworks and simplifies locks management for
individual tasks now managed for the PythonImageUploader class
namespace only.

When fetching source layer, cross-link it for the target
local image, whenever that source is already exists. When pushing a
layer to a target registry, do not repeat transfering the same data,
if already pushed earlier for another image.

The 1st time a layer gets uploaded/fetched for an image, that image and
its known path (local or remote) becomes a reference for future
cross-referencing by other images.

Store such information about already processed layers in global view
shared for all workers to speed-up data transfering jobs they execute.

Having that global view, uploading the 1st image in the tasks list as a
separate (and non-concurrent) job becomes redundant and now will be
executed concurently with other images.

Based on the dynamically picked multi-workers mode, provide the global
view as a graf with its MP/MT state synchronization as the following:

* use globally shared locking info also containing global layers view
  for MP-workers. With the shared global view state we can no longer
  use local locking objects individual for each task.
* if cannot use multi-process workers, like when executing it via
  Mistral by monkey patched eventlet greenthreads, choose threadinglock
  and multi-threads-safe standard dictionary in the shared class
  namespace to store the global view there
* if it can do MP, pick processlock also containing a safe from data
  races Manager().dict() as the global view shared among cooperating OS
  processes.
* use that global view in a transparent fashion, provided by a special
  classmethod proxying access to the internal state shared for workers.

Ultimately, all that optimizes:

* completion time
* re-fetching of the already processed layers
* local deduplication of layers
* the amount of outbound HTTP requests to registries
* if-layer-exists and other internal logic check executed against the
  in-memory cache firstly.

As layers locking and unlocking becomes a popular action, reduce the
noise of the debug messages it produces.

Closes-bug: #1847225
Related-bug: #1844446

Change-Id: Ie5ef4045b7e22c06551e886f9f9b6f22c8d4bd21
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/88/687288/6 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/exception.py', 'tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py']",3,f16224785ed3448db69ad6de66e6c17208ef2b2d,bug/1844446,"from tripleo_common.image.exception import ImageUploaderSkippedException uploader_lock = threading.Lock() uploader_lock_info = set() uploaded_layers_info = set() @classmethod def _fetch_lock(cls, obj): if obj in cls.uploader_lock_info: LOG.debug('[%s] object is being fetched by another ' 'thread' % obj) raise ImageUploaderThreadException('object being fetched') if obj in cls.uploaded_layers_info: LOG.debug('[%s] skip locking for an already uploaded ' 'layer' % obj) raise ImageUploaderSkippedException('skipping uploaded layer') LOG.debug('[%s] Locking object' % obj) LOG.debug('[%s] Starting acquire for lock' % obj) with cls.uploader_lock: if obj in cls.uploader_lock_info: LOG.debug('[%s] Collision for lock' % obj) raise ImageUploaderThreadException('conflict detected') LOG.debug('[%s] Acquired for lock' % obj) cls.uploader_lock_info.add(obj) LOG.debug('[%s] Updated lock info' % obj) LOG.debug('[%s] Got lock on object' % obj) @classmethod def _fetch_unlock(cls, obj): LOG.debug('[%s] Unlocking object' % obj) LOG.debug('[%s] Starting acquire for lock' % obj) with cls.uploader_lock: LOG.debug('[%s] Acquired for unlock' % obj) if obj in cls.uploader_lock_info: cls.uploader_lock_info.remove(obj) LOG.debug('[%s] Updated lock info' % obj) LOG.debug('[%s] Released lock on object' % obj) @classmethod def _track_uploaded_layers(cls, layer): with cls.uploader_lock: LOG.debug('[%s] Tracking uploaded layer in the global view' % layer) cls.uploaded_layers_info.add(layer) @classmethod def _check_uploaded_layers(cls, layer): with cls.uploader_lock: if layer in cls.uploaded_layers_info: LOG.debug('[%s] Layer is recognized as already uploaded' % layer) return True else: return False cls._fetch_lock(layer) cls._fetch_unlock(layer) except (ImageUploaderThreadException, ImageUploaderSkippedException): cls._fetch_unlock(layer) # Track it for the global view of all workers # and for the *_layer_exists fast path cls._track_uploaded_layers(layer) cls._fetch_unlock(layer) # Check, if the layer had been already uploaded into the # image-serve registry and is tracked in the global view if cls._check_uploaded_layers(layer): return True "," uploader_lock = threading.Lock() uploader_lock_info = set() @classmethod @tenacity.retry( # Retry until we no longer have collisions retry=tenacity.retry_if_exception_type(ImageUploaderThreadException), wait=tenacity.wait_random_exponential(multiplier=1, max=10) ) def _layer_fetch_lock(cls, layer): if layer in cls.uploader_lock_info: LOG.debug('[%s] Layer is being fetched by another thread' % layer) raise ImageUploaderThreadException('layer being fetched') LOG.debug('[%s] Locking layer' % layer) LOG.debug('[%s] Starting acquire for lock' % layer) with cls.uploader_lock: if layer in cls.uploader_lock_info: LOG.debug('[%s] Collision for lock' % layer) raise ImageUploaderThreadException('layer conflict') LOG.debug('[%s] Acquired for lock' % layer) cls.uploader_lock_info.add(layer) LOG.debug('[%s] Updated lock info' % layer) LOG.debug('[%s] Got lock on layer' % layer) @classmethod def _layer_fetch_unlock(cls, layer): LOG.debug('[%s] Unlocking layer' % layer) LOG.debug('[%s] Starting acquire for lock' % layer) with cls.uploader_lock: LOG.debug('[%s] Acquired for unlock' % layer) if layer in cls.uploader_lock_info: cls.uploader_lock_info.remove(layer) LOG.debug('[%s] Updated lock info' % layer) LOG.debug('[%s] Released lock on layer' % layer) cls._layer_fetch_lock(layer) cls._layer_fetch_unlock(layer) except ImageUploaderThreadException: cls._layer_fetch_unlock(layer) cls._layer_fetch_unlock(layer)",78,42
openstack%2Ftripleo-ci~master~I1de172073613d07fee21cb6a19d1382866dec11c,openstack/tripleo-ci,master,I1de172073613d07fee21cb6a19d1382866dec11c,Remove container build timeout default to 3 hours,ABANDONED,2019-12-30 09:18:37.000000000,2020-01-02 08:10:16.000000000,,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-12-30 09:18:37.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e467224ce97fd357925cd545834a25b473c1ee4f', 'message': 'Remove container build timeout default to 3 hours\n\nThis removes the 7200s (2 hour) timeout from the container build\njob. This means it will inherit from tripleo-ci-base which has\n3 hour timeout. As in related bug, the master container build push\ntimes out and blocks promotions.\n\nChange-Id: I1de172073613d07fee21cb6a19d1382866dec11c\nRelated-Bug: 1857884\n'}]",0,700764,e467224ce97fd357925cd545834a25b473c1ee4f,8,12,1,8449,,,0,"Remove container build timeout default to 3 hours

This removes the 7200s (2 hour) timeout from the container build
job. This means it will inherit from tripleo-ci-base which has
3 hour timeout. As in related bug, the master container build push
times out and blocks promotions.

Change-Id: I1de172073613d07fee21cb6a19d1382866dec11c
Related-Bug: 1857884
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/64/700764/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,e467224ce97fd357925cd545834a25b473c1ee4f,,, timeout: 7200,0,1
openstack%2Fheat~master~I3f9db686c31659437ff4797555e6608986946572,openstack/heat,master,I3f9db686c31659437ff4797555e6608986946572,Eliminate race in CancelUpdateTest,MERGED,2019-10-17 01:20:39.000000000,2020-01-02 07:58:01.000000000,2019-12-18 13:48:48.000000000,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 01:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c12f2014dd34ca278252ec6bacc2ae62b1483370', 'message': 'Eliminate race in CancelUpdateTest\n\nThe purpose of this test is to ensure we can rollback an in-progress\nServer resource with attached ports. However, by cancelling immediately\nwe create a race whereby the stack may be rolled back before we have\neven started updating the stack, in which case we are not testing the\nbehaviour we actually care about. Inserting a delay gives Heat enough\ntime to process the Port and start updating the Server before we cancel\nthe update.\n\nIn some circumstances this could also trigger a race within Heat,\nwhereby the rollback traversal would not block, but the update traversal\nwould retrigger it anyway. This resulted in the stack rollback being\nmarked COMPLETE multiple times, which could also lead to errors in\ndeleting the old raw_template after it had already been removed. The\nlatter have been fixed by separate patches. The race itself should be\naddressed separately.\n\nChange-Id: I3f9db686c31659437ff4797555e6608986946572\nTask: 37199\n'}, {'number': 2, 'created': '2019-10-17 01:47:12.000000000', 'files': ['heat_integrationtests/functional/test_cancel_update.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3b4e0cda282e3df64daf16d64081faa47dd72135', 'message': 'Eliminate race in CancelUpdateTest\n\nThe purpose of this test is to ensure we can rollback an in-progress\nServer resource with attached ports. However, by cancelling immediately\nwe create a race whereby the stack may be rolled back before we have\neven started updating the stack, in which case we are not testing the\nbehaviour we actually care about. Inserting a delay gives Heat enough\ntime to process the Port and start updating the Server before we cancel\nthe update.\n\nIn some circumstances this could also trigger a race within Heat,\nwhereby the rollback traversal would not block, but the update traversal\nwould retrigger it anyway. This resulted in the stack rollback being\nmarked COMPLETE multiple times, which could also lead to errors in\ndeleting the old raw_template after it had already been removed. The\nlatter have been fixed by separate patches. The race itself should be\naddressed separately.\n\nChange-Id: I3f9db686c31659437ff4797555e6608986946572\nTask: 37199\n'}]",0,689063,3b4e0cda282e3df64daf16d64081faa47dd72135,9,2,2,4257,,,0,"Eliminate race in CancelUpdateTest

The purpose of this test is to ensure we can rollback an in-progress
Server resource with attached ports. However, by cancelling immediately
we create a race whereby the stack may be rolled back before we have
even started updating the stack, in which case we are not testing the
behaviour we actually care about. Inserting a delay gives Heat enough
time to process the Port and start updating the Server before we cancel
the update.

In some circumstances this could also trigger a race within Heat,
whereby the rollback traversal would not block, but the update traversal
would retrigger it anyway. This resulted in the stack rollback being
marked COMPLETE multiple times, which could also lead to errors in
deleting the old raw_template after it had already been removed. The
latter have been fixed by separate patches. The race itself should be
addressed separately.

Change-Id: I3f9db686c31659437ff4797555e6608986946572
Task: 37199
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/689063/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_cancel_update.py'],1,c12f2014dd34ca278252ec6bacc2ae62b1483370,,import time # Ensure we start updating the server before rolling back time.sleep(4) ,,5,0
openstack%2Ftripleo-quickstart~master~I8386278663c502ecede9d530681c9d6d95cc8765,openstack/tripleo-quickstart,master,I8386278663c502ecede9d530681c9d6d95cc8765,Add bindep for Fedora 31,ABANDONED,2019-11-27 12:07:35.000000000,2020-01-02 07:20:04.000000000,,"[{'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-27 12:07:35.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/42788fa82cfb6b1afb720c14f55172dee7aa3385', 'message': 'Add bindep for Fedora 31\n\nChange-Id: I8386278663c502ecede9d530681c9d6d95cc8765\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",0,696294,42788fa82cfb6b1afb720c14f55172dee7aa3385,5,3,1,6926,,,0,"Add bindep for Fedora 31

Change-Id: I8386278663c502ecede9d530681c9d6d95cc8765
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/94/696294/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,42788fa82cfb6b1afb720c14f55172dee7aa3385,,# fedora 29/31 python3-libselinux [platform:fedora-29 platform:fedora-31] python3-netaddr [platform:fedora-29 platform:fedora-31] python3-setuptools [platform:fedora-29 platform:fedora-31] python3-virtualenv [platform:fedora-29 platform:fedora-31] python3-pip [platform:fedora-29 platform:fedora-31],# fedora 29 python3-libselinux [platform:fedora-29] python3-netaddr [platform:fedora-29] python3-setuptools [platform:fedora-29] python3-virtualenv [platform:fedora-29] python3-pip [platform:fedora-29],6,6
openstack%2Fpaunch~master~I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5,openstack/paunch,master,I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5,Fix container config IDs lookup by lists vs str,ABANDONED,2019-12-04 13:16:22.000000000,2020-01-02 07:19:23.000000000,,"[{'_account_id': 3153}, {'_account_id': 8297}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-04 13:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/65536c24a6eee638ac746d3f11611fd5fe97b8aa', 'message': 'Fix container config IDs lookup by lists vs str\n\nAs of Train, paunch had been taking its config_id as a list.\nThat was not supported by paunch and fixed by\nId8985795fc8fac5a10466486d404799e9c65cc65.\n\nThe fix was incomplete for minor updates, when the existing\ncontainers had been already created earlier with config id values\npassed as lists. For such cases, paunch was still unable to lookup\nthem (as paunch cannot process multi-value config_ids) therefore\nfailing to delete and recreate the updated containers.\n\nWhen searching containers by a config_id, also look by a\nsingle-item list representation to identify such configs\nfor the minor updates case.\n\nChange-Id: I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5\nCloses-bug: #1855090\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-12-12 11:48:07.000000000', 'files': ['paunch/runner.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/88291ce6f0168f36205b74543aa658f5786f5e86', 'message': 'Fix container config IDs lookup by lists vs str\n\nAs of Train, paunch had been taking its config_id as a list.\nThat was not supported by paunch and fixed by\nId8985795fc8fac5a10466486d404799e9c65cc65.\n\nThe fix was incomplete for minor updates, when the existing\ncontainers had been already created earlier with config id values\npassed as lists. For such cases, paunch was still unable to lookup\nthem (as paunch cannot process multi-value config_ids) therefore\nfailing to delete and recreate the updated containers.\n\nWhen searching containers by a config_id, also look by a\nsingle-item list representation to identify such configs\nfor the minor updates case.\n\nChange-Id: I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5\nCloses-bug: #1855090\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",1,697280,88291ce6f0168f36205b74543aa658f5786f5e86,12,7,2,6926,,,0,"Fix container config IDs lookup by lists vs str

As of Train, paunch had been taking its config_id as a list.
That was not supported by paunch and fixed by
Id8985795fc8fac5a10466486d404799e9c65cc65.

The fix was incomplete for minor updates, when the existing
containers had been already created earlier with config id values
passed as lists. For such cases, paunch was still unable to lookup
them (as paunch cannot process multi-value config_ids) therefore
failing to delete and recreate the updated containers.

When searching containers by a config_id, also look by a
single-item list representation to identify such configs
for the minor updates case.

Change-Id: I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5
Closes-bug: #1855090
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/paunch refs/changes/80/697280/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/runner.py'],1,65536c24a6eee638ac746d3f11611fd5fe97b8aa,," results = cmd_stdout.split() if returncode == 0 and results and results != ['']: return results[0] # NOTE(bogdando): also look by a single-item list representation # to identify such configs for the minor updates case cmd = [ self.cont_cmd, 'ps', '-a', '--filter', 'label=container_name=%s' % container, '--filter', 'label=config_id=[\'%s\']' % cid, '--format', '{{.Names}}' ] (cmd_stdout, cmd_stderr, returncode) = self.execute(cmd, self.log) results = cmd_stdout.split() if returncode == 0 and results and results != ['']: return results[0]", if returncode == 0: names = cmd_stdout.split() if names: return names[0],20,4
openstack%2Fpaunch~stable%2Ftrain~I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5,openstack/paunch,stable/train,I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5,Fix container config IDs lookup by lists vs str,ABANDONED,2019-12-05 14:45:15.000000000,2020-01-02 07:19:11.000000000,,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-05 14:45:15.000000000', 'files': ['paunch/runner.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/fbaf40a9feba15cc3bbc1254afaf600d4cea71fc', 'message': 'Fix container config IDs lookup by lists vs str\n\nAs of Train, paunch had been taking its config_id as a list.\nThat was not supported by paunch and fixed by\nId8985795fc8fac5a10466486d404799e9c65cc65.\n\nThe fix was incomplete for minor updates, when the existing\ncontainers had been already created earlier with config id values\npassed as lists. For such cases, paunch was still unable to lookup\nthem (as paunch cannot process multi-value config_ids) therefore\nfailing to delete and recreate the updated containers.\n\nWhen searching containers by a config_id, also look by a\nsingle-item list representation to identify such configs\nfor the minor updates case.\n\n(cherry picked from commit 65536c24a6eee638ac746d3f11611fd5fe97b8aa)\n\nChange-Id: I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5\nCloses-bug: #1855090\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",0,697487,fbaf40a9feba15cc3bbc1254afaf600d4cea71fc,6,5,1,20775,,,0,"Fix container config IDs lookup by lists vs str

As of Train, paunch had been taking its config_id as a list.
That was not supported by paunch and fixed by
Id8985795fc8fac5a10466486d404799e9c65cc65.

The fix was incomplete for minor updates, when the existing
containers had been already created earlier with config id values
passed as lists. For such cases, paunch was still unable to lookup
them (as paunch cannot process multi-value config_ids) therefore
failing to delete and recreate the updated containers.

When searching containers by a config_id, also look by a
single-item list representation to identify such configs
for the minor updates case.

(cherry picked from commit 65536c24a6eee638ac746d3f11611fd5fe97b8aa)

Change-Id: I70e1add6b8b4d2fdfbcaf4113578e007bb6c3cb5
Closes-bug: #1855090
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/paunch refs/changes/87/697487/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/runner.py'],1,fbaf40a9feba15cc3bbc1254afaf600d4cea71fc,," results = cmd_stdout.split() if returncode == 0 and results and results != ['']: return results[0] # NOTE(bogdando): also look by a single-item list representation # to identify such configs for the minor updates case cmd = [ self.cont_cmd, 'ps', '-a', '--filter', 'label=container_name=%s' % container, '--filter', 'label=config_id=[\'%s\']' % cid, '--format', '{{.Names}}' ] (cmd_stdout, cmd_stderr, returncode) = self.execute(cmd, self.log) results = cmd_stdout.split() if returncode == 0 and results and results != ['']: return results[0]", if returncode == 0: names = cmd_stdout.split() if names: return names[0],20,4
openstack%2Ftripleo-heat-templates~master~If58bf4047425c8bcb47b139514dd7e9bb8ddef1a,openstack/tripleo-heat-templates,master,If58bf4047425c8bcb47b139514dd7e9bb8ddef1a,Align service_name for easy parsing for image prepration,ABANDONED,2019-11-27 13:11:55.000000000,2020-01-02 06:55:27.000000000,,"[{'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-27 13:11:55.000000000', 'files': ['deployment/database/mysql-container-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'roles/ControllerStorageDashboard.yaml', 'environments/services-baremetal/undercloud-gnocchi.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80ef4f1afe4794fe3dc44013b4c7b306473d320c', 'message': 'Align service_name for easy parsing for image prepration\n\nIn mysql and rabbitmq services, replace the actual service_name\ninstead of getting from the base class, so that static file parsing\nwould be easier. Also removed unused services.\n\nChange-Id: If58bf4047425c8bcb47b139514dd7e9bb8ddef1a\n'}]",0,696301,80ef4f1afe4794fe3dc44013b4c7b306473d320c,10,3,1,18575,,,0,"Align service_name for easy parsing for image prepration

In mysql and rabbitmq services, replace the actual service_name
instead of getting from the base class, so that static file parsing
would be easier. Also removed unused services.

Change-Id: If58bf4047425c8bcb47b139514dd7e9bb8ddef1a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/01/696301/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/database/mysql-container-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'environments/services-baremetal/undercloud-gnocchi.yaml', 'roles/ControllerStorageDashboard.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml']",6,80ef4f1afe4794fe3dc44013b4c7b306473d320c,image_prepare_with_enabled_services, service_name: oslo_messaging_rpc," service_name: {get_attr: [RabbitmqBase, role_data, service_name]}",4,10
openstack%2Fheat-tempest-plugin~master~Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983,openstack/heat-tempest-plugin,master,Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983,setup.cfg: Cleanup,NEW,2019-10-12 17:19:09.000000000,2020-01-02 05:44:34.000000000,,"[{'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-10-12 17:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/2569bb6452c7d74e3c487099ff3a1efd285d5d56', 'message': ""setup.cfg: Cleanup\n\n- pbr hasn't need the hook configuration since forever [1]\n- The 'wheel' group is renamed to 'bdist_wheel' [2]\n\n[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2\n[2] https://github.com/pypa/wheel/commit/f7c9878712390414c03c64e9afa55ea4f30e965b\n\nChange-Id: Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983\n""}, {'number': 2, 'created': '2019-10-12 17:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/c8bdb03361852f220f0242a9529d466069a3387a', 'message': ""setup.cfg: Cleanup\n\n- pbr hasn't need the hook configuration since forever [1]\n- The 'wheel' group is renamed to 'bdist_wheel' [2]\n\n[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2\n[2] https://github.com/pypa/wheel/commit/f7c9878712390414c03c64e9afa55ea4f30e965b\n\nChange-Id: Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983\n""}, {'number': 3, 'created': '2019-10-12 17:31:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/9fefa6c01a4be0d62d7bf3e1784c1b49015cd32a', 'message': ""setup.cfg: Cleanup\n\n- pbr hasn't need the hook configuration since forever [1]\n- The 'wheel' group is renamed to 'bdist_wheel' [2]\n\n[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2\n[2] https://github.com/pypa/wheel/commit/f7c9878712390414c03c64e9afa55ea4f30e965b\n\nChange-Id: Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983\n""}]",0,688276,9fefa6c01a4be0d62d7bf3e1784c1b49015cd32a,6,3,3,30356,,,0,"setup.cfg: Cleanup

- pbr hasn't need the hook configuration since forever [1]
- The 'wheel' group is renamed to 'bdist_wheel' [2]

[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2
[2] https://github.com/pypa/wheel/commit/f7c9878712390414c03c64e9afa55ea4f30e965b

Change-Id: Id985f9e07bc20bf19aeba417a2cfdca7cc1bf983
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/76/688276/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2569bb6452c7d74e3c487099ff3a1efd285d5d56,,[bdist_wheel],[global] setup-hooks = pbr.hooks.setup_hook [wheel],1,5
openstack%2Fopenstack-helm-infra~master~Iba11c1c965f9958a12641de3e6e817faa6a4ce79,openstack/openstack-helm-infra,master,Iba11c1c965f9958a12641de3e6e817faa6a4ce79,Service-Proxy: Bring a external endpoint,ABANDONED,2018-09-20 04:21:18.000000000,2020-01-02 05:23:20.000000000,,"[{'_account_id': 8181}, {'_account_id': 8898}, {'_account_id': 16513}, {'_account_id': 17068}, {'_account_id': 17966}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26931}]","[{'number': 1, 'created': '2018-09-20 04:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/835aa500ae52a12419821387ebaaae6834744260', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service on\nthe cluster. Every resource can use any external endpoint through this chart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modificaiotn of the configuration. This\ncan be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file has\ndefault values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 2, 'created': '2018-09-20 04:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8cd1eb46631df3f1ccbac841be6f55e55c7fc71b', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modificaiotn of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 3, 'created': '2018-09-20 04:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f12ab48a7b00f0f1f164703a0b3b5361ed1f68c9', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modificaiotn of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 4, 'created': '2018-09-20 04:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/db2740326616308c955c44d6c53fd02cb8c046dd', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modificaiotn of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 5, 'created': '2018-09-20 05:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/36fa2f17be1b1d479ad97082e8f8d448d11a2cda', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modification of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 6, 'created': '2019-01-09 11:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/80faffbae94ad894fd20ef399a7e48d518c994b5', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modification of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 7, 'created': '2019-01-09 13:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e70b9791f6b72e4c00eee19a453993a6b2271cae', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modification of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}, {'number': 8, 'created': '2019-06-10 12:00:44.000000000', 'files': ['releasenotes/notes/service_proxy-4365071d450084c0.yaml', 'service-proxy/Chart.yaml', 'service-proxy/templates/service.yaml', 'service-proxy/values.yaml', 'service-proxy/requirements.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/803229471c2c1e9ecd8c8fe55fe0a873f4d94399', 'message': 'Service-Proxy: Bring a external endpoint\n\nThis chart introduces a mechanism to bring an external endpoint as a service\non the cluster. Every resource can use any external endpoint through this\nchart.\n\nAs a practical usage, this makes the prometheus server gather metrics from\nexternally installed CEPH without any modification of the configuration.\nThis can be used for a federation of Prometheus.\n\nThis can deploy multiple services by overriding values. The values.yaml file\nhas default values for two example described above.\n\nChange-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79\n'}]",6,603971,803229471c2c1e9ecd8c8fe55fe0a873f4d94399,34,8,8,26931,,,0,"Service-Proxy: Bring a external endpoint

This chart introduces a mechanism to bring an external endpoint as a service
on the cluster. Every resource can use any external endpoint through this
chart.

As a practical usage, this makes the prometheus server gather metrics from
externally installed CEPH without any modification of the configuration.
This can be used for a federation of Prometheus.

This can deploy multiple services by overriding values. The values.yaml file
has default values for two example described above.

Change-Id: Iba11c1c965f9958a12641de3e6e817faa6a4ce79
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/71/603971/8 && git format-patch -1 --stdout FETCH_HEAD,"['service-proxy/.helmignore', 'service-proxy/Chart.yaml', 'service-proxy/templates/service.yaml', 'service-proxy/values.yaml', 'service-proxy/requirements.yaml']",5,835aa500ae52a12419821387ebaaae6834744260,service_proxy,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. dependencies: - name: helm-toolkit repository: http://localhost:8879/charts version: 0.1.0 ",,234,0
openstack%2Ftempest~master~Id7c56b5146ff3f852c41766afbe7495bfca52d05,openstack/tempest,master,Id7c56b5146ff3f852c41766afbe7495bfca52d05,add image tags test in image list,ABANDONED,2019-12-13 07:13:52.000000000,2020-01-02 04:35:02.000000000,,"[{'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 07:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/20b4aa3c29d7791f8b5a729e8da4cecb3db00a41', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 2, 'created': '2019-12-14 01:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9801ea4187ad9c56da555a50bc03065483321790', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 3, 'created': '2019-12-27 04:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/84fc7e61f6ca571c91ecb88f5f67551e063b2b80', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 4, 'created': '2019-12-27 08:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/43f2735fff7d50b58d08a3274b6f0478e9359af6', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 5, 'created': '2019-12-30 00:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a5d4888c76db2324f4930a19113b73837ef94050', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 6, 'created': '2019-12-30 05:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0d1b591490afca74dbc89215a8b7db4da528325d', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 7, 'created': '2020-01-02 00:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0aee7e629aec11923c11d5aae5eb62c533c785b8', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}, {'number': 8, 'created': '2020-01-02 04:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f71ef43a11318dce76d90207a267461da29d14bb', 'message': 'add image tags test in image list\n\nadd image tags test in image list for v2 version\n\nChange-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05\n'}]",1,698839,f71ef43a11318dce76d90207a267461da29d14bb,17,2,8,31280,,,0,"add image tags test in image list

add image tags test in image list for v2 version

Change-Id: Id7c56b5146ff3f852c41766afbe7495bfca52d05
",git fetch https://review.opendev.org/openstack/tempest refs/changes/39/698839/8 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/image/v2/test_images_tags.py'],1,20b4aa3c29d7791f8b5a729e8da4cecb3db00a41,," def test_tags_for_image_list(self): image = self.create_image(container_format='bare', disk_format='raw', visibility='private') tag = data_utils.rand_name('tag') self.addCleanup(self.client.delete_image, image['id']) # Creating image tag and verify it. self.client.add_image_tag(image['id'], tag) params = {""name"": image['name']} image_body = self.client.list_images(params=params)['images'] self.assertIn(tag, image_body[0]['tags']) # Deleting image tag. self.client.delete_image_tag(image['id'], tag) image_body = self.client.list_images(params=params)['images'] self.assertNotIn(tag, image_body[0]['tags'])",,18,0
openstack%2Fkeystone~master~I0f4b9e24d949aa4838ee721a165999b29c684d32,openstack/keystone,master,I0f4b9e24d949aa4838ee721a165999b29c684d32,Fix token auth error if federated_groups_id is empty list,MERGED,2019-12-19 08:00:14.000000000,2020-01-02 04:11:58.000000000,2020-01-02 03:09:27.000000000,"[{'_account_id': 8482}, {'_account_id': 13063}, {'_account_id': 22348}, {'_account_id': 27621}, {'_account_id': 29071}]","[{'number': 1, 'created': '2019-12-19 08:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bf5d2594006ba3705fbc58e6797d1f43d280b428', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding weather\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 2, 'created': '2019-12-23 03:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3fd3192028a15854997984a321e55dacce01a386', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 3, 'created': '2019-12-23 07:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e71b20af8bfbe1ca02bf51ad062e40ffd88d607c', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 4, 'created': '2019-12-24 00:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7bb98ea289ece7b9d32ab550bb23cfb93cfec54a', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 5, 'created': '2019-12-24 02:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a9dce3de279130c6abe73380e6c363054b804ae3', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 6, 'created': '2019-12-24 04:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/143f89562081fb7f3046dc126a0ce4931ecd0b5a', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}, {'number': 7, 'created': '2019-12-30 16:55:32.000000000', 'files': ['keystone/token/provider.py', 'releasenotes/notes/bug-1856962-2c87d541da61c727.yaml', 'keystone/tests/unit/token/test_fernet_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f0d964e66675037d62ad17847a966e71720dbd54', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32\nCloses-Bug: #1856962\n'}]",7,699927,f0d964e66675037d62ad17847a966e71720dbd54,32,5,7,29071,,,0,"Fix token auth error if federated_groups_id is empty list

`federation_group_ids` could be zero length list, so deciding whether
a token is federated by checking if it is none.

Change-Id: I0f4b9e24d949aa4838ee721a165999b29c684d32
Closes-Bug: #1856962
",git fetch https://review.opendev.org/openstack/keystone refs/changes/27/699927/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/provider.py', 'keystone/tests/unit/token/test_fernet_provider.py']",2,bf5d2594006ba3705fbc58e6797d1f43d280b428,bug/1856962," def _test_validate_v3_token_federted_info(self, group_ids): def test_validate_v3_token_federated_info(self): # Check the user fields in the token result when use validate_v3_token # when the token has federated info. group_ids = [uuid.uuid4().hex, ] self._test_validate_v3_token_federted_info(group_ids) def test_validate_v3_token_federated_info_empty_group(self): # Check the user fields in the token result when use validate_v3_token # when the token has federated info. self._test_validate_v3_token_federted_info([]) class TestValidateWithoutCache(TestValidate): def config_overrides(self): super(TestValidateWithoutCache, self).config_overrides() self.config_fixture.config(group='token', caching=False) self.config_fixture.config(group='token', cache_on_issue=False) "," def test_validate_v3_token_federated_info(self): group_ids = [uuid.uuid4().hex, ]",23,3
openstack%2Fzaqar-specs~master~Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe,openstack/zaqar-specs,master,Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe,Support to query queues with count for ussuri,MERGED,2019-12-30 02:23:09.000000000,2020-01-02 03:06:42.000000000,2020-01-02 03:05:35.000000000,"[{'_account_id': 8846}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-30 02:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/444360792ed63d55cfcb5a8d63e6ca0e95683354', 'message': 'Add fold for ussuri\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\n'}, {'number': 2, 'created': '2019-12-31 07:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/d7941845092c7c68795574f286f1f1ee3a69ded2', 'message': 'Add fold for ussuri\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\n'}, {'number': 3, 'created': '2020-01-02 01:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/b79182688ca801104d70955ea1d14117c8484400', 'message': ""Support to query queues with count for ussuri\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\n""}, {'number': 4, 'created': '2020-01-02 01:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/8234877725585a0ad4f868b5b3ec7c923c5f0f0f', 'message': ""Support to query queues with count for ussuri\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 5, 'created': '2020-01-02 02:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/485e1c0b169050afe7b4f2147d490982a56bafc5', 'message': ""Support to query queues with count for ussuri\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 6, 'created': '2020-01-02 02:39:31.000000000', 'files': ['specs/ussuri/index.rst', 'specs/ussuri/query-queues-with-count.rst'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/0cd4708ce737f231020000c80c9c6523df88cbcf', 'message': ""Support to query queues with count for ussuri\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}]",2,700756,0cd4708ce737f231020000c80c9c6523df88cbcf,20,3,6,8846,,,0,"Support to query queues with count for ussuri

Zaqar will support query queues with 'with_count' to
return the amount of the queues. This will help users to
quickly get the exact total number of queues which they own.

Change-Id: Ic1ff218e4e975b4f6e16ebe4192f406efaeb94fe
Implements: blueprint query-queues-with-count
Signed-off-by: wanghao <sxmatch1986@gmail.com>
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/56/700756/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/index.rst'],1,444360792ed63d55cfcb5a8d63e6ca0e95683354,bp/query-queues-with-count,======================= Ussuri Specifications ======================= .. toctree:: :glob: :maxdepth: 2 ,,8,0
openstack%2Fcinder~master~I6c87d75e61796943e570f8f98803e9135ce7d6ee,openstack/cinder,master,I6c87d75e61796943e570f8f98803e9135ce7d6ee,Mark storwize driver supported,MERGED,2019-11-26 10:09:31.000000000,2020-01-02 02:29:40.000000000,2019-12-30 01:05:32.000000000,"[{'_account_id': 1736}, {'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12988}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30428}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-11-26 10:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7876bf42047116e866694cd7a673619862f246db', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now our new external CI system is up\nand running. We have to mark storwize cinder driver as supported\nagain. This commit only change cinder driver itself, no changes\nmade to release notes and support matrix file.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}, {'number': 2, 'created': '2019-11-27 09:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/129e5232718f6de4560e1055c73f1445718ba8fd', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now our new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}, {'number': 3, 'created': '2019-11-27 09:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/93ca25674186474af9a616b3e44ae220410a4e68', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now our new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}, {'number': 4, 'created': '2019-11-28 06:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/39387c21984e4b4dc41c1d6fe7e0e10d65714d0a', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now our new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}, {'number': 5, 'created': '2019-11-28 06:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/35f3938d82417469d00e44d8e0c157873dd7b566', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}, {'number': 6, 'created': '2019-11-28 06:43:11.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/ibm-storwize-supported-6518628fb78d58a4.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e012113ca14cad7f1d8d8dcd43eb4053d541fe87', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n'}]",3,696051,e012113ca14cad7f1d8d8dcd43eb4053d541fe87,105,39,6,30428,,,0,"Mark storwize driver supported

Storwize cinder driver has been marked as unsupported due to lack
of external CI running log. Now IBM new external CI system is up
and running. We plan to mark storwize cinder driver as supported
again. This commit updated Storwize driver, release notes and
support-matrix.ini.

Change-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee
",git fetch https://review.opendev.org/openstack/cinder refs/changes/51/696051/6 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'],1,7876bf42047116e866694cd7a673619862f246db,mark_storwize_supported,, # TODO(jsbryant) Remove driver in the 'U' release if CI is not fixed. SUPPORTED = False,0,2
openstack%2Fheat~master~I0d1437cd97da93984342896afa20f31e6a473cbc,openstack/heat,master,I0d1437cd97da93984342896afa20f31e6a473cbc,Imported Translations from Zanata,MERGED,2019-12-22 09:16:40.000000000,2020-01-02 02:11:33.000000000,2020-01-02 02:09:48.000000000,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 09:16:40.000000000', 'files': ['heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ja/LC_MESSAGES/heat.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/9c6fd452b7585f41a0ac3cf10f441f42eea9d6e3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0d1437cd97da93984342896afa20f31e6a473cbc\n'}]",0,700325,9c6fd452b7585f41a0ac3cf10f441f42eea9d6e3,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I0d1437cd97da93984342896afa20f31e6a473cbc
",git fetch https://review.opendev.org/openstack/heat refs/changes/25/700325/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ja/LC_MESSAGES/heat.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po']",12,9c6fd452b7585f41a0ac3cf10f441f42eea9d6e3,zanata/translations,"""POT-Creation-Date: 2019-12-20 05:37+0000\n""","""POT-Creation-Date: 2019-10-01 05:53+0000\n""msgid ""An ordered list of firewall rules to apply to the firewall."" msgstr """" ""Una lista ordenada de reglas de cortafuegos que se aplican al cortafuegos."" ",147,52
openstack%2Fheat-tempest-plugin~master~Ife8cf8cb3b271f0bce21ae0e637e58c1e206ee6f,openstack/heat-tempest-plugin,master,Ife8cf8cb3b271f0bce21ae0e637e58c1e206ee6f,[TEST] Check TARGET_BRANCH,ABANDONED,2020-01-01 08:17:58.000000000,2020-01-02 02:07:54.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-01 08:17:58.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/aeb7b18ce23beb189178471183e3c648c66ab3e8', 'message': '[TEST] Check TARGET_BRANCH\n\nDepends-On: https://review.opendev.org/700830\nChange-Id: Ife8cf8cb3b271f0bce21ae0e637e58c1e206ee6f\n'}]",0,700831,aeb7b18ce23beb189178471183e3c648c66ab3e8,9,2,1,12404,,,0,"[TEST] Check TARGET_BRANCH

Depends-On: https://review.opendev.org/700830
Change-Id: Ife8cf8cb3b271f0bce21ae0e637e58c1e206ee6f
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/31/700831/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,aeb7b18ce23beb189178471183e3c648c66ab3e8,test,, - heat-functional-orig-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2-non-apache - heat-functional-convg-mysql-lbaasv2-py35 - heat-functional-convg-rocky - heat-functional-convg-rocky-py35 - heat-functional-orig-rocky,0,7
openstack%2Fneutron-vpnaas-dashboard~master~I24d333db823232f9d7a86f474a94c95d68b3b07b,openstack/neutron-vpnaas-dashboard,master,I24d333db823232f9d7a86f474a94c95d68b3b07b,translation: drop babel extractor definitions,MERGED,2019-12-26 17:22:33.000000000,2020-01-02 02:01:51.000000000,2020-01-02 02:00:17.000000000,"[{'_account_id': 15905}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:22:33.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/4d959e80f20e5f799d7b050c4e0f57deb3713b73', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I24d333db823232f9d7a86f474a94c95d68b3b07b\n'}]",0,700641,4d959e80f20e5f799d7b050c4e0f57deb3713b73,8,3,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I24d333db823232f9d7a86f474a94c95d68b3b07b
",git fetch https://review.opendev.org/openstack/neutron-vpnaas-dashboard refs/changes/41/700641/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,4d959e80f20e5f799d7b050c4e0f57deb3713b73,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fzaqar-specs~master~I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5,openstack/zaqar-specs,master,I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5,"Fix doc job, pep8 error and remove py27",MERGED,2019-12-13 19:09:00.000000000,2020-01-02 01:40:51.000000000,2020-01-02 01:39:04.000000000,"[{'_account_id': 8846}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-13 19:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/ae74017307760ca69cddb0453fa9a093e3ff7261', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5\n'}, {'number': 2, 'created': '2019-12-13 22:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/6ebf5771415da6bde5f63b0e9570a38dab6e7f67', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5\n'}, {'number': 3, 'created': '2019-12-13 22:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/3566c01936561008049dc83a5d56c9d1805d6024', 'message': ""Fix doc job, pep8 error and remove py27\n\nThis commit does multiple fix\n1. Doc building still use deprcated oslosphinx and incompatible\nversion of yasfb which lead to error-\n\nsphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')\n\nReplace oslosphinx with openstackdocstheme to fix the error.\n\n2. Remove py27 job and replace with pep8\n3. fix the pep8 error\n\nChange-Id: I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5\n""}, {'number': 4, 'created': '2019-12-17 18:47:56.000000000', 'files': ['requirements.txt', 'tests/test_title.py', '.zuul.yaml', 'doc/source/conf.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/7aa078296c44b83c6920d59b97e3831fdbb11f69', 'message': ""Fix doc job, pep8 error and remove py27\n\nThis commit does multiple fix\n1. Doc building still use deprcated oslosphinx and incompatible\nversion of yasfb which lead to error-\n\nsphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')\n\nReplace oslosphinx with openstackdocstheme to fix the error.\n\n2. Switch py27 job with py37\n3. fix the pep8 error\n\nChange-Id: I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5\n""}]",0,698998,7aa078296c44b83c6920d59b97e3831fdbb11f69,15,4,4,8556,,,0,"Fix doc job, pep8 error and remove py27

This commit does multiple fix
1. Doc building still use deprcated oslosphinx and incompatible
version of yasfb which lead to error-

sphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')

Replace oslosphinx with openstackdocstheme to fix the error.

2. Switch py27 job with py37
3. fix the pep8 error

Change-Id: I33ad4d0a2924082b7c56ac7c7973ad02ac6e9df5
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/98/698998/4 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,ae74017307760ca69cddb0453fa9a093e3ff7261,drop-py27-support,"envlist = docs,pep8basepython = python3","envlist = docs,py27,pep8basepython = python3basepython = python3basepython = python3basepython = python3",4,7
openstack%2Fneutron~master~I41dda554e8cb4b4ca36515d64f17ad5bf52f3b49,openstack/neutron,master,I41dda554e8cb4b4ca36515d64f17ad5bf52f3b49,Improve ovs cleanup utility help,MERGED,2019-12-05 11:03:36.000000000,2020-01-01 22:22:23.000000000,2020-01-01 22:20:34.000000000,"[{'_account_id': 2733}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-05 11:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b63862aba886c28c93cb385511dd3d9b788a579a', 'message': 'Improve ovs cleanup utility help\n\nFixed a couple of things for ovs_all_ports=False.\nFirst state that it also cleans up ports created Nova.\nSecond since [1] it only cleans up the integration bridge.\n[1] https://opendev.org/openstack/neutron/commit/b09b4460\n\nChange-Id: I41dda554e8cb4b4ca36515d64f17ad5bf52f3b49\nCloses-Bug: #1853582\n'}, {'number': 2, 'created': '2019-12-20 09:18:30.000000000', 'files': ['neutron/conf/agent/cmd.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4075db5fd066715fd143201590092a1cf0bdf08a', 'message': 'Improve ovs cleanup utility help\n\nFixed a couple of things for ovs_all_ports=False.\nFirst state that it also cleans up ports created by Nova.\nSecond since [1] it only cleans up the integration bridge.\n\n[1] https://opendev.org/openstack/neutron/commit/b09b4460\n\nChange-Id: I41dda554e8cb4b4ca36515d64f17ad5bf52f3b49\nCloses-Bug: #1853582\n'}]",5,697439,4075db5fd066715fd143201590092a1cf0bdf08a,24,8,2,2733,,,0,"Improve ovs cleanup utility help

Fixed a couple of things for ovs_all_ports=False.
First state that it also cleans up ports created by Nova.
Second since [1] it only cleans up the integration bridge.

[1] https://opendev.org/openstack/neutron/commit/b09b4460

Change-Id: I41dda554e8cb4b4ca36515d64f17ad5bf52f3b49
Closes-Bug: #1853582
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/697439/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/agent/cmd.py'],1,b63862aba886c28c93cb385511dd3d9b788a579a,bug/1853582, 'Neutron and Nova on the integration bridge.')), 'Neutron on integration and external network ' 'bridges.')),1,2
openstack%2Fkolla~stable%2Fstein~Ie2a1077f7def0743f1403341985e2109aa490026,openstack/kolla,stable/stein,Ie2a1077f7def0743f1403341985e2109aa490026,create missing apache2 directory on Debian/Ubuntu,MERGED,2019-12-31 02:03:56.000000000,2020-01-01 21:52:27.000000000,2020-01-01 21:51:08.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2019-12-31 02:03:56.000000000', 'files': ['docker/panko/panko-api/extend_start.sh', 'docker/heat/heat-base/extend_start.sh', 'docker/monasca/monasca-log-api/extend_start.sh', 'docker/barbican/barbican-api/extend_start.sh', 'docker/octavia/octavia-api/extend_start.sh', 'docker/vitrage/vitrage-api/extend_start.sh', 'docker/cinder/cinder-api/extend_start.sh', 'docker/monasca/monasca-api/extend_start.sh', 'docker/keystone/keystone/extend_start.sh', 'docker/crane/extend_start.sh', 'docker/cyborg/cyborg-api/extend_start.sh', 'docker/ironic/ironic-api/extend_start.sh', 'docker/ironic/ironic-pxe/extend_start.sh', 'docker/cloudkitty/cloudkitty-api/extend_start.sh', 'docker/tripleo-ui/extend_start.sh', 'docker/aodh/aodh-api/extend_start.sh', 'docker/gnocchi/gnocchi-api/extend_start.sh', 'docker/zaqar/zaqar-wsgi/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh', 'docker/nova/nova-api/extend_start.sh', 'docker/mistral/mistral-api/extend_start.sh', 'docker/zun/zun-api/extend_start.sh', 'docker/manila/manila-api/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7d9cd19673e9520c181cbe4d7b83387a43a464c4', 'message': 'create missing apache2 directory on Debian/Ubuntu\n\nUbuntu/source deployment of several images (horizon, placement-api, zun)\nfailed with:\n\n+ exec /usr/sbin/apache2 -DFOREGROUND\napache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot\n\nChange-Id: Ie2a1077f7def0743f1403341985e2109aa490026\n(cherry picked from commit 932f09bcd65e15524b5229fdb6bc73a7e0111b27)\n'}]",0,700794,7d9cd19673e9520c181cbe4d7b83387a43a464c4,11,4,1,26970,,,0,"create missing apache2 directory on Debian/Ubuntu

Ubuntu/source deployment of several images (horizon, placement-api, zun)
failed with:

+ exec /usr/sbin/apache2 -DFOREGROUND
apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot

Change-Id: Ie2a1077f7def0743f1403341985e2109aa490026
(cherry picked from commit 932f09bcd65e15524b5229fdb6bc73a7e0111b27)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/94/700794/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/panko/panko-api/extend_start.sh', 'docker/heat/heat-base/extend_start.sh', 'docker/monasca/monasca-log-api/extend_start.sh', 'docker/barbican/barbican-api/extend_start.sh', 'docker/octavia/octavia-api/extend_start.sh', 'docker/vitrage/vitrage-api/extend_start.sh', 'docker/cinder/cinder-api/extend_start.sh', 'docker/monasca/monasca-api/extend_start.sh', 'docker/keystone/keystone/extend_start.sh', 'docker/crane/extend_start.sh', 'docker/cyborg/cyborg-api/extend_start.sh', 'docker/ironic/ironic-api/extend_start.sh', 'docker/ironic/ironic-pxe/extend_start.sh', 'docker/cloudkitty/cloudkitty-api/extend_start.sh', 'docker/tripleo-ui/extend_start.sh', 'docker/aodh/aodh-api/extend_start.sh', 'docker/gnocchi/gnocchi-api/extend_start.sh', 'docker/zaqar/zaqar-wsgi/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh', 'docker/nova/nova-api/extend_start.sh', 'docker/mistral/mistral-api/extend_start.sh', 'docker/zun/zun-api/extend_start.sh', 'docker/manila/manila-api/extend_start.sh']",23,7d9cd19673e9520c181cbe4d7b83387a43a464c4,, install -d /var/run/apache2/,,23,0
openstack%2Fneutron-lib~master~I2696c9e407cd5661a49d7d8c6b0232375682f827,openstack/neutron-lib,master,I2696c9e407cd5661a49d7d8c6b0232375682f827,Handle generation conflicts caused by concurrent updates,MERGED,2019-11-20 14:29:18.000000000,2020-01-01 21:40:19.000000000,2020-01-01 21:38:58.000000000,"[{'_account_id': 7166}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-11-20 14:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/21cafde29f06b05f0c7620bbb2cb7191bdcb4090', 'message': 'Handle generation conflicts caused by concurrent updates\n\nAs discussed on the Nova-Neutron cross project session of the\nUssuri/Shanghai PTG [1]:\n\n* Nova and Neutron will need to cooperate to identify the resource\n  providers representing the same physical NICs.\n* This will happen by Nova adding both RPs (created by Nova and\n  Neutron respectively) representing the same physical NIC to one\n  resource provider aggregate.\n* Resource providers have a generation attribute to detect concurrent\n  updates to the same RP (and its traits, inventories and aggregates).\n* Therefore Neutron will start seeing update failures because of\n  concurrent updates by Nova and retry its operation if it failed\n  because of a concurrent (but otherwise irrelevant) update.\n\nNOTE: The logic added to update inventory, inventories and traits\nshould be added to update resource provider too, but that API request\ndoes not take a generation parameter today - which is likely a bug on\nthe placement side.\n\nWhile implementing this change I noticed\nthat update_resource_provider_inventory and\nupdate_resource_provider_inventories translated HTTP 409 Conflicts to\ndifferent neutron exception classes - which I deemed to be a bug in\nplacement client code and corrected it in this change too.\n\n[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron\n\nChange-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827\n'}, {'number': 2, 'created': '2019-11-25 13:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/1b6dd122b4b59135c416ddf07161eed87c5d6e63', 'message': 'Handle generation conflicts caused by concurrent updates\n\nAs discussed on the Nova-Neutron cross project session of the\nUssuri/Shanghai PTG [1]:\n\n* Nova and Neutron will need to cooperate to identify the resource\n  providers representing the same physical NICs.\n* This will happen by Nova adding both RPs (created by Nova and\n  Neutron respectively) representing the same physical NIC to one\n  resource provider aggregate.\n* Resource providers have a generation attribute to detect concurrent\n  updates to the same RP (and its traits, inventories and aggregates).\n* Therefore Neutron will start seeing update failures because of\n  concurrent updates by Nova and retry its operation if it failed\n  because of a concurrent (but otherwise irrelevant) update.\n\nNOTE: The logic added to update inventory, inventories and traits\nshould be added to update resource provider too, but that API request\ndoes not take a generation parameter today - which is likely a bug on\nthe placement side.\n\nWhile implementing this change I noticed\nthat update_resource_provider_inventory and\nupdate_resource_provider_inventories translated HTTP 409 Conflicts to\ndifferent neutron exception classes - which I deemed to be a bug in\nplacement client code and corrected it in this change too.\n\n[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron\n\nChange-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827\n'}, {'number': 3, 'created': '2019-12-10 13:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/c31583553c363c615dae93d25b57c4bc01633590', 'message': 'Handle generation conflicts caused by concurrent updates\n\nAs discussed on the Nova-Neutron cross project session of the\nUssuri/Shanghai PTG [1]:\n\n* Nova and Neutron will need to cooperate to identify the resource\n  providers representing the same physical NICs.\n* This will happen by Nova adding both RPs (created by Nova and\n  Neutron respectively) representing the same physical NIC to one\n  resource provider aggregate.\n* Resource providers have a generation attribute to detect concurrent\n  updates to the same RP (and its traits, inventories and aggregates).\n* Therefore Neutron will start seeing update failures because of\n  concurrent updates by Nova and retry its operation if it failed\n  because of a concurrent (but otherwise irrelevant) update.\n\nNOTE: The logic added to update inventory, inventories and traits\nshould be added to update resource provider too, but that API request\ndoes not take a generation parameter today - which is likely a bug on\nthe placement side.\n\nWhile implementing this change I noticed\nthat update_resource_provider_inventory and\nupdate_resource_provider_inventories translated HTTP 409 Conflicts to\ndifferent neutron exception classes - which I deemed to be a bug in\nplacement client code and corrected it in this change too.\n\n[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron\n\nChange-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827\n'}, {'number': 4, 'created': '2019-12-19 09:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/50e8c257cf1c330b3b0d28da0e7873595452593e', 'message': 'Handle generation conflicts caused by concurrent updates\n\nAs discussed on the Nova-Neutron cross project session of the\nUssuri/Shanghai PTG [1]:\n\n* Nova and Neutron will need to cooperate to identify the resource\n  providers representing the same physical NICs.\n* This will happen by Nova adding both RPs (created by Nova and\n  Neutron respectively) representing the same physical NIC to one\n  resource provider aggregate.\n* Resource providers have a generation attribute to detect concurrent\n  updates to the same RP (and its traits, inventories and aggregates).\n* Therefore Neutron will start seeing update failures because of\n  concurrent updates by Nova and retry its operation if it failed\n  because of a concurrent (but otherwise irrelevant) update.\n\nNOTE: The logic added to update inventory, inventories and traits\nshould be added to update resource provider too, but that API request\ndoes not take a generation parameter today - which is likely a bug on\nthe placement side.\n\nWhile implementing this change I noticed\nthat update_resource_provider_inventory and\nupdate_resource_provider_inventories translated HTTP 409 Conflicts to\ndifferent neutron exception classes - which I deemed to be a bug in\nplacement client code and corrected it in this change too.\n\n[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron\n\nChange-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827\n'}, {'number': 5, 'created': '2019-12-23 11:03:07.000000000', 'files': ['neutron_lib/placement/client.py', 'neutron_lib/tests/unit/placement/test_client.py', 'releasenotes/notes/placement-client-bump-latest-supported-version-to-1-23-83589217b7b079fe.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/755f6f462e8509c68ca04728c2d6ce5d18beacd2', 'message': 'Handle generation conflicts caused by concurrent updates\n\nAs discussed on the Nova-Neutron cross project session of the\nUssuri/Shanghai PTG [1]:\n\n* Nova and Neutron will need to cooperate to identify the resource\n  providers representing the same physical NICs.\n* This will happen by Nova adding both RPs (created by Nova and\n  Neutron respectively) representing the same physical NIC to one\n  resource provider aggregate.\n* Resource providers have a generation attribute to detect concurrent\n  updates to the same RP (and its traits, inventories and aggregates).\n* Therefore Neutron will start seeing update failures because of\n  concurrent updates by Nova and retry its operation if it failed\n  because of a concurrent (but otherwise irrelevant) update.\n\nNOTE: The logic added to update inventory, inventories and traits\nshould be added to update resource provider too, but that API request\ndoes not take a generation parameter today - which is likely a bug on\nthe placement side.\n\nGeneration conflicts are signalled not just by the 409 Conflict HTTP\nresponse code but by the placement.concurrent_update error code inside\nthe HTTP JSON body. This is only available in Placement microversions\n1.23+, therefore we bump the Placement microversion used in neutron-lib\nto 1.23.\n\nWhile implementing this change I noticed\nthat update_resource_provider_inventory and\nupdate_resource_provider_inventories translated HTTP 409 Conflicts to\ndifferent neutron exception classes - which I deemed to be a bug in\nplacement client code and corrected it in this change too.\n\n[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron\n\nChange-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827\n'}]",17,695205,755f6f462e8509c68ca04728c2d6ce5d18beacd2,28,8,5,15554,,,0,"Handle generation conflicts caused by concurrent updates

As discussed on the Nova-Neutron cross project session of the
Ussuri/Shanghai PTG [1]:

* Nova and Neutron will need to cooperate to identify the resource
  providers representing the same physical NICs.
* This will happen by Nova adding both RPs (created by Nova and
  Neutron respectively) representing the same physical NIC to one
  resource provider aggregate.
* Resource providers have a generation attribute to detect concurrent
  updates to the same RP (and its traits, inventories and aggregates).
* Therefore Neutron will start seeing update failures because of
  concurrent updates by Nova and retry its operation if it failed
  because of a concurrent (but otherwise irrelevant) update.

NOTE: The logic added to update inventory, inventories and traits
should be added to update resource provider too, but that API request
does not take a generation parameter today - which is likely a bug on
the placement side.

Generation conflicts are signalled not just by the 409 Conflict HTTP
response code but by the placement.concurrent_update error code inside
the HTTP JSON body. This is only available in Placement microversions
1.23+, therefore we bump the Placement microversion used in neutron-lib
to 1.23.

While implementing this change I noticed
that update_resource_provider_inventory and
update_resource_provider_inventories translated HTTP 409 Conflicts to
different neutron exception classes - which I deemed to be a bug in
placement client code and corrected it in this change too.

[1] https://etherpad.openstack.org/p/ptg-ussuri-xproj-nova-neutron

Change-Id: I2696c9e407cd5661a49d7d8c6b0232375682f827
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/05/695205/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/placement/client.py', 'neutron_lib/tests/unit/placement/test_client.py']",2,21cafde29f06b05f0c7620bbb2cb7191bdcb4090,rp-generation," def test_update_rp_traits_caller_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = ks_exc.Conflict( response=mock_resp) self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_traits, resource_provider_uuid='resource provider uuid', traits=['trait a', 'trait b'], resource_provider_generation=3, ) self.placement_fixture.mock_put.assert_called_once() def test_update_rp_traits_callee_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = [ ks_exc.Conflict(response=mock_resp), mock.Mock(), ] self.placement_api_client.update_resource_provider_traits( resource_provider_uuid='resource provider uuid', traits=['trait a', 'trait b'], resource_provider_generation=None, ) self.assertEqual(2, self.placement_fixture.mock_put.call_count) def test_update_rp_traits_reached_max_tries(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = 10 * [ ks_exc.Conflict(response=mock_resp), ] self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_traits, resource_provider_uuid='resource provider uuid', traits=['trait a', 'trait b'], resource_provider_generation=None, ) self.assertEqual(10, self.placement_fixture.mock_put.call_count) def test_update_rp_inventory_caller_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = ks_exc.Conflict( response=mock_resp) self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_inventory, resource_provider_uuid='resource provider uuid', inventory={}, resource_class='a resource class', resource_provider_generation=3, ) self.placement_fixture.mock_put.assert_called_once() def test_update_rp_inventory_callee_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = [ ks_exc.Conflict(response=mock_resp), mock.Mock(), ] self.placement_api_client.update_resource_provider_inventory( resource_provider_uuid='resource provider uuid', inventory={}, resource_class='a resource class', resource_provider_generation=None, ) self.assertEqual(2, self.placement_fixture.mock_put.call_count) def test_update_rp_inventory_reached_max_tries(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = 10 * [ ks_exc.Conflict(response=mock_resp), ] self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_inventory, resource_provider_uuid='resource provider uuid', inventory={}, resource_class='a resource class', resource_provider_generation=None, ) self.assertEqual(10, self.placement_fixture.mock_put.call_count) def test_update_rp_inventories_caller_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = ks_exc.Conflict( response=mock_resp) self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_inventories, resource_provider_uuid='resource provider uuid', inventories={}, resource_provider_generation=3, ) self.placement_fixture.mock_put.assert_called_once() def test_update_rp_inventories_callee_handles_generation_conflict(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = [ ks_exc.Conflict(response=mock_resp), mock.Mock(), ] self.placement_api_client.update_resource_provider_inventories( resource_provider_uuid='resource provider uuid', inventories={}, resource_provider_generation=None, ) self.assertEqual(2, self.placement_fixture.mock_put.call_count) def test_update_rp_inventories_reached_max_tries(self): mock_resp = mock.Mock() mock_resp.text = '' self.placement_fixture.mock_put.side_effect = 10 * [ ks_exc.Conflict(response=mock_resp), ] self.assertRaises( n_exc.PlacementResourceProviderGenerationConflict, self.placement_api_client.update_resource_provider_inventories, resource_provider_uuid='resource provider uuid', inventories={}, resource_provider_generation=None, ) self.assertEqual(10, self.placement_fixture.mock_put.call_count)"," def test_update_resource_inventory_inventory_conflict_exception(self): self.placement_fixture.mock_put.side_effect = ks_exc.Conflict() self.assertRaises( n_exc.PlacementInventoryUpdateConflict, self.placement_api_client.update_resource_provider_inventory, RESOURCE_PROVIDER_UUID, INVENTORY, RESOURCE_CLASS_NAME, resource_provider_generation=1) ",234,42
openstack%2Fzun~master~Id1beeae646cf41fa217424adf2df46fe588a25a0,openstack/zun,master,Id1beeae646cf41fa217424adf2df46fe588a25a0,Add 'cni_metadata' to db layer,MERGED,2019-12-30 17:56:00.000000000,2020-01-01 20:16:50.000000000,2020-01-01 20:15:23.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-30 17:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/a279aece968405d57b134cd36a281ccec0036a2b', 'message': ""Add 'cni_metadata' to db layer\n\nThis field will be used by Zun to pass information to CNI plugin.\n\nChange-Id: Id1beeae646cf41fa217424adf2df46fe588a25a0\nImplements: blueprint add-annotations-to-capsule\n""}, {'number': 2, 'created': '2019-12-31 02:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2f21af7fb87eaa69c863264be4ddafcea27204aa', 'message': ""Add 'cni_metadata' to db layer\n\nThis field will be used by Zun to pass information to CNI plugin.\n\nChange-Id: Id1beeae646cf41fa217424adf2df46fe588a25a0\nImplements: blueprint support-cni\n""}, {'number': 3, 'created': '2020-01-01 17:36:21.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/alembic/versions/47d79ffdc582_add_cni_metadata_to_container.py', 'zun/db/sqlalchemy/models.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/be5d95ac7c69eb5347b9112e41c49cbd696c46c1', 'message': ""Add 'cni_metadata' to db layer\n\nThis field will be used by Zun to pass information to CNI plugin.\n\nChange-Id: Id1beeae646cf41fa217424adf2df46fe588a25a0\nImplements: blueprint support-cni\n""}]",0,700784,be5d95ac7c69eb5347b9112e41c49cbd696c46c1,12,2,3,11536,,,0,"Add 'cni_metadata' to db layer

This field will be used by Zun to pass information to CNI plugin.

Change-Id: Id1beeae646cf41fa217424adf2df46fe588a25a0
Implements: blueprint support-cni
",git fetch https://review.opendev.org/openstack/zun refs/changes/84/700784/3 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/alembic/versions/47d79ffdc582_add_cni_metadata_to_container.py', 'zun/db/sqlalchemy/models.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py']",5,a279aece968405d57b134cd36a281ccec0036a2b,bp/support-cni," 'Capsule': '1.4-66281771e65f95e6e79c604b59b7e3a3', 'CapsuleContainer': '1.4-ab82355ff19b201307c59a5b17ecc32d', 'CapsuleInitContainer': '1.4-ab82355ff19b201307c59a5b17ecc32d', 'Container': '1.43-bdd6b22fc8d6d1bb8518ed807e8e7b90',"," 'Capsule': '1.3-3ef24a2b99fa141caffa564dd3880fc5', 'CapsuleContainer': '1.3-2de3af3092ecb918e4d270c7bb2d93cb', 'CapsuleInitContainer': '1.3-2de3af3092ecb918e4d270c7bb2d93cb', 'Container': '1.42-cc5b84f4d846f2c0cf6231e808f1a4d1',",60,8
openstack%2Fpython-neutronclient~master~I9d82335c37f114aa43f26dec106e7598e776e068,openstack/python-neutronclient,master,I9d82335c37f114aa43f26dec106e7598e776e068,fix a typo,MERGED,2019-12-27 08:36:42.000000000,2020-01-01 20:11:21.000000000,2020-01-01 20:09:50.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 08:36:42.000000000', 'files': ['releasenotes/notes/relnotes-from-3.0.0-d7306f5af5e3868d.yaml'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/29043825e7e19b4f32f3998ea95419ad2429cd14', 'message': 'fix a typo\n\nChange-Id: I9d82335c37f114aa43f26dec106e7598e776e068\n'}]",0,700691,29043825e7e19b4f32f3998ea95419ad2429cd14,8,4,1,27383,,,0,"fix a typo

Change-Id: I9d82335c37f114aa43f26dec106e7598e776e068
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/91/700691/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/relnotes-from-3.0.0-d7306f5af5e3868d.yaml'],1,29043825e7e19b4f32f3998ea95419ad2429cd14,, - Support keystoneauth1 library which brings us better keystone v3 support., - Support keystoneauth1 library which brings us better kyestone v3 support.,1,1
openstack%2Fzun~master~Ie70ed401dea63e9397d98c82b05059212e4e31c2,openstack/zun,master,Ie70ed401dea63e9397d98c82b05059212e4e31c2,Change default of resume_container_state as True,MERGED,2019-11-30 22:18:58.000000000,2020-01-01 18:06:28.000000000,2020-01-01 18:05:01.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-30 22:18:58.000000000', 'files': ['zun/conf/compute.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/bcf9607516067877684e5d78de5a9983fe89a374', 'message': 'Change default of resume_container_state as True\n\nThis config determine whether zun-compute will restart containers\nthat was running in before. However, this might conflict with\nrestart policy of individual containers.\nFor example, if users create a container with auto-restart disabled,\nsetting resume_container_state to true would negate this effect.\n\nChange-Id: Ie70ed401dea63e9397d98c82b05059212e4e31c2\n'}]",0,696780,bcf9607516067877684e5d78de5a9983fe89a374,19,2,1,11536,,,0,"Change default of resume_container_state as True

This config determine whether zun-compute will restart containers
that was running in before. However, this might conflict with
restart policy of individual containers.
For example, if users create a container with auto-restart disabled,
setting resume_container_state to true would negate this effect.

Change-Id: Ie70ed401dea63e9397d98c82b05059212e4e31c2
",git fetch https://review.opendev.org/openstack/zun refs/changes/80/696780/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/conf/compute.py'],1,bcf9607516067877684e5d78de5a9983fe89a374,," default=False,"," default=True,",1,1
openstack%2Fheat~master~I27668b4bcdda5068fac34d617a42d1e5d1513c5c,openstack/heat,master,I27668b4bcdda5068fac34d617a42d1e5d1513c5c,[Test][DMT] add  librdkafka-dev to devstack,ABANDONED,2019-12-24 07:46:20.000000000,2020-01-01 16:55:05.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 07:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1ae5288c641fbd8d3716e4adf77b5face272edb4', 'message': '[Test][DMT] add  librdkafka-dev to devstack\n\nChange-Id: I27668b4bcdda5068fac34d617a42d1e5d1513c5c\n'}, {'number': 2, 'created': '2019-12-24 15:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a77620da6a53ba948dc3c1919e5e4a0c2b580c1e', 'message': '[Test][DMT] add  librdkafka-dev to devstack\n\nDepends-On: https://review.opendev.org/#/c/700490/\n\nChange-Id: I27668b4bcdda5068fac34d617a42d1e5d1513c5c\n'}, {'number': 3, 'created': '2019-12-26 08:58:17.000000000', 'files': ['devstack/lib/heat'], 'web_link': 'https://opendev.org/openstack/heat/commit/aa7f200b0d3670f5f52f9cdb87862e935af29647', 'message': '[Test][DMT] add  librdkafka-dev to devstack\n\nDepends-On: https://review.opendev.org/#/c/700512\n\nChange-Id: I27668b4bcdda5068fac34d617a42d1e5d1513c5c\n'}]",0,700488,aa7f200b0d3670f5f52f9cdb87862e935af29647,19,2,3,12404,,,0,"[Test][DMT] add  librdkafka-dev to devstack

Depends-On: https://review.opendev.org/#/c/700512

Change-Id: I27668b4bcdda5068fac34d617a42d1e5d1513c5c
",git fetch https://review.opendev.org/openstack/heat refs/changes/88/700488/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/heat'],1,1ae5288c641fbd8d3716e4adf77b5face272edb4,, install_package librdkafka-dev,,1,0
openstack%2Fheat-tempest-plugin~master~I6cac57ac9cb292d7215c300f7627cb129552a09d,openstack/heat-tempest-plugin,master,I6cac57ac9cb292d7215c300f7627cb129552a09d,Allow set branch_override in zuul job,ABANDONED,2020-01-01 02:02:44.000000000,2020-01-01 16:50:06.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-01 02:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/8e491e05be5c812411a6b5fc9ebff3b8354b9495', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 2, 'created': '2020-01-01 02:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/cff3697257249dc37a7de0f7fb3abc680c922a0b', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 3, 'created': '2020-01-01 02:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/f229ef8c9b67e496cc92f36aaca21188d3043845', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 4, 'created': '2020-01-01 02:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/6b5a2d085a24104146da6605d39ef168812ab0f9', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 5, 'created': '2020-01-01 03:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/53ead17da28cb73895c6354f38e3cd3a93fcc0fc', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 6, 'created': '2020-01-01 05:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/23efabf0226dc9609ce2f4e09374675f7e896f93', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 7, 'created': '2020-01-01 05:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/f8d1bdfa4102bf1dac41c0cb4d214c83ef1b07aa', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/700698\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}, {'number': 8, 'created': '2020-01-01 07:31:17.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/b1f99db6f33d91e05acece44c1466278aeb551f7', 'message': 'Allow set branch_override in zuul job\n\nDepends-On: https://review.opendev.org/#/c/660877\nChange-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d\n'}]",0,700827,b1f99db6f33d91e05acece44c1466278aeb551f7,16,2,8,12404,,,0,"Allow set branch_override in zuul job

Depends-On: https://review.opendev.org/#/c/660877
Change-Id: I6cac57ac9cb292d7215c300f7627cb129552a09d
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/27/700827/8 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,8e491e05be5c812411a6b5fc9ebff3b8354b9495,test, vars: branch_override: stable/queens parent: heat-functional-legacy vars: branch_override: stable/queens, override-checkout: stable/queens parent: heat-functional-orig-mysql-lbaasv2 override-checkout: stable/queens - tempest-plugin-jobs - heat-functional-orig-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2-non-apache - heat-functional-convg-mysql-lbaasv2-py35 - heat-functional-convg-queens-py35 - heat-functional-convg-rocky - heat-functional-convg-rocky-py35 - heat-functional-orig-rocky,5,12
openstack%2Fmanila~master~I57b15b7ebb29c545c9780a90734988565fa1f6b7,openstack/manila,master,I57b15b7ebb29c545c9780a90734988565fa1f6b7,Fix error that failed to get image for booting server,MERGED,2019-10-01 07:22:54.000000000,2020-01-01 15:17:07.000000000,2020-01-01 15:15:43.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23950}, {'_account_id': 25243}, {'_account_id': 27336}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-10-01 07:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e02cb7d4eb2123a6b08dded94b724b5d494df84b', 'message': 'Fix error that failed to get image for booting server\n\nGlance image list API supports pagination, but `_get_service_image`\nuses novaclient.glance.list() that only return images in one page.\nWhen the image needed by share server is not returned in the first\npage, the exception occurs. This patch will use `find_image` method\nto get the image.\nSince latest novaclient has no proxy to lookup image, so only\nnovaclient.glance.\n\nChange-Id: I57b15b7ebb29c545c9780a90734988565fa1f6b7\nCloses-Bug: #1844046\n'}, {'number': 2, 'created': '2019-10-26 06:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f80907bd6df5952b3c7e409dd8e97f7f898ee7c4', 'message': 'Fix error that failed to get image for booting server\n\nGlance image list API supports pagination, but `_get_service_image`\nuses novaclient.glance.list() that only return images in one page.\nWhen the image needed by share server is not returned in the first\npage, the exception occurs. This patch uses `find_image` method\nto get the image.\nSince latest novaclient has no proxy to lookup image, so only\nnovaclient.glance.\n\nChange-Id: I57b15b7ebb29c545c9780a90734988565fa1f6b7\nCloses-Bug: #1844046\n'}, {'number': 3, 'created': '2019-12-13 01:32:06.000000000', 'files': ['manila/share/drivers/service_instance.py', 'manila/tests/fake_compute.py', 'manila/tests/share/drivers/test_service_instance.py', 'releasenotes/notes/bug_1844046-fix-image-not-found-629415d50cd6042a.yaml', 'manila/compute/nova.py', 'manila/tests/compute/test_nova.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/a7aa8470972303ab144ed46df576569abd494c04', 'message': 'Fix error that failed to get image for booting server\n\nGlance image list API supports pagination, but `_get_service_image`\nuses novaclient.glance.list() that only return images in one page.\nWhen the image needed by share server is not returned in the first\npage, the exception occurs. This patch uses `find_image` method\nto get the image.\nSince latest novaclient has no proxy to lookup image, so only\nnovaclient.glance.\n\nChange-Id: I57b15b7ebb29c545c9780a90734988565fa1f6b7\nCloses-Bug: #1844046\n'}]",5,685886,a7aa8470972303ab144ed46df576569abd494c04,98,15,3,23950,,,0,"Fix error that failed to get image for booting server

Glance image list API supports pagination, but `_get_service_image`
uses novaclient.glance.list() that only return images in one page.
When the image needed by share server is not returned in the first
page, the exception occurs. This patch uses `find_image` method
to get the image.
Since latest novaclient has no proxy to lookup image, so only
novaclient.glance.

Change-Id: I57b15b7ebb29c545c9780a90734988565fa1f6b7
Closes-Bug: #1844046
",git fetch https://review.opendev.org/openstack/manila refs/changes/86/685886/3 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/service_instance.py', 'manila/tests/fake_compute.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/compute/nova.py', 'manila/tests/compute/test_nova.py']",5,e02cb7d4eb2123a6b08dded94b724b5d494df84b,bug_1844046," def test_image_get_novaclient_has_no_proxy(self): image = 'fake-image' class FakeGlanceClient(object): def find_image(self, name): return image self.novaclient.glance = FakeGlanceClient() result = self.api.image_get(self.ctx, 'fake-image') self.assertEqual(image, result) def test_image_get_novaclient_not_found(self): image = 'fake-image' class FakeGlanceClient(object): def find_image(self, image): return image self.novaclient.glance = FakeGlanceClient() self.mock_object(self.novaclient.glance, 'find_image', mock.Mock(return_value=image, side_effect=nova_exception.NotFound(404))) self.assertRaises(exception.ServiceInstanceException, self.api.image_get, self.ctx, image) def test_image_get_novaclient_multi_match(self): image = 'fake-image' class FakeGlanceClient(object): def find_image(self, image): return image self.novaclient.glance = FakeGlanceClient() self.mock_object(self.novaclient.glance, 'find_image', mock.Mock(return_value=image, side_effect=nova_exception.NoUniqueMatch)) self.assertRaises(exception.ServiceInstanceException, self.api.image_get, self.ctx, image) ",,68,43
openstack%2Fvitrage~master~If5df9893cc248efd8b8369b4eaaaca352bdf95d7,openstack/vitrage,master,If5df9893cc248efd8b8369b4eaaaca352bdf95d7,Use only py3 as base,MERGED,2019-12-29 11:09:13.000000000,2020-01-01 10:45:56.000000000,2020-01-01 10:44:38.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-29 11:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/36db3446075bcc917026147d556c4f712c0b5769', 'message': 'Use only py3 as base\n\nChange-Id: If5df9893cc248efd8b8369b4eaaaca352bdf95d7\n'}, {'number': 2, 'created': '2019-12-29 11:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a76383740a1d7bdddfca65cd165de3ff3064bf57', 'message': 'Use only py3 as base\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: If5df9893cc248efd8b8369b4eaaaca352bdf95d7\n'}, {'number': 3, 'created': '2019-12-30 10:35:40.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/352cc33b8184cd143bf6e53db65e4ea237b72cf7', 'message': 'Use only py3 as base\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: If5df9893cc248efd8b8369b4eaaaca352bdf95d7\n'}]",0,700744,352cc33b8184cd143bf6e53db65e4ea237b72cf7,14,2,3,19134,,,0,"Use only py3 as base

Depends-On: https://review.opendev.org/#/c/700512/
Change-Id: If5df9893cc248efd8b8369b4eaaaca352bdf95d7
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/44/700744/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,36db3446075bcc917026147d556c4f712c0b5769,eyalb/py3,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,9
openstack%2Fvitrage-tempest-plugin~master~Ic6d010d7e14933d9fd2bc39f157af54147f4401d,openstack/vitrage-tempest-plugin,master,Ic6d010d7e14933d9fd2bc39f157af54147f4401d,Drop python 2.7 support and testing,MERGED,2019-10-30 05:31:42.000000000,2020-01-01 08:47:16.000000000,2020-01-01 08:45:57.000000000,"[{'_account_id': 1736}, {'_account_id': 8556}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-30 05:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/13bb4e96af33edb66a5fff975b4b795d077e3b38', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nvitrage-tempest-plugin is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: Ic6d010d7e14933d9fd2bc39f157af54147f4401d\n'}, {'number': 2, 'created': '2019-12-30 11:41:19.000000000', 'files': ['requirements.txt', 'releasenotes/notes/drop-py-2-7-1be17025c498d4bd.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/98969445603a24ab18295e08b6789c4a6d500ab9', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nvitrage-tempest-plugin is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: Ic6d010d7e14933d9fd2bc39f157af54147f4401d\n'}]",0,692028,98969445603a24ab18295e08b6789c4a6d500ab9,12,4,2,8556,,,0,"Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

vitrage-tempest-plugin is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Change-Id: Ic6d010d7e14933d9fd2bc39f157af54147f4401d
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/28/692028/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'releasenotes/notes/drop-py-2-7-1be17025c498d4bd.yaml', 'setup.cfg', 'tox.ini']",4,13bb4e96af33edb66a5fff975b4b795d077e3b38,drop-py27-support,"envlist = py37,py36,pep8","envlist = py37,py36,py27,pep8",7,4
openstack%2Fvitrage~master~If5fda069dcc4c40f6dfa62ef0daea9331dfbb8a0,openstack/vitrage,master,If5fda069dcc4c40f6dfa62ef0daea9331dfbb8a0,Use py3 only,MERGED,2019-12-30 12:25:55.000000000,2020-01-01 08:47:15.000000000,2020-01-01 08:45:56.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-30 12:25:55.000000000', 'files': ['requirements.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/db91c4e15ba106935803bed71cedb29fad6b35df', 'message': 'Use py3 only\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: If5fda069dcc4c40f6dfa62ef0daea9331dfbb8a0\n'}]",0,700770,db91c4e15ba106935803bed71cedb29fad6b35df,7,2,1,19134,,,0,"Use py3 only

Depends-On: https://review.opendev.org/#/c/700512/
Change-Id: If5fda069dcc4c40f6dfa62ef0daea9331dfbb8a0
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/70/700770/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'doc/requirements.txt']",2,db91c4e15ba106935803bed71cedb29fad6b35df,eyalb/networkx,,"sphinx!=1.6.6,!=1.6.7,>=1.6.2,<2.0.0;python_version=='2.7' # BSD",0,2
openstack%2Frequirements~master~I1ec341dab9457c15f0aec70fef2b05551282a485,openstack/requirements,master,I1ec341dab9457c15f0aec70fef2b05551282a485,confluent-kafka 1.3.0 fails to install,MERGED,2019-12-24 12:25:59.000000000,2020-01-01 08:02:50.000000000,2019-12-31 23:57:51.000000000,"[{'_account_id': 2}, {'_account_id': 10311}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 14107}, {'_account_id': 14288}, {'_account_id': 18955}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 26588}]","[{'number': 1, 'created': '2019-12-24 12:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/05a88d61e294844a81cb74a93609c4b0d98cbef9', 'message': 'confluent-kafka 1.3.0 fails to install\n\nversion 1.3.0 cannot build wheel see\n\nhttps://storage.gra.cloud.ovh.net/v1/AUTH_dcaab5e32b234d56b626f72581e3644c/zuul_opendev_logs_38c/682356/12/check/vitrage-dsvm-api-py3/38c7a56/logs/devstacklog.txt.gz\n\nChange-Id: I1ec341dab9457c15f0aec70fef2b05551282a485\n'}, {'number': 2, 'created': '2019-12-24 12:39:45.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/21e8e3cd34ef5b83bc4fa0b9a5bc4155acb655b2', 'message': 'confluent-kafka 1.3.0 fails to install\n\nversion 1.3.0 cannot build wheel see\n\nhttps://github.com/confluentinc/confluent-kafka-python/issues/751\nhttps://storage.gra.cloud.ovh.net/v1/AUTH_dcaab5e32b234d56b626f72581e3644c/zuul_opendev_logs_38c/682356/12/check/vitrage-dsvm-api-py3/38c7a56/logs/devstacklog.txt.gz\n\nChange-Id: I1ec341dab9457c15f0aec70fef2b05551282a485\n'}]",0,700512,21e8e3cd34ef5b83bc4fa0b9a5bc4155acb655b2,21,10,2,19134,,,0,"confluent-kafka 1.3.0 fails to install

version 1.3.0 cannot build wheel see

https://github.com/confluentinc/confluent-kafka-python/issues/751
https://storage.gra.cloud.ovh.net/v1/AUTH_dcaab5e32b234d56b626f72581e3644c/zuul_opendev_logs_38c/682356/12/check/vitrage-dsvm-api-py3/38c7a56/logs/devstacklog.txt.gz

Change-Id: I1ec341dab9457c15f0aec70fef2b05551282a485
",git fetch https://review.opendev.org/openstack/requirements refs/changes/12/700512/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,05a88d61e294844a81cb74a93609c4b0d98cbef9,kafka,confluent-kafka===1.2.0,confluent-kafka===1.3.0,1,1
openstack%2Fheat~master~I88b89e9bfdd38224a1553e489fea42e5e6dbd29f,openstack/heat,master,I88b89e9bfdd38224a1553e489fea42e5e6dbd29f,[DMT][TEST] TEST Migrate zuul v3,ABANDONED,2019-12-27 10:12:10.000000000,2020-01-01 07:08:27.000000000,,"[{'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 10:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f95a3078b5ef767a8b60117381f7adbd03946220', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 2, 'created': '2019-12-27 10:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/78b7f974a3708b6dce75151f528e39dceaf22f13', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 3, 'created': '2019-12-27 15:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/151f61b41a9f9c80839d556e41ce289c09fc6757', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 4, 'created': '2019-12-27 18:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e86b1bd1c9ca3c181bf82d2c8cda19e9e248a72a', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 5, 'created': '2019-12-28 06:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aeac15c4166c72deb8288c6d981fd56b545c3539', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 6, 'created': '2019-12-28 08:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4aa59a39bc302e7112438963d789c271379b12be', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 7, 'created': '2019-12-28 09:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef5964d600aab92abc0eb65d6e7ffed50902c2d2', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 8, 'created': '2019-12-28 10:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e7bd6d2e5937d68dc34593c885fc8ffa90a313dc', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 9, 'created': '2019-12-28 10:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/08c04575be588b280aa6d48667f2babd8a2c3fa3', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 10, 'created': '2019-12-28 14:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b505b5ee03a50105981e4269f083f6755bbd9cc5', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 11, 'created': '2019-12-28 14:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ee4a5ab823e62e56431fa1309837eb604b178fca', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 12, 'created': '2019-12-28 16:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7a41df1770d9f6736d56325f294e1fa119ee9766', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 13, 'created': '2019-12-28 16:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/142ef88ef51474b29f89ca015fab40be7a89c7ed', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 14, 'created': '2019-12-28 17:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/66ae93552d35228891e374e77c5b137c17daf936', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 15, 'created': '2019-12-28 17:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a1c6ad23fdaf5fb10d8c5ecf54a66e367b6ed864', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 16, 'created': '2019-12-28 18:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0dc48dd5f9cab39d88071e4a6c66ce423b1f6820', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 17, 'created': '2019-12-29 01:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97a2f20112d4e33c6e8da1ea7b5d912f29f0ebb8', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 18, 'created': '2019-12-29 02:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d96115b34391b58a0cad08cdc37cc711c5d6f9f8', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 19, 'created': '2019-12-29 05:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1ae93d98a069978bbc6f6abdfb00fc3bf1dd458f', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 20, 'created': '2019-12-29 05:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/308d09626511d505fc8f61ba3314a0691fc606f5', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 21, 'created': '2019-12-29 09:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6c2d7117ebcbaf45028532e10fee490191003edd', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 22, 'created': '2019-12-29 13:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/421854f743e05edb03e411f1375426626cb1d1c1', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 23, 'created': '2019-12-29 14:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8ee4b7b9e5c4e8cd1ef61396b048629592d650c2', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 24, 'created': '2019-12-29 18:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/439f9b37975d942e1f2309f15197eccacc30a9a2', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 25, 'created': '2019-12-30 01:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d81bf8e2c075d60b2d48f85fdbbc496598eb7243', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 26, 'created': '2019-12-30 01:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/88f58f7fbb1d96d1c8839eb8571d2ff156b23077', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 27, 'created': '2019-12-30 01:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/50e7bc323d57486b8097d83f1d5db88cb48ad2e7', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 28, 'created': '2019-12-30 06:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5582912ee154a681842ec765cf9bcf73bc82894b', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\nDepends-On: https://review.opendev.org/#/c/700751/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 29, 'created': '2019-12-30 07:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/74784a0b14cc954351bf9df66fbbe086d1c3874d', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nDepends-On: https://review.opendev.org/#/c/700751/\n\nDepends-On: https://review.opendev.org/#/c/700760\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 30, 'created': '2019-12-30 09:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/95b4440674a9e6c9f649209e9cbb7deede7119df', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nDepends-On: https://review.opendev.org/#/c/700751/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 31, 'created': '2019-12-30 15:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eca45bc4e45ff2f63bd94f161de0ffaeb6709ee5', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nDepends-On: https://review.opendev.org/#/c/700751/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 32, 'created': '2019-12-31 01:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a50b2726db823d72ef378d0b227faa41ee21ab2c', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nDepends-On: https://review.opendev.org/#/c/700751/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 33, 'created': '2019-12-31 02:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/093dd84ff4fc5612c35f9e7d5f457f1e3a9f6aca', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nDepends-On: https://review.opendev.org/#/c/700751/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 34, 'created': '2019-12-31 03:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e5cc2df1b97df0454b1db194a6160e713809793', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 35, 'created': '2019-12-31 05:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b67aa78296b09fb9b459b670acc48ddf2ff1ac64', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 36, 'created': '2019-12-31 06:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3d265153cd8abdc47aa46bb71abb2091e9ac9042', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 37, 'created': '2019-12-31 07:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d849ba70aa57c8fc94771ef7291dd022ab46b198', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 38, 'created': '2019-12-31 07:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0a8720198e9ca5da69f9ae04adc78034d8da9bb6', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 39, 'created': '2019-12-31 09:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/59c0043df5103db94006d52c42b438f54d986b42', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 40, 'created': '2019-12-31 17:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/21f433ba43783f526a7ced240cb32217108b23f5', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 41, 'created': '2019-12-31 17:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9219a6f4d5a333de06c8d29db4111ffe4b2a7dd9', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 42, 'created': '2019-12-31 19:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d8b9674479b6db4872f7959a9e4b060bafc0c788', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}, {'number': 43, 'created': '2020-01-01 01:51:24.000000000', 'files': ['playbooks/devstack/functional/post.yaml', 'heat_integrationtests/common/test.py', 'heat_integrationtests/pre_test_hook.sh', '.zuul.yaml', 'devstack/plugin.sh', 'devstack/lib/heat', 'heat_integrationtests/post_test_hook.sh', 'heat_integrationtests/cleanup_test_env.sh', 'playbooks/devstack/grenade/post.yaml', 'requirements.txt', 'playbooks/devstack/functional/run.yaml', 'heat_integrationtests/__init__.py', 'setup.cfg', 'heat_integrationtests/plugin.py', 'playbooks/devstack/functional/pre-run.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/fe5e15a98a8dc81a02f4454b529e4b8403ac6436', 'message': '[DMT][TEST] TEST Migrate zuul v3\n\nTODO: move heat_integrationtests tempest tests out of heat\n\nChange-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f\n'}]",0,700698,fe5e15a98a8dc81a02f4454b529e4b8403ac6436,96,2,43,12404,,,0,"[DMT][TEST] TEST Migrate zuul v3

TODO: move heat_integrationtests tempest tests out of heat

Change-Id: I88b89e9bfdd38224a1553e489fea42e5e6dbd29f
",git fetch https://review.opendev.org/openstack/heat refs/changes/98/700698/37 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/devstack/functional/run.yaml', '.zuul.yaml', 'heat_integrationtests/post_test_hook.sh']",3,f95a3078b5ef767a8b60117381f7adbd03946220,story/2007056,, cd $DEST/tempest sudo tox -evenv-tempest -- stestr --test-path=$DEST/heat/heat_integrationtests --top-dir=$DEST/heat --group_regex='heat_tempest_plugin\.tests\.api\.test_heat_api[._]([^_]+)' run sudo -E $DEST/heat/heat_integrationtests/cleanup_test_env.sh,51,186
openstack%2Fheat~master~I86a0a73aacd808812a21827fa03d90acc4b18901,openstack/heat,master,I86a0a73aacd808812a21827fa03d90acc4b18901,[DMT][TEST] gate TEST,ABANDONED,2020-01-01 02:23:30.000000000,2020-01-01 06:43:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-01 02:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ea5f942420db3e1e825adc13b0da75001fcc346d', 'message': '[DMT][TEST] gate TEST\n\nChange-Id: I86a0a73aacd808812a21827fa03d90acc4b18901\n'}, {'number': 2, 'created': '2020-01-01 02:39:27.000000000', 'files': ['playbooks/devstack/functional/post.yaml', 'heat_integrationtests/common/test.py', 'heat_integrationtests/pre_test_hook.sh', '.zuul.yaml', 'devstack/plugin.sh', 'devstack/lib/heat', 'heat_integrationtests/post_test_hook.sh', 'heat_integrationtests/cleanup_test_env.sh', 'playbooks/devstack/grenade/post.yaml', 'requirements.txt', 'playbooks/devstack/functional/run.yaml', 'heat_integrationtests/__init__.py', 'setup.cfg', 'heat_integrationtests/plugin.py', 'playbooks/devstack/functional/pre-run.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/905a66470afd7182fe23762510ba9bd13c91de8d', 'message': '[DMT][TEST] gate TEST\n\nChange-Id: I86a0a73aacd808812a21827fa03d90acc4b18901\n'}]",0,700828,905a66470afd7182fe23762510ba9bd13c91de8d,4,1,2,12404,,,0,"[DMT][TEST] gate TEST

Change-Id: I86a0a73aacd808812a21827fa03d90acc4b18901
",git fetch https://review.opendev.org/openstack/heat refs/changes/28/700828/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/devstack/functional/post.yaml', 'heat_integrationtests/common/test.py', 'heat_integrationtests/pre_test_hook.sh', '.zuul.yaml', 'devstack/plugin.sh', 'devstack/lib/heat', 'heat_integrationtests/post_test_hook.sh', 'heat_integrationtests/cleanup_test_env.sh', 'playbooks/devstack/grenade/post.yaml', 'requirements.txt', 'playbooks/devstack/functional/run.yaml', 'heat_integrationtests/__init__.py', 'setup.cfg', 'heat_integrationtests/plugin.py', 'playbooks/devstack/functional/pre-run.yaml']",15,ea5f942420db3e1e825adc13b0da75001fcc346d,test,"- hosts: all name: Job for functional tests tasks: - set_fact: devstack_base_dir: /opt/stack when: devstack_base_dir is not defined - name: run heat functional tests shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true # NOTE(mnaser): This will use the region local mirrors to avoid going out # to network if [[ -e /etc/ci/mirror_info.sh ]]; then source /etc/ci/mirror_info.sh fi export NODEPOOL_FEDORA_MIRROR=${NODEPOOL_FEDORA_MIRROR:-https://download.fedoraproject.org/pub/fedora/linux} export IMAGE_URLS=${NODEPOOL_FEDORA_MIRROR}/releases/29/Cloud/x86_64/images/Fedora-Cloud-Base-29-1.2.x86_64.qcow2 executable: /bin/bash chdir: ""{{ zuul.project.src_dir }}"" environment: DEVSTACK_BASE_DIR: ""{{ devstack_base_dir }}"" become: true ",,241,310
openstack%2Fopenstack-helm~master~I2896c76e012b9acbf1e725276ba9c0b74789fa54,openstack/openstack-helm,master,I2896c76e012b9acbf1e725276ba9c0b74789fa54,Improve accuracy for version detection on nova,MERGED,2019-12-17 11:06:14.000000000,2020-01-01 05:15:42.000000000,2020-01-01 05:14:02.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-12-17 11:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/42d5114e2907bcd41a59b1daa61033cd1f82e2e8', 'message': ""Improve accuracy for version detection on nova\n\nBecause it's almost time for expiring on some python version, OpenStack client\nrunning on that version generates some messages for warning. Two scripts on\nnova Fixed by this PS get version information using the OpenStack client\nwithout any protection for this kinds of messages. This PS gives a little\nsophistication way of it.\n\nChange-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54\n""}, {'number': 2, 'created': '2019-12-17 11:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e0d65f599bba663821bbf22712d1d87c94cb7336', 'message': ""Improve accuracy for version detection on nova\n\nBecause it's almost time for expiring on some python version, OpenStack client\nrunning on that version generates some messages for warning. Two scripts on\nnova Fixed by this PS get version information using the OpenStack client\nwithout any protection for this kinds of messages. This PS gives a little\nsophistication way of it.\n\nChange-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54\n""}, {'number': 3, 'created': '2019-12-19 04:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8c1e0349159d3a573299d52c33415b7a3612649e', 'message': ""Improve accuracy for version detection on nova\n\nBecause it's almost time for expiring on some python version, OpenStack client\nrunning on that version generates some messages for warning. Two scripts on\nnova Fixed by this PS get version information using the OpenStack client\nwithout any protection for this kinds of messages. This PS gives a little\nmore sophisticated way of it.\n\nChange-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54\n""}, {'number': 4, 'created': '2019-12-31 18:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e367f3a9da97dafb0daf6f7fe5696b68cf719c5b', 'message': ""Improve accuracy for version detection on nova\n\nBecause it's almost time for expiring on some python version, OpenStack client\nrunning on that version generates some messages for warning. Two scripts on\nnova Fixed by this PS get version information using the OpenStack client\nwithout any protection for this kinds of messages. This PS gives a little\nmore sophisticated way of it.\n\nChange-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54\n""}, {'number': 5, 'created': '2020-01-01 01:11:05.000000000', 'files': ['nova/templates/bin/_db-sync.sh.tpl', 'nova/templates/bin/_cell-setup.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/620286117bf5f023bf3d352bb8c73f6108e3fd7c', 'message': ""Improve accuracy for version detection on nova\n\nBecause it's almost time for expiring on some python version, OpenStack client\nrunning on that version generates some messages for warning. Two scripts on\nnova Fixed by this PS get version information using the OpenStack client\nwithout any protection for this kinds of messages. This PS gives a little\nmore sophisticated way of it.\n\nChange-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54\n""}]",0,699390,620286117bf5f023bf3d352bb8c73f6108e3fd7c,15,3,5,26931,,,0,"Improve accuracy for version detection on nova

Because it's almost time for expiring on some python version, OpenStack client
running on that version generates some messages for warning. Two scripts on
nova Fixed by this PS get version information using the OpenStack client
without any protection for this kinds of messages. This PS gives a little
more sophisticated way of it.

Change-Id: I2896c76e012b9acbf1e725276ba9c0b74789fa54
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/90/699390/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/templates/bin/_db-sync.sh.tpl', 'nova/templates/bin/_cell-setup.sh.tpl']",2,42d5114e2907bcd41a59b1daa61033cd1f82e2e8,nova/improve_accuracy_ver_detection,NOVA_VERSION=$(nova-manage --version 2>&1 | grep -Eo '[0-9]+[.][0-9]+[.][0-9]+'),NOVA_VERSION=$(nova-manage --version 2>&1),2,2
openstack%2Fcinder~master~I81805a2b06f85c3a8569aa572a0c7a328bef2319,openstack/cinder,master,I81805a2b06f85c3a8569aa572a0c7a328bef2319,Correct typos,MERGED,2019-12-26 06:46:47.000000000,2019-12-31 22:04:58.000000000,2019-12-31 22:03:03.000000000,"[{'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-26 06:46:47.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e35b19ec4186f5260f24df316cceb960649cca07', 'message': 'Correct typos\n\nChange-Id: I81805a2b06f85c3a8569aa572a0c7a328bef2319\n'}]",0,700595,e35b19ec4186f5260f24df316cceb960649cca07,36,26,1,31455,,,0,"Correct typos

Change-Id: I81805a2b06f85c3a8569aa572a0c7a328bef2319
",git fetch https://review.opendev.org/openstack/cinder refs/changes/95/700595/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,e35b19ec4186f5260f24df316cceb960649cca07,cinder/repo, # Use the admin context to be able to access volume extra_specs, # Use the admin contex to be able to access volume extra_specs,1,1
openstack%2Fopenstack-helm-infra~master~Ibedb48467cc047436530baee40551eb986bbe7b5,openstack/openstack-helm-infra,master,Ibedb48467cc047436530baee40551eb986bbe7b5,Get osh-infra netpol gate passing,ABANDONED,2019-09-13 19:31:51.000000000,2019-12-31 21:42:46.000000000,,"[{'_account_id': 20466}, {'_account_id': 20469}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-09-13 19:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7661713c59b3f1fbf0e7d0b6c6f1e62de70dc50c', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 2, 'created': '2019-09-13 22:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6d65c02add1e003055c6c1c378cf7b57e1d815c1', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 3, 'created': '2019-09-17 14:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7cea59c9bc15a862691ed3811a661b2f3a70db63', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 4, 'created': '2019-10-02 03:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c855f0ec2255953acb0596759153878f5443e26d', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 5, 'created': '2019-10-02 19:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fd6cf15b4dd30481fa329b10396cfc0ec8497c0a', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 6, 'created': '2019-10-14 15:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e0b0efca8eb01af742405b7b097c1a21e4eca6de', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 7, 'created': '2019-10-14 15:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6f2e8768e5d71f30d40c0a3152caf2144ddd5565', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 8, 'created': '2019-10-14 21:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf914d225b64fda0ff09f98cd57f3fd8d1b5ad51', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 9, 'created': '2019-10-14 22:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0782092086ad88a54b17be11e20661afe12989c3', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 10, 'created': '2019-10-14 22:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b165f0e03653b3e414ce2e37340ef969edf71878', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 11, 'created': '2019-10-14 23:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e03ed2f2b25e2208c08cfd06f91fcf786490bece', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 12, 'created': '2019-10-15 00:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a65a0cc95e749c12c82567b04816f557392e5407', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 13, 'created': '2019-10-15 01:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3272c82f18710755bbaf610419746c6bc556fd9e', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 14, 'created': '2019-10-15 03:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/028d5f99a05d7f9366c0e246485d630b56a64b60', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 15, 'created': '2019-10-15 05:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/039d3209235f481124317a9ab9ef4197e986e0eb', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 16, 'created': '2019-10-16 19:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/69d8f48f47804bb82666ae5fdf3e0624fcd13e5d', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 17, 'created': '2019-10-16 19:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bde6d8592342c963f59e5f280af2f16a98da78e6', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 18, 'created': '2019-10-17 00:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8de11b9d0716d8cc36c11a9b8f701f13ef817559', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 19, 'created': '2019-10-17 02:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/105f0c12729508689caf73eee37ce736f408194c', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 20, 'created': '2019-10-17 02:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/144627cc6c0ac96e043fb9f48df81d3d1e9a4f48', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 21, 'created': '2019-10-17 04:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/306db8febe125a94bdd3bf398275f3b7977c3ed6', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 22, 'created': '2019-10-17 14:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fc5c35099c6c5d4cfc0b749ebc44b0d182334bc3', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 23, 'created': '2019-10-17 14:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2ce3bc79e0a8c9ace006c174fdd48318fb0eadf6', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 24, 'created': '2019-10-18 04:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/30a8c7efbae34cbd9509d5c8ce225868d06de80f', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 25, 'created': '2019-10-18 05:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/16bf6c0d15c05b2d5fddb83113dee5b736eb4fc7', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 26, 'created': '2019-10-18 05:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b4d7982a5f40107f0dfe19fcc441c090b54fc3de', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 27, 'created': '2019-10-30 19:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7819d1933ff60a0fd6b52a9d5b7fb3fd70407052', 'message': '[WIP] Fix osh-infra netpol gate\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 28, 'created': '2019-10-31 03:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ab2c80e474ebce340ba9b2790e1c64ce439b660c', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 29, 'created': '2019-11-04 23:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e544457e0befa8e6cd7ca8e8a2e20a3d20e9216a', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 30, 'created': '2019-11-05 03:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/50f90709822d7c8f6401f141934489d1c2eefe01', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 31, 'created': '2019-11-13 05:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8cedfa8265641971fd5fce3837582c899022de43', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 32, 'created': '2019-11-18 21:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/43467833e211fef8605073fadffba296ca6a030d', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 33, 'created': '2019-11-18 21:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ac6219d7912fa4f3166089dc70e273acfdc6f057', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 34, 'created': '2019-11-23 23:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6cf4f7948cf82dc175cab8f25f9b73675c8e05c7', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 35, 'created': '2019-11-29 04:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ca6f4f907df31f6f9bb00c7cf60ab270a98e6d35', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 36, 'created': '2019-11-29 04:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e9a8bac28138738980e494ecec40ac6edbcdc465', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 37, 'created': '2019-12-31 18:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5e254eb92326f04c13de3a7c6dc8af5a7478fd3a', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 38, 'created': '2019-12-31 21:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b0ad00826a5dbde0863591cd8e582b8049777efe', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}, {'number': 39, 'created': '2019-12-31 21:24:06.000000000', 'files': ['tools/deployment/network-policy/901-test-networkpolicy.sh', 'tools/deployment/network-policy/045-mariadb.sh', 'tools/deployment/network-policy/135-fluentd-deployment.sh', 'zuul.d/jobs.yaml', 'fluentd/templates/monitoring/prometheus/exporter-network-policy.yaml', 'tools/deployment/network-policy/130-fluentd-daemonset.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c762f4d80aaed44c6eff31d16b1414f66650300b', 'message': 'Get osh-infra netpol gate passing\n\nThis change adds in missing network policy overrides for\nfluent-daemonset and prometheus-exporter, as well as removes\nexisting mariadb network policies overrides that were causing\nthe network policy check job to fail.\n\nChange-Id: Ibedb48467cc047436530baee40551eb986bbe7b5\n'}]",4,682144,c762f4d80aaed44c6eff31d16b1414f66650300b,117,5,39,21420,,,0,"Get osh-infra netpol gate passing

This change adds in missing network policy overrides for
fluent-daemonset and prometheus-exporter, as well as removes
existing mariadb network policies overrides that were causing
the network policy check job to fail.

Change-Id: Ibedb48467cc047436530baee40551eb986bbe7b5
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/44/682144/34 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/osh-infra-logging/070-fluentd-deployment.sh', 'zuul.d/project.yaml', 'tools/deployment/common/fluentd-daemonset.sh']",3,7661713c59b3f1fbf0e7d0b6c6f1e62de70dc50c,netpol, --values=/tmp/fluentd-daemonset.yaml \ --set manifests.network_policy=true, --values=/tmp/fluentd-daemonset.yaml,18,16
openstack%2Fcinder~master~I77698b0095dd0a990d954db622ed630b72062b79,openstack/cinder,master,I77698b0095dd0a990d954db622ed630b72062b79,Fix trivial typo in comment.,MERGED,2019-12-31 11:47:25.000000000,2019-12-31 21:24:06.000000000,2019-12-31 17:26:11.000000000,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-31 11:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8bc434cd0d984b06f2c4b49bd1f98619205cfffa', 'message': ""There's a typo in manager.py line 2419,so I modify it.\n\nChange-Id: I77698b0095dd0a990d954db622ed630b72062b79\n""}, {'number': 2, 'created': '2019-12-31 13:32:21.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8af54dcb735962fc25242a96523a3995e69fe785', 'message': 'Fix trivial typo in comment.\n\nChange-Id: I77698b0095dd0a990d954db622ed630b72062b79\n'}]",1,700806,8af54dcb735962fc25242a96523a3995e69fe785,47,23,2,31464,,,0,"Fix trivial typo in comment.

Change-Id: I77698b0095dd0a990d954db622ed630b72062b79
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/700806/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,8bc434cd0d984b06f2c4b49bd1f98619205cfffa,typomodify," # In the new flow we simplified this and we don't need it, instead of"," # In the new flow we simlified this and we don't need it, instead of",1,1
openstack%2Fpython-tricircleclient~master~I1ab7461978627e3b25b3bd6315b9ac7d067bb6f5,openstack/python-tricircleclient,master,I1ab7461978627e3b25b3bd6315b9ac7d067bb6f5,Switch to Ussuri jobs,ABANDONED,2019-10-22 07:11:06.000000000,2019-12-31 20:24:45.000000000,,"[{'_account_id': 8726}, {'_account_id': 22348}, {'_account_id': 23312}]","[{'number': 1, 'created': '2019-10-22 07:11:06.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/f6f372712615446253280f737399c78312021ab6', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I1ab7461978627e3b25b3bd6315b9ac7d067bb6f5\n'}]",0,689984,f6f372712615446253280f737399c78312021ab6,12,3,1,23312,,,0,"Switch to Ussuri jobs

Change-Id: I1ab7461978627e3b25b3bd6315b9ac7d067bb6f5
",git fetch https://review.opendev.org/openstack/python-tricircleclient refs/changes/84/689984/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f6f372712615446253280f737399c78312021ab6,, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fpython-tricircleclient~master~I998b55d72fa54a2c93f346b80fab3ffc089f8d87,openstack/python-tricircleclient,master,I998b55d72fa54a2c93f346b80fab3ffc089f8d87,Switch to official Ussuri jobs,ABANDONED,2019-11-20 09:43:50.000000000,2019-12-31 20:24:21.000000000,,"[{'_account_id': 8726}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-20 09:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/eaad77043a8ed3117b7fed9fefc42c958de85edf', 'message': 'openstack-python3-ussuri-jobs\n\nChange-Id: I998b55d72fa54a2c93f346b80fab3ffc089f8d87\n'}, {'number': 2, 'created': '2019-11-20 09:48:25.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/237b9c6ac8a63dc229cf1fa1bf13333fc5546e9b', 'message': 'Switch to official Ussuri jobs\n\nChange-Id: I998b55d72fa54a2c93f346b80fab3ffc089f8d87\n'}]",0,695153,237b9c6ac8a63dc229cf1fa1bf13333fc5546e9b,7,2,2,24061,,,0,"Switch to official Ussuri jobs

Change-Id: I998b55d72fa54a2c93f346b80fab3ffc089f8d87
",git fetch https://review.opendev.org/openstack/python-tricircleclient refs/changes/53/695153/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,eaad77043a8ed3117b7fed9fefc42c958de85edf,, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fopenstack-helm-infra~master~I43469c5bb5734b62cf69be924fe9cf7078e82a9c,openstack/openstack-helm-infra,master,I43469c5bb5734b62cf69be924fe9cf7078e82a9c,Kafka - Implement SASL Authentication,MERGED,2019-11-29 22:50:17.000000000,2019-12-31 19:06:39.000000000,2019-12-31 19:02:38.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-11-29 22:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ad31c98b7726448955c6a3b3dad8d3fe85e524d', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 2, 'created': '2019-12-03 21:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/658e968e7ccd444eca300a27b75aadd6e6f0ecef', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 3, 'created': '2019-12-03 21:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf943317d16f07203993149f08cd360260b41e5b', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 4, 'created': '2019-12-03 22:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8c2945f16fe627c14e0f4d9c28f5562d9bd52d32', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 5, 'created': '2019-12-04 23:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/16e037ff04c03730c81bd7da446f58dbbbcf978d', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nWIP While Demo Config in values.yaml\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 6, 'created': '2019-12-05 04:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/13e11218be9078fc9ec3678b85746cde868cfad6', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nWIP While Demo Config in values.yaml\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 7, 'created': '2019-12-09 16:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bf7a41f4cc91c7b0bcdd12847d3fd54d65c83596', 'message': '[WIP] Kafka - Implement SASL Authentication\n\nWIP While Demo Config in values.yaml\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}, {'number': 8, 'created': '2019-12-16 22:59:16.000000000', 'files': ['kafka/templates/statefulset.yaml', 'kafka/templates/configmap-bin.yaml', 'kafka/templates/bin/_generate-acl.sh.tpl', 'kafka/templates/bin/_helm-test.sh.tpl', 'kafka/values.yaml', 'kafka/templates/monitoring/prometheus/deployment.yaml', 'kafka/templates/monitoring/prometheus/secret-exporter.yaml', 'zookeeper/templates/statefulset.yaml', 'kafka/templates/bin/_kafka.sh.tpl', 'kafka/templates/configmap-etc.yaml', 'zookeeper/values.yaml', 'kafka/templates/job-generate-acl.yaml', 'kafka/templates/monitoring/prometheus/bin/_kafka-exporter.sh.tpl', 'kafka/templates/pod-helm-test.yaml', 'zookeeper/templates/configmap-etc.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/472097d7ebda980063f5fbe195b8b2c3f72bbf46', 'message': 'Kafka - Implement SASL Authentication\n\nThis change implements SASL authentication in the Kafka chart.\nKafka and Exporter credentials are defined in the endpoints section,\nwhile other credentials for producers and consumers can be defined\nin the jaas section.\n\nAdditionally, a few server settings are provided to enable SASL auth,\nand a jvm_options key is introduced. Any options specified here will\nbe set when starting Kafka, including the location of the jaas file\nin this case.\n\nChange-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c\n'}]",30,696765,472097d7ebda980063f5fbe195b8b2c3f72bbf46,26,4,8,30777,,,0,"Kafka - Implement SASL Authentication

This change implements SASL authentication in the Kafka chart.
Kafka and Exporter credentials are defined in the endpoints section,
while other credentials for producers and consumers can be defined
in the jaas section.

Additionally, a few server settings are provided to enable SASL auth,
and a jvm_options key is introduced. Any options specified here will
be set when starting Kafka, including the location of the jaas file
in this case.

Change-Id: I43469c5bb5734b62cf69be924fe9cf7078e82a9c
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/65/696765/8 && git format-patch -1 --stdout FETCH_HEAD,"['kafka/templates/bin/_generate_acl.sh.tpl', 'kafka/templates/statefulset.yaml', 'zookeeper/templates/etc/_jaas.conf.tpl', 'kafka/templates/configmap-bin.yaml', 'zookeeper/templates/statefulset.yaml', 'kafka/templates/configmap-etc.yaml', 'kafka/values.yaml', 'zookeeper/values.yaml', 'kafka/templates/etc/_jaas.conf.tpl', 'kafka/templates/monitoring/prometheus/bin/_kafka-exporter.sh.tpl', 'zookeeper/templates/configmap-etc.yaml']",11,7ad31c98b7726448955c6a3b3dad8d3fe85e524d,kafka-auth,"{{- if .Values.manifests.secret_kafka }} jaas.conf: | {{ tuple ""etc/_jaas.conf.tpl"" . | include ""helm-toolkit.utils.template"" | b64enc | indent 4}} {{- end }}",,245,2
openstack%2Fopenstack-helm-infra~master~I3ce0afba155e923b6dd50f83fa6b529908b9a79b,openstack/openstack-helm-infra,master,I3ce0afba155e923b6dd50f83fa6b529908b9a79b,Disable kubeadm-aio jobs while issues addressed,MERGED,2019-12-18 15:53:46.000000000,2019-12-31 19:05:19.000000000,2019-12-31 19:02:37.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-12-18 15:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/df5210068dcfdf102d57f9c94bf2c85bf45117bb', 'message': 'Disable kubeadm-aio jobs while issues addressed\n\nThis disables the keystone-auth single node job and all multinode\nperiodic and experimental jobs while standing issues with the\nkubeadm-aio image deployment are sorted out\n\nChange-Id: I3ce0afba155e923b6dd50f83fa6b529908b9a79b\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-12-18 15:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e00c95df1689f6740622a3b6d2aa558698b080d1', 'message': 'Disable kubeadm-aio jobs while issues addressed\n\nThis disables the keystone-auth single node job and all multinode\nperiodic and experimental jobs while standing issues with the\nkubeadm-aio image deployment are sorted out\n\nChange-Id: I3ce0afba155e923b6dd50f83fa6b529908b9a79b\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-12-18 19:56:33.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/803f0e8435400238fda6e7da1da8cac6557d3f81', 'message': 'Disable kubeadm-aio jobs while issues addressed\n\nThis disables the keystone-auth single node job and all multinode\nperiodic and experimental jobs while standing issues with the\nkubeadm-aio image deployment are sorted out\n\nChange-Id: I3ce0afba155e923b6dd50f83fa6b529908b9a79b\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,699714,803f0e8435400238fda6e7da1da8cac6557d3f81,11,3,3,17591,,,0,"Disable kubeadm-aio jobs while issues addressed

This disables the keystone-auth single node job and all multinode
periodic and experimental jobs while standing issues with the
kubeadm-aio image deployment are sorted out

Change-Id: I3ce0afba155e923b6dd50f83fa6b529908b9a79b
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/14/699714/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,df5210068dcfdf102d57f9c94bf2c85bf45117bb,update-beats-versions, # NOTE(srwilkers): Disabling this job until issues with the kubeadm-aio # based deployments are addressed # NOTE(srwilkers): Disabling all periodic and experimental jobs until # issues with the kubeadm-aio based deployments are addressed # periodic: # jobs: # - openstack-helm-infra-tenant-ceph # - openstack-helm-infra-five-ubuntu # - openstack-helm-infra-armada-deploy # - openstack-helm-infra-armada-update-uuid # - openstack-helm-infra-armada-update-passwords # experimental: # jobs: # - openstack-helm-infra-five-ubuntu # - openstack-helm-infra-tenant-ceph # - openstack-helm-infra-elastic-beats # - openstack-helm-infra-armada-deploy # - openstack-helm-infra-armada-update-uuid # - openstack-helm-infra-armada-update-passwords, periodic: jobs: - openstack-helm-infra-tenant-ceph - openstack-helm-infra-five-ubuntu - openstack-helm-infra-armada-deploy - openstack-helm-infra-armada-update-uuid - openstack-helm-infra-armada-update-passwords experimental: jobs: - openstack-helm-infra-five-ubuntu - openstack-helm-infra-tenant-ceph - openstack-helm-infra-elastic-beats - openstack-helm-infra-armada-deploy - openstack-helm-infra-armada-update-uuid - openstack-helm-infra-armada-update-passwords,19,15
openstack%2Fopenstack-helm~master~I4e1de001ddf17b3c035ca174b7ef8acec8f2bf2c,openstack/openstack-helm,master,I4e1de001ddf17b3c035ca174b7ef8acec8f2bf2c,Disable kubeadm-aio jobs while issues addressed,MERGED,2019-12-18 15:56:07.000000000,2019-12-31 19:04:06.000000000,2019-12-31 19:01:37.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-12-18 15:56:07.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f6fe35d452e214a31040383252316c9614c9b620', 'message': 'Disable kubeadm-aio jobs while issues addressed\n\nThis disables the keystone-auth single node job and all multinode\nperiodic and experimental jobs while standing issues with the\nkubeadm-aio image deployment are sorted out\n\nChange-Id: I4e1de001ddf17b3c035ca174b7ef8acec8f2bf2c\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,699716,f6fe35d452e214a31040383252316c9614c9b620,14,4,1,17591,,,0,"Disable kubeadm-aio jobs while issues addressed

This disables the keystone-auth single node job and all multinode
periodic and experimental jobs while standing issues with the
kubeadm-aio image deployment are sorted out

Change-Id: I4e1de001ddf17b3c035ca174b7ef8acec8f2bf2c
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/16/699716/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,f6fe35d452e214a31040383252316c9614c9b620,disable-kubeadm-jobs, # NOTE(srwilkers): Disabling the following jobs until # issues with the kubeadm-aio based deployments are addressed # - openstack-helm-multinode-temp-ubuntu # - openstack-helm-ironic-ubuntu # - openstack-helm-armada-deploy # - openstack-helm-armada-update-uuid # - openstack-helm-armada-update-passwords # NOTE(srwilkers): Disabling the following jobs until # issues with the kubeadm-aio based deployments are addressed # experimental: # jobs: # - openstack-helm-armada-deploy # - openstack-helm-armada-update-uuid # - openstack-helm-armada-update-passwords, - openstack-helm-multinode-temp-ubuntu - openstack-helm-ironic-ubuntu - openstack-helm-armada-deploy - openstack-helm-armada-update-uuid - openstack-helm-armada-update-passwords experimental: jobs: - openstack-helm-armada-deploy - openstack-helm-armada-update-uuid - openstack-helm-armada-update-passwords,14,10
openstack%2Fironic~master~Id00d8886b2025203ec0023092064aa8f70904202,openstack/ironic,master,Id00d8886b2025203ec0023092064aa8f70904202,Remove those switches for python2.,MERGED,2019-12-26 02:34:12.000000000,2019-12-31 18:02:24.000000000,2019-12-31 18:00:50.000000000,"[{'_account_id': 10206}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 29792}]","[{'number': 1, 'created': '2019-12-26 02:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5d105355ac0d82d9d3679743076f91b5ff6e9cb', 'message': 'Remove those switches for python2.\n\nChange-Id: Id00d8886b2025203ec0023092064aa8f70904202\n'}, {'number': 2, 'created': '2019-12-26 08:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/55bedc653f2b8e596700348c614f8d1d3dbc2e1d', 'message': 'Remove those switches for python2.\n\nChange-Id: Id00d8886b2025203ec0023092064aa8f70904202\n'}, {'number': 3, 'created': '2019-12-26 08:47:44.000000000', 'files': ['doc/source/contributor/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/82b17f0b041d4d22166bbbda29ac62f3153a0bb6', 'message': 'Remove those switches for python2.\n\nChange-Id: Id00d8886b2025203ec0023092064aa8f70904202\n'}]",13,700578,82b17f0b041d4d22166bbbda29ac62f3153a0bb6,18,6,3,29792,,,0,"Remove those switches for python2.

Change-Id: Id00d8886b2025203ec0023092064aa8f70904202
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/700578/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/dev-quickstart.rst'],1,a5d105355ac0d82d9d3679743076f91b5ff6e9cb,," # to run the py3 unit tests, and the style tests # run the unit tests under and also run the pep8 tests tox -epep8 # run a specific test for Python tox -- test_conductor"," # to run the py27, py3 unit tests, and the style tests # run the unit tests under py27 and also run the pep8 tests tox -epy27 -epep8 # run a specific test for Python 2.7 tox -epy27 -- test_conductor",5,5
openstack%2Fironic~master~I3e3d672eed0e059de7b01adc1e009f01dbd35a74,openstack/ironic,master,I3e3d672eed0e059de7b01adc1e009f01dbd35a74,Replace disk-image-create with ironic-python-agent-builder,MERGED,2019-12-27 05:27:07.000000000,2019-12-31 17:59:53.000000000,2019-12-31 17:58:16.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 05:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cfdf9ff5b79378e4cfc706093db012ae3a2a935b', 'message': 'Replace disk-image-create with ironic-python-agent-builder\n\nChange-Id: I3e3d672eed0e059de7b01adc1e009f01dbd35a74\n'}, {'number': 2, 'created': '2019-12-27 05:55:52.000000000', 'files': ['doc/source/admin/drivers/ilo.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fcbf25aec5bd5d39ffe3f2d727b3c03cdbd7825a', 'message': 'Replace disk-image-create with ironic-python-agent-builder\n\nChange-Id: I3e3d672eed0e059de7b01adc1e009f01dbd35a74\n'}]",0,700675,fcbf25aec5bd5d39ffe3f2d727b3c03cdbd7825a,11,4,2,10206,,,0,"Replace disk-image-create with ironic-python-agent-builder

Change-Id: I3e3d672eed0e059de7b01adc1e009f01dbd35a74
",git fetch https://review.opendev.org/openstack/ironic refs/changes/75/700675/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/drivers/ilo.rst'],1,cfdf9ff5b79378e4cfc706093db012ae3a2a935b,ipa_builder,Install ``ironic-python-agent-builder`` following the guide [1]_ ironic-python-agent-builder -o proliant-agent-ramdisk -e proliant-tools fedoraInstall ``ironic-python-agent-builder`` following the guide [1]_ ironic-python-agent-builder -o proliant-agent-ramdisk -e proliant-tools fedora.. [1] `ironic-python-agent-builder`: https://docs.openstack.org/ironic-python-agent-builder/latest/install/index.html, disk-image-create -o proliant-agent-ramdisk ironic-python-agent-ramdisk fedora proliant-tools disk-image-create -o proliant-agent-ramdisk ironic-python-agent-ramdisk fedora proliant-tools,5,2
openstack%2Fopenstack-helm-infra~master~I2d1cd051c61695a12aa11af1ecb356f91b9e8279,openstack/openstack-helm-infra,master,I2d1cd051c61695a12aa11af1ecb356f91b9e8279,[Ceph-OSD] Update exit code for flock,MERGED,2019-12-30 17:46:29.000000000,2019-12-31 16:44:50.000000000,2019-12-31 16:43:31.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 18538}, {'_account_id': 22348}, {'_account_id': 26686}, {'_account_id': 29108}, {'_account_id': 29132}, {'_account_id': 29974}]","[{'number': 1, 'created': '2019-12-30 17:46:29.000000000', 'files': ['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cd6f3442e9e17c366be2d3d9242b7f9ba214a945', 'message': '[Ceph-OSD] Update exit code for flock\n\nThe PS updates the exit code for flock. Now we are using default value (1)\nif timeout happened.\n\nChange-Id: I2d1cd051c61695a12aa11af1ecb356f91b9e8279\n'}]",0,700783,cd6f3442e9e17c366be2d3d9242b7f9ba214a945,13,8,1,17119,,,0,"[Ceph-OSD] Update exit code for flock

The PS updates the exit code for flock. Now we are using default value (1)
if timeout happened.

Change-Id: I2d1cd051c61695a12aa11af1ecb356f91b9e8279
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/83/700783/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/ceph-volume/_init-with-ceph-volume.sh.tpl'],1,cd6f3442e9e17c366be2d3d9242b7f9ba214a945,," flock -w 60 --verbose ""${lock_fd}"""," flock -w 60 -E 0 --verbose ""${lock_fd}""",1,1
openstack%2Fopenstack-ansible-os_tempest~master~Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41,openstack/openstack-ansible-os_tempest,master,Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41,Fix stackwiz venv pip install args,MERGED,2019-11-19 10:29:31.000000000,2019-12-31 16:40:56.000000000,2019-12-09 22:18:17.000000000,"[{'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23182}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-11-19 10:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/d49fbf29f76ef9fcfa45612dc631277052cb160f', 'message': 'Fix stackwiz venv pip install args\n\nStackwiz install use venv_pip_install_args when defined.\n\nChange-Id: Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41\nClose-bug: #1852276\n'}, {'number': 2, 'created': '2019-11-19 13:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0f9c4e7151a210974675d933e48cc732b3b32649', 'message': 'Fix stackwiz venv pip install args\n\nStackwiz install use venv_pip_install_args when defined.\n\nChange-Id: Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41\nClose-bug: #1852276\n'}, {'number': 3, 'created': '2019-11-19 14:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/10052890036f31c88c1548059f2d1d4370ee650a', 'message': 'Fix stackwiz venv pip install args\n\nStackwiz install use venv_pip_install_args when defined.\n\nChange-Id: Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41\nClose-bug: #1852276\n'}, {'number': 4, 'created': '2019-12-09 11:32:02.000000000', 'files': ['tasks/tempest_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/1bcb1ffbd8f8dc0ef4e4676c714ef369518ba0c9', 'message': 'Fix stackwiz venv pip install args\n\nStackwiz install use venv_pip_install_args when defined.\n\nChange-Id: Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41\nClose-bug: #1852276\n'}]",3,694979,1bcb1ffbd8f8dc0ef4e4676c714ef369518ba0c9,27,6,4,23182,,,0,"Fix stackwiz venv pip install args

Stackwiz install use venv_pip_install_args when defined.

Change-Id: Ib1cc8fbe721aff1840251e8858d9a4a7eaa1ab41
Close-bug: #1852276
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/79/694979/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_install.yml'],1,d49fbf29f76ef9fcfa45612dc631277052cb160f,bug/1852276," venv_pip_install_args: ""{{ venv_pip_install_args | default('--isolated') }}"""," venv_pip_install_args: ""--isolated""",1,1
openstack%2Fkeystoneauth~stable%2Ftrain~I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef,openstack/keystoneauth,stable/train,I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef,Fetch discovery documents with auth when needed,ABANDONED,2019-10-04 13:56:12.000000000,2019-12-31 14:42:03.000000000,,"[{'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-10-04 13:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/6cbfb5b370dbac7e96ea377d725dd442607c4ac5', 'message': 'Fetch discovery documents with auth when needed\n\nSome services, like Nova, default to requiring auth for their\nversioned discovery documents. This means strict discovery\ndoes not work on them, because discovery as it is now defaults\nto not sending auth. Just changing the default would be a behavior\nchange resulting in sending unneeded data with *every* request.\nInstead, respond to Unauthorized exceptions by retrying the request\nwith auth token. This way discovery will work for services that\nare otherwise blocking unauthenticated access, and will get more\nefficient over time as those services improve.\n\nDepends-On: https://review.opendev.org/686600\nChange-Id: I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef\n'}, {'number': 2, 'created': '2019-10-04 15:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/9b1cfcfda2798c15f25fa00890304c08b9526bc4', 'message': 'Fetch discovery documents with auth when needed\n\nSome services, like Nova, default to requiring auth for their\nversioned discovery documents. This means strict discovery\ndoes not work on them, because discovery as it is now defaults\nto not sending auth. Just changing the default would be a behavior\nchange resulting in sending unneeded data with *every* request.\nInstead, respond to Unauthorized exceptions by retrying the request\nwith auth token. This way discovery will work for services that\nare otherwise blocking unauthenticated access, and will get more\nefficient over time as those services improve.\n\nDepends-On: https://review.opendev.org/686600\nChange-Id: I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef\n'}, {'number': 3, 'created': '2019-10-04 16:35:31.000000000', 'files': ['keystoneauth1/discover.py', 'releasenotes/notes/retry-authenticated-discovery-19c4354ff983f507.yaml', 'keystoneauth1/tests/unit/test_discovery.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/a2907aa100ae37657a12aea129e2cde0be5477de', 'message': 'Fetch discovery documents with auth when needed\n\nSome services, like Nova, default to requiring auth for their\nversioned discovery documents. This means strict discovery\ndoes not work on them, because discovery as it is now defaults\nto not sending auth. Just changing the default would be a behavior\nchange resulting in sending unneeded data with *every* request.\nInstead, respond to Unauthorized exceptions by retrying the request\nwith auth token. This way discovery will work for services that\nare otherwise blocking unauthenticated access, and will get more\nefficient over time as those services improve.\n\nDepends-On: https://review.opendev.org/686600\nChange-Id: I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef\n'}]",2,686727,a2907aa100ae37657a12aea129e2cde0be5477de,10,3,3,2,,,0,"Fetch discovery documents with auth when needed

Some services, like Nova, default to requiring auth for their
versioned discovery documents. This means strict discovery
does not work on them, because discovery as it is now defaults
to not sending auth. Just changing the default would be a behavior
change resulting in sending unneeded data with *every* request.
Instead, respond to Unauthorized exceptions by retrying the request
with auth token. This way discovery will work for services that
are otherwise blocking unauthenticated access, and will get more
efficient over time as those services improve.

Depends-On: https://review.opendev.org/686600
Change-Id: I8a33e8a05bed0f18e4e42431f6d16b8a6a5270ef
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/27/686727/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth1/discover.py', 'releasenotes/notes/retry-authenticated-discovery-19c4354ff983f507.yaml', 'keystoneauth1/tests/unit/test_discovery.py']",3,6cbfb5b370dbac7e96ea377d725dd442607c4ac5,fix-auth-discovery," def test_run_discovery_auth(self): url = 'https://example.com' headers = {'Accept': 'application/json'} session = mock.Mock() session.get.side_effect = [ exceptions.Unauthorized('unauthorized'), # Throw a different exception the second time so that we can # catch it in the test and verify the retry. exceptions.BadRequest('bad request'), ] try: discover.get_version_data(session, url) except exceptions.BadRequest: pass # Only one call with 'url1' self.assertEqual(2, session.get.call_count) session.get.assert_has_calls([ mock.call(url, headers=headers, authenticated=None), mock.call(url, headers=headers, authenticated=True), ]) ",,41,1
openstack%2Fpython-swiftclient~master~Ia64cfd0d45d51d66d3c842a94ec7bdd98375f6e6,openstack/python-swiftclient,master,Ia64cfd0d45d51d66d3c842a94ec7bdd98375f6e6,Unit test validating header path in python3,ABANDONED,2016-12-22 12:29:25.000000000,2019-12-31 14:41:54.000000000,,[],"[{'number': 1, 'created': '2016-12-22 12:29:25.000000000', 'files': ['test-requirements.txt', 'tests/unit/test_swiftclient.py', 'tests/unit/fixtures/catalog.json'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/0bcbc4f2b44f864f47719cbc2e804a2edf0557f6', 'message': ""Unit test validating header path in python3\n\nAs part of working on shade in patch\nhttps://review.openstack.org/#/c/412108, we ran in to a fascinating\nproblem where we were getting bytes values back for container header\nvalues when we converted over to using requests_mock for mocking the\nrequests.Session object. It seemed there was either a but in\nrequests_mock or a bug in swiftclient.\n\nThis test is a reduction of the test that we had in shade to its bare\nminimum ... and lo and behold it shows that neither swiftclient nor\nrequests_mock have the bug we thought they had. NO CLUE what was going\non. In any case, I thought I'd put this up because it exists.\n\nChange-Id: Ia64cfd0d45d51d66d3c842a94ec7bdd98375f6e6\n""}]",0,414077,0bcbc4f2b44f864f47719cbc2e804a2edf0557f6,4,0,1,2,,,0,"Unit test validating header path in python3

As part of working on shade in patch
https://review.openstack.org/#/c/412108, we ran in to a fascinating
problem where we were getting bytes values back for container header
values when we converted over to using requests_mock for mocking the
requests.Session object. It seemed there was either a but in
requests_mock or a bug in swiftclient.

This test is a reduction of the test that we had in shade to its bare
minimum ... and lo and behold it shows that neither swiftclient nor
requests_mock have the bug we thought they had. NO CLUE what was going
on. In any case, I thought I'd put this up because it exists.

Change-Id: Ia64cfd0d45d51d66d3c842a94ec7bdd98375f6e6
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/77/414077/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tests/unit/test_swiftclient.py', 'tests/unit/fixtures/catalog.json']",3,0bcbc4f2b44f864f47719cbc2e804a2edf0557f6,,"{ ""access"": { ""token"": { ""issued_at"": ""2016-04-14T10:09:58.014014Z"", ""expires"": ""9999-12-31T23:59:59Z"", ""id"": ""7fa3037ae2fe48ada8c626a51dc01ffd"", ""tenant"": { ""enabled"": true, ""description"": ""Bootstrap project for initializing the cloud."", ""name"": ""admin"", ""id"": ""1c36b64c840a42cd9e9b931a369337f0"" }, ""audit_ids"": [ ""FgG3Q8T3Sh21r_7HyjHP8A"" ] }, ""serviceCatalog"": [ { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://compute.example.com/v2.1/1c36b64c840a42cd9e9b931a369337f0"", ""region"": ""RegionOne"", ""publicURL"": ""https://compute.example.com/v2.1/1c36b64c840a42cd9e9b931a369337f0"", ""internalURL"": ""https://compute.example.com/v2.1/1c36b64c840a42cd9e9b931a369337f0"", ""id"": ""32466f357f3545248c47471ca51b0d3a"" } ], ""type"": ""compute"", ""name"": ""nova"" }, { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://volume.example.com/v2/1c36b64c840a42cd9e9b931a369337f0"", ""region"": ""RegionOne"", ""publicURL"": ""https://volume.example.com/v2/1c36b64c840a42cd9e9b931a369337f0"", ""internalURL"": ""https://volume.example.com/v2/1c36b64c840a42cd9e9b931a369337f0"", ""id"": ""1e875ca2225b408bbf3520a1b8e1a537"" } ], ""type"": ""volumev2"", ""name"": ""cinderv2"" }, { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://image.example.com"", ""region"": ""RegionOne"", ""publicURL"": ""https://image.example.com"", ""internalURL"": ""https://image.example.com"", ""id"": ""5a64de3c4a614d8d8f8d1ba3dee5f45f"" } ], ""type"": ""image"", ""name"": ""glance"" }, { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://volume.example.com/v1/1c36b64c840a42cd9e9b931a369337f0"", ""region"": ""RegionOne"", ""publicURL"": ""https://volume.example.com/v1/1c36b64c840a42cd9e9b931a369337f0"", ""internalURL"": ""https://volume.example.com/v1/1c36b64c840a42cd9e9b931a369337f0"", ""id"": ""3d15fdfc7d424f3c8923324417e1a3d1"" } ], ""type"": ""volume"", ""name"": ""cinder"" }, { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://identity.example.com/v2.0"", ""region"": ""RegionOne"", ""publicURL"": ""https://identity.example.comv2.0"", ""internalURL"": ""https://identity.example.comv2.0"", ""id"": ""4deb4d0504a044a395d4480741ba628c"" } ], ""type"": ""identity"", ""name"": ""keystone"" }, { ""endpoints_links"": [], ""endpoints"": [ { ""adminURL"": ""https://object-store.example.com/v1/project"", ""region"": ""RegionOne"", ""publicURL"": ""https://object-store.example.com/v1/project"", ""internalURL"": ""https://object-store.example.com/v1/project"", ""id"": ""4deb4d0504a044a395d4480741ba628c"" } ], ""type"": ""object-store"", ""name"": ""swift"" } ], ""user"": { ""username"": ""dummy"", ""roles_links"": [], ""id"": ""71675f719c3343e8ac441cc28f396474"", ""roles"": [ { ""name"": ""admin"" } ], ""name"": ""admin"" }, ""metadata"": { ""is_admin"": 0, ""roles"": [ ""6d813db50b6e4a1ababdbbb5a83c7de5"" ] } } } ",,159,0
openstack%2Ftempest~master~I494b5ef08ba6c906827705a2a16d72e95e37af12,openstack/tempest,master,I494b5ef08ba6c906827705a2a16d72e95e37af12,Fix app cred client unit test name,MERGED,2019-12-23 22:03:29.000000000,2019-12-31 08:41:44.000000000,2019-12-31 08:40:16.000000000,"[{'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-12-23 22:03:29.000000000', 'files': ['tempest/tests/lib/services/identity/v3/test_application_credentials_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dce03904bc0ea707f79ea9427d9429462ffd286a', 'message': ""Fix app cred client unit test name\n\nA copy-paste error led to one of the application credential client unit\ntests being named 'test_delete_trust' which is not correct in this\ncontext. This change corrects the test name\n\nChange-Id: I494b5ef08ba6c906827705a2a16d72e95e37af12\n""}]",0,700457,dce03904bc0ea707f79ea9427d9429462ffd286a,8,3,1,8482,,,0,"Fix app cred client unit test name

A copy-paste error led to one of the application credential client unit
tests being named 'test_delete_trust' which is not correct in this
context. This change corrects the test name

Change-Id: I494b5ef08ba6c906827705a2a16d72e95e37af12
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/700457/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/lib/services/identity/v3/test_application_credentials_client.py'],1,dce03904bc0ea707f79ea9427d9429462ffd286a,app-cred-client-tests, def test_delete_application_credential(self):, def test_delete_trust(self):,1,1
openstack%2Fzaqar~master~If7f2f5c98be866a876fe82c0941e8a341e392b89,openstack/zaqar,master,If7f2f5c98be866a876fe82c0941e8a341e392b89,Update requirements,ABANDONED,2016-02-18 14:22:17.000000000,2019-12-31 07:39:52.000000000,,"[{'_account_id': 8846}, {'_account_id': 17081}]","[{'number': 1, 'created': '2016-02-18 14:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c95ed03954cfd8390774bf57b9741923e8f0626a', 'message': 'Update requirements\n\npytz is used currently in our code, but WebOb is not.\n\nChange-Id: If7f2f5c98be866a876fe82c0941e8a341e392b89\n'}, {'number': 2, 'created': '2016-02-22 03:57:32.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/53da5a8e049b9ddbef950c241f53d710314ea2b5', 'message': 'Update requirements\n\npytz is used currently in our code[1], but WebOb is not.\n\n[1]https://github.com/openstack/zaqar/blob/master/zaqar/transport/\nwebsocket/protocol.py#L134\n\nChange-Id: If7f2f5c98be866a876fe82c0941e8a341e392b89\n'}]",1,281884,53da5a8e049b9ddbef950c241f53d710314ea2b5,10,2,2,17081,,,0,"Update requirements

pytz is used currently in our code[1], but WebOb is not.

[1]https://github.com/openstack/zaqar/blob/master/zaqar/transport/
websocket/protocol.py#L134

Change-Id: If7f2f5c98be866a876fe82c0941e8a341e392b89
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/84/281884/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c95ed03954cfd8390774bf57b9741923e8f0626a,update-requirments,pytz>=2013.6 # MIT,WebOb>=1.2.3 # MIT,1,1
openstack%2Ffreezer-web-ui~master~I68b0eecd6b17be0e059fccdbced5784151c0e492,openstack/freezer-web-ui,master,I68b0eecd6b17be0e059fccdbced5784151c0e492,translation: drop babel extractor definitions,MERGED,2019-12-26 17:08:32.000000000,2019-12-31 07:04:38.000000000,2019-12-31 07:04:38.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:08:32.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/d0e560fc91028e6ab5c9802f30648bb8a2d1d80c', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I68b0eecd6b17be0e059fccdbced5784151c0e492\n'}]",0,700630,d0e560fc91028e6ab5c9802f30648bb8a2d1d80c,7,3,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I68b0eecd6b17be0e059fccdbced5784151c0e492
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/30/700630/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,d0e560fc91028e6ab5c9802f30648bb8a2d1d80c,babel-config,[angular: **/static/**.html] ,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # .../dashboards/XYZ/static which will ensure # that plugins are also translated. [angular: **/static/**.html],1,16
openstack%2Fcyborg~master~Id9b6656b14298f1bfff01f5a195638e516109907,openstack/cyborg,master,Id9b6656b14298f1bfff01f5a195638e516109907,Improve objects/device.py UT coverage from 82% to 100%,MERGED,2019-12-19 02:53:12.000000000,2019-12-31 06:34:31.000000000,2019-12-31 06:33:05.000000000,"[{'_account_id': 14107}, {'_account_id': 14131}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 27458}, {'_account_id': 28748}]","[{'number': 1, 'created': '2019-12-19 02:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/63627140ae05b25727028c07959320ab86f7be69', 'message': 'Improve objects/device.py UT coverage from 76% to 100%\n\nChange-Id: Id9b6656b14298f1bfff01f5a195638e516109907\nStory: 2007036\n'}, {'number': 2, 'created': '2019-12-19 11:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/ba3cee1ec72da48d83a1c8e13f9afc1d61b991bb', 'message': 'Improve objects/device.py UT coverage from 82% to 100%\n\nChange-Id: Id9b6656b14298f1bfff01f5a195638e516109907\nStory: 2007036\n'}, {'number': 3, 'created': '2019-12-21 02:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/ecd9bc527518298a3cba9512a807cd70bef33acf', 'message': 'Improve objects/device.py UT coverage from 82% to 100%\n\nChange-Id: Id9b6656b14298f1bfff01f5a195638e516109907\nStory: 2007036\nTask: 37842\n'}, {'number': 4, 'created': '2019-12-23 02:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f9e45edca30d804dd371e8cc05883386c1508033', 'message': 'Improve objects/device.py UT coverage from 82% to 100%\n\nChange-Id: Id9b6656b14298f1bfff01f5a195638e516109907\nStory: 2007036\nTask: 37842\n'}, {'number': 5, 'created': '2019-12-30 02:41:51.000000000', 'files': ['cyborg/tests/unit/objects/test_device.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/7d98ff25993d5dd2acd3c88650fe39aa66688bff', 'message': 'Improve objects/device.py UT coverage from 82% to 100%\n\nChange-Id: Id9b6656b14298f1bfff01f5a195638e516109907\nStory: 2007036\nTask: 37842\n'}]",18,699906,7d98ff25993d5dd2acd3c88650fe39aa66688bff,30,8,5,28748,,,0,"Improve objects/device.py UT coverage from 82% to 100%

Change-Id: Id9b6656b14298f1bfff01f5a195638e516109907
Story: 2007036
Task: 37842
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/06/699906/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg/tests/unit/objects/test_device.py'],1,63627140ae05b25727028c07959320ab86f7be69,fix_get_device_id," def test_get_by_hostname(self): hostname = self.fake_device['hostname'] dev_filter = {'hostname': hostname} with mock.patch.object(objects.Device, 'list', autospec=True) as mock_device_list: mock_device_list.return_value = [self.fake_device] attach_handles = objects.Device.get_list_by_hostname( self.context, hostname) mock_device_list.assert_called_once_with( self.context, dev_filter) self.assertEqual( hostname, attach_handles[0]['hostname']) def test_get_by_device_id(self): device_id = self.fake_device['id'] dev_filter = {'device_id': device_id} with mock.patch.object(objects.Device, 'list', autospec=True) as mock_device_list: mock_device_list.return_value = [self.fake_device] attach_handles = objects.Device.get_by_device_id( self.context, device_id) mock_device_list.assert_called_once_with( self.context, dev_filter) self.assertEqual( device_id, attach_handles[0]['id']) def test_list_with_filter(self): with mock.patch.object(self.dbapi, 'device_list_by_filters', autospec=True) as mock_device_with_filter_list: mock_device_with_filter_list.return_value = [self.fake_device] filters = {'limit': 1} devices = objects.Device.list(self.context, filters) self.assertEqual(1, mock_device_with_filter_list.call_count) self.assertEqual(1, len(devices)) self.assertIsInstance(devices[0], objects.Device) mock_device_with_filter_list.assert_called_once_with( self.context, {}, sort_dir='desc', sort_key='created_at', limit=1, marker=None, ) ",,46,0
openstack%2Ftripleo-quickstart-extras~master~I7075f06923272bce67f9b5987e1a6c68c3372289,openstack/tripleo-quickstart-extras,master,I7075f06923272bce67f9b5987e1a6c68c3372289,Add failing tempest test to skip list,MERGED,2019-12-23 18:47:00.000000000,2019-12-31 05:05:25.000000000,2019-12-30 22:01:58.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 18:47:00.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_queens.yml', 'roles/validate-tempest/vars/tempest_skip_rocky.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/851fdafe3b01e0ae80ef18c9f224912d612ff264', 'message': 'Add failing tempest test to skip list\n\nQueens and Rocky started failing fs020 recently.\nAdding failing tempest tests to skip list to\nallow time for failure investigation.\n\nChange-Id: I7075f06923272bce67f9b5987e1a6c68c3372289\nRelated-Bug: #1857365\n'}]",0,700443,851fdafe3b01e0ae80ef18c9f224912d612ff264,15,4,1,9976,,,0,"Add failing tempest test to skip list

Queens and Rocky started failing fs020 recently.
Adding failing tempest tests to skip list to
allow time for failure investigation.

Change-Id: I7075f06923272bce67f9b5987e1a6c68c3372289
Related-Bug: #1857365
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/43/700443/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/validate-tempest/vars/tempest_skip_queens.yml', 'roles/validate-tempest/vars/tempest_skip_rocky.yml']",2,851fdafe3b01e0ae80ef18c9f224912d612ff264,bug1857365, - test: 'tempest.api.compute.admin.test_servers_on_multinodes.ServersOnMultiNodesTest.test_create_servers_on_different_hosts_with_list_of_servers' reason: 'Errors with servres on multiple nodes' lp: 'https://bugs.launchpad.net/tripleo/+bug/1857365',,15,0
openstack%2Fpython-tricircleclient~master~I7d608f8dd142283101e54f9c211813ebdf739c3f,openstack/python-tricircleclient,master,I7d608f8dd142283101e54f9c211813ebdf739c3f,Drop python 2.7 support and testing,MERGED,2019-10-30 07:11:44.000000000,2019-12-31 04:54:14.000000000,2019-12-31 04:52:31.000000000,"[{'_account_id': 8556}, {'_account_id': 8726}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-30 07:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/a756210d874d4ba042a75444b033dc317a5d7299', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\npython-tricircleclient is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7d608f8dd142283101e54f9c211813ebdf739c3f\n'}, {'number': 2, 'created': '2019-12-13 23:48:11.000000000', 'files': ['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-3c68ac538cef7e83.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/27bfddea9d3d13670b4aae40698b88751633132f', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\npython-tricircleclient is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7d608f8dd142283101e54f9c211813ebdf739c3f\n'}]",0,692049,27bfddea9d3d13670b4aae40698b88751633132f,11,3,2,8556,,,0,"Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

python-tricircleclient is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Change-Id: I7d608f8dd142283101e54f9c211813ebdf739c3f
",git fetch https://review.opendev.org/openstack/python-tricircleclient refs/changes/49/692049/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-3c68ac538cef7e83.yaml', 'setup.cfg', 'tox.ini']",4,a756210d874d4ba042a75444b033dc317a5d7299,drop-py27-support,"envlist = py37,pep8","envlist = py27,py37,pep8",8,5
openstack%2Fheat-tempest-plugin~master~I79e7672e844c60d9d49d1255d33b413e72e4184e,openstack/heat-tempest-plugin,master,I79e7672e844c60d9d49d1255d33b413e72e4184e,[TEST] only for test,ABANDONED,2019-12-29 14:45:31.000000000,2019-12-31 03:28:39.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-29 14:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/308dd211562815ff640d7d4afedd2ea8496f4b1f', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 2, 'created': '2019-12-29 18:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/bdbaf730321e3069029d6acc560b75dce43bdb5d', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 3, 'created': '2019-12-30 01:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/a1c1feeafe4afa8cbc4cb5283fdc92c0fed02836', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 4, 'created': '2019-12-30 04:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/51ed87c0e1d2e8f212333b8d43a52073d44b6cc6', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 5, 'created': '2019-12-30 04:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/94c7f1f427a693901902788f9eb16803da9fe60c', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 6, 'created': '2019-12-30 05:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/07fb2951b25b6cf8c0771f25bedb74ac7b31ea71', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 7, 'created': '2019-12-30 07:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/9da9e9737ea7b4297581d229ba0993a6e4b1c792', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 8, 'created': '2019-12-30 12:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/bb8b520e2aebfc72ee275a39f2f96e476000d215', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 9, 'created': '2019-12-30 15:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/df1ef8d422f05a68b9b03ba828d86d99b51b0c98', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}, {'number': 10, 'created': '2019-12-30 17:32:28.000000000', 'files': ['heat_tempest_plugin/tests/functional/test_event_sinks.py', 'heat_tempest_plugin/services/clients.py', 'heat_tempest_plugin/tests/api/test_heat_api.py', 'heat_tempest_plugin/common/test.py', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/aadbb66fd9db7efa67b5167d9a43cd53c857dcf2', 'message': '[TEST] only for test\n\nChange-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e\n'}]",0,700751,aadbb66fd9db7efa67b5167d9a43cd53c857dcf2,13,1,10,12404,,,0,"[TEST] only for test

Change-Id: I79e7672e844c60d9d49d1255d33b413e72e4184e
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/51/700751/10 && git format-patch -1 --stdout FETCH_HEAD,['heat_tempest_plugin/common/test.py'],1,308dd211562815ff640d7d4afedd2ea8496f4b1f,test, if self.conf.auth_url is None: raise KeyError(config.CONF.heat_plugin.__dict__),,2,0
openstack%2Fkolla~master~Ie2a1077f7def0743f1403341985e2109aa490026,openstack/kolla,master,Ie2a1077f7def0743f1403341985e2109aa490026,create missing apache2 directory on Debian/Ubuntu,MERGED,2019-05-28 10:03:28.000000000,2019-12-31 02:05:02.000000000,2019-06-05 11:48:21.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 23717}, {'_account_id': 24072}]","[{'number': 1, 'created': '2019-05-28 10:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8c23e2a9ccf863f852f8d017c10cb82a52d3a1b9', 'message': ""create missing apache2 directory on Debian/Ubuntu\n\nUbuntu/source deployment of several images (horizon, placement-api, zun)\nfailed with:\n\n+ exec /usr/sbin/apache2 -DFOREGROUND apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot\n\nSo instead of fixing image by image let's create that directory\nglobally.\n\nChange-Id: Ie2a1077f7def0743f1403341985e2109aa490026\n""}, {'number': 2, 'created': '2019-06-03 09:09:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/55b254f526100156b3e901ecf264781ef1182050', 'message': ""create missing apache2 directory on Debian/Ubuntu\n\nUbuntu/source deployment of several images (horizon, placement-api, zun)\nfailed with:\n\n+ exec /usr/sbin/apache2 -DFOREGROUND apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot\n\nSo instead of fixing image by image let's create that directory\nglobally.\n\nChange-Id: Ie2a1077f7def0743f1403341985e2109aa490026\n""}, {'number': 3, 'created': '2019-06-03 13:11:48.000000000', 'files': ['docker/panko/panko-api/extend_start.sh', 'docker/heat/heat-base/extend_start.sh', 'docker/monasca/monasca-log-api/extend_start.sh', 'docker/barbican/barbican-api/extend_start.sh', 'docker/octavia/octavia-api/extend_start.sh', 'docker/vitrage/vitrage-api/extend_start.sh', 'docker/cinder/cinder-api/extend_start.sh', 'docker/monasca/monasca-api/extend_start.sh', 'docker/keystone/keystone/extend_start.sh', 'docker/crane/extend_start.sh', 'docker/cyborg/cyborg-api/extend_start.sh', 'docker/ironic/ironic-api/extend_start.sh', 'docker/ironic/ironic-pxe/extend_start.sh', 'docker/cloudkitty/cloudkitty-api/extend_start.sh', 'docker/tripleo-ui/extend_start.sh', 'docker/aodh/aodh-api/extend_start.sh', 'docker/gnocchi/gnocchi-api/extend_start.sh', 'docker/zaqar/zaqar-wsgi/extend_start.sh', 'docker/freezer/freezer-api/extend_start.sh', 'docker/nova/nova-api/extend_start.sh', 'docker/mistral/mistral-api/extend_start.sh', 'docker/zun/zun-api/extend_start.sh', 'docker/manila/manila-api/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/932f09bcd65e15524b5229fdb6bc73a7e0111b27', 'message': 'create missing apache2 directory on Debian/Ubuntu\n\nUbuntu/source deployment of several images (horizon, placement-api, zun)\nfailed with:\n\n+ exec /usr/sbin/apache2 -DFOREGROUND\napache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot\n\nChange-Id: Ie2a1077f7def0743f1403341985e2109aa490026\n'}]",0,661713,932f09bcd65e15524b5229fdb6bc73a7e0111b27,24,7,3,24072,,,0,"create missing apache2 directory on Debian/Ubuntu

Ubuntu/source deployment of several images (horizon, placement-api, zun)
failed with:

+ exec /usr/sbin/apache2 -DFOREGROUND
apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot

Change-Id: Ie2a1077f7def0743f1403341985e2109aa490026
",git fetch https://review.opendev.org/openstack/kolla refs/changes/13/661713/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/start.sh', 'docker/horizon/extend_start.sh', 'docker/placement/placement-api/extend_start.sh']",3,8c23e2a9ccf863f852f8d017c10cb82a52d3a1b9,661713,, install -d /var/run/apache2/,6,2
openstack%2Fzun~master~I6e57b4f5ff7d63a4f876de6453f1aa8c8ca95d23,openstack/zun,master,I6e57b4f5ff7d63a4f876de6453f1aa8c8ca95d23,Remove unused db column 'meta' from 'container' table,MERGED,2019-12-30 17:20:56.000000000,2019-12-31 01:39:47.000000000,2019-12-31 01:38:18.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-30 17:20:56.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/models.py', 'zun/db/sqlalchemy/alembic/versions/c2052ead4f95_remove_meta_from_container.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/4a6cbe7d05b8ac190823c2232e09d1dc70a9fa82', 'message': ""Remove unused db column 'meta' from 'container' table\n\nChange-Id: I6e57b4f5ff7d63a4f876de6453f1aa8c8ca95d23\n""}]",0,700781,4a6cbe7d05b8ac190823c2232e09d1dc70a9fa82,7,2,1,11536,,,0,"Remove unused db column 'meta' from 'container' table

Change-Id: I6e57b4f5ff7d63a4f876de6453f1aa8c8ca95d23
",git fetch https://review.opendev.org/openstack/zun refs/changes/81/700781/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/models.py', 'zun/db/sqlalchemy/alembic/versions/c2052ead4f95_remove_meta_from_container.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py']",5,4a6cbe7d05b8ac190823c2232e09d1dc70a9fa82,," 'Capsule': '1.3-3ef24a2b99fa141caffa564dd3880fc5', 'CapsuleContainer': '1.3-2de3af3092ecb918e4d270c7bb2d93cb', 'CapsuleInitContainer': '1.3-2de3af3092ecb918e4d270c7bb2d93cb', 'Container': '1.42-cc5b84f4d846f2c0cf6231e808f1a4d1',"," 'Capsule': '1.2-09d3dd7dba14b637e8fac2ba79a7f624', 'CapsuleContainer': '1.2-068254182aa6a33e6cadad60bf9e5640', 'CapsuleInitContainer': '1.2-068254182aa6a33e6cadad60bf9e5640', 'Container': '1.41-aa2199ccf568ee0a229606508c9b2d6e',",43,11
openstack%2Fopenstack-ansible~master~I3180d3331f7daccbdb25dd832e2a82f99c9b4d35,openstack/openstack-ansible,master,I3180d3331f7daccbdb25dd832e2a82f99c9b4d35,Bump SHAs for master,ABANDONED,2019-12-15 13:48:16.000000000,2019-12-30 22:36:23.000000000,,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 25591}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-12-15 13:48:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2946123243a35480a4d89f532140836ee6d0a4e6', 'message': 'Bump SHAs for master\n\nChange-Id: I3180d3331f7daccbdb25dd832e2a82f99c9b4d35\n'}, {'number': 2, 'created': '2019-12-20 15:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/96c2a0e2eb4d191e6d3184b1b5d949f214a3081d', 'message': 'Bump SHAs for master\n\nChange-Id: I3180d3331f7daccbdb25dd832e2a82f99c9b4d35\n'}, {'number': 3, 'created': '2019-12-20 15:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/35206c98f40381f14b6742372b8674be6b9d543c', 'message': 'Bump SHAs for master\n\nDepends-On: https://review.opendev.org/699684\nChange-Id: I3180d3331f7daccbdb25dd832e2a82f99c9b4d35\n'}, {'number': 4, 'created': '2019-12-24 22:42:59.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/ceph_keyrings_in_files-7d6a01e64861f8c6.yaml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4342ea1da58af73a77439f53fcb6a325f7db30ba', 'message': 'Bump SHAs for master\n\nDepends-On: https://review.opendev.org/699684\nChange-Id: I3180d3331f7daccbdb25dd832e2a82f99c9b4d35\n'}]",0,699123,4342ea1da58af73a77439f53fcb6a325f7db30ba,21,5,4,28619,,,0,"Bump SHAs for master

Depends-On: https://review.opendev.org/699684
Change-Id: I3180d3331f7daccbdb25dd832e2a82f99c9b4d35
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/23/699123/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/ceph_keyrings_in_files-7d6a01e64861f8c6.yaml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",5,2946123243a35480a4d89f532140836ee6d0a4e6,bump_osa,tempest_git_install_branch: 83c606135bbaf13223499a6765339bdd129006f7 # HEAD as of 15.12.2019,tempest_git_install_branch: 5d9229b5216037586d4e8f6920d6e21bf11f41ae # HEAD as of 01.12.2019,63,48
openstack%2Fpython-tripleoclient~master~I44fd6811dab17b78959ed6fe52d2961ea625a04e,openstack/python-tripleoclient,master,I44fd6811dab17b78959ed6fe52d2961ea625a04e,Whitelist the profile_tasks callback by default,MERGED,2019-12-09 21:47:01.000000000,2019-12-30 19:13:57.000000000,2019-12-30 19:12:42.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 10969}, {'_account_id': 11090}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-09 21:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8ae0ce6a9cbcaf659aaab7598a20e2880dd8f6d2', 'message': 'Whitelist the profile_tasks callback by default\n\nThis change adds the profile_tasks plugin to our default callback\nwhitelist which will allow us to collect data on process runtimes\nby default.\n\nChange-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-12-10 00:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/078206b13fe6cf06a5e8075aa9ca7ba4704d5422', 'message': 'Whitelist the profile_tasks callback by default\n\nThis change adds the profile_tasks plugin to our default callback\nwhitelist which will allow us to collect data on process runtimes\nby default.\n\nChange-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2019-12-10 14:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e3e22fb3b12a43a366d6568e17e692fb9f8b0d2b', 'message': 'Whitelist the profile_tasks callback by default\n\nThis change adds the profile_tasks plugin to our default callback\nwhitelist which will allow us to collect data on process runtimes\nby default.\n\nChange-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 4, 'created': '2019-12-17 15:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/678fa7e2e8bcc789ec77df3b43b30aed1a115036', 'message': 'Whitelist the profile_tasks callback by default\n\nThis change adds the profile_tasks plugin to our default callback\nwhitelist which will allow us to collect data on process runtimes\nby default.\n\nChange-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 5, 'created': '2019-12-20 03:47:11.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ff1b07778dc775c16eb4f142375ef06a4656140f', 'message': 'Whitelist the profile_tasks callback by default\n\nThis change adds the profile_tasks plugin to our default callback\nwhitelist which will allow us to collect data on process runtimes\nby default.\n\nChange-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",1,698096,ff1b07778dc775c16eb4f142375ef06a4656140f,41,10,5,7353,,,0,"Whitelist the profile_tasks callback by default

This change adds the profile_tasks plugin to our default callback
whitelist which will allow us to collect data on process runtimes
by default.

Change-Id: I44fd6811dab17b78959ed6fe52d2961ea625a04e
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/96/698096/3 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,8ae0ce6a9cbcaf659aaab7598a20e2880dd8f6d2,," callback_whitelist = ','.join([callback_whitelist, 'profile_tasks'])"," if verbosity > 0: callback_whitelist = ','.join([callback_whitelist, 'profile_tasks'])",1,2
openstack%2Ftripleo-heat-templates~master~I6d2765cff7045aa2c91f3cd47f570f6bf842bc9f,openstack/tripleo-heat-templates,master,I6d2765cff7045aa2c91f3cd47f570f6bf842bc9f,Fix nuage firewall rules,MERGED,2019-12-23 17:32:20.000000000,2019-12-30 18:35:19.000000000,2019-12-30 18:35:18.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 17:32:20.000000000', 'files': ['deployment/neutron/neutron-controller-plugin-nuage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/849e07f2494d60de77fbaad951b1429ef3ab3612', 'message': ""Fix nuage firewall rules\n\nWe switched to ansible for firewall rule management but the nuage\nfile wasn't properly converted.\n\nChange-Id: I6d2765cff7045aa2c91f3cd47f570f6bf842bc9f\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",0,700440,849e07f2494d60de77fbaad951b1429ef3ab3612,18,5,1,7353,,,0,"Fix nuage firewall rules

We switched to ansible for firewall rule management but the nuage
file wasn't properly converted.

Change-Id: I6d2765cff7045aa2c91f3cd47f570f6bf842bc9f
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/700440/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-controller-plugin-nuage.yaml'],1,849e07f2494d60de77fbaad951b1429ef3ab3612,bug/1857356, firewall_rules: - if: - apply_vxlan_iptables_rule - '118 neutron vxlan networks': proto: 'udp' dport: 4789 - {}, - if: - apply_vxlan_iptables_rule - tripleo.neutron_controller_plugin_nuage.firewall_rules: '118 neutron vxlan networks': proto: 'udp' dport: 4789 - {} ,7,9
openstack%2Ftripleo-common~stable%2Ftrain~Idf0351dbc05bb63ae180e61beb9e7f933dc6fa31,openstack/tripleo-common,stable/train,Idf0351dbc05bb63ae180e61beb9e7f933dc6fa31,Default to 50 Ansible forks.,MERGED,2019-12-19 17:06:43.000000000,2019-12-30 18:31:13.000000000,2019-12-30 18:29:53.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 17:06:43.000000000', 'files': ['tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/97480760291f350fe2fe20397d3a1ce3a097d643', 'message': 'Default to 50 Ansible forks.\n\nDuring the initial Overcloud deployment, tasks will be ran on 50\nhosts at a time now instead of 25. This allows for a faster\ndeployment of a large number of Overcloud nodes.\n\nChange-Id: Idf0351dbc05bb63ae180e61beb9e7f933dc6fa31\nSigned-off-by: Luke Short <ekultails@gmail.com>\n(cherry picked from commit 0fa8f221d2153738624dda80b43f902b95d6ac58)\n'}]",0,700031,97480760291f350fe2fe20397d3a1ce3a097d643,9,4,1,25877,,,0,"Default to 50 Ansible forks.

During the initial Overcloud deployment, tasks will be ran on 50
hosts at a time now instead of 25. This allows for a faster
deployment of a large number of Overcloud nodes.

Change-Id: Idf0351dbc05bb63ae180e61beb9e7f933dc6fa31
Signed-off-by: Luke Short <ekultails@gmail.com>
(cherry picked from commit 0fa8f221d2153738624dda80b43f902b95d6ac58)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/31/700031/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py']",2,97480760291f350fe2fe20397d3a1ce3a097d643,," self.assertEqual('50', ansible_cfg.get('defaults', 'forks'))"," self.assertEqual('25', ansible_cfg.get('defaults', 'forks'))",2,2
openstack%2Ftripleo-heat-templates~master~I0c651d127cd2bb179f7592a0519a5fd5064faeb3,openstack/tripleo-heat-templates,master,I0c651d127cd2bb179f7592a0519a5fd5064faeb3,Use async tasks for long running common tasks,MERGED,2019-12-12 23:21:26.000000000,2019-12-30 18:29:56.000000000,2019-12-30 18:29:56.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-12 23:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/305823d5b71cb7b2bf04382f4eb53ff1f8192063', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 2, 'created': '2019-12-13 19:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a84ef5cebd2f8e222d0cb6e3cdc37a9c3975a923', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 3, 'created': '2019-12-13 19:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d9aef7d061428f0799a05f5065200091ac91cf50', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 4, 'created': '2019-12-13 20:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61597e1f5ddf8b3eb3ea276b32422337c307fb5c', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 5, 'created': '2019-12-15 02:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ba93d199a1210283c271c7f8a7ea31696cbed441', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 6, 'created': '2019-12-15 13:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90a790640e26c7d13104fc8e25c71a46c8f3a17d', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}, {'number': 7, 'created': '2019-12-15 22:22:28.000000000', 'files': ['common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/106ce3267fd1471cee184f697f7cb19c695ab36c', 'message': 'Use async tasks for long running common tasks\n\nUse async with poll: 0 for the long running common tasks including:\n\n- puppet host configuration\n- container-puppet generate config\n- container starting\n- container-puppet bootstrap tasks\n\nExecuting the tasks in this manner and then polling for the results\ncauses all of the tasks to be started in parallel across all the nodes,\nregardless of the number of ansible forks configured.\n\nThe behavior will be that ansible will start the task on the first count\nof nodes that matches the configured forks value. Since poll:0, ansible\nwill immediately move on to the next batch, etc. Effectively, all the\ntasks are started in parallel just as quickly as ansible can start them.\n\nThe polling tasks (async_status) will then execute in parallel up to the\nconfigured number of forks. As tasks start to finish, ansible moves on\nto checking the status of the next batch (again, up to the configured\nnumber of forks). Since most nodes will configure around the same time,\nthe polling tasks finish roughly at the same time (except for\ndifferences in roles, such as controllers taking much longer).\n\nThis behavior results in a signifcant performance improvement at scale,\nor when deploying any number of nodes greater than the configured forks\nvalue. Instead of waiting for the first batch to fully complete, all the\nnodes are started in parallel.\n\nFor example, if puppet host configuration usually takes 5 minutes per\nnode, and there are 100 nodes, with 25 forks, previously this would have\ntaken 20 minutes. With this patch, it would now take closer to 5 minutes\nfor all 100 nodes, plus some overhead for polling.\n\nThis more closely matches the behavior previously used with Heat, when\nall the nodes were operating in ""pull"" mode in parallel.\n\nChange-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3\n'}]",0,698815,106ce3267fd1471cee184f697f7cb19c695ab36c,24,5,7,7144,,,0,"Use async tasks for long running common tasks

Use async with poll: 0 for the long running common tasks including:

- puppet host configuration
- container-puppet generate config
- container starting
- container-puppet bootstrap tasks

Executing the tasks in this manner and then polling for the results
causes all of the tasks to be started in parallel across all the nodes,
regardless of the number of ansible forks configured.

The behavior will be that ansible will start the task on the first count
of nodes that matches the configured forks value. Since poll:0, ansible
will immediately move on to the next batch, etc. Effectively, all the
tasks are started in parallel just as quickly as ansible can start them.

The polling tasks (async_status) will then execute in parallel up to the
configured number of forks. As tasks start to finish, ansible moves on
to checking the status of the next batch (again, up to the configured
number of forks). Since most nodes will configure around the same time,
the polling tasks finish roughly at the same time (except for
differences in roles, such as controllers taking much longer).

This behavior results in a signifcant performance improvement at scale,
or when deploying any number of nodes greater than the configured forks
value. Instead of waiting for the first batch to fully complete, all the
nodes are started in parallel.

For example, if puppet host configuration usually takes 5 minutes per
node, and there are 100 nodes, with 25 forks, previously this would have
taken 20 minutes. With this patch, it would now take closer to 5 minutes
for all 100 nodes, plus some overhead for polling.

This more closely matches the behavior previously used with Heat, when
all the nodes were operating in ""pull"" mode in parallel.

Change-Id: I0c651d127cd2bb179f7592a0519a5fd5064faeb3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/698815/3 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-tasks.yaml'],1,305823d5b71cb7b2bf04382f4eb53ff1f8192063,scale-and-performance," async: 3600 poll: 0 register: async_result - name: Wait for puppet host configuration to finish async_status: jid: ""{{ async_result.ansible_job_id }}"" register: outputs changed_when: outputs.rc == 2 failed_when: outputs.rc not in [0, 2] ignore_errors: true until: outputs.finished retries: 1200 delay: 3 tags: - host_config tags: - container_config - name: Wait for container-puppet tasks (generate config) to finish async_status: jid: ""{{ async_result.ansible_job_id }}"" register: outputs changed_when: false ignore_errors: true until: outputs.finished retries: 1200 delay: 3 when: step|int == 1 async: 3600 poll: 0 register: async_result tags: - container_startup_configs - name: Wait for containers to start for step {{ step }} using paunch async_status: jid: ""{{ async_result.ansible_job_id }}"" changed_when: false ignore_errors: true until: outputs.finished retries: 1200 delay: 3 async: 3600 poll: 0 register: async_result - name: Wait for container-puppet tasks (bootstrap tasks) for step {{ step }} to finish async_status: jid: ""{{ async_result.ansible_job_id }}"" register: outputs changed_when: false ignore_errors: true until: outputs.finished retries: 1200 delay: 3 when: host_container_puppet_tasks is defined tags: - container_config_tasks ", changed_when: outputs.rc == 2 register: outputs failed_when: false changed_when: false failed_when: false no_log: true failed_when: false changed_when: false register: outputs failed_when: false,59,10
openstack%2Ftripleo-heat-templates~master~I06ee04b9b47226433f25e3cff08c461462a907d9,openstack/tripleo-heat-templates,master,I06ee04b9b47226433f25e3cff08c461462a907d9,Execute deploy_steps_tasks per step,MERGED,2019-12-12 02:41:28.000000000,2019-12-30 18:29:54.000000000,2019-12-30 18:29:54.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-12 02:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c739f9016afc9a5b181d9e5b27ade59f828e593', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 2, 'created': '2019-12-12 02:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87c01719d97b82fe615808f6a253852223d83faf', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 3, 'created': '2019-12-12 15:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eb3e17393c19f320765b357b18fe7589dc5fd6c6', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 4, 'created': '2019-12-12 19:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2b0de371100d78c9940aad9943dff28de2f452ee', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 5, 'created': '2019-12-12 23:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/abe4b82ed477320db00ad6ec860b831eae8d3798', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 6, 'created': '2019-12-13 19:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ecf5fca56afd2e38fec74ca152eeea5f4743303d', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 7, 'created': '2019-12-15 13:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b60e3476c833d3885c5a252f40c8a81f0769f886', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}, {'number': 8, 'created': '2019-12-15 22:22:28.000000000', 'files': ['common/deploy-steps.j2', 'common/deploy-steps-tasks-step-0.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2a6336a742c05e2e6c5fd30a21cd1989823773a1', 'message': ""Execute deploy_steps_tasks per step\n\nInstead of including the entire deploy_steps_tasks.yaml tasks file for\neach role at each step, use the per-step files and only if they exist.\n\nThis cuts down on the amount of time that ansible has to spend skipping\ntasks that don't get run at a certain step, which can be significant at\nscale.\n\nChange-Id: I06ee04b9b47226433f25e3cff08c461462a907d9\nDepends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n""}]",0,698615,2a6336a742c05e2e6c5fd30a21cd1989823773a1,40,6,8,7144,,,0,"Execute deploy_steps_tasks per step

Instead of including the entire deploy_steps_tasks.yaml tasks file for
each role at each step, use the per-step files and only if they exist.

This cuts down on the amount of time that ansible has to spend skipping
tasks that don't get run at a certain step, which can be significant at
scale.

Change-Id: I06ee04b9b47226433f25e3cff08c461462a907d9
Depends-On: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/698615/7 && git format-patch -1 --stdout FETCH_HEAD,"['common/deploy-steps.j2', 'common/deploy-steps-tasks-step-0.j2.yaml']",2,3c739f9016afc9a5b181d9e5b27ade59f828e593,scale-and-performance,"- name: Check for {{role.name}}/deploy_steps_tasks_step{{step}}.yaml delegate_to: localhost run_once: true stat: path: ""{{ '{{' }} playbook_dir ~ '/' ~ {{role.name}} ~ '/' ~ 'deploy_steps_tasks_step{{step}}.yaml' {{ '}}' }}"" register: tasks_stat - include_tasks: {{role.name}}/deploy_steps_tasks_step{{step}}.yaml when: - tripleo_role_name == '{{role.name}}' - tasks_stat.stat.exists",- include_tasks: {{role.name}}/deploy_steps_tasks.yaml when: tripleo_role_name == '{{role.name}}',20,4
openstack%2Fzun~master~I093fdfc5beb1ca45993b36c4c9512fa511773965,openstack/zun,master,I093fdfc5beb1ca45993b36c4c9512fa511773965,Introduce VIFState object,MERGED,2019-12-28 20:10:45.000000000,2019-12-30 17:54:17.000000000,2019-12-30 17:52:56.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-28 20:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/319e52c0bf081316c016e0ffec6657bea8d03b18', 'message': 'Introduce VIFState object\n\nThis object will be used by the Zun CNI plugin which is under\ndevelopment.\n\nChange-Id: I093fdfc5beb1ca45993b36c4c9512fa511773965\nImplements: blueprint support-cni\n'}, {'number': 2, 'created': '2019-12-28 20:46:14.000000000', 'files': ['requirements.txt', 'zun/objects/__init__.py', 'lower-constraints.txt', 'zun/objects/vif.py', 'zun/objects/fields.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/9cc9267897d946e8422b2b3f9c0cd03e2420acba', 'message': 'Introduce VIFState object\n\nThis object will be used by the Zun CNI plugin which is under\ndevelopment.\n\nChange-Id: I093fdfc5beb1ca45993b36c4c9512fa511773965\nImplements: blueprint support-cni\n'}]",0,700734,9cc9267897d946e8422b2b3f9c0cd03e2420acba,8,2,2,11536,,,0,"Introduce VIFState object

This object will be used by the Zun CNI plugin which is under
development.

Change-Id: I093fdfc5beb1ca45993b36c4c9512fa511773965
Implements: blueprint support-cni
",git fetch https://review.opendev.org/openstack/zun refs/changes/34/700734/2 && git format-patch -1 --stdout FETCH_HEAD,"['zun/objects/__init__.py', 'zun/objects/vif.py', 'zun/objects/fields.py']",3,319e52c0bf081316c016e0ffec6657bea8d03b18,bp/support-cni,"from os_vif.objects import vifimport six class DictOfVIFsField(fields.AutoTypedField): AUTO_TYPE = fields.Dict(fields.Object(vif.VIFBase.__name__, subclasses=True))",import six ,55,2
openstack%2Fpython-tripleoclient~master~I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9,openstack/python-tripleoclient,master,I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9,Overload stdout callback plugin,MERGED,2019-12-09 14:02:18.000000000,2019-12-30 17:37:20.000000000,2019-12-28 04:56:33.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 10969}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-09 14:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2bd9a7c414d0fde810366470aeb6b33eed729e73', 'message': '[WIP] overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-12-09 14:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/15871f7bc810367182ad4c21d4900b38b8bad35a', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2019-12-09 14:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e5d7a6437fafd4104cdeb9a573c8781c7105a375', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 4, 'created': '2019-12-09 14:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/694f5f24bfc37ad613f9eb6048d5a4769c1991f8', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 5, 'created': '2019-12-09 14:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/819da5a9baff68c1943ba3edf9135b3df3a0036c', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 6, 'created': '2019-12-09 15:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9c827c95e42ca5361492e79e110b0c228893b67c', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 7, 'created': '2019-12-09 15:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/eca9708a6aacbbf908222c869bc32f3f0619fda2', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 8, 'created': '2019-12-09 19:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fceb5151f392127aa863f0474f1e7cd5b413ede2', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 9, 'created': '2019-12-09 21:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/553fa061968b8382750b24a47c11954cdd45cfa2', 'message': 'Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 10, 'created': '2019-12-09 23:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1814ece48df7953c9a089dfcdbdd9aed35864b86', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 11, 'created': '2019-12-09 23:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d4b5478f9b89454bfde3665ac19bc7e41056684b', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 12, 'created': '2019-12-10 09:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bcafd9579d3373249a8935dc6f7e80fd11fbd430', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 13, 'created': '2019-12-10 14:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3c9e4a59b27c12369a076160dcfa68f704b5474d', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 14, 'created': '2019-12-13 14:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9c000046248fbc70771e4e703a44a661948460d5', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 15, 'created': '2019-12-17 13:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/74ce93477b9b5a0645ed7b7b1dbec0b0ed9c1763', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 16, 'created': '2019-12-20 03:46:35.000000000', 'files': ['tripleoclient/utils.py', 'tripleoclient/v1/tripleo_validator.py', 'tripleoclient/tests/fakes.py', 'tripleoclient/tests/v1/tripleo/test_tripleo_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/49d3f725f2be0681b6e761781372782e2514c869', 'message': ""Overload stdout callback plugin\n\nThe stdout callback plugin is being set within ansible runner making it\nnot respect the user defined configuration. This change adds the required\nenvironment variable after the prepare function to ensure our defined\noutput callback plugin is always used.\n\nBecause we're allowing the assumed output callback plugin to be user defined\nwe need to cater for parallel playbook execution by defining\n`directory_isolation_base_path` in config. Now, whenever parallel playbook\nexecution is required, `directory_isolation_base_path` will be used ensuring\nthere are no collisions at runtime.\n\nChange-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",4,698015,49d3f725f2be0681b6e761781372782e2514c869,78,7,16,7353,,,0,"Overload stdout callback plugin

The stdout callback plugin is being set within ansible runner making it
not respect the user defined configuration. This change adds the required
environment variable after the prepare function to ensure our defined
output callback plugin is always used.

Because we're allowing the assumed output callback plugin to be user defined
we need to cater for parallel playbook execution by defining
`directory_isolation_base_path` in config. Now, whenever parallel playbook
execution is required, `directory_isolation_base_path` will be used ensuring
there are no collisions at runtime.

Change-Id: I7c7e7472d238bd2ab3316cac3dbee01f6d0b10e9
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/15/698015/16 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,2bd9a7c414d0fde810366470aeb6b33eed729e73,mistral_to_ansible," env['ANSIBLE_CALLBACK_WHITELIST'] = ','.join( ['profile_tasks', 'validation_output', output_callback] ) # NOTE(cloudnull): overload the output callback after prepare # to define the specific format we want. # This is only required until PR # https://github.com/ansible/ansible-runner/pull/387 # is merged and released. After this PR has # been made available to us, this line should be removed. runner_config.env['ANSIBLE_STDOUT_CALLBACK'] = \ r_opts['envvars']['ANSIBLE_STDOUT_CALLBACK']"," env['ANSIBLE_CALLBACK_WHITELIST'] = 'profile_tasks,validation_output'",11,1
openstack%2Ftripleo-quickstart~master~I1b1447006c41856a00207e7bf6760d7088f49df8,openstack/tripleo-quickstart,master,I1b1447006c41856a00207e7bf6760d7088f49df8,DNM - test CI against quay.io,ABANDONED,2019-09-19 18:01:51.000000000,2019-12-30 15:46:26.000000000,,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-19 18:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8e8ffee364b557f7d3c37fbf4644926bcaa96629', 'message': 'DNM - test CI against quay.io\n\nChange-Id: I1b1447006c41856a00207e7bf6760d7088f49df8\n'}, {'number': 2, 'created': '2019-09-20 04:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1f695f692e317aa4c9d26b62eea55e0a1431c75a', 'message': 'DNM - test CI against quay.io\n\nChange-Id: I1b1447006c41856a00207e7bf6760d7088f49df8\n'}, {'number': 3, 'created': '2019-09-22 02:54:34.000000000', 'files': ['config/release/tripleo-ci/CentOS-7/master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b79754dcc63e81cc9657e93e275c765951ec4ee3', 'message': 'DNM - test CI against quay.io\n\nChange-Id: I1b1447006c41856a00207e7bf6760d7088f49df8\n'}]",0,683212,b79754dcc63e81cc9657e93e275c765951ec4ee3,24,4,3,3153,,,0,"DNM - test CI against quay.io

Change-Id: I1b1447006c41856a00207e7bf6760d7088f49df8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/12/683212/3 && git format-patch -1 --stdout FETCH_HEAD,['config/release/tripleo-ci/CentOS-7/master.yml'],1,8e8ffee364b557f7d3c37fbf4644926bcaa96629,quay.io,docker_registry_host: quay.io,docker_registry_host: docker.io,1,1
openstack%2Ftripleo-heat-templates~master~Ifc766e11f612b74a68f40f2c1c72b01d137755b3,openstack/tripleo-heat-templates,master,Ifc766e11f612b74a68f40f2c1c72b01d137755b3,container config: remove '' value for TRIPLEO_MINOR_UPDATE,ABANDONED,2019-10-23 11:24:06.000000000,2019-12-30 15:46:07.000000000,,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-23 11:24:06.000000000', 'files': ['deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c4302da0a692f4df625c7c22f116df8d3e7e8fed', 'message': ""container config: remove '' value for TRIPLEO_MINOR_UPDATE\n\nWe don't want to set TRIPLEO_MINOR_UPDATE to '', but rather grab the\nvalue from the host; so later podman can do:\n\npodman run -e TRIPLEO_MINOR_UPDATE (...) in order to inherit the value of\nTRIPLEO_MINOR_UPDATE from what's currently defined on the host.\n\nChange-Id: Ifc766e11f612b74a68f40f2c1c72b01d137755b3\n""}]",3,690551,c4302da0a692f4df625c7c22f116df8d3e7e8fed,18,5,1,3153,,,0,"container config: remove '' value for TRIPLEO_MINOR_UPDATE

We don't want to set TRIPLEO_MINOR_UPDATE to '', but rather grab the
value from the host; so later podman can do:

podman run -e TRIPLEO_MINOR_UPDATE (...) in order to inherit the value of
TRIPLEO_MINOR_UPDATE from what's currently defined on the host.

Change-Id: Ifc766e11f612b74a68f40f2c1c72b01d137755b3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/690551/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml']",10,c4302da0a692f4df625c7c22f116df8d3e7e8fed,empty, TRIPLEO_MINOR_UPDATE, TRIPLEO_MINOR_UPDATE: '',10,10
openstack%2Fpython-tripleoclient~master~Icd9cb9a2759a12d68623cf6557282648022f08ba,openstack/python-tripleoclient,master,Icd9cb9a2759a12d68623cf6557282648022f08ba,Set RootStackName when deploying the Overcloud,ABANDONED,2019-12-05 02:57:29.000000000,2019-12-30 15:45:43.000000000,,"[{'_account_id': 3153}, {'_account_id': 9712}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-05 02:57:29.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/33e10342b3178a732737ec9901381a0aa2a246cd', 'message': ""Set RootStackName when deploying the Overcloud\n\nIt was done in a Mistral task before, but now it's done directly in the\nclient when deploying the Overcloud.\n\nChange-Id: Icd9cb9a2759a12d68623cf6557282648022f08ba\n""}]",0,697403,33e10342b3178a732737ec9901381a0aa2a246cd,6,4,1,3153,,,0,"Set RootStackName when deploying the Overcloud

It was done in a Mistral task before, but now it's done directly in the
client when deploying the Overcloud.

Change-Id: Icd9cb9a2759a12d68623cf6557282648022f08ba
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/03/697403/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py']",2,33e10342b3178a732737ec9901381a0aa2a246cd,rootstackname, parameters['RootStackName'] = args.stack,,5,0
openstack%2Ftripleo-heat-templates~master~I3c395e0698e0d61ed9fc66fbed373008dc35a335,openstack/tripleo-heat-templates,master,I3c395e0698e0d61ed9fc66fbed373008dc35a335,CI/fs010: disable Paunch on the overcloud,ABANDONED,2019-11-13 13:48:10.000000000,2019-12-30 15:43:09.000000000,,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-13 13:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3d0ca7abcadb65531d0cdc1d2a64afbbda6617f9', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 2, 'created': '2019-11-14 09:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/17e771ea11cca3a0125b9c4677ce3b4c0960b243', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 3, 'created': '2019-11-15 12:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a8a0146602055738b7b81b0b13694eae2a513790', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 4, 'created': '2019-11-15 16:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fffc6ea85c613cb27862f0f40de669438a73bbd0', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 5, 'created': '2019-11-26 13:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4a621ef59196849f3170d4768f1303a4d8417ad4', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 6, 'created': '2019-11-27 12:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/747422d5bcf0c32220156451de27b17fe450c5c7', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nDepends-On: If728788293dd64622cf95da840b60e271197e9a0\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 7, 'created': '2019-12-12 17:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/893130bbc682849f70de3aa1614bdc0e7c6acaf9', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 8, 'created': '2019-12-12 17:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dea677615e7e3fa5051b0ce061c9642b6b70a626', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 9, 'created': '2019-12-16 13:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0bae99dbe5f6b6e1b50e4625cdcc5109d4138c7a', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 10, 'created': '2019-12-16 18:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2db80d1286091256d9ee9c44ab7ed8bef6cb992f', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 11, 'created': '2019-12-17 13:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/884c323dbc05ec737b27c2e2b3bcc979e167f7ce', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}, {'number': 12, 'created': '2019-12-28 20:44:17.000000000', 'files': ['ci/environments/multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/df2166541871e6ee4f2f2475e7520212e11a9c4d', 'message': 'CI/fs010: disable Paunch on the overcloud\n\nDepends-On: I313dc6233895f37fb7616aee730e5802c9aac3df\nChange-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335\n'}]",0,694076,df2166541871e6ee4f2f2475e7520212e11a9c4d,49,4,12,3153,,,0,"CI/fs010: disable Paunch on the overcloud

Depends-On: I313dc6233895f37fb7616aee730e5802c9aac3df
Change-Id: I3c395e0698e0d61ed9fc66fbed373008dc35a335
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/76/694076/3 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/multinode-containers.yaml'],1,3d0ca7abcadb65531d0cdc1d2a64afbbda6617f9,shutdown, EnablePaunch: False,,1,0
openstack%2Fnova~master~I9c81aa3c60d6892ad95dc13a5106298dbb501bd0,openstack/nova,master,I9c81aa3c60d6892ad95dc13a5106298dbb501bd0,Fix get_compute_nodes_by_host_or_node() returns a list,ABANDONED,2019-12-30 00:06:20.000000000,2019-12-30 14:41:20.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 28988}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-30 00:06:20.000000000', 'files': ['nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ac97ef538b24ee15c61421faa58b559ba77319f2', 'message': ""Fix get_compute_nodes_by_host_or_node() returns a list\n\nThe bug description mentioned the error occurs when\nget_compute_nodes_by_host_or_node() function returns\ndid_not_respond_sentinel object, not iterable list.\n\nHaving a look inside of get_compute_nodes_by_host_or_node(),\nnodes variable should be a list which has len() attribute.\nBut when nodes variable only has did_not_respond_sentinel object,\nit doesn't have len() attribute.\n\nSo this commit make nodes list data type including\ndid_not_respond_sentinel object. As following the comment,\nit returns an empty list if no cell has a value.\n\nFuture work should be handling did_not_respond_sentinel object.\n\nChange-Id: I9c81aa3c60d6892ad95dc13a5106298dbb501bd0\nCloses-Bug: #1857139\n""}]",1,700753,ac97ef538b24ee15c61421faa58b559ba77319f2,11,8,1,28988,,,0,"Fix get_compute_nodes_by_host_or_node() returns a list

The bug description mentioned the error occurs when
get_compute_nodes_by_host_or_node() function returns
did_not_respond_sentinel object, not iterable list.

Having a look inside of get_compute_nodes_by_host_or_node(),
nodes variable should be a list which has len() attribute.
But when nodes variable only has did_not_respond_sentinel object,
it doesn't have len() attribute.

So this commit make nodes list data type including
did_not_respond_sentinel object. As following the comment,
it returns an empty list if no cell has a value.

Future work should be handling did_not_respond_sentinel object.

Change-Id: I9c81aa3c60d6892ad95dc13a5106298dbb501bd0
Closes-Bug: #1857139
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/700753/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/host_manager.py'],1,ac97ef538b24ee15c61421faa58b559ba77319f2,bug/1857139," iter(nodes for nodes in nodes_by_cell.values() if nodes), objects.ComputeNodeList())"," (nodes for nodes in nodes_by_cell.values() if nodes), objects.ComputeNodeList())",2,2
openstack%2Fcinder~master~Ibbf481da981428cd921fb9cb6bec6af8f6f330b3,openstack/cinder,master,Ibbf481da981428cd921fb9cb6bec6af8f6f330b3,Elaborate on terminate_connection documentation,MERGED,2019-12-04 15:22:57.000000000,2019-12-30 14:23:12.000000000,2019-12-30 13:08:15.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12988}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-04 15:22:57.000000000', 'files': ['cinder/interface/volume_driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/effe719e8f715ffadcab1d8e91b04e22a8881dc2', 'message': 'Elaborate on terminate_connection documentation\n\nWe have had issues with drivers not handling terminate_connection\ncorrectly when the connector argument is None. In these cases, the\ndriver is expected to terminate all connections to the volume.\n\nThis adds additional information to the volume driver interface\ndocstring to try to better point out this expectation.\n\nChange-Id: Ibbf481da981428cd921fb9cb6bec6af8f6f330b3\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,697306,effe719e8f715ffadcab1d8e91b04e22a8881dc2,70,29,1,11904,,,0,"Elaborate on terminate_connection documentation

We have had issues with drivers not handling terminate_connection
correctly when the connector argument is None. In these cases, the
driver is expected to terminate all connections to the volume.

This adds additional information to the volume driver interface
docstring to try to better point out this expectation.

Change-Id: Ibbf481da981428cd921fb9cb6bec6af8f6f330b3
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/697306/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/interface/volume_driver.py'],1,effe719e8f715ffadcab1d8e91b04e22a8881dc2,terminate_connection," Note: If ``connector`` is ``None``, then all connections to the volume should be terminated. ",,3,0
openstack%2Ftripleo-quickstart-extras~master~Id50579329365ba3e57c5be8eb15063ea1b819503,openstack/tripleo-quickstart-extras,master,Id50579329365ba3e57c5be8eb15063ea1b819503,Bumps up default Ceph container images,MERGED,2019-12-19 12:44:09.000000000,2019-12-30 13:50:10.000000000,2019-12-30 13:50:10.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 14270}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:44:09.000000000', 'files': ['roles/extras-common/README.md', 'roles/extras-common/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/df3cc910cf567405cb1ad7b3a617a36df8bd831d', 'message': 'Bumps up default Ceph container images\n\nUpdates ceph/daemon image to to 3.2.10 for queens/rocky and\nto 4.0.8 for stein/train/master\n\nThis same change is applied by default to all new deployments\nvia tripleo-common defaults\n\nDepends-On: I15b3d092c911b465b8399a30e4d984e3cc3665b4\nDepends-On: I6b80ae2e13deb390cbb2b152299a5915ebb337a2\nChange-Id: Id50579329365ba3e57c5be8eb15063ea1b819503\n'}]",1,699976,df3cc910cf567405cb1ad7b3a617a36df8bd831d,16,7,1,6796,,,0,"Bumps up default Ceph container images

Updates ceph/daemon image to to 3.2.10 for queens/rocky and
to 4.0.8 for stein/train/master

This same change is applied by default to all new deployments
via tripleo-common defaults

Depends-On: I15b3d092c911b465b8399a30e4d984e3cc3665b4
Depends-On: I6b80ae2e13deb390cbb2b152299a5915ebb337a2
Change-Id: Id50579329365ba3e57c5be8eb15063ea1b819503
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/76/699976/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/extras-common/README.md', 'roles/extras-common/defaults/main.yml']",2,df3cc910cf567405cb1ad7b3a617a36df8bd831d,, v3.2.10-stable-3.2-luminous-centos-7-x86_64 v4.0.8-stable-4.0-nautilus-centos-7-x86_64, v3.2.8-stable-3.2-luminous-centos-7-x86_64 v4.0.4-stable-4.0-nautilus-centos-7-x86_64,3,3
openstack%2Ftripleo-docs~master~I543d501239cfbd09fed102b0746836a6b45f0480,openstack/tripleo-docs,master,I543d501239cfbd09fed102b0746836a6b45f0480,Update docs for ManageNetworks,MERGED,2019-12-17 18:51:47.000000000,2019-12-30 13:02:21.000000000,2019-12-30 13:00:47.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-17 18:51:47.000000000', 'files': ['deploy-guide/source/features/distributed_compute_node.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/99d23255c497e081d493251e194903b8a718e0b3', 'message': 'Update docs for ManageNetworks\n\nAdds some finer points about using ManageNetworks, especially when\nadding new leaves.\n\nChange-Id: I543d501239cfbd09fed102b0746836a6b45f0480\n'}]",0,699479,99d23255c497e081d493251e194903b8a718e0b3,8,2,1,7144,,,0,"Update docs for ManageNetworks

Adds some finer points about using ManageNetworks, especially when
adding new leaves.

Change-Id: I543d501239cfbd09fed102b0746836a6b45f0480
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/79/699479/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/features/distributed_compute_node.rst'],1,99d23255c497e081d493251e194903b8a718e0b3,,"When using ``ManageNetworks``, all network resources (except for ports) are managed in the central stack. When the central stack is deployed, ``ManageNetworks`` should be left unset (or set to True). When a child stack is deployed, it is then set to false so that the child stack does not attempt to manage the already existing network resources. Additionally, when adding new network resources, such as entire new leaves when deploying spine/leaf, the central stack must first be updated with the new ``network_data.yaml`` that contains the new leaf definitions. Even though the central stack is not directly using the new network resources, it still is responsible for creating and managing them. Once the new network resources are made available in the central stack, a child stack (such as a new edge site) could be deployed using the new networks. ",,14,0
openstack%2Fvitrage-specs~master~Iac7477a9cfce0458b55d40d5219a315c47abee27,openstack/vitrage-specs,master,Iac7477a9cfce0458b55d40d5219a315c47abee27,[ussuri][goal] Drop python 2.7 support,MERGED,2019-12-13 18:56:28.000000000,2019-12-30 12:37:35.000000000,2019-12-30 12:35:58.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/5d9bf3c3d1e4bb131dbcc6b7ac7a177cfca98a78', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27\n'}, {'number': 2, 'created': '2019-12-30 11:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/f8b5a81f7b909ec73dae956d9ca1a05ca289a544', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27\n'}, {'number': 3, 'created': '2019-12-30 12:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/6183acf4a266ab54f5e8d9a4b2e17c32e58ceb22', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27\n'}, {'number': 4, 'created': '2019-12-30 12:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/6b8753acf8d4ceb1f8710dbd96d85fd75c12cc04', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27\n'}, {'number': 5, 'created': '2019-12-30 12:22:13.000000000', 'files': ['requirements.txt', 'bindep.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/c7b937010d2cf13e5cf0cfab80fcca8d9e4e74e1', 'message': '[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27\n'}]",0,698995,c7b937010d2cf13e5cf0cfab80fcca8d9e4e74e1,15,2,5,8556,,,0,"[ussuri][goal] Drop python 2.7 support

OpenStack is dropping the py2.7 support in ussuri cycle.

specs repo either has py27 job or requirement or tox env.

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: Iac7477a9cfce0458b55d40d5219a315c47abee27
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/95/698995/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5d9bf3c3d1e4bb131dbcc6b7ac7a177cfca98a78,drop-py27-support,"minversion = 3.1.1 envlist = docs,py37ignore_basepython_conflict = Truebasepython = python3","minversion = 2.0 envlist = docs,py27basepython = python3basepython = python3basepython = python3basepython = python3",4,6
openstack%2Fhorizon~stable%2Fstein~I73234b2c69ce8ea648b4a9721abe4f5670031909,openstack/horizon,stable/stein,I73234b2c69ce8ea648b4a9721abe4f5670031909,"Fix ""prev"" link pagination for instances with identical timestamps",MERGED,2019-12-27 18:12:46.000000000,2019-12-30 11:18:11.000000000,2019-12-30 11:16:43.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 18:12:46.000000000', 'files': ['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5f27609352a8f7f8bfdca1df14afad8c15dc0f93', 'message': 'Fix ""prev"" link pagination for instances with identical timestamps\n\nThis patch resolves an issue with the ""prev"" link when instances\nhave identical ""created_at"" values. This can occur when creating\ninstance using the ""min/max count"" option. The reverse sort does not\nwork correctly as the server list returned from nova is not an exact\nreverse as the forward sort. It looks like the combination of sort_keys\nmust be unique to ensure the forward and reverse pagination properly.\nAs a workaround \'uuid\' (server ID) is added to \'sort_keys\'.\nIn addition, \'display_name\' is added before \'uuid\' in \'sort_keys\'\nto list servers in the alphabetical order (which sounds natural).\n\nCloses-Bug #1856243\nChange-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909\n(cherry picked from commit 9637d733749d741d5aac3b89b92e100d32fbdbb0)\n'}]",0,700708,5f27609352a8f7f8bfdca1df14afad8c15dc0f93,8,3,1,14892,,,0,"Fix ""prev"" link pagination for instances with identical timestamps

This patch resolves an issue with the ""prev"" link when instances
have identical ""created_at"" values. This can occur when creating
instance using the ""min/max count"" option. The reverse sort does not
work correctly as the server list returned from nova is not an exact
reverse as the forward sort. It looks like the combination of sort_keys
must be unique to ensure the forward and reverse pagination properly.
As a workaround 'uuid' (server ID) is added to 'sort_keys'.
In addition, 'display_name' is added before 'uuid' in 'sort_keys'
to list servers in the alphabetical order (which sounds natural).

Closes-Bug #1856243
Change-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909
(cherry picked from commit 9637d733749d741d5aac3b89b92e100d32fbdbb0)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/08/700708/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py']",2,5f27609352a8f7f8bfdca1df14afad8c15dc0f93,bug/1856243-stable/train-stable/stein," # NOTE(amotoki): It looks like the 'sort_keys' must be unique to make # the pagination in the nova API works as expected. Multiple servers # can have a same 'created_at' as its resolution is a second. # To ensure the uniqueness we add 'uuid' to the sort keys. # 'display_name' is added before 'uuid' to list servers in the # alphabetical order. sort_keys = ['created_at', 'display_name', 'uuid'] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=[sort_dir] * 3)] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=['desc'] * 3)] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=['asc'] * 3)]"," search_opts['sort_dir'] = sort_dir for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'desc' for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'asc' for s in nova_client.servers.list(detailed, search_opts)]",28,12
openstack%2Fvitrage-tempest-plugin~master~Id6397f7374f621333adfc96c8a8c80ce665c1924,openstack/vitrage-tempest-plugin,master,Id6397f7374f621333adfc96c8a8c80ce665c1924,Use only py3 as base,MERGED,2019-12-30 10:38:28.000000000,2019-12-30 10:56:45.000000000,2019-12-30 10:55:12.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-30 10:38:28.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c15d42ce818ea74879d2e043607dadbcb82b6c58', 'message': 'Use only py3 as base\n\nChange-Id: Id6397f7374f621333adfc96c8a8c80ce665c1924\n'}]",0,700767,c15d42ce818ea74879d2e043607dadbcb82b6c58,8,2,1,19134,,,0,"Use only py3 as base

Change-Id: Id6397f7374f621333adfc96c8a8c80ce665c1924
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/67/700767/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c15d42ce818ea74879d2e043607dadbcb82b6c58,tox,minversion = 3.1.1ignore_basepython_conflict = True,minversion = 2.3.1,2,1
openstack%2Fkolla-ansible~master~Ifa8fb271ee2d5642785097755f7347e3be00f8e9,openstack/kolla-ansible,master,Ifa8fb271ee2d5642785097755f7347e3be00f8e9,Fix /etc/kolla to node_config_directory,MERGED,2019-12-30 02:39:12.000000000,2019-12-30 09:50:36.000000000,2019-12-30 09:49:12.000000000,"[{'_account_id': 7488}, {'_account_id': 22348}, {'_account_id': 29344}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-30 02:39:12.000000000', 'files': ['ansible/roles/common/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0449c4fc8ef3bd230279de4616a8ba8a914cad52', 'message': 'Fix /etc/kolla to node_config_directory\n\nChange-Id: Ifa8fb271ee2d5642785097755f7347e3be00f8e9\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}]",0,700757,0449c4fc8ef3bd230279de4616a8ba8a914cad52,10,4,1,29344,,,0,"Fix /etc/kolla to node_config_directory

Change-Id: Ifa8fb271ee2d5642785097755f7347e3be00f8e9
Signed-off-by: yj.bai <bai.yongjun@99cloud.net>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/57/700757/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/tasks/config.yml'],1,0449c4fc8ef3bd230279de4616a8ba8a914cad52,Bug#1856725," dest: ""{{ node_config_directory }}/kolla-toolbox/rabbitmq-env.conf"" dest: ""{{ node_config_directory }}/kolla-toolbox/erl_inetrc""", dest: /etc/kolla/kolla-toolbox/rabbitmq-env.conf dest: /etc/kolla/kolla-toolbox/erl_inetrc,2,2
openstack%2Fheat-tempest-plugin~master~I67210f4dcf955265312f5d7c14418eae91d06d82,openstack/heat-tempest-plugin,master,I67210f4dcf955265312f5d7c14418eae91d06d82,Register heat tempest config options in tempest,ABANDONED,2019-12-30 07:13:28.000000000,2019-12-30 09:33:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-30 07:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/a18427d108bf9b784696d97df7032fe60b8a1181', 'message': ""Register heat tempest config options in tempest\n\nRegister heat tempest config options as native tempest config options.\n\nSkip config group `ServiceAvailableGroup` since it's already deprecated.\n\nChange-Id: I67210f4dcf955265312f5d7c14418eae91d06d82\n""}, {'number': 2, 'created': '2019-12-30 07:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/3850bbe413b9a084fbe2b5f0b2ec2a61d45dcc0d', 'message': ""Register heat tempest config options in tempest\n\nRegister heat tempest config options as native tempest config options.\n\nSkip config group `ServiceAvailableGroup` since it's already deprecated.\n\nChange-Id: I67210f4dcf955265312f5d7c14418eae91d06d82\n""}, {'number': 3, 'created': '2019-12-30 09:17:50.000000000', 'files': ['heat_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/28b2383b9bdd8cf892494335669cd180246b2a80', 'message': ""Register heat tempest config options in tempest\n\nRegister heat tempest config options as native tempest config options.\n\nSkip config group `ServiceAvailableGroup` since it's already deprecated.\n\nDepends-On: https://review.opendev.org/#/c/700512/\n\nChange-Id: I67210f4dcf955265312f5d7c14418eae91d06d82\n""}]",0,700760,28b2383b9bdd8cf892494335669cd180246b2a80,5,1,3,12404,,,0,"Register heat tempest config options in tempest

Register heat tempest config options as native tempest config options.

Skip config group `ServiceAvailableGroup` since it's already deprecated.

Depends-On: https://review.opendev.org/#/c/700512/

Change-Id: I67210f4dcf955265312f5d7c14418eae91d06d82
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/60/700760/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_tempest_plugin/config.py'],1,a18427d108bf9b784696d97df7032fe60b8a1181,register-tempest-config,"from tempest import configCONF = config.CONF for opt in HeatGroup: CONF.register_opt(opt, 'heat_plugin') for opt in HeatFeaturesGroup: CONF.register_opt(opt, 'heat_features_enabled') ",,9,0
openstack%2Fcloudkitty-dashboard~master~I9b856e6ba9b5783a765ea8d14f0bd6f012256876,openstack/cloudkitty-dashboard,master,I9b856e6ba9b5783a765ea8d14f0bd6f012256876,translation: drop babel extractor definitions,MERGED,2019-12-26 17:10:34.000000000,2019-12-30 09:27:35.000000000,2019-12-30 09:26:15.000000000,"[{'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-12-26 17:10:34.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/5493889d835824bceb50c5908c6bdc403d8a7582', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I9b856e6ba9b5783a765ea8d14f0bd6f012256876\n'}]",0,700632,5493889d835824bceb50c5908c6bdc403d8a7582,8,3,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I9b856e6ba9b5783a765ea8d14f0bd6f012256876
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/32/700632/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,5493889d835824bceb50c5908c6bdc403d8a7582,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # .../dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fcyborg~master~I6410d7201c938b67cd5a651447a7d8e661e80a15,openstack/cyborg,master,I6410d7201c938b67cd5a651447a7d8e661e80a15,BugFix: Modify objects/device.py get_by_device_id method,MERGED,2019-12-19 10:32:27.000000000,2019-12-30 09:12:17.000000000,2019-12-30 09:10:57.000000000,"[{'_account_id': 14107}, {'_account_id': 14131}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 27458}, {'_account_id': 28748}, {'_account_id': 30759}]","[{'number': 1, 'created': '2019-12-19 10:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/3b9e597ba32a639863fcbf622c78d5d610a7f4f7', 'message': 'BugFix: Modify objects/device.py get_by_device_id method\n\nThis get_by_device_id will returns [], regardless of whether\na device exists in the database. Because there is no device_id\nfield in the device table.\n\nThis method has not yet been executed, so this error is hidden.\n\nBecause the id of device is unique, we can use get instead of\nlist.\n\nChange-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15\nStory: 2007038\n'}, {'number': 2, 'created': '2019-12-19 11:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/5a959d854dcb70bcdc3aed0a0b23a9b07efa94a2', 'message': 'BugFix: Modify objects/device.py get_by_device_id method\n\nThis get_by_device_id will returns [], regardless of whether\na device exists in the database. Because there is no device_id\nfield in the device table.\n\nThis method has not yet been executed, so this error is hidden.\n\nBecause the id of device is unique, we can use get instead of\nlist.\n\nChange-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15\nStory: 2007038\n'}, {'number': 3, 'created': '2019-12-20 09:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/c1f71f5d679fc0a2ef70b40abd85df913e8acc3f', 'message': 'BugFix: Modify objects/device.py get_by_device_id method\n\nThis get_by_device_id will returns [], regardless of whether\na device exists in the database. Because there is no device_id\nfield in the device table.\n\nThis method has not yet been executed, so this error is hidden.\n\nBecause the id of device is unique, we can use get instead of\nlist.\n\nChange-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15\nStory: 2007038\n'}, {'number': 4, 'created': '2019-12-20 09:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/49dcd8dc8020d783dcf0b80ce9b3d2b2f1ec39f8', 'message': 'BugFix: Modify objects/device.py get_by_device_id method\n\nThis get_by_device_id will returns [], regardless of whether\na device exists in the database. Because there is no device_id\nfield in the device table.\n\nThis method has not yet been executed, so this error is hidden.\n\nBecause the id of device is unique, we can use get instead of\nlist.\n\nChange-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15\nStory: 2007038\n'}, {'number': 5, 'created': '2019-12-20 09:46:45.000000000', 'files': ['cyborg/db/sqlalchemy/api.py', 'cyborg/tests/unit/objects/test_device.py', 'cyborg/objects/device.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/b35f6ea72b49dcdb99f0748bdb003b872afe1ba7', 'message': 'BugFix: Modify objects/device.py get_by_device_id method\n\nThis get_by_device_id will returns [], regardless of whether\na device exists in the database. Because there is no device_id\nfield in the device table.\n\nThis method has not yet been executed, so this error is hidden.\n\nBecause the id of device is unique, we can use get instead of\nlist.\n\nChange-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15\nStory: 2007038\nTask: 37846\n'}]",3,699949,b35f6ea72b49dcdb99f0748bdb003b872afe1ba7,17,9,5,28748,,,0,"BugFix: Modify objects/device.py get_by_device_id method

This get_by_device_id will returns [], regardless of whether
a device exists in the database. Because there is no device_id
field in the device table.

This method has not yet been executed, so this error is hidden.

Because the id of device is unique, we can use get instead of
list.

Change-Id: I6410d7201c938b67cd5a651447a7d8e661e80a15
Story: 2007038
Task: 37846
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/49/699949/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg/tests/unit/objects/test_device.py', 'cyborg/objects/device.py']",2,3b9e597ba32a639863fcbf622c78d5d610a7f4f7,fix_get_device_id," """"""get device object by the device ID."""""" db_device = cls.dbapi.device_get(context, device_id) obj_device = cls._from_db_object(cls(context), db_device) return obj_device"," """"""get device object list from the device ID. return [] if not exist. """""" dev_filter = {'device_id': device_id} device_obj_list = Device.list(context, dev_filter) return device_obj_list",14,7
openstack%2Foctavia~stable%2Ftrain~Ic194a030edd84106217eb5ac02f9b3190d3a7ba6,openstack/octavia,stable/train,Ic194a030edd84106217eb5ac02f9b3190d3a7ba6,Remove duplicate keys in sample config files,ABANDONED,2019-12-30 08:58:15.000000000,2019-12-30 09:04:14.000000000,,[{'_account_id': 1131}],"[{'number': 1, 'created': '2019-12-30 08:58:15.000000000', 'files': ['octavia/tests/unit/common/sample_configs/sample_configs_split.py', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/201760ca9ebc545315aceabc6ad90f659da98723', 'message': ""Remove duplicate keys in sample config files\n\nW0109: Duplicate key 'protocol' in dictionary (duplicate-key)\n\npep8 is failing on that as error\n\nTrivialfix\n\nChange-Id: Ic194a030edd84106217eb5ac02f9b3190d3a7ba6\n(cherry picked from commit e6cd43d6cc2710266a1990c952201c5714a03393)\n""}]",0,700763,201760ca9ebc545315aceabc6ad90f659da98723,2,1,1,7249,,,0,"Remove duplicate keys in sample config files

W0109: Duplicate key 'protocol' in dictionary (duplicate-key)

pep8 is failing on that as error

Trivialfix

Change-Id: Ic194a030edd84106217eb5ac02f9b3190d3a7ba6
(cherry picked from commit e6cd43d6cc2710266a1990c952201c5714a03393)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/63/700763/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/common/sample_configs/sample_configs_split.py', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py']",2,201760ca9ebc545315aceabc6ad90f659da98723,duplicate-keys-stable/train,," 'protocol': 'http',",0,2
openstack%2Foctavia~master~Ic194a030edd84106217eb5ac02f9b3190d3a7ba6,openstack/octavia,master,Ic194a030edd84106217eb5ac02f9b3190d3a7ba6,Remove duplicate keys in sample config files,MERGED,2019-10-10 01:21:36.000000000,2019-12-30 08:58:15.000000000,2019-10-10 09:46:42.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-10 01:21:36.000000000', 'files': ['octavia/tests/unit/common/sample_configs/sample_configs_split.py', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e6cd43d6cc2710266a1990c952201c5714a03393', 'message': ""Remove duplicate keys in sample config files\n\nW0109: Duplicate key 'protocol' in dictionary (duplicate-key)\n\nTrivialfix\n\nChange-Id: Ic194a030edd84106217eb5ac02f9b3190d3a7ba6\n""}]",0,687760,e6cd43d6cc2710266a1990c952201c5714a03393,9,3,1,1131,,,0,"Remove duplicate keys in sample config files

W0109: Duplicate key 'protocol' in dictionary (duplicate-key)

Trivialfix

Change-Id: Ic194a030edd84106217eb5ac02f9b3190d3a7ba6
",git fetch https://review.opendev.org/openstack/octavia refs/changes/60/687760/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/common/sample_configs/sample_configs_split.py', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py']",2,e6cd43d6cc2710266a1990c952201c5714a03393,duplicate-keys,," 'protocol': 'http',",0,2
openstack%2Fzun~master~I21de241311caa27a5eddc75ad452e8488f913c30,openstack/zun,master,I21de241311caa27a5eddc75ad452e8488f913c30,check volume name in capsule,MERGED,2019-12-28 08:57:04.000000000,2019-12-30 07:44:03.000000000,2019-12-30 07:42:19.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-28 08:57:04.000000000', 'files': ['zun/api/controllers/v1/schemas/parameter_types.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/08313109106c4c9b8674b38e8165a3a18539afdc', 'message': 'check volume name in capsule\n\nChange-Id: I21de241311caa27a5eddc75ad452e8488f913c30\n'}]",0,700715,08313109106c4c9b8674b38e8165a3a18539afdc,15,2,1,23365,,,0,"check volume name in capsule

Change-Id: I21de241311caa27a5eddc75ad452e8488f913c30
",git fetch https://review.opendev.org/openstack/zun refs/changes/15/700715/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/api/controllers/v1/schemas/parameter_types.py'],1,08313109106c4c9b8674b38e8165a3a18539afdc,," 'name': volume_name,"," 'name': image_name,",1,1
openstack%2Fvitrage-tempest-plugin~master~I17d1638ca9211cd833fe69344b5f29cacce2c441,openstack/vitrage-tempest-plugin,master,I17d1638ca9211cd833fe69344b5f29cacce2c441,Use only py3 as base,MERGED,2019-12-29 11:10:59.000000000,2019-12-30 07:05:36.000000000,2019-12-30 07:04:08.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-29 11:10:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/0950c7623671a758e008a1f140d23fe53ebb8263', 'message': 'Use only py3 as base\n\nChange-Id: I17d1638ca9211cd833fe69344b5f29cacce2c441\n'}]",0,700745,0950c7623671a758e008a1f140d23fe53ebb8263,7,2,1,19134,,,0,"Use only py3 as base

Change-Id: I17d1638ca9211cd833fe69344b5f29cacce2c441
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/45/700745/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0950c7623671a758e008a1f140d23fe53ebb8263,eyalb/py3,"minversion = 2.3.1 envlist = py37,pep8basepython = python3","minversion = 2.0 envlist = py37,py36,py27,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",3,8
openstack%2Fmurano-dashboard~master~I21e26fb424d489ed0d489927beaa692909ab2f8b,openstack/murano-dashboard,master,I21e26fb424d489ed0d489927beaa692909ab2f8b,Drop python 2.7 testing,MERGED,2019-12-28 16:54:04.000000000,2019-12-30 06:20:58.000000000,2019-12-30 06:20:58.000000000,"[{'_account_id': 8556}, {'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-28 16:54:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/51ea988b7072ac47b862f116d71fe622d960d524', 'message': 'Drop python 2.7 testing\n\nhttps://review.opendev.org/#/c/694647/ dropped python 2.7 support\nbut it forgot to update zuul.yaml.\n\nThis completes the goal of python 2.7 drop.\n\nChange-Id: I21e26fb424d489ed0d489927beaa692909ab2f8b\n'}]",0,700729,51ea988b7072ac47b862f116d71fe622d960d524,6,3,1,841,,,0,"Drop python 2.7 testing

https://review.opendev.org/#/c/694647/ dropped python 2.7 support
but it forgot to update zuul.yaml.

This completes the goal of python 2.7 drop.

Change-Id: I21e26fb424d489ed0d489927beaa692909ab2f8b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/29/700729/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,51ea988b7072ac47b862f116d71fe622d960d524,drop-py27-support,, - openstack-python-jobs-horizon,0,1
openstack%2Fcyborg~master~Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa,openstack/cyborg,master,Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa,Modify api-paste.ini v1 to v2,MERGED,2019-12-20 03:28:28.000000000,2019-12-30 02:25:46.000000000,2019-12-30 02:24:32.000000000,"[{'_account_id': 14107}, {'_account_id': 14131}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}]","[{'number': 1, 'created': '2019-12-20 03:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/83dd10888b94311a9a982041d8772e849ad1373a', 'message': 'Modify api-paste.ini v1 to v2\n\nChange-Id: Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa\n'}, {'number': 2, 'created': '2019-12-20 03:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/de5544e81a355ab9f63802d02749906b4de2981a', 'message': 'Modify api-paste.ini v1 to v2\n\nSince Cyborg v1 api has been deprecated. We should change\nthe pipeline to v2.\n\nStory: 2007041\nChange-Id: Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa\n'}, {'number': 3, 'created': '2019-12-20 09:41:41.000000000', 'files': ['etc/cyborg/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/afa4a2ab246e4b54d863e3906e261aeedb2ac937', 'message': 'Modify api-paste.ini v1 to v2\n\nSince Cyborg v1 api has been deprecated. We should change\nthe pipeline to v2.\n\nStory: 2007041\nTask: 37853\nChange-Id: Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa\n'}]",0,700102,afa4a2ab246e4b54d863e3906e261aeedb2ac937,15,6,3,28748,,,0,"Modify api-paste.ini v1 to v2

Since Cyborg v1 api has been deprecated. We should change
the pipeline to v2.

Story: 2007041
Task: 37853
Change-Id: Ieca9776cec8fe2e65e7ec9a6d4e96a6b0a6affaa
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/02/700102/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/cyborg/api-paste.ini'],1,83dd10888b94311a9a982041d8772e849ad1373a,change_api_paste,"pipeline = cors request_id authtoken api_v2 [app:api_v2]acl_public_routes = /, /v2","pipeline = cors request_id authtoken api_v1 [app:api_v1]acl_public_routes = /, /v1",3,3
openstack%2Fvitrage~master~Ie32097695684ba7d767ad79fe16e935fbfd76b55,openstack/vitrage,master,Ie32097695684ba7d767ad79fe16e935fbfd76b55,"update  executor from blocking to threading, eliminate warn info",ABANDONED,2019-12-27 02:51:59.000000000,2019-12-30 01:37:16.000000000,,"[{'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30408}]","[{'number': 1, 'created': '2019-12-27 02:51:59.000000000', 'files': ['vitrage/rpc.py', 'vitrage/messaging.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/75afb7e919cb5e04d59074c798ccf9543dfd011a', 'message': 'update  executor from blocking to threading, eliminate warn info\n\nChange-Id: Ie32097695684ba7d767ad79fe16e935fbfd76b55\n'}]",0,700670,75afb7e919cb5e04d59074c798ccf9543dfd011a,5,3,1,30408,,,0,"update  executor from blocking to threading, eliminate warn info

Change-Id: Ie32097695684ba7d767ad79fe16e935fbfd76b55
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/70/700670/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/rpc.py', 'vitrage/messaging.py']",2,75afb7e919cb5e04d59074c798ccf9543dfd011a,," transport, targets, endpoints, executor='threading',"," transport, targets, endpoints, executor='blocking',",2,2
openstack%2Fnova~master~I494eb5fcfc1fbbe5034253c9de1167c3f76f559f,openstack/nova,master,I494eb5fcfc1fbbe5034253c9de1167c3f76f559f,Fix get_compute_nodes_by_host_or_node() returns a list,ABANDONED,2019-12-29 21:06:05.000000000,2019-12-29 21:54:38.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 23498}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-29 21:06:05.000000000', 'files': ['nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15b2969e986f8fa62684afe7fc7bcb1222812019', 'message': ""Fix get_compute_nodes_by_host_or_node() returns a list\n\nThe bug description mentioned the error occurs when\nget_compute_nodes_by_host_or_node() function returns\ndid_not_respond_sentinel object, not iterable list.\n\nHaving a look inside of get_compute_nodes_by_host_or_node(),\nnodes variable should be a list which has len() attribute.\nBut when nodes variable only has did_not_respond_sentinel object,\nit doesn't have len() attribute.\n\nSo this commit make nodes list data type including\ndid_not_respond_sentinel object. As following the comment,\nit returns an empty list if no cell has a value.\n\nFuture work should be handling did_not_respond_sentinel object.\n\nChange-Id: I494eb5fcfc1fbbe5034253c9de1167c3f76f559f\nCloses-Bug: #1857139\n""}]",0,700752,15b2969e986f8fa62684afe7fc7bcb1222812019,6,4,1,28988,,,0,"Fix get_compute_nodes_by_host_or_node() returns a list

The bug description mentioned the error occurs when
get_compute_nodes_by_host_or_node() function returns
did_not_respond_sentinel object, not iterable list.

Having a look inside of get_compute_nodes_by_host_or_node(),
nodes variable should be a list which has len() attribute.
But when nodes variable only has did_not_respond_sentinel object,
it doesn't have len() attribute.

So this commit make nodes list data type including
did_not_respond_sentinel object. As following the comment,
it returns an empty list if no cell has a value.

Future work should be handling did_not_respond_sentinel object.

Change-Id: I494eb5fcfc1fbbe5034253c9de1167c3f76f559f
Closes-Bug: #1857139
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/700752/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/host_manager.py'],1,15b2969e986f8fa62684afe7fc7bcb1222812019,bug/1857139, nodes = [] for node in nodes_by_cell.values(): nodes.append(node) nodes = objects.ComputeNodeList() if not nodes," nodes = next( (nodes for nodes in nodes_by_cell.values() if nodes), objects.ComputeNodeList())",4,3
openstack%2Fnova~stable%2Ftrain~I6a4252b0c12c41c233299f30ce8294fef21c7b40,openstack/nova,stable/train,I6a4252b0c12c41c233299f30ce8294fef21c7b40,libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event,MERGED,2019-11-25 13:40:05.000000000,2019-12-29 20:08:56.000000000,2019-12-29 20:02:41.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-25 13:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a69e61aefae7fa61caf095f51c986165d7c8a53c', 'message': 'libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n'}, {'number': 2, 'created': '2019-12-29 13:59:43.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py', 'nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/test_migration.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/27bfd0bc6233c25114504bb363402807752a7ece', 'message': 'libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n'}]",0,695900,27bfd0bc6233c25114504bb363402807752a7ece,118,9,2,6873,,,0,"libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event

Change Ic5cab99944df9e501ba2032eb96911c36304494d added handling for
the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration
but failed to distinguish between the live migration actually succeeding
or failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED
up into the ComputeManager.handle_lifecycle_event method.

As a result, failed live migrations will inadvertantly trigger
activation of the port bindings on the destination host, which
deactivates the source host port bindings, and then
_rollback_live_migration will delete those activated dest host port
bindings and leave the source host port bindings deactivated.

In this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED
event, we attempt to get the job status to determine the course to
take and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,
which triggers the dest host port activation, if we can determine
the live migration job completed successfully. Otherwise we simply
report the guest as paused, the same as before Ic5cab9994.

Change-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40
Closes-Bug: #1788014
(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/695900/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py', 'nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/virt/libvirt/test_migration.py']",5,a69e61aefae7fa61caf095f51c986165d7c8a53c,bug/1788014," @mock.patch('nova.virt.libvirt.migration.LOG', new_callable=mock.NonCallableMock) # asserts not called @mock.patch('nova.virt.libvirt.guest.Guest.is_active', return_value=True) def test_live_migration_find_type_no_logging(self, mock_active, _mock_log): self.assertEqual(fakelibvirt.VIR_DOMAIN_JOB_FAILED, migration.find_job_type(self.guest, self.instance, logging_ok=False)) ",,88,31
openstack%2Fsahara-dashboard~master~Ideff438f8100a330c49c6ae087d9bf7d4f540d29,openstack/sahara-dashboard,master,Ideff438f8100a330c49c6ae087d9bf7d4f540d29,translation: drop babel extractor definitions,MERGED,2019-12-26 17:25:41.000000000,2019-12-29 16:45:22.000000000,2019-12-29 16:45:22.000000000,"[{'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:25:41.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/e803202a7553f9aa424f158d8746b07e86272a4a', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: Ideff438f8100a330c49c6ae087d9bf7d4f540d29\n'}]",0,700644,e803202a7553f9aa424f158d8746b07e86272a4a,7,3,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: Ideff438f8100a330c49c6ae087d9bf7d4f540d29
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/44/700644/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,e803202a7553f9aa424f158d8746b07e86272a4a,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/en/latest/messages.html#message-extraction for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Foctavia-dashboard~master~I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461,openstack/octavia-dashboard,master,I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461,OpenStack is dropping the py2.7 support in ussuri cycle.,MERGED,2019-10-30 08:34:44.000000000,2019-12-29 14:36:18.000000000,2019-12-29 14:34:27.000000000,"[{'_account_id': 841}, {'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 8556}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29313}, {'_account_id': 30619}]","[{'number': 1, 'created': '2019-10-30 08:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/76783ccf0fbba0d8f49e1ec31b5f9c993995d13c', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 2, 'created': '2019-11-28 05:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/a75cddda318a1a39f1bb0cb6ad252c49eeb8c321', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 3, 'created': '2019-11-28 05:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/7a601b391bc414d440b761ae7ddf1248c9d3e955', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 4, 'created': '2019-11-28 05:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/5608ed9dd39baea0f8f9e9ca99666c297f8c838f', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 5, 'created': '2019-11-28 05:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/902749fbfafd515861f9ca88ea6ca1419cdf0200', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 6, 'created': '2019-11-28 06:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/cb46e128edd87a7114e9fcd9a4f05bd6f709aa04', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 7, 'created': '2019-11-29 04:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/a07d3190ed3653e0dadf968af6ab03b0f1179491', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 8, 'created': '2019-11-29 05:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/4f90bac7a394dcd18e908929395ef962498efbb4', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 9, 'created': '2019-11-29 06:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/42f93281da95e43120de974b84e1cf80e4265fbe', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 10, 'created': '2019-12-27 08:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/82f125371034fafab09a742e9efb6f861c4cd434', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 11, 'created': '2019-12-27 08:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/d8000b4827f7f7e97e1cfa46b922095a6fe5af7a', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 12, 'created': '2019-12-27 08:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/e24b9c0cf7918687aff0fa12e003e38880330813', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 13, 'created': '2019-12-27 18:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/e88d86c3a9df5733fba6271a97a2ebac8d6c166e', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}, {'number': 14, 'created': '2019-12-28 13:21:55.000000000', 'files': ['octavia_dashboard/karma.conf.js', 'zuul.d/projects.yaml', 'doc/requirements.txt', 'releasenotes/notes/drop-py-2-7-f3372b5c26171513.yaml', 'setup.cfg', 'octavia_dashboard/post_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/2fd7d6ede223fcff626cea0f9ff2091f72986f75', 'message': 'OpenStack is dropping the py2.7 support in ussuri cycle.\n\noctavia-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461\n'}]",3,692073,2fd7d6ede223fcff626cea0f9ff2091f72986f75,42,10,14,30619,,,0,"OpenStack is dropping the py2.7 support in ussuri cycle.

octavia-dashboard is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Change-Id: I1a7a75ddb132c8e2f41f1e47d3ebca15cb86f461
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/73/692073/8 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'doc/requirements.txt', 'releasenotes/notes/drop-py-2-7-f3372b5c26171513.yaml', 'setup.cfg', 'tox.ini']",5,76783ccf0fbba0d8f49e1ec31b5f9c993995d13c,drop-py27-support,"envlist = py37,py3-{dj111,dj22},pep8,eslint,karma","envlist = py27,py37,py3-{dj111,dj22},pep8,eslint,karma",6,4
openstack%2Fmagnum-ui~master~I3ec4561eba1387876c2bbd8ea0f227043e1809ca,openstack/magnum-ui,master,I3ec4561eba1387876c2bbd8ea0f227043e1809ca,translation: drop babel extractor definitions,MERGED,2019-12-26 17:06:46.000000000,2019-12-29 09:35:48.000000000,2019-12-29 09:33:18.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/efeda2e3812f2721755917083dbb90c97ad6da52', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I3ec4561eba1387876c2bbd8ea0f227043e1809ca\n'}, {'number': 2, 'created': '2019-12-28 14:36:55.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/f6b5a2dc5ec5926225e512ba20b2c0fcf5fbd23d', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I3ec4561eba1387876c2bbd8ea0f227043e1809ca\n'}]",0,700625,f6b5a2dc5ec5926225e512ba20b2c0fcf5fbd23d,10,3,2,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I3ec4561eba1387876c2bbd8ea0f227043e1809ca
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/25/700625/2 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,efeda2e3812f2721755917083dbb90c97ad6da52,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fmagnum-ui~master~I12a57a5d8a59dbc958512641a1ef49fee5c81152,openstack/magnum-ui,master,I12a57a5d8a59dbc958512641a1ef49fee5c81152,Add requirements.txt to docs reqs,MERGED,2019-12-28 14:33:43.000000000,2019-12-29 09:34:49.000000000,2019-12-29 09:33:17.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-28 14:33:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/56af6c02305488f23b104feeb6ef3e148b1a522e', 'message': 'Add requirements.txt to docs reqs\n\nmagnum-ui doc generated the module reference,\nso requirements.txt should be here to apply upper-constraints.\n\nChange-Id: I12a57a5d8a59dbc958512641a1ef49fee5c81152\n'}]",0,700724,56af6c02305488f23b104feeb6ef3e148b1a522e,8,3,1,841,,,0,"Add requirements.txt to docs reqs

magnum-ui doc generated the module reference,
so requirements.txt should be here to apply upper-constraints.

Change-Id: I12a57a5d8a59dbc958512641a1ef49fee5c81152
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/24/700724/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,56af6c02305488f23b104feeb6ef3e148b1a522e,fix-docs-job," # magnum-ui doc generated the module reference, # so requirements.txt should be here to apply upper-constraints. -r{toxinidir}/requirements.txt",,3,0
openstack%2Fzaqar-ui~master~I9804234a0f05e3043ed75666c974b191ac366f25,openstack/zaqar-ui,master,I9804234a0f05e3043ed75666c974b191ac366f25,translation: drop babel extractor definitions,MERGED,2019-12-26 17:33:05.000000000,2019-12-29 09:01:54.000000000,2019-12-29 08:59:34.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/7d39c63c5369d42ca1df8d174e9d587345a5c1c0', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I9804234a0f05e3043ed75666c974b191ac366f25\n'}, {'number': 2, 'created': '2019-12-28 14:34:14.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/da0324dc47b84b8adb49a5a8e91dd0396e12dedd', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I9804234a0f05e3043ed75666c974b191ac366f25\n'}]",0,700651,da0324dc47b84b8adb49a5a8e91dd0396e12dedd,10,3,2,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I9804234a0f05e3043ed75666c974b191ac366f25
",git fetch https://review.opendev.org/openstack/zaqar-ui refs/changes/51/700651/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,7d39c63c5369d42ca1df8d174e9d587345a5c1c0,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fzaqar-ui~master~I4b20cfe3807e26a664dfc8e2ed656d9fac28a09b,openstack/zaqar-ui,master,I4b20cfe3807e26a664dfc8e2ed656d9fac28a09b,Add requirements.txt to docs reqs,MERGED,2019-12-28 14:20:08.000000000,2019-12-29 09:00:55.000000000,2019-12-29 08:59:33.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-28 14:20:08.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/e5903ae8e423b4731aa34c3f4d7930c9426c9c0f', 'message': 'Add requirements.txt to docs reqs\n\nzaqar-ui doc generated the module reference,\nso requirements.txt should be here to apply upper-constraints.\n\nChange-Id: I4b20cfe3807e26a664dfc8e2ed656d9fac28a09b\n'}]",0,700722,e5903ae8e423b4731aa34c3f4d7930c9426c9c0f,8,3,1,841,,,0,"Add requirements.txt to docs reqs

zaqar-ui doc generated the module reference,
so requirements.txt should be here to apply upper-constraints.

Change-Id: I4b20cfe3807e26a664dfc8e2ed656d9fac28a09b
",git fetch https://review.opendev.org/openstack/zaqar-ui refs/changes/22/700722/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e5903ae8e423b4731aa34c3f4d7930c9426c9c0f,fix-docs-job," # zaqar-ui doc generated the module reference, # so requirements.txt should be here to apply upper-constraints -r{toxinidir}/requirements.txt",,3,0
openstack%2Fsenlin-dashboard~master~I9136eae1e5946c46e28b54c134ac723dc89c478d,openstack/senlin-dashboard,master,I9136eae1e5946c46e28b54c134ac723dc89c478d,Imported Translations from Zanata,MERGED,2019-12-22 08:54:23.000000000,2019-12-29 03:24:30.000000000,2019-12-29 03:21:44.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-22 08:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/19ad7e9eb1e3c0160868f0f18d942c4cba00894a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9136eae1e5946c46e28b54c134ac723dc89c478d\n'}, {'number': 2, 'created': '2019-12-28 15:38:29.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/a4b5519ebca762409a2a3cba1598d24c1c8cf63a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9136eae1e5946c46e28b54c134ac723dc89c478d\n'}]",0,700318,a4b5519ebca762409a2a3cba1598d24c1c8cf63a,9,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I9136eae1e5946c46e28b54c134ac723dc89c478d
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/18/700318/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,19ad7e9eb1e3c0160868f0f18d942c4cba00894a,zanata/translations,"""POT-Creation-Date: 2019-12-11 20:16+0000\n""""PO-Revision-Date: 2019-12-21 02:50+0000\n""msgid ""0.11.0-10"" msgstr ""0.11.0-10"" msgid """" ""Python 2.7 support has been dropped. Last release of senlin-dashboard to "" ""support python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by senlin-dashboard is Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Senlin-dashboard to "" ""support Python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by Senlin-dashboard is Python 3.6."" ","""POT-Creation-Date: 2019-11-26 05:00+0000\n""""PO-Revision-Date: 2019-11-14 11:32+0000\n""",14,2
openstack%2Fsenlin-dashboard~master~I5983a30ffe68e3140b60bc8c320ed41fa2af6abf,openstack/senlin-dashboard,master,I5983a30ffe68e3140b60bc8c320ed41fa2af6abf,Make py36 check job voting again,MERGED,2019-12-28 14:46:06.000000000,2019-12-29 03:23:25.000000000,2019-12-29 03:21:44.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-28 14:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/fec7d2379565184c08997793bd91545d67f2f26f', 'message': 'Make py36 check job voting again\n\npy36 is one of the required runtime in Ussuri and\nit is also voting in the gate job.\nI see no value to keep py36 non-voting.\n\nChange-Id: I5983a30ffe68e3140b60bc8c320ed41fa2af6abf\n'}, {'number': 2, 'created': '2019-12-28 15:37:46.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/1c53d38277496c90c8fc17a948cea589fef99e27', 'message': 'Make py36 check job voting again\n\npy36 is one of the required runtime in Ussuri and\nit is also voting in the gate job.\nI see no value to keep py36 non-voting.\n\nChange-Id: I5983a30ffe68e3140b60bc8c320ed41fa2af6abf\n'}]",0,700725,1c53d38277496c90c8fc17a948cea589fef99e27,11,3,2,841,,,0,"Make py36 check job voting again

py36 is one of the required runtime in Ussuri and
it is also voting in the gate job.
I see no value to keep py36 non-voting.

Change-Id: I5983a30ffe68e3140b60bc8c320ed41fa2af6abf
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/25/700725/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,fec7d2379565184c08997793bd91545d67f2f26f,py36-voting,, check: jobs: - openstack-tox-py36: voting: false required-projects: - openstack/horizon,0,6
openstack%2Fcinder~master~I3c9e4c8069042672ea8822f8452e87c91ef2e676,openstack/cinder,master,I3c9e4c8069042672ea8822f8452e87c91ef2e676,"Huawei Cinder Driver Support Dorado V6 Storage.(iSCSI, FC)",ABANDONED,2019-12-19 03:57:52.000000000,2019-12-29 03:14:42.000000000,,"[{'_account_id': 9008}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29217}, {'_account_id': 29705}]","[{'number': 1, 'created': '2019-12-19 03:57:52.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'releasenotes/notes/Huawei_Cinder_Driver_Support_Dorado_V6-5289a3b0ef90e8b1.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b252fe4bdc9ebdd9d007aed5d62dfc7147261345', 'message': 'Huawei Cinder Driver Support Dorado V6 Storage.(iSCSI, FC)\n\nChange-Id: I3c9e4c8069042672ea8822f8452e87c91ef2e676\n'}]",0,699909,b252fe4bdc9ebdd9d007aed5d62dfc7147261345,32,17,1,29217,,,0,"Huawei Cinder Driver Support Dorado V6 Storage.(iSCSI, FC)

Change-Id: I3c9e4c8069042672ea8822f8452e87c91ef2e676
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/699909/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/support-matrix.ini', 'releasenotes/notes/Huawei_Cinder_Driver_Support_Dorado_V6-5289a3b0ef90e8b1.yaml']",2,b252fe4bdc9ebdd9d007aed5d62dfc7147261345,,"--- features: - | Huawei Cinder Driver Support Dorado V6 Storage.(iSCSI, FC) ",,36,18
openstack%2Fdesignate-dashboard~master~If4b8e4c56497ad7e99da26a7c391592a2b3d272a,openstack/designate-dashboard,master,If4b8e4c56497ad7e99da26a7c391592a2b3d272a,Imported Translations from Zanata,MERGED,2019-12-23 07:56:50.000000000,2019-12-29 02:59:54.000000000,2019-12-29 02:57:35.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-23 07:56:50.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/90b2263bde181638cd3b0abe4d598b132f4a681e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: If4b8e4c56497ad7e99da26a7c391592a2b3d272a\n'}]",0,700386,90b2263bde181638cd3b0abe4d598b132f4a681e,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: If4b8e4c56497ad7e99da26a7c391592a2b3d272a
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/86/700386/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,90b2263bde181638cd3b0abe4d598b132f4a681e,zanata/translations,"""POT-Creation-Date: 2019-12-22 08:21+0000\n""""PO-Revision-Date: 2019-12-22 08:12+0000\n""msgid ""9.0.0-8"" msgstr ""9.0.0-8""","""POT-Creation-Date: 2019-12-05 10:22+0000\n""""PO-Revision-Date: 2019-12-21 01:05+0000\n""msgid ""9.0.0-7"" msgstr ""9.0.0-7""",4,4
openstack%2Fdesignate-dashboard~master~Id90a29feed0bae697168492ac43961535178fe85,openstack/designate-dashboard,master,Id90a29feed0bae697168492ac43961535178fe85,translation: drop babel extractor definitions,MERGED,2019-12-26 17:09:17.000000000,2019-12-29 02:58:49.000000000,2019-12-29 02:57:35.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:09:17.000000000', 'files': ['babel-django.cfg'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/b7ce98f169d3e36c55a596dc0c27396203a78418', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: Id90a29feed0bae697168492ac43961535178fe85\n'}]",0,700631,b7ce98f169d3e36c55a596dc0c27396203a78418,10,3,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: Id90a29feed0bae697168492ac43961535178fe85
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/31/700631/1 && git format-patch -1 --stdout FETCH_HEAD,['babel-django.cfg'],1,b7ce98f169d3e36c55a596dc0c27396203a78418,babel-config,,[extractors] django = django_babel.extract:extract_django ,0,3
openstack%2Fneutron~stable%2Frocky~Iea61238f37fdf24c0264f96d104ee0b3b6aec8e2,openstack/neutron,stable/rocky,Iea61238f37fdf24c0264f96d104ee0b3b6aec8e2,Use constraints for docs tox target and cap hacking,MERGED,2019-12-19 12:30:23.000000000,2019-12-29 01:48:29.000000000,2019-12-29 01:47:01.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 10342}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28714}, {'_account_id': 29071}]","[{'number': 1, 'created': '2019-12-19 12:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5adb3a6fac55d3fb32b13009226b1c9a27b21d0', 'message': 'Use constraints for docs tox target and cap hacking\n\nThis patch fixes 2 problems to fix gate jobs in Rocky.\n\n1. In Stein the docs target started to fail when new release of\n   neutron-lib appeared. This is because tox installs neutron and its\n   requirements without any constraints. To fix this both the upper\n   constraints and neutron requirements needs to be added to\n   dependencies of docs target.\n\n2. Cap hacking in test-requirements.txt\n\n   hacking as a linter is in global requirements blacklist and so is\n   not in constraints. Recent release introduced new rules that\n   required fix on master, on stable branches we should rather cap to\n   the version that was in use during this release development.\n\nConflicts:\n       tox.ini\n\nCloses-Bug: #1856156\nChange-Id: Iea61238f37fdf24c0264f96d104ee0b3b6aec8e2\n(cherry picked from commit 07be7934359aa121761396ba47128904f19cb2e4)\n(cherry picked from commit d1c4ba581085f4978da82a597b1387d60e79ff0c)\n(cherry picked from commit 34239888eb661415ed372808304a42339563dad6)\n'}, {'number': 2, 'created': '2019-12-19 14:19:46.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca63f48054d7e359c47ebd73541f114b1fcba6ba', 'message': 'Use constraints for docs tox target and cap hacking\n\nThis patch fixes 3 problems to fix gate jobs in Rocky.\n\n1. In Stein the docs target started to fail when new release of\n   neutron-lib appeared. This is because tox installs neutron and its\n   requirements without any constraints. To fix this both the upper\n   constraints and neutron requirements needs to be added to\n   dependencies of docs target.\n\n2. Cap hacking in test-requirements.txt\n\n   hacking as a linter is in global requirements blacklist and so is\n   not in constraints. Recent release introduced new rules that\n   required fix on master, on stable branches we should rather cap to\n   the version that was in use during this release development.\n\n3. Update sphinx requirements\n\n   Requirement check is failing on sphinx:\n\n   Requirement(package=\'sphinx\', location=\'\', specifiers=\'!=1.6.6,>=1.6.2\', markers=\'\', comment=\'# BSD\', extras=frozenset()) \'markers\': \'\' does not match ""python_version>=\'3.4\'""\n   Could not find a global requirements entry to match package {}. If the package is already included in the global list, the name or platform markers there may not match the local settings.\n\nConflicts:\n       tox.ini\n\nCloses-Bug: #1856156\nChange-Id: Iea61238f37fdf24c0264f96d104ee0b3b6aec8e2\n(cherry picked from commit 07be7934359aa121761396ba47128904f19cb2e4)\n(cherry picked from commit d1c4ba581085f4978da82a597b1387d60e79ff0c)\n(cherry picked from commit 34239888eb661415ed372808304a42339563dad6)\n'}]",1,699969,ca63f48054d7e359c47ebd73541f114b1fcba6ba,16,10,2,21798,,,0,"Use constraints for docs tox target and cap hacking

This patch fixes 3 problems to fix gate jobs in Rocky.

1. In Stein the docs target started to fail when new release of
   neutron-lib appeared. This is because tox installs neutron and its
   requirements without any constraints. To fix this both the upper
   constraints and neutron requirements needs to be added to
   dependencies of docs target.

2. Cap hacking in test-requirements.txt

   hacking as a linter is in global requirements blacklist and so is
   not in constraints. Recent release introduced new rules that
   required fix on master, on stable branches we should rather cap to
   the version that was in use during this release development.

3. Update sphinx requirements

   Requirement check is failing on sphinx:

   Requirement(package='sphinx', location='', specifiers='!=1.6.6,>=1.6.2', markers='', comment='# BSD', extras=frozenset()) 'markers': '' does not match ""python_version>='3.4'""
   Could not find a global requirements entry to match package {}. If the package is already included in the global list, the name or platform markers there may not match the local settings.

Conflicts:
       tox.ini

Closes-Bug: #1856156
Change-Id: Iea61238f37fdf24c0264f96d104ee0b3b6aec8e2
(cherry picked from commit 07be7934359aa121761396ba47128904f19cb2e4)
(cherry picked from commit d1c4ba581085f4978da82a597b1387d60e79ff0c)
(cherry picked from commit 34239888eb661415ed372808304a42339563dad6)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/699969/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,b5adb3a6fac55d3fb32b13009226b1c9a27b21d0,bug/1856156,envdir = {toxworkdir}/docs deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/rocky} -r{toxinidir}/doc/requirements.txt -r{toxinidir}/requirements.txt,deps = -r{toxinidir}/doc/requirements.txt,6,2
openstack%2Fzun~master~I3fe1d8a6c961745801b07612b8982940aa683b3a,openstack/zun,master,I3fe1d8a6c961745801b07612b8982940aa683b3a,Rename Network object to ZunNetwork,MERGED,2019-12-28 19:08:11.000000000,2019-12-29 01:13:03.000000000,2019-12-29 01:11:37.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-28 19:08:11.000000000', 'files': ['zun/network/kuryr_network.py', 'zun/objects/zun_network.py', 'zun/tests/unit/compute/test_compute_manager.py', 'zun/objects/__init__.py', 'zun/tests/unit/api/controllers/v1/test_networks.py', 'zun/tests/unit/network/test_kuryr_network.py', 'zun/api/controllers/v1/networks.py', 'zun/tests/unit/compute/test_compute_api.py', 'zun/tests/unit/objects/test_network.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/29df26207566717f0d1009091d25ea63b3b1d771', 'message': 'Rename Network object to ZunNetwork\n\nThere is a Network object defined in os_vif library. To avoid\nname conflicting, we rename the object in Zun.\n\nChange-Id: I3fe1d8a6c961745801b07612b8982940aa683b3a\n'}]",0,700730,29df26207566717f0d1009091d25ea63b3b1d771,7,2,1,11536,,,0,"Rename Network object to ZunNetwork

There is a Network object defined in os_vif library. To avoid
name conflicting, we rename the object in Zun.

Change-Id: I3fe1d8a6c961745801b07612b8982940aa683b3a
",git fetch https://review.opendev.org/openstack/zun refs/changes/30/700730/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/network/kuryr_network.py', 'zun/objects/zun_network.py', 'zun/tests/unit/compute/test_compute_manager.py', 'zun/objects/__init__.py', 'zun/tests/unit/api/controllers/v1/test_networks.py', 'zun/tests/unit/network/test_kuryr_network.py', 'zun/api/controllers/v1/networks.py', 'zun/tests/unit/compute/test_compute_api.py', 'zun/tests/unit/objects/test_network.py', 'zun/tests/unit/objects/test_objects.py']",10,29df26207566717f0d1009091d25ea63b3b1d771,," 'ZunNetwork': '1.1-26e8d37a54e5fc905ede657744a221d9',"," 'Network': '1.1-26e8d37a54e5fc905ede657744a221d9',",36,36
openstack%2Fnetworking-ovn~master~I1bd9da9eaa64c2475f5495243980a9e334befa45,openstack/networking-ovn,master,I1bd9da9eaa64c2475f5495243980a9e334befa45,Update pointer to OVN with OpenStack tutorial,MERGED,2019-12-01 04:55:37.000000000,2019-12-29 00:26:20.000000000,2019-12-29 00:24:54.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5756}, {'_account_id': 11952}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 29874}]","[{'number': 1, 'created': '2019-12-01 04:55:37.000000000', 'files': ['doc/source/admin/tutorial.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f59c5aad780cf34e978efce7f1cea75edb361380', 'message': 'Update pointer to OVN with OpenStack tutorial\n\nUpdate pointer to OVN with OpenStack tutorial\n\nTrivialFix\n\nChange-Id: I1bd9da9eaa64c2475f5495243980a9e334befa45\n'}]",2,696783,f59c5aad780cf34e978efce7f1cea75edb361380,21,9,1,4694,,,0,"Update pointer to OVN with OpenStack tutorial

Update pointer to OVN with OpenStack tutorial

TrivialFix

Change-Id: I1bd9da9eaa64c2475f5495243980a9e334befa45
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/83/696783/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/tutorial.rst'],1,f59c5aad780cf34e978efce7f1cea75edb361380,fix-tutorial-link,`OpenStack and OVN Tutorial <http://docs.openvswitch.org/en/stable/tutorials/ovn-openstack/>`_,`OpenStack and OVN Tutorial <http://docs.openvswitch.org/en/latest/tutorials/ovn-openstack/>`_,1,1
openstack%2Ftempest-stress~master~I79ab8d8773cedd22d51fd0e7cd5d2007f11bb186,openstack/tempest-stress,master,I79ab8d8773cedd22d51fd0e7cd5d2007f11bb186,Correct README for repo path,MERGED,2019-12-28 23:20:07.000000000,2019-12-29 00:06:58.000000000,2019-12-29 00:06:58.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-28 23:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-stress/commit/30401ed882de5739868ae80ae28dbc93b94fcef7', 'message': 'Correct README for repo path\n\nChange-Id: I79ab8d8773cedd22d51fd0e7cd5d2007f11bb186\n'}, {'number': 2, 'created': '2019-12-29 00:00:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tempest-stress/commit/de0856c5682465f445439f3adaa12015029c9322', 'message': 'Correct README for repo path\n\nChange-Id: I79ab8d8773cedd22d51fd0e7cd5d2007f11bb186\n'}]",0,700739,de0856c5682465f445439f3adaa12015029c9322,8,2,2,8556,,,0,"Correct README for repo path

Change-Id: I79ab8d8773cedd22d51fd0e7cd5d2007f11bb186
",git fetch https://review.opendev.org/openstack/tempest-stress refs/changes/39/700739/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,30401ed882de5739868ae80ae28dbc93b94fcef7,, $ git clone https://github.com/openstack/tempest-stresss, $ git clone https://github.com/ghanshyammann/tempest_stress,1,1
openstack%2Fheat-dashboard~master~I0ce4f80fc0ff254ef7f3da968ff58e74ef056d60,openstack/heat-dashboard,master,I0ce4f80fc0ff254ef7f3da968ff58e74ef056d60,Imported Translations from Zanata,MERGED,2019-12-22 07:42:51.000000000,2019-12-28 22:36:53.000000000,2019-12-28 22:35:25.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 07:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/383ca2e7ac31fbeb0c313fa90a1c74ba8de6ad86', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0ce4f80fc0ff254ef7f3da968ff58e74ef056d60\n'}, {'number': 2, 'created': '2019-12-24 07:49:50.000000000', 'files': ['releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/f7af4f4117313219368d8041f5f2634452469f77', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0ce4f80fc0ff254ef7f3da968ff58e74ef056d60\n'}]",0,700309,f7af4f4117313219368d8041f5f2634452469f77,9,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I0ce4f80fc0ff254ef7f3da968ff58e74ef056d60
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/09/700309/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po']",4,383ca2e7ac31fbeb0c313fa90a1c74ba8de6ad86,zanata/translations,,"# Gaelle <pattedeph@gmail.com>, 2017. #zanata # Loic Nicolle <loic.nicolle@orange.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: heat-dashboard\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2018-08-20 07:47+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-11-14 07:50+0000\n"" ""Last-Translator: Gaelle <pattedeph@gmail.com>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid ""Current Series Release Notes"" msgstr ""Notes sur la Release Actuelle"" msgid ""New Features"" msgstr ""Nouvelles fonctionnalits"" ",14,63
openstack%2Fkeystone~stable%2Ftrain~I1b2413a5d6818f73f721f00ba5c4b610be733b1b,openstack/keystone,stable/train,I1b2413a5d6818f73f721f00ba5c4b610be733b1b,Fix line-length PEP8 errors for c7fae97,MERGED,2019-10-24 20:56:32.000000000,2019-12-28 17:21:01.000000000,2019-12-28 17:19:18.000000000,"[{'_account_id': 5046}, {'_account_id': 6873}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 27621}, {'_account_id': 28471}]","[{'number': 1, 'created': '2019-10-24 20:56:32.000000000', 'files': ['keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/test_backend_ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a16400f023618c81b6a2f843f15fbe55b66c259f', 'message': 'Fix line-length PEP8 errors for c7fae97\n\nThis patch corrects PEP8 failures introduced in c7fae97 that were not\ncaught by the linter since the check was accidentally disabled. This\npatch is backportable. A followup patch will correct the issue for the\nwhole codebase and re-enable the check.\n\nChange-Id: I1b2413a5d6818f73f721f00ba5c4b610be733b1b\n(cherry picked from commit 19d4831daa3991bed48fb364fa05927740c96445)\n'}]",0,691118,a16400f023618c81b6a2f843f15fbe55b66c259f,26,8,1,8482,,,0,"Fix line-length PEP8 errors for c7fae97

This patch corrects PEP8 failures introduced in c7fae97 that were not
caught by the linter since the check was accidentally disabled. This
patch is backportable. A followup patch will correct the issue for the
whole codebase and re-enable the check.

Change-Id: I1b2413a5d6818f73f721f00ba5c4b610be733b1b
(cherry picked from commit 19d4831daa3991bed48fb364fa05927740c96445)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/691118/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/test_backend_ldap.py']",2,a16400f023618c81b6a2f843f15fbe55b66c259f,e501-stable/train," group_ref = PROVIDERS.identity_api.get_group_by_name( group_name, CONF.identity.default_domain_id) PROVIDERS.identity_api.check_user_in_group( user_ref['id'], group_ref['id']) group_ref = PROVIDERS.identity_api.get_group_by_name( group_name, CONF.identity.default_domain_id) PROVIDERS.identity_api.check_user_in_group( user_ref['id'], group_ref['id'])"," group_ref = PROVIDERS.identity_api.get_group_by_name(group_name, CONF.identity.default_domain_id) PROVIDERS.identity_api.check_user_in_group(user_ref['id'], group_ref['id']) group_ref = PROVIDERS.identity_api.get_group_by_name(group_name, CONF.identity.default_domain_id) PROVIDERS.identity_api.check_user_in_group(user_ref['id'], group_ref['id'])",12,8
openstack%2Ftrove-dashboard~master~I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0,openstack/trove-dashboard,master,I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0,Drop python 2.7 support and testing,MERGED,2019-10-30 05:41:07.000000000,2019-12-28 17:11:49.000000000,2019-12-28 17:09:56.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-10-30 05:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/36dfc428b8590949b6c3f66164cc5da98651f6a4', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\ntrove-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0\n'}, {'number': 2, 'created': '2019-12-05 06:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/1d026965fd6bca3630f66ae37bab6787b38335f4', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\ntrove-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nAlso this patch update minimum tox version in tox.ini file.\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0\n'}, {'number': 3, 'created': '2019-12-05 06:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/2e1bc950adc37f3e72cac5895865bc11945a9a76', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\ntrove-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nAlso this patch update minimum tox version in tox.ini file.\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0\n'}, {'number': 4, 'created': '2019-12-05 06:15:32.000000000', 'files': ['releasenotes/notes/drop-py-2-7-ee223d109e3bd38e.yaml', '.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/60924242e1d537e1eb593624682a299606b3fc33', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\ntrove-dashboard is ready with python 3 and ok to drop the\npython 2.7 support.\n\nAlso this patch update minimum tox version in tox.ini file.\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0\n'}]",3,692030,60924242e1d537e1eb593624682a299606b3fc33,18,4,4,8556,,,0,"Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

trove-dashboard is ready with python 3 and ok to drop the
python 2.7 support.

Also this patch update minimum tox version in tox.ini file.
Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Change-Id: I7fcfcb5c32481ad5a5839b98cf35198545d2e6a0
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/30/692030/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-py-2-7-ee223d109e3bd38e.yaml', '.zuul.yaml', 'setup.cfg', 'tox.ini']",4,36dfc428b8590949b6c3f66164cc5da98651f6a4,drop-py27-support,"envlist = py37,py3-{dj111,dj22},pep8","envlist = py27,py37,py3-{dj111,dj22},pep8[testenv:py27] setenv = DJANGO_SETTINGS_MODULE=trove_dashboard.test.settings [testenv:py27integration] basepython = python2.7 commands = /bin/bash run_tests.sh -N --integration --selenium-headless {posargs} ",8,12
openstack%2Fneutron-fwaas-dashboard~master~I323376e44701f69bef9fbfab9cb1d11e59c582ac,openstack/neutron-fwaas-dashboard,master,I323376e44701f69bef9fbfab9cb1d11e59c582ac,Imported Translations from Zanata,MERGED,2019-12-22 08:13:30.000000000,2019-12-28 17:09:15.000000000,2019-12-28 17:07:52.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 08:13:30.000000000', 'files': ['releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas-dashboard/commit/4eb4547c2be3ede216ee8858e678e9cc068e16b1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I323376e44701f69bef9fbfab9cb1d11e59c582ac\n'}]",0,700315,4eb4547c2be3ede216ee8858e678e9cc068e16b1,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I323376e44701f69bef9fbfab9cb1d11e59c582ac
",git fetch https://review.opendev.org/openstack/neutron-fwaas-dashboard refs/changes/15/700315/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/es/LC_MESSAGES/releasenotes.po']",3,4eb4547c2be3ede216ee8858e678e9cc068e16b1,zanata/translations,,"# Jose Porrua <jose.porrua@netapp.com>, 2016. #zanata # Eduardo Gonzalez Gutierrez <dabarren@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: neutron-fwaas-dashboard\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2019-03-27 14:25+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-09-27 03:49+0000\n"" ""Last-Translator: Eduardo Gonzalez Gutierrez <dabarren@gmail.com>\n"" ""Language-Team: Spanish\n"" ""Language: es\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" msgid ""Bug Fixes"" msgstr ""Correccin de errores"" msgid ""Current Series Release Notes"" msgstr ""Notas de la versin actual"" msgid ""New Features"" msgstr ""Nuevas Funcionalidades"" ",14,52
openstack%2Fmanila~master~Ia6ba0ae28181f0ca0f01f93284b347cbf0bda642,openstack/manila,master,Ia6ba0ae28181f0ca0f01f93284b347cbf0bda642,Add manila-specs link to readme.rst,MERGED,2019-12-27 09:27:53.000000000,2019-12-28 15:31:39.000000000,2019-12-28 15:29:56.000000000,"[{'_account_id': 6413}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 17130}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-12-27 09:27:53.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/edfde7ed03cf05c8a36ba11fe71591fe412428a0', 'message': 'Add manila-specs link to readme.rst\n\nChange-Id: Ia6ba0ae28181f0ca0f01f93284b347cbf0bda642\n'}]",0,700696,edfde7ed03cf05c8a36ba11fe71591fe412428a0,16,14,1,27383,,,0,"Add manila-specs link to readme.rst

Change-Id: Ia6ba0ae28181f0ca0f01f93284b347cbf0bda642
",git fetch https://review.opendev.org/openstack/manila refs/changes/96/700696/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,edfde7ed03cf05c8a36ba11fe71591fe412428a0,add_spec_link, * Design specifications are tracked at: https://specs.openstack.org/openstack/manila-specs/,,4,0
openstack%2Fsenlin-dashboard~master~I8294fce89d06415ff8142f032c2f939c74e5088b,openstack/senlin-dashboard,master,I8294fce89d06415ff8142f032c2f939c74e5088b,translation: drop babel extractor definitions,MERGED,2019-12-26 17:28:35.000000000,2019-12-28 15:03:28.000000000,2019-12-28 15:02:11.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-26 17:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/0a8860f611f39638c87e05e9dc799483ba8b3b30', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I8294fce89d06415ff8142f032c2f939c74e5088b\n'}, {'number': 2, 'created': '2019-12-28 14:35:47.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/e0f29257eb964af5ba831d57b051681de289b7db', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I8294fce89d06415ff8142f032c2f939c74e5088b\n'}]",0,700646,e0f29257eb964af5ba831d57b051681de289b7db,10,2,2,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I8294fce89d06415ff8142f032c2f939c74e5088b
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/46/700646/2 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,0a8860f611f39638c87e05e9dc799483ba8b3b30,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fsenlin-dashboard~master~Ic1329872733397842bba0187440557df37c32826,openstack/senlin-dashboard,master,Ic1329872733397842bba0187440557df37c32826,Add requirements.txt to docs reqs,MERGED,2019-12-28 14:25:12.000000000,2019-12-28 14:59:41.000000000,2019-12-28 14:58:12.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-28 14:25:12.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/639748cfe7ab0ed674f5c4dd5de78d4e8c89d4b8', 'message': 'Add requirements.txt to docs reqs\n\nsenlin-dashboard doc generated the module reference,\nso requirements.txt should be here to apply upper-constraints.\n\nChange-Id: Ic1329872733397842bba0187440557df37c32826\n'}]",0,700723,639748cfe7ab0ed674f5c4dd5de78d4e8c89d4b8,8,2,1,841,,,0,"Add requirements.txt to docs reqs

senlin-dashboard doc generated the module reference,
so requirements.txt should be here to apply upper-constraints.

Change-Id: Ic1329872733397842bba0187440557df37c32826
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/23/700723/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,639748cfe7ab0ed674f5c4dd5de78d4e8c89d4b8,fix-docs-job," # senlin-dashboard doc generated the module reference, # so requirements.txt should be here to apply upper-constraints. -r{toxinidir}/requirements.txt",,3,0
openstack%2Fmanila~master~I595446580a171d38a4612e6849d0c16ae9fe5efd,openstack/manila,master,I595446580a171d38a4612e6849d0c16ae9fe5efd,fix a typo,MERGED,2019-12-27 09:17:02.000000000,2019-12-28 14:39:19.000000000,2019-12-28 14:37:44.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-12-27 09:17:02.000000000', 'files': ['doc/source/contributor/development-environment-devstack.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/7874ea98873231a97158d8573679511de7d4b739', 'message': 'fix a typo\n\nChange-Id: I595446580a171d38a4612e6849d0c16ae9fe5efd\n'}]",0,700694,7874ea98873231a97158d8573679511de7d4b739,16,12,1,27383,,,0,"fix a typo

Change-Id: I595446580a171d38a4612e6849d0c16ae9fe5efd
",git fetch https://review.opendev.org/openstack/manila refs/changes/94/700694/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/development-environment-devstack.rst'],1,7874ea98873231a97158d8573679511de7d4b739,fix_typo,"environments on a virtual machine. If you are not familiar with devstack,","environments on a virtual machine. If you are not familar with devstack,",1,1
openstack%2Fhorizon~stable%2Ftrain~I73234b2c69ce8ea648b4a9721abe4f5670031909,openstack/horizon,stable/train,I73234b2c69ce8ea648b4a9721abe4f5670031909,"Fix ""prev"" link pagination for instances with identical timestamps",MERGED,2019-12-27 18:12:07.000000000,2019-12-28 14:16:49.000000000,2019-12-28 14:14:53.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 18:12:07.000000000', 'files': ['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1108d2c40ee302ed7b350f543d98119fe2c8cbd7', 'message': 'Fix ""prev"" link pagination for instances with identical timestamps\n\nThis patch resolves an issue with the ""prev"" link when instances\nhave identical ""created_at"" values. This can occur when creating\ninstance using the ""min/max count"" option. The reverse sort does not\nwork correctly as the server list returned from nova is not an exact\nreverse as the forward sort. It looks like the combination of sort_keys\nmust be unique to ensure the forward and reverse pagination properly.\nAs a workaround \'uuid\' (server ID) is added to \'sort_keys\'.\nIn addition, \'display_name\' is added before \'uuid\' in \'sort_keys\'\nto list servers in the alphabetical order (which sounds natural).\n\nCloses-Bug #1856243\nChange-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909\n(cherry picked from commit 9637d733749d741d5aac3b89b92e100d32fbdbb0)\n'}]",0,700707,1108d2c40ee302ed7b350f543d98119fe2c8cbd7,9,3,1,14892,,,0,"Fix ""prev"" link pagination for instances with identical timestamps

This patch resolves an issue with the ""prev"" link when instances
have identical ""created_at"" values. This can occur when creating
instance using the ""min/max count"" option. The reverse sort does not
work correctly as the server list returned from nova is not an exact
reverse as the forward sort. It looks like the combination of sort_keys
must be unique to ensure the forward and reverse pagination properly.
As a workaround 'uuid' (server ID) is added to 'sort_keys'.
In addition, 'display_name' is added before 'uuid' in 'sort_keys'
to list servers in the alphabetical order (which sounds natural).

Closes-Bug #1856243
Change-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909
(cherry picked from commit 9637d733749d741d5aac3b89b92e100d32fbdbb0)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/07/700707/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py']",2,1108d2c40ee302ed7b350f543d98119fe2c8cbd7,bug/1856243-stable/train," # NOTE(amotoki): It looks like the 'sort_keys' must be unique to make # the pagination in the nova API works as expected. Multiple servers # can have a same 'created_at' as its resolution is a second. # To ensure the uniqueness we add 'uuid' to the sort keys. # 'display_name' is added before 'uuid' to list servers in the # alphabetical order. sort_keys = ['created_at', 'display_name', 'uuid'] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=[sort_dir] * 3)] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=['desc'] * 3)] for s in nova_client.servers.list(detailed, search_opts, sort_keys=sort_keys, sort_dirs=['asc'] * 3)]"," search_opts['sort_dir'] = sort_dir for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'desc' for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'asc' for s in nova_client.servers.list(detailed, search_opts)]",28,12
openstack%2Fpython-tripleoclient~master~Iab363e327ce4c08c5e9be13b877f835219bae407,openstack/python-tripleoclient,master,Iab363e327ce4c08c5e9be13b877f835219bae407,tripleo_deploy: specify deployment source host,ABANDONED,2019-12-20 15:16:11.000000000,2019-12-28 13:41:36.000000000,,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 15:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ae671ffe06057412e815c00d1d3bbc458f0c24bf', 'message': ""tripleo_deploy: specify deployment source host\n\nExternal deployment tasks for the standalone/undercloud should be\nexecuted against the actual host. Currently, when we deploy a standalone\nit runs the tasks against 'Undercloud' but there are no group vars for\nthe 'Undercloud' in the standalone ansible.  By specifying\ndeployment_source_host with the role in the tripleo deploy command, we\nensure that the tasks are executed against either the 'Undercloud' or a\n'Standalone' role as neccessary.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nChange-Id: Iab363e327ce4c08c5e9be13b877f835219bae407\n""}, {'number': 2, 'created': '2019-12-20 17:16:30.000000000', 'files': ['tripleoclient/v1/tripleo_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/98064f2874490ed8206ca7a885c8d62162187124', 'message': ""tripleo_deploy: specify deployment source host\n\nExternal deployment tasks for the standalone/undercloud should be\nexecuted against the actual host. Currently, when we deploy a standalone\nit runs the tasks against 'Undercloud' but there are no group vars for\nthe 'Undercloud' in the standalone ansible.  By specifying\ndeployment_source_host with the role in the tripleo deploy command, we\nensure that the tasks are executed against either the 'Undercloud' or a\n'Standalone' role as neccessary.\n\nCo-Authored-By: Alex Schultz <aschultz@redhat.com>\nChange-Id: Iab363e327ce4c08c5e9be13b877f835219bae407\n""}]",0,700189,98064f2874490ed8206ca7a885c8d62162187124,9,4,2,3153,,,0,"tripleo_deploy: specify deployment source host

External deployment tasks for the standalone/undercloud should be
executed against the actual host. Currently, when we deploy a standalone
it runs the tasks against 'Undercloud' but there are no group vars for
the 'Undercloud' in the standalone ansible.  By specifying
deployment_source_host with the role in the tripleo deploy command, we
ensure that the tasks are executed against either the 'Undercloud' or a
'Standalone' role as neccessary.

Co-Authored-By: Alex Schultz <aschultz@redhat.com>
Change-Id: Iab363e327ce4c08c5e9be13b877f835219bae407
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/89/700189/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_deploy.py'],1,ae671ffe06057412e815c00d1d3bbc458f0c24bf,deployment_source_host," 'deployment_source_hosts': role_name,",,1,0
openstack%2Fbarbican-ui~master~I7325ff930c65d0c836a1f3181ec3fface1f14355,openstack/barbican-ui,master,I7325ff930c65d0c836a1f3181ec3fface1f14355,translation: drop babel extractor definitions,ABANDONED,2019-12-26 17:11:20.000000000,2019-12-28 13:13:35.000000000,,[{'_account_id': 841}],"[{'number': 1, 'created': '2019-12-26 17:11:20.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/barbican-ui/commit/430641640497d26c325aae845b5937370aafbf3c', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I7325ff930c65d0c836a1f3181ec3fface1f14355\n'}]",0,700634,430641640497d26c325aae845b5937370aafbf3c,3,1,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I7325ff930c65d0c836a1f3181ec3fface1f14355
",git fetch https://review.opendev.org/openstack/barbican-ui refs/changes/34/700634/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,430641640497d26c325aae845b5937370aafbf3c,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fkolla-ansible~stable%2Fstein~Ie9ecb8ab5d4e74af9b83a5b00ccced5b630ab1ed,openstack/kolla-ansible,stable/stein,Ie9ecb8ab5d4e74af9b83a5b00ccced5b630ab1ed,Adds monasca-ui to horizon,ABANDONED,2019-12-28 05:43:34.000000000,2019-12-28 11:48:15.000000000,,"[{'_account_id': 7556}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 31333}]","[{'number': 1, 'created': '2019-12-28 05:43:34.000000000', 'files': ['ansible/roles/horizon/defaults/main.yml', 'ansible/group_vars/all.yml', 'ansible/roles/horizon/tasks/config.yml', 'etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1eebbde7033f3cd83eca71b1e6e199b6a47db901', 'message': 'Adds monasca-ui to horizon\n\nVariable added to evaluate ""ENABLE_MONASCA"" env for \'kolla/horizon\'. In\ncase \'enable_horizon_monasca\' is true, \'policy_item\' would be called for\nMonasca.\n\nChange-Id: Ie9ecb8ab5d4e74af9b83a5b00ccced5b630ab1ed\nImplements: blueprint monasca-ui\nSigned-off-by: Hamed Bahadorzadeh <h.bahadorzadeh@gmail.com>\n'}]",0,700713,1eebbde7033f3cd83eca71b1e6e199b6a47db901,7,4,1,31333,,,0,"Adds monasca-ui to horizon

Variable added to evaluate ""ENABLE_MONASCA"" env for 'kolla/horizon'. In
case 'enable_horizon_monasca' is true, 'policy_item' would be called for
Monasca.

Change-Id: Ie9ecb8ab5d4e74af9b83a5b00ccced5b630ab1ed
Implements: blueprint monasca-ui
Signed-off-by: Hamed Bahadorzadeh <h.bahadorzadeh@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/13/700713/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/horizon/defaults/main.yml', 'ansible/group_vars/all.yml', 'ansible/roles/horizon/tasks/config.yml', 'etc/kolla/globals.yml']",4,1eebbde7033f3cd83eca71b1e6e199b6a47db901,bp/monasca-ui,"#enable_horizon_monasca: ""{{ enable_monasca | bool }}""",,4,0
openstack%2Fswift~master~I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4,openstack/swift,master,I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4,Add versioning+sharding probe test,ABANDONED,2019-12-24 01:51:14.000000000,2019-12-28 06:23:12.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 01:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ba7f93c453e247b78b4b8f2831fad5e5706973ab', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}, {'number': 2, 'created': '2019-12-24 08:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/45b5560f36336d5651984c5c1f91f7febc632d3a', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}, {'number': 3, 'created': '2019-12-26 06:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b227fa7f7252a66e94f1554ad8f464957f2a36ff', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}, {'number': 4, 'created': '2019-12-26 07:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5368871203eff6b2624223ac765a91e4649216d1', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}, {'number': 5, 'created': '2019-12-26 21:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/acdaa8dc80712510cb99a8a0905a71163bf6bbbd', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}, {'number': 6, 'created': '2019-12-27 01:14:44.000000000', 'files': ['test/unit/common/middleware/test_object_versioning.py', 'test/probe/test_sharder.py', 'swift/container/backend.py', 'swift/common/middleware/versioned_writes/object_versioning.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/12429ec5e4c0daa8d723f014812cd8891ef70e51', 'message': 'Add versioning+sharding probe test\n\nChange-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4\n'}]",0,700464,12429ec5e4c0daa8d723f014812cd8891ef70e51,16,2,6,15343,,,0,"Add versioning+sharding probe test

Change-Id: I25b6e7df7bf3782b267798288bcfe9b44fe3a6c4
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/700464/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/test_sharder.py', 'swift/container/backend.py', 'swift/common/middleware/versioned_writes/object_versioning.py']",3,ba7f93c453e247b78b4b8f2831fad5e5706973ab,bug/1856894," HTTPRequestEntityTooLarge, HTTPInternalServerError, HTTPNotAcceptable, \ HTTPConflict raise HTTPConflict( 'Delete all versions before deleting container.',"," HTTPRequestEntityTooLarge, HTTPInternalServerError, HTTPNotAcceptable raise HTTPBadRequest( 'Delete all versions to delete container.',",244,19
openstack%2Ftripleo-heat-templates~master~I36aee0d1001a20916633c18d2c28eccd6f46c56a,openstack/tripleo-heat-templates,master,I36aee0d1001a20916633c18d2c28eccd6f46c56a,Fix ceph-grafana firewall rules,MERGED,2019-12-23 17:35:56.000000000,2019-12-28 06:20:11.000000000,2019-12-28 06:20:11.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 17:35:56.000000000', 'files': ['deployment/ceph-ansible/ceph-grafana.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/238800d1364e4ef5e101c1e04f1a65aecdb0720c', 'message': ""Fix ceph-grafana firewall rules\n\nWe switched to ansible for firewall rule management but the ceph-grafana\nfile wasn't properly converted.\n\nChange-Id: I36aee0d1001a20916633c18d2c28eccd6f46c56a\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",0,700441,238800d1364e4ef5e101c1e04f1a65aecdb0720c,15,5,1,7353,,,0,"Fix ceph-grafana firewall rules

We switched to ansible for firewall rule management but the ceph-grafana
file wasn't properly converted.

Change-Id: I36aee0d1001a20916633c18d2c28eccd6f46c56a
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/41/700441/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ceph-ansible/ceph-grafana.yaml'],1,238800d1364e4ef5e101c1e04f1a65aecdb0720c,bug/1857356, - 9092 - 9283," - tripleo::ceph_grafana::firewall_rules: '123 ceph_dashboard': dport: [3100,9092,9093,9094,9100,9283] - {}",2,4
openstack%2Fkeystone~master~I691e8dad2f1d2fc9b9942934db5e15a48fade1eb,openstack/keystone,master,I691e8dad2f1d2fc9b9942934db5e15a48fade1eb,Imported Translations from Zanata,MERGED,2019-12-22 09:05:46.000000000,2019-12-28 03:20:03.000000000,2019-12-28 03:18:12.000000000,"[{'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-22 09:05:46.000000000', 'files': ['keystone/locale/en_GB/LC_MESSAGES/keystone.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a950f9c376534154ba15b2a7a9f962d316448b7a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I691e8dad2f1d2fc9b9942934db5e15a48fade1eb\n'}]",0,700321,a950f9c376534154ba15b2a7a9f962d316448b7a,23,4,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I691e8dad2f1d2fc9b9942934db5e15a48fade1eb
",git fetch https://review.opendev.org/openstack/keystone refs/changes/21/700321/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/locale/en_GB/LC_MESSAGES/keystone.po'],1,a950f9c376534154ba15b2a7a9f962d316448b7a,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-17 16:21+0000\n""""PO-Revision-Date: 2019-12-21 02:36+0000\n""msgid """" ""%(private_key)s does not exist. You can generate a key pair using `keystone-"" ""manage create_jws_keypair`."" msgstr """" ""%(private_key)s does not exist. You can generate a key pair using `keystone-"" ""manage create_jws_keypair`."" #, python-format msgid """" ""%(public_key_repo)s does not exist. Please make sure the directory exists "" ""and is readable by the process running keystone."" msgstr """" ""%(public_key_repo)s does not exist. Please make sure the directory exists "" ""and is readable by the process running Keystone."" #, python-format msgid """" ""%(public_key_repo)s must contain at least one public key but it is empty. "" ""You can generate a key pair using `keystone-manage create_jws_keypair`."" msgstr """" ""%(public_key_repo)s must contain at least one public key but it is empty. "" ""You can generate a key pair using `keystone-manage create_jws_keypair`."" #, python-formatmsgid ""Cannot create an application credential for another user."" msgstr ""Cannot create an application credential for another user."" ""Cannot create project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" msgstr """" ""Cannot create project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" #, python-format msgid """"""Cannot delete project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" msgstr """" ""Cannot delete project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" #, python-format msgid """"msgid ""Cannot open certificate %(cert_file)s.Reason: %(reason)s"" msgstr ""Cannot open certificate %(cert_file)s.Reason: %(reason)s"" #, python-format#, python-format msgid """" ""Cannot update project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" msgstr """" ""Cannot update project tags for %(project_id)s, project is immutable. Set "" ""\""immutable\"" option to false before creating project tags."" msgid ""Could not find Access Rule: %(access_rule_id)s."" msgstr ""Could not find Access Rule: %(access_rule_id)s."" #, python-formatmsgid ""Could not find application credential: %s"" msgstr ""Could not find application credential: %s"" #, python-format msgid ""Could not find auth receipt: %(receipt_id)s."" msgstr ""Could not find auth receipt: %(receipt_id)s."" #, python-formatmsgid ""Could not recognize Fernet token"" msgstr ""Could not recognise Fernet token"" #, python-format msgid ""DN attribute %(dn)s not found in LDAP"" msgstr ""DN attribute %(dn)s not found in LDAP"" msgid ""Domain ID does not conform to required UUID format."" msgstr ""Domain ID does not conform to required UUID format."" msgid """" ""ERROR: Either --bootstrap-password argument or OS_BOOTSTRAP_PASSWORD must be "" ""set."" msgstr """" ""ERROR: Either --bootstrap-password argument or OS_BOOTSTRAP_PASSWORD must be "" ""set."" msgid ""Failed to validate receipt"" msgstr ""Failed to validate receipt"" msgid ""No receipt in the request"" msgstr ""No receipt in the request"" #, python-format msgid ""Private key %(path)s already exists"" msgstr ""Private key %(path)s already exists"" #, python-format msgid ""Public key %(path)s already exists"" msgstr ""Public key %(path)s already exists"" msgid """" ""The new password cannot be identical to a previous password. The total "" ""number which includes the new password must be unique is %(unique_count)s."" msgstr """" ""The new password cannot be identical to a previous password. The total "" ""number which includes the new password must be unique is %(unique_count)s."" #, python-format#, python-format msgid """" ""The resource limit (%(level)s: %(id)s, resource_name: %(resource_name)s, "" ""resource_limit: %(resource_limit)s, service_id: %(service_id)s, region_id: "" ""%(region_id)s) doesn't satisfy current hierarchy model."" msgstr """" ""The resource limit (%(level)s: %(id)s, resource_name: %(resource_name)s, "" ""resource_limit: %(resource_limit)s, service_id: %(service_id)s, region_id: "" ""%(region_id)s) doesn't satisfy current hierarchy model."" ""The value of the limit which project is %(project_id)s should not bigger "" ""than its parent domain %(domain_id)s."" msgstr """" ""The value of the limit which project is %(project_id)s should not bigger "" ""than its parent domain %(domain_id)s."" #, python-format msgid """"msgid """" ""This API is no longer available due to the removal of support for PKI tokens."" msgstr """" ""This API is no longer available due to the removal of support for PKI tokens."" #, python-format msgid ""This is not a recognized Fernet receipt %s"" msgstr ""This is not a recognised Fernet receipt %s"" ""Unable to delete immutable %(type)s resource: `%(resource_id)s. Set resource "" ""option \""immutable\"" to false first."" msgstr """" ""Unable to delete immutable %(type)s resource: `%(resource_id)s. Set resource "" ""option \""immutable\"" to false first."" #, python-format msgid """"msgid """" ""Unable to locate %(binary)s binary on the system. Check to make sure it is "" ""installed."" msgstr """" ""Unable to locate %(binary)s binary on the system. Check to make sure it is "" ""installed."" #, python-format""Unable to update immutable %(type)s resource: `%(resource_id)s. Set resource "" ""option \""immutable\"" to false first."" msgstr """" ""Unable to update immutable %(type)s resource: `%(resource_id)s. Set resource "" ""option \""immutable\"" to false first."" #, python-format msgid """"msgid ""Unknown parameters found,please provide only oauth parameters."" msgstr ""Unknown parameters found,please provide only oauth parameters."" #, python-format msgid """" ""it is not permitted to have two projects with either the same name or same "" ""id in the same domain: name is %(name)s, project id %(id)s"" msgstr """" ""it is not permitted to have two projects with either the same name or same "" ""id in the same domain: name is %(name)s, project id %(id)s"" msgid ""resulting JSON load was not a dict"" msgstr ""resulting JSON load was not a dict"" ","""POT-Creation-Date: 2019-09-30 20:17+0000\n""""PO-Revision-Date: 2018-08-08 08:58+0000\n""",174,2
openstack%2Foctavia-dashboard~master~I71c629b5ac3ff0978c832c4d25ff09f8c2a2ea11,openstack/octavia-dashboard,master,I71c629b5ac3ff0978c832c4d25ff09f8c2a2ea11,translation: drop babel extractor definitions,MERGED,2019-12-26 17:23:45.000000000,2019-12-28 01:58:35.000000000,2019-12-28 01:57:21.000000000,"[{'_account_id': 2245}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-26 17:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/6f9001383534f527c4e491b2d1ffba88590b0246', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I71c629b5ac3ff0978c832c4d25ff09f8c2a2ea11\n'}, {'number': 2, 'created': '2019-12-27 07:25:28.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/f4f7be3cdc9518c94d6e2dd204b032070ff6b1e6', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I71c629b5ac3ff0978c832c4d25ff09f8c2a2ea11\n'}]",0,700642,f4f7be3cdc9518c94d6e2dd204b032070ff6b1e6,10,3,2,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I71c629b5ac3ff0978c832c4d25ff09f8c2a2ea11
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/42/700642/2 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,6f9001383534f527c4e491b2d1ffba88590b0246,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # .../dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Foctavia-dashboard~master~I7f8db57600b39e4f230261e15d103b1d32968b38,openstack/octavia-dashboard,master,I7f8db57600b39e4f230261e15d103b1d32968b38,Fix Django version in lower-constraints,MERGED,2019-12-27 06:24:07.000000000,2019-12-28 01:54:39.000000000,2019-12-28 01:53:13.000000000,"[{'_account_id': 2245}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-27 06:24:07.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/86fb321f340fea70e5c0ef77e96197815ff0be92', 'message': 'Fix Django version in lower-constraints\n\nhorizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard\nuses Django 1.8. As a result, the latest Django 3.0.1 which is not supported\nin horizon yet is installed when installing horizon as sibling.\nThis leads to a failure in lower-constraints job like [1].\n\n[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616\n\nChange-Id: I7f8db57600b39e4f230261e15d103b1d32968b38\n'}]",0,700676,86fb321f340fea70e5c0ef77e96197815ff0be92,9,3,1,841,,,0,"Fix Django version in lower-constraints

horizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard
uses Django 1.8. As a result, the latest Django 3.0.1 which is not supported
in horizon yet is installed when installing horizon as sibling.
This leads to a failure in lower-constraints job like [1].

[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616

Change-Id: I7f8db57600b39e4f230261e15d103b1d32968b38
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/76/700676/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,86fb321f340fea70e5c0ef77e96197815ff0be92,django-lower-constraitns,Django==1.11,Django==1.8,1,1
openstack%2Fopenstack-helm-images~master~I011862dcf9efbb8b1f9757c65f3d58da49a496d7,openstack/openstack-helm-images,master,I011862dcf9efbb8b1f9757c65f3d58da49a496d7,mini-mirror: Preserve codename and label,MERGED,2019-12-26 20:06:05.000000000,2019-12-27 23:07:25.000000000,2019-12-27 20:23:50.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28237}, {'_account_id': 28618}, {'_account_id': 28628}]","[{'number': 1, 'created': '2019-12-26 20:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/edfdcdfa2b3000480258f5aa2b2f42d5352987e3', 'message': 'mini-mirror: Preserve codename and label\n\nUbuntu 18.04 performs strict checking of the Codename and Label when\nperforming an apt-get update. The snapshots published by aptly do not\nset these parameters in a way that apt-get likes.\n\nThis change explicitly sets the codename and label based on the values\nfrom the upstream repo being mirrored.\n\nNote: this relies on a currently unmerged pull request/\nhttps://github.com/aptly-dev/aptly/pull/892\n\nChange-Id: I011862dcf9efbb8b1f9757c65f3d58da49a496d7\n'}, {'number': 2, 'created': '2019-12-26 20:45:19.000000000', 'files': ['mini-mirror/tools/publish_snapshots.sh', 'mini-mirror/build.sh', 'mini-mirror/Dockerfile.ubuntu_bionic', 'mini-mirror/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/066efa5767dac46944b609edc3b4902ae61a4d9e', 'message': 'mini-mirror: Preserve codename and label\n\nUbuntu 18.04 performs strict checking of the Codename and Label when\nperforming an apt-get update. The snapshots published by aptly do not\nset these parameters in a way that apt-get likes.\n\nThis change explicitly sets the codename and label based on the values\nfrom the upstream repo being mirrored.\n\nNote: this relies on a currently unmerged pull request/\nhttps://github.com/aptly-dev/aptly/pull/892\n\nChange-Id: I011862dcf9efbb8b1f9757c65f3d58da49a496d7\n'}]",0,700655,066efa5767dac46944b609edc3b4902ae61a4d9e,16,8,2,28719,,,0,"mini-mirror: Preserve codename and label

Ubuntu 18.04 performs strict checking of the Codename and Label when
performing an apt-get update. The snapshots published by aptly do not
set these parameters in a way that apt-get likes.

This change explicitly sets the codename and label based on the values
from the upstream repo being mirrored.

Note: this relies on a currently unmerged pull request/
https://github.com/aptly-dev/aptly/pull/892

Change-Id: I011862dcf9efbb8b1f9757c65f3d58da49a496d7
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/55/700655/2 && git format-patch -1 --stdout FETCH_HEAD,"['mini-mirror/tools/publish_snapshots.sh', 'mini-mirror/build.sh']",2,edfdcdfa2b3000480258f5aa2b2f42d5352987e3,,"# Explicitly setting the codename relies on an unmerged pull request # https://github.com/aptly-dev/aptly/pull/892 APTLY_REPO=${APTLY_REPO:-""https://github.com/smstone/aptly.git""} APTLY_REFSPEC=${APTLY_REFSPEC:-""allow-custom-codename""}","APTLY_REPO=${APTLY_REPO:-""https://github.com/aptly-dev/aptly.git""} APTLY_REFSPEC=${APTLY_REFSPEC:-""v1.4.0""}",12,2
openstack%2Fopenstack-helm-images~master~I96495bd08babadf8ab1d332e86b251bd985248be,openstack/openstack-helm-images,master,I96495bd08babadf8ab1d332e86b251bd985248be,mini-mirror: Build aptly from source,MERGED,2019-12-26 20:06:05.000000000,2019-12-27 23:07:18.000000000,2019-12-27 20:23:09.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28237}, {'_account_id': 28618}, {'_account_id': 28628}]","[{'number': 1, 'created': '2019-12-26 20:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/ec1cc28c3e9ed5add0f3517935f50239624c0433', 'message': 'mini-mirror: build aptly from source\n\nThis change allows aptly to be build from source instead of installed\nfrom the aptly repo.\n\nChange-Id: I96495bd08babadf8ab1d332e86b251bd985248be\n'}, {'number': 2, 'created': '2019-12-26 20:45:19.000000000', 'files': ['mini-mirror/tools/install_aptly.sh', 'mini-mirror/build.sh', 'mini-mirror/Dockerfile.ubuntu_bionic', 'mini-mirror/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/6c3f46abd8d16eff89a62292ee8769d99dcc0900', 'message': 'mini-mirror: Build aptly from source\n\nThis change allows aptly to be built from source instead of installed\nfrom the aptly repo.\n\nChange-Id: I96495bd08babadf8ab1d332e86b251bd985248be\n'}]",0,700654,6c3f46abd8d16eff89a62292ee8769d99dcc0900,16,8,2,28719,,,0,"mini-mirror: Build aptly from source

This change allows aptly to be built from source instead of installed
from the aptly repo.

Change-Id: I96495bd08babadf8ab1d332e86b251bd985248be
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/54/700654/1 && git format-patch -1 --stdout FETCH_HEAD,"['mini-mirror/tools/install_aptly.sh', 'mini-mirror/build.sh', 'mini-mirror/Dockerfile.ubuntu_bionic', 'mini-mirror/Dockerfile.ubuntu_xenial']",4,ec1cc28c3e9ed5add0f3517935f50239624c0433,,ARG APTLY_INSTALL_FROM=source ARG APTLY_REPO=https://github.com/aptly-dev/aptly.git ARG APTLY_REFSPEC=master ,,52,4
openstack%2Fopenstack-helm-images~master~Ib12b29097c5d734982d613d3d01b057791170733,openstack/openstack-helm-images,master,Ib12b29097c5d734982d613d3d01b057791170733,mini-mirror: Create one mirror per repo,MERGED,2019-12-26 20:06:05.000000000,2019-12-27 23:07:14.000000000,2019-12-27 20:21:56.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28237}, {'_account_id': 28618}, {'_account_id': 28628}]","[{'number': 1, 'created': '2019-12-26 20:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c17abd27a48d5dfb9025a33f181997df338335c5', 'message': 'mini-mirror: Create one mirror per repo\n\nWhen mirroring a repo with multiple components, mini-mirror will create\na separate mirror for each component, create a snapshot for each of the\ncomponent repos, and then publish a merge of the snapshots.\n\nThis change makes it a one-to-one mapping of aptly mirrors to repos.\n\nChange-Id: Ib12b29097c5d734982d613d3d01b057791170733\n'}, {'number': 2, 'created': '2019-12-26 20:45:19.000000000', 'files': ['mini-mirror/tools/publish_snapshots.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/2527c091c16273c0f446bde20acdd6354e585ffe', 'message': 'mini-mirror: Create one mirror per repo\n\nWhen mirroring a repo with multiple components, mini-mirror will create\na separate mirror for each component, create a snapshot for each of the\ncomponent repos, and then publish a merge of the snapshots.\n\nThis change makes it a one-to-one mapping of aptly mirrors to repos.\n\nChange-Id: Ib12b29097c5d734982d613d3d01b057791170733\n'}]",0,700653,2527c091c16273c0f446bde20acdd6354e585ffe,17,8,2,28719,,,0,"mini-mirror: Create one mirror per repo

When mirroring a repo with multiple components, mini-mirror will create
a separate mirror for each component, create a snapshot for each of the
component repos, and then publish a merge of the snapshots.

This change makes it a one-to-one mapping of aptly mirrors to repos.

Change-Id: Ib12b29097c5d734982d613d3d01b057791170733
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/53/700653/2 && git format-patch -1 --stdout FETCH_HEAD,['mini-mirror/tools/publish_snapshots.sh'],1,c17abd27a48d5dfb9025a33f181997df338335c5,," # Create a mirror of the source repository, update it, aptly mirror create \ -config=""${conf}"" \ -filter=""${packages}"" \ -filter-with-deps \ ""${source}"" ""${repo}"" ""${dist}"" ${components[@]} aptly mirror update -config=""${conf}"" -max-tries=3 ""${source}"" aptly snapshot create -config=""${conf}"" ""${source}"" from mirror ""${source}"" ""${source}"" ""${source_prefix:13}"" ""${source}"" ""${source_prefix:13}"""," # Create a mirror of each component from a source's repository, update it, mirrors=() for component in $components; do name=""${source}-${component}"" mirrors+=(""$name"") aptly mirror create \ -config=""${conf}"" \ -filter=""${packages}"" \ -filter-with-deps \ ""${name}"" ""${repo}"" ""${dist}"" ""${component}"" aptly mirror update -config=""${conf}"" -max-tries=3 ""${name}"" aptly snapshot create -config=""${conf}"" ""${name}"" from mirror ""${name}"" done ""${mirrors[@]}"" ""${source_prefix:13}"" ""${mirrors[@]}"" ""${source_prefix:13}""",10,16
openstack%2Ftacker~master~Ib81dc846bb1ebe1466f1c27694684b1d244c66fc,openstack/tacker,master,Ib81dc846bb1ebe1466f1c27694684b1d244c66fc,Fix gate failure,ABANDONED,2019-12-17 15:09:05.000000000,2019-12-27 21:45:46.000000000,,"[{'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26588}, {'_account_id': 27180}, {'_account_id': 31072}]","[{'number': 1, 'created': '2019-12-17 15:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6420ebd2a9775c281cc667ba7e1297e805dafd36', 'message': 'Fix gate failure\n\nDevstack fail to fatch openwrt image from [1], as this location\nis inaccessible now. Fixing this issue by providing official\nopenwrt image location.\n\n[1]: https://anda.ssu.ac.kr/~openwrt/openwrt-x86-kvm_guest-combined-ext4.img.gz\n\nChange-Id: Ib81dc846bb1ebe1466f1c27694684b1d244c66fc\n'}, {'number': 2, 'created': '2019-12-18 15:13:27.000000000', 'files': ['devstack/lib/tacker', 'doc/source/install/deploy_openwrt.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/f56851a6515b607626f21b64bf4c29855a997bd4', 'message': 'Fix gate failure\n\nDevstack fail to fatch openwrt image from [1], as this location\nis inaccessible now. Fixing this issue by providing official\nopenwrt image location.\n\n[1]: https://anda.ssu.ac.kr/~openwrt/openwrt-x86-kvm_guest-combined-ext4.img.gz\n\nChange-Id: Ib81dc846bb1ebe1466f1c27694684b1d244c66fc\n'}]",0,699432,f56851a6515b607626f21b64bf4c29855a997bd4,11,6,2,18955,,,0,"Fix gate failure

Devstack fail to fatch openwrt image from [1], as this location
is inaccessible now. Fixing this issue by providing official
openwrt image location.

[1]: https://anda.ssu.ac.kr/~openwrt/openwrt-x86-kvm_guest-combined-ext4.img.gz

Change-Id: Ib81dc846bb1ebe1466f1c27694684b1d244c66fc
",git fetch https://review.opendev.org/openstack/tacker refs/changes/32/699432/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/tacker', 'doc/source/install/deploy_openwrt.rst']",2,6420ebd2a9775c281cc667ba7e1297e805dafd36,,.. [#] https://archive.openwrt.org/chaos_calmer/15.05/x86/kvm_guest/openwrt-15.05-x86-kvm_guest-combined-ext4.img.gz,.. [#] https://anda.ssu.ac.kr/~openwrt/openwrt-x86-kvm_guest-combined-ext4.img.gz,5,3
openstack%2Fkuryr-libnetwork~master~I18a2a6c057225e30ba7e03e1377ab88884d8d2bd,openstack/kuryr-libnetwork,master,I18a2a6c057225e30ba7e03e1377ab88884d8d2bd,Retry a few times on listing extensions,MERGED,2019-11-30 20:06:28.000000000,2019-12-27 20:32:44.000000000,2019-12-04 13:41:35.000000000,"[{'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-30 20:06:28.000000000', 'files': ['kuryr_libnetwork/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr-libnetwork/commit/97266ff5b904db5bd89930ff8fa7bc4ba3506ebe', 'message': 'Retry a few times on listing extensions\n\nListing neutron extensions is part of the startup process.\nDuring system reboot, kuryr-libnetwork process might start before\nthe neutron processes, which leads to failure on listing neutron\nextensions thus failing the kuryr process.\n\nWe need to be robust on startup. This commit will retry a few\ntimes on listing extensions to handle this case.\n\nChange-Id: I18a2a6c057225e30ba7e03e1377ab88884d8d2bd\nRelated-Bug: #1850936\n'}]",0,696779,97266ff5b904db5bd89930ff8fa7bc4ba3506ebe,9,7,1,11536,,,0,"Retry a few times on listing extensions

Listing neutron extensions is part of the startup process.
During system reboot, kuryr-libnetwork process might start before
the neutron processes, which leads to failure on listing neutron
extensions thus failing the kuryr process.

We need to be robust on startup. This commit will retry a few
times on listing extensions to handle this case.

Change-Id: I18a2a6c057225e30ba7e03e1377ab88884d8d2bd
Related-Bug: #1850936
",git fetch https://review.opendev.org/openstack/kuryr-libnetwork refs/changes/79/696779/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_libnetwork/controllers.py'],1,97266ff5b904db5bd89930ff8fa7bc4ba3506ebe,bug/1850936,"import mathimport time max_attempts = 8 for attempt in range(max_attempts): try: app.neutron.show_extension(MANDATORY_NEUTRON_EXTENSION) break except n_exceptions.NeutronClientException as e: if e.status_code == n_exceptions.NotFound.status_code: raise exceptions.MandatoryApiMissing( ""Neutron extension with alias '{0}' not found"" .format(MANDATORY_NEUTRON_EXTENSION)) elif attempt == max_attempts - 1: raise else: LOG.error(""Error happened during retrieving neutron "" ""extensions"") except Exception as e: if attempt == max_attempts - 1: raise else: LOG.error(""Error happened during retrieving neutron "" ""extensions: %s"", e) backoff = int(math.pow(2, attempt) - 1) time.sleep(backoff)"," try: app.neutron.show_extension(MANDATORY_NEUTRON_EXTENSION) except n_exceptions.NeutronClientException as e: if e.status_code == n_exceptions.NotFound.status_code: raise exceptions.MandatoryApiMissing( ""Neutron extension with alias '{0}' not found"" .format(MANDATORY_NEUTRON_EXTENSION))",25,7
openstack%2Fkeystonemiddleware~stable%2Ftrain~I4f8872e30d85de9a1ab9babe5ead73a65407e5d9,openstack/keystonemiddleware,stable/train,I4f8872e30d85de9a1ab9babe5ead73a65407e5d9,Update TOX/UPPER_CONSTRAINTS_FILE for stable/train,MERGED,2019-09-20 16:23:11.000000000,2019-12-27 20:27:52.000000000,2019-12-27 20:26:39.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-20 16:23:11.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/77704686299e2750f50df3ab521411c3e66548d5', 'message': 'Update TOX/UPPER_CONSTRAINTS_FILE for stable/train\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/train branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I4f8872e30d85de9a1ab9babe5ead73a65407e5d9\n'}]",0,683461,77704686299e2750f50df3ab521411c3e66548d5,15,5,1,22816,,,0,"Update TOX/UPPER_CONSTRAINTS_FILE for stable/train

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/train branch, tests will
continue to use the upper-constraints list on master.

Change-Id: I4f8872e30d85de9a1ab9babe5ead73a65407e5d9
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/61/683461/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,77704686299e2750f50df3ab521411c3e66548d5,create-train, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train}, -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt},1,1
openstack%2Fkeystonemiddleware~stable%2Ftrain~I94130c964769e960459555ab433893643f4f1101,openstack/keystonemiddleware,stable/train,I94130c964769e960459555ab433893643f4f1101,Update .gitreview for stable/train,MERGED,2019-09-20 16:23:06.000000000,2019-12-27 18:29:20.000000000,2019-12-27 18:28:04.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-20 16:23:06.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3cd00ced8655783e536e7a591cad3a425dcc8714', 'message': 'Update .gitreview for stable/train\n\nChange-Id: I94130c964769e960459555ab433893643f4f1101\n'}]",0,683460,3cd00ced8655783e536e7a591cad3a425dcc8714,15,5,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: I94130c964769e960459555ab433893643f4f1101
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/60/683460/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,3cd00ced8655783e536e7a591cad3a425dcc8714,create-train,defaultbranch=stable/train,,1,0
openstack%2Fhorizon~master~I73234b2c69ce8ea648b4a9721abe4f5670031909,openstack/horizon,master,I73234b2c69ce8ea648b4a9721abe4f5670031909,"Fix ""prev"" link pagination for instances with identical timestamps",MERGED,2019-12-18 19:34:03.000000000,2019-12-27 18:12:07.000000000,2019-12-27 17:44:58.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 1916}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 18889}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-18 19:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/66304dbe282737b6969335042e8b79878086b366', 'message': 'Fix ""prev"" link pagination for instances with identical timestamps\n\nThis patch resolves an issue with the ""prev"" link when instances\nhave identical ""created_at"" values. This can occur when creating\ninstance using the ""min/max count"" option. The reverse sort does not work\ncorrectly as the server list returned from nova is not an exact\nreverse as the forward sort. In order to resolve this, a second\nkey ""display_name"" is added. This ensures the forward and reverse\nsort are exact opposites.\n\nCloses-Bug #1856243\n\nChange-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909\n'}, {'number': 2, 'created': '2019-12-24 21:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/99d08aceba19017ee51a7e6519daf1450135b91f', 'message': 'Fix ""prev"" link pagination for instances with identical timestamps\n\nThis patch resolves an issue with the ""prev"" link when instances\nhave identical ""created_at"" values. This can occur when creating\ninstance using the ""min/max count"" option. The reverse sort does not work\ncorrectly as the server list returned from nova is not an exact\nreverse as the forward sort. In order to resolve this, a second\nkey ""display_name"" is added. This ensures the forward and reverse\nsort are exact opposites.\n\nCloses-Bug #1856243\n\nChange-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909\n'}, {'number': 3, 'created': '2019-12-25 11:16:20.000000000', 'files': ['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9637d733749d741d5aac3b89b92e100d32fbdbb0', 'message': 'Fix ""prev"" link pagination for instances with identical timestamps\n\nThis patch resolves an issue with the ""prev"" link when instances\nhave identical ""created_at"" values. This can occur when creating\ninstance using the ""min/max count"" option. The reverse sort does not\nwork correctly as the server list returned from nova is not an exact\nreverse as the forward sort. It looks like the combination of sort_keys\nmust be unique to ensure the forward and reverse pagination properly.\nAs a workaround \'uuid\' (server ID) is added to \'sort_keys\'.\nIn addition, \'display_name\' is added before \'uuid\' in \'sort_keys\'\nto list servers in the alphabetical order (which sounds natural).\n\nCloses-Bug #1856243\nChange-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909\n'}]",3,699858,9637d733749d741d5aac3b89b92e100d32fbdbb0,27,8,3,14892,,,0,"Fix ""prev"" link pagination for instances with identical timestamps

This patch resolves an issue with the ""prev"" link when instances
have identical ""created_at"" values. This can occur when creating
instance using the ""min/max count"" option. The reverse sort does not
work correctly as the server list returned from nova is not an exact
reverse as the forward sort. It looks like the combination of sort_keys
must be unique to ensure the forward and reverse pagination properly.
As a workaround 'uuid' (server ID) is added to 'sort_keys'.
In addition, 'display_name' is added before 'uuid' in 'sort_keys'
to list servers in the alphabetical order (which sounds natural).

Closes-Bug #1856243
Change-Id: I73234b2c69ce8ea648b4a9721abe4f5670031909
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/699858/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py']",2,66304dbe282737b6969335042e8b79878086b366,bug/1856243," for s in nova_client.servers.list(detailed, search_opts, sort_keys=['created_at', 'display_name'], sort_dirs=[sort_dir, sort_dir])] for s in nova_client.servers.list(detailed, search_opts, sort_keys=['created_at', 'display_name'], sort_dirs=['desc', 'desc'])] for s in nova_client.servers.list(detailed, search_opts, sort_keys=['created_at', 'display_name'], sort_dirs=['asc', 'asc'])]"," search_opts['sort_dir'] = sort_dir for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'desc' for s in nova_client.servers.list(detailed, search_opts)] search_opts['sort_dir'] = 'asc' for s in nova_client.servers.list(detailed, search_opts)]",26,12
openstack%2Fpython-keystoneclient~stable%2Ftrain~I9c7e572833f538d68a9988d440f09bdb6f61087c,openstack/python-keystoneclient,stable/train,I9c7e572833f538d68a9988d440f09bdb6f61087c,Update TOX/UPPER_CONSTRAINTS_FILE for stable/train,MERGED,2019-09-12 09:27:31.000000000,2019-12-27 18:04:54.000000000,2019-12-27 18:03:29.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-12 09:27:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/13b7e7615d70aa169c5944958f9b6312002867db', 'message': 'Update TOX/UPPER_CONSTRAINTS_FILE for stable/train\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/train branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I9c7e572833f538d68a9988d440f09bdb6f61087c\n'}]",0,681677,13b7e7615d70aa169c5944958f9b6312002867db,9,4,1,22816,,,0,"Update TOX/UPPER_CONSTRAINTS_FILE for stable/train

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/train branch, tests will
continue to use the upper-constraints list on master.

Change-Id: I9c7e572833f538d68a9988d440f09bdb6f61087c
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/77/681677/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,13b7e7615d70aa169c5944958f9b6312002867db,create-train, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},1,1
openstack%2Fkeystoneauth~stable%2Ftrain~Ifd8fbd4cc7a2959c0d0214053f188715da51378b,openstack/keystoneauth,stable/train,Ifd8fbd4cc7a2959c0d0214053f188715da51378b,Update TOX/UPPER_CONSTRAINTS_FILE for stable/train,MERGED,2019-09-07 18:24:25.000000000,2019-12-27 18:04:28.000000000,2019-12-27 18:03:13.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-07 18:24:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/fbbd0a44f63a06c4de625ab7ff6ff94946338a3d', 'message': 'Update TOX/UPPER_CONSTRAINTS_FILE for stable/train\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/train branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: Ifd8fbd4cc7a2959c0d0214053f188715da51378b\n'}]",0,680823,fbbd0a44f63a06c4de625ab7ff6ff94946338a3d,10,5,1,22816,,,0,"Update TOX/UPPER_CONSTRAINTS_FILE for stable/train

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/train branch, tests will
continue to use the upper-constraints list on master.

Change-Id: Ifd8fbd4cc7a2959c0d0214053f188715da51378b
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/23/680823/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,fbbd0a44f63a06c4de625ab7ff6ff94946338a3d,create-train, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train}, -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},3,3
openstack%2Fkeystoneauth~stable%2Ftrain~I9e92f16ff9c5b9f327428357d4c185055498e957,openstack/keystoneauth,stable/train,I9e92f16ff9c5b9f327428357d4c185055498e957,Update .gitreview for stable/train,MERGED,2019-09-07 18:24:24.000000000,2019-12-27 18:03:06.000000000,2019-12-27 18:02:00.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-07 18:24:24.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/092f95cba126c2884a79c916fff998d71b7133fa', 'message': 'Update .gitreview for stable/train\n\nChange-Id: I9e92f16ff9c5b9f327428357d4c185055498e957\n'}]",0,680822,092f95cba126c2884a79c916fff998d71b7133fa,14,5,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: I9e92f16ff9c5b9f327428357d4c185055498e957
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/22/680822/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,092f95cba126c2884a79c916fff998d71b7133fa,create-train,defaultbranch=stable/train,,1,0
openstack%2Fpython-keystoneclient~stable%2Ftrain~Ic0c1510257b512f1dfbb4eec8fe15df73c83d6e6,openstack/python-keystoneclient,stable/train,Ic0c1510257b512f1dfbb4eec8fe15df73c83d6e6,Update .gitreview for stable/train,MERGED,2019-09-12 09:27:21.000000000,2019-12-27 18:02:37.000000000,2019-12-27 18:01:20.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-12 09:27:21.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/37a8302b9225a4694ff5e8546dbeabd161193944', 'message': 'Update .gitreview for stable/train\n\nChange-Id: Ic0c1510257b512f1dfbb4eec8fe15df73c83d6e6\n'}]",0,681676,37a8302b9225a4694ff5e8546dbeabd161193944,9,4,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: Ic0c1510257b512f1dfbb4eec8fe15df73c83d6e6
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/76/681676/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,37a8302b9225a4694ff5e8546dbeabd161193944,create-train,defaultbranch=stable/train,,1,0
openstack%2Fsenlin~master~I9f9cced75c77dfe85ec496aca6129465c960f25a,openstack/senlin,master,I9f9cced75c77dfe85ec496aca6129465c960f25a,Update release notes to better reflect new configs,MERGED,2019-12-24 23:22:12.000000000,2019-12-27 17:28:26.000000000,2019-12-27 17:27:00.000000000,"[{'_account_id': 22348}, {'_account_id': 22998}]","[{'number': 1, 'created': '2019-12-24 23:22:12.000000000', 'files': ['releasenotes/notes/split-engine-service-acea7821cadf9d00.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/abdc171303cf5a51eab1019099d12a5416ed5a4f', 'message': 'Update release notes to better reflect new configs\n\nWhile the original release note is correct, we have\nsince deprecated num_engine_workers.\n\nChange-Id: I9f9cced75c77dfe85ec496aca6129465c960f25a\n'}]",0,700525,abdc171303cf5a51eab1019099d12a5416ed5a4f,7,2,1,22623,,,0,"Update release notes to better reflect new configs

While the original release note is correct, we have
since deprecated num_engine_workers.

Change-Id: I9f9cced75c77dfe85ec496aca6129465c960f25a
",git fetch https://review.opendev.org/openstack/senlin refs/changes/25/700525/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/split-engine-service-acea7821cadf9d00.yaml'],1,abdc171303cf5a51eab1019099d12a5416ed5a4f,update_reno, With the introduction of these new services new configuration options [engine] workers = 1 .. .. code-block:: ini , With the introduction of these new services two new configuration options The ``senlin-engine`` service still uses ``num_engine_workers`` to control the number of processes to spawn.,7,4
openstack%2Fopenstack-ansible~stable%2Ftrain~I60ebb8e75e51fa1fd4dad14d019a595f56546f59,openstack/openstack-ansible,stable/train,I60ebb8e75e51fa1fd4dad14d019a595f56546f59,Make upgrade script respect OSA_CONFIG_DIR,MERGED,2019-12-17 10:29:51.000000000,2019-12-27 16:33:05.000000000,2019-12-27 16:31:08.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25591}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-12-17 10:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aafa37f1c8662f5f6dea7e38e6000ceac53277ab', 'message': 'Make upgrade script respect OSA_CONFIG_DIR\n\nThis also adds variable `openstack_clone_root` which equals to\nenvironment variable $OSA_CLONE_ROOT and defaults to\n`/opt/openstack-ansible`.\n\nChange-Id: I60ebb8e75e51fa1fd4dad14d019a595f56546f59\n'}, {'number': 2, 'created': '2019-12-17 11:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/141658376e20e0135d982e37f9e68e2575d17898', 'message': 'Make upgrade script respect OSA_CONFIG_DIR\n\nThis patch applies only for train as placement upgrade has been already\nreverted for master\n\nChange-Id: I60ebb8e75e51fa1fd4dad14d019a595f56546f59\n'}, {'number': 3, 'created': '2019-12-17 12:01:51.000000000', 'files': ['doc/source/admin/upgrades/major-upgrades.rst', 'scripts/upgrade-utilities/deploy-config-changes.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/59e54f529ef23b3ca1c7cc6bf927c48a3e1cbc2e', 'message': 'Make upgrade script respect OSA_CONFIG_DIR\n\nAlso it adds placement_migrate_flag into docs for running\ndeploy-config-changes.yml\n\nThis patch applies only for train as placement upgrade has been already\nreverted for master\n\nChange-Id: I60ebb8e75e51fa1fd4dad14d019a595f56546f59\n'}]",0,699385,59e54f529ef23b3ca1c7cc6bf927c48a3e1cbc2e,16,5,3,28619,,,0,"Make upgrade script respect OSA_CONFIG_DIR

Also it adds placement_migrate_flag into docs for running
deploy-config-changes.yml

This patch applies only for train as placement upgrade has been already
reverted for master

Change-Id: I60ebb8e75e51fa1fd4dad14d019a595f56546f59
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/85/699385/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/upgrade-utilities/deploy-config-changes.yml'],1,aafa37f1c8662f5f6dea7e38e6000ceac53277ab,deploy_changes," dest: ""{{ openstack_config_dir }}/conf.d/placement.yml"" dest: ""{{ openstack_config_dir }}/env.d/placement_metal.yml""", dest: /etc/openstack_deploy/conf.d/placement.yml dest: /etc/openstack_deploy/env.d/placement_metal.yml,2,2
openstack%2Fheat~master~I6de88e687ff95432ddbd0547a7f5759e18d7749e,openstack/heat,master,I6de88e687ff95432ddbd0547a7f5759e18d7749e,Fix the wrong time unit for OS::Octavia::HealthMonitor,MERGED,2019-09-28 11:33:09.000000000,2019-12-27 16:02:33.000000000,2019-09-30 03:20:34.000000000,"[{'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6732}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-28 11:33:09.000000000', 'files': ['heat/engine/resources/openstack/octavia/health_monitor.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ad841b4483eeba9dfd0ccd8f8b4c5d5fd3e15cc1', 'message': ""Fix the wrong time unit for OS::Octavia::HealthMonitor\n\nUnit of both 'delay' and 'timeout' should be seconds based on Octavia\nAPI doc\nhttps://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=create-health-monitor-detail#id105\n\nChange-Id: I6de88e687ff95432ddbd0547a7f5759e18d7749e\nStory: 2006637\nTask: 36852\n""}]",0,685536,ad841b4483eeba9dfd0ccd8f8b4c5d5fd3e15cc1,17,10,1,6732,,,0,"Fix the wrong time unit for OS::Octavia::HealthMonitor

Unit of both 'delay' and 'timeout' should be seconds based on Octavia
API doc
https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=create-health-monitor-detail#id105

Change-Id: I6de88e687ff95432ddbd0547a7f5759e18d7749e
Story: 2006637
Task: 36852
",git fetch https://review.opendev.org/openstack/heat refs/changes/36/685536/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/octavia/health_monitor.py'],1,ad841b4483eeba9dfd0ccd8f8b4c5d5fd3e15cc1,fix-unit, _('The minimum time in seconds between regular connections ' _('Maximum number of seconds for a monitor to wait for a ', _('The minimum time in milliseconds between regular connections ' _('Maximum number of milliseconds for a monitor to wait for a ',2,2
openstack%2Fopenstack-ansible-os_magnum~stable%2Ftrain~Id22502d0fbe33b3d07ad738f39aff8367ef52074,openstack/openstack-ansible-os_magnum,stable/train,Id22502d0fbe33b3d07ad738f39aff8367ef52074,Fix magnum-api wsgi name,MERGED,2019-12-18 17:41:12.000000000,2019-12-27 15:27:41.000000000,2019-12-27 15:26:32.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-12-18 17:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/b37c6a602ca344b2ed18987f3fe6702559acd54a', 'message': 'Fix magnum-api wsgi name\n\nThis should not be a hardcoded path and certainly not to python2.7\n\nChange-Id: Id22502d0fbe33b3d07ad738f39aff8367ef52074\n'}, {'number': 2, 'created': '2019-12-19 15:05:09.000000000', 'files': ['tasks/magnum_post_install.yml', 'defaults/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/a1d2ecdba470d7f434be1fe68981ea87d03c1a0c', 'message': 'Fix magnum-api wsgi name\n\nThis should not be a hardcoded path and certainly not to python2.7\n\nChange-Id: Id22502d0fbe33b3d07ad738f39aff8367ef52074\n'}]",0,699738,a1d2ecdba470d7f434be1fe68981ea87d03c1a0c,13,4,2,28619,,,0,"Fix magnum-api wsgi name

This should not be a hardcoded path and certainly not to python2.7

Change-Id: Id22502d0fbe33b3d07ad738f39aff8367ef52074
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/38/699738/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/magnum_post_install.yml', 'defaults/main.yml', 'vars/main.yml']",3,b37c6a602ca344b2ed18987f3fe6702559acd54a,wsgi_name," 'wsgi_path': magnum_lib_dir.stdout ~ '/api/app.wsgi',"," 'wsgi_path': magnum_bin | dirname ~ '/' ~ value.wsgi_name,",8,2
openstack%2Fansible-hardening~master~I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,openstack/ansible-hardening,master,I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae,Fix ignoring of packages in 'latest' state,MERGED,2019-12-19 12:10:43.000000000,2019-12-27 15:27:27.000000000,2019-12-27 15:21:39.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-12-19 12:10:43.000000000', 'files': ['tasks/rhel7stig/packages.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/2093f503a64f213f58f9cab97a10a6f915a02ce9', 'message': ""Fix ignoring of packages in 'latest' state\n\nChange-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae\n""}]",0,699963,2093f503a64f213f58f9cab97a10a6f915a02ce9,11,3,1,28619,,,0,"Fix ignoring of packages in 'latest' state

Change-Id: I019ed9d87435a1ab6e0b7ae8624d85afd95db3ae
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/63/699963/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/packages.yml'],1,2093f503a64f213f58f9cab97a10a6f915a02ce9,fix_packages," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'in', ['present', 'latest']) | map(attribute='state') | unique | list }}"""," - ""{{ stig_packages_rhel7 | selectattr('enabled') | selectattr('state', 'equalto', 'present') | map(attribute='state') | unique | list }}""",1,1
openstack%2Fproject-config~master~I0c7542461555f5a23eddf0b3d3e548a734af778e,openstack/project-config,master,I0c7542461555f5a23eddf0b3d3e548a734af778e,New project: go-redfish,MERGED,2019-12-09 23:59:56.000000000,2019-12-27 14:46:59.000000000,2019-12-13 16:54:17.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7321}, {'_account_id': 22348}, {'_account_id': 22477}]","[{'number': 1, 'created': '2019-12-09 23:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5ef80ce3bd4d5e44514a7b6ed9b0dcf2d14f068f', 'message': 'New project: go-redfish\n\nThis new project will host go client library for the Redfish\nhost management API.  It is intended to be consumable/useful\noutside of Airship itself; the Airship team created this library\nonly because of deficiencies in other available implementations.\n\nThe folks that own the github repo from which the extant\nimplementation should be imported have blessed this change, and\nwill continue their work under the Airship umbrella.\n\nPlease add me (Matt McEuen) as an initial member of the new ACL,\nand I can add additional seed core reviewers.\n\nThanks!\n\nChange-Id: I0c7542461555f5a23eddf0b3d3e548a734af778e\n'}, {'number': 2, 'created': '2019-12-11 16:54:42.000000000', 'files': ['gerrit/acls/airship/go-redfish.config', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/04013d4943ac3329cc566373039ca9ff498e9275', 'message': 'New project: go-redfish\n\nThis new project will host go client library for the Redfish\nhost management API.  It is intended to be consumable/useful\noutside of Airship itself; the Airship team created this library\nonly because of deficiencies in other available implementations.\n\nThe folks that own the github repo from which the extant\nimplementation should be imported have blessed this change, and\nwill continue their work under the Airship umbrella.\n\nPlease add me (Matt McEuen) as an initial member of the new ACL,\nand I can add additional seed core reviewers.\n\nThanks!\n\nChange-Id: I0c7542461555f5a23eddf0b3d3e548a734af778e\n'}]",1,698115,04013d4943ac3329cc566373039ca9ff498e9275,11,5,2,22477,,,0,"New project: go-redfish

This new project will host go client library for the Redfish
host management API.  It is intended to be consumable/useful
outside of Airship itself; the Airship team created this library
only because of deficiencies in other available implementations.

The folks that own the github repo from which the extant
implementation should be imported have blessed this change, and
will continue their work under the Airship umbrella.

Please add me (Matt McEuen) as an initial member of the new ACL,
and I can add additional seed core reviewers.

Thanks!

Change-Id: I0c7542461555f5a23eddf0b3d3e548a734af778e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/15/698115/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/airship/go-redfish.config', 'gerrit/projects.yaml']",2,5ef80ce3bd4d5e44514a7b6ed9b0dcf2d14f068f,new-project,- project: airship/go-redfish description: A go client library for the Redfish API upstream: https://github.com/Nordix/go-redfish,,19,0
openstack%2Fzun-ui~master~Ie6896118b226d008402282c914c75014b90ecbb2,openstack/zun-ui,master,Ie6896118b226d008402282c914c75014b90ecbb2,translation: drop babel extractor definitions,MERGED,2019-12-26 17:07:00.000000000,2019-12-27 13:26:21.000000000,2019-12-27 13:25:10.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 17:07:00.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/zun-ui/commit/ed5fff3c587dfca8213fef6c78e36f88152113ec', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: Ie6896118b226d008402282c914c75014b90ecbb2\n'}]",0,700626,ed5fff3c587dfca8213fef6c78e36f88152113ec,7,2,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: Ie6896118b226d008402282c914c75014b90ecbb2
",git fetch https://review.opendev.org/openstack/zun-ui refs/changes/26/700626/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,ed5fff3c587dfca8213fef6c78e36f88152113ec,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fironic~master~I4e8559bd215f70fb895ed0d41b2154c648e03597,openstack/ironic,master,I4e8559bd215f70fb895ed0d41b2154c648e03597,Restrict ability to change owner on provisioned or allocated node,MERGED,2019-12-09 20:19:05.000000000,2019-12-27 11:33:28.000000000,2019-12-27 11:31:52.000000000,"[{'_account_id': 6873}, {'_account_id': 7386}, {'_account_id': 10118}, {'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-09 20:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3f6a2319d74770817af85894047d4ac13a87283e', 'message': ""Restrict ability to change owner on provisioned node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}, {'number': 2, 'created': '2019-12-10 15:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/efc6134fad1a6791d405a64d06eef52ff5d489b1', 'message': ""Restrict ability to change owner on provisioned node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}, {'number': 3, 'created': '2019-12-10 18:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/af5981fd6bc16636d2185ee838a32fe55873fcef', 'message': ""Restrict ability to change owner on provisioned node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}, {'number': 4, 'created': '2019-12-11 18:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3675b776ed15a76f409254c803a2bb02675a97b', 'message': ""Restrict ability to change owner on provisioned node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}, {'number': 5, 'created': '2019-12-12 17:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c8b1da9d840565fa8f180407a023f6a046d5bd5', 'message': ""Restrict ability to change owner on provisioned node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}, {'number': 6, 'created': '2019-12-13 21:06:40.000000000', 'files': ['ironic/tests/unit/api/controllers/v1/test_utils.py', 'releasenotes/notes/node-owner-provision-fix-ee2348b5922f7648.yaml', 'ironic/api/controllers/v1/utils.py', 'ironic/common/policy.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f22ab44888e4b9fd549a5da8e907f4b8fa01faed', 'message': ""Restrict ability to change owner on provisioned or allocated node\n\nPrevents a user from changing the owner of a provisioned node unless\nthey pass the new policy rule 'baremetal:node:update_owner_provisioned'.\nIn addition, always prevents a user from changing the owner of an\nallocated node, if the allocation specifies an owner.\n\nStory: 2006997\nTask: 37766\nChange-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597\n""}]",25,698078,f22ab44888e4b9fd549a5da8e907f4b8fa01faed,54,10,6,7386,,,0,"Restrict ability to change owner on provisioned or allocated node

Prevents a user from changing the owner of a provisioned node unless
they pass the new policy rule 'baremetal:node:update_owner_provisioned'.
In addition, always prevents a user from changing the owner of an
allocated node, if the allocation specifies an owner.

Story: 2006997
Task: 37766
Change-Id: I4e8559bd215f70fb895ed0d41b2154c648e03597
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/698078/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/controllers/v1/test_utils.py', 'ironic/api/controllers/v1/utils.py', 'ironic/common/policy.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/api/controllers/v1/node.py']",5,3f6a2319d74770817af85894047d4ac13a87283e,node-owner-provision-fix," elif (rpc_node.provision_state == ir_states.ACTIVE and api_utils.get_patch_values(patch, '/owner')): try: api_utils.check_node_policy_and_retrieve( 'baremetal:node:update_owner_provisioned', node_ident, node=rpc_node) except exception.HTTPForbidden: msg = _('Cannot update owner of node ""%(node)s"" while it is ' 'in state ""%(state)s"".') % {'node': rpc_node.uuid, 'state': ir_states.ACTIVE} raise wsme.exc.ClientSideError( msg, status_code=http_client.CONFLICT)",,89,11
openstack%2Fpython-manilaclient~master~I4122887422056aa7d4f453c17cf7133f4f8ecbc9,openstack/python-manilaclient,master,I4122887422056aa7d4f453c17cf7133f4f8ecbc9,Implements OSC share type commands In this patch we add openstack commands for: share type create share type delete share type set share type unset share type list share type show share type access create share type access list share type access delete,ABANDONED,2019-12-23 16:31:54.000000000,2019-12-27 11:07:50.000000000,,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 31213}]","[{'number': 1, 'created': '2019-12-23 16:31:54.000000000', 'files': ['manilaclient/osc/v2/share_types.py', 'setup.cfg', 'manilaclient/osc/v2/share_type_access.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/cb207235ac43ec4fe5cc20eba0a6d99f66b21edd', 'message': 'Implements OSC share type commands\nIn this patch we add openstack commands for:\nshare type create\nshare type delete\nshare type set\nshare type unset\nshare type list\nshare type show\nshare type access create\nshare type access list\nshare type access delete\n\nChange-Id: I4122887422056aa7d4f453c17cf7133f4f8ecbc9\nPartially-implements: bp openstack-client-support\n'}]",0,700437,cb207235ac43ec4fe5cc20eba0a6d99f66b21edd,4,3,1,31213,,,0,"Implements OSC share type commands
In this patch we add openstack commands for:
share type create
share type delete
share type set
share type unset
share type list
share type show
share type access create
share type access list
share type access delete

Change-Id: I4122887422056aa7d4f453c17cf7133f4f8ecbc9
Partially-implements: bp openstack-client-support
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/37/700437/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/osc/v2/share_types.py', 'setup.cfg', 'manilaclient/osc/v2/share_type_access.py']",3,cb207235ac43ec4fe5cc20eba0a6d99f66b21edd,pb/openstack-client-support,"# Copyright 2019 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging from osc_lib.command import command from osc_lib import utils as oscutils from manilaclient.common._i18n import _ from manilaclient.common.apiclient import utils as apiutils LOG = logging.getLogger(__name__) class CreateShareTypeAccess(command.Command): """"""Add access for share type."""""" _description = _(""Add access for share type"") def get_parser(self, prog_name): parser = super(CreateShareTypeAccess, self).get_parser(prog_name) parser.add_argument( 'share_type', metavar=""<share_type>"", help=_(""Share type name or ID to add access to"") ) parser.add_argument( 'project_id', metavar=""<project_id>"", help=_(""Project ID to add share type access for"") ) return parser def take_action(self, parsed_args): share_client = self.app.client_manager.share share_type = apiutils.find_resource( share_client.share_types, parsed_args.share_type) try: share_client.share_type_access.add_project_access( share_type, parsed_args.project_id) except Exception as e: LOG.error(_(""Failed to add access to share type : %s""), e) class ListShareTypeAccess(command.Lister): """"""Get access list for share type."""""" _description = _(""Get access list for share type"") def get_parser(self, prog_name): parser = super(ListShareTypeAccess, self).get_parser(prog_name) parser.add_argument( 'share_type', metavar=""<share_type>"", help=_(""Share type name or ID to get access list for"") ) return parser def take_action(self, parsed_args): share_client = self.app.client_manager.share share_type = apiutils.find_resource( share_client.share_types, parsed_args.share_type) data = share_client.share_type_access.list(share_type) columns = ['Project_ID'] values = (oscutils.get_item_properties(s, columns) for s in data) return (columns, values) class DeleteShareTypeAccess(command.Command): """"""Delete access from share type."""""" _description = _(""Delete access from share type"") def get_parser(self, prog_name): parser = super(DeleteShareTypeAccess, self).get_parser(prog_name) parser.add_argument( 'share_type', metavar=""<share_type>"", help=_(""Share type name or ID to delete access from"") ) parser.add_argument( 'project_id', metavar=""<project_id>"", help=_(""Project ID to delete share type access for"") ) return parser def take_action(self, parsed_args): share_client = self.app.client_manager.share share_type = apiutils.find_resource( share_client.share_types, parsed_args.share_type) try: share_client.share_type_access.remove_project_access( share_type, parsed_args.project_id) except Exception as e: LOG.error(_(""Failed to remove access from share type : %s""), e) ",,476,0
openstack%2Fkolla-ansible~master~I42e46c06c172b355b0236368fd9a9af0c4b4cae7,openstack/kolla-ansible,master,I42e46c06c172b355b0236368fd9a9af0c4b4cae7,Fix pem file,ABANDONED,2019-12-25 11:26:18.000000000,2019-12-27 10:30:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-25 11:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e9c0ebc4b09d285bec218b160116bee6452c11cb', 'message': 'Add cert and fix pem\n\nChange-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7\nSigned-off-by: baiyongjun <baiyongjun@99cloud.net>\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 2, 'created': '2019-12-26 02:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/beb87e52081af834d3fc39e94f26f959a99763c6', 'message': 'Add cert and fix pem\n\nChange-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7\nSigned-off-by: baiyongjun <baiyongjun@99cloud.net>\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 3, 'created': '2019-12-26 02:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3cc4f0d2ec3506f5a25a7f96eb6e46cdf21ecfce', 'message': 'Add cert and fix pem\n\nChange-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 4, 'created': '2019-12-27 10:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ea428bc4ea32190f253fc1f539b616a27da48958', 'message': 'Fix pem file\n\nThe internal.pem generated is just an external certificate\n\nChange-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 5, 'created': '2019-12-27 10:22:43.000000000', 'files': ['ansible/roles/certificates/tasks/generate.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/350648aedb4e26004fc2c8d0c2341dec4ce89256', 'message': 'Fix pem file\n\nThe internal.pem generated is just an external certificate\n\nChange-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}]",0,700569,350648aedb4e26004fc2c8d0c2341dec4ce89256,14,1,5,29344,,,0,"Fix pem file

The internal.pem generated is just an external certificate

Change-Id: I42e46c06c172b355b0236368fd9a9af0c4b4cae7
Signed-off-by: yj.bai <bai.yongjun@99cloud.net>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/69/700569/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/nova-cell/defaults/main.yml', 'ansible/roles/mariadb/templates/galera.cnf.j2', 'ansible/roles/common/defaults/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/certificates/tasks/generate.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml']",8,e9c0ebc4b09d285bec218b160116bee6452c11cb,," - ""/etc/pki:/etc/pki""",,34,2
openstack%2Fsearchlight-ui~master~I91543d809a907121df057dbb2da1d09b606c0311,openstack/searchlight-ui,master,I91543d809a907121df057dbb2da1d09b606c0311,tox: Trivial cleanup,MERGED,2019-12-22 16:13:13.000000000,2019-12-27 09:52:57.000000000,2019-12-27 09:51:29.000000000,"[{'_account_id': 22348}, {'_account_id': 27068}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-12-22 16:13:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/04d5234c9451853aad82ef17328d26eda16f4406', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: I91543d809a907121df057dbb2da1d09b606c0311\n""}]",0,700351,04d5234c9451853aad82ef17328d26eda16f4406,8,3,1,22165,,,0,"tox: Trivial cleanup

move 'basepython' to the top-level 'testenv'

Change-Id: I91543d809a907121df057dbb2da1d09b606c0311
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/51/700351/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,04d5234c9451853aad82ef17328d26eda16f4406,,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,9
openstack%2Ftrove~stable%2Ftrain~I1032ec89c514840206fbac4f072daf634bb8e29d,openstack/trove,stable/train,I1032ec89c514840206fbac4f072daf634bb8e29d,Enable trove-scenario-mariadb-single CI job,MERGED,2019-12-27 01:39:31.000000000,2019-12-27 09:50:54.000000000,2019-12-27 09:48:59.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 01:39:31.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/trove/commit/d5f7f1e6336b87134c8d6be60be48e53db746e77', 'message': 'Enable trove-scenario-mariadb-single CI job\n\nChange-Id: I1032ec89c514840206fbac4f072daf634bb8e29d\n'}]",0,700663,d5f7f1e6336b87134c8d6be60be48e53db746e77,8,2,1,6732,,,0,"Enable trove-scenario-mariadb-single CI job

Change-Id: I1032ec89c514840206fbac4f072daf634bb8e29d
",git fetch https://review.opendev.org/openstack/trove refs/changes/63/700663/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d5f7f1e6336b87134c8d6be60be48e53db746e77,enable-trove-scenario-mariadb-single, - trove-scenario-mariadb-single - trove-scenario-postgresql-single - trove-scenario-postgresql-multi - trove-scenario-redis-single - trove-scenario-redis-multi - trove-tempest-ipv6-only, - trove-scenario-postgresql-single: voting: false - trove-scenario-postgresql-multi: voting: false - trove-scenario-mariadb-single: voting: false - trove-scenario-redis-single: voting: false - trove-scenario-redis-multi: voting: false - trove-tempest-ipv6-only: voting: false - trove-scenario-mongodb-single - trove-scenario-mongodb-multi,6,14
openstack%2Fmanila~master~I09c187360d1585dd29a8625df7f2cd8227f7f280,openstack/manila,master,I09c187360d1585dd29a8625df7f2cd8227f7f280,Add manila-specs link to readme.rst,ABANDONED,2019-08-30 09:13:37.000000000,2019-12-27 09:24:00.000000000,,"[{'_account_id': 6413}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 17130}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-30 09:13:37.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/dcea37cfe7a17f7a53120198b99610032515fe2f', 'message': 'Add manila-specs link to readme.rst\n\nChange-Id: I09c187360d1585dd29a8625df7f2cd8227f7f280\n'}]",2,679401,dcea37cfe7a17f7a53120198b99610032515fe2f,21,11,1,27383,,,0,"Add manila-specs link to readme.rst

Change-Id: I09c187360d1585dd29a8625df7f2cd8227f7f280
",git fetch https://review.opendev.org/openstack/manila refs/changes/01/679401/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,dcea37cfe7a17f7a53120198b99610032515fe2f,manila_specs_link,* Design specifications is tracked at: https://specs.openstack.org/openstack/manila-specs/ ,,4,0
openstack%2Ftrove-tempest-plugin~master~Ibf713328d5495dda5bbadc10592cd11a84834647,openstack/trove-tempest-plugin,master,Ibf713328d5495dda5bbadc10592cd11a84834647,Add instance upgrade API test,MERGED,2019-12-27 00:31:38.000000000,2019-12-27 08:31:11.000000000,2019-12-27 08:28:56.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-27 00:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/1ed5d5230eaf3e36d34a5eed95b867774ce0dfd4', 'message': 'Add instance upgrade API test\n\nChange-Id: Ibf713328d5495dda5bbadc10592cd11a84834647\n'}, {'number': 2, 'created': '2019-12-27 05:31:34.000000000', 'files': ['trove_tempest_plugin/services/client.py', 'trove_tempest_plugin/tests/scenario/base.py', '.zuul.yaml', 'trove_tempest_plugin/tests/api/base.py', 'trove_tempest_plugin/tests/scenario/mysql/__init__.py', 'trove_tempest_plugin/tests/scenario/test_instance_basic.py', 'trove_tempest_plugin/tests/api/test_instance_actions.py'], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/f5a0e84a59422cb08a1a404f73a695ce7ac73470', 'message': 'Add instance upgrade API test\n\nChange-Id: Ibf713328d5495dda5bbadc10592cd11a84834647\n'}]",0,700661,f5a0e84a59422cb08a1a404f73a695ce7ac73470,9,2,2,6732,,,0,"Add instance upgrade API test

Change-Id: Ibf713328d5495dda5bbadc10592cd11a84834647
",git fetch https://review.opendev.org/openstack/trove-tempest-plugin refs/changes/61/700661/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove_tempest_plugin/services/client.py', 'trove_tempest_plugin/tests/scenario/base.py', 'trove_tempest_plugin/tests/api/base.py', 'trove_tempest_plugin/tests/scenario/mysql/__init__.py', 'trove_tempest_plugin/tests/scenario/test_instance_basic.py', 'trove_tempest_plugin/tests/api/test_instance_actions.py']",6,1ed5d5230eaf3e36d34a5eed95b867774ce0dfd4,upgrade-test,"# Copyright 2019 Catalyst Cloud Ltd. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from trove_tempest_plugin.tests.api import base class TestInstanceActionsMySQL(base.TestInstanceActionsBase): datastore = 'mysql' ",,94,5
openstack%2Fswift~stable%2Ftrain~I587275e68083aaed3c04486049b67791b52562b7,openstack/swift,stable/train,I587275e68083aaed3c04486049b67791b52562b7,Fix BadResponseLength error when creating symlink,MERGED,2019-12-04 17:41:47.000000000,2019-12-27 07:49:43.000000000,2019-12-27 07:48:07.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-04 17:41:47.000000000', 'files': ['swift/common/middleware/symlink.py', 'test/unit/common/middleware/test_symlink.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/289181ea3db01982c81ead03402c8070e8c94d17', 'message': 'Fix BadResponseLength error when creating symlink\n\nCloses-Bug: #1854074\n\nChange-Id: I587275e68083aaed3c04486049b67791b52562b7\n(cherry picked from commit a2aaf598520331874c8d49a3230f6d4892fb3207)\n'}]",0,697333,289181ea3db01982c81ead03402c8070e8c94d17,19,3,1,15343,,,0,"Fix BadResponseLength error when creating symlink

Closes-Bug: #1854074

Change-Id: I587275e68083aaed3c04486049b67791b52562b7
(cherry picked from commit a2aaf598520331874c8d49a3230f6d4892fb3207)
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/697333/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/symlink.py', 'test/unit/common/middleware/test_symlink.py']",2,289181ea3db01982c81ead03402c8070e8c94d17,bug/1854074-stable/train," def test_symlink_simple_put_error(self): self.app.register('HEAD', '/v1/a/c1/o', swob.HTTPInternalServerError, {}, 'bad news') req = Request.blank('/v1/a/c/symlink', method='PUT', headers={ 'X-Symlink-Target': 'c1/o', 'X-Symlink-Target-Etag': 'not-tgt-etag', }, body='') status, headers, body = self.call_sym(req) self.assertEqual(status, '500 Internal Error') # this is a PUT response; so if we have a content-length... self.assertGreater(int(dict(headers)['Content-Length']), 0) # ... we better have a body! self.assertIn(b'Internal Error', body) ",,22,5
openstack%2Fmistral~master~If79c778d28b4d67721234e6bb32d4fe6d10e8609,openstack/mistral,master,If79c778d28b4d67721234e6bb32d4fe6d10e8609,[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate,MERGED,2019-09-17 04:38:09.000000000,2019-12-27 07:12:44.000000000,2019-12-27 07:10:39.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-09-17 04:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0a5b367751a92ea1fd263b0153ba72a449bd9b14', 'message': ""[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit Run 'mistral-devstack-tempest-ipv6-only' job in mistral gate.\n\nBecause cyborg-tempest-ipv6-only is non-voting job it is added on check\npipeline only. This is non voting because cyborg-tempest job is not yet\nvoting.\n\nDepends-On: https://review.opendev.org/#/c/682536/\n\nStory: #2005477\nTask: #35905\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: If79c778d28b4d67721234e6bb32d4fe6d10e8609\n""}, {'number': 2, 'created': '2019-12-10 05:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bc216ff2f2e39181ee333d27033bd476b0607634', 'message': ""[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit Run 'mistral-devstack-tempest-ipv6-only' job in mistral gate.\n\nBecause cyborg-tempest-ipv6-only is non-voting job it is added on check\npipeline only. This is non voting because cyborg-tempest job is not yet\nvoting.\n\nDepends-On: https://review.opendev.org/#/c/682536/\n\nStory: #2005477\nTask: #35905\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: If79c778d28b4d67721234e6bb32d4fe6d10e8609\n""}, {'number': 3, 'created': '2019-12-19 14:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5471895c647781efe33f78eb7611eb85e2f95750', 'message': ""[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit Run 'mistral-devstack-tempest-ipv6-only' job in mistral gate.\n\nBecause cyborg-tempest-ipv6-only is non-voting job it is added on check\npipeline only. This is non voting because cyborg-tempest job is not yet\nvoting.\n\nDepends-On: https://review.opendev.org/#/c/682536/\n\nStory: #2005477\nTask: #35905\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: If79c778d28b4d67721234e6bb32d4fe6d10e8609\n""}, {'number': 4, 'created': '2019-12-19 14:46:20.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/8165fb4ca1c806970c917c48cf6107f94a59389d', 'message': ""[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit Run 'mistral-devstack-tempest-ipv6-only' job in mistral gate.\n\nBecause cyborg-tempest-ipv6-only is non-voting job it is added on check\npipeline only. This is non voting because cyborg-tempest job is not yet\nvoting.\n\nDepends-On: https://review.opendev.org/#/c/682536/\nDepends-On: https://review.opendev.org/#/c/699959/\n\nStory: #2005477\nTask: #35905\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: If79c778d28b4d67721234e6bb32d4fe6d10e8609\n""}]",0,682538,8165fb4ca1c806970c917c48cf6107f94a59389d,21,4,4,8556,,,0,"[train][goal] Run 'mistral-devstack-tempest-ipv6-only' job in gate

As part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],
Tempest has defined the base job 'devstack-tempest-ipv6' which will
deploy services on IPv6.

This commit Run 'mistral-devstack-tempest-ipv6-only' job in mistral gate.

Because cyborg-tempest-ipv6-only is non-voting job it is added on check
pipeline only. This is non voting because cyborg-tempest job is not yet
voting.

Depends-On: https://review.opendev.org/#/c/682536/
Depends-On: https://review.opendev.org/#/c/699959/

Story: #2005477
Task: #35905

[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html

Change-Id: If79c778d28b4d67721234e6bb32d4fe6d10e8609
",git fetch https://review.opendev.org/openstack/mistral refs/changes/38/682538/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0a5b367751a92ea1fd263b0153ba72a449bd9b14,ipv6-only-deployment-and-testing, - mistral-devstack-tempest-ipv6-only - mistral-devstack-tempest-ipv6-only,,2,0
openstack%2Fmistral-tempest-plugin~master~Iacd2d9cb5effde9a801010ce3e5f590f47f8831e,openstack/mistral-tempest-plugin,master,Iacd2d9cb5effde9a801010ce3e5f590f47f8831e,[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job,MERGED,2019-09-17 04:35:11.000000000,2019-12-27 05:54:42.000000000,2019-12-27 05:54:42.000000000,"[{'_account_id': 8556}, {'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-09-17 04:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/bfc8557998919aca38117df92e764c41d1ba2fa7', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 2, 'created': '2019-10-29 21:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/2dcbde6f3352e1b789f747a881783b720c7fbb6c', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/681377\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 3, 'created': '2019-12-19 09:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/f14de202c5383e36a3a57b56f377914c248d3ef1', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/681377\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 4, 'created': '2019-12-19 10:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/a9a9893ef438ef1f186edb64671c5c81374c854a', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/681377\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 5, 'created': '2019-12-19 10:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/3dc5a0653f638cab9342bfb1fa951b70e1d7be6b', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/681377\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 6, 'created': '2019-12-23 07:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/13a9a762fbf94bd80f39322ae80720ba096f7af0', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/681377\nDepends-On: https://review.opendev.org/#/c/699959/\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}, {'number': 7, 'created': '2019-12-25 10:33:57.000000000', 'files': ['mistral_tempest_tests/tests/scenario/engine/actions/v2/test_openstack_actions.py', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/4805d2ea5ea464eea1a09650ed829f4c8c12052c', 'message': ""[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job\n\nAs part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],\nTempest has defined the base job 'devstack-tempest-ipv6' which will\ndeploy services on IPv6.\n\nThis commit adds the new job 'mistral-devstack-tempest-ipv6-only'\nrun on gate which is derived from 'devstack-tempest-ipv6'.\n\nVerification structure will be:\n- 'devstack-IPv6' deploy the service on IPv6\n- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address\n- 'mistral-devstack-tempest-ipv6-only' will run the tests.\n- 'mistral-devstack-non-apache-tempest-ipv6-only' will run the tests.\n\nStory: #2005477\nTask: #35905\n\nDepends-On: https://review.opendev.org/#/c/699959/\n\n[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html\n\nChange-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e\n""}]",0,682536,4805d2ea5ea464eea1a09650ed829f4c8c12052c,26,5,7,8556,,,0,"[train][goal] Define new 'mistral-devstack-tempest-ipv6-only' job

As part of Train community goal 'Support IPv6-Only Deployments and Testing'[1],
Tempest has defined the base job 'devstack-tempest-ipv6' which will
deploy services on IPv6.

This commit adds the new job 'mistral-devstack-tempest-ipv6-only'
run on gate which is derived from 'devstack-tempest-ipv6'.

Verification structure will be:
- 'devstack-IPv6' deploy the service on IPv6
- 'devstack-tempest-ipv6' run will verify the IPv6-only setting and listen address
- 'mistral-devstack-tempest-ipv6-only' will run the tests.
- 'mistral-devstack-non-apache-tempest-ipv6-only' will run the tests.

Story: #2005477
Task: #35905

Depends-On: https://review.opendev.org/#/c/699959/

[1] https://governance.openstack.org/tc/goals/train/ipv6-support-and-testing.html

Change-Id: Iacd2d9cb5effde9a801010ce3e5f590f47f8831e
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/36/682536/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,bfc8557998919aca38117df92e764c41d1ba2fa7,ipv6-only-deployment-and-testing, required-projects: &base_required_projects vars: &base_vars name: mistral-devstack-tempest-ipv6-only parent: devstack-tempest-ipv6 description: | Mistral devstack tempest tests job for IPv6-only deployment pre-run: playbooks/tempest/pre.yaml timeout: 9000 required-projects: *base_required_projects vars: *base_vars - job: - mistral-devstack-tempest-ipv6-only - mistral-devstack-tempest-ipv6-only, required-projects: vars:,14,2
openstack%2Fheat~stable%2Fqueens~Id54015b469536176222b417bff8869c79062461d,openstack/heat,stable/queens,Id54015b469536176222b417bff8869c79062461d,[TEST][DMT] Add target branch to queens,ABANDONED,2019-12-27 04:42:37.000000000,2019-12-27 05:52:14.000000000,,[],"[{'number': 1, 'created': '2019-12-27 04:42:37.000000000', 'files': ['playbooks/devstack/functional/run.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/09c01f902961af85abd79e2b9473794fc6cc36d4', 'message': '[TEST][DMT] Add target branch to queens\n\nChange-Id: Id54015b469536176222b417bff8869c79062461d\n'}]",0,700673,09c01f902961af85abd79e2b9473794fc6cc36d4,2,0,1,12404,,,0,"[TEST][DMT] Add target branch to queens

Change-Id: Id54015b469536176222b417bff8869c79062461d
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/700673/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/devstack/functional/run.yaml'],1,09c01f902961af85abd79e2b9473794fc6cc36d4,, export TARGET_BRANCH=stable/queens,,1,0
openstack%2Fheat-tempest-plugin~master~Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538,openstack/heat-tempest-plugin,master,Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538,[TEST][WIP] add devstack localrc TARGET_BRANCH,ABANDONED,2019-12-27 03:25:21.000000000,2019-12-27 05:52:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-27 03:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/033d7bb5cc426073730a9347d3320fdf13a08efb', 'message': '[TEST][WIP] add devstack localrc TARGET_BRANCH\n\nChange-Id: Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538\n'}, {'number': 2, 'created': '2019-12-27 04:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/e4b040c048056e374dc79be1bb5faac09ac8210d', 'message': '[TEST][WIP] add devstack localrc TARGET_BRANCH\n\nDepends-On: https://review.opendev.org/700673\nChange-Id: Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538\n'}, {'number': 3, 'created': '2019-12-27 05:45:02.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/06ae96e578ae02196dd678e9dd5e356ae724f673', 'message': '[TEST][WIP] add devstack localrc TARGET_BRANCH\n\nDepends-On: https://review.opendev.org/700673\nChange-Id: Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538\n'}]",0,700672,06ae96e578ae02196dd678e9dd5e356ae724f673,7,1,3,12404,,,0,"[TEST][WIP] add devstack localrc TARGET_BRANCH

Depends-On: https://review.opendev.org/700673
Change-Id: Ie223455164a5aa0b410bc7a7fb4c3d915ab6d538
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/72/700672/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,033d7bb5cc426073730a9347d3320fdf13a08efb,story/2007054, vars: devstack_localrc: TARGET_BRANCH: stable/queens branch_override: stable/queens, - heat-functional-orig-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2-non-apache - heat-functional-convg-mysql-lbaasv2-py35 - heat-functional-convg-queens-py35 - heat-functional-orig-queens - heat-functional-convg-rocky - heat-functional-convg-rocky-py35 - heat-functional-orig-rocky,4,9
openstack%2Fswift~stable%2Ftrain~Ifb15ce50fc3bcfda9532a2c3dec542c272ea4933,openstack/swift,stable/train,Ifb15ce50fc3bcfda9532a2c3dec542c272ea4933,py3: Fix s3api header casing,MERGED,2019-12-04 23:10:45.000000000,2019-12-27 05:42:10.000000000,2019-12-27 05:40:25.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-04 23:10:45.000000000', 'files': ['swift/common/middleware/s3api/s3response.py', 'test/unit/common/middleware/s3api/test_s3response.py', 'swift/common/header_key_dict.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f98396e6a2e3f87983fa4ba49bfbd19bd4e9607f', 'message': 'py3: Fix s3api header casing\n\nCloses-Bug: #1853367\n\nChange-Id: Ifb15ce50fc3bcfda9532a2c3dec542c272ea4933\n(cherry picked from commit b5c9dc1c9f68afe8083b74eaf8080e17a9ef8f8b)\n'}]",0,697384,f98396e6a2e3f87983fa4ba49bfbd19bd4e9607f,7,2,1,15343,,,0,"py3: Fix s3api header casing

Closes-Bug: #1853367

Change-Id: Ifb15ce50fc3bcfda9532a2c3dec542c272ea4933
(cherry picked from commit b5c9dc1c9f68afe8083b74eaf8080e17a9ef8f8b)
",git fetch https://review.opendev.org/openstack/swift refs/changes/84/697384/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3response.py', 'test/unit/common/middleware/s3api/test_s3response.py', 'swift/common/header_key_dict.py']",3,f98396e6a2e3f87983fa4ba49bfbd19bd4e9607f,695053-stable/train," @staticmethod def _title(s): if six.PY2: return s.title() else: return s.encode('latin1').title().decode('latin1') self[self._title(key)] = other[key] self[self._title(key)] = value return dict.get(self, self._title(key)) key = self._title(key) if value is None: self.pop(key, None) elif six.PY2 and isinstance(value, six.text_type): return dict.__setitem__(self, key, value.encode('utf-8')) elif six.PY3 and isinstance(value, six.binary_type): return dict.__setitem__(self, key, value.decode('latin-1')) else: return dict.__setitem__(self, key, str(value)) return dict.__contains__(self, self._title(key)) return dict.__delitem__(self, self._title(key)) return dict.get(self, self._title(key), default) return dict.pop(self, self._title(key), default)","def _title(s): if six.PY2: return s.title() else: return s.encode('latin1').title().decode('latin1') self[_title(key)] = other[key] self[_title(key)] = value return dict.get(self, _title(key)) if value is None: self.pop(_title(key), None) elif six.PY2 and isinstance(value, six.text_type): return dict.__setitem__(self, _title(key), value.encode('utf-8')) elif six.PY3 and isinstance(value, six.binary_type): return dict.__setitem__(self, _title(key), value.decode('latin-1')) else: return dict.__setitem__(self, _title(key), str(value)) return dict.__contains__(self, _title(key)) return dict.__delitem__(self, _title(key)) return dict.get(self, _title(key), default) return dict.pop(self, _title(key), default)",49,50
openstack%2Fheat-tempest-plugin~master~I8c938bf7484eb02175dd821493ca27ff155d2dec,openstack/heat-tempest-plugin,master,I8c938bf7484eb02175dd821493ca27ff155d2dec,[DMT][TEST]Update test jobs for Ussuri,ABANDONED,2019-12-27 04:53:39.000000000,2019-12-27 05:29:30.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-27 04:53:39.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/d60bb2b1205ae306d13ed57fd11b9444da8403d2', 'message': '[DMT][TEST]Update test jobs for Ussuri\n\nChange-Id: I8c938bf7484eb02175dd821493ca27ff155d2dec\n'}]",0,700674,d60bb2b1205ae306d13ed57fd11b9444da8403d2,3,1,1,12404,,,0,"[DMT][TEST]Update test jobs for Ussuri

Change-Id: I8c938bf7484eb02175dd821493ca27ff155d2dec
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/74/700674/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d60bb2b1205ae306d13ed57fd11b9444da8403d2,story/2007054, - heat-functional - heat-functional-legacy - heat-functional - heat-functional-legacy, - heat-functional-orig-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2-non-apache - heat-functional-convg-mysql-lbaasv2-py35 - heat-functional-orig-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2 - heat-functional-convg-mysql-lbaasv2-py35,4,7
openstack%2Foctavia-tempest-plugin~master~Id055763f35b487da539eddfe802c543a11246503,openstack/octavia-tempest-plugin,master,Id055763f35b487da539eddfe802c543a11246503,Run tests with algorithm supported by provider driver,MERGED,2019-07-23 11:08:16.000000000,2019-12-27 05:21:45.000000000,2019-12-27 05:20:21.000000000,"[{'_account_id': 1131}, {'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}, {'_account_id': 29244}]","[{'number': 1, 'created': '2019-07-23 11:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/afe00259d6681363c90b3a717974ac768e87ab69', 'message': 'Add option to reuse connections and skip spread validation for OVN\n\nWhile using request.session TCP connections are\nreused. OVN provider driver Load Balancing algorithm\nuses tuple source_port_address and source_ip_address while\ncreating the hash and it is not yet decided if the algorithm\nshould be called SOURCE_IP or SOURCE_PORT_ADDRESS or ROUND_ROBIN [1].\nFor now lets add an option to do not reuse the same connection.\n\nOVN LB Algorithm is not truly ROUND_ROBIN, so requests are not\nspread equally across active members. Lets disable the spread\nvalidation for OVN.\n\n[1] https://review.opendev.org/#/c/660369\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 2, 'created': '2019-07-24 10:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/c2b6664b4ff6f0a0dc90b0a715485cc15217b158', 'message': 'Add an option to reuse connections and specify used algorithm for tests\n\nWhile using requests.session TCP connections are\nreused. OVN Load Balancing algorithm uses hash with source port\nto route clients requests. In that terms if connection is reused\nthe load is not spread across members. This patch adds an option\nto disable reusing connections.\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 3, 'created': '2019-07-26 13:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/f89676f42f96b958e3697d3196d0db12d6b33544', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 4, 'created': '2019-07-29 11:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/91f40012139322905c673edf960c449f9fb81679', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 5, 'created': '2019-08-05 08:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/4ad64f4d8b82546328d1cf97190eda0e16e8298f', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 6, 'created': '2019-08-06 08:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/2d1edef09fe04f2392e8f44f95ba42cc91716f8f', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 7, 'created': '2019-09-27 10:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/cace89a4d38273b85e5d6061ed9c7f953569fc7c', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 8, 'created': '2019-10-03 07:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/c16e4cfeeaf04cd695c82cfaf4ec79ef9606b05d', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 9, 'created': '2019-10-10 14:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/aec9b555b89c77f8e58bf82e9d1fcca172957867', 'message': 'Specify used algorithm for tests\n\nOVN LB Algorithm is SOURCE_IP_PORT type of algorithm, so members\nhave not the same number of served requests. This patch introduce\npossibility to specify against which protocol tempest is run.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 10, 'created': '2019-12-03 11:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/483220817f3e8ee4cdbf30176f9669031f0f93fc', 'message': 'Discover used LB algorithm used for test\n\nThis patch introduce simple supported algorithm\ndiscover mechanism that uses first supported\nalgorithm within provider driver to be used a\ndefault.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 11, 'created': '2019-12-03 11:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/bd824596e8eb1f77398018749d64dbcceb19e72d', 'message': 'Discover LB algorithm used for test\n\nThis patch introduce simple supported algorithm\ndiscover mechanism that uses first supported\nalgorithm within provider driver to be used a\ndefault.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 12, 'created': '2019-12-04 08:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/6065d24a7295f3f2196ec26dc36cc2f8cc1604ca', 'message': 'Discover LB algorithm used for test\n\nThis patch introduce simple supported algorithm\ndiscover mechanism that uses first supported\nalgorithm within provider driver to be used a\ndefault.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 13, 'created': '2019-12-04 12:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/371cf81c62653cbd15a5db11d7297939e4574288', 'message': 'Discover LB algorithm used for test\n\nThis patch introduce simple supported algorithm\ndiscover mechanism that uses first supported\nalgorithm within provider driver to be used a\ndefault.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 14, 'created': '2019-12-05 15:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/257442bc2bd3bb7ecb13daf3bf78b1e68902bd4b', 'message': 'Discover LB algorithm used for test\n\nThis patch introduce simple supported algorithm\ndiscover mechanism that uses first supported\nalgorithm within provider driver to be used a\ndefault.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 15, 'created': '2019-12-09 15:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/2a1e7b53401fde329016d9271acd9e643578e47e', 'message': 'Run tests with algorithm supported by provider driver\n\nThis patch adds map of supported algorithms by\nprovider drivers. For a first iteration lets select\nthe first from supported algorithms to be used as\na default and run the tests with it.\n\nIn addition this patch splits check_members_balanced()\ninto subfunctions related to the algorithm\nthat is validated.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}, {'number': 16, 'created': '2019-12-10 10:21:36.000000000', 'files': ['octavia_tempest_plugin/tests/scenario/v2/test_healthmonitor.py', 'octavia_tempest_plugin/tests/scenario/v2/test_pool.py', 'octavia_tempest_plugin/tests/test_base.py', 'octavia_tempest_plugin/tests/scenario/v2/test_listener.py', 'octavia_tempest_plugin/tests/api/v2/test_member.py', 'octavia_tempest_plugin/tests/api/v2/test_pool.py', 'octavia_tempest_plugin/tests/spare_pool_scenario/v2/test_spare_pool.py', 'octavia_tempest_plugin/tests/api/v2/test_l7rule.py', 'octavia_tempest_plugin/tests/act_stdby_scenario/v2/test_active_standby_iptables.py', 'octavia_tempest_plugin/tests/scenario/v2/test_ipv6_traffic_ops.py', 'octavia_tempest_plugin/tests/scenario/v2/test_traffic_ops.py', 'octavia_tempest_plugin/tests/api/v2/test_l7policy.py', 'octavia_tempest_plugin/common/constants.py', 'octavia_tempest_plugin/tests/scenario/v2/test_member.py', 'octavia_tempest_plugin/tests/api/v2/test_healthmonitor.py', 'octavia_tempest_plugin/tests/scenario/v2/test_l7policy.py', 'octavia_tempest_plugin/tests/barbican_scenario/v2/test_tls_barbican.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/b6df5f8143c7e0831c49e9ae4344de4f11a6e227', 'message': 'Run tests with algorithm supported by provider driver\n\nThis patch adds map of supported algorithms by\nprovider drivers. For a first iteration lets select\nthe first from supported algorithms to be used as\na default and run the tests with it.\n\nIn addition this patch splits check_members_balanced()\ninto subfunctions related to the algorithm\nthat is validated.\n\nStory: 2006264\nTask: 35972\n\nChange-Id: Id055763f35b487da539eddfe802c543a11246503\n'}]",18,672264,b6df5f8143c7e0831c49e9ae4344de4f11a6e227,105,9,16,24791,,,0,"Run tests with algorithm supported by provider driver

This patch adds map of supported algorithms by
provider drivers. For a first iteration lets select
the first from supported algorithms to be used as
a default and run the tests with it.

In addition this patch splits check_members_balanced()
into subfunctions related to the algorithm
that is validated.

Story: 2006264
Task: 35972

Change-Id: Id055763f35b487da539eddfe802c543a11246503
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/64/672264/16 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_tempest_plugin/config.py', 'octavia_tempest_plugin/tests/test_base.py']",2,afe00259d6681363c90b3a717974ac768e87ab69,source_ip_port_octavia_ovn," handler = requests if CONF.load_balancer.test_reuse_connection: handler = requests.Session() r = handler.get('{0}://{1}'.format(protocol, vip_address), if CONF.load_balancer.provider != 'ovn': self.assertEqual(1, len(set(response_counts.values())))"," session = requests.Session() r = session.get('{0}://{1}'.format(protocol, vip_address), self.assertEqual(1, len(set(response_counts.values())))",9,3
openstack%2Fbifrost~master~I64bdbcc7b253f035abdbfb10f7f877d14d73857a,openstack/bifrost,master,I64bdbcc7b253f035abdbfb10f7f877d14d73857a,Add librsvg2* to bindep,NEW,2019-12-24 08:24:16.000000000,2019-12-27 05:00:14.000000000,,"[{'_account_id': 10206}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 08:24:16.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/29d392b66fa4c4522e1af737881b8b85e020eef6', 'message': 'Add librsvg2* to bindep\n\n0bc77a53c08f24b97324e1e3628fa043c7735af2 added the docs\nbuild requirement on sphinxcontrib-svg2pdfconverter which\nneeds the native rsvg-convert command. This change adds\nthe native package that provides that command to bindep.txt.\n\nChange-Id: I64bdbcc7b253f035abdbfb10f7f877d14d73857a\n'}]",0,700497,29d392b66fa4c4522e1af737881b8b85e020eef6,4,2,1,10206,,,0,"Add librsvg2* to bindep

0bc77a53c08f24b97324e1e3628fa043c7735af2 added the docs
build requirement on sphinxcontrib-svg2pdfconverter which
needs the native rsvg-convert command. This change adds
the native package that provides that command to bindep.txt.

Change-Id: I64bdbcc7b253f035abdbfb10f7f877d14d73857a
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/97/700497/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,29d392b66fa4c4522e1af737881b8b85e020eef6,fix_doc_generation, # libsrvg2 is needed for sphinxcontrib-svg2pdfconverter in docs builds. librsvg2-tools [doc platform:rpm] librsvg2-bin [doc platform:dpkg],,4,0
openstack%2Ftrove~stable%2Ftrain~Ifee8620a41e439b028e0a4d65164a75a100ce4d9,openstack/trove,stable/train,Ifee8620a41e439b028e0a4d65164a75a100ce4d9,Fix unmount path for instance upgrade,MERGED,2019-12-26 22:51:56.000000000,2019-12-27 04:11:18.000000000,2019-12-27 04:10:03.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 22:51:56.000000000', 'files': ['trove/guestagent/datastore/mysql_common/manager.py', 'doc/source/user/upgrade-datastore.rst', 'trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/b217577894533dbbe6a5b2339b6720030f311d01', 'message': 'Fix unmount path for instance upgrade\n\nChange-Id: Ifee8620a41e439b028e0a4d65164a75a100ce4d9\n(cherry picked from commit 35f989a8701bd675f5ec3bafe161897fc23dfd90)\n'}]",0,700657,b217577894533dbbe6a5b2339b6720030f311d01,7,2,1,6732,,,0,"Fix unmount path for instance upgrade

Change-Id: Ifee8620a41e439b028e0a4d65164a75a100ce4d9
(cherry picked from commit 35f989a8701bd675f5ec3bafe161897fc23dfd90)
",git fetch https://review.opendev.org/openstack/trove refs/changes/57/700657/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/datastore/mysql_common/manager.py', 'doc/source/user/upgrade-datastore.rst', 'trove/taskmanager/models.py']",3,b217577894533dbbe6a5b2339b6720030f311d01,," LOG.info(""Upgrading instance %s to new datastore version %s"", self.id, datastore_version) sleep_time=5, time_out=600) LOG.info('Finished rebuilding server for instance %s', self.id) LOG.info(""Finished upgrading instance %s to new datastore "" ""version %s"", self.id, datastore_version)"," LOG.debug(""Upgrading instance %s to new datastore version %s"", self, datastore_version) sleep_time=2, time_out=600)",49,39
openstack%2Fnova~master~I6d43cbe6dd32e17eda99a72699953b83b4e556bb,openstack/nova,master,I6d43cbe6dd32e17eda99a72699953b83b4e556bb,Introduce scope_types in Admin Actions,MERGED,2019-05-08 14:32:12.000000000,2019-12-27 03:21:26.000000000,2019-12-26 06:48:34.000000000,"[{'_account_id': 782}, {'_account_id': 5046}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-05-08 14:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/985145957dd6453316ebe967429769cbb57149ec', 'message': 'WIP: add scope check, see tests catch the change\n\nTODO: need test with optional scope enforement\n\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n'}, {'number': 2, 'created': '2019-06-03 16:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b3c027fe09b589a88a11b97f172f06a3dafc6df', 'message': 'WIP: add scope check, see tests catch the change\n\nTODO: need test with optional scope enforement\n\nblueprint policy-defaults-refresh\n\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n'}, {'number': 3, 'created': '2019-06-04 16:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d4a8bfcf5c6e84bc94226de0bac162c72c9d24b', 'message': 'WIP: add scope check, see tests catch the change\n\nTODO: need test with optional scope enforement\n\ncurrently unable to pass the scope tests correctly\n\nblueprint policy-defaults-refresh\n\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n'}, {'number': 4, 'created': '2019-06-04 17:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1f0ff799f9a9e044d28765190e3a91341ff1aa5', 'message': 'WIP: add scope check, see tests catch the change\n\nTODO: need test with optional scope enforement\n\nblueprint policy-defaults-refresh\n\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n'}, {'number': 5, 'created': '2019-06-05 15:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ceb8e1faca99b774b5fc07fcd92a03b922dceddf', 'message': 'WIP: add scope check, see tests catch the change\n\nTODO: need test with optional scope enforement\n\nblueprint policy-defaults-refresh\n\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n'}, {'number': 6, 'created': '2019-08-15 10:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/254ebc932d24c88a8936380c0b1fb16e1099fa77', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nThere are two type of scope:\n1. 'system': policy with 'system' scope means user with\n'system-scoped' token have permission to access otherwise not.\nThis scope type can be applied to API policies which need\naccess permission at system level.\n\n2. 'project': policy with 'project' scope means user with\n'project-scoped' token have permission to access.\nThis scope type can be applied to API policies which need\naccess permission at project level.\n\nAny policy need permission for both scope 'system' and 'project'\ncan be added with both scope, for example: scope_type['system', 'project']\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}, {'number': 7, 'created': '2019-08-15 11:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b68d490ca2a4a19fbbc640673b96a6632dedb2d', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nThere are two type of scope:\n1. 'system': policy with 'system' scope means user with\n'system-scoped' token have permission to access otherwise not.\nThis scope type can be applied to API policies which need\naccess permission at system level.\n\n2. 'project': policy with 'project' scope means user with\n'project-scoped' token have permission to access.\nThis scope type can be applied to API policies which need\naccess permission at project level.\n\nAny policy need permission for both scope 'system' and 'project'\ncan be added with both scope, for example: scope_type['system', 'project']\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}, {'number': 8, 'created': '2019-08-15 12:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/994485ed1217a499695641b27ade5fea2d635b60', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nThere are two type of scope:\n1. 'system': policy with 'system' scope means user with\n'system-scoped' token have permission to access otherwise not.\nThis scope type can be applied to API policies which need\naccess permission at system level.\n\n2. 'project': policy with 'project' scope means user with\n'project-scoped' token have permission to access.\nThis scope type can be applied to API policies which need\naccess permission at project level.\n\nAny policy need permission for both scope 'system' and 'project'\ncan be added with both scope, for example: scope_type['system', 'project']\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}, {'number': 9, 'created': '2019-10-29 20:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c91311d5fdeb180d8511426b625616905512efdb', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nThere are two type of scope:\n1. 'system': policy with 'system' scope means user with\n'system-scoped' token have permission to access otherwise not.\nThis scope type can be applied to API policies which need\naccess permission at system level.\n\n2. 'project': policy with 'project' scope means user with\n'project-scoped' token have permission to access.\nThis scope type can be applied to API policies which need\naccess permission at project level.\n\nAny policy need permission for both scope 'system' and 'project'\ncan be added with both scope, for example: scope_type['system', 'project']\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}, {'number': 10, 'created': '2019-10-29 20:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a38dd8e36128436304a9953d09648d72051e32c8', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nThere are two type of scope:\n1. 'system': policy with 'system' scope means user with\n'system-scoped' token have permission to access otherwise not.\nThis scope type can be applied to API policies which need\naccess permission at system level.\n\n2. 'project': policy with 'project' scope means user with\n'project-scoped' token have permission to access.\nThis scope type can be applied to API policies which need\naccess permission at project level.\n\nAny policy need permission for both scope 'system' and 'project'\ncan be added with both scope, for example: scope_type['system', 'project']\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}, {'number': 11, 'created': '2019-12-04 19:35:02.000000000', 'files': ['nova/tests/unit/policies/test_admin_actions.py', 'nova/policies/admin_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dfaf229e0050ee65ccf31ec8aefc81b2b4226aea', 'message': ""Introduce scope_types in Admin Actions\n\noslo.policy introduced the scope_type feature which can\ncontrol the access level at system-level and project-level.\n - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope\n - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html\n\nAppropriate scope_type for nova case:\n- https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#scope\n\nThis commit introduce scope_type for Admin Actions API policies.\n\nAll the Admin Actions policy are scopped as 'system' because\nnova services operation should not be given access to\nproject scopped token.\n\nAlso adds the test case with scope_type enabled and verify we\npass and fail the policy check with expected context.\n\nPartial implement blueprint policy-defaults-refresh\nChange-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb\n""}]",7,657823,dfaf229e0050ee65ccf31ec8aefc81b2b4226aea,134,19,11,782,,,0,"Introduce scope_types in Admin Actions

oslo.policy introduced the scope_type feature which can
control the access level at system-level and project-level.
 - https://docs.openstack.org/oslo.policy/latest/user/usage.html#setting-scope
 - http://specs.openstack.org/openstack/keystone-specs/specs/keystone/queens/system-scope.html

Appropriate scope_type for nova case:
- https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#scope

This commit introduce scope_type for Admin Actions API policies.

All the Admin Actions policy are scopped as 'system' because
nova services operation should not be given access to
project scopped token.

Also adds the test case with scope_type enabled and verify we
pass and fail the policy check with expected context.

Partial implement blueprint policy-defaults-refresh
Change-Id: I6d43cbe6dd32e17eda99a72699953b83b4e556bb
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/657823/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/policies/admin_actions.py', 'nova/tests/unit/api/openstack/compute/test_admin_actions.py']",2,985145957dd6453316ebe967429769cbb57149ec,bp/policy-defaults-refresh," # TODO this now fails due to adding the system_scope check ensure_raises(req) #func(req, *arg, **kwarg)"," func(req, *arg, **kwarg)",7,4
openstack%2Fsearchlight-ui~master~I2cf6846440302c60bc717db50c34a4ca9122899e,openstack/searchlight-ui,master,I2cf6846440302c60bc717db50c34a4ca9122899e,Imported Translations from Zanata,MERGED,2019-12-22 09:38:27.000000000,2019-12-27 03:15:47.000000000,2019-12-27 03:13:23.000000000,"[{'_account_id': 22348}, {'_account_id': 27068}]","[{'number': 1, 'created': '2019-12-22 09:38:27.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/8bfe3f50bbdb1691a5285140226ec687501975c4', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I2cf6846440302c60bc717db50c34a4ca9122899e\n'}]",0,700329,8bfe3f50bbdb1691a5285140226ec687501975c4,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I2cf6846440302c60bc717db50c34a4ca9122899e
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/29/700329/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,8bfe3f50bbdb1691a5285140226ec687501975c4,zanata/translations,"""POT-Creation-Date: 2019-11-25 16:44+0000\n""""PO-Revision-Date: 2019-12-21 02:51+0000\n""msgid ""7.0.0-9"" msgstr ""7.0.0-9""","""POT-Creation-Date: 2019-10-28 06:34+0000\n""""PO-Revision-Date: 2019-11-14 11:30+0000\n""msgid ""7.0.0-6"" msgstr ""7.0.0-6""",4,4
openstack%2Fsearchlight-ui~master~I5eb8b97475e1e277426a112f33212f78bb2295c6,openstack/searchlight-ui,master,I5eb8b97475e1e277426a112f33212f78bb2295c6,translation: drop babel extractor definitions,MERGED,2019-12-26 17:27:23.000000000,2019-12-27 03:14:37.000000000,2019-12-27 03:13:23.000000000,"[{'_account_id': 22348}, {'_account_id': 27068}]","[{'number': 1, 'created': '2019-12-26 17:27:23.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/a249a0e2cd7d4b3dad2b8310e54d7330e75d325a', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I5eb8b97475e1e277426a112f33212f78bb2295c6\n'}]",0,700645,a249a0e2cd7d4b3dad2b8310e54d7330e75d325a,7,2,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I5eb8b97475e1e277426a112f33212f78bb2295c6
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/45/700645/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,a249a0e2cd7d4b3dad2b8310e54d7330e75d325a,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # .../dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fsolum-dashboard~master~I3317fff56f55752d1df13f266877755cada1ebe1,openstack/solum-dashboard,master,I3317fff56f55752d1df13f266877755cada1ebe1,translation: drop babel extractor definitions,MERGED,2019-12-26 17:29:24.000000000,2019-12-27 01:45:51.000000000,2019-12-27 01:45:51.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 17:29:24.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/89627485976a0cda11454c40068b3b58fa71e2c0', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I3317fff56f55752d1df13f266877755cada1ebe1\n'}]",0,700647,89627485976a0cda11454c40068b3b58fa71e2c0,6,2,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I3317fff56f55752d1df13f266877755cada1ebe1
",git fetch https://review.opendev.org/openstack/solum-dashboard refs/changes/47/700647/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,89627485976a0cda11454c40068b3b58fa71e2c0,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Fmurano-dashboard~master~I0c3efb65e75e62212b9c5fc0cd759271111b5956,openstack/murano-dashboard,master,I0c3efb65e75e62212b9c5fc0cd759271111b5956,translation: drop babel extractor definitions,MERGED,2019-12-26 17:19:58.000000000,2019-12-27 01:42:36.000000000,2019-12-27 01:42:36.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 17:19:58.000000000', 'files': ['babel-django.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/10a8a5695a27c91ebe7966876582934cf0cbea88', 'message': 'translation: drop babel extractor definitions\n\nbabel extractors are now registered via python entry points,\nso there is no need to declare babel extractors in babel configs.\n\nThis change is important to make translation work in Django 2.2.\ndjango-babel does not work with Django 2.2 and looks unmaintained\nfor over two years. The horizon team is thinking to switch the extractor\nto enmerkar (a fork of django-babel) to make extraction of translation\nstring work again near future. It is important to drop the extractor\ndefinition to make the transition smooth.\n\nChange-Id: I0c3efb65e75e62212b9c5fc0cd759271111b5956\n'}]",0,700638,10a8a5695a27c91ebe7966876582934cf0cbea88,6,2,1,841,,,0,"translation: drop babel extractor definitions

babel extractors are now registered via python entry points,
so there is no need to declare babel extractors in babel configs.

This change is important to make translation work in Django 2.2.
django-babel does not work with Django 2.2 and looks unmaintained
for over two years. The horizon team is thinking to switch the extractor
to enmerkar (a fork of django-babel) to make extraction of translation
string work again near future. It is important to drop the extractor
definition to make the transition smooth.

Change-Id: I0c3efb65e75e62212b9c5fc0cd759271111b5956
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/38/700638/1 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'babel-djangojs.cfg']",2,10a8a5695a27c91ebe7966876582934cf0cbea88,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular # We need to look into all static folders for HTML files. # The **/static ensures that we also search within # /openstack_dashboard/dashboards/XYZ/static which will ensure # that plugins are also translated.,0,15
openstack%2Ftripleo-common~master~I15b3d092c911b465b8399a30e4d984e3cc3665b4,openstack/tripleo-common,master,I15b3d092c911b465b8399a30e4d984e3cc3665b4,Bump ceph/daemon container image to v4.0.8,MERGED,2019-12-19 12:23:47.000000000,2019-12-26 23:06:35.000000000,2019-12-26 23:05:16.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:23:47.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/428f9965038c1f9e153702c3671dfb9b2e1a6dc6', 'message': 'Bump ceph/daemon container image to v4.0.8\n\nTested via https://review.opendev.org/562213\n\nChange-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4\n'}]",0,699966,428f9965038c1f9e153702c3671dfb9b2e1a6dc6,14,5,1,6796,,,0,"Bump ceph/daemon container image to v4.0.8

Tested via https://review.opendev.org/562213

Change-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/66/699966/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,428f9965038c1f9e153702c3671dfb9b2e1a6dc6,," 'ceph_tag': 'v4.0.8-stable-4.0-nautilus-centos-7-x86_64',"," 'ceph_tag': 'v4.0.4-stable-4.0-nautilus-centos-7-x86_64',",3,3
openstack%2Fswift~master~I5dac8a35be00f520171e5e179504e8f1c6361988,openstack/swift,master,I5dac8a35be00f520171e5e179504e8f1c6361988,WIP: sharding: Fix conainer_name typo in probe test,ABANDONED,2019-12-23 21:51:35.000000000,2019-12-26 22:57:33.000000000,,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 21:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/75c07a68c6f02e9e98947a4b6f268f56293eb64b', 'message': 'sharding: Fix conainer_name typo in probe test\n\nTest now fails on at least py3; will see what the py2 gate job does...\n\nChange-Id: I5dac8a35be00f520171e5e179504e8f1c6361988\n'}, {'number': 2, 'created': '2019-12-24 00:23:26.000000000', 'files': ['swift/common/direct_client.py', 'test/probe/test_sharder.py', 'swift/container/sharder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/403dabffedd47c4b749ff580100c87e42315d917', 'message': 'WIP: sharding: Fix conainer_name typo in probe test\n\nTest now fails on at least py3; will see what the py2 gate job does...\n\nChange-Id: I5dac8a35be00f520171e5e179504e8f1c6361988\n'}]",0,700454,403dabffedd47c4b749ff580100c87e42315d917,7,3,2,15343,,,0,"WIP: sharding: Fix conainer_name typo in probe test

Test now fails on at least py3; will see what the py2 gate job does...

Change-Id: I5dac8a35be00f520171e5e179504e8f1c6361988
",git fetch https://review.opendev.org/openstack/swift refs/changes/54/700454/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/direct_client.py', 'test/probe/test_sharder.py', 'swift/container/sharder.py']",3,75c07a68c6f02e9e98947a4b6f268f56293eb64b,," 'Failed to put shard ranges to %s:%s/%s: %s\n%s', node['ip'], node['port'], node['device'], err.http_status, err.http_response_content.decode('utf-8'))"," 'Failed to put shard ranges to %s:%s/%s: %s', node['ip'], node['port'], node['device'], err.http_status)",21,15
openstack%2Ftrove~master~Ifee8620a41e439b028e0a4d65164a75a100ce4d9,openstack/trove,master,Ifee8620a41e439b028e0a4d65164a75a100ce4d9,Fix unmount path for instance upgrade,MERGED,2019-12-26 11:52:07.000000000,2019-12-26 22:43:40.000000000,2019-12-26 22:42:19.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 11:52:07.000000000', 'files': ['trove/guestagent/datastore/mysql_common/manager.py', 'doc/source/user/upgrade-datastore.rst', 'trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/35f989a8701bd675f5ec3bafe161897fc23dfd90', 'message': 'Fix unmount path for instance upgrade\n\nChange-Id: Ifee8620a41e439b028e0a4d65164a75a100ce4d9\n'}]",0,700619,35f989a8701bd675f5ec3bafe161897fc23dfd90,7,2,1,6732,,,0,"Fix unmount path for instance upgrade

Change-Id: Ifee8620a41e439b028e0a4d65164a75a100ce4d9
",git fetch https://review.opendev.org/openstack/trove refs/changes/19/700619/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/datastore/mysql_common/manager.py', 'doc/source/user/upgrade-datastore.rst', 'trove/taskmanager/models.py']",3,35f989a8701bd675f5ec3bafe161897fc23dfd90,upgrade," LOG.info(""Upgrading instance %s to new datastore version %s"", self.id, datastore_version) sleep_time=5, time_out=600) LOG.info('Finished rebuilding server for instance %s', self.id) LOG.info(""Finished upgrading instance %s to new datastore "" ""version %s"", self.id, datastore_version)"," LOG.debug(""Upgrading instance %s to new datastore version %s"", self, datastore_version) sleep_time=2, time_out=600)",48,39
openstack%2Fpycadf~master~Ica55dea9f53e363b08f89c54ea896ba2081bf86a,openstack/pycadf,master,Ica55dea9f53e363b08f89c54ea896ba2081bf86a,Change README.rst with a better title,MERGED,2019-12-26 03:04:05.000000000,2019-12-26 22:28:20.000000000,2019-12-26 22:27:04.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 03:04:05.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/cf022925787bd0e64b2f032e9046884b61a258a2', 'message': 'Change README.rst with a better title\n\nChange-Id: Ica55dea9f53e363b08f89c54ea896ba2081bf86a\n'}]",0,700580,cf022925787bd0e64b2f032e9046884b61a258a2,7,2,1,30883,,,0,"Change README.rst with a better title

Change-Id: Ica55dea9f53e363b08f89c54ea896ba2081bf86a
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/80/700580/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cf022925787bd0e64b2f032e9046884b61a258a2,,====== PyCADF ======,======================== Team and repository tags ============================== PyCADF ====== ,3,7
openstack%2Ftripleo-common~stable%2Ftrain~I15b3d092c911b465b8399a30e4d984e3cc3665b4,openstack/tripleo-common,stable/train,I15b3d092c911b465b8399a30e4d984e3cc3665b4,Bump ceph/daemon container image to v4.0.8,MERGED,2019-12-19 12:26:53.000000000,2019-12-26 19:51:05.000000000,2019-12-26 19:49:44.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:26:53.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8f54f3b2154851e2acdf2541934cc7d19dd6944a', 'message': 'Bump ceph/daemon container image to v4.0.8\n\nTested via https://review.opendev.org/690036\n\nChange-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4\n(cherry picked from commit 428f9965038c1f9e153702c3671dfb9b2e1a6dc6)\n'}]",0,699967,8f54f3b2154851e2acdf2541934cc7d19dd6944a,10,5,1,6796,,,0,"Bump ceph/daemon container image to v4.0.8

Tested via https://review.opendev.org/690036

Change-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4
(cherry picked from commit 428f9965038c1f9e153702c3671dfb9b2e1a6dc6)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/67/699967/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,8f54f3b2154851e2acdf2541934cc7d19dd6944a,," 'ceph_tag': 'v4.0.8-stable-4.0-nautilus-centos-7-x86_64',"," 'ceph_tag': 'v4.0.4-stable-4.0-nautilus-centos-7-x86_64',",3,3
openstack%2Ftripleo-common~stable%2Fstein~I15b3d092c911b465b8399a30e4d984e3cc3665b4,openstack/tripleo-common,stable/stein,I15b3d092c911b465b8399a30e4d984e3cc3665b4,Bump ceph/daemon container image to v4.0.8,MERGED,2019-12-19 12:28:17.000000000,2019-12-26 19:50:55.000000000,2019-12-26 19:49:45.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:28:17.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d1298e119ab0bdeb80266fd5700439739cb8c131', 'message': 'Bump ceph/daemon container image to v4.0.8\n\nTested via https://review.opendev.org/656934\n\nChange-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4\n(cherry picked from commit 428f9965038c1f9e153702c3671dfb9b2e1a6dc6)\n(cherry picked from commit 8f54f3b2154851e2acdf2541934cc7d19dd6944a)\n'}]",0,699968,d1298e119ab0bdeb80266fd5700439739cb8c131,10,5,1,6796,,,0,"Bump ceph/daemon container image to v4.0.8

Tested via https://review.opendev.org/656934

Change-Id: I15b3d092c911b465b8399a30e4d984e3cc3665b4
(cherry picked from commit 428f9965038c1f9e153702c3671dfb9b2e1a6dc6)
(cherry picked from commit 8f54f3b2154851e2acdf2541934cc7d19dd6944a)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/699968/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,d1298e119ab0bdeb80266fd5700439739cb8c131,," 'ceph_tag': 'v4.0.8-stable-4.0-nautilus-centos-7-x86_64',"," 'ceph_tag': 'v4.0.4-stable-4.0-nautilus-centos-7-x86_64',",3,3
openstack%2Ftripleo-common~stable%2Fqueens~I6b80ae2e13deb390cbb2b152299a5915ebb337a2,openstack/tripleo-common,stable/queens,I6b80ae2e13deb390cbb2b152299a5915ebb337a2,Bump ceph/daemon container image to v3.2.10,MERGED,2019-12-19 12:41:55.000000000,2019-12-26 19:49:47.000000000,2019-12-26 19:49:47.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:41:55.000000000', 'files': ['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2e64a73a46708bb565731b755bff04a2a1b2b299', 'message': 'Bump ceph/daemon container image to v3.2.10\n\nTested via https://review.opendev.org/562215\n\nChange-Id: I6b80ae2e13deb390cbb2b152299a5915ebb337a2\n(cherry picked from commit 51e50777513460d005b957044baf50310fa99da4)\n'}]",0,699975,2e64a73a46708bb565731b755bff04a2a1b2b299,9,5,1,6796,,,0,"Bump ceph/daemon container image to v3.2.10

Tested via https://review.opendev.org/562215

Change-Id: I6b80ae2e13deb390cbb2b152299a5915ebb337a2
(cherry picked from commit 51e50777513460d005b957044baf50310fa99da4)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/75/699975/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,2e64a73a46708bb565731b755bff04a2a1b2b299,," 'ceph_tag': 'v3.2.10-stable-3.2-luminous-centos-7-x86_64',"," 'ceph_tag': 'v3.2.8-stable-3.2-luminous-centos-7-x86_64',",3,3
openstack%2Ftripleo-common~stable%2Frocky~I6b80ae2e13deb390cbb2b152299a5915ebb337a2,openstack/tripleo-common,stable/rocky,I6b80ae2e13deb390cbb2b152299a5915ebb337a2,Bump ceph/daemon container image to v3.2.10,MERGED,2019-12-19 12:31:59.000000000,2019-12-26 19:49:46.000000000,2019-12-26 19:49:46.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-12-19 12:31:59.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/51e50777513460d005b957044baf50310fa99da4', 'message': 'Bump ceph/daemon container image to v3.2.10\n\nTested via https://review.opendev.org/601598\n\nChange-Id: I6b80ae2e13deb390cbb2b152299a5915ebb337a2\n'}]",0,699970,51e50777513460d005b957044baf50310fa99da4,10,6,1,6796,,,0,"Bump ceph/daemon container image to v3.2.10

Tested via https://review.opendev.org/601598

Change-Id: I6b80ae2e13deb390cbb2b152299a5915ebb337a2
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/70/699970/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,51e50777513460d005b957044baf50310fa99da4,," 'ceph_tag': 'v3.2.10-stable-3.2-luminous-centos-7-x86_64',"," 'ceph_tag': 'v3.2.8-stable-3.2-luminous-centos-7-x86_64',",3,3
openstack%2Fcinder~master~I559e14af76381e01e95deeaec4d0ffbfb4f975bb,openstack/cinder,master,I559e14af76381e01e95deeaec4d0ffbfb4f975bb,Adds peer persistence feature to HPE 3PAR driver,NEW,2018-10-19 11:46:12.000000000,2019-12-26 17:52:39.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12822}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24863}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-10-19 11:46:12.000000000', 'files': ['cinder/volume/drivers/hpe/hpe_3par_base.py', 'cinder/volume/drivers/hpe/hpe_3par_fc.py', 'cinder/volume/drivers/hpe/hpe_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b39eeaa5c9c5f8fee3dffd036eaa8955706d9a1', 'message': 'Adds peer persistence feature to HPE 3PAR driver\n\nFirst attempt at a naive implementation for Peer Persistence volumes in the\nHPE 3PAR driver for Cinder.\n\nThis is a cleaned-up version of a patch we are currently using on a\nstandalone Cinder installation (non-OpenStack). This means that the basic\nfunctionality of being able to create cinder volumes with peer persistence\nhas been validated. However, a multitude of tests will be required in order\nto merge this functionality upstream.\n\nA first attempt at listing the tests to be executed:\n\n- Validation of the ""replication:peer_persistence"" setting\n- Double-check implementation/configuration of peerpersistent volumes\n- Validate creation of peerpersistent volumes when one 3PAR instance is\n  unavailable\n- Validate automatic fail-over of an existing peerpersistent volume when\n  a 3PAR instance goes offline\n- Validate manual fail-over of a peerpersistent volumes\n- Evaluate retype functionality for peerpersistent volumes\n\nChanged:\n\n- Fixed invalid variable name\n- Resolved all Flake8 warnings\n- Fixed one invalid if-clause when replication is not enabled\n- Dict comprehension instead of dict constructor for PEP8\n\nChange-Id: I559e14af76381e01e95deeaec4d0ffbfb4f975bb\n'}]",0,611854,5b39eeaa5c9c5f8fee3dffd036eaa8955706d9a1,23,22,1,28394,,,0,"Adds peer persistence feature to HPE 3PAR driver

First attempt at a naive implementation for Peer Persistence volumes in the
HPE 3PAR driver for Cinder.

This is a cleaned-up version of a patch we are currently using on a
standalone Cinder installation (non-OpenStack). This means that the basic
functionality of being able to create cinder volumes with peer persistence
has been validated. However, a multitude of tests will be required in order
to merge this functionality upstream.

A first attempt at listing the tests to be executed:

- Validation of the ""replication:peer_persistence"" setting
- Double-check implementation/configuration of peerpersistent volumes
- Validate creation of peerpersistent volumes when one 3PAR instance is
  unavailable
- Validate automatic fail-over of an existing peerpersistent volume when
  a 3PAR instance goes offline
- Validate manual fail-over of a peerpersistent volumes
- Evaluate retype functionality for peerpersistent volumes

Changed:

- Fixed invalid variable name
- Resolved all Flake8 warnings
- Fixed one invalid if-clause when replication is not enabled
- Dict comprehension instead of dict constructor for PEP8

Change-Id: I559e14af76381e01e95deeaec4d0ffbfb4f975bb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/611854/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hpe/hpe_3par_base.py', 'cinder/volume/drivers/hpe/hpe_3par_fc.py', 'cinder/volume/drivers/hpe/hpe_3par_common.py']",3,5b39eeaa5c9c5f8fee3dffd036eaa8955706d9a1,feature/cinder-hpe3par-peer-persistence," EXTRA_SPEC_REP_PEERPERSISTENCE = ""replication:peer_persistence"" DEFAULT_REP_PEERPERSISTENCE = False replication_peer_persistence = extra_specs.get( self.EXTRA_SPEC_REP_PEERPERSISTENCE, self.DEFAULT_REP_PEERPERSISTENCE) if replication_peer_persistence: # 'sync_targets_peer' added to enable Peer Persistence on # these volumes sync_targets_peer = [] # define peer-persistent volume objects if replication_peer_persistence: sync_target_peer = {'targetName': target['backend_id'], 'policies': {'autoRecover': True, 'autoFailover': True, 'pathManagement': True } } sync_targets_peer.append(sync_target_peer) # If peer persistence is enabled, add the necessary options if replication_peer_persistence: opt = {'targets': sync_targets_peer} try: self.client.modifyRemoteCopyGroup(rcg_name, opt) except Exception as ex: msg = (_(""There was an error setting the peer persistence "" ""for the remote copy group: %s."") % six.text_type(ex)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) ",,197,2
openstack%2Ftempest~master~I4ce1ee9bf07d125876d4fc18a494334740fae599,openstack/tempest,master,I4ce1ee9bf07d125876d4fc18a494334740fae599,Add test to validate identity max request body size limit,ABANDONED,2019-12-11 07:48:48.000000000,2019-12-26 17:35:47.000000000,,"[{'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 23467}, {'_account_id': 30108}]","[{'number': 1, 'created': '2019-12-11 07:48:48.000000000', 'files': ['tempest/api/identity/admin/v3/test_size_limit.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0357fbb99192f5425a89e682dd61dd7680e447de', 'message': 'Add test to validate identity max request body size limit\n\nThe aim of this PS is to add a test to validate identity api\nmax request body size limit feature. This test ensures that\nany malicious oversized request gets blocked ensuring continued\navailability of the component. For more details, pls refer\nhttps://docs.openstack.org/security-guide/identity/checklist.html#check-identity-05-is-max-request-body-size-set-to-default-114688\n\nChange-Id: I4ce1ee9bf07d125876d4fc18a494334740fae599\n'}]",0,698413,0357fbb99192f5425a89e682dd61dd7680e447de,13,13,1,23467,,,0,"Add test to validate identity max request body size limit

The aim of this PS is to add a test to validate identity api
max request body size limit feature. This test ensures that
any malicious oversized request gets blocked ensuring continued
availability of the component. For more details, pls refer
https://docs.openstack.org/security-guide/identity/checklist.html#check-identity-05-is-max-request-body-size-set-to-default-114688

Change-Id: I4ce1ee9bf07d125876d4fc18a494334740fae599
",git fetch https://review.opendev.org/openstack/tempest refs/changes/13/698413/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/admin/v3/test_size_limit.py', 'tempest/config.py']",2,0357fbb99192f5425a89e682dd61dd7680e447de,," cfg.IntOpt('max_request_body_size', default=114688, help=""The maximum body size for each request, in bytes. "" ""For more details, refer to keystone config options "" ""keystone.conf:max_request_body_size. "" ""NOTE: This config option value must be same as "" ""keystone.conf: max_request_body_size "" ""otherwise test might fail"" )",,47,0
openstack%2Ftripleo-common~stable%2Fqueens~I974f22ded851897b6c8fc0374dc51d34b575dfcf,openstack/tripleo-common,stable/queens,I974f22ded851897b6c8fc0374dc51d34b575dfcf,Bump ceph/daemon container image to v3.2.10,ABANDONED,2019-12-19 12:36:47.000000000,2019-12-26 17:02:50.000000000,,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 12:36:47.000000000', 'files': ['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b79aa38948cc72505a8690c258fbeefd38abe7d7', 'message': 'Bump ceph/daemon container image to v3.2.10\n\nTested via https://review.opendev.org/562215\n\n(cherry picked from commit 51e50777513460d005b957044baf50310fa99da4)\n\nChange-Id: I974f22ded851897b6c8fc0374dc51d34b575dfcf\n'}]",0,699973,b79aa38948cc72505a8690c258fbeefd38abe7d7,5,3,1,6796,,,0,"Bump ceph/daemon container image to v3.2.10

Tested via https://review.opendev.org/562215

(cherry picked from commit 51e50777513460d005b957044baf50310fa99da4)

Change-Id: I974f22ded851897b6c8fc0374dc51d34b575dfcf
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/73/699973/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,b79aa38948cc72505a8690c258fbeefd38abe7d7,," 'ceph_tag': 'v3.2.10-stable-3.2-luminous-centos-7-x86_64',"," 'ceph_tag': 'v3.2.8-stable-3.2-luminous-centos-7-x86_64',",3,3
openstack%2Fhorizon~master~Icf93d4551bd3db1baa84c110f06dcc1c36e18b7e,openstack/horizon,master,Icf93d4551bd3db1baa84c110f06dcc1c36e18b7e,Drop babel extractor definitions from babel config,MERGED,2019-12-23 08:25:18.000000000,2019-12-26 16:30:54.000000000,2019-12-26 16:29:17.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-23 08:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e56d36ac9de782e3d2fb5602d555e924a6305e00', 'message': 'Drop babel extractor definitions from babel config\n\nBabel allows us to register babel extractors via entry points.\nThis means we no longer need to have extractor definitions in\neach babel config files. All horizon plugins have copies of\nbabel-django.cfg and babel-djangojs.cfg now. By dropping the\nextractor defintiions from babel config files, we can make\na potential migration from django-babel to enmerkar (and\nwe can also avoid more modifications of babel config files\neven if more transition is required).\n\nChange-Id: Icf93d4551bd3db1baa84c110f06dcc1c36e18b7e\n'}, {'number': 2, 'created': '2019-12-23 08:27:59.000000000', 'files': ['babel-django.cfg', 'setup.cfg', 'babel-djangojs.cfg'], 'web_link': 'https://opendev.org/openstack/horizon/commit/155bf2278841126045667afe07c6b30f09be3602', 'message': ""Drop babel extractor definitions from babel config\n\nBabel allows us to register babel extractors via entry points.\nThis means we no longer need to have extractor definitions in\neach babel config files. All horizon plugins have copies of\nbabel-django.cfg and babel-djangojs.cfg now. By dropping the\nextractor defintiions from babel config files, we can make\na potential migration from django-babel to enmerkar (and\nwe can also avoid more modifications of babel config files\neven if more transition is required).\n\ndjango-babel and enmerkar both define 'django' extractor\nin the entry point, so we can drop it from babel-django.cfg.\nThis commit also registers 'angular' extractor, so we can drop\nthe extractor for AngularJS from babel-djangojs.cfg.\n\nChange-Id: Icf93d4551bd3db1baa84c110f06dcc1c36e18b7e\n""}]",0,700391,155bf2278841126045667afe07c6b30f09be3602,12,4,2,841,,,0,"Drop babel extractor definitions from babel config

Babel allows us to register babel extractors via entry points.
This means we no longer need to have extractor definitions in
each babel config files. All horizon plugins have copies of
babel-django.cfg and babel-djangojs.cfg now. By dropping the
extractor defintiions from babel config files, we can make
a potential migration from django-babel to enmerkar (and
we can also avoid more modifications of babel config files
even if more transition is required).

django-babel and enmerkar both define 'django' extractor
in the entry point, so we can drop it from babel-django.cfg.
This commit also registers 'angular' extractor, so we can drop
the extractor for AngularJS from babel-djangojs.cfg.

Change-Id: Icf93d4551bd3db1baa84c110f06dcc1c36e18b7e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/700391/2 && git format-patch -1 --stdout FETCH_HEAD,"['babel-django.cfg', 'setup.cfg', 'babel-djangojs.cfg']",3,e56d36ac9de782e3d2fb5602d555e924a6305e00,babel-config,,[extractors] # We use a custom extractor to find translatable strings in AngularJS # templates. The extractor is included in horizon.utils for now. # See http://babel.pocoo.org/docs/messages/#referencing-extraction-methods for # details on how this works. angular = horizon.utils.babel_extract_angular:extract_angular ,5,10
openstack%2Fopenstack-ansible-os_nova~stable%2Fstein~I01df855d8b9255d24efe16ab053ffa491fda351f,openstack/openstack-ansible-os_nova,stable/stein,I01df855d8b9255d24efe16ab053ffa491fda351f,Use integrated repo for nova-lxd job,ABANDONED,2019-08-07 17:02:43.000000000,2019-12-26 15:36:49.000000000,,"[{'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-08-07 17:02:43.000000000', 'files': ['tests/test-create-zfs-dev.yml', 'zuul.d/playbooks/pre-lxd.yml', 'zuul.d/project.yaml', 'zuul.d/playbooks/files/user_variables_lxd.yml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/6370567b02a97469798aab74509c82af713008ab', 'message': 'Use integrated repo for nova-lxd job\n\nDepends-On: I8ec359f5c65c957064a39b75b9c3ea3d3a9d9e89\nDepends-On: I2d49b6802d8cf99f6d7ac74ae4ce0ab8f6d1c7a5\nDepends-On: I0e77423a1f28d9a53215ae68c1f9f3e2af00f340\nDepends-On: I621660f39c4e51db4b8063feee782aae5cd16840\nChange-Id: I01df855d8b9255d24efe16ab053ffa491fda351f\n(cherry picked from commit 8f55c68d8371a50625c3fdb5b82cbeb62f2808c4)\n'}]",0,675155,6370567b02a97469798aab74509c82af713008ab,7,4,1,1004,,,0,"Use integrated repo for nova-lxd job

Depends-On: I8ec359f5c65c957064a39b75b9c3ea3d3a9d9e89
Depends-On: I2d49b6802d8cf99f6d7ac74ae4ce0ab8f6d1c7a5
Depends-On: I0e77423a1f28d9a53215ae68c1f9f3e2af00f340
Depends-On: I621660f39c4e51db4b8063feee782aae5cd16840
Change-Id: I01df855d8b9255d24efe16ab053ffa491fda351f
(cherry picked from commit 8f55c68d8371a50625c3fdb5b82cbeb62f2808c4)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/55/675155/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-create-zfs-dev.yml', 'zuul.d/playbooks/pre-lxd.yml', 'zuul.d/project.yaml', 'zuul.d/playbooks/files/user_variables_lxd.yml', 'zuul.d/jobs.yaml']",5,6370567b02a97469798aab74509c82af713008ab,use-integrated-repo-for-all-tests-stable/stein, name: openstack-ansible-deploy-aio_metal_lxd-ubuntu-bionic parent: openstack-ansible-deploy-aio_metal-ubuntu-bionic pre-run: - zuul.d/playbooks/pre-lxd.yml, name: openstack-ansible-lxd-ubuntu-bionic parent: openstack-ansible-functional-ubuntu-bionic vars: tox_env: lxd,34,9
openstack%2Fopenstack-ansible-os_ironic~stable%2Fstein~Ibc4859326c39e07411a55c03b95d106a5a563130,openstack/openstack-ansible-os_ironic,stable/stein,Ibc4859326c39e07411a55c03b95d106a5a563130,Add integrated coverage,ABANDONED,2019-07-31 20:00:40.000000000,2019-12-26 15:36:40.000000000,,"[{'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-07-31 20:00:40.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/9ac5622dd1978305a75d615a2792f4293f736300', 'message': ""Add integrated coverage\n\nCurrently this role doesn't test the integrated jobs.\n\nThis is a problem because it's not consistent with other jobs.\n\nChange-Id: Ibc4859326c39e07411a55c03b95d106a5a563130\n(cherry picked from commit 1388c2abd06f29a91a7e575d92ccd0570a1d4fd2)\n""}]",0,673901,9ac5622dd1978305a75d615a2792f4293f736300,6,4,1,1004,,,0,"Add integrated coverage

Currently this role doesn't test the integrated jobs.

This is a problem because it's not consistent with other jobs.

Change-Id: Ibc4859326c39e07411a55c03b95d106a5a563130
(cherry picked from commit 1388c2abd06f29a91a7e575d92ccd0570a1d4fd2)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/01/673901/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,9ac5622dd1978305a75d615a2792f4293f736300,use-integrated-repo-for-all-tests-stable/stein,,"--- # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - job: name: openstack-ansible-deploy-aio_metal_ironic-centos-7 parent: openstack-ansible-deploy-aio nodeset: centos-7 vars: action: deploy scenario: aio_metal_ironic - job: name: openstack-ansible-deploy-aio_metal_ironic-opensuse-150 parent: openstack-ansible-deploy-aio nodeset: opensuse-150 vars: action: deploy scenario: aio_metal_ironic - job: name: openstack-ansible-deploy-aio_metal_ironic-ubuntu-bionic parent: openstack-ansible-deploy-aio nodeset: ubuntu-bionic vars: action: deploy scenario: aio_metal_ironic - job: name: openstack-ansible-deploy-aio_metal_ironic-debian-stable parent: openstack-ansible-deploy-aio nodeset: debian-stable vars: action: deploy scenario: aio_metal_ironic ",4,57
openstack%2Fopenstack-ansible-rabbitmq_server~master~If42fdf70ef84e7fe4f22c1256615e1c57df64264,openstack/openstack-ansible-rabbitmq_server,master,If42fdf70ef84e7fe4f22c1256615e1c57df64264,debian: install from distro for debian,ABANDONED,2019-05-06 03:02:09.000000000,2019-12-26 15:36:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-05-06 03:02:09.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/1d1a2bbb0d460b55bfe951611de5a38cc458e972', 'message': 'debian: install from distro for debian\n\nUbuntu will keep installing from files but Debian ships modern\nand supported RabbitMQ and Erlang combinations.  We should keep\nusing them.\n\nChange-Id: If42fdf70ef84e7fe4f22c1256615e1c57df64264\n'}]",0,657305,1d1a2bbb0d460b55bfe951611de5a38cc458e972,3,1,1,1004,,,0,"debian: install from distro for debian

Ubuntu will keep installing from files but Debian ships modern
and supported RabbitMQ and Erlang combinations.  We should keep
using them.

Change-Id: If42fdf70ef84e7fe4f22c1256615e1c57df64264
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/05/657305/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,1d1a2bbb0d460b55bfe951611de5a38cc458e972,osa/debian-support,"_rabbitmq_install_method: ""{% if ansible_distribution == 'Debian' %}file{% else %}distro{% endif %}""",_rabbitmq_install_method: file,1,1
openstack%2Fopenstack-ansible-rabbitmq_server~master~Id086e9d667f95261fac90b2d6a226b60c57315ae,openstack/openstack-ansible-rabbitmq_server,master,Id086e9d667f95261fac90b2d6a226b60c57315ae,debian: use ansible_lsb.codename,ABANDONED,2019-05-06 02:52:29.000000000,2019-12-26 15:36:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-05-06 02:52:29.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/c52e9f61ec268f636ccbe28c5d1d8f4dfdb132e0', 'message': 'debian: use ansible_lsb.codename\n\nThe LSB codename is far more reliable in order of giving us the\nname of the current series as ansible_distribution_version can\nbe inaccurate in the case of unreleased versions such as Buster\nwhich would return ""NA"" for that variable.\n\nChange-Id: Id086e9d667f95261fac90b2d6a226b60c57315ae\n'}]",0,657303,c52e9f61ec268f636ccbe28c5d1d8f4dfdb132e0,3,1,1,1004,,,0,"debian: use ansible_lsb.codename

The LSB codename is far more reliable in order of giving us the
name of the current series as ansible_distribution_version can
be inaccurate in the case of unreleased versions such as Buster
which would return ""NA"" for that variable.

Change-Id: Id086e9d667f95261fac90b2d6a226b60c57315ae
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/03/657303/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,c52e9f61ec268f636ccbe28c5d1d8f4dfdb132e0,osa/debian-support," repo: ""deb {{ rabbitmq_repo_url }} {{ ansible_lsb.codename | lower }} main"" repo: ""deb {{ rabbitmq_erlang_repo_url }} {{ ansible_lsb.codename | lower }} contrib"""," repo: ""deb {{ rabbitmq_repo_url }} {{ ansible_distribution_release | lower }} main"" repo: ""deb {{ rabbitmq_erlang_repo_url }} {{ ansible_distribution_release | lower }} contrib""",2,2
openstack%2Fopenstack-ansible-rabbitmq_server~master~I1448417a3a3fda35a05214dc4117d482ab0d21fc,openstack/openstack-ansible-rabbitmq_server,master,I1448417a3a3fda35a05214dc4117d482ab0d21fc,debian: move to installing from bintray,ABANDONED,2019-05-06 02:49:04.000000000,2019-12-26 15:36:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-05-06 02:49:04.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/961fe1a70e13c3369ef89992b53d388b514bc80d', 'message': 'debian: move to installing from bintray\n\nBintray contains a single deb which works across all Debian variants\nwhich means that it can support current operating systems and those\nwhich have not been released yet too (i.e. buster).\n\nLong term, it would probably be good for us to use pinning and then\ninstall the bintray repo, but this will make things work for Buster\nfor now.\n\nChange-Id: I1448417a3a3fda35a05214dc4117d482ab0d21fc\n'}]",0,657302,961fe1a70e13c3369ef89992b53d388b514bc80d,3,1,1,1004,,,0,"debian: move to installing from bintray

Bintray contains a single deb which works across all Debian variants
which means that it can support current operating systems and those
which have not been released yet too (i.e. buster).

Long term, it would probably be good for us to use pinning and then
install the bintray repo, but this will make things work for Buster
for now.

Change-Id: I1448417a3a3fda35a05214dc4117d482ab0d21fc
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/02/657302/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,961fe1a70e13c3369ef89992b53d388b514bc80d,osa/debian-support,"_rabbitmq_package_url: ""https://dl.bintray.com/rabbitmq/debian/pool/rabbitmq-server/rabbitmq-server_3.7.8-1_all.deb"" _rabbitmq_package_version: ""{{ rabbitmq_package_url.split('/')[-1].split('_')[1] }}""_rabbitmq_package_sha256: ""240b300f96352807674e4e3cbb85962dc1a05fc45e2dcba09fcb577fa7a13865""","_rabbitmq_package_url: ""https://packagecloud.io/rabbitmq/rabbitmq-server/packages/{{ ansible_distribution | lower }}/{{ ansible_distribution_release | lower }}/rabbitmq-server_3.7.8-1_all.deb/download.deb"" _rabbitmq_package_version: ""{{ rabbitmq_package_url.split('/')[-2].split('_')[1] }}""_rabbitmq_package_sha256: ""11f70dd68e098e4dc32e3eda49ab68c795e599f3ac0b8b858014c79432173928""",3,3
openstack%2Fopenstack-ansible-galera_client~master~Id5565bcf0369fc4dca6e48cb2f85ba568ef84795,openstack/openstack-ansible-galera_client,master,Id5565bcf0369fc4dca6e48cb2f85ba568ef84795,debian: use ansible_lsb.codename,ABANDONED,2019-05-06 02:28:56.000000000,2019-12-26 15:36:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-05-06 02:28:56.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/f50cd2f151068c49c659a4104aba41dc4ecbee08', 'message': 'debian: use ansible_lsb.codename\n\nThe LSB codename is far more reliable in order of giving us the\nname of the current series as ansible_distribution_version can\nbe inaccurate in the case of unreleased versions such as Buster\nwhich would return ""NA"" for that variable.\n\nChange-Id: Id5565bcf0369fc4dca6e48cb2f85ba568ef84795\n'}]",0,657299,f50cd2f151068c49c659a4104aba41dc4ecbee08,3,1,1,1004,,,0,"debian: use ansible_lsb.codename

The LSB codename is far more reliable in order of giving us the
name of the current series as ansible_distribution_version can
be inaccurate in the case of unreleased versions such as Buster
which would return ""NA"" for that variable.

Change-Id: Id5565bcf0369fc4dca6e48cb2f85ba568ef84795
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/99/657299/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,f50cd2f151068c49c659a4104aba41dc4ecbee08,osa/debian-support,"_galera_client_repo: ""deb {{ galera_client_repo_url }} {{ ansible_lsb.codename }} main""","_galera_client_repo: ""deb {{ galera_client_repo_url }} {{ ansible_distribution_release }} main""",1,1
openstack%2Fopenstack-ansible-galera_server~master~Id5f6f24471736d6bed97b84dd9a031f7a674bb41,openstack/openstack-ansible-galera_server,master,Id5f6f24471736d6bed97b84dd9a031f7a674bb41,debian: use ansible_lsb.codename,ABANDONED,2019-05-06 02:25:51.000000000,2019-12-26 15:36:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-05-06 02:25:51.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/9bdba71143b3f69bc46dde305588bf6c99928fb0', 'message': 'debian: use ansible_lsb.codename\n\nThe LSB codename is far more reliable in order of giving us the\nname of the current series as ansible_distribution_version can\nbe inaccurate in the case of unreleased versions such as Buster\nwhich would return ""NA"" for that variable.\n\nChange-Id: Id5f6f24471736d6bed97b84dd9a031f7a674bb41\n'}]",0,657298,9bdba71143b3f69bc46dde305588bf6c99928fb0,3,1,1,1004,,,0,"debian: use ansible_lsb.codename

The LSB codename is far more reliable in order of giving us the
name of the current series as ansible_distribution_version can
be inaccurate in the case of unreleased versions such as Buster
which would return ""NA"" for that variable.

Change-Id: Id5f6f24471736d6bed97b84dd9a031f7a674bb41
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/98/657298/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,9bdba71143b3f69bc46dde305588bf6c99928fb0,osa/debian-support," repo: ""deb {{ galera_repo_url }} {{ ansible_lsb.codename }} main""galera_wsrep_provider: ""/usr/lib/galera/libgalera_smm.so"" "," repo: ""deb {{ galera_repo_url }} {{ ansible_distribution_release }} main""galera_wsrep_provider: ""/usr/lib/galera/libgalera_smm.so""",2,2
openstack%2Fopenstack-ansible-os_nova~master~I3495cbfc79d25f5fcce5553150daca16356b7bc0,openstack/openstack-ansible-os_nova,master,I3495cbfc79d25f5fcce5553150daca16356b7bc0,nova: stop configuring image_cache_manager_interval by default,ABANDONED,2018-10-21 13:20:52.000000000,2019-12-26 15:35:18.000000000,,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-10-21 13:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/4bcecf271ab671a6588e99e867b65d30fe69d15f', 'message': 'nova: stop configuring image_cache_manager_interval by default\n\nThe value of `image_cache_manager_interval` is misleading because\nwhen setting it 0, it does not default to the nova value (2400)\nbut to the oslo.service default of 60 seconds which can cause\na tremendous amount of load in an environment where shared storage\nis being used (such as NFS) where every hypervisor will pull a list\nof all instances every 60 seconds.\n\nChange-Id: I3495cbfc79d25f5fcce5553150daca16356b7bc0\n'}, {'number': 2, 'created': '2018-10-21 16:01:12.000000000', 'files': ['templates/nova.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/12fd8aa7957c2f475d593c1f575728b17d9b566b', 'message': 'nova: stop configuring image_cache_manager_interval by default\n\nThe value of `image_cache_manager_interval` is misleading because\nwhen setting it 0, it does not default to the nova value (2400)\nbut to the oslo.service default of 60 seconds which can cause\na tremendous amount of load in an environment where shared storage\nis being used (such as NFS) where every hypervisor will pull a list\nof all instances every 60 seconds.\n\nChange-Id: I3495cbfc79d25f5fcce5553150daca16356b7bc0\n'}]",0,612166,12fd8aa7957c2f475d593c1f575728b17d9b566b,6,2,2,1004,,,0,"nova: stop configuring image_cache_manager_interval by default

The value of `image_cache_manager_interval` is misleading because
when setting it 0, it does not default to the nova value (2400)
but to the oslo.service default of 60 seconds which can cause
a tremendous amount of load in an environment where shared storage
is being used (such as NFS) where every hypervisor will pull a list
of all instances every 60 seconds.

Change-Id: I3495cbfc79d25f5fcce5553150daca16356b7bc0
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/66/612166/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/nova.conf.j2', 'defaults/main.yml']",2,4bcecf271ab671a6588e99e867b65d30fe69d15f,fix-image-cache,# nova_image_cache_manager_interval: 2400,nova_image_cache_manager_interval: 0,3,1
openstack%2Fopenstack-ansible-os_nova~master~I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92,openstack/openstack-ansible-os_nova,master,I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92,Stop running map_cell0 all the time,ABANDONED,2018-09-16 16:39:50.000000000,2019-12-26 15:35:00.000000000,,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2018-09-16 16:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/4173bf46542e4b5affb2f9aec774951201b22ef0', 'message': 'Stop running map_cell0 all the time\n\nThis task is only necessary to run when upgrading to Cells V2 which\nwas in Newton.  It takes a large amount of time to run in environments\nthat have already been upgraded as it scans the entire instances\ndatabase.\n\nBeyond Newton, this task is no longer necessary.\n\nChange-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92\n'}, {'number': 2, 'created': '2018-09-27 02:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8064a740f1bd5bf3520a39b4639c5b7daf32cc5b', 'message': 'Stop running map_cell0 all the time\n\nThis task is only necessary to run when upgrading to Cells V2 which\nwas in Newton.  It takes a large amount of time to run in environments\nthat have already been upgraded as it scans the entire instances\ndatabase.\n\nBeyond Newton, this task is no longer necessary.\n\nChange-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92\n'}, {'number': 3, 'created': '2019-03-16 03:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/452c11e7dde98e991f0b55a505b87767255241a4', 'message': 'Stop running map_cell0 all the time\n\nThis task is only necessary to run when upgrading to Cells V2 which\nwas in Newton.  It takes a large amount of time to run in environments\nthat have already been upgraded as it scans the entire instances\ndatabase.\n\nBeyond Newton, this task is no longer necessary.\n\nChange-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92\n'}, {'number': 4, 'created': '2019-09-20 11:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8f999b53be8cfe3d5972290f2de250264a10981c', 'message': 'Stop running map_cell0 all the time\n\nThis task is only necessary to run when upgrading to Cells V2 which\nwas in Newton.  It takes a large amount of time to run in environments\nthat have already been upgraded as it scans the entire instances\ndatabase.\n\nBeyond Newton, this task is no longer necessary.\n\nChange-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92\n'}, {'number': 5, 'created': '2019-09-20 15:11:11.000000000', 'files': ['tasks/nova_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/31914cee1ca36d1afa8052fc20ee40f2570f2c57', 'message': 'Stop running map_cell0 all the time\n\nThis task is only necessary to run when upgrading to Cells V2 which\nwas in Newton.  It takes a large amount of time to run in environments\nthat have already been upgraded as it scans the entire instances\ndatabase.\n\nBeyond Newton, this task is no longer necessary.\n\nChange-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92\n'}]",0,602979,31914cee1ca36d1afa8052fc20ee40f2570f2c57,13,3,5,1004,,,0,"Stop running map_cell0 all the time

This task is only necessary to run when upgrading to Cells V2 which
was in Newton.  It takes a large amount of time to run in environments
that have already been upgraded as it scans the entire instances
database.

Beyond Newton, this task is no longer necessary.

Change-Id: I3f2f2eded9d6eb0385cff51e8b74bd4e6a7e0f92
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/79/602979/5 && git format-patch -1 --stdout FETCH_HEAD,['tasks/nova_db_setup.yml'],1,4173bf46542e4b5affb2f9aec774951201b22ef0,,,"# This is idempotent and therefore safe for greenfield # and brownfield installations. - name: Create the cell0 mapping entry in the nova API DB command: >- {{ nova_bin }}/nova-manage cell_v2 map_cell0 --database_connection mysql+pymysql://{{ nova_api_galera_user }}:{{ nova_api_container_mysql_password }}@{{ nova_api_galera_address }}/{{ nova_cell0_database }}?charset=utf8 become: yes become_user: ""{{ nova_system_user_name }}"" changed_when: false ",0,10
openstack%2Fironic-inspector~master~Ia14bc6397a88f200277abc5485cab02eb3724e1b,openstack/ironic-inspector,master,Ia14bc6397a88f200277abc5485cab02eb3724e1b,Enforce running tox with correct python version based on env,MERGED,2019-12-20 15:24:56.000000000,2019-12-26 15:34:48.000000000,2019-12-26 15:32:06.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 15:24:56.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/917d2e44ebeac69afe169c413dd46e849702a5ad', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: Ia14bc6397a88f200277abc5485cab02eb3724e1b\n'}]",0,700190,917d2e44ebeac69afe169c413dd46e849702a5ad,8,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: Ia14bc6397a88f200277abc5485cab02eb3724e1b
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/90/700190/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,917d2e44ebeac69afe169c413dd46e849702a5ad,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,,2,0
openstack%2Fnova~master~I4f5d9e3cee3e006ace19579962b73f0ea09ab904,openstack/nova,master,I4f5d9e3cee3e006ace19579962b73f0ea09ab904,Remove nova.image.download.modules extension point,ABANDONED,2019-08-15 02:29:53.000000000,2019-12-26 15:34:29.000000000,,"[{'_account_id': 1004}, {'_account_id': 6873}, {'_account_id': 10338}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28397}]","[{'number': 1, 'created': '2019-08-15 02:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdfe9732b8fc065e521cc459e72af3e8813bae57', 'message': 'Remove nova.image.download.modules extension point\n\nThere has been no patches to continue to maintain this extension\npoint so this patch removes that extension point from Nova.\n\nChange-Id: I4f5d9e3cee3e006ace19579962b73f0ea09ab904\n'}, {'number': 2, 'created': '2019-08-15 12:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b768b168742ad86481fd072ed456330136c8e69', 'message': 'Remove nova.image.download.modules extension point\n\nThere has been no patches to continue to maintain this extension\npoint so this patch removes that extension point from Nova.\n\nChange-Id: I4f5d9e3cee3e006ace19579962b73f0ea09ab904\n'}, {'number': 3, 'created': '2019-08-15 14:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/777da0b95ffc2b75b175e12a0a5b55981f855740', 'message': 'Remove nova.image.download.modules extension point\n\nThere has been no patches to continue to maintain this extension\npoint so this patch removes that extension point from Nova.\n\nChange-Id: I4f5d9e3cee3e006ace19579962b73f0ea09ab904\n'}, {'number': 4, 'created': '2019-08-15 15:51:45.000000000', 'files': ['nova/image/download/__init__.py', 'nova/image/glance.py', 'releasenotes/notes/remove-image-download-ext-point-c887132d656bde5b.yaml', 'nova/conf/glance.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7216c587e5467821eaf5771ed9c6bcc9dd4cec8', 'message': 'Remove nova.image.download.modules extension point\n\nThere has been no patches to continue to maintain this extension\npoint so this patch removes that extension point from Nova.\n\nChange-Id: I4f5d9e3cee3e006ace19579962b73f0ea09ab904\n'}]",0,676540,a7216c587e5467821eaf5771ed9c6bcc9dd4cec8,32,12,4,1004,,,0,"Remove nova.image.download.modules extension point

There has been no patches to continue to maintain this extension
point so this patch removes that extension point from Nova.

Change-Id: I4f5d9e3cee3e006ace19579962b73f0ea09ab904
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/676540/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/image/download/__init__.py', 'nova/image/glance.py', 'releasenotes/notes/remove-image-download-ext-point-c887132d656bde5b.yaml', 'nova/conf/glance.py', 'nova/tests/unit/image/test_glance.py']",5,bdfe9732b8fc065e521cc459e72af3e8813bae57,nova/config-cleanup,," @mock.patch('nova.image.glance.GlanceImageServiceV2._get_transfer_module') @mock.patch('nova.image.glance.GlanceImageServiceV2.show') def test_download_direct_file_uri_v2(self, show_mock, get_tran_mock): self.flags(allowed_direct_url_schemes=['file'], group='glance') show_mock.return_value = { 'locations': [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] } tran_mod = mock.MagicMock() get_tran_mock.return_value = tran_mod client = mock.MagicMock() ctx = mock.sentinel.ctx service = glance.GlanceImageServiceV2(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) self.assertFalse(client.call.called) show_mock.assert_called_once_with(ctx, mock.sentinel.image_id, include_locations=True) get_tran_mock.assert_called_once_with('file') tran_mod.download.assert_called_once_with(ctx, mock.ANY, mock.sentinel.dst_path, mock.sentinel.loc_meta) @mock.patch('nova.image.glance.GlanceImageServiceV2._get_transfer_module') @mock.patch('nova.image.glance.GlanceImageServiceV2.show') @mock.patch('nova.image.glance.GlanceImageServiceV2._safe_fsync') def test_download_direct_exception_fallback_v2( self, fsync_mock, show_mock, get_tran_mock): # Test that we fall back to downloading to the dst_path # if the download method of the transfer module raised # an exception. self.flags(allowed_direct_url_schemes=['file'], group='glance') show_mock.return_value = { 'locations': [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] } tran_mod = mock.MagicMock() tran_mod.download.side_effect = Exception get_tran_mock.return_value = tran_mod client = mock.MagicMock() client.call.return_value = fake_glance_response([1, 2, 3]) ctx = mock.sentinel.ctx writer = mock.MagicMock() with mock.patch.object(six.moves.builtins, 'open') as open_mock: open_mock.return_value = writer service = glance.GlanceImageServiceV2(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) show_mock.assert_called_once_with(ctx, mock.sentinel.image_id, include_locations=True) get_tran_mock.assert_called_once_with('file') tran_mod.download.assert_called_once_with(ctx, mock.ANY, mock.sentinel.dst_path, mock.sentinel.loc_meta) client.call.assert_called_once_with( ctx, 2, 'data', args=(mock.sentinel.image_id,)) fsync_mock.assert_called_once_with(writer) # NOTE(jaypipes): log messages call open() in part of the # download path, so here, we just check that the last open() # call was done for the dst_path file descriptor. open_mock.assert_called_with(mock.sentinel.dst_path, 'wb') self.assertIsNone(res) writer.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) @mock.patch('nova.image.glance.GlanceImageServiceV2._get_transfer_module') @mock.patch('nova.image.glance.GlanceImageServiceV2.show') @mock.patch('nova.image.glance.GlanceImageServiceV2._safe_fsync') def test_download_direct_no_mod_fallback( self, fsync_mock, show_mock, get_tran_mock): # Test that we fall back to downloading to the dst_path # if no appropriate transfer module is found... # an exception. self.flags(allowed_direct_url_schemes=['funky'], group='glance') show_mock.return_value = { 'locations': [ { 'url': 'file:///files/image', 'metadata': mock.sentinel.loc_meta } ] } get_tran_mock.return_value = None client = mock.MagicMock() client.call.return_value = fake_glance_response([1, 2, 3]) ctx = mock.sentinel.ctx writer = mock.MagicMock() with mock.patch.object(six.moves.builtins, 'open') as open_mock: open_mock.return_value = writer service = glance.GlanceImageServiceV2(client) res = service.download(ctx, mock.sentinel.image_id, dst_path=mock.sentinel.dst_path) self.assertIsNone(res) show_mock.assert_called_once_with(ctx, mock.sentinel.image_id, include_locations=True) get_tran_mock.assert_called_once_with('file') client.call.assert_called_once_with( ctx, 2, 'data', args=(mock.sentinel.image_id,)) fsync_mock.assert_called_once_with(writer) # NOTE(jaypipes): log messages call open() in part of the # download path, so here, we just check that the last open() # call was done for the dst_path file descriptor. open_mock.assert_called_with(mock.sentinel.dst_path, 'wb') self.assertIsNone(res) writer.write.assert_has_calls( [ mock.call(1), mock.call(2), mock.call(3) ] ) writer.close.assert_called_once_with() ",5,256
openstack%2Fironic-python-agent~master~I96758527bbba9d8ec298867390b25be493f57789,openstack/ironic-python-agent,master,I96758527bbba9d8ec298867390b25be493f57789,Enforce running tox with correct python version based on env,MERGED,2019-12-23 08:57:58.000000000,2019-12-26 15:33:43.000000000,2019-12-26 15:32:07.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 08:57:58.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/96d46aa5bff240724428dfe2abc0fc1173131004', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I96758527bbba9d8ec298867390b25be493f57789\n'}]",0,700395,96d46aa5bff240724428dfe2abc0fc1173131004,9,4,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I96758527bbba9d8ec298867390b25be493f57789
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/95/700395/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,96d46aa5bff240724428dfe2abc0fc1173131004,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fironic-inspector~master~I72aa8695c058989b4a1aa62cbb5d5fda2ce348ad,openstack/ironic-inspector,master,I72aa8695c058989b4a1aa62cbb5d5fda2ce348ad,Add librsvg2* to bindep and bindep env,MERGED,2019-12-24 08:04:30.000000000,2019-12-26 15:33:29.000000000,2019-12-26 15:32:05.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-24 08:04:30.000000000', 'files': ['bindep.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/51e791e9548dfa470b3e774251a1a38af1b0c20c', 'message': 'Add librsvg2* to bindep and bindep env\n\n76cbd2dbbb131224e73a4b7c4019c378d2bbaf20 added the docs\nbuild requirement on sphinxcontrib-svg2pdfconverter which\nneeds the native rsvg-convert command. This change adds\nthe native package that provides that command to bindep.txt.\nAlso adds bindep env in tox.ini.\n\nChange-Id: I72aa8695c058989b4a1aa62cbb5d5fda2ce348ad\n'}]",0,700491,51e791e9548dfa470b3e774251a1a38af1b0c20c,12,4,1,10206,,,0,"Add librsvg2* to bindep and bindep env

76cbd2dbbb131224e73a4b7c4019c378d2bbaf20 added the docs
build requirement on sphinxcontrib-svg2pdfconverter which
needs the native rsvg-convert command. This change adds
the native package that provides that command to bindep.txt.
Also adds bindep env in tox.ini.

Change-Id: I72aa8695c058989b4a1aa62cbb5d5fda2ce348ad
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/91/700491/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'tox.ini']",2,51e791e9548dfa470b3e774251a1a38af1b0c20c,fix_doc_generation,"# This environment can be used to quickly validate that all needed system # packages required to successfully execute test targets are installed [testenv:bindep] # Do not install any requirements. We want this to be fast and work even if # system dependencies are missing, since it's used to tell you what system # dependencies are missing! This also means that bindep must be installed # separately, outside of the requirements files. deps = bindep commands = bindep test ",,14,0
openstack%2Fironic-lib~master~I63127c91c708af3a215fc653e43e2017c46dd7ad,openstack/ironic-lib,master,I63127c91c708af3a215fc653e43e2017c46dd7ad,Enforce running tox with correct python version based on env,MERGED,2019-12-23 10:19:20.000000000,2019-12-26 15:33:27.000000000,2019-12-26 15:32:06.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 10:19:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/b849d0ff4241cad4e63d0e2075496b1a61b7abae', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I63127c91c708af3a215fc653e43e2017c46dd7ad\n'}]",0,700408,b849d0ff4241cad4e63d0e2075496b1a61b7abae,8,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I63127c91c708af3a215fc653e43e2017c46dd7ad
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/08/700408/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b849d0ff4241cad4e63d0e2075496b1a61b7abae,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 1.8,2,1
openstack%2Fpython-ironicclient~master~I9731a9d99597f14b20e3ab7067ca5a060ec13835,openstack/python-ironicclient,master,I9731a9d99597f14b20e3ab7067ca5a060ec13835,Enforce running tox with correct python version based on env,MERGED,2019-12-23 09:05:14.000000000,2019-12-26 15:33:24.000000000,2019-12-26 15:32:08.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 09:05:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/369a2030b3705f50d93201ae50b66fe4b5652e48', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I9731a9d99597f14b20e3ab7067ca5a060ec13835\n'}]",0,700397,369a2030b3705f50d93201ae50b66fe4b5652e48,9,3,1,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I9731a9d99597f14b20e3ab7067ca5a060ec13835
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/97/700397/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,369a2030b3705f50d93201ae50b66fe4b5652e48,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fdevstack~master~I65b37114f826b4a45a60ea7d42480fd303867162,openstack/devstack,master,I65b37114f826b4a45a60ea7d42480fd303867162,Add librdkafka and confluent to Ubuntu,ABANDONED,2019-12-24 07:55:23.000000000,2019-12-26 15:27:00.000000000,,"[{'_account_id': 12404}, {'_account_id': 14107}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 07:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6b6c8d3e6669bb2be08c5a2e5fdda7aca71fa624', 'message': 'Add librdkafka-dev package\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}, {'number': 2, 'created': '2019-12-25 01:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e88b17fca288c3dd803fe75ea7bebb5cc1f75a57', 'message': 'Add librdkafka package for Ubuntu\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}, {'number': 3, 'created': '2019-12-25 01:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/06e1b93edeb5e53bf91e12dbfe94b37732d694f6', 'message': 'Add librdkafka package for Ubuntu\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}, {'number': 4, 'created': '2019-12-25 08:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4753bf1f7d3e714d1e0194e0ebc80ac0423de10b', 'message': 'Add librdkafka package for Ubuntu\n\nStory: #2007053\nTask: #37895\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}, {'number': 5, 'created': '2019-12-25 14:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/968c1f342b23011f1660e610aa720fd1bc5223e7', 'message': 'Add librdkafka when enable ceilometer in Ubuntu\n\nStory: #2007053\nTask: #37895\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}, {'number': 6, 'created': '2019-12-25 16:12:30.000000000', 'files': ['files/debs/general', 'tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d0f401813fe35146ee3ae49a8ba8f98285db1a00', 'message': 'Add librdkafka and confluent to Ubuntu\n\nStory: #2007053\nTask: #37895\n\nChange-Id: I65b37114f826b4a45a60ea7d42480fd303867162\n'}]",0,700490,d0f401813fe35146ee3ae49a8ba8f98285db1a00,16,4,6,12404,,,0,"Add librdkafka and confluent to Ubuntu

Story: #2007053
Task: #37895

Change-Id: I65b37114f826b4a45a60ea7d42480fd303867162
",git fetch https://review.opendev.org/openstack/devstack refs/changes/90/700490/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,6b6c8d3e6669bb2be08c5a2e5fdda7aca71fa624,story/2007053, # Ensure librdkafka-dev is installed # -------------------------- is_package_installed librdkafka-dev || install_package librdkafka-dev ,,5,0
openstack%2Fneutron~master~I37da4025b93c8032164b0c3f12f400ed0d77c1ab,openstack/neutron,master,I37da4025b93c8032164b0c3f12f400ed0d77c1ab,Remove locks from privileged ip_lib module,MERGED,2019-12-13 09:22:33.000000000,2019-12-26 14:56:43.000000000,2019-12-26 14:54:54.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-13 09:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/59bc4ee89385434be61c1a3b17da9832f507b49d', 'message': ""Remove locks from privileged ip_lib module\n\nBecause of issue with pyroute2.NetNS objects running in\nthreads we needed to lock privileged ip_lib functions\nwhich are using this object to workaround the problem.\nFor details please check [1].\n\nThis problem was solved in pyroute 0.5.5. Now as we are using\n0.5.7 we don't need those locks anymore.\n\n[1] https://bugs.launchpad.net/neutron/+bug/1811515\n\nChange-Id: I37da4025b93c8032164b0c3f12f400ed0d77c1ab\n""}, {'number': 2, 'created': '2019-12-13 09:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a66144b619fdcfcce376b736e2b155e3b078a72e', 'message': ""Remove locks from privileged ip_lib module\n\nBecause of issue with pyroute2.NetNS objects running in\nthreads we needed to lock privileged ip_lib functions\nwhich are using this object to workaround the problem.\nFor details please check [1].\n\nThis problem was solved in pyroute 0.5.5. Now as we are using\n0.5.7 we don't need those locks anymore.\n\n[1] https://bugs.launchpad.net/neutron/+bug/1811515\n\nChange-Id: I37da4025b93c8032164b0c3f12f400ed0d77c1ab\n""}, {'number': 3, 'created': '2019-12-13 15:44:58.000000000', 'files': ['neutron/privileged/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/364fc1413bf042e809fc1a688ab9ed667598d51b', 'message': ""Remove locks from privileged ip_lib module\n\nBecause of issue with pyroute2.NetNS objects running in\nthreads we needed to lock privileged ip_lib functions\nwhich are using this object to workaround the problem.\nFor details please check [1].\n\nThis problem was solved in pyroute 0.5.5. Now as we are using\n0.5.7 we don't need those locks anymore.\n\n[1] https://bugs.launchpad.net/neutron/+bug/1811515\n\nChange-Id: I37da4025b93c8032164b0c3f12f400ed0d77c1ab\n""}]",4,698854,364fc1413bf042e809fc1a688ab9ed667598d51b,42,8,3,11975,,,0,"Remove locks from privileged ip_lib module

Because of issue with pyroute2.NetNS objects running in
threads we needed to lock privileged ip_lib functions
which are using this object to workaround the problem.
For details please check [1].

This problem was solved in pyroute 0.5.5. Now as we are using
0.5.7 we don't need those locks anymore.

[1] https://bugs.launchpad.net/neutron/+bug/1811515

Change-Id: I37da4025b93c8032164b0c3f12f400ed0d77c1ab
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/698854/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/privileged/agent/linux/ip_lib.py'],1,59bc4ee89385434be61c1a3b17da9832f507b49d,bump-pyroute,,"@lockutils.synchronized(""privileged-ip-lib"") # NOTE(slaweq): Because of issue with pyroute2.NetNS objects running in threads # we need to lock this function to workaround this issue. # For details please check https://bugs.launchpad.net/neutron/+bug/1811515 def _sync(input_func): # NOTE(ralonsoh): this is needed because PY2 functools.update_wrapper do # not handle correctly partial functions (nested decorators). This could be # removed once we abandon support for PY2. if six.PY2 and isinstance(input_func, functools.partial): for asig in functools.WRAPPER_ASSIGNMENTS: setattr(input_func, asig, '') @six.wraps(input_func) def sync_inner(*args, **kwargs): return input_func(*args, **kwargs) return sync_inner @_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync@_sync",0,41
openstack%2Fmistral~master~I772651e33eada4a5c2149bfa867095c277eddeed,openstack/mistral,master,I772651e33eada4a5c2149bfa867095c277eddeed,Add coordination support for devstack,MERGED,2019-12-24 11:40:51.000000000,2019-12-26 13:27:38.000000000,2019-12-26 13:26:23.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-12-24 11:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f067fd459bfdea02d5634542f71f236239f2304f', 'message': 'Add coordination support for devstack\n\nThis way we can test the service api later on gate\n\nChange-Id: I772651e33eada4a5c2149bfa867095c277eddeed\n'}, {'number': 2, 'created': '2019-12-25 08:45:30.000000000', 'files': ['mistral/event_engine/event_engine_server.py', 'mistral/api/app.py', 'devstack/plugin.sh', 'mistral/service/coordination.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/d838607b2f2d112e867ce50dfae397e8eb0af633', 'message': 'Add coordination support for devstack\n\nThis way we can test the service api later on gate\n\nIn order to use etcd in gate few changes were made:\n* All identifiers must be byte type (group type, member id)\n* Tooz has a built-in mechanizm for heartbeat no need to implement it\n* Need to use eventlet monkey patch since etcd client uses blocking\n  methods\n* Services name must be identical to LAUNCH_OPTIONS used in cli\n* Gate coordination url should be define with a schema of etcd+http\n  which is the etcd gateway and works better then just etcd\n\nChange-Id: I772651e33eada4a5c2149bfa867095c277eddeed\n'}]",6,700507,d838607b2f2d112e867ce50dfae397e8eb0af633,19,4,2,19134,,,0,"Add coordination support for devstack

This way we can test the service api later on gate

In order to use etcd in gate few changes were made:
* All identifiers must be byte type (group type, member id)
* Tooz has a built-in mechanizm for heartbeat no need to implement it
* Need to use eventlet monkey patch since etcd client uses blocking
  methods
* Services name must be identical to LAUNCH_OPTIONS used in cli
* Gate coordination url should be define with a schema of etcd+http
  which is the etcd gateway and works better then just etcd

Change-Id: I772651e33eada4a5c2149bfa867095c277eddeed
",git fetch https://review.opendev.org/openstack/mistral refs/changes/07/700507/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/event_engine/event_engine_server.py', 'mistral/api/app.py', 'devstack/plugin.sh', 'mistral/service/coordination.py']",4,f067fd459bfdea02d5634542f71f236239f2304f,coordination, self._my_id = six.b(my_id or utils.get_process_identifier()) self._coordinator.start(start_heart=True) join_req = self._coordinator.join_group(six.b(group_id)) create_grp_req = self._coordinator.create_group(six.b(group_id)) self._coordinator.leave_group(six.b(group_id)) get_members_req = self._coordinator.get_members(six.b(group_id)),"from oslo_service import threadgroup self._my_id = my_id or utils.get_process_identifier() self._coordinator.start() def heartbeat(self): if not self.is_active(): # Re-connect. self.start() if not self.is_active(): LOG.debug(""Coordination backend didn't start."") return try: self._coordinator.heartbeat() except tooz.coordination.ToozError as e: LOG.exception('Error sending a heartbeat to coordination ' 'backend. %s', six.text_type(e)) self._started = False join_req = self._coordinator.join_group(group_id) create_grp_req = self._coordinator.create_group(group_id) self._coordinator.leave_group(group_id) get_members_req = self._coordinator.get_members(group_id) self._tg = None self._tg = threadgroup.ThreadGroup() self._tg.add_timer( cfg.CONF.coordination.heartbeat_interval, service_coordinator.heartbeat ) self._tg.stop() ",16,35
openstack%2Fpython-ironic-inspector-client~master~I294cc2acf827a813f9ccc9794a640e70fe5fc126,openstack/python-ironic-inspector-client,master,I294cc2acf827a813f9ccc9794a640e70fe5fc126,Add bindep env and fix pdf doc generation,MERGED,2019-12-24 08:18:09.000000000,2019-12-26 12:38:14.000000000,2019-12-26 12:36:57.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-24 08:18:09.000000000', 'files': ['bindep.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/00a771be12c4fa8148007357abdaf3b2665f6c9f', 'message': 'Add bindep env and fix pdf doc generation\n\nd95a4cd30fd73c47cb5798a5eb474eedac728e00 added the docs\nbuild requirement on sphinxcontrib-svg2pdfconverter which\nneeds the native rsvg-convert command. This change adds\nthe native package that provides that command to bindep.txt.\nAlso adds bindep env in tox.ini\n\nChange-Id: I294cc2acf827a813f9ccc9794a640e70fe5fc126\n'}]",0,700496,00a771be12c4fa8148007357abdaf3b2665f6c9f,9,4,1,10206,,,0,"Add bindep env and fix pdf doc generation

d95a4cd30fd73c47cb5798a5eb474eedac728e00 added the docs
build requirement on sphinxcontrib-svg2pdfconverter which
needs the native rsvg-convert command. This change adds
the native package that provides that command to bindep.txt.
Also adds bindep env in tox.ini

Change-Id: I294cc2acf827a813f9ccc9794a640e70fe5fc126
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/96/700496/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'tox.ini']",2,00a771be12c4fa8148007357abdaf3b2665f6c9f,fix_doc_generation," # This environment can be used to quickly validate that all needed system # packages required to successfully execute test targets are installed [testenv:bindep] # Do not install any requirements. We want this to be fast and work even if # system dependencies are missing, since it's used to tell you what system # dependencies are missing! This also means that bindep must be installed # separately, outside of the requirements files. deps = bindep commands = bindep test",,13,0
openstack%2Fironic~master~I55d96b6bd0c1cb990bf0eb55a95602f62c7506c7,openstack/ironic,master,I55d96b6bd0c1cb990bf0eb55a95602f62c7506c7,Fix invalid assertIsNone statements,MERGED,2019-12-26 08:26:59.000000000,2019-12-26 12:36:13.000000000,2019-12-26 12:10:44.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-26 08:26:59.000000000', 'files': ['ironic/tests/unit/drivers/modules/drac/test_raid.py', 'ironic/tests/unit/api/controllers/v1/test_allocation.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b091790861c72747e23027547b7f20a8462cfa3e', 'message': ""Fix invalid assertIsNone statements\n\nThis is to fix invalid assertIsNone statements of:\n* self.assertIsNone(None, result['owner'])\n* self.assertIsNone(None, return_value)\n\nChange-Id: I55d96b6bd0c1cb990bf0eb55a95602f62c7506c7\n""}]",0,700600,b091790861c72747e23027547b7f20a8462cfa3e,10,5,1,20190,,,0,"Fix invalid assertIsNone statements

This is to fix invalid assertIsNone statements of:
* self.assertIsNone(None, result['owner'])
* self.assertIsNone(None, return_value)

Change-Id: I55d96b6bd0c1cb990bf0eb55a95602f62c7506c7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/00/700600/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/drac/test_raid.py', 'ironic/tests/unit/api/controllers/v1/test_allocation.py']",2,b091790861c72747e23027547b7f20a8462cfa3e,assertIsNone, self.assertIsNone(result['owner'])," self.assertIsNone(None, result['owner'])",2,2
openstack%2Fvirtualbmc~master~I35ac19308337f9fb603efa5b8a3dc97aea234cbc,openstack/virtualbmc,master,I35ac19308337f9fb603efa5b8a3dc97aea234cbc,Remove version check for encoding,MERGED,2019-12-12 11:48:08.000000000,2019-12-26 12:31:10.000000000,2019-12-26 12:30:00.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-12 11:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/8ba25845a7874d4e72d20eacba7fd7234b15faa0', 'message': 'Remove version check for encoding\n\nVirtualbmc is now Python 3 only, encoding for ET can be set to\nunicode only.\n\nChange-Id: I35ac19308337f9fb603efa5b8a3dc97aea234cbc\n'}, {'number': 2, 'created': '2019-12-12 13:41:59.000000000', 'files': ['virtualbmc/vbmc.py'], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/3ef73c8d8fb21888d1666f17a6bc06ba455f9e83', 'message': 'Remove version check for encoding\n\nVirtualbmc is now Python 3 only, encoding for ET can be set to\nunicode only.\nRemoving import sys from vbmc.py as it was used only for that\ncheck.\n\nChange-Id: I35ac19308337f9fb603efa5b8a3dc97aea234cbc\n'}]",0,698701,3ef73c8d8fb21888d1666f17a6bc06ba455f9e83,12,5,2,23851,,,0,"Remove version check for encoding

Virtualbmc is now Python 3 only, encoding for ET can be set to
unicode only.
Removing import sys from vbmc.py as it was used only for that
check.

Change-Id: I35ac19308337f9fb603efa5b8a3dc97aea234cbc
",git fetch https://review.opendev.org/openstack/virtualbmc refs/changes/01/698701/1 && git format-patch -1 --stdout FETCH_HEAD,['virtualbmc/vbmc.py'],1,8ba25845a7874d4e72d20eacba7fd7234b15faa0,py3-only," conn.defineXML(ET.tostring(tree, encoding=""unicode""))"," # conn.defineXML can't take bytes but # in py3 ET.tostring returns bytes unless ""unicode"" # in py2 ""unicode"" is unknown so specify ""utf8"" instead enc = sys.version_info[0] < 3 and ""utf8"" or ""unicode"" conn.defineXML(ET.tostring(tree, encoding=enc))",1,5
openstack%2Fironic~master~I142774a28ebb200c2e6212f41c5734d578c5abea,openstack/ironic,master,I142774a28ebb200c2e6212f41c5734d578c5abea,Enforce running tox with correct python version based on env,MERGED,2019-12-19 11:47:00.000000000,2019-12-26 12:12:33.000000000,2019-12-26 12:10:42.000000000,"[{'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-19 11:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/28396ce0b49145178afcec9fe23addbbe895128f', 'message': 'Enfore running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0.\n\nChange-Id: I142774a28ebb200c2e6212f41c5734d578c5abea\n'}, {'number': 2, 'created': '2019-12-19 11:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f349769ff2b2fadedffe1a1838992f9f2ecfa19d', 'message': 'Enfore running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I142774a28ebb200c2e6212f41c5734d578c5abea\n'}, {'number': 3, 'created': '2019-12-19 11:52:55.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f0f3cb840ff6ae81cd0f57bc531dbbcf477c43c0', 'message': 'Enforce running tox with correct python version based on env\n\nSince removing support for Python 2, we changed the basepython\nvalue to 3.\nThis means that all the tox tests run with the default python\nversion available in the system.\nThis is not quite correct when running on environment such as\npy36, py37 or py38, since they imply running with different\nPython versions based on the environment.\nTo enforce the correct version we need to add the option\nignore_basepython_conflict available since tox 3.1.0 [0].\n\n[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict\n\nChange-Id: I142774a28ebb200c2e6212f41c5734d578c5abea\n'}]",0,699960,f0f3cb840ff6ae81cd0f57bc531dbbcf477c43c0,12,5,3,23851,,,0,"Enforce running tox with correct python version based on env

Since removing support for Python 2, we changed the basepython
value to 3.
This means that all the tox tests run with the default python
version available in the system.
This is not quite correct when running on environment such as
py36, py37 or py38, since they imply running with different
Python versions based on the environment.
To enforce the correct version we need to add the option
ignore_basepython_conflict available since tox 3.1.0 [0].

[0] https://tox.readthedocs.io/en/latest/config.html#conf-ignore_basepython_conflict

Change-Id: I142774a28ebb200c2e6212f41c5734d578c5abea
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/699960/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,28396ce0b49145178afcec9fe23addbbe895128f,tox-enforce-correct-pyver,minversion = 3.1.0ignore_basepython_conflict=true,minversion = 2.0,2,1
openstack%2Fproject-config~master~I16edd504036a1bc0f9510db50b94a4eaa0dc7518,openstack/project-config,master,I16edd504036a1bc0f9510db50b94a4eaa0dc7518,Remove devstack-plugin-sheepdog,MERGED,2019-05-21 16:49:09.000000000,2019-12-26 10:19:29.000000000,2019-12-26 10:19:29.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-21 16:49:09.000000000', 'files': ['gerrit/acls/x/devstack-plugin-sheepdog.config', 'zuul.d/projects.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ca79d057ff15296bd639c1647142aff5287dbea4', 'message': 'Remove devstack-plugin-sheepdog\n\nThis is step 4 in retiring the devstack-plugin-sheepdog project.\n\nDepends-on: https://review.opendev.org/#/c/660453/\nChange-Id: I16edd504036a1bc0f9510db50b94a4eaa0dc7518\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,660454,ca79d057ff15296bd639c1647142aff5287dbea4,10,4,1,11904,,,0,"Remove devstack-plugin-sheepdog

This is step 4 in retiring the devstack-plugin-sheepdog project.

Depends-on: https://review.opendev.org/#/c/660453/
Change-Id: I16edd504036a1bc0f9510db50b94a4eaa0dc7518
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/660454/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/x/devstack-plugin-sheepdog.config', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml']",4,ca79d057ff15296bd639c1647142aff5287dbea4,sheepdog,, - x/devstack-plugin-sheepdog,2,21
openstack%2Fhorizon~master~I545b6c666d13d39cf5287ccc7c972dc746faf2fb,openstack/horizon,master,I545b6c666d13d39cf5287ccc7c972dc746faf2fb,Deprecate exceptions.check_message,MERGED,2019-04-15 00:37:20.000000000,2019-12-26 08:39:32.000000000,2019-12-26 08:37:45.000000000,"[{'_account_id': 841}, {'_account_id': 19521}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}, {'_account_id': 30250}]","[{'number': 1, 'created': '2019-04-15 00:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/570b209a3458d68e076f5501a892ae6178f2597c', 'message': 'Error handling: Deprecate check_message in favor of handle\n\nChange-Id: I545b6c666d13d39cf5287ccc7c972dc746faf2fb\nCloses-Bug: 1339885\n'}, {'number': 2, 'created': '2019-04-15 00:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9493306bc6d7fec2ed44d3c0001253ab89e9f84f', 'message': 'Error handling: Deprecate check_message in favor of handle\n\nBecause in Horizon we already have a centralized place for handling exceptions.\n\nWe should use horizon/exceptions.py(249)handle() instead of old\nhorizon/exceptions.py(96)check_message().\n\nChange-Id: I545b6c666d13d39cf5287ccc7c972dc746faf2fb\nCloses-Bug: 1339885\n'}, {'number': 3, 'created': '2019-04-15 04:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3afbcc6ae6bf402bf40cac3114906a196cfd619a', 'message': 'Error handling: Remove check_message in favor of handle\n\nBecause in Horizon we already have a centralized place for handling exceptions.\n\nWe should use horizon/exceptions.py(249)handle() instead of old\nhorizon/exceptions.py(96)check_message().\n\nChange-Id: I545b6c666d13d39cf5287ccc7c972dc746faf2fb\nCloses-Bug: 1339885\n'}, {'number': 4, 'created': '2019-12-23 11:12:52.000000000', 'files': ['openstack_dashboard/dashboards/admin/info/tabs.py', 'horizon/exceptions.py', 'requirements.txt', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/dashboards/admin/aggregates/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/31f7fc6bb24995376bb74d7de6866f5bf2b322c8', 'message': ""Deprecate exceptions.check_message\n\nexceptions.handle() is used in most cases consistently.\ncheck_message() is a legacy which was introduced when exceptions\nwere not well classified. exceptions.handle() should cover all\ncommon error scenarios and there is no role played by check_messages().\nLet's clean up its usage and deprecate it for the future removal.\n\nCo-Authored-By: Akihiro Motoki <amotoki@gmail.com>\nChange-Id: I545b6c666d13d39cf5287ccc7c972dc746faf2fb\nCloses-Bug: #1339885\n""}]",4,652427,31f7fc6bb24995376bb74d7de6866f5bf2b322c8,27,6,4,19521,,,0,"Deprecate exceptions.check_message

exceptions.handle() is used in most cases consistently.
check_message() is a legacy which was introduced when exceptions
were not well classified. exceptions.handle() should cover all
common error scenarios and there is no role played by check_messages().
Let's clean up its usage and deprecate it for the future removal.

Co-Authored-By: Akihiro Motoki <amotoki@gmail.com>
Change-Id: I545b6c666d13d39cf5287ccc7c972dc746faf2fb
Closes-Bug: #1339885
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/652427/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/info/tabs.py', 'horizon/exceptions.py', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/dashboards/project/cgroups/workflows.py', 'openstack_dashboard/dashboards/admin/aggregates/workflows.py', 'openstack_dashboard/dashboards/project/volume_groups/workflows.py']",6,570b209a3458d68e076f5501a892ae6178f2597c,bug/1339885," exceptions.handle(self.request, msg)"," exceptions.check_message([""Connection"", ""refused""], msg)",5,24
openstack%2Ftacker~master~I39c0ca534ede603d32c220ddd0b850ff5f16431c,openstack/tacker,master,I39c0ca534ede603d32c220ddd0b850ff5f16431c,Fix devstack installation error in FT,ABANDONED,2019-12-25 05:49:16.000000000,2019-12-26 08:08:10.000000000,,"[{'_account_id': 22348}, {'_account_id': 26588}]","[{'number': 1, 'created': '2019-12-25 05:49:16.000000000', 'files': ['playbooks/devstack/pre.yaml', 'roles/install-librdkafka/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/225d2b7d57c45cd5b85a77adba5793f59347e3e6', 'message': 'Fix devstack installation error in FT\n\nThis patch fixes a bug[1] that devstack installation failed\ndue to a failed installation of the library(confluent-kafka)\nrequired by Ceilometer.\n\nThe bug occurs because patch[2] has been merged,\nand librdkafka(v1.3.0) required by confluent-kafka(v1.3.0)\nis not installed.\nNOTE: apt command installs v0.11.3, so build install.\n\n[1]\nhttp://paste.openstack.org/show/787901/\n\n[2]\nhttps://opendev.org/openstack/requirements/commit/c99ab09bc44818b92fe86842f98f564d54783982\n\nChange-Id: I39c0ca534ede603d32c220ddd0b850ff5f16431c\n'}]",0,700537,225d2b7d57c45cd5b85a77adba5793f59347e3e6,4,2,1,31072,,,0,"Fix devstack installation error in FT

This patch fixes a bug[1] that devstack installation failed
due to a failed installation of the library(confluent-kafka)
required by Ceilometer.

The bug occurs because patch[2] has been merged,
and librdkafka(v1.3.0) required by confluent-kafka(v1.3.0)
is not installed.
NOTE: apt command installs v0.11.3, so build install.

[1]
http://paste.openstack.org/show/787901/

[2]
https://opendev.org/openstack/requirements/commit/c99ab09bc44818b92fe86842f98f564d54783982

Change-Id: I39c0ca534ede603d32c220ddd0b850ff5f16431c
",git fetch https://review.opendev.org/openstack/tacker refs/changes/37/700537/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/devstack/pre.yaml', 'roles/install-librdkafka/tasks/main.yaml']",2,225d2b7d57c45cd5b85a77adba5793f59347e3e6,tacker-functional,"- name: Install librdkafka v1.3.0 shell: sudo bash -c ""wget https://github.com/edenhill/librdkafka/archive/v1.3.0.tar.gz && tar xvzf v1.3.0.tar.gz && cd librdkafka-1.3.0/ && ./configure && make && make install && ldconfig"" ",,5,0
openstack%2Fcinder~master~I3be3c99f9317726fa3182f750b27690da3cdab83,openstack/cinder,master,I3be3c99f9317726fa3182f750b27690da3cdab83,Add 'volume_attachment' to volume expected attributes,MERGED,2018-08-20 10:51:29.000000000,2019-12-26 07:37:01.000000000,2018-10-04 06:24:51.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23083}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-08-20 10:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/18551720456cd52fe1af3393a23ee9227d4860ee', 'message': ""Add 'volume_attachment' to volume expected attributes\n\n'volume_attachment' is a frequently used attribute when\nlisting volumes inside or outside cinder, considering\nit already has been loaded from database [1], this patch\nadds it to volume's expected attributes to improve\nperformance.\n\n[1]: https://github.com/openstack/cinder/blob/0652085f23ba22f0a6335726d9f0f7018d4662ea/cinder/db/sqlalchemy/api.py#L1926\n\nChange-Id: I3be3c99f9317726fa3182f750b27690da3cdab83\n""}, {'number': 2, 'created': '2018-08-21 09:06:38.000000000', 'files': ['cinder/objects/volume.py', 'cinder/tests/unit/keymgr/test_migration.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/af66bce67638626e9c32f1ab75d1d67c8984b1b6', 'message': ""Add 'volume_attachment' to volume expected attributes\n\n'volume_attachment' is a frequently used attribute when\nlisting volumes inside or outside cinder, considering\nit already has been loaded from database [1], this patch\nadds it to volume's expected attributes to improve\nperformance.\n\n[1]: https://github.com/openstack/cinder/blob/0652085f23ba22f0a6335726d9f0f7018d4662ea/cinder/db/sqlalchemy/api.py#L1926\n\nChange-Id: I3be3c99f9317726fa3182f750b27690da3cdab83\n""}]",2,593594,af66bce67638626e9c32f1ab75d1d67c8984b1b6,78,38,2,23083,,,0,"Add 'volume_attachment' to volume expected attributes

'volume_attachment' is a frequently used attribute when
listing volumes inside or outside cinder, considering
it already has been loaded from database [1], this patch
adds it to volume's expected attributes to improve
performance.

[1]: https://github.com/openstack/cinder/blob/0652085f23ba22f0a6335726d9f0f7018d4662ea/cinder/db/sqlalchemy/api.py#L1926

Change-Id: I3be3c99f9317726fa3182f750b27690da3cdab83
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/593594/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/objects/volume.py'],1,18551720456cd52fe1af3393a23ee9227d4860ee,performance/volume_get_all," expected_attrs = ['metadata', 'volume_type', 'volume_attachment']"," expected_attrs = ['metadata', 'volume_type']",1,1
openstack%2Fheat~master~I27d2e499b74af82277e7ab998e53500dc47f6f5b,openstack/heat,master,I27d2e499b74af82277e7ab998e53500dc47f6f5b,[WIP]Migrate heat functional test to zuulv3 native,ABANDONED,2018-04-20 11:25:04.000000000,2019-12-26 07:19:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-04-20 11:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb66af241c7829ddf50d3b1a236355c2901fc2ea', 'message': '[WIP]Migrate heat functional test to zuulv3 native\n\nChange-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b\n'}, {'number': 2, 'created': '2018-04-20 11:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d42e6986488c467959b6e7096e71ab0346f367f3', 'message': '[WIP]Migrate heat functional test to zuulv3 native\n\nChange-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b\n'}, {'number': 3, 'created': '2018-04-20 12:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ca8ef481dd0ea25cc5b116b163295d10d76de74a', 'message': '[WIP]Migrate heat functional test to zuulv3 native\n\nChange-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b\n'}, {'number': 4, 'created': '2018-04-20 14:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c311acd407c1150c7ed8a845deaa80b2d57dd3c6', 'message': '[WIP]Migrate heat functional test to zuulv3 native\n\nChange-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b\n'}, {'number': 5, 'created': '2018-04-20 15:44:19.000000000', 'files': ['playbooks/devstack/functional/post.yaml', 'playbooks/devstack/functional/run.yaml', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/27f8a3671eb5cc93fb7b188d86c18c43bf9e8433', 'message': '[WIP]Migrate heat functional test to zuulv3 native\n\nChange-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b\n'}]",0,563082,27f8a3671eb5cc93fb7b188d86c18c43bf9e8433,11,1,5,12404,,,0,"[WIP]Migrate heat functional test to zuulv3 native

Change-Id: I27d2e499b74af82277e7ab998e53500dc47f6f5b
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/563082/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/devstack/functional/run.yaml', '.zuul.yaml']",2,cb66af241c7829ddf50d3b1a236355c2901fc2ea,zuulv3-migrate," parent: devstack-tempest #test_matrix_configs: [neutron] default should not needs tox_environment: KEEP_LOCALRC: 1 DISABLE_CONVERGENCE: false #PYTHONUNBUFFERED: 'true' #DEVSTACK_GATE_TEMPEST_NOTESTS: 1 #DEVSTACK_GATE_EXERCISES: 0 #DEVSTACK_GATE_INSTALL_TESTONLY: 1 tox_envlist: all tempest_test_regex: heat devstack_localrc: TEMPEST_PLUGINS: ""'{{ ansible_user_dir }}/src/git.openstack.org/openstack/heat-tempest-plugin'"" devstack_services: rabbit: true tempest: true mysql: true dstat: true key: true n-api: true n-api-meta: true n-cpu: true n-cond: true n-sch: true n-crt: true placement-api: true placement-client: true g-api: true g-reg: true c-sch: true c-api: true c-vol: true c-bak: true neutron-api: true neutron-dhcp: true neutron-metadata-agent: true neutron-agent: true neutron-l3: true neutron-trunk: true # enabling lbaas plugin does not enable the lbaasv2 service, explicitly enable it neutron-lbaasv2: true q-lbaasv2: true octavia: true o-cw: true o-hk: true o-hm: true o-api: true devstack_plugins: aodh: https://git.openstack.org/openstack/aodh barbican: https://git.openstack.org/openstack/barbican ceilometer: https://git.openstack.org/openstack/ceilometer heat: https://git.openstack.org/openstack/heat neutron: https://git.openstack.org/openstack/neutron neutron-lbaas: https://git.openstack.org/openstack/neutron-lbaas octavia: https://git.openstack.org/openstack/octavia zaqar: https://git.openstack.org/openstack/zaqar - job: name: heat-functional-devstack-py27 parent: heat-functional-devstack-base vars: tox_envlist: py27 devstack_services: s-proxy: true s-object: true s-container: true s-account: true parent: heat-functional-devstack-py27 vars: tox_environment: DISABLE_CONVERGENCE: true parent: heat-functional-devstack-py27 parent: heat-functional-devstack-py27 required-projects: - openstack/devstack-plugin-amqp1 - openstack/oslo.messaging vars: tox_environment: AMQP1_SERVICE: qpid-hybrid CELLSV2_SETUP: singleconductor devstack_plugins: devstack-plugin-amqp1: https://git.openstack.org/openstack/devstack-plugin-amqp1 parent: heat-functional-devstack-py27 vars: tox_environment: HEAT_USE_MOD_WSGI: False tox_envlist: py35 parent: heat-functional-devstack-py27 tox_environment: ENABLE_IDENTITY_V2: False", parent: legacy-dsvm-base disable_convergence: 'false' sql: mysql use_amqp1: 0 use_apache: 1 use_python3: 0 use_identity_v3_only: 0 branch_override: default parent: heat-functional-devstack-base vars: disable_convergence: 'true' parent: heat-functional-devstack-base parent: heat-functional-devstack-base vars: use_amqp1: 1 parent: heat-functional-devstack-base vars: use_apache: 0 use_python3: 1 parent: heat-functional-devstack-base vars: use_identity_v3_only: 1 branch_override: default,89,113
openstack%2Fironic~master~Ief712996e5880e149bbeecc93dc1be5b886653ac,openstack/ironic,master,Ief712996e5880e149bbeecc93dc1be5b886653ac,Add librsvg2* to bindep,MERGED,2019-12-23 12:04:54.000000000,2019-12-26 06:47:37.000000000,2019-12-23 16:10:58.000000000,"[{'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-23 12:04:54.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/968f7876f2490f1c220670474488df0032c00feb', 'message': 'Add librsvg2* to bindep\n\n9aab525d4546931f81bed665261278e7fc5bbeb4 added the docs\nbuild requirement on sphinxcontrib-svg2pdfconverter which\nneeds the native rsvg-convert command. This change adds\nthe native package that provides that command to bindep.txt.\n\nChange-Id: Ief712996e5880e149bbeecc93dc1be5b886653ac\n'}]",1,700431,968f7876f2490f1c220670474488df0032c00feb,12,5,1,10206,,,0,"Add librsvg2* to bindep

9aab525d4546931f81bed665261278e7fc5bbeb4 added the docs
build requirement on sphinxcontrib-svg2pdfconverter which
needs the native rsvg-convert command. This change adds
the native package that provides that command to bindep.txt.

Change-Id: Ief712996e5880e149bbeecc93dc1be5b886653ac
",git fetch https://review.opendev.org/openstack/ironic refs/changes/31/700431/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,968f7876f2490f1c220670474488df0032c00feb,,# libsrvg2 is needed for sphinxcontrib-svg2pdfconverter in docs builds. librsvg2-tools [doc platform:rpm] librsvg2-bin [doc platform:dpkg],,3,0
openstack%2Fheat~master~If9cee84403f2a6f32b548413b22228c78a249d0d,openstack/heat,master,If9cee84403f2a6f32b548413b22228c78a249d0d,Move to use py3 default for zuul jobs,ABANDONED,2019-06-25 09:04:42.000000000,2019-12-26 06:42:39.000000000,,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-25 09:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89d6d3e88ea4f736393e648857d1672bc3b785e9', 'message': 'Move to use py3 default for zuul jobs\n\nchange zuul test jobs from py2 to py3. Change the original py3 job\nto py2.\n\nChange-Id: If9cee84403f2a6f32b548413b22228c78a249d0d\n'}, {'number': 2, 'created': '2019-06-26 13:05:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/cd35d038b0b2f219c2977aa5962e4ce0efc29bd9', 'message': 'Move to use py3 default for zuul jobs\n\nchange zuul test jobs from py2 to py3. Change the original py3 job\nto py2.\n\nChange-Id: If9cee84403f2a6f32b548413b22228c78a249d0d\n'}]",0,667293,cd35d038b0b2f219c2977aa5962e4ce0efc29bd9,11,3,2,12404,,,0,"Move to use py3 default for zuul jobs

change zuul test jobs from py2 to py3. Change the original py3 job
to py2.

Change-Id: If9cee84403f2a6f32b548413b22228c78a249d0d
",git fetch https://review.opendev.org/openstack/heat refs/changes/93/667293/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,89d6d3e88ea4f736393e648857d1672bc3b785e9,py3-default, use_python3: 1 name: heat-functional-convg-mysql-lbaasv2-py2 use_python3: 0, use_python3: 0 name: heat-functional-convg-mysql-lbaasv2-py3 use_python3: 1,3,3
openstack%2Frpm-packaging-tools~master~Ibf15e5371f7adb232f3f6d4e6fa3df5f3dcbf736,openstack/rpm-packaging-tools,master,Ibf15e5371f7adb232f3f6d4e6fa3df5f3dcbf736,update GERRIT_HOST url.,MERGED,2019-12-18 06:42:42.000000000,2019-12-26 06:35:50.000000000,2019-12-26 06:35:50.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 06:42:42.000000000', 'files': ['tools/rpm-packaging-status.py'], 'web_link': 'https://opendev.org/openstack/rpm-packaging-tools/commit/003d4a009ac1c96a740df35732ccb20cfc3aae03', 'message': 'update GERRIT_HOST url.\n\nChange-Id: Ibf15e5371f7adb232f3f6d4e6fa3df5f3dcbf736\n'}]",0,699565,003d4a009ac1c96a740df35732ccb20cfc3aae03,7,3,1,30717,,,0,"update GERRIT_HOST url.

Change-Id: Ibf15e5371f7adb232f3f6d4e6fa3df5f3dcbf736
",git fetch https://review.opendev.org/openstack/rpm-packaging-tools refs/changes/65/699565/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/rpm-packaging-status.py'],1,003d4a009ac1c96a740df35732ccb20cfc3aae03,,GERRIT_HOST = 'https://review.opendev.org',GERRIT_HOST = 'https://review.openstack.org',1,1
openstack%2Frpm-packaging~stable%2Frocky~I2c9377273d983538d965a403103648d1d1afadb5,openstack/rpm-packaging,stable/rocky,I2c9377273d983538d965a403103648d1d1afadb5,Add the vmware-nsx-tempest-plugin package,MERGED,2019-09-20 14:53:41.000000000,2019-12-26 06:35:40.000000000,2019-12-26 06:35:40.000000000,"[{'_account_id': 6593}, {'_account_id': 6876}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-20 14:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/56aaa2f2449503952ffd8f113cd00381caa4850a', 'message': 'Add the vmware-nsx-tempest-plugin package\n\nChange-Id: I2c9377273d983538d965a403103648d1d1afadb5\n(cherry picked from commit 9f89b53753b183df06739263609e190dc76f9b2b)\n'}, {'number': 2, 'created': '2019-09-20 15:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/95347fa2bbaad5ee87567e31247e9a38d8be7732', 'message': 'Add the vmware-nsx-tempest-plugin package\n\nChange-Id: I2c9377273d983538d965a403103648d1d1afadb5\n(cherry picked from commit 9f89b53753b183df06739263609e190dc76f9b2b)\n'}, {'number': 3, 'created': '2019-09-20 16:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/bd8ba05894287f63b0a34f89578f290e975b02ab', 'message': 'Add the vmware-nsx-tempest-plugin package\n\nChange-Id: I2c9377273d983538d965a403103648d1d1afadb5\n(cherry picked from commit 9f89b53753b183df06739263609e190dc76f9b2b)\n'}, {'number': 4, 'created': '2019-09-20 17:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/52c5935461e2139a240a482a362414915ae9266f', 'message': 'Add the vmware-nsx-tempest-plugin package\n\nChange-Id: I2c9377273d983538d965a403103648d1d1afadb5\n(cherry picked from commit 9f89b53753b183df06739263609e190dc76f9b2b)\n'}, {'number': 5, 'created': '2019-09-27 16:44:34.000000000', 'files': ['openstack/vmware-nsx-tempest-plugin/vmware-nsx-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/43e05a274c2d0e393ac410cca6cfd721bbf1e279', 'message': 'Add the vmware-nsx-tempest-plugin package\n\nChange-Id: I2c9377273d983538d965a403103648d1d1afadb5\n(cherry picked from commit d2d7d2a236e779880f48a0cb5404d26bb7482ccb)\n'}]",0,683415,43e05a274c2d0e393ac410cca6cfd721bbf1e279,29,6,5,6876,,,0,"Add the vmware-nsx-tempest-plugin package

Change-Id: I2c9377273d983538d965a403103648d1d1afadb5
(cherry picked from commit d2d7d2a236e779880f48a0cb5404d26bb7482ccb)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/15/683415/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/vmware-nsx-tempest-plugin/vmware-nsx-tempest-plugin.spec.j2'],1,56aaa2f2449503952ffd8f113cd00381caa4850a,nsx-tempest-rocky,"{% set pypi_name = 'vmware-nsx-tempest-plugin' %} {% set rpm_release = '1' %} {% set source=fetch_source('https://tarballs.openstack.org/vmware-nsx-tempest-plugin/vmware-nsx-tempest-plugin-master.tar.gz') %} {% set upstream_version = upstream_version() %} %global with_doc 0 Name: {{ py2name(py_versions='py2') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for the vmware-nsx project License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/{{ pypi_name }} Source0: {{ source|basename }} BuildRequires: fdupes BuildRequires: openstack-macros BuildRequires: {{ py2pkg('coverage') }} BuildRequires: {{ py2pkg('mock') }} BuildRequires: {{ py2pkg('os-testr') }} BuildRequires: {{ py2pkg('oslotest') }} BuildRequires: {{ py2pkg('pbr') }} BuildRequires: {{ py2pkg('python-subunit') }} BuildRequires: {{ py2pkg('reno') }} BuildRequires: {{ py2pkg('stestr') }} BuildRequires: {{ py2pkg('testtools') }} Requires: {{ py2pkg('tempest') }} Requires: {{ py2pkg('neutron-lib') }} Requires: {{ py2pkg('pbr') }} BuildArch: noarch %description This package contains Tempest tests to cover the vmware-nsx project. Additionally it provides a plugin to automatically load these tests into Tempest. %if 0%{with_doc} %package doc Summary: Documentation for the vmware-nsx-tempest-plugin package BuildRequires: {{ py2pkg('Sphinx') }} BuildRequires: {{ py2pkg('openstackdocstheme') }} BuildRequires: {{ py2pkg('reno') }} %documentation doc This package contains the documentation for the vmware-nsx tempest tests %endif %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{python_build} # Generate Docs %if 0%{?with_doc} PBR_VERSION={{ upstream_version }} %sphinx_build -b html doc/source doc/build/html # remove the sphinx build leftovers rm -rf doc/build/html/.{doctrees,buildinfo} %endif %install %{python_install} %fdupes %{buildroot}%{python_sitelib} %files %license LICENSE %doc README.rst %{python_sitelib}/vmware_nsx_tempest_plugin %{python_sitelib}/*.egg-info %if 0%{?with_doc} %files doc %doc doc/build/html %license LICENSE %endif %changelog ",,75,0
openstack%2Frpm-packaging~stable%2Fpike~I4e0e78bf3627e77f52f88e5de40f3f702e80f26c,openstack/rpm-packaging,stable/pike,I4e0e78bf3627e77f52f88e5de40f3f702e80f26c,add X.509 certificate check plugin for monasca-agent,MERGED,2019-11-20 23:32:07.000000000,2019-12-26 06:35:04.000000000,2019-12-26 06:35:03.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 10311}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 16222}, {'_account_id': 19648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-20 23:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fde370630a02bed0e25a2a816b90c42ee79be0d9', 'message': 'add X.509 certificate check plugin for monasca-agent\n\nWe need this in order to monitor the internal TLS certificates. Since\nbackporting feature to stable/pike is not feasible, the next option is\nto patch RPM.\n\nChange-Id: I4e0e78bf3627e77f52f88e5de40f3f702e80f26c\n'}, {'number': 2, 'created': '2019-12-12 01:11:50.000000000', 'files': ['openstack/monasca-agent/monasca-agent.spec.j2', 'openstack/monasca-agent/0001-add-X.509-certificate-check-plugin.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/56cc9c048b96c2571a32f960b81d6bf1576e27f9', 'message': 'add X.509 certificate check plugin for monasca-agent\n\nWe need this in order to monitor the internal TLS certificates. Since\nbackporting feature to stable/pike is not feasible, the next option is\nto patch RPM.\n\nChange-Id: I4e0e78bf3627e77f52f88e5de40f3f702e80f26c\n'}]",0,695319,56cc9c048b96c2571a32f960b81d6bf1576e27f9,12,9,2,1916,,,0,"add X.509 certificate check plugin for monasca-agent

We need this in order to monitor the internal TLS certificates. Since
backporting feature to stable/pike is not feasible, the next option is
to patch RPM.

Change-Id: I4e0e78bf3627e77f52f88e5de40f3f702e80f26c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/19/695319/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/monasca-agent/monasca-agent.spec.j2', 'openstack/monasca-agent/0001-add-X.509-certificate-check-plugin.patch']",2,fde370630a02bed0e25a2a816b90c42ee79be0d9,add_x509_cert_check,"From 7156a40914ba4ac13fb92a7dd1d2bfcb1f440b8d Mon Sep 17 00:00:00 2001 From: Guang Yee <guang.yee@suse.com> Date: Tue, 22 Oct 2019 23:44:32 -0700 Subject: [PATCH] add X.509 certificate check plugin Currently we don't have any capability to monitor the internal TLS/SSL certificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for distribution, etc. The cert_check plugin is not adequate for this purpose becaue it can only check on certficates over HTTPS endpoints. Furthermore, checking on these internal certificates over the network is cumbersome because the agent plugin would have to speak specific protocols. This patch adds a cert_file_check plugin to detect the certificate expiry (in days from now) for the given X.509 certificate file in PEM format. Similar to cert_check plugin, this plugin will a metric 'cert_file.cert_expire_days' which contains the number of days from now the given certificate will be expired. If the certificate has already expired, this will be a negative number. Change-Id: Id95cc7115823f972e234417223ab5906b57447cc Story: 2006753 (cherry picked from commit e1d73c4b5de577e663084bda9d3f5185c433af84) --- docs/Plugins.md | 75 +++++++++ .../collector/checks_d/cert_file_check.py | 68 +++++++++ .../detection/plugins/cert_file_check.py | 73 +++++++++ setup.cfg | 2 + test-requirements.txt | 2 + tests/checks_d/test_cert_file_check.py | 144 ++++++++++++++++++ tests/detection/test_cert_file_check.py | 65 ++++++++ tox.ini | 2 +- 8 files changed, 430 insertions(+), 1 deletion(-) create mode 100644 monasca_agent/collector/checks_d/cert_file_check.py create mode 100644 monasca_setup/detection/plugins/cert_file_check.py create mode 100644 tests/checks_d/test_cert_file_check.py create mode 100644 tests/detection/test_cert_file_check.py diff --git a/docs/Plugins.md b/docs/Plugins.md index 4c2e255..63db187 100644 --- a/docs/Plugins.md +++ b/docs/Plugins.md @@ -30,6 +30,7 @@ - [Check_MK_Local](#check_mk_local) - [Ceph](#ceph) - [Certificate Expiration (HTTPS)](#certificate-expiration-https) + - [Certificate Expiration (PEM File)](#certificate-expiration-file) - [Couch](#couch) - [Couchbase](#couchbase) - [Crash](#crash) @@ -141,6 +142,7 @@ The following plugins are delivered via setup as part of the standard plugin che | cacti | | | | cAdvisor_host | | | | cert_check | | | +| cert_file_check | | | | check_mk_local | | | | couch | | | | couchbase | | | @@ -319,6 +321,7 @@ These are the detection plugins included with the Monasca Agent. See [Customiza | ceilometer | ServicePlugin | | ceph | Plugin | | cert_check | ArgsPlugin | +| cert_file_check | ArgsPlugin | | check_mk_local | Plugin | | cinder | ServicePlugin | | crash | Plugin | @@ -835,6 +838,78 @@ These options can be set if desired: * collect_period: Integer time in seconds between outputting the metric. Since the metric is in days, it makes sense to output it at a slower rate. The default is 3600, once per hour * timeout: Float time in seconds before timing out the connect to the url. Increase if needed for very slow servers, but making this too long will increase the time this plugin takes to run if the server for the url is down. The default is 1.0 seconds +======= +## Certificate Expiration (PEM file) +An extension to the Agent provides the ability to determine the expiration date +of the PEM formatted X.509 certificate in a file. The metric is days until the +certificate expires. If the given certificate has already expired, it will +return a negative number. For example, if the certificate has already expired +5 days prior to the check, -5 will be returned. + +Notice that the days till expiration value is calculated based on every 24 +hours block, rounded down. For example, if the certificate will be expiring in +23 hours, the days till expiration value will be 0. Here are some more +examples. + +| Certificate Expiration Date | Plugin Execution Date | cert_file.cert_expire_days | +| --------------------------- | --------------------- | -------------------------- | +| Nov 1 23:00:50 2019 GMT | Oct 29 23:01:00 2019 GMT | 2 | +| Nov 1 23:00:50 2019 GMT | Oct 30 23:01:00 2019 GMT | 1 | +| Nov 1 23:00:50 2019 GMT | Nov 1 10:00:50 2019 GMT | 0 | +| Nov 1 23:00:50 2019 GMT | Nov 1 23:01:50 2019 GMT | 0 | +| Nov 1 23:00:50 2019 GMT | Nov 2 23:01:50 2019 GMT | -1 | +| Nov 1 23:00:50 2019 GMT | Nov 3 23:23:00 2019 GMT | -2 | + +The following dimensions are included with the metric by default: +``` + cert_file: cert_file +``` + +### Configuration +A YAML file (cert_file_check.yaml) contains the list of cert_files to check. + +The configuration of the certificate expiration check is done in YAML, and consists of two keys: + +* init_config +* instances + +The init_config section lists the global configuration settings, such as the +period (in seconds) at which to output the metric. The default value for +collect_period is 1 hour (3600 seconds). To change it to emit metric every +24 hours, set it to 86400. + +```yaml +init_config: + collect_period: 3600 +``` + +The instances section contains the urls to check. + +```yaml +instances: +- built_by: CertificateFileCheck + cert_file: /etc/myservice/myservice.pem +- built_by: CertificateFileCheck + cert_file: /etc/ssl/myotherservice.pem +``` + +The certicate expiration checks return the following metrics + +| Metric Name | Dimensions | Semantics | +| ----------- | ---------- | --------- | +| cert_file.cert_expire_days | cert_file=supplied certificate file being checked | The number of days until the certificate expires + + +There is a detection plugin that should be used to configure this extension. It is invoked as: + + $ monasca-setup -d CertificateFileCheck -a ""cert_files=/etc/myservice/myservice.pem,/etc/myotherservice/myotherservice.pem"" + +The cert_files option is a comma separated list of certificate files to check. + +These options can be set if desired: +* collect_period: Integer time in seconds between outputting the metric. +Since the metric is in days, it makes sense to output it at a slower rate. +The default is 3600, once per hour ## Couch See [the example configuration](https://github.com/openstack/monasca-agent/blob/master/conf.d/couch.yaml.example) for how to configure the Couch plugin. diff --git a/monasca_agent/collector/checks_d/cert_file_check.py b/monasca_agent/collector/checks_d/cert_file_check.py new file mode 100644 index 0000000..811e113 --- /dev/null +++ b/monasca_agent/collector/checks_d/cert_file_check.py @@ -0,0 +1,68 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +from datetime import datetime + +from cryptography.hazmat.backends import default_backend +from cryptography import x509 + +from monasca_agent.collector.checks import AgentCheck + + +class CertificateFileCheck(AgentCheck): + """"""Check the given certificate file and output a metric + which is the number of days until it expires + """""" + + def __init__(self, name, init_config, agent_config, instances=None): + super(CertificateFileCheck, self).__init__(name, init_config, + agent_config, instances) + + def check(self, instance): + cert_file = instance.get('cert_file', None) + + if cert_file is None: + self.log.warning('Instance have no ""cert_file"" configured.') + return + + dimensions = self._set_dimensions(None, instance) + dimensions['cert_file'] = cert_file + self.log.info('cert_file = %s' % cert_file) + expire_in_days = self.get_expire_in_days(cert_file) + if expire_in_days is not None: + self.gauge('cert_file.cert_expire_days', expire_in_days, + dimensions=dimensions) + self.log.debug('%d days till expiration for %s' % (expire_in_days, + cert_file)) + + def get_expire_in_days(self, cert_file): + """"""Take the path the the TLS certificate file and returns the number + of till the certificate expires. If the certificate has already + expired, it will return a negative number. For example, + if the certificate has already expired 5 days prior to the check, + -5 will be returned. + """""" + try: + with open(cert_file, 'r') as cf: + pem_data = cf.read().encode('ascii') + + cert = x509.load_pem_x509_certificate(pem_data, default_backend()) + return (cert.not_valid_after - datetime.utcnow()).days + except IOError: + self.log.warning( + 'Unable to read certificate from %s' % (cert_file)) + except ValueError: + self.log.warning( + 'Unable to load certificate from %s. Invalid content.' % ( + cert_file)) diff --git a/monasca_setup/detection/plugins/cert_file_check.py b/monasca_setup/detection/plugins/cert_file_check.py new file mode 100644 index 0000000..988f080 --- /dev/null +++ b/monasca_setup/detection/plugins/cert_file_check.py @@ -0,0 +1,73 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import logging + +import monasca_setup.agent_config +import monasca_setup.detection + +log = logging.getLogger(__name__) + +DEFAULT_COLLECT_PERIOD = 3600 + + +class CertificateFileCheck(monasca_setup.detection.ArgsPlugin): + """"""Setup a X.509 certificate file check according to the passed in args. + + Outputs one metric: cert_file.cert_expire_days which is the number of + days until the certificate expires + + Despite being a detection plugin, this plugin does no detection and + will be a NOOP without arguments. Expects one argument, 'cert_files' + which is a comma-separated list of PEM-formatted X.509 certificate + files. + + Examples: + + monasca-setup -d CertificateFileCheck -a ""cert_files=cert1.pem,cert2.pem"" + + These arguments are optional: + collect_period: Integer time in seconds between outputting the metric. + Since the metric is in days, it makes sense to output + it at a slower rate. The default is once per hour + """""" + + def _detect(self): + """"""Run detection, set self.available True if cert_files are detected + """""" + self.available = self._check_required_args(['cert_files']) + + def build_config(self): + """"""Build the config as a Plugins object and return. + """""" + config = monasca_setup.agent_config.Plugins() + instances = [] + init_config = {'collect_period': DEFAULT_COLLECT_PERIOD} + if 'collect_period' in self.args: + collect_period = int(self.args['collect_period']) + init_config['collect_period'] = collect_period + for cert_file in self.args['cert_files'].split(','): + cert_file = cert_file.strip() + # Allow comma terminated lists + if not cert_file: + continue + log.info(""\tAdding X.509 Certificate expiration check for {}"".format(cert_file)) + instance = self._build_instance([]) + instance.update({'cert_file': cert_file, 'name': cert_file}) + instances.append(instance) + + config['cert_file_check'] = {'init_config': init_config, + 'instances': instances} + + return config diff --git a/setup.cfg b/setup.cfg index 4bbf252..19726f6 100644 --- a/setup.cfg +++ b/setup.cfg @@ -56,6 +56,8 @@ libvirt = ovs = python-novaclient>=9.0.0 python-neutronclient>=6.3.0 +cert_file_check = + cryptography>=2.0.2 # BSD/Apache-2.0 [global] setup-hooks = diff --git a/test-requirements.txt b/test-requirements.txt index a74162c..6f20d9e 100644 --- a/test-requirements.txt +++ b/test-requirements.txt @@ -9,3 +9,5 @@ oslotest>=1.10.0 # Apache-2.0 os-testr>=0.8.0 # Apache-2.0 prometheus_client docutils>=0.11 # OSI-Approved Open Source, Public Domain +freezegun>=0.3.6 # Apache-2.0 +cryptography>=2.0.2 # BSD/Apache-2.0 diff --git a/tests/checks_d/test_cert_file_check.py b/tests/checks_d/test_cert_file_check.py new file mode 100644 index 0000000..539159f --- /dev/null +++ b/tests/checks_d/test_cert_file_check.py @@ -0,0 +1,144 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import datetime +import logging +import mock +import os +import shutil +import tempfile +import unittest + +from cryptography import x509 +from cryptography.x509.oid import NameOID +from cryptography.hazmat.primitives import hashes +from cryptography.hazmat.backends import default_backend +from cryptography.hazmat.primitives import serialization +from cryptography.hazmat.primitives.asymmetric import rsa +import freezegun + +from monasca_agent.collector.checks_d import cert_file_check + +LOG = logging.getLogger('monasca_agent.collector.checks.check.cert_file_check') + + +def generate_selfsigned_cert(expired_in): + key = rsa.generate_private_key( + public_exponent=65537, + key_size=1024, + backend=default_backend() + ) + issuer = subject = x509.Name([ + x509.NameAttribute(NameOID.COMMON_NAME, u'foo') + ]) + now = datetime.datetime.utcnow() + cert = ( + x509.CertificateBuilder() + .subject_name(issuer) + .issuer_name(subject) + .public_key(key.public_key()) + .serial_number(1) + .not_valid_before(now) + .not_valid_after(now + datetime.timedelta(days=expired_in)) + .sign(key, hashes.SHA256(), default_backend()) + ) + cert_pem = cert.public_bytes(encoding=serialization.Encoding.PEM) + + return cert_pem.decode('ascii') + + +class TestCertificateFileCheck(unittest.TestCase): + + def setUp(self): + super(TestCertificateFileCheck, self).setUp() + self.cert_file_check_obj = cert_file_check.CertificateFileCheck( + name='cert_file_check', + init_config={}, + instances=[], + agent_config={} + ) + + def test_cert_file_is_none(self): + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'foo': 'bar'}) + mock_log.assert_called_with( + 'Instance have no ""cert_file"" configured.') + + def test_unable_to_read_file(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + bogus_cert_file = os.path.join(tmp_certdir, 'foo') + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) + mock_log.assert_called_with( + 'Unable to read certificate from %s' % (bogus_cert_file)) + finally: + shutil.rmtree(tmp_certdir) + + def test_unable_to_load_file(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + bogus_cert_file = os.path.join(tmp_certdir, 'foo') + # create a non-PEM formatted certificate file + with open(bogus_cert_file, 'w') as f: + f.write('foo') + + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) + mock_log.assert_called_with( + 'Unable to load certificate from %s. Invalid content.' % ( + bogus_cert_file)) + finally: + shutil.rmtree(tmp_certdir) + + def test_check(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + cert_file = os.path.join(tmp_certdir, 'foo') + # create a self-signed cert that expires in 10 days from now + with open(cert_file, 'w') as f: + f.write(generate_selfsigned_cert(10)) + + with mock.patch.object(cert_file_check.CertificateFileCheck, + 'gauge') as mock_gauge: + self.cert_file_check_obj.check({'cert_file': cert_file}) + args, kwargs = mock_gauge.call_args + # make sure the plugin correctly detect the given cert will be + # expiring in equal or less than 10 days from now + self.assertEqual('cert_file.cert_expire_days', args[0]) + self.assertLessEqual(args[1], 10) + finally: + shutil.rmtree(tmp_certdir) + + def test_check_expired_cert(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + cert_file = os.path.join(tmp_certdir, 'foo') + # create a self-signed cert that has expired 10 days ago + with open(cert_file, 'w') as f: + f.write(generate_selfsigned_cert(10)) + + now = datetime.datetime.utcnow() + back_to_the_future = now + datetime.timedelta(days=20) + with freezegun.freeze_time(back_to_the_future): + with mock.patch.object(cert_file_check.CertificateFileCheck, + 'gauge') as mock_gauge: + self.cert_file_check_obj.check({'cert_file': cert_file}) + args, kwargs = mock_gauge.call_args + # make sure the plugin correctly detect that the given + # cert has already expired + self.assertEqual('cert_file.cert_expire_days', args[0]) + self.assertLessEqual(args[1], -9) + finally: + shutil.rmtree(tmp_certdir) diff --git a/tests/detection/test_cert_file_check.py b/tests/detection/test_cert_file_check.py new file mode 100644 index 0000000..ad1225e --- /dev/null +++ b/tests/detection/test_cert_file_check.py @@ -0,0 +1,65 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import logging +import unittest + +from mock import patch + +from monasca_setup.detection.plugins.cert_file_check import CertificateFileCheck + +LOG = logging.getLogger('monasca_setup.detection.plugins.cert_check') + + +class TestCertFileCheck(unittest.TestCase): + + def setUp(self): + unittest.TestCase.setUp(self) + with patch.object(CertificateFileCheck, '_detect') as mock_detect: + self.cert_obj = CertificateFileCheck('temp_dir') + self.assertTrue(mock_detect.called) + self.cert_obj.args = {'cert_files': '/etc/myservice/myserver.pem'} + + def test_detect(self): + self.cert_obj.available = False + with patch.object(self.cert_obj, '_check_required_args', + return_value=True) as mock_check_required_args: + self.cert_obj._detect() + self.assertTrue(self.cert_obj.available) + self.assertTrue(mock_check_required_args.called) + + def _build_config(self): + with patch.object(self.cert_obj, '_build_instance', + return_value={}) as mock_build_instance: + result = self.cert_obj.build_config() + self.assertTrue(mock_build_instance.called) + self.assertEqual( + result['cert_file_check']['instances'][0]['cert_file'], + '/etc/myservice/myserver.pem') + self.assertEqual(result['cert_file_check']['instances'][0]['name'], + '/etc/myservice/myserver.pem') + return result + + def test_build_config_without_args(self): + result = self._build_config() + self.assertEqual( + result['cert_file_check']['init_config']['collect_period'], + 3600) + + def test_build_config_with_args(self): + self.cert_obj.args.update({'collect_period': 1200}) + result = self._build_config() + self.assertEqual( + result['cert_file_check']['init_config']['collect_period'], + 1200) diff --git a/tox.ini b/tox.ini index e6ad0b1..bc990e0 100644 --- a/tox.ini +++ b/tox.ini @@ -15,7 +15,7 @@ deps = -r{toxinidir}/test-requirements.txt whitelist_externals = bash find rm -install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/pike} {opts} {packages} +install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/stable/pike/upper-constraints.txt} {opts} {packages} commands = find . -type f -name ""*.pyc"" -delete rm -Rf .testrepository/times.dbm -- 2.17.1 ",,558,0
openstack%2Ftripleo-ansible~master~I5105c007d890ec98b34eafba3ab410bf9ba4f089,openstack/tripleo-ansible,master,I5105c007d890ec98b34eafba3ab410bf9ba4f089,Change drop action,MERGED,2019-12-18 14:37:41.000000000,2019-12-26 06:01:04.000000000,2019-12-21 02:26:40.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-18 14:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c2885d6d05f7f72e2b82f8b174d0abd6406fd4f3', 'message': 'Change drop action\n\nThe new firewall rule action plugin was setting the rule state as absent\nwhen using the drop ""action"", this change updates that so we\'re adding\ndrop rules and appending them to the rule chain.\n\nChange-Id: I5105c007d890ec98b34eafba3ab410bf9ba4f089\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-12-18 14:43:20.000000000', 'files': ['tripleo_ansible/ansible_plugins/action/tripleo_iptables.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8f11437b1c5173d3dda669b8b1d700837b33b245', 'message': 'Change drop action\n\nThe new firewall rule action plugin was setting the rule state as absent\nwhen using the drop ""action"", this change updates that so we\'re adding\ndrop rules and appending them to the rule chain.\n\nChange-Id: I5105c007d890ec98b34eafba3ab410bf9ba4f089\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,699692,8f11437b1c5173d3dda669b8b1d700837b33b245,13,5,2,7353,,,0,"Change drop action

The new firewall rule action plugin was setting the rule state as absent
when using the drop ""action"", this change updates that so we're adding
drop rules and appending them to the rule chain.

Change-Id: I5105c007d890ec98b34eafba3ab410bf9ba4f089
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/92/699692/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/action/tripleo_iptables.py'],1,c2885d6d05f7f72e2b82f8b174d0abd6406fd4f3,fw-update, rule_data['action'] = 'append', rule_data['action'] = 'insert' rule_data['state'] = 'absent',1,2
openstack%2Ftrove~master~If48ef016c6fb7a875ceabc9f106e4cd85858d147,openstack/trove,master,If48ef016c6fb7a875ceabc9f106e4cd85858d147,Improve API doc,MERGED,2019-12-24 03:53:37.000000000,2019-12-26 04:08:36.000000000,2019-12-26 04:06:40.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 03:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/47fb6434672bba069cb731aaa83068be4dd95c25', 'message': 'Improve API doc\n\nChange-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147\n'}, {'number': 2, 'created': '2019-12-24 04:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b115ef807d35ab5eb88c80f8d940dde14cdf35a0', 'message': 'Improve API doc\n\nChange-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147\n'}, {'number': 3, 'created': '2019-12-24 06:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1b4d216214ba6e877f2fd51d48b20e05538b92bf', 'message': 'Improve API doc\n\nChange-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147\n'}, {'number': 4, 'created': '2019-12-24 06:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/765bb1dc743cebe4b22349d00cfc7f19db3671c1', 'message': 'Improve API doc\n\nChange-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147\n'}, {'number': 5, 'created': '2019-12-24 10:59:57.000000000', 'files': ['api-ref/source/samples/instance-log-show-response.json', 'api-ref/source/samples/db-instance-disable-log-response.json', 'api-ref/source/samples/db-instance-reboot-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-response.json', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-response-json-http.txt', 'api-ref/source/samples/instance-log-publish-request.json', 'api-ref/source/samples/db-configuration-edit-parameters-request-json-http.txt', 'api-ref/source/samples/backup-create-response.json', 'api-ref/source/samples/db-datastore-by-id-request-json-http.txt', 'api-ref/source/samples/datastore-version-parameter-show-response.json', 'api-ref/source/samples/instance-log-publish-response.json', 'api-ref/source/samples/db-configuration-update-parameters-request.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-response.json', 'api-ref/source/samples/db-configuration-update-parameters-response-json-http.txt', 'api-ref/source/samples/config-groups-list-response.json', 'api-ref/source/index.rst', 'api-ref/source/samples/db-datastore-versions-list-response.json', 'api-ref/source/samples/db-patch-config-group-request-json-http.txt', 'api-ref/source/samples/db-backup-restore-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-instances-request-json-http.txt', 'api-ref/source/samples/db-create-config-group-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-instance-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-root-details-request-json-http.txt', 'api-ref/source/samples/db-delete-databases-response-json-http.txt', 'api-ref/source/samples/instance-log-disable-response.json', 'api-ref/source/samples/instance-put-attach-config-group-request.json', 'api-ref/source/samples/db-list-databases-request-json-http.txt', 'api-ref/source/samples/db-delete-databases-request-json-http.txt', 'api-ref/source/samples/db-instance-resize-instance-request.json', 'api-ref/source/samples/db-create-users-response-json-http.txt', 'api-ref/source/samples/datastore-version-mgmt-show-response.json', 'api-ref/source/samples/db-config-group-instances-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-host-detail-response.json', 'api-ref/source/samples/db-backup-restore-response-json-http.txt', 'api-ref/source/samples/db-list-parameters-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-request-json-http.txt', 'api-ref/source/samples/db-delete-users-response-json-http.txt', 'api-ref/source/samples/db-attach-config-group-request-json-http.txt', 'api-ref/source/samples/db-instances-index-pagination-response-json-http.txt', 'api-ref/source/samples/db-configuration-delete-response-json-http.txt', 'api-ref/source/samples/db-instance-restart-response-json-http.txt', 'api-ref/source/samples/db-datastores-list-response.json', 'api-ref/source/samples/user-grant-databases-access-request.json', 'api-ref/source/samples/db-backup-get-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-response.json', 'api-ref/source/datastore-versions.inc', 'api-ref/source/samples/db-backup-list-request-json-http.txt', 'api-ref/source/samples/user-show-root-history-response.json', 'api-ref/source/samples/db-instance-discard-log-response.json', '.zuul.yaml', 'api-ref/source/samples/db-configuration-attach-to-instance-response-json-http.txt', 'api-ref/source/samples/db-backup-restore-request.json', 'api-ref/source/samples/instance-mgmt-action-migrate-request.json', 'api-ref/source/samples/db-list-databases-pagination-response-json-http.txt', 'api-ref/source/samples/db-backup-create-incremental-response-json-http.txt', 'api-ref/source/samples/db-config-group-details-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-response-json-http.txt', 'api-ref/source/samples/db-create-instance-request-json-http.txt', 'api-ref/source/samples/instance-create-request.json', 'api-ref/source/samples/db-backup-create-incremental-request.json', 'api-ref/source/samples/db-backup-restore-response.json', 'api-ref/source/samples/db-instance-resize-flavor-response-json-http.txt', 'api-ref/source/users.inc', 'trove/extensions/mgmt/instances/models.py', 'api-ref/source/samples/datastore-version-parameter-create-response.json', 'api-ref/source/samples/db-config-group-details-request-json-http.txt', 'api-ref/source/samples/instance-log-enable-response.json', 'api-ref/source/samples/db-backup-create-incremental-request-json-http.txt', 'api-ref/source/samples/db-list-datastore-versions-response-json-http.txt', 'api-ref/source/samples/db-configuration-delete-request-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-request.json', 'api-ref/source/samples/db-instance-resize-instance-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-root-details-response.json', 'api-ref/source/samples/db-backup-create-incremental-response.json', 'api-ref/source/samples/instance-create-response.json', 'api-ref/source/samples/db-configuration-edit-parameters-response-json-http.txt', 'api-ref/source/samples/db-version-request-json-http.txt', 'api-ref/source/databases.inc', 'api-ref/source/samples/db-detach-replica-request-json-http.txt', 'api-ref/source/samples/instance-action-resize-request.json', 'api-ref/source/samples/instance-patch-detach-replica-request.json', 'api-ref/source/samples/db-show-parameter-details-response-json-http.txt', 'api-ref/source/samples/db-create-databases-request-json-http.txt', 'api-ref/source/samples/user-check-root-response.json', 'api-ref/source/samples/datastore-version-parameter-create-request.json', 'api-ref/source/samples/db-mgmt-list-hosts-request-json-http.txt', 'api-ref/source/samples/db-list-databases-response.json', 'api-ref/source/samples/instance-backup-list-response.json', 'api-ref/source/samples/users-put-request.json', 'api-ref/source/samples/db-mgmt-instance-index-response.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-response-json-http.txt', 'api-ref/source/samples/db-change-user-attributes-request-json-http.txt', 'api-ref/source/samples/db-datastores-list-response-json-http.txt', 'api-ref/source/samples/db-list-user-access-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-response.json', 'api-ref/source/samples/db-instance-show-log-response.json', 'api-ref/source/samples/db-configuration-details-response.json', 'api-ref/source/samples/db-instances-index-pagination-request-json-http.txt', 'api-ref/source/samples/instance-log-disable-request.json', 'api-ref/source/samples/db-datastore-version-by-id-response-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-reset-task-status-request.json', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-response-json-http.txt', 'api-ref/source/samples/db-configuration-attach-to-instance-request-json-http.txt', 'api-ref/source/samples/db-list-users-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-instance-details-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-versions-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-host-detail-request-json-http.txt', 'api-ref/source/samples/db-disable-root-user-response-json-http.txt', 'api-ref/source/samples/db-update-config-group-response-json-http.txt', 'api-ref/source/samples/backup-get-response.json', 'api-ref/source/samples/db-delete-instance-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-storage-request-json-http.txt', 'api-ref/source/samples/db-config-group-instances-response-json-http.txt', 'api-ref/source/samples/db-get-default-instance-configuration-request-json-http.txt', 'api-ref/source/samples/databases-create-request.json', 'api-ref/source/samples/db-datastore-version-by-id-response.json', 'api-ref/source/samples/db-detach-config-group-response-json-http.txt', 'api-ref/source/samples/db-list-user-dbs-response.json', 'api-ref/source/samples/datastore-version-parameter-update-request.json', 'api-ref/source/samples/db-mgmt-list-accounts-response.json', 'api-ref/source/samples/db-faults-badRequest.json', 'api-ref/source/samples/db-backup-delete-request-json-http.txt', 'api-ref/source/samples/versions-response.json', 'api-ref/source/samples/db-grant-user-access-request-json-http.txt', 'api-ref/source/samples/db-instance-resize-volume-response-json-http.txt', 'api-ref/source/samples/db-mgmt-list-hosts-response.json', 'api-ref/source/samples/db-list-cfg-groups-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-account-details-response.json', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-response.json', 'api-ref/source/samples/db-datastore-versions-list-response-json-http.txt', 'api-ref/source/instances.inc', 'api-ref/source/samples/db-versions-request-json-http.txt', 'api-ref/source/configurations.inc', 'api-ref/source/samples/datastore-version-create-request.json', 'api-ref/source/samples/db-mgmt-get-account-details-response-json-http.txt', 'api-ref/source/samples/db-update-config-group-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-show-response.json', 'api-ref/source/samples/db-mgmt-list-accounts-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-request.json', 'api-ref/source/samples/db-list-databases-pagination-request-json-http.txt', 'api-ref/source/samples/db-list-cfg-groups-request-json-http.txt', 'api-ref/source/samples/db-configuration-update-parameters-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-storage-response.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-request-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-response-json-http.txt', 'api-ref/source/samples/user-show-response.json', 'api-ref/source/parameters.yaml', 'api-ref/source/samples/db-check-root-user-response-json-http.txt', 'api-ref/source/samples/config-group-show-response.json', 'api-ref/source/api-versions.inc', 'api-ref/source/samples/db-restore-delete-request-json-http.txt', 'api-ref/source/samples/db-change-users-password-request-json-http.txt', 'api-ref/source/samples/db-show-parameter-details.json', 'api-ref/source/samples/db-enable-root-user-response-json-http.txt', 'api-ref/source/database-instance-actions.inc', 'trove/common/api.py', 'api-ref/source/samples/db-faults-itemNotFound.json', 'api-ref/source/samples/db-datastore-version-by-id-request-json-http.txt', 'api-ref/source/samples/instance-log-enable-request.json', 'api-ref/source/samples/db-list-parameters-request-json-http.txt', 'api-ref/source/samples/instance-action-eject-replica-request.json', 'api-ref/source/samples/db-show-parameter-details-request-json-http.txt', 'api-ref/source/samples/datastore-version-list-response.json', 'api-ref/source/samples/instance-action-restart-request.json', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-instances-response.json', 'api-ref/source/samples/instance-show-response.json', 'api-ref/source/samples/db-list-user-dbs-request-json-http.txt', 'api-ref/source/samples/db-mgmt-list-accounts-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-response.json', 'api-ref/source/samples/db-list-datastore-versions-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-request-json-http.txt', 'api-ref/source/samples/db-configuration-edit-parameters-request.json', 'api-ref/source/samples/db-change-user-attributes-response-json-http.txt', 'api-ref/source/samples/db-instance-promote-replica-request-json-http.txt', 'api-ref/source/samples/datastore-list-response.json', 'api-ref/source/samples/db-configuration-list-response-json-http.txt', 'api-ref/source/samples/db-delete-root-request-json-http.txt', 'api-ref/source/samples/db-instances-index-request-json-http.txt', 'api-ref/source/samples/db-delete-config-group-request-json-http.txt', 'api-ref/source/samples/db-enable-root-user-request-json-http.txt', 'api-ref/source/samples/db-detach-replica-response-json-http.txt', 'api-ref/source/samples/db-datastore-by-id-response-json-http.txt', 'api-ref/source/samples/db-instance-eject-replica-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-response-json-http.txt', 'api-ref/source/samples/user-put-request.json', 'api-ref/source/samples/db-get-default-instance-configuration-response-json-http.txt', 'api-ref/source/samples/db-create-instance-response-json-http.txt', 'api-ref/source/samples/db-list-cfg-defaults-response.json', 'api-ref/source/samples/db-mgmt-instance-index-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-reboot-request.json', 'api-ref/source/samples/instance-action-resize-volume-request.json', 'api-ref/source/samples/db-create-instance-response.json', 'api-ref/source/samples/user-enable-root-response.json', 'api-ref/source/samples/db-attach-config-group-response-json-http.txt', 'api-ref/source/samples/db-list-users-response.json', 'api-ref/source/samples/db-mgmt-get-instance-details-response.json', 'api-ref/source/samples/db-list-cfg-defaults-request-json-http.txt', 'api-ref/source/samples/db-list-user-access-response.json', 'api-ref/source/instance-logs.inc', 'api-ref/source/samples/db-instance-enable-log-response.json', 'api-ref/source/samples/datastore-version-mgmt-patch-request.json', 'api-ref/source/samples/db-restore-delete-response-json-http.txt', 'api-ref/source/instance-actions.inc', 'api-ref/source/samples/db-mgmt-get-host-detail-response-json-http.txt', 'api-ref/source/user-management.inc', 'api-ref/source/samples/db-enable-root-user-response.json', 'api-ref/source/samples/db-list-user-dbs-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-flavor-request.json', 'api-ref/source/samples/instance-log-discard-response.json', 'api-ref/source/samples/db-mgmt-get-root-details-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-account-details-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-stop-request.json', 'api-ref/source/samples/db-instance-publish-log-response.json', 'api-ref/source/samples/limit-show-response.json', 'api-ref/source/samples/db-instance-resize-volume-request-json-http.txt', 'api-ref/source/samples/instance-list-response.json', 'api-ref/source/samples/instance-log-list-response.json', 'api-ref/source/samples/datastore-version-parameter-update-response.json', 'api-ref/source/samples/db-change-users-password-request.json', 'api-ref/source/samples/db-delete-instance-response-json-http.txt', 'api-ref/source/samples/db-list-user-access-request-json-http.txt', 'api-ref/source/samples/config-group-list-instances-response.json', 'api-ref/source/samples/db-list-users-pagination-response-json-http.txt', 'api-ref/source/samples/db-mgmt-list-hosts-response-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-request-json-http.txt', 'api-ref/source/samples/db-configuration-create-response-json-http.txt', 'api-ref/source/quotas.inc', 'api-ref/source/samples/db-revoke-user-access-request-json-http.txt', 'api-ref/source/samples/datastore-version-show-response.json', 'api-ref/source/samples/db-list-users-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-instance-details-response-json-http.txt', 'api-ref/source/samples/db-grant-user-access-response-json-http.txt', 'api-ref/source/samples/db-backup-create-response-json-http.txt', 'api-ref/source/samples/db-backup-list-response-json-http.txt', 'api-ref/source/samples/db-instance-reboot-response-json-http.txt', 'api-ref/source/samples/db-datastore-versions-list-request-json-http.txt', 'api-ref/source/samples/db-backup-delete-response-json-http.txt', 'api-ref/source/samples/db-faults-instanceFault.json', 'api-ref/source/samples/db-mgmt-instance-index-response-json-http.txt', 'api-ref/source/samples/db-detach-config-group-request-json-http.txt', 'api-ref/source/samples/db-instance-restart-request-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-response-json-http.txt', 'api-ref/source/samples/db-check-root-user-request-json-http.txt', 'api-ref/source/samples/db-create-databases-response-json-http.txt', 'api-ref/source/backups.inc', 'api-ref/source/samples/db-instances-index-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-flavor-request-json-http.txt', 'api-ref/source/samples/db-list-parameters-response.json', 'api-ref/source/samples/datastore-version-parameter-list-response.json', 'api-ref/source/samples/instance-patch-upgrade-datastore-version-request.json', 'api-ref/source/samples/db-datastores-list-request-json-http.txt', 'api-ref/source/samples/instance-action-reset-status-request.json', 'api-ref/source/samples/db-create-users-request-json-http.txt', 'api-ref/source/samples/instance-log-discard-request.json', 'api-ref/source/samples/instance-mgmt-list-response.json', 'api-ref/source/samples/config-group-patch-request.json', 'api-ref/source/samples/db-change-users-password-response-json-http.txt', 'api-ref/source/samples/user-list-response.json', 'api-ref/source/samples/db-delete-users-request-json-http.txt', 'api-ref/source/samples/backup-list-response.json', 'api-ref/source/samples/datastore-version-mgmt-list-response.json', 'api-ref/source/samples/db-list-datastore-versions.json', 'api-ref/source/samples/db-version-response-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-request-json-http.txt', 'api-ref/source/samples/db-backup-get-request-json-http.txt', 'api-ref/source/samples/instance-patch-update-name-request.json', 'api-ref/source/samples/user-create-request.json', 'api-ref/source/samples/db-list-cfg-defaults-response-json-http.txt', 'api-ref/source/samples/instance-action-promote-replica-request.json', 'api-ref/source/samples/db-backup-create-request-json-http.txt', 'api-ref/source/samples/databases-list-response.json', 'api-ref/source/samples/db-configuration-list-response.json', 'api-ref/source/samples/db-detach-config-group-request.json', 'api-ref/source/samples/db-instances-index-pagination-response.json', 'api-ref/source/samples/db-list-users-pagination-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-response.json', 'api-ref/source/samples/db-patch-config-group-response-json-http.txt', 'api-ref/source/samples/db-configuration-attach-to-instance-request.json', 'api-ref/source/samples/db-configuration-list-instances-response-json-http.txt', 'api-ref/source/samples/db-instances-index-response.json', 'api-ref/source/samples/db-revoke-user-access-response-json-http.txt', 'api-ref/source/samples/db-change-user-attributes-request.json', 'api-ref/source/samples/db-list-databases-response-json-http.txt', 'api-ref/source/datastores.inc', 'api-ref/source/samples/config-group-create-response.json', 'api-ref/source/samples/datastore-show-response.json', 'api-ref/source/samples/db-create-config-group-request-json-http.txt', 'api-ref/source/samples/db-datastore-by-id-response.json', 'api-ref/source/samples/db-mgmt-get-storage-response-json-http.txt', 'api-ref/source/samples/db-version-response.json', 'api-ref/source/samples/db-configuration-details-response-json-http.txt', 'api-ref/source/samples/db-disable-root-user-request-json-http.txt', 'api-ref/source/samples/config-group-create-request.json', 'api-ref/source/samples/config-group-put-request.json', 'api-ref/source/samples/db-configuration-details-request-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-response.json', 'api-ref/source/samples/instance-list-detail-response.json', 'api-ref/source/samples/instance-configuration-list-response.json', 'api-ref/source/samples/instance-log-show-request.json', 'api-ref/source/samples/backup-create-request.json', 'api-ref/source/samples/db-datastore-parameters-response.json', 'api-ref/source/samples/db-list-databases-pagination-response.json'], 'web_link': 'https://opendev.org/openstack/trove/commit/dacb400e0bc3c267d55c5d99032b4692f421f141', 'message': 'Improve API doc\n\nChange-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147\n'}]",0,700466,dacb400e0bc3c267d55c5d99032b4692f421f141,15,2,5,6732,,,0,"Improve API doc

Change-Id: If48ef016c6fb7a875ceabc9f106e4cd85858d147
",git fetch https://review.opendev.org/openstack/trove refs/changes/66/700466/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/samples/instance-log-show-response.json', 'api-ref/source/samples/db-instance-disable-log-response.json', 'api-ref/source/samples/db-instance-reboot-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-response.json', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-response-json-http.txt', 'api-ref/source/samples/instance-log-publish-request.json', 'api-ref/source/samples/db-configuration-edit-parameters-request-json-http.txt', 'api-ref/source/samples/backup-create-response.json', 'api-ref/source/samples/db-datastore-by-id-request-json-http.txt', 'api-ref/source/samples/datastore-version-parameter-show-response.json', 'api-ref/source/samples/instance-log-publish-response.json', 'api-ref/source/samples/db-configuration-update-parameters-request.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-response.json', 'api-ref/source/samples/db-configuration-update-parameters-response-json-http.txt', 'api-ref/source/samples/config-groups-list-response.json', 'api-ref/source/index.rst', 'api-ref/source/samples/db-datastore-versions-list-response.json', 'api-ref/source/samples/db-patch-config-group-request-json-http.txt', 'api-ref/source/samples/db-backup-restore-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-instances-request-json-http.txt', 'api-ref/source/samples/db-create-config-group-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-instance-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-root-details-request-json-http.txt', 'api-ref/source/samples/db-delete-databases-response-json-http.txt', 'api-ref/source/samples/instance-log-disable-response.json', 'api-ref/source/samples/instance-put-attach-config-group-request.json', 'api-ref/source/samples/db-list-databases-request-json-http.txt', 'api-ref/source/samples/db-delete-databases-request-json-http.txt', 'api-ref/source/samples/db-instance-resize-instance-request.json', 'api-ref/source/samples/db-create-users-response-json-http.txt', 'api-ref/source/samples/datastore-version-mgmt-show-response.json', 'api-ref/source/samples/db-config-group-instances-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-host-detail-response.json', 'api-ref/source/samples/db-backup-restore-response-json-http.txt', 'api-ref/source/samples/db-list-parameters-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-request-json-http.txt', 'api-ref/source/samples/db-delete-users-response-json-http.txt', 'api-ref/source/samples/db-attach-config-group-request-json-http.txt', 'api-ref/source/samples/db-instances-index-pagination-response-json-http.txt', 'api-ref/source/samples/db-configuration-delete-response-json-http.txt', 'api-ref/source/samples/db-instance-restart-response-json-http.txt', 'api-ref/source/samples/db-datastores-list-response.json', 'api-ref/source/samples/user-grant-databases-access-request.json', 'api-ref/source/samples/db-backup-get-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-response.json', 'api-ref/source/samples/db-backup-list-request-json-http.txt', 'api-ref/source/samples/user-show-root-history-response.json', 'api-ref/source/samples/db-instance-discard-log-response.json', 'api-ref/source/samples/db-configuration-attach-to-instance-response-json-http.txt', 'api-ref/source/samples/db-backup-restore-request.json', 'api-ref/source/samples/instance-mgmt-action-migrate-request.json', 'api-ref/source/samples/db-list-databases-pagination-response-json-http.txt', 'api-ref/source/samples/db-backup-create-incremental-response-json-http.txt', 'api-ref/source/samples/db-config-group-details-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-response-json-http.txt', 'api-ref/source/samples/db-create-instance-request-json-http.txt', 'api-ref/source/samples/instance-create-request.json', 'api-ref/source/samples/db-backup-create-incremental-request.json', 'api-ref/source/samples/db-backup-restore-response.json', 'api-ref/source/samples/db-instance-resize-flavor-response-json-http.txt', 'api-ref/source/users.inc', 'trove/extensions/mgmt/instances/models.py', 'api-ref/source/samples/datastore-version-parameter-create-response.json', 'api-ref/source/samples/db-config-group-details-request-json-http.txt', 'api-ref/source/samples/instance-log-enable-response.json', 'api-ref/source/samples/db-backup-create-incremental-request-json-http.txt', 'api-ref/source/samples/db-list-datastore-versions-response-json-http.txt', 'api-ref/source/samples/db-configuration-delete-request-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-request.json', 'api-ref/source/samples/db-instance-resize-instance-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-root-details-response.json', 'api-ref/source/samples/db-backup-create-incremental-response.json', 'api-ref/source/samples/instance-create-response.json', 'api-ref/source/samples/db-configuration-edit-parameters-response-json-http.txt', 'api-ref/source/samples/db-version-request-json-http.txt', 'api-ref/source/databases.inc', 'api-ref/source/samples/db-detach-replica-request-json-http.txt', 'api-ref/source/samples/instance-action-resize-request.json', 'api-ref/source/samples/instance-patch-detach-replica-request.json', 'api-ref/source/samples/db-show-parameter-details-response-json-http.txt', 'api-ref/source/samples/db-create-databases-request-json-http.txt', 'api-ref/source/samples/user-check-root-response.json', 'api-ref/source/samples/datastore-version-parameter-create-request.json', 'api-ref/source/samples/db-mgmt-list-hosts-request-json-http.txt', 'api-ref/source/samples/db-list-databases-response.json', 'api-ref/source/samples/instance-backup-list-response.json', 'api-ref/source/samples/users-put-request.json', 'api-ref/source/samples/db-mgmt-instance-index-response.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-response-json-http.txt', 'api-ref/source/samples/db-change-user-attributes-request-json-http.txt', 'api-ref/source/datastore-versionss.inc', 'api-ref/source/samples/db-datastores-list-response-json-http.txt', 'api-ref/source/samples/db-list-user-access-response-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-without-datastore-version-response.json', 'api-ref/source/samples/db-instance-show-log-response.json', 'api-ref/source/samples/db-configuration-details-response.json', 'api-ref/source/samples/db-instances-index-pagination-request-json-http.txt', 'api-ref/source/samples/instance-log-disable-request.json', 'api-ref/source/samples/db-datastore-version-by-id-response-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-reset-task-status-request.json', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-response-json-http.txt', 'api-ref/source/samples/db-configuration-attach-to-instance-request-json-http.txt', 'api-ref/source/samples/db-list-users-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-instance-details-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-versions-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-host-detail-request-json-http.txt', 'api-ref/source/samples/db-disable-root-user-response-json-http.txt', 'api-ref/source/samples/db-update-config-group-response-json-http.txt', 'api-ref/source/samples/backup-get-response.json', 'api-ref/source/samples/db-delete-instance-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-storage-request-json-http.txt', 'api-ref/source/samples/db-config-group-instances-response-json-http.txt', 'api-ref/source/samples/db-get-default-instance-configuration-request-json-http.txt', 'api-ref/source/samples/databases-create-request.json', 'api-ref/source/samples/db-datastore-version-by-id-response.json', 'api-ref/source/samples/db-detach-config-group-response-json-http.txt', 'api-ref/source/samples/db-list-user-dbs-response.json', 'api-ref/source/samples/datastore-version-parameter-update-request.json', 'api-ref/source/samples/db-mgmt-list-accounts-response.json', 'api-ref/source/samples/db-faults-badRequest.json', 'api-ref/source/samples/db-backup-delete-request-json-http.txt', 'api-ref/source/samples/versions-response.json', 'api-ref/source/samples/db-grant-user-access-request-json-http.txt', 'api-ref/source/samples/db-instance-resize-volume-response-json-http.txt', 'api-ref/source/samples/db-mgmt-list-hosts-response.json', 'api-ref/source/samples/db-list-cfg-groups-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-account-details-response.json', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-response.json', 'api-ref/source/samples/db-datastore-versions-list-response-json-http.txt', 'api-ref/source/instances.inc', 'api-ref/source/samples/db-versions-request-json-http.txt', 'api-ref/source/configurations.inc', 'api-ref/source/samples/datastore-version-create-request.json', 'api-ref/source/samples/db-mgmt-get-account-details-response-json-http.txt', 'api-ref/source/samples/db-update-config-group-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-show-response.json', 'api-ref/source/samples/db-mgmt-list-accounts-response-json-http.txt', 'api-ref/source/samples/db-configuration-create-request.json', 'api-ref/source/samples/db-list-databases-pagination-request-json-http.txt', 'api-ref/source/samples/db-list-cfg-groups-request-json-http.txt', 'api-ref/source/samples/db-configuration-update-parameters-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-mgmt-get-storage-response.json', 'api-ref/source/samples/db-mgmt-instance-diagnostics-request-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-response-json-http.txt', 'api-ref/source/samples/user-show-response.json', 'api-ref/source/parameters.yaml', 'api-ref/source/samples/db-check-root-user-response-json-http.txt', 'api-ref/source/samples/config-group-show-response.json', 'api-ref/source/api-versions.inc', 'api-ref/source/samples/db-restore-delete-request-json-http.txt', 'api-ref/source/samples/db-change-users-password-request-json-http.txt', 'api-ref/source/samples/db-show-parameter-details.json', 'api-ref/source/samples/db-enable-root-user-response-json-http.txt', 'api-ref/source/database-instance-actions.inc', 'trove/common/api.py', 'api-ref/source/samples/db-faults-itemNotFound.json', 'api-ref/source/samples/db-datastore-version-by-id-request-json-http.txt', 'api-ref/source/samples/instance-log-enable-request.json', 'api-ref/source/samples/db-list-parameters-request-json-http.txt', 'api-ref/source/samples/instance-action-eject-replica-request.json', 'api-ref/source/samples/db-show-parameter-details-request-json-http.txt', 'api-ref/source/samples/datastore-version-list-response.json', 'api-ref/source/samples/instance-action-restart-request.json', 'api-ref/source/samples/db-configuration-parameter-without-datastore-version-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-instances-response.json', 'api-ref/source/samples/instance-show-response.json', 'api-ref/source/samples/db-list-user-dbs-request-json-http.txt', 'api-ref/source/samples/db-mgmt-list-accounts-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameters-for-datastore-version-response.json', 'api-ref/source/samples/db-list-datastore-versions-request-json-http.txt', 'api-ref/source/samples/db-configuration-list-request-json-http.txt', 'api-ref/source/samples/db-configuration-edit-parameters-request.json', 'api-ref/source/samples/db-change-user-attributes-response-json-http.txt', 'api-ref/source/samples/db-instance-promote-replica-request-json-http.txt', 'api-ref/source/samples/datastore-list-response.json', 'api-ref/source/samples/db-configuration-list-response-json-http.txt', 'api-ref/source/samples/db-delete-root-request-json-http.txt', 'api-ref/source/samples/db-instances-index-request-json-http.txt', 'api-ref/source/samples/db-delete-config-group-request-json-http.txt', 'api-ref/source/samples/db-enable-root-user-request-json-http.txt', 'api-ref/source/samples/db-detach-replica-response-json-http.txt', 'api-ref/source/samples/db-datastore-by-id-response-json-http.txt', 'api-ref/source/samples/db-instance-eject-replica-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-request-json-http.txt', 'api-ref/source/samples/db-configuration-parameter-for-datastore-version-response-json-http.txt', 'api-ref/source/samples/user-put-request.json', 'api-ref/source/samples/db-get-default-instance-configuration-response-json-http.txt', 'api-ref/source/samples/db-create-instance-response-json-http.txt', 'api-ref/source/samples/db-list-cfg-defaults-response.json', 'api-ref/source/samples/db-mgmt-instance-index-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-reboot-request.json', 'api-ref/source/samples/instance-action-resize-volume-request.json', 'api-ref/source/samples/db-create-instance-response.json', 'api-ref/source/samples/user-enable-root-response.json', 'api-ref/source/samples/db-attach-config-group-response-json-http.txt', 'api-ref/source/samples/db-list-users-response.json', 'api-ref/source/samples/db-mgmt-get-instance-details-response.json', 'api-ref/source/samples/db-list-cfg-defaults-request-json-http.txt', 'api-ref/source/samples/db-list-user-access-response.json', 'api-ref/source/instance-logs.inc', 'api-ref/source/samples/db-instance-enable-log-response.json', 'api-ref/source/samples/datastore-version-mgmt-patch-request.json', 'api-ref/source/samples/db-restore-delete-response-json-http.txt', 'api-ref/source/instance-actions.inc', 'api-ref/source/samples/db-mgmt-get-host-detail-response-json-http.txt', 'api-ref/source/user-management.inc', 'api-ref/source/samples/db-enable-root-user-response.json', 'api-ref/source/samples/db-list-user-dbs-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-flavor-request.json', 'api-ref/source/samples/instance-log-discard-response.json', 'api-ref/source/samples/db-mgmt-get-root-details-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-account-details-request-json-http.txt', 'api-ref/source/samples/instance-mgmt-action-stop-request.json', 'api-ref/source/samples/db-instance-publish-log-response.json', 'api-ref/source/samples/limit-show-response.json', 'api-ref/source/samples/db-instance-resize-volume-request-json-http.txt', 'api-ref/source/samples/instance-list-response.json', 'api-ref/source/samples/instance-log-list-response.json', 'api-ref/source/samples/datastore-version-parameter-update-response.json', 'api-ref/source/samples/db-change-users-password-request.json', 'api-ref/source/samples/db-delete-instance-response-json-http.txt', 'api-ref/source/samples/db-list-user-access-request-json-http.txt', 'api-ref/source/samples/config-group-list-instances-response.json', 'api-ref/source/samples/db-list-users-pagination-response-json-http.txt', 'api-ref/source/samples/db-mgmt-list-hosts-response-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-request-json-http.txt', 'api-ref/source/samples/db-configuration-create-response-json-http.txt', 'api-ref/source/quotas.inc', 'api-ref/source/samples/db-revoke-user-access-request-json-http.txt', 'api-ref/source/samples/datastore-version-show-response.json', 'api-ref/source/samples/db-list-users-response-json-http.txt', 'api-ref/source/samples/db-mgmt-get-instance-details-response-json-http.txt', 'api-ref/source/samples/db-grant-user-access-response-json-http.txt', 'api-ref/source/samples/db-backup-create-response-json-http.txt', 'api-ref/source/samples/db-backup-list-response-json-http.txt', 'api-ref/source/samples/db-instance-reboot-response-json-http.txt', 'api-ref/source/samples/db-datastore-versions-list-request-json-http.txt', 'api-ref/source/samples/db-backup-delete-response-json-http.txt', 'api-ref/source/samples/db-faults-instanceFault.json', 'api-ref/source/samples/db-mgmt-instance-index-response-json-http.txt', 'api-ref/source/samples/db-detach-config-group-request-json-http.txt', 'api-ref/source/samples/db-instance-restart-request-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-response-json-http.txt', 'api-ref/source/samples/db-check-root-user-request-json-http.txt', 'api-ref/source/samples/db-create-databases-response-json-http.txt', 'api-ref/source/backups.inc', 'api-ref/source/samples/db-instances-index-response-json-http.txt', 'api-ref/source/samples/db-instance-resize-flavor-request-json-http.txt', 'api-ref/source/samples/db-list-parameters-response.json', 'api-ref/source/samples/datastore-version-parameter-list-response.json', 'api-ref/source/samples/instance-patch-upgrade-datastore-version-request.json', 'api-ref/source/samples/db-datastores-list-request-json-http.txt', 'api-ref/source/samples/instance-action-reset-status-request.json', 'api-ref/source/samples/db-create-users-request-json-http.txt', 'api-ref/source/samples/instance-log-discard-request.json', 'api-ref/source/samples/instance-mgmt-list-response.json', 'api-ref/source/samples/config-group-patch-request.json', 'api-ref/source/samples/db-change-users-password-response-json-http.txt', 'api-ref/source/samples/user-list-response.json', 'api-ref/source/samples/db-delete-users-request-json-http.txt', 'api-ref/source/samples/backup-list-response.json', 'api-ref/source/samples/datastore-version-mgmt-list-response.json', 'api-ref/source/samples/db-list-datastore-versions.json', 'api-ref/source/samples/db-version-response-json-http.txt', 'api-ref/source/samples/db-configuration-detach-from-instance-request-json-http.txt', 'api-ref/source/samples/db-backup-get-request-json-http.txt', 'api-ref/source/samples/instance-patch-update-name-request.json', 'api-ref/source/samples/user-create-request.json', 'api-ref/source/samples/db-list-cfg-defaults-response-json-http.txt', 'api-ref/source/samples/instance-action-promote-replica-request.json', 'api-ref/source/samples/db-backup-create-request-json-http.txt', 'api-ref/source/samples/databases-list-response.json', 'api-ref/source/samples/db-configuration-list-response.json', 'api-ref/source/samples/db-detach-config-group-request.json', 'api-ref/source/samples/db-instances-index-pagination-response.json', 'api-ref/source/samples/db-list-users-pagination-request-json-http.txt', 'api-ref/source/samples/db-instance-status-detail-response.json', 'api-ref/source/samples/db-patch-config-group-response-json-http.txt', 'api-ref/source/samples/db-configuration-attach-to-instance-request.json', 'api-ref/source/samples/db-configuration-list-instances-response-json-http.txt', 'api-ref/source/samples/db-instances-index-response.json', 'api-ref/source/samples/db-revoke-user-access-response-json-http.txt', 'api-ref/source/samples/db-change-user-attributes-request.json', 'api-ref/source/samples/db-list-databases-response-json-http.txt', 'api-ref/source/datastores.inc', 'api-ref/source/samples/config-group-create-response.json', 'api-ref/source/samples/datastore-show-response.json', 'api-ref/source/samples/db-create-config-group-request-json-http.txt', 'api-ref/source/samples/db-datastore-by-id-response.json', 'api-ref/source/samples/db-mgmt-get-storage-response-json-http.txt', 'api-ref/source/samples/db-version-response.json', 'api-ref/source/samples/db-configuration-details-response-json-http.txt', 'api-ref/source/samples/db-disable-root-user-request-json-http.txt', 'api-ref/source/samples/config-group-create-request.json', 'api-ref/source/samples/config-group-put-request.json', 'api-ref/source/samples/db-configuration-details-request-json-http.txt', 'api-ref/source/samples/db-backups-by-instance-response.json', 'api-ref/source/samples/instance-list-detail-response.json', 'api-ref/source/samples/instance-configuration-list-response.json', 'api-ref/source/samples/instance-log-show-request.json', 'api-ref/source/samples/backup-create-request.json', 'api-ref/source/samples/db-datastore-parameters-response.json', 'api-ref/source/samples/db-list-databases-pagination-response.json']",307,47fb6434672bba069cb731aaa83068be4dd95c25,api-doc,,"{ ""databases"": [ { ""name"": ""anotherdb"" } ], ""links"": [ { ""href"": ""https://troveapi.org/v1.0/1234/instances/44b277eb-39be-4921-be31-3d61b43651d7/databases?limit=1&marker=anotherdb"", ""rel"": ""next"" } ] } ",2460,3837
openstack%2Fgovernance-sigs~master~I5d9e844758fa84a3491ba22f64f83769a0d8cffe,openstack/governance-sigs,master,I5d9e844758fa84a3491ba22f64f83769a0d8cffe,Tag status for SIGs and update SIG chair,MERGED,2019-11-22 04:22:26.000000000,2019-12-26 04:05:53.000000000,2019-12-26 04:04:36.000000000,"[{'_account_id': 308}, {'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 12898}, {'_account_id': 13629}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28606}]","[{'number': 1, 'created': '2019-11-22 04:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/d80738fb94886d99a270087d02412836715c3241', 'message': 'Tag advisory status for SIGs\n\nThis patch propose to tag advosory\nAdvisory presents that the SIG stay around for help, make sure\neverything stay working and provide advice when needed.\n\nChange-Id: I5d9e844758fa84a3491ba22f64f83769a0d8cffe\n'}, {'number': 2, 'created': '2019-11-22 07:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/8cabe0bcf011c46abf79c915a8f7447d8ba4fe5c', 'message': 'Tag advisory status for SIGs\n\nThis patch propose to tag advosory\nAdvisory presents that the SIG stay around for help, make sure\neverything stay working and provide advice when needed.\n\nChange-Id: I5d9e844758fa84a3491ba22f64f83769a0d8cffe\n'}, {'number': 3, 'created': '2019-11-22 16:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/b3bea08b6b0d4db6cc8d6b3f570d1740be60e406', 'message': 'Tag advisory status for SIGs and update SIG chair\n\nThis patch propose to tag advisory\nAdvisory presents that the SIG stay around for help, make sure\neverything stay working and provide advice when needed.\n\nAlso update Resource Management SIG chair list.\n\nChange-Id: I5d9e844758fa84a3491ba22f64f83769a0d8cffe\n'}, {'number': 4, 'created': '2019-12-19 04:23:51.000000000', 'files': ['sigs.yaml'], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/add9c87007d1ffcc675651c1f0a6501eb4bb399c', 'message': 'Tag status for SIGs and update SIG chair\n\nThis patch propose to update status tags. You can check [1] for more status\ninformation.\n\nAlso update Resource Management SIG chair list.\n\n[1] https://governance.openstack.org/sigs/reference/sig-status.html\n\nChange-Id: I5d9e844758fa84a3491ba22f64f83769a0d8cffe\n'}]",11,695625,add9c87007d1ffcc675651c1f0a6501eb4bb399c,38,10,4,12404,,,0,"Tag status for SIGs and update SIG chair

This patch propose to update status tags. You can check [1] for more status
information.

Also update Resource Management SIG chair list.

[1] https://governance.openstack.org/sigs/reference/sig-status.html

Change-Id: I5d9e844758fa84a3491ba22f64f83769a0d8cffe
",git fetch https://review.opendev.org/openstack/governance-sigs refs/changes/25/695625/1 && git format-patch -1 --stdout FETCH_HEAD,['sigs.yaml'],1,d80738fb94886d99a270087d02412836715c3241,update-sigs, status: advisory status: advisory status: advosory, status: active status: active status: active,3,3
openstack%2Fzaqar~master~Ib8391ec8c0aa28fb9f393e7b811dd6d951f716c9,openstack/zaqar,master,Ib8391ec8c0aa28fb9f393e7b811dd6d951f716c9,Switch to Ussuri jobs,ABANDONED,2019-12-24 10:19:34.000000000,2019-12-26 02:59:19.000000000,,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 10:19:34.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d5180c34d2aea9d26cf9a2a496bd5a3687875c5a', 'message': 'Switch to Ussuri jobs\n\nChange-Id: Ib8391ec8c0aa28fb9f393e7b811dd6d951f716c9\n'}]",0,700502,d5180c34d2aea9d26cf9a2a496bd5a3687875c5a,3,2,1,27383,,,0,"Switch to Ussuri jobs

Change-Id: Ib8391ec8c0aa28fb9f393e7b811dd6d951f716c9
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/02/700502/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d5180c34d2aea9d26cf9a2a496bd5a3687875c5a,, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fnova~master~Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996,openstack/nova,master,Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996,Add cross-cell resize policy rule and enable in API,MERGED,2019-02-20 21:15:18.000000000,2019-12-26 02:17:30.000000000,2019-12-24 00:19:54.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9725}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 26936}, {'_account_id': 27336}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-02-20 21:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a533935a932581363b747d06d90555944d402f48', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 2, 'created': '2019-02-20 21:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/162434cbe58cb01ee5ee4ffe7b954019af0e03f8', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 3, 'created': '2019-02-26 22:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94fad78d1e611bff10904f5441ddddaf7d2beec1', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 4, 'created': '2019-03-07 22:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3727cea80bd6df34d39bdb6dcec84950302fe8d0', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 5, 'created': '2019-03-08 23:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6da83b4bf8abb7dcdd809af643ab2b28d43d1f41', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 6, 'created': '2019-03-11 22:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89055a3207cd334187292eb407e73224aa53b6c4', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 7, 'created': '2019-03-14 20:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6be52369b29f95d1d0ec2a39256f54de6fd83c59', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 8, 'created': '2019-03-14 20:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/289e919f6c1bedc1e2dba0ed49df3218b48633b0', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 9, 'created': '2019-03-15 11:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0449d957caffa92708e60d41e52adeafc145389', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 10, 'created': '2019-04-01 22:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92e71534a19c15f19926b04078d02dbaa1bb2af2', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 11, 'created': '2019-04-03 21:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1b1b11ff540b7e410857f7a75093300f8f6543a', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 12, 'created': '2019-04-06 01:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0534b5f2844bcac2dfab46f7ed820ad67898104', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 13, 'created': '2019-04-08 20:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ee3656add083496804c0b09eb148f45530abe1a', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 14, 'created': '2019-04-11 19:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0aa05abeda4975e2830473dcec8663664eb13f54', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 15, 'created': '2019-04-17 22:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16e60775edb580f4a6706594b2a1b94cb0f4d886', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 16, 'created': '2019-04-19 01:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f62fb5c9736df2c7dce9f5c03b12801cb1a0a81d', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 17, 'created': '2019-04-20 22:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32acb11732fe38218736381242f8327f7ba77522', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 18, 'created': '2019-04-26 20:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2392f31214857076775fac7da50a2708afcea7de', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 19, 'created': '2019-04-30 20:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e84c688b75a4c0d20925a07103ba0bdaf0a2be1', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 20, 'created': '2019-05-01 15:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4cb0eb4b8dc876d1a275a05edfbf3efcd49cc02e', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 21, 'created': '2019-05-02 03:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a665cc4fa80ef6361b6a313ed2fa228a0f2e1e21', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 22, 'created': '2019-05-09 22:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f23fab41f708a53c668622b79b9cac20fcf262b', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 23, 'created': '2019-05-10 20:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c238d048d7cc4cb1d356b12cba858ca3568c6b0c', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 24, 'created': '2019-05-11 22:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d6085099ec947eee6e9ab9c140a1359a2900eb4', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 25, 'created': '2019-05-13 19:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52ae0f3d8d81ac07a853515b5e0f80837b2bae6e', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 26, 'created': '2019-05-16 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd22e52d93722f46680cf391cb17b38a0fcff3ff', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 27, 'created': '2019-05-16 16:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1427901b16475949c08984679290ae33fdd23f9', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 28, 'created': '2019-05-22 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/605775a3c335f10ef11907c5ee180c493fa389c9', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 29, 'created': '2019-05-28 23:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/445fd5a1f8446f96e19704ab37360db94fa795fb', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 30, 'created': '2019-05-29 21:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/729dba8b3fcae134c8d5f3fcdd048cf12d07ad16', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 31, 'created': '2019-06-10 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4db4f6b16011a18693ffdea3ea253d6481b7feef', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 32, 'created': '2019-06-27 16:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df1ef1533d8e5cf30d129d119b612f6ce4a01a4c', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 33, 'created': '2019-06-28 00:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/478585be49807da035f00755255c77fee8de32c9', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 34, 'created': '2019-07-04 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/809ebfbb6d5bae1d16da8de406a98e781e92f3c5', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 35, 'created': '2019-07-05 22:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07cc15e803fe43b05b54817a4be95cbaa1f96271', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 36, 'created': '2019-07-10 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e859ea1c133b309267d1673677baa2e5e1d953b', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 37, 'created': '2019-07-26 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dfcb6f6fd776100ac857579fdd314b4cc438664a', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 38, 'created': '2019-08-07 22:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bc7b22bd67b9cf73112f9987a92247e8af48f01', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 39, 'created': '2019-08-14 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea3cbb1590b90cb9b2182577c5f5d22239f26bc5', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 40, 'created': '2019-08-27 19:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/313e4787486f3fd1ab90a79bd650cdedb24ad4a7', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 41, 'created': '2019-09-04 18:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dde9528240e826dd703eff8fdc4495a18f979704', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 42, 'created': '2019-09-21 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/973414d93214857488529ace07c26b954a4c1478', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 43, 'created': '2019-10-03 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/551ba1db52fffbc8d62dfaa091d5f6f25e1bedbf', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 44, 'created': '2019-10-08 15:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0450ec60f44c411f143c52a3c551614549667223', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 45, 'created': '2019-10-14 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92b1f87ce559776b219d4c9c2fa72939c40dfb71', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 46, 'created': '2019-10-14 18:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bac47f1b8d7695e2c256577909faaf22a8a1245b', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 47, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cad61c7e3ff39305fcb112558fef3a30db364c84', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 48, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edd40dba1759a22a3331ecb7b2e0992d72520b2f', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 49, 'created': '2019-10-29 21:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c80527343b3f32b801853c75d12436b63acdf178', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 50, 'created': '2019-10-29 21:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5af1b9f4a6e3bd7bd63063e380a163547228c7ad', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 51, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aee84c0af4e84084230b3423b014708f0d3b58ba', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 52, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/432d28c92518e8ee7c89ff43ac6f38cc33b99dcc', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 53, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd6b37566815fb5e1cece871b747a25a8777e8a', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 54, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4469e477eace859fb60c91a8448715909193c4e4', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 55, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98d470be655941611f167876a0368c0f28d7fd88', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 56, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9208dd54dd393857679d29a0fa288f70847cbb9b', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 57, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cd45135e3b5b9e2d671169bb632bdb9e5796bf6', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 58, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff0992f5733eb717b34f1d52ad5ca9eef7cdb278', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 59, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b04ecd397a8d9386a32872e8d523a0be4f20258f', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 60, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4924a266ddf2e197f1e99944e1898bcde91fec6f', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 61, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/536ab3ef0f1fdd0713c379df6cb3b20d84211e57', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 62, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df0abd271494e37d689f050e0edc11e05dd1fa33', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 63, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07a205addb1c10dfce536344b01f2587406022e3', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}, {'number': 64, 'created': '2019-12-23 15:11:19.000000000', 'files': ['doc/source/admin/configuration/cross-cell-resize.rst', 'releasenotes/notes/cross-cell-resize-37a735adadbafe91.yaml', 'nova/tests/unit/test_policy.py', 'nova/tests/unit/compute/test_compute_api.py', 'doc/source/admin/configuration/resize.rst', 'nova/tests/functional/test_cross_cell_migrate.py', 'doc/source/admin/configuration/index.rst', 'nova/policies/base.py', 'nova/policies/servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ebee92445d799a2e610116cf72b4bf3d3d6a2f3', 'message': 'Add cross-cell resize policy rule and enable in API\n\nThis adds the ""compute:servers:resize:cross_cell"" policy\nrule which is now used in the API to determine if a resize\nor cold migrate operation can be performed across cells.\n\nThe check in the API is based on:\n\n- The policy check passing for the request.\n- The minimum nova-compute service version being high\n  enough across all cells to perform a cross-cell resize.\n\nIf either of those conditions fail a traditional same-cell\nresize will be performed.\n\nA docs stub is added here and will be fleshed out in an\nupcoming patch.\n\nImplements blueprint cross-cell-resize\n\nChange-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996\n'}]",23,638269,6ebee92445d799a2e610116cf72b4bf3d3d6a2f3,594,21,64,6873,,,0,"Add cross-cell resize policy rule and enable in API

This adds the ""compute:servers:resize:cross_cell"" policy
rule which is now used in the API to determine if a resize
or cold migrate operation can be performed across cells.

The check in the API is based on:

- The policy check passing for the request.
- The minimum nova-compute service version being high
  enough across all cells to perform a cross-cell resize.

If either of those conditions fail a traditional same-cell
resize will be performed.

A docs stub is added here and will be fleshed out in an
upcoming patch.

Implements blueprint cross-cell-resize

Change-Id: Ie8a0f79a3b16e02b7a34a1b81f547013a3d88996
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/638269/30 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/configuration/cross-cell-resize.rst', 'nova/tests/unit/test_policy.py', 'nova/tests/unit/compute/test_compute_api.py', 'doc/source/admin/configuration/resize.rst', 'nova/tests/functional/test_cross_cell_migrate.py', 'doc/source/admin/configuration/index.rst', 'nova/tests/functional/integrated_helpers.py', 'nova/policies/base.py', 'nova/policies/servers.py', 'nova/compute/api.py']",10,a533935a932581363b747d06d90555944d402f48,bp/cross-cell-resize,"MIN_COMPUTE_CROSS_CELL_RESIZE = 43 # First check to see if the requesting project/user is allowed by # policy to perform cross-cell resize. allowed = context.can( servers_policies.CROSS_CELL_RESIZE, target={'user_id': instance.user_id, 'project_id': instance.project_id}, fatal=False) # If the user is allowed by policy, check to make sure the deployment # is upgraded to the point of supporting cross-cell resize on all # compute services. if allowed: # TODO(mriedem): We can remove this minimum compute version check # in the 21.0.0 ""U"" release. min_compute_version = ( objects.service.get_minimum_version_all_cells( context, ['nova-compute'])) if min_compute_version < MIN_COMPUTE_CROSS_CELL_RESIZE: LOG.debug('Request is allowed by policy to perform cross-cell ' 'resize but the minimum nova-compute service ' 'version in the deployment %s is less than %s so ' 'cross-cell resize is not allowed at this time.', min_compute_version, MIN_COMPUTE_CROSS_CELL_RESIZE) allowed = False return allowed"," # TODO(mriedem): Uncomment this when confirm/revert are done. For now # this method can just be used to internally enable the feature for # functional testing. # TODO(mriedem): If true, we should probably check if all of the # computes are running a high enough service version and if not, do # what? Raise an exception or just log something and return False? # return context.can( # server_policies.CROSS_CELL_RESIZE, # target={'user_id': instance.user_id, # 'project_id': instance.project_id}, # fatal=False) return False",122,29
openstack%2Fnova~master~Iff8194c868580facb1cc81b5567d66d4093c5274,openstack/nova,master,Iff8194c868580facb1cc81b5567d66d4093c5274,Implement cleanup_instance_network_on_host for neutron API,MERGED,2019-12-03 19:03:48.000000000,2019-12-26 02:06:29.000000000,2019-12-26 02:04:03.000000000,"[{'_account_id': 782}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-03 19:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08ff2ddb8049d13034bc7294886e3774df74ebaa', 'message': 'WIP: Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 2, 'created': '2019-12-03 22:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65f6bf8dec0e3bbf14fb34eaf9bb6614738831fb', 'message': 'WIP: Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 3, 'created': '2019-12-04 14:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e3bc9ec522cdd52bef2f8cbdb38468c31be86a3', 'message': 'WIP: Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 4, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/359843ebbcd682f00b2c09ad40def145d418f679', 'message': 'Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 5, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28e073511588e0b3d6810cbca0e4c27d008ceda0', 'message': 'Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 6, 'created': '2019-12-09 20:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2d47b76c97d86449b76946df74f08bcdbc418af', 'message': 'Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 7, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/142bbe5e03877a4072209a44d984ac72db582b51', 'message': 'Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}, {'number': 8, 'created': '2019-12-23 15:11:19.000000000', 'files': ['nova/network/neutronv2/api.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/92bf69bfa52f56b359cb3a6f0871f7cc4ec6bdf9', 'message': 'Implement cleanup_instance_network_on_host for neutron API\n\nThis implements the cleanup_instance_network_on_host method\nin the neutron API which will delete port bindings for the\ngiven instance and the given host, similar to how\nsetup_networks_on_host works when teardown=True and the\ninstance.host does not match the host provided to that method.\n\nThis allows removing the hacks in the\n_confirm_snapshot_based_resize_delete_port_bindings and\n_revert_snapshot_based_resize_at_dest methods.\n\nChange-Id: Iff8194c868580facb1cc81b5567d66d4093c5274\n'}]",6,697162,92bf69bfa52f56b359cb3a6f0871f7cc4ec6bdf9,91,11,8,6873,,,0,"Implement cleanup_instance_network_on_host for neutron API

This implements the cleanup_instance_network_on_host method
in the neutron API which will delete port bindings for the
given instance and the given host, similar to how
setup_networks_on_host works when teardown=True and the
instance.host does not match the host provided to that method.

This allows removing the hacks in the
_confirm_snapshot_based_resize_delete_port_bindings and
_revert_snapshot_based_resize_at_dest methods.

Change-Id: Iff8194c868580facb1cc81b5567d66d4093c5274
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/697162/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",3,08ff2ddb8049d13034bc7294886e3774df74ebaa,bp/cross-cell-resize," LOG.debug('Deleting port bindings for source host.', instance=instance) try: self.network_api.cleanup_instance_network_on_host( ctxt, instance, self.host) except exception.PortBindingDeletionFailed as e: # Do not let this stop us from cleaning up since the guest # is already gone. LOG.error('Failed to delete port bindings from source host. ' 'Error: %s', six.text_type(e), instance=instance) # Delete port bindings for the target host. LOG.debug('Deleting port bindings for target host %s.', self.host, instance=instance) try: # Note that deleting the destination host port bindings does # not automatically activate the source host port bindings. self.network_api.cleanup_instance_network_on_host( ctxt, instance, self.host) except exception.PortBindingDeletionFailed as e: # Do not let this stop us from cleaning up since the guest # is already gone. LOG.error('Failed to delete port bindings from target host. ' 'Error: %s', six.text_type(e), instance=instance)"," # setup_networks_on_host relies on the instance.host not being the same # as the host we pass in, so we have to mutate the instance to # effectively trick this code. with utils.temporary_mutation(instance, host=migration.dest_compute): LOG.debug('Deleting port bindings for source host.', instance=instance) try: self.network_api.setup_networks_on_host( ctxt, instance, host=self.host, teardown=True) except exception.PortBindingDeletionFailed as e: # Do not let this stop us from cleaning up since the guest # is already gone. LOG.error('Failed to delete port bindings from source host. ' 'Error: %s', six.text_type(e), instance=instance) # Delete port bindings for the target host. This relies on the # instance.host not being the same as the host we pass in, so we # have to mutate the instance to effectively trick this code. with utils.temporary_mutation(instance, host=migration.source_compute): LOG.debug('Deleting port bindings for target host %s.', self.host, instance=instance) try: # Note that deleting the destination host port bindings does # not automatically activate the source host port bindings. self.network_api.setup_networks_on_host( ctxt, instance, host=self.host, teardown=True) except exception.PortBindingDeletionFailed as e: # Do not let this stop us from cleaning up since the guest # is already gone. LOG.error('Failed to delete port bindings from target host. ' 'Error: %s', six.text_type(e), instance=instance)",97,94
openstack%2Fnova~master~I32334afdbff2f17d6a1e98dfb29d393575e71080,openstack/nova,master,I32334afdbff2f17d6a1e98dfb29d393575e71080,WIP: Add negative test to delete server during cross-cell resize claim,NEW,2019-10-15 23:10:45.000000000,2019-12-26 02:01:04.000000000,,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-15 23:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ce0e922823e7f38e391e4a456ec9079906c2c50', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\nTODO: open a bug for the latent issue during same-cell resize rollback\n'}, {'number': 2, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cef9db83447abddb01a7077c8a26557e008448c', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\nTODO: open a bug for the latent issue during same-cell resize rollback\n'}, {'number': 3, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d3173c85e15a04b89298cf607a011dc121e8382', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 4, 'created': '2019-10-29 21:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84e855b00cce28d1beae70dc57cb5612066e6990', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 5, 'created': '2019-10-29 21:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/702d3baf16bd6e5f836ea635b0a90429e38d164c', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 6, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0027cfef392f305dd661635c22369ae00a3c9d70', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 7, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08b403bcab9cf6702a34af156da3adc5100baece', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 8, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3d53da1f81fc6c71c797ca98807cfcbab25a148', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 9, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98d8dc1a4cc5966dd5396dc8df2c5ccebf4bdd3a', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 10, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e12e550acd326196b14784e5172b87a48ca17e59', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 11, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/105afe35e7bf50fd110ee1b7ecaacd1ce456d4ea', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 12, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e72b924fce7163b2f432b6b987ff4143d095a5f3', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 13, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd4ba343832256e68aa238468bccf463359c8f18', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 14, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ab4dbdba600049ea41e9723398294c11050e91e', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 15, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f960bc9d666e7048aefcac894cab65794aca87e', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 16, 'created': '2019-12-02 16:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9859d8ec2001146e29c1130aa6c4ff51f8b7de3', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 17, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b55cb47f8da7e051284c41589719e6f7613f008', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 18, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d59f49f5b66d2b6d8a62cf8c5288cf46ec30e0fb', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 19, 'created': '2019-12-09 20:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1826fa9d24dbaaac573eb5f62691fb932dabfb6', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 20, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ba86c581c6d6f102c45c822f1e9f063e806c625', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 21, 'created': '2019-12-14 21:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a49eb305c4ab402a9432492751bd30c51a618d7', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 22, 'created': '2019-12-16 16:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7210171fa10df15e2efd434da8c6838e8d1d439', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 23, 'created': '2019-12-16 17:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07230019839b42a6f3d1a75bb943597a25a6c3e2', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 24, 'created': '2019-12-17 15:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1392d201fc49a55a2c4a89f4cfcaee4e5c22edef', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 25, 'created': '2019-12-20 16:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/657c0d50af06bc0889915495b164fda447669a30', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}, {'number': 26, 'created': '2019-12-23 15:11:19.000000000', 'files': ['nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py', 'nova/tests/functional/test_cross_cell_migrate.py', 'nova/conductor/tasks/migrate.py', 'nova/scheduler/client/report.py', 'nova/conductor/tasks/cross_cell_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e72f0e6da6a1ec9e41c3b3a98c2c01f5ac1c5a60', 'message': 'WIP: Add negative test to delete server during cross-cell resize claim\n\nThis adds a test based on review feedback [1] to see what happens\nif the server is deleted from the source cell while a cross-cell\nresize is claiming resources on the target host in the target cell.\nThe test ensures that the server is deleted from both the source\nand target cell databases and volume attachments are cleaned up.\n\nThe test does expose a latent bug in the MigrationTask.rollback\ncode which moves the source node allocations, held by the migration\nconsumer, to the now-deleted instance. This is masked in part\nby the SchedulerReportClient.move_allocations method not checking\nthat the target consumer has a generation so we POST /allocations\nand re-create the instance allocations on the source node.\n\nWhile in here I realized that the _cold_migrate method is not\ngracefully handling InstanceNotFound when calling instance.refresh()\nand that Migration.save() does not raise MigrationNotFound even if\nthe migration record is soft-deleted so a comment is left for that.\nThose are really issues that should be dealt with separately.\n\n[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495\n\nRelated-Bug: #1848343\n\nChange-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080\n'}]",15,688832,e72f0e6da6a1ec9e41c3b3a98c2c01f5ac1c5a60,201,12,26,6873,,,0,"WIP: Add negative test to delete server during cross-cell resize claim

This adds a test based on review feedback [1] to see what happens
if the server is deleted from the source cell while a cross-cell
resize is claiming resources on the target host in the target cell.
The test ensures that the server is deleted from both the source
and target cell databases and volume attachments are cleaned up.

The test does expose a latent bug in the MigrationTask.rollback
code which moves the source node allocations, held by the migration
consumer, to the now-deleted instance. This is masked in part
by the SchedulerReportClient.move_allocations method not checking
that the target consumer has a generation so we POST /allocations
and re-create the instance allocations on the source node.

While in here I realized that the _cold_migrate method is not
gracefully handling InstanceNotFound when calling instance.refresh()
and that Migration.save() does not raise MigrationNotFound even if
the migration record is soft-deleted so a comment is left for that.
Those are really issues that should be dealt with separately.

[1] https://review.opendev.org/#/c/627890/60/nova/conductor/tasks/cross_cell_migrate.py@495

Related-Bug: #1848343

Change-Id: I32334afdbff2f17d6a1e98dfb29d393575e71080
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/688832/21 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py', 'nova/tests/functional/test_cross_cell_migrate.py', 'nova/conductor/tasks/migrate.py', 'nova/scheduler/client/report.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/cross_cell_migrate.py']",6,2ce0e922823e7f38e391e4a456ec9079906c2c50,bp/cross-cell-resize, self.instance.save(expected_task_state=task_states.RESIZE_PREP), self.instance.save(),101,10
openstack%2Fnova~master~Ia4f3671c40e69674afc7a96b5d9b198dabaa4224,openstack/nova,master,Ia4f3671c40e69674afc7a96b5d9b198dabaa4224,Enable cross-cell resize in the nova-multi-cell job,MERGED,2019-05-01 15:36:51.000000000,2019-12-26 01:50:35.000000000,2019-12-24 06:54:21.000000000,"[{'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-05-01 15:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa45babd6cb54734db5dc00ddfc4a968f5e4dd76', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup is done after devstack is\ndone stacking but before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 2, 'created': '2019-05-02 03:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/459d1a1613e5f47f2f160aa597457693dd671242', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup is done after devstack is\ndone stacking but before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 3, 'created': '2019-05-02 15:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7b1156310d8df8356d3ffdd424ab8c323a53b84', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup is done after devstack is\ndone stacking but before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 4, 'created': '2019-05-03 15:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e01175717ab6ccce197b033ad6fdcdcf355d58c', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 5, 'created': '2019-05-03 21:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/035b5927ea416e9a610307618bf679561d84c02d', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 6, 'created': '2019-05-04 13:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e25703ed564e1013cc4cfa8c521837321aa6f9e0', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 7, 'created': '2019-05-09 22:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3363ae0629d62f0fe5b27377c20673b89f7a0d4', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 8, 'created': '2019-05-10 20:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a597443f3fa0193841d04834cfd6436719c66fc', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 9, 'created': '2019-05-11 22:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78a3d2d4e63c4d63a177ce71594847ca9515f49b', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 10, 'created': '2019-05-13 19:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e811b6f01877884db84c933d5377e82194fc259', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 11, 'created': '2019-05-16 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/952dcd74b3e7881542c6035e8a76a2f461146115', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 12, 'created': '2019-05-16 16:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/473e4471d0c4190193b4e92848dbab192465e259', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 13, 'created': '2019-05-22 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3943b451f80d0a73a7e8d3d9853de97b21df345', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 14, 'created': '2019-05-23 16:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97c136bc0a731d99fc551ca4f87ec5f5fe620387', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 15, 'created': '2019-05-23 22:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c3676b42ef293b15772b68f47444b07ac34caa7', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 16, 'created': '2019-05-28 23:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63e3dbd41a8e62ec501267fc792b6160dc29aa95', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 17, 'created': '2019-05-29 21:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da2c97b6040914c3fce3c4618ff7b282ca96f648', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 18, 'created': '2019-06-10 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17242f5895f4d1f55b9f2f3648f657e9ccaf583a', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 19, 'created': '2019-06-27 16:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc2317621b545b674f2b91d54b699b2b20ced911', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 20, 'created': '2019-06-28 00:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/736fb9e2aa324851b1dec025c4b26e14f1734519', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 21, 'created': '2019-07-04 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55ca4e20080b4b2a7de8d5406207189082d0d599', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 22, 'created': '2019-07-05 22:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e864f38cee493d06c7c3bd7c9beec0e476e5e40e', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 23, 'created': '2019-07-10 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fab80e1ebc17a382d76c558108d562602af1102', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 24, 'created': '2019-07-26 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcb3b565d4c312cf64242f5999dd19d1313f3806', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 25, 'created': '2019-08-07 22:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbbc446eb45cbe2fdf3380f19ba083e84e650a1d', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 26, 'created': '2019-08-14 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3bb78081fac64673c6f0584384fc6940a15571f', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 27, 'created': '2019-08-27 19:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f69301be7b51f4cff33dd95ca49feaf554b02b94', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 28, 'created': '2019-09-04 18:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b869edb434e4cd14669af7e8275016e3198a7694', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 29, 'created': '2019-09-21 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4a3f0bc3744b2f275086768efc823c1e1b700d6', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 30, 'created': '2019-10-03 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63ce84f225aca56d7b784bfa33a1aa0eac9852c9', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 31, 'created': '2019-10-08 15:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/257b07cade85d874718a2c83e3d15c2473e176b6', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 32, 'created': '2019-10-14 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c42dae5975ac389f52a02e2fdfe8d3ad4c74cfca', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 33, 'created': '2019-10-14 18:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4ef46cab7bd2353424f30abcf414db7494ed562', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 34, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a2aeb66900aa1ff8a896bcc9190ba662939c697', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 35, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93571d873aa3c0187e182e95f0214afa655657a8', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 36, 'created': '2019-10-29 21:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ddb349eaf00401fd74945b0ff8b3d821f1bdb949', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 37, 'created': '2019-10-29 21:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2115194b032791f1a9942e3b1708106e04726445', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 38, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54b636c2a866a39e22964aecc7fcd9432a9f40f6', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 39, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fd50e572b05ec8198121d5cf69dac161fde6a08', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 40, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/947eb9bbef1e1c3e0f8bc6c31be7e290345d67a1', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 41, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cca5263f0548b2c8d6512af565432b00d99facf', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 42, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e70f2c210d373434814515af67d7743b4a4ffa7', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 43, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e988034d88e8ecb96d25874bc7f4e86143f6ea38', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 44, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccdd3da4a54651767649661ce978579d25eb7ce9', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 45, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb506aa2099d810fc89aa1e503db2e9c6a138ec3', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 46, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7072dfec9e7a6a75c4e58c3743a70c621686e4d', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 47, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66eeac401ca396baf96c32b08a4b5d7831ac1909', 'message': 'WIP: Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 48, 'created': '2019-12-02 16:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28f4228dc5ac6b4069b787cf84396a743b28cae5', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 49, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/823294ce28c0cef236b37f2ed7ff4ada40857a88', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 50, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a42fe99324a8e46242da6f65da70104b3e21c832', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 51, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3dcf86efba76cf421017d709ad67b390460d5ac', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}, {'number': 52, 'created': '2019-12-23 15:11:19.000000000', 'files': ['playbooks/nova-multi-cell/pre.yaml', 'roles/setup-multi-cell-policy/defaults/main.yaml', 'roles/setup-multi-cell-policy/README.rst', 'roles/setup-multi-cell-policy/tasks/main.yaml', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/7661995b69c3302533646dc72446fcdea496e589', 'message': 'Enable cross-cell resize in the nova-multi-cell job\n\nThis changes the nova-multi-cell job to essentially\nforce cross-cell resize and cold migration. By ""force""\nI mean there is only one compute in each cell and\nresize to the same host is disabled, so the scheduler\nhas no option but to move the server to the other cell.\n\nThis adds a new role to write the nova policy.yaml file\nto enable cross-cell resize and a pre-run playbook so\nthat the policy file setup before tempest runs.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224\n'}]",16,656656,7661995b69c3302533646dc72446fcdea496e589,539,19,52,6873,,,0,"Enable cross-cell resize in the nova-multi-cell job

This changes the nova-multi-cell job to essentially
force cross-cell resize and cold migration. By ""force""
I mean there is only one compute in each cell and
resize to the same host is disabled, so the scheduler
has no option but to move the server to the other cell.

This adds a new role to write the nova policy.yaml file
to enable cross-cell resize and a pre-run playbook so
that the policy file setup before tempest runs.

Part of blueprint cross-cell-resize

Change-Id: Ia4f3671c40e69674afc7a96b5d9b198dabaa4224
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/656656/45 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/nova-multi-cell/pre.yaml', 'roles/setup-multi-cell-policy/defaults/main.yaml', 'roles/setup-multi-cell-policy/README.rst', 'roles/setup-multi-cell-policy/tasks/main.yaml', '.zuul.yaml']",5,fa45babd6cb54734db5dc00ddfc4a968f5e4dd76,bp/cross-cell-resize," post-config: $NOVA_CONF: oslo_policy: # The default policy file is policy.json but the # setup-multi-cell-policy role will write to policy.yaml. policy_file: policy.yaml # Enable cold migration for migrating across cells. Note that # because NOVA_ALLOW_MOVE_TO_SAME_HOST=false, all cold migrations # will move across cells. cold_migration: true # Disable resize to the same host so all resizes will move across # cells. NOVA_ALLOW_MOVE_TO_SAME_HOST: false # Perform setup for the multi-cell environment after devstack is done # but before tempest runs. pre-run: playbooks/nova-multi-cell/pre.yaml", # TODO(mriedem): Enable cold migration once cross-cell resize is # supported. We cannot enable it until then because this job has # one compute in each cell and with # allow_resize_to_same_host=True cold migrate will try to migrate # on the same host which is not supported by the libvirt driver. cold_migration: false # Resize to the same host is supported for now since we only have # two computes and they are in different cells. # TODO(mriedem): Disable resize to the same host once cross-cell resize # is supported so all resizes will move across cells. NOVA_ALLOW_MOVE_TO_SAME_HOST: true,45,11
openstack%2Fnova~master~I13f07a2d45bf5b8584adc8aa079bae640cb5c470,openstack/nova,master,I13f07a2d45bf5b8584adc8aa079bae640cb5c470,Flesh out docs for cross-cell resize/cold migrate,MERGED,2019-11-27 00:25:33.000000000,2019-12-26 01:50:28.000000000,2019-12-24 09:39:06.000000000,"[{'_account_id': 6873}, {'_account_id': 9708}, {'_account_id': 13252}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d275dc5463207d7fc06c6dc965a3eb759c901b90', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 2, 'created': '2019-12-02 16:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1826ebecd0d85b5b11e85667a556b49b61db8628', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 3, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6c5bd09f5d33753db9417c52690c9d42a07b8d3', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 4, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c62924bae584a1fea8089b8ac168a57cf2c6fe9e', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 5, 'created': '2019-12-09 20:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d778147e16646616e4967ace148cbbb964a0ef2f', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 6, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/861d702dff46434ae0f2d328e36b43543c8e43c0', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}, {'number': 7, 'created': '2019-12-23 15:11:19.000000000', 'files': ['doc/source/admin/configuration/cross-cell-resize.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/aa74ac60e2aaf8c131b87c86336cffc938687de2', 'message': ""Flesh out docs for cross-cell resize/cold migrate\n\nThis gives most of the high level information. I'm sure there\nare more troubleshooting things we can add but those could come\nlater as they crop up.\n\nThe sequence diagram(s) will come in a separate change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470\n""}]",26,696212,aa74ac60e2aaf8c131b87c86336cffc938687de2,75,11,7,6873,,,0,"Flesh out docs for cross-cell resize/cold migrate

This gives most of the high level information. I'm sure there
are more troubleshooting things we can add but those could come
later as they crop up.

The sequence diagram(s) will come in a separate change.

Part of blueprint cross-cell-resize

Change-Id: I13f07a2d45bf5b8584adc8aa079bae640cb5c470
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/696212/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/configuration/cross-cell-resize.rst'],1,d275dc5463207d7fc06c6dc965a3eb759c901b90,bp/cross-cell-resize,"Historically resizing and cold migrating a server has been explicitly `restricted`_ to within the same cell in which the server already exists. The cross-cell resize feature allows configuring nova to allow resizing and cold migrating servers across cells. The full design details are in the `Ussuri spec`_ and there is a `video`_ from a summit talk with a high-level overview. .. _restricted: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/conductor/tasks/migrate.py#L164 .. _Ussuri spec: https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/cross-cell-resize.html .. _video: https://www.openstack.org/videos/summits/denver-2019/whats-new-in-nova-cellsv2 Use case ~~~~~~~~ There are many reasons to use multiple cells in a nova deployment beyond just scaling the database and message queue. Cells can also be used to shard a deployment by hardware generation and feature functionality. When sharding by hardware generation, it would be natural to setup a host aggregate for each cell and map flavors to the aggregate. Then when it comes time to decommission old hardware the deployer could provide new flavors and request that users resize to the new flavors, before some deadline, which under the covers will migrate their servers to the new cell with newer hardware. Administrators could also just cold migrate the servers during a maintenance window to the new cell. Requirements ~~~~~~~~~~~~ To enable cross-cell resize functionality the following conditions must be met. Minimum compute versions ------------------------ All compute services must be upgraded to Ussuri or later and not be pinned to older RPC API versions in :oslo.config:option:`upgrade_levels.compute`. Policy configuration -------------------- The policy rule ``compute:servers:resize:cross_cell`` controls who can perform a cross-cell resize or cold migrate operation. By default the policy disables the functionality for *all* users. A microversion is not required to opt into the behavior, just passing the policy check. As such, it is recommended to start by allowing only certain users to be able to perform a cross-cell resize or cold migration, for example by setting the rule to ``rule:admin_api`` or some other rule for test teams but not normal users until you are comfortable supporting the feature. Compute driver -------------- There are no special compute driver implementations required to support the feature, it is built on existing driver interfaces used during resize and shelve/unshelve. However, only the libvirt compute driver has integration testing in the ``nova-multi-cell`` CI job. Notifications ~~~~~~~~~~~~~ The types of events and their payloads remain unchanged. The major difference from same-cell resize is the *publisher_id* may be different in some cases since some events are sent from the conductor service rather than a compute service. For example, with same-cell resize the ``instance.resize_revert.start`` notification is sent from the source compute host in the `finish_revert_resize`_ method but with cross-cell resize that same notification is sent from the conductor service. Obviously the actual message queue sending the notifications would be different for the source and target cells assuming they use separate transports. .. _finish_revert_resize: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/compute/manager.py#L4326 Instance actions ~~~~~~~~~~~~~~~~ The overall instance actions named ``resize``, ``confirmResize`` and ``revertResize`` are the same as same-cell resize. However, the *events* which make up those actions will be different for cross-cell resize since the event names are generated based on the compute service methods involved in the operation and there are different methods involved in a cross-cell resize. This is important for triage when a cross-cell resize operation fails. Scheduling ~~~~~~~~~~ .. TODO: link to CrossCellWeigher docs when published. A ``CrossCellWeigher`` is enabled by default. When a scheduling request allows selecting compute nodes from another cell the weigher will by default *prefer* hosts within the source cell over hosts from another cell. However, this behavior is configurable using the ``[filter_scheduler]/cross_cell_move_weight_multiplier`` configuration option if, for example, you want to drain old cells when resizing or cold migrating. Code flow ~~~~~~~~~ The end user experience is meant to not change, i.e. status transitions. A successfully cross-cell resized server will go to ``VERIFY_RESIZE`` status and from there the user can either confirm or revert the resized server using the normal `confirmResize`_ and `revertResize`_ server action APIs. Under the covers there are some differences from a traditional same-cell resize: * There is no inter-compute interaction. Everything is synchronously `orchestrated`_ from the (super)conductor service. This uses the :oslo.config:option:`long_rpc_timeout` configuration option. * The orchestration tasks in the (super)conductor service are in charge of creating a copy of the instance and its related records in the target cell database at the beginning of the operation, deleting them in case of rollback or when the resize is confirmed/reverted, and updating the ``instance_mappings`` table record in the API database. * Non-volume-backed servers will have their root disk uploaded to the image service as a temporary snapshot image just like during the `shelveOffload`_ operation. When finishing the resize on the destination host in the target cell that snapshot image will be used to spawn the guest and then the snapshot image will be deleted. .. _confirmResize: https://docs.openstack.org/api-ref/compute/#confirm-resized-server-confirmresize-action .. _revertResize: https://docs.openstack.org/api-ref/compute/#revert-resized-server-revertresize-action .. _orchestrated: https://opendev.org/openstack/nova/src/branch/master/nova/conductor/tasks/cross_cell_migrate.py .. _shelveOffload: https://docs.openstack.org/api-ref/compute/#shelf-offload-remove-server-shelveoffload-action Sequence diagram ---------------- .. todo:: Add diagrams for what happens with the resize, confirm and revert flows like in https://review.opendev.org/695759/.* Instances with ports attached that have :doc:`bandwidth-aware </admin/ports-with-resource-requests>` resource provider allocations. * Rescheduling to alternative hosts within the same target cell in case the primary selected host fails the ``prep_snapshot_based_resize_at_dest`` call. These may not work since they have not been validated by integration testing: Other limitations: * The config drive associated with the server, if there is one, will be re-generated on the destination host in the target cell. Therefore if the server was created with `personality files`_ they will be lost. However, this is no worse than `evacuating`_ a server that had a config drive when the source and destination compute host are not on shared storage or when shelve offloading and unshelving a server with a config drive. If necessary, the resized server can be rebuilt to regain the personality files. .. _personality files: https://docs.openstack.org/api-guide/compute/server_concepts.html#server-personality .. _evacuating: https://docs.openstack.org/api-ref/compute/#evacuate-server-evacuate-action Troubleshooting ~~~~~~~~~~~~~~~ Timeouts -------- Configure a :ref:`service user <user_token_timeout>` in case the user token times out, e.g. during the snapshot and download of a large server image. If RPC calls are timing out with a ``MessagingTimeout`` error in the logs, check the :oslo.config:option:`long_rpc_timeout` option to see if it is high enough though the default value (30 minutes) should be sufficient. Recovering from failure ----------------------- The orchestration tasks in conductor that drive the operation are built with rollbacks so each part of the operation can be rolled back in order if a subsequent task fails. The thing to keep in mind is the ``instance_mappings`` record in the API DB is the authority on where the instance ""lives"" and that is where the API will go to show the instance in a ``GET /servers/{server_id}`` call or any action performed on the server, including deleting it. So if the resize fails and there is a copy of the instance and its related records in the target cell, the tasks should automatically delete them but if not you can hard-delete the records from whichever cell is *not* the one in the ``instance_mappings`` table. If the instance is in ``ERROR`` status, check the logs in both the source and destination compute service to see if there is anything that needs to be manually recovered, for example volume attachments or port bindings, and also check the conductor service logs. Assuming volume attachments and port bindings are OK (current and pointing at the correct host), then try hard rebooting the server to get it back to ``ACTIVE`` status. If that fails, you may need to `rebuild`_ the server on the source host. .. _rebuild: https://docs.openstack.org/api-ref/compute/#rebuild-server-rebuild-action","Train spec: https://specs.openstack.org/openstack/nova-specs/specs/train/approved/cross-cell-resize.html .. todo:: Flesh this out to describe what cross-cell resize is, how it is triggered (policy), related configuration (long_rpc_timeout) including the CrossCellWeigher, limitations and known issues, recovering from failures during a cross-cell resize, maybe a flow chart for the overall process in the code, minimum upgrade requirements and supported drivers (libvirt-only at this time).* Instances with ports attached that have bandwidth-aware resource provider allocations. * Reschedules These are likely not to work since they have not been validated by testing:",190,11
openstack%2Fnova~master~I8053765797f097859bf585459f4a00d31844708e,openstack/nova,master,I8053765797f097859bf585459f4a00d31844708e,Simplify FinishResizeAtDestTask event handling,MERGED,2019-11-21 01:10:40.000000000,2019-12-26 01:49:23.000000000,2019-12-25 20:08:39.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ece6a5eb37276cc14ef03400ded6d3fbe1f574d6', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 2, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51b1d5f196cbb283244f2fb7e34acabc0d560cf7', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 3, 'created': '2019-12-02 16:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b809e8a0eb899bc90c9e5dd19a197c3e4a049ef', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 4, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8729a6e316344fb3db13ea399b4e51bc212df7e9', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 5, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fd6e28c2b22858b29740c8ca0b35c35748d2891', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 6, 'created': '2019-12-09 20:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fc79683c448045f6222e2ff193ad3e7cce79570', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 7, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c58cfa53ab79c5011b37b7ba6133da3ff47ffd00', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}, {'number': 8, 'created': '2019-12-23 15:11:19.000000000', 'files': ['nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py', 'nova/conductor/tasks/cross_cell_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/166df253258e9423ce24a2f00254846f0583e47f', 'message': 'Simplify FinishResizeAtDestTask event handling\n\nRather than copy the instance action event from the target\ncell DB to the source cell DB when\n_finish_snapshot_based_resize_at_dest fails on the dest host,\nwe can simply use the EventReporter context in conductor with\nthe source cell context and get the same event.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I8053765797f097859bf585459f4a00d31844708e\n'}]",3,695337,166df253258e9423ce24a2f00254846f0583e47f,127,12,8,6873,,,0,"Simplify FinishResizeAtDestTask event handling

Rather than copy the instance action event from the target
cell DB to the source cell DB when
_finish_snapshot_based_resize_at_dest fails on the dest host,
we can simply use the EventReporter context in conductor with
the source cell context and get the same event.

Part of blueprint cross-cell-resize

Change-Id: I8053765797f097859bf585459f4a00d31844708e
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/695337/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py', 'nova/conductor/tasks/cross_cell_migrate.py']",2,ece6a5eb37276cc14ef03400ded6d3fbe1f574d6,bp/cross-cell-resize," event_name = 'compute_finish_snapshot_based_resize_at_dest' source_cell_context = self.source_cell_instance._context try: with compute_utils.EventReporter( source_cell_context, event_name, self.migration.dest_compute, self.instance.uuid): self.compute_rpcapi.finish_snapshot_based_resize_at_dest( self.context, self.instance, self.migration, self.snapshot_id, self.request_spec)"," try: self.compute_rpcapi.finish_snapshot_based_resize_at_dest( self.context, self.instance, self.migration, self.snapshot_id, self.request_spec) source_cell_context = self.source_cell_instance._context # wrap_instance_event (this is best effort) self._copy_finish_snapshot_based_resize_at_dest_event( source_cell_context) def _copy_finish_snapshot_based_resize_at_dest_event( self, source_cell_context): """"""Copies the compute_finish_snapshot_based_resize_at_dest event from the target cell database to the source cell database. :param source_cell_context: nova auth request context targeted at the source cell """""" event_name = 'compute_finish_snapshot_based_resize_at_dest' try: # TODO(mriedem): Need a method on InstanceActionEventList to # lookup an event by action request_id and event name. # Get the single action for this request in the target cell DB. action = objects.InstanceAction.get_by_request_id( self.context, self.instance.uuid, self.context.request_id) if action: # Get the events for this action in the target cell DB. events = objects.InstanceActionEventList.get_by_action( self.context, action.id) # Find the finish_snapshot_based_resize_at_dest event and # create it in the source cell DB. for event in events: if event.event == event_name: event_clone = clone_creatable_object( source_cell_context, event) event_clone.create(action.instance_uuid, action.request_id) break else: LOG.warning('Failed to find InstanceActionEvent with ' 'name %s in target cell DB', event_name, instance=self.instance) else: LOG.warning( 'Failed to find InstanceAction by request_id %s', self.context.request_id, instance=self.instance) except Exception: LOG.exception( 'Failed to copy %s instance action event from target cell DB', event_name, instance=self.instance) ",29,124
openstack%2Fnova~master~I27c549901a3359f106ba5d77aa6559397ee12a5d,openstack/nova,master,I27c549901a3359f106ba5d77aa6559397ee12a5d,Add sequence diagrams for cross-cell-resize,MERGED,2019-12-09 17:38:10.000000000,2019-12-26 01:49:20.000000000,2019-12-24 10:18:27.000000000,"[{'_account_id': 6873}, {'_account_id': 9708}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da5c553bad90538b1d5df856b599d946d820d7f7', 'message': 'Add sequence diagrams for cross-cell-resize\n\nThis tries to strike a balance between giving a useful high level\nflow without injecting too much complex detail in each diagram.\n\nFor the more complicated resize diagram, I have used labels to\ntry and make clear which conductor task is performing an action.\n\nFor the less complicated confirm and revert diagrams, I add a\nseparator to show where the conductor task is orchestrating the\ncalls and provide a bit more detail into what each task is doing\nsince the calls to computes are minimal in those cases.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d\n'}, {'number': 2, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/173c578f846b6cb6b6ae5807c54685d8f2cc90bc', 'message': 'Add sequence diagrams for cross-cell-resize\n\nThis tries to strike a balance between giving a useful high level\nflow without injecting too much complex detail in each diagram.\n\nFor the more complicated resize diagram, I have used labels to\ntry and make clear which conductor task is performing an action.\n\nFor the less complicated confirm and revert diagrams, I add a\nseparator to show where the conductor task is orchestrating the\ncalls and provide a bit more detail into what each task is doing\nsince the calls to computes are minimal in those cases.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d\n'}, {'number': 3, 'created': '2019-12-09 20:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba8d8ccf76f683ab7d28d2219f41f753d081325b', 'message': 'Add sequence diagrams for cross-cell-resize\n\nThis tries to strike a balance between giving a useful high level\nflow without injecting too much complex detail in each diagram.\n\nFor the more complicated resize diagram, I have used labels to\ntry and make clear which conductor task is performing an action.\n\nFor the less complicated confirm and revert diagrams, I add a\nseparator to show where the conductor task is orchestrating the\ncalls and provide a bit more detail into what each task is doing\nsince the calls to computes are minimal in those cases.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d\n'}, {'number': 4, 'created': '2019-12-12 19:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28a05599d10f48da4b8509afd05cf06a78e14a98', 'message': 'Add sequence diagrams for cross-cell-resize\n\nThis tries to strike a balance between giving a useful high level\nflow without injecting too much complex detail in each diagram.\n\nFor the more complicated resize diagram, I have used labels to\ntry and make clear which conductor task is performing an action.\n\nFor the less complicated confirm and revert diagrams, I add a\nseparator to show where the conductor task is orchestrating the\ncalls and provide a bit more detail into what each task is doing\nsince the calls to computes are minimal in those cases.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d\n'}, {'number': 5, 'created': '2019-12-23 15:11:19.000000000', 'files': ['doc/source/admin/configuration/cross-cell-resize.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/6aafb29820a2a447fcc7d23dc109835ea9e6c6df', 'message': 'Add sequence diagrams for cross-cell-resize\n\nThis tries to strike a balance between giving a useful high level\nflow without injecting too much complex detail in each diagram.\n\nFor the more complicated resize diagram, I have used labels to\ntry and make clear which conductor task is performing an action.\n\nFor the less complicated confirm and revert diagrams, I add a\nseparator to show where the conductor task is orchestrating the\ncalls and provide a bit more detail into what each task is doing\nsince the calls to computes are minimal in those cases.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d\n'}]",5,698051,6aafb29820a2a447fcc7d23dc109835ea9e6c6df,52,10,5,6873,,,0,"Add sequence diagrams for cross-cell-resize

This tries to strike a balance between giving a useful high level
flow without injecting too much complex detail in each diagram.

For the more complicated resize diagram, I have used labels to
try and make clear which conductor task is performing an action.

For the less complicated confirm and revert diagrams, I add a
separator to show where the conductor task is orchestrating the
calls and provide a bit more detail into what each task is doing
since the calls to computes are minimal in those cases.

Part of blueprint cross-cell-resize

Change-Id: I27c549901a3359f106ba5d77aa6559397ee12a5d
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/698051/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/configuration/cross-cell-resize.rst'],1,da5c553bad90538b1d5df856b599d946d820d7f7,bp/cross-cell-resize,"Networking ---------- The networking API must expose the ``Port Bindings Extended`` API extension which was added in the 13.0.0 (Rocky) release for Neutron. ~~~~~~~~~~~~~~~~ The following diagrams are current as of the 21.0.0 (Ussuri) release. .. NOTE(mriedem): These diagrams could be more detailed, for example breaking down the individual parts of the conductor tasks and the calls made on the source and dest compute to the virt driver, cinder and neutron, but the diagrams could (1) get really complex and (2) become inaccurate with changes over time. If there are particular sub-sequences that should have diagrams I would suggest putting those into separate focused diagrams. Resize ------ This is the sequence of calls to get the server to ``VERIFY_RESIZE`` status. .. seqdiag:: seqdiag { API; Conductor; Scheduler; Source; Destination; edge_length = 300; span_height = 15; activation = none; default_note_color = white; API ->> Conductor [label = ""cast"", note = ""resize_instance/migrate_server""]; Conductor => Scheduler [label = ""MigrationTask"", note = ""select_destinations""]; Conductor -> Conductor [label = ""TargetDBSetupTask""]; Conductor => Destination [label = ""PrepResizeAtDestTask"", note = ""prep_snapshot_based_resize_at_dest""]; Conductor => Source [label = ""PrepResizeAtSourceTask"", note = ""prep_snapshot_based_resize_at_source""]; Conductor => Destination [label = ""FinishResizeAtDestTask"", note = ""finish_snapshot_based_resize_at_dest""]; Conductor -> Conductor [label = ""FinishResizeAtDestTask"", note = ""update instance mapping""]; } Confirm resize -------------- This is the sequence of calls when confirming `or deleting`_ a server in ``VERIFY_RESIZE`` status. .. seqdiag:: seqdiag { API; Conductor; Source; edge_length = 300; span_height = 15; activation = none; default_note_color = white; API ->> Conductor [label = ""cast (or call if deleting)"", note = ""confirm_snapshot_based_resize""]; // separator to indicate everything after this is driven by ConfirmResizeTask === ConfirmResizeTask === Conductor => Source [label = ""call"", note = ""confirm_snapshot_based_resize_at_source""]; Conductor -> Conductor [note = ""hard delete source cell instance""]; Conductor -> Conductor [note = ""update target cell instance status""]; } Revert resize ------------- This is the sequence of calls when reverting a server in ``VERIFY_RESIZE`` status. .. seqdiag:: seqdiag { API; Conductor; Source; Destination; edge_length = 300; span_height = 15; activation = none; default_note_color = white; API ->> Conductor [label = ""cast"", note = ""revert_snapshot_based_resize""]; // separator to indicate everything after this is driven by RevertResizeTask === RevertResizeTask === Conductor -> Conductor [note = ""update records from target to source cell""]; Conductor -> Conductor [note = ""update instance mapping""]; Conductor => Destination [label = ""call"", note = ""revert_snapshot_based_resize_at_dest""]; Conductor -> Conductor [note = ""hard delete target cell instance""]; Conductor => Source [label = ""call"", note = ""finish_revert_snapshot_based_resize_at_source""]; } .. _or deleting: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/compute/api.py#L2171check the (super)conductor service logs. Assuming volume attachments and port bindings are OK (current and pointing at the correct host), then try hard rebooting the server to get it back to ``ACTIVE`` status. If that fails, you may need to `rebuild`_ the server on the source host. Note that the guest's disks on the source host are not deleted until the resize is confirmed so if there is an issue prior to confirm or confirm itself fails, the guest disks should still be available for rebuilding the instance if necessary.","---------------- .. todo:: Add diagrams for what happens with the resize, confirm and revert flows like in https://review.opendev.org/695759/.check the conductor service logs. Assuming volume attachments and port bindings are OK (current and pointing at the correct host), then try hard rebooting the server to get it back to ``ACTIVE`` status. If that fails, you may need to `rebuild`_ the server on the source host.",101,7
openstack%2Fmonasca-persister~master~I05eab6a6bf5fb383e543f110d2ae5519e92a5a56,openstack/monasca-persister,master,I05eab6a6bf5fb383e543f110d2ae5519e92a5a56,Replace the invalid links with the right ones for the document,ABANDONED,2019-08-22 07:07:13.000000000,2019-12-26 01:47:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-08-22 07:07:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/6da0d26c09fff9cb28fd71f37edf7c453f9e132b', 'message': 'Replace the invalid links with the right ones for the document\n\nChange-Id: I05eab6a6bf5fb383e543f110d2ae5519e92a5a56\n'}]",0,677901,6da0d26c09fff9cb28fd71f37edf7c453f9e132b,3,1,1,27399,,,0,"Replace the invalid links with the right ones for the document

Change-Id: I05eab6a6bf5fb383e543f110d2ae5519e92a5a56
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/01/677901/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,6da0d26c09fff9cb28fd71f37edf7c453f9e132b,,"https://www.dropwizard.io/1.3.14/docs/, which provides a nice Web","https://dropwizard.github.io/dropwizard/, which provides a nice Web",1,1
openstack%2Fdesignate~master~I3d8d4021b17b0522ab3a37a337f2a7a1936ca23b,openstack/designate,master,I3d8d4021b17b0522ab3a37a337f2a7a1936ca23b,Imported Translations from Zanata,MERGED,2019-12-22 09:04:26.000000000,2019-12-26 00:37:52.000000000,2019-12-26 00:36:26.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-22 09:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/fa0194123bb8fd8bb78eed67a94646def5e9cc9f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3d8d4021b17b0522ab3a37a337f2a7a1936ca23b\n'}, {'number': 2, 'created': '2019-12-25 09:11:31.000000000', 'files': ['designate/locale/en_GB/LC_MESSAGES/designate.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/0050549441a1889a40b85accc4733d3dca8f067f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3d8d4021b17b0522ab3a37a337f2a7a1936ca23b\n'}]",0,700320,0050549441a1889a40b85accc4733d3dca8f067f,9,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3d8d4021b17b0522ab3a37a337f2a7a1936ca23b
",git fetch https://review.opendev.org/openstack/designate refs/changes/20/700320/2 && git format-patch -1 --stdout FETCH_HEAD,"['designate/locale/en_GB/LC_MESSAGES/designate.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po']",2,fa0194123bb8fd8bb78eed67a94646def5e9cc9f,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-17 08:07+0000\n""""PO-Revision-Date: 2019-12-21 01:07+0000\n""msgid ""7.0.0-17"" msgstr ""7.0.0-17"" msgid ""8.0.0"" msgstr ""8.0.0"" msgid ""8.0.0-12"" msgstr ""8.0.0-12"" msgid ""9.0.0"" msgstr ""9.0.0"" msgid ""9.0.0-25"" msgstr ""9.0.0-25"" msgid """" ""A bug that prevented Designate from starting up when services are running a "" ""mixture of Python 2 and 3 has been fixed, but there is still an issue when "" ""running a mixture of a patched and unpatched versions of Designate under "" ""Python 3."" msgstr """" ""A bug that prevented Designate from starting up when services are running a "" ""mixture of Python 2 and 3 has been fixed, but there is still an issue when "" ""running a mixture of a patched and unpatched versions of Designate under "" ""Python 3."" msgid """" ""A new ``designate-status upgrade check`` command has been added which can be "" ""used to validate a deployment before starting services with new code. See "" ""the documentation for details: https://docs.openstack.org/designate/latest/"" ""cli/designate-status.html"" msgstr """" ""A new ``designate-status upgrade check`` command has been added which can be "" ""used to validate a deployment before starting services with new code. See "" ""the documentation for details: https://docs.openstack.org/designate/latest/"" ""cli/designate-status.html""msgid """" ""A recordset will now always report its highest priority state when it "" ""contains multiple records. The order of priority is, `ERROR`, `PENDING`, "" ""`ACTIVE` and `DELETED`."" msgstr """" ""A recordset will now always report its highest priority state when it "" ""contains multiple records. The order of priority is, `ERROR`, `PENDING`, "" ""`ACTIVE` and `DELETED`."" msgid """" ""Added an experimental entrypoint for wsgi called ``designate-api-wsgi``."" msgstr """" ""Added an experimental entrypoint for wsgi called ``designate-api-wsgi``."" ""Adds a new option for pools using the ``pdns4`` backend: ``tsigkey_name``. "" ""This allows deployers to specify a tsig key that is installed in powerdns to "" ""use for AFXR requests. This key name is the name used to create the key in "" ""powerdns, not the Designate UUID based ID for the key."" msgstr """" ""Adds a new option for pools using the ``pdns4`` backend: ``tsigkey_name``. "" ""This allows deployers to specify a tsig key that is installed in powerdns to "" ""use for AFXR requests. This key name is the name used to create the key in "" ""powerdns, not the Designate UUID based ID for the key."" msgid """"""Because of this the ``[service:worker]`` option ``enabled`` has been "" ""permanently removed, and in addition the ``notify`` option under the same "" ""section has been deprecated for removal."" msgstr """" ""Because of this the ``[service:worker]`` option ``enabled`` has been "" ""permanently removed, and in addition the ``notify`` option under the same "" ""section has been deprecated for removal."" msgid """"msgid """" ""CAA and NAPTR recordset types have been added. All users should be able to "" ""use these types from the API and openstack client. These can be disabled "" ""(like other record types) by setting the `[DEFAULT].supported-record-type` "" ""config variable in all designate services."" msgstr """" ""CAA and NAPTR recordset types have been added. All users should be able to "" ""use these types from the API and openstack client. These can be disabled "" ""(like other record types) by setting the `[DEFAULT].supported-record-type` "" ""config variable in all designate services."" msgid ""Drop the Python 2.7 support."" msgstr ""Drop the Python 2.7 support."" msgid """" ""Fixed a bug preventing `service_statuses` from properly updating when "" ""Designate services were configured with multiple workers."" msgstr """" ""Fixed a bug preventing `service_statuses` from properly updating when "" ""Designate services were configured with multiple workers."" msgid """" ""Fixed a bug with the recordset status implementation to make it report its "" ""status more accurately."" msgstr """" ""Fixed a bug with the recordset status implementation to make it report its "" ""status more accurately."" msgid """" ""Fixed an `issue`_ when upgrading to Python 3 (where bytes and str are "" ""different types) and _update_partitions() attempts to sort types of 'str' "" ""and 'bytes', causing designate-producer to crash."" msgstr """" ""Fixed an `issue`_ when upgrading to Python 3 (where bytes and str are "" ""different types) and _update_partitions() attempts to sort types of 'str' "" ""and 'bytes', causing designate-producer to crash."" msgid """" ""It was previously not possible to override the topics for various serivces "" ""(e.g. mdns), due to `bug 1832799`_. This has been fixed, and these services "" ""now use a common option name to override the topic."" msgstr """" ""It was previously not possible to override the topics for various serivces "" ""(e.g. mdns), due to `bug 1832799`_. This has been fixed, and these services "" ""now use a common option name to override the topic."" ""New installs will now have pool manager disabled by default and will use the "" ""worker and producer services. To continue to use pool manager set "" ""``enabled=False`` in the ``[service:worker]`` of your config."" msgstr """" ""New installs will now have pool manager disabled by default and will use the "" ""worker and producer services. To continue to use pool manager set "" ""``enabled=False`` in the ``[service:worker]`` of your config."" msgid """"msgid ""Pool-Manager removal is complete in this version of designate."" msgstr ""Pool-Manager removal is complete in this version of designate."" msgid """" ""Python 2.7 support has been dropped. Last release of Designate to support "" ""python 2.7 is OpenStack Train. The minimum version of Python now supported "" ""by Designate is Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Designate to support "" ""Python 2.7 is OpenStack Train. The minimum version of Python now supported "" ""by Designate is Python 3.6."" msgid ""See `bug 1755788`_ for more information."" msgstr ""See `bug 1755788`_ for more information."" msgid ""See `bug 1827070`_ for more information."" msgstr ""See `bug 1827070`_ for more information."" msgid ""See `bug 1828534`_ for more information."" msgstr ""See `bug 1828534`_ for more information."" msgid ""See `bug 1842994`_ for more information."" msgstr ""See `bug 1842994`_ for more information."" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid """" ""TXT and SPF records are now validated for empty spaces in the values. If "" ""record value has empty space it should use \""\"" quotation according to "" ""RFC-1035 section 5.1. Use of single quotation mark within record value "" ""requires quote symbol to be escaped with backslash."" msgstr """" ""TXT and SPF records are now validated for empty spaces in the values. If "" ""record value has empty space it should use \""\"" quotation according to "" ""RFC-1035 section 5.1. Use of single quotation mark within record value "" ""requires quote symbol to be escaped with backslash."" msgid """" ""The Designate ``sink`` service will now use the heartbeat reporting system "" ""to report its status. This was already the case for all other Designate "" ""services."" msgstr """" ""The Designate ``sink`` service will now use the heartbeat reporting system "" ""to report its status. This was already the case for all other Designate "" ""services."" msgid """" ""The PowerDNS MySQL based backend has been deprecated since the introduction "" ""of the PowerDNS 4 driver and is now being removed."" msgstr """" ""The PowerDNS MySQL based backend has been deprecated since the introduction "" ""of the PowerDNS 4 driver and is now being removed."" msgid """" ""The ``[service:api]`` option ``enable_host_header`` is now enabled by "" ""default."" msgstr """" ""The ``[service:api]`` option ``enable_host_header`` is now enabled by "" ""default."" ""The pool-manager has been removed and can no longer be used. Instead the "" ""worker and producer service should be used."" msgstr """" ""The pool-manager has been removed and can no longer be used. Instead the "" ""worker and producer service should be used."" msgid """" ""The previously deprecated options ``api_host``, ``api_port``, ``host`` and "" ""``port`` have been permanently removed and are replaced by ``listen``."" msgstr """" ""The previously deprecated options ``api_host``, ``api_port``, ``host`` and "" ""``port`` have been permanently removed and are replaced by ``listen``."" msgid """"msgid ""This is only available in the 4.2.x versions (and above) of pdns."" msgstr ""This is only available in the 4.2.x versions (and above) of pdns."" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" msgid """" ""Update command ``designate-manage pool update``, change ``--dry_run`` to ``--"" ""dry-run``, and change ``--delete`` and ``--dry-run`` as switchs not key "" ""value pair. e.g."" msgstr """" ""Update command ``designate-manage pool update``, change ``--dry_run`` to ``--"" ""dry-run``, and change ``--delete`` and ``--dry-run`` as switchs not key "" ""value pair. e.g."" msgid ""e.g."" msgstr ""e.g.""","""POT-Creation-Date: 2018-12-04 15:32+0000\n""""PO-Revision-Date: 2018-12-04 05:21+0000\n""msgid ""7.0.0-40"" msgstr ""7.0.0-40""",230,14
openstack%2Ftripleo-common~stable%2Ftrain~I571af51db0d21226bc42dc21925384f0129cd581,openstack/tripleo-common,stable/train,I571af51db0d21226bc42dc21925384f0129cd581,image-uploader: allow an image without Labels to be uploaded,MERGED,2019-12-19 21:10:08.000000000,2019-12-25 22:39:50.000000000,2019-12-20 09:01:29.000000000,"[{'_account_id': 4571}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 21:10:08.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/95f837bf1ecd563f4f49df1232015e52db72af77', 'message': ""image-uploader: allow an image without Labels to be uploaded\n\nSome images, like grafana don't have Labels set; let's just set an empty\ndefault if an image has no Labels and continue the upload.\n\nChange-Id: I571af51db0d21226bc42dc21925384f0129cd581\nCloses-Bug: #1857012\n(cherry picked from commit 95b68c6d19119a022f94061ba98accc717ff6657)\n""}]",0,700069,95f837bf1ecd563f4f49df1232015e52db72af77,9,3,1,3153,,,0,"image-uploader: allow an image without Labels to be uploaded

Some images, like grafana don't have Labels set; let's just set an empty
default if an image has no Labels and continue the upload.

Change-Id: I571af51db0d21226bc42dc21925384f0129cd581
Closes-Bug: #1857012
(cherry picked from commit 95b68c6d19119a022f94061ba98accc717ff6657)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/69/700069/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py']",2,95f837bf1ecd563f4f49df1232015e52db72af77,train/labels," labels = config['config'].get('Labels', {}) labels = config['config'].get('Labels', {})", labels = config['config']['Labels'] labels = config['config']['Labels'],45,2
openstack%2Fcinder~master~Ibef4de965ea30066abfa893739c8f29cc9185194,openstack/cinder,master,Ibef4de965ea30066abfa893739c8f29cc9185194,[WIP] Support Ceph clustername config for Rados,NEW,2019-01-03 01:39:34.000000000,2019-12-25 21:09:24.000000000,,"[{'_account_id': 9008}, {'_account_id': 9236}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 16897}, {'_account_id': 19930}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30590}]","[{'number': 1, 'created': '2019-01-03 01:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/74aa151de927ca195bf2be596e436df061b9b78d', 'message': '[WIP] Support Ceph clustername config for Rados\n\nChange-Id: Ibef4de965ea30066abfa893739c8f29cc9185194\n'}, {'number': 2, 'created': '2019-01-03 01:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9581c94324f5f5959059f69c93e7ef5fc30fbfcb', 'message': '[WIP] Support Ceph clustername config for Rados\n\nChange-Id: Ibef4de965ea30066abfa893739c8f29cc9185194\n'}, {'number': 3, 'created': '2019-01-03 01:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b013a6a3aebab4ad329df99a9a98b86dad6df6f', 'message': '[WIP] Support Ceph clustername config for Rados\n\nCloses-Bug: #1810353\n\nChange-Id: Ibef4de965ea30066abfa893739c8f29cc9185194\n'}, {'number': 4, 'created': '2019-09-07 06:43:31.000000000', 'files': ['cinder/backup/drivers/ceph.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2394dc3225597826e3b8acb3614c197df6de01c1', 'message': '[WIP] Support Ceph clustername config for Rados\n\nCloses-Bug: #1810353\n\nChange-Id: Ibef4de965ea30066abfa893739c8f29cc9185194\n'}]",0,628076,2394dc3225597826e3b8acb3614c197df6de01c1,56,25,4,19930,,,0,"[WIP] Support Ceph clustername config for Rados

Closes-Bug: #1810353

Change-Id: Ibef4de965ea30066abfa893739c8f29cc9185194
",git fetch https://review.opendev.org/openstack/cinder refs/changes/76/628076/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/ceph.py'],1,74aa151de927ca195bf2be596e436df061b9b78d,," cfg.StrOpt('backup_ceph_cluster_name', default='ceph', help='The Ceph cluster name to connect with. Default value is ' 'ceph which is similar with default cluster name of Ceph'), self._ceph_backup_cluster_name = utils.convert_str(CONF.backup_ceph_cluster_name) conffile=self._ceph_backup_conf, clustername=self._ceph_backup_cluster_name))", conffile=self._ceph_backup_conf)),6,1
openstack%2Fcinder~master~Ic36c22683c0c4f1b34af1bf33a9ee2614ce37933,openstack/cinder,master,Ic36c22683c0c4f1b34af1bf33a9ee2614ce37933,"volume query function supplement, acquire information of volume accoording to creator and volume id",NEW,2019-07-31 03:42:33.000000000,2019-12-25 20:54:36.000000000,,"[{'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 16897}, {'_account_id': 17130}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 30754}]","[{'number': 1, 'created': '2019-07-31 03:42:33.000000000', 'files': ['cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/df79a1b7e560b3e6db4da73805a060030187d993', 'message': 'volume query function supplement, acquire information of volume accoording to creator and volume id\n\nChange-Id: Ic36c22683c0c4f1b34af1bf33a9ee2614ce37933\n'}]",2,673721,df79a1b7e560b3e6db4da73805a060030187d993,23,21,1,30754,,,0,"volume query function supplement, acquire information of volume accoording to creator and volume id

Change-Id: Ic36c22683c0c4f1b34af1bf33a9ee2614ce37933
",git fetch https://review.opendev.org/openstack/cinder refs/changes/21/673721/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/db/sqlalchemy/api.py'],1,df79a1b7e560b3e6db4da73805a060030187d993,cinder_study," joined_load=True,volume_id = None,user_id = None): query = model_query(context, models.Volume, session=session, query = model_query(context, models.Volume, session=session, if volume_id and user_id: return query.filter(or_(models.Volume.id.in_(volume_id),models.Volume.user_id.in_(user_id))) elif volume_id and not user_id: return query.filter(models.Volume.id.in_(volume_id)) elif not volume_id and user_id: return query.filter(models.Volume.user_id.in_(user_id)) else: return query"," joined_load=True): return model_query(context, models.Volume, session=session, return model_query(context, models.Volume, session=session,",11,3
openstack%2Fcinder~master~Ifd39301ab5a46f491f141220efbffa49def2be23,openstack/cinder,master,Ifd39301ab5a46f491f141220efbffa49def2be23,[DNM] Testing Cisco Third Party Enhancement,NEW,2019-10-30 16:09:56.000000000,2019-12-25 18:42:33.000000000,,"[{'_account_id': 9008}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28080}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2019-10-30 16:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/620242ea37a83e1e17622d5a90a0b275acbd58c8', 'message': '[DNM] Testing Cisco Third Party Enhhancement\n\nChange-Id: Ifd39301ab5a46f491f141220efbffa49def2be23\n'}, {'number': 2, 'created': '2019-10-30 18:49:32.000000000', 'files': ['cinder/zonemanager/drivers/cisco/cisco_fabric_opts.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a61c5b731d5c89f5b914fa97b7977c694c14f09', 'message': '[DNM] Testing Cisco Third Party Enhancement\n\nChange-Id: Ifd39301ab5a46f491f141220efbffa49def2be23\n'}]",0,692183,6a61c5b731d5c89f5b914fa97b7977c694c14f09,30,16,2,28080,,,0,"[DNM] Testing Cisco Third Party Enhancement

Change-Id: Ifd39301ab5a46f491f141220efbffa49def2be23
",git fetch https://review.opendev.org/openstack/cinder refs/changes/83/692183/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/zonemanager/drivers/cisco/cisco_fabric_opts.py'],1,620242ea37a83e1e17622d5a90a0b275acbd58c8,dynamic_auth," cfg.BoolOpt('cisco_dynamic_credential', default=False, help='dynamic password credentials'),def get_dynamic_password(): return ""nbv_12345"" def re_register_opts(config): password=get_dynamic_password() config.conf.set_default(""cisco_fc_fabric_password"",password) return config if config.safe_get(""cisco_dynamic_credential""): config=re_register_opts(config)",,11,2
openstack%2Fvitrage-dashboard~master~I2f18694306a269d20a5037e5824f12e6d0f2482f,openstack/vitrage-dashboard,master,I2f18694306a269d20a5037e5824f12e6d0f2482f,Fix typos in this yaml,MERGED,2019-12-25 09:48:33.000000000,2019-12-25 10:33:58.000000000,2019-12-25 10:32:39.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-25 09:48:33.000000000', 'files': ['releasenotes/notes/vitrage-admin-menu-5fa73358a8559a37.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/3c01f8f4749e06155f2e6ff4112d0a2b915b47cc', 'message': 'Fix typos in this yaml\n\nChange-Id: I2f18694306a269d20a5037e5824f12e6d0f2482f\n'}]",0,700563,3c01f8f4749e06155f2e6ff4112d0a2b915b47cc,7,2,1,23317,,,0,"Fix typos in this yaml

Change-Id: I2f18694306a269d20a5037e5824f12e6d0f2482f
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/63/700563/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/vitrage-admin-menu-5fa73358a8559a37.yaml'],1,3c01f8f4749e06155f2e6ff4112d0a2b915b47cc,fix," - A new ``Vitrage Admin Menu`` was added, to handle authorize management of tanents from the administrator perspective. When a regular user will login,"," - A new ``Vitrage Admin Menu`` was added, to handle authorize managment of tanents from the administrator prespective. When a regular user will login,",2,2
openstack%2Fneutron-vpnaas-dashboard~master~Ie97c94c5ec92ac7d2d635db6757dce0ec6de975d,openstack/neutron-vpnaas-dashboard,master,Ie97c94c5ec92ac7d2d635db6757dce0ec6de975d,Bump the openstackdocstheme extension to 1.20,ABANDONED,2019-10-12 06:34:41.000000000,2019-12-25 09:21:51.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 06:34:41.000000000', 'files': ['doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/7650229ac5afc2abb13c209c739e38e5199dbde3', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: Ie97c94c5ec92ac7d2d635db6757dce0ec6de975d\n'}]",0,688234,7650229ac5afc2abb13c209c739e38e5199dbde3,4,2,1,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: Ie97c94c5ec92ac7d2d635db6757dce0ec6de975d
",git fetch https://review.opendev.org/openstack/neutron-vpnaas-dashboard refs/changes/34/688234/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py']",4,7650229ac5afc2abb13c209c739e38e5199dbde3,openstackdocstheme,,html_last_updated_fmt = '%Y-%m-%d %H:%M'project = u'Neutron VPNaaS Dashboard Release Notes',2,19
openstack%2Fosc-lib~master~Ia6173383bcc8228642dd6fd3bae0233ca191c077,openstack/osc-lib,master,Ia6173383bcc8228642dd6fd3bae0233ca191c077,Bump the openstackdocstheme extension to 1.20,ABANDONED,2019-10-12 06:41:31.000000000,2019-12-25 09:21:36.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 06:41:31.000000000', 'files': ['test-requirements.txt', 'doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/73b90e17f4f6b0a9a61173923816f5639834a0e4', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: Ia6173383bcc8228642dd6fd3bae0233ca191c077\n'}]",0,688236,73b90e17f4f6b0a9a61173923816f5639834a0e4,4,2,1,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: Ia6173383bcc8228642dd6fd3bae0233ca191c077
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/36/688236/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py']",5,73b90e17f4f6b0a9a61173923816f5639834a0e4,openstackdocstheme,,"project = u'osc-lib Release Notes'latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } ",2,46
openstack%2Fhorizon~stable%2Fstein~I2cfeecc483d7c301257c4b3dae61cdb28e03583a,openstack/horizon,stable/stein,I2cfeecc483d7c301257c4b3dae61cdb28e03583a,Change Rebuild Instance Form select widget to normal style,ABANDONED,2019-12-25 09:19:49.000000000,2019-12-25 09:20:30.000000000,,[],"[{'number': 1, 'created': '2019-12-25 09:19:49.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6d71f8d8c99487b533949aad7c884607d1b33a8b', 'message': 'Change Rebuild Instance Form select widget to normal style\n\nReplace select widget from ThemableSelectWidget to SelectWidget in case that there are too many images.\n\ncloses-bug: 1794000\nChange-Id: I2cfeecc483d7c301257c4b3dae61cdb28e03583a\n'}]",0,700554,6d71f8d8c99487b533949aad7c884607d1b33a8b,2,0,1,30562,,,0,"Change Rebuild Instance Form select widget to normal style

Replace select widget from ThemableSelectWidget to SelectWidget in case that there are too many images.

closes-bug: 1794000
Change-Id: I2cfeecc483d7c301257c4b3dae61cdb28e03583a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/54/700554/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/forms.py'],1,6d71f8d8c99487b533949aad7c884607d1b33a8b,bug/1794000," widget=forms.SelectWidget( disk_config = forms.ChoiceField(label=_(""Disk Partition""),"," widget=forms.ThemableSelectWidget( disk_config = forms.ThemableChoiceField(label=_(""Disk Partition""),",2,2
openstack%2Fnetworking-bagpipe~master~I3f8eb857fbf482e66b11565faf15f8621e7b8133,openstack/networking-bagpipe,master,I3f8eb857fbf482e66b11565faf15f8621e7b8133,Update and replace http with https for doc links,ABANDONED,2019-08-28 01:20:44.000000000,2019-12-25 08:49:16.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-28 01:20:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/878bba2bda3825369b578cf391974378aaea7c7c', 'message': 'Update and replace http with https for doc links\n\nChange-Id: I3f8eb857fbf482e66b11565faf15f8621e7b8133\n'}]",0,678972,878bba2bda3825369b578cf391974378aaea7c7c,4,2,1,27399,,,0,"Update and replace http with https for doc links

Change-Id: I3f8eb857fbf482e66b11565faf15f8621e7b8133
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/72/678972/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,878bba2bda3825369b578cf391974378aaea7c7c,fixmaster,* Source: https://opendev.org/openstack/networking-bagpipe.. _RFC4364: https://tools.ietf.org/html/rfc4364 .. _RFC7432: https://tools.ietf.org/html/rfc7432,* Source: http://opendev.org/openstack/networking-bagpipe.. _RFC4364: http://tools.ietf.org/html/rfc4364 .. _RFC7432: http://tools.ietf.org/html/rfc7432,3,3
openstack%2Fceilometer~master~Ifbc1161ed153fc4a1d80d69a429999ed15fd094b,openstack/ceilometer,master,Ifbc1161ed153fc4a1d80d69a429999ed15fd094b,TEST CI,ABANDONED,2019-12-24 08:12:01.000000000,2019-12-25 08:38:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-24 08:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b846f206ca01cea221abe72bdaceeac021e6d85c', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}, {'number': 2, 'created': '2019-12-25 01:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7d56e981c5ebd88971553155201f003d5ac11291', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}, {'number': 3, 'created': '2019-12-25 01:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cb3e7eb5f2b97c570ebd0257d96ab05e3e3ddac7', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}, {'number': 4, 'created': '2019-12-25 02:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3c772038ea54d8ec250553d413269dba31eb4def', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}, {'number': 5, 'created': '2019-12-25 03:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4f616191509aca823b2233d8f8acaf764ebd0f56', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}, {'number': 6, 'created': '2019-12-25 05:33:39.000000000', 'files': ['bindep.txt', 'ceilometer/messaging.py', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b417d95cd7657e65b839b00f6f0b9748ea039eca', 'message': 'TEST CI\n\nChange-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b\n'}]",0,700494,b417d95cd7657e65b839b00f6f0b9748ea039eca,11,1,6,14107,,,0,"TEST CI

Change-Id: Ifbc1161ed153fc4a1d80d69a429999ed15fd094b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/94/700494/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/messaging.py'],1,b846f206ca01cea221abe72bdaceeac021e6d85c,,,,1,0
openstack%2Fheat-specs~master~Ia8c3e82ea9af194e4c6307203d5e84e98a88294e,openstack/heat-specs,master,Ia8c3e82ea9af194e4c6307203d5e84e98a88294e,Update and replace http with https for doc links,NEW,2019-12-25 08:27:47.000000000,2019-12-25 08:34:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-25 08:27:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/9c0dbf423f57d5e8056f76dae797a9a7506c88be', 'message': 'Update and replace http with https for doc links\n\nChange-Id: Ia8c3e82ea9af194e4c6307203d5e84e98a88294e\n'}]",0,700547,9c0dbf423f57d5e8056f76dae797a9a7506c88be,2,1,1,30883,,,0,"Update and replace http with https for doc links

Change-Id: Ia8c3e82ea9af194e4c6307203d5e84e98a88294e
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/47/700547/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,9c0dbf423f57d5e8056f76dae797a9a7506c88be,, https://blueprints.launchpad.net/heat https://docs.openstack.org/infra/manual/developers.html#development-workflow, http://blueprints.launchpad.net/heat http://docs.openstack.org/infra/manual/developers.html#development-workflow,2,2
openstack%2Fmistral~stable%2Frocky~I40463bc34006665c0ac8659f0bb445f47a4d747e,openstack/mistral,stable/rocky,I40463bc34006665c0ac8659f0bb445f47a4d747e,"Revert ""Make the mistral devstack jobs non-voting in Rocky""",ABANDONED,2019-11-20 16:36:13.000000000,2019-12-25 08:22:19.000000000,,"[{'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-11-20 16:36:13.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/mistral/commit/125215c72c89a009f4c798bfa342b831c5e0094c', 'message': 'Revert ""Make the mistral devstack jobs non-voting in Rocky""\n\nThis reverts commit 3f3b15f7d1c31e8236623e276591f79f2e4fc058.\n\nChange-Id: I40463bc34006665c0ac8659f0bb445f47a4d747e\n'}]",0,695241,125215c72c89a009f4c798bfa342b831c5e0094c,14,5,1,9712,,,0,"Revert ""Make the mistral devstack jobs non-voting in Rocky""

This reverts commit 3f3b15f7d1c31e8236623e276591f79f2e4fc058.

Change-Id: I40463bc34006665c0ac8659f0bb445f47a4d747e
",git fetch https://review.opendev.org/openstack/mistral refs/changes/41/695241/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,125215c72c89a009f4c798bfa342b831c5e0094c,bug/1850843, - mistral-devstack - mistral-devstack-non-apache: - mistral-devstack - mistral-devstack-non-apache - mistral-devstack-kombu, - mistral-devstack: voting: false - mistral-devstack-non-apache: voting: false voting: false,4,4
openstack%2Fmistral~master~I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70,openstack/mistral,master,I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70,Dry run feature,NEW,2019-07-10 23:02:50.000000000,2019-12-25 07:46:53.000000000,,"[{'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 15895}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 27008}, {'_account_id': 29124}]","[{'number': 1, 'created': '2019-07-10 23:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3fec162447412e4f45895bd9bba3a5b065718dee', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 2, 'created': '2019-07-11 14:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7e3058c7f926353e06faea82fc696eae53383729', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 3, 'created': '2019-07-11 20:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/10697374f1097897e061dc73f0a47b66ff3ddf6d', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 4, 'created': '2019-07-11 23:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/edbf5444c8c37d73aef8dc21236353ea98170058', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 5, 'created': '2019-12-07 17:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/dc3c4966706493800f5e5517d9c0b28bf3f21d8e', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 6, 'created': '2019-12-10 05:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ffbfc28434fec550069f770fd743a0ea9623bbfc', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}, {'number': 7, 'created': '2019-12-25 05:01:15.000000000', 'files': ['mistral/executors/base.py', 'mistral/engine/tasks.py', 'mistral/lang/v2/tasks.py', 'mistral/tests/unit/engine/test_dry_run.py', 'mistral/tests/unit/engine/test_environment.py', 'mistral/engine/actions.py', 'mistral/executors/default_executor.py', 'mistral/executors/executor_server.py', 'mistral/lang/v2/task_defaults.py', 'mistral/rpc/clients.py', 'mistral/tests/unit/engine/test_safe_rerun.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/97ed8d17f83cde476805c3c2b978a6e29cedc55f', 'message': ""Dry run feature\n\nNow it is possible to execute tasks in dry-run mode, so instead of 'run'\naction method 'test' will be executed. It could be configured\nfor a single task or for a whole workflow in task-defaults section.\n\nChange-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70\nImplements: blueprint mistral-dry-run\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n""}]",4,670211,97ed8d17f83cde476805c3c2b978a6e29cedc55f,18,8,7,29124,,,0,"Dry run feature

Now it is possible to execute tasks in dry-run mode, so instead of 'run'
action method 'test' will be executed. It could be configured
for a single task or for a whole workflow in task-defaults section.

Change-Id: I9b50bb40d2f1fc883f32406f4bc11f03a15f0a70
Implements: blueprint mistral-dry-run
Signed-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>
",git fetch https://review.opendev.org/openstack/mistral refs/changes/11/670211/7 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/executors/base.py', 'mistral/engine/tasks.py', 'mistral/lang/v2/tasks.py', 'mistral/engine/actions.py', 'mistral/tests/unit/engine/test_dry_run.py', 'mistral/executors/default_executor.py', 'mistral/executors/executor_server.py', 'mistral/lang/v2/task_defaults.py', 'mistral/rpc/clients.py']",9,3fec162447412e4f45895bd9bba3a5b065718dee,bp/mistral-dry-run," params, safe_rerun, dry_run, execution_context, redelivered=False, target=None, async_=True, timeout=None): :param dry_run: Executes the test method instead of the run. 'dry_run': dry_run,"," params, safe_rerun, execution_context, redelivered=False, target=None, async_=True, timeout=None):",293,23
openstack%2Fmasakari~master~I14726a429797f3e7d29955ceeb6a2e093f7a3b52,openstack/masakari,master,I14726a429797f3e7d29955ceeb6a2e093f7a3b52,The spell have some error,ABANDONED,2018-02-05 09:03:51.000000000,2019-12-25 06:54:12.000000000,,"[{'_account_id': 22348}, {'_account_id': 23327}, {'_account_id': 25267}]","[{'number': 1, 'created': '2018-02-05 09:03:51.000000000', 'files': ['doc/source/how_to_get_involved.rst'], 'web_link': 'https://opendev.org/openstack/masakari/commit/b4002aff1d100379ec12ea705e1d9967602bb371', 'message': 'The spell have some error\n\nChange-Id: I14726a429797f3e7d29955ceeb6a2e093f7a3b52\n'}]",0,540769,b4002aff1d100379ec12ea705e1d9967602bb371,5,3,1,27399,,,0,"The spell have some error

Change-Id: I14726a429797f3e7d29955ceeb6a2e093f7a3b52
",git fetch https://review.opendev.org/openstack/masakari refs/changes/69/540769/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/how_to_get_involved.rst'],1,b4002aff1d100379ec12ea705e1d9967602bb371,,the existing ways Masakari is currently being used. The good news is this,"the existing ways Masakari is currently being used. The good news, is this",1,1
openstack%2Fzaqar~master~I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc,openstack/zaqar,master,I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-10-30 02:50:41.000000000,2019-12-25 05:05:02.000000000,2019-12-25 05:03:01.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-30 02:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/62967d37d76cc9db60dbf8452713f5fe082f6a33', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}, {'number': 2, 'created': '2019-10-30 03:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/35dda22df03da50b4acc024cecdc39d9eb1af226', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}, {'number': 3, 'created': '2019-10-30 06:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/51c0f6404df7cc37648c813624ae714fe4ab0cee', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}, {'number': 4, 'created': '2019-11-15 00:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/85483c278c52424ac97123e1d5adf4fad17ef1d1', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}, {'number': 5, 'created': '2019-11-16 14:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1c1b5e94ff0f4137f730319beca9baafa0e701d9', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}, {'number': 6, 'created': '2019-12-13 00:22:57.000000000', 'files': ['requirements.txt', 'playbooks/legacy/tempest-devstack-zaqar-base/run.yaml', 'playbooks/legacy/rally-dsvm-zaqar-zaqar/run.yaml', '.zuul.yaml', 'playbooks/legacy/grenade-devstack-zaqar-base/run.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini', 'releasenotes/notes/drop-py-2-7-09cf95d7d843d8f6.yaml'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/22ade4fa7748aa7c3895aa932f65be8b516900b0', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nZaqar is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nDepends-On: https://review.opendev.org/#/c/693631/\n\nChange-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc\n'}]",0,692010,22ade4fa7748aa7c3895aa932f65be8b516900b0,27,2,6,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

Zaqar is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Depends-On: https://review.opendev.org/#/c/693631/

Change-Id: I0fde9d2f16f3cc77be3d4cab482fa0fb7ab9e7fc
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/10/692010/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'playbooks/legacy/tempest-devstack-zaqar-base/run.yaml', 'playbooks/legacy/rally-dsvm-zaqar-zaqar/run.yaml', '.zuul.yaml', 'playbooks/legacy/grenade-devstack-zaqar-base/run.yaml', 'setup.cfg', 'tox.ini', 'releasenotes/notes/drop-py-2-7-09cf95d7d843d8f6.yaml']",8,62967d37d76cc9db60dbf8452713f5fe082f6a33,drop-py27-support,--- upgrade: - | Python 2.7 support has been dropped. Last release of Zaqar to support py2.7 is OpenStack Train. The minimum version of Python now supported by Zaqar is Python 3.6. ,,11,8
openstack%2Fnetworking-bagpipe~master~I8b1e3836c82412786694262e24c6a4795b367d1e,openstack/networking-bagpipe,master,I8b1e3836c82412786694262e24c6a4795b367d1e,"fix the urls, replace http to https",ABANDONED,2019-08-28 01:36:32.000000000,2019-12-25 03:15:36.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-28 01:36:32.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/c8b54199abcf992c029564ed9d273a1600095c39', 'message': 'fix the urls, replace http to https\n\nChange-Id: I8b1e3836c82412786694262e24c6a4795b367d1e\n'}]",0,678974,c8b54199abcf992c029564ed9d273a1600095c39,7,2,1,27399,,,0,"fix the urls, replace http to https

Change-Id: I8b1e3836c82412786694262e24c6a4795b367d1e
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/74/678974/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,c8b54199abcf992c029564ed9d273a1600095c39,fixmaster,https://docs.openstack.org/infra/manual/developers.htmlhttps://docs.openstack.org/infra/manual/developers.html#development-workflow,http://docs.openstack.org/infra/manual/developers.htmlhttp://docs.openstack.org/infra/manual/developers.html#development-workflow,2,2
openstack%2Fceilometer~master~I8506e940fda9ed9d72003967e7c461f420aad29f,openstack/ceilometer,master,I8506e940fda9ed9d72003967e7c461f420aad29f,Imported Translations from Zanata,MERGED,2019-12-24 08:16:42.000000000,2019-12-25 01:54:51.000000000,2019-12-25 01:53:31.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 08:16:42.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0c0948f0a7ae292b90c8878a41e107f5de4e8000', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I8506e940fda9ed9d72003967e7c461f420aad29f\n'}]",0,700495,0c0948f0a7ae292b90c8878a41e107f5de4e8000,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I8506e940fda9ed9d72003967e7c461f420aad29f
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/95/700495/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,0c0948f0a7ae292b90c8878a41e107f5de4e8000,zanata/translations,"""POT-Creation-Date: 2019-12-22 10:15+0000\n""""PO-Revision-Date: 2019-12-22 08:07+0000\n""msgid ""13.0.0.0rc1-20"" msgstr ""13.0.0.0rc1-20""","""POT-Creation-Date: 2019-12-09 08:14+0000\n""""PO-Revision-Date: 2019-12-21 01:04+0000\n""msgid ""13.0.0.0rc1-19"" msgstr ""13.0.0.0rc1-19""",4,4
openstack%2Fopenstack-ansible-lxc_hosts~master~Idd88ff4bbfb6947665016d015c30d84f7e303eb6,openstack/openstack-ansible-lxc_hosts,master,Idd88ff4bbfb6947665016d015c30d84f7e303eb6,Add py3 installation for CentOS,MERGED,2019-12-20 11:33:09.000000000,2019-12-25 01:41:33.000000000,2019-12-25 01:40:16.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-12-20 11:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/76ec58772ff140bd0bbdc50f14c4446f865a77dc', 'message': 'Add py3 installation for CentOS\n\nChange-Id: Idd88ff4bbfb6947665016d015c30d84f7e303eb6\n'}, {'number': 2, 'created': '2019-12-20 13:06:47.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d3c1910cdcb37b2930149860d2fff7e67901edd2', 'message': 'Add py3 installation for CentOS\n\nChange-Id: Idd88ff4bbfb6947665016d015c30d84f7e303eb6\n'}]",0,700160,d3c1910cdcb37b2930149860d2fff7e67901edd2,12,4,2,28619,,,0,"Add py3 installation for CentOS

Change-Id: Idd88ff4bbfb6947665016d015c30d84f7e303eb6
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/60/700160/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7-host.yml', 'vars/redhat-7.yml']",2,76ec58772ff140bd0bbdc50f14c4446f865a77dc,osa_py3_centos, - python3-devel,,2,0
openstack%2Fdesignate~master~I383884aa100fd983e1087d7458396f8053414d55,openstack/designate,master,I383884aa100fd983e1087d7458396f8053414d55,Delete removed dashboard panel when upgrading,MERGED,2019-11-11 09:50:22.000000000,2019-12-25 00:16:34.000000000,2019-12-25 00:15:14.000000000,"[{'_account_id': 8099}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-11-11 09:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/677940b14ae37de6f97c2ef9787cfd52b1d6ed97', 'message': 'Delete removed dashboard panel when upgrading\n\nThe old v1 dashboard panel has been removed, when upgrading from an\nolder version we need to remove the symbolic link for it in order to\navoid horizon from failing.\n\nChange-Id: I383884aa100fd983e1087d7458396f8053414d55\n'}, {'number': 2, 'created': '2019-11-11 11:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/389ce35e45e8d8bf7acde918730df341605b41b9', 'message': 'Delete removed dashboard panel when upgrading\n\nThe old v1 dashboard panel has been removed, when upgrading from an\nolder version we need to remove the symbolic link for it in order to\navoid horizon from failing.\n\nChange-Id: I383884aa100fd983e1087d7458396f8053414d55\n'}, {'number': 3, 'created': '2019-11-28 01:39:32.000000000', 'files': ['devstack/upgrade/upgrade.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/d5f6f2ab7a34ee04877fbaf80b1571d42799a68c', 'message': 'Delete removed dashboard panel when upgrading\n\nThe old v1 dashboard panel has been removed, when upgrading from an\nolder version we need to remove the symbolic link for it in order to\navoid horizon from failing.\n\nChange-Id: I383884aa100fd983e1087d7458396f8053414d55\n'}]",0,693671,d5f6f2ab7a34ee04877fbaf80b1571d42799a68c,12,3,3,13252,,,0,"Delete removed dashboard panel when upgrading

The old v1 dashboard panel has been removed, when upgrading from an
older version we need to remove the symbolic link for it in order to
avoid horizon from failing.

Change-Id: I383884aa100fd983e1087d7458396f8053414d55
",git fetch https://review.opendev.org/openstack/designate refs/changes/71/693671/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/upgrade/upgrade.sh'],1,677940b14ae37de6f97c2ef9787cfd52b1d6ed97,fix-missing-dashboard-panel,# Hack: uninstall link to removed dashboard panel in order to avoid horizon from failing if [ -L $HORIZON_DIR/openstack_dashboard/local/enabled/_1720_project_dns_panel.py \ -a ! -e $DESIGNATEDASHBOARD_DIR/designatedashboard/enabled/_1720_project_dns_panel.py ]; then rm $HORIZON_DIR/openstack_dashboard/local/enabled/_1720_project_dns_panel.py fi ,,6,0
openstack%2Fhorizon~master~I2b8f89dc60db2b0e513d6b303321a2adafa7cd04,openstack/horizon,master,I2b8f89dc60db2b0e513d6b303321a2adafa7cd04,WIP: integration tests: Install avconv,ABANDONED,2019-03-12 14:56:22.000000000,2019-12-24 23:36:18.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-12 14:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/48b658330f1ecede1c52f47775b3d655f2a58b3f', 'message': 'integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 2, 'created': '2019-03-12 15:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/866f606d21f7c5dc90d405ecb325f8928f6ac8be', 'message': 'integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 3, 'created': '2019-03-12 16:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3498580bbe10089a644f583daea5736c9dc80c18', 'message': 'integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 4, 'created': '2019-08-06 17:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a8b2f6693bf6d7f22f1ee9cbc2bb65de7caa89f6', 'message': 'WIP: integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 5, 'created': '2019-08-06 17:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/44327a77f957adc7db19efa83259e2f9628a2118', 'message': 'WIP: integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 6, 'created': '2019-08-06 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5d736e9f89b943cf306a859d1aa66870cfa59265', 'message': 'WIP: integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 7, 'created': '2019-08-06 18:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0952e0a295f77a33e165fa95cda7bdeda5b0965c', 'message': 'WIP: integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}, {'number': 8, 'created': '2019-08-07 06:26:22.000000000', 'files': ['bindep.txt', 'playbooks/horizon-devstack-integration/pre.yaml', 'playbooks/horizon-devstack-integration/run.yaml', 'roles/setup-integration-tests/tasks/main.yaml', '.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/72529d792da61384596442463131436155c65ad5', 'message': 'WIP: integration tests: Install avconv\n\navconv was previously installed by devstack-gate hooks,\nbut it does not work after zuul v3 migration.\nThe logic was migrated from scripts under tools/gate/integration.\n\nChange-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04\n'}]",4,642777,72529d792da61384596442463131436155c65ad5,24,3,8,841,,,0,"WIP: integration tests: Install avconv

avconv was previously installed by devstack-gate hooks,
but it does not work after zuul v3 migration.
The logic was migrated from scripts under tools/gate/integration.

Change-Id: I2b8f89dc60db2b0e513d6b303321a2adafa7cd04
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/642777/7 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'playbooks/horizon-devstack-integration/pre.yaml', 'roles/setup-integration-tests/tasks/main.yaml', 'tox.ini']",4,48b658330f1ecede1c52f47775b3d655f2a58b3f,avconv, AVCONV_INSTALLED={env:AVCONV_INSTALLED:1},# Run integration tests only passenv = AVCONV_INSTALLED,24,3
openstack%2Fpython-tripleoclient~master~I286c71edf120e11d8e51c792e6078dc60147f026,openstack/python-tripleoclient,master,I286c71edf120e11d8e51c792e6078dc60147f026,"Revert ""Added for support for generating overcloud clouds.yaml""",MERGED,2019-12-17 03:13:10.000000000,2019-12-24 21:31:48.000000000,2019-12-24 21:30:31.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 03:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/887c2efabdbc6d8991da2165fe16c91107c9aa20', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\nDepends-On: https://review.opendev.org/#/c/696390/\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 2, 'created': '2019-12-17 03:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/76f17230d439f401b13db1f6bbce1498986805ff', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\nDepends-On: https://review.opendev.org/#/c/696390/\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 3, 'created': '2019-12-17 16:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/50fd3741426607f066c1006db46ef0a4d988bee8', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nDepends-On: https://review.opendev.org/#/c/696390/\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 4, 'created': '2019-12-17 19:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c0a6cfee43fc3e46735ac4413a643c8a567c2fd1', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nDepends-On: https://review.opendev.org/#/c/696390/\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 5, 'created': '2019-12-18 20:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/904ac10f0ecd7e99610b8107bc709e039f1bd7c6', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nDepends-On: https://review.opendev.org/#/c/696390/\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 6, 'created': '2019-12-19 03:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/33d49b34432c29662b9c1fd3ebcc7b02401e9348', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 7, 'created': '2019-12-19 03:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/249074a160bb9ad291f571abeb1df69b3e2022a5', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 8, 'created': '2019-12-19 03:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/097919e03c68c5de139758295b3fe6c1c81bc785', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 9, 'created': '2019-12-19 16:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c45b9beb8d0c4011c042d91f0c9acedaf966eecc', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}, {'number': 10, 'created': '2019-12-20 03:41:24.000000000', 'files': ['tripleoclient/workflows/deployment.py', 'tripleoclient/v1/mock_clouds_yaml.py', 'releasenotes/notes/overcloud-cloud-yaml-support-fae7585c46eda8e8.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ba9560467862c5d801b80d1d641dc6eca81836e1', 'message': 'Revert ""Added for support for generating overcloud clouds.yaml""\n\nThis has been replaced by Ansible.\nThis reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.\n\nChange-Id: I286c71edf120e11d8e51c792e6078dc60147f026\n'}]",3,699329,ba9560467862c5d801b80d1d641dc6eca81836e1,49,8,10,3153,,,0,"Revert ""Added for support for generating overcloud clouds.yaml""

This has been replaced by Ansible.
This reverts commit 0a8fc376cdbd7973cb84290cd7a4fa670e12e4d6.

Change-Id: I286c71edf120e11d8e51c792e6078dc60147f026
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/29/699329/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/constants.py', 'tripleoclient/workflows/deployment.py', 'tripleoclient/v1/mock_clouds_yaml.py', 'releasenotes/notes/overcloud-cloud-yaml-support-fae7585c46eda8e8.yaml', 'tripleoclient/v1/overcloud_deploy.py']",5,887c2efabdbc6d8991da2165fe16c91107c9aa20,revert,,"# FIXME(chkumar246): Once https://review.opendev.org/664568 gets merged # and new version of tripleo-common gots released, It requires a version # bump in requirements.txt. try: from tripleo_common.utils import clouds_yaml except ImportError: from tripleoclient.v1 import mock_clouds_yaml as clouds_yaml # Create overcloud clouds.yaml cloud_data = deployment.create_cloudsyaml( self.clients, container=stack.stack_name) cloud_yaml_dir = os.path.join(constants.CLOUD_HOME_DIR, constants.CLOUDS_YAML_DIR) cloud_user_id = os.stat(constants.CLOUD_HOME_DIR).st_uid cloud_group_id = os.stat(constants.CLOUD_HOME_DIR).st_gid clouds_yaml.create_clouds_yaml( cloud=cloud_data, cloud_yaml_dir=cloud_yaml_dir, user_id=cloud_user_id, group_id=cloud_group_id)",0,57
openstack%2Ftripleo-heat-templates~master~Id7f2942436565015211dcfa19fe95adb454c667e,openstack/tripleo-heat-templates,master,Id7f2942436565015211dcfa19fe95adb454c667e,Fix pacemaker firewall rules,MERGED,2019-12-23 17:22:57.000000000,2019-12-24 18:50:33.000000000,2019-12-24 18:50:33.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 17:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f876943e2d711c6036e5de3dd2a180c526122f4c', 'message': ""Fix pacemaker firewall rules\n\nWe switched to ansible for firewall rule management but the pacemaker\nfile wasn't properly converted.\n\nChange-Id: Id7f2942436565015211dcfa19fe95adb454c667e\nCloses-Bug: #1857356\n""}, {'number': 2, 'created': '2019-12-24 05:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/647bac11a3562d1048601181f776b40d758b2040', 'message': ""Fix pacemaker firewall rules\n\nWe switched to ansible for firewall rule management but the pacemaker\nfile wasn't properly converted.\n\nDepends-On: https://review.opendev.org/#/c/700472/\nChange-Id: Id7f2942436565015211dcfa19fe95adb454c667e\nCloses-Bug: #1857356\n""}, {'number': 3, 'created': '2019-12-24 05:48:10.000000000', 'files': ['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/daef223cc31d0d67a3b8f6ad45a928e2fa063346', 'message': ""Fix pacemaker firewall rules\n\nWe switched to ansible for firewall rule management but the pacemaker\nfile wasn't properly converted.\n\nDepends-On: https://review.opendev.org/#/c/700472/\nChange-Id: Id7f2942436565015211dcfa19fe95adb454c667e\nCloses-Bug: #1857356\n""}]",0,700439,daef223cc31d0d67a3b8f6ad45a928e2fa063346,23,9,3,14985,,,0,"Fix pacemaker firewall rules

We switched to ansible for firewall rule management but the pacemaker
file wasn't properly converted.

Depends-On: https://review.opendev.org/#/c/700472/
Change-Id: Id7f2942436565015211dcfa19fe95adb454c667e
Closes-Bug: #1857356
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/700439/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'],1,f876943e2d711c6036e5de3dd2a180c526122f4c,bug/1857356, firewall_rules: '130 pacemaker tcp': proto: 'tcp' dport: - 2224 - 3121 - 21064 '131 pacemaker udp': proto: 'udp' dport: 5405, tripleo.pacemaker.firewall_rules: '130 pacemaker tcp': proto: 'tcp' dport: - 2224 - 3121 - 21064 '131 pacemaker udp': proto: 'udp' dport: 5405,10,10
openstack%2Fmagnum~stable%2Ftrain~I4afaf159eaf2d2ff75bd3abec4137257e0daa8f2,openstack/magnum,stable/train,I4afaf159eaf2d2ff75bd3abec4137257e0daa8f2,k8s_fedora: Bump up default kube_tag to v1.15.7,MERGED,2019-12-20 10:55:43.000000000,2019-12-24 16:46:08.000000000,2019-12-24 13:09:21.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-12-20 10:55:43.000000000', 'files': ['magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7ed86653cc3a5d998d87494d11f2f96bb0b2cd4b', 'message': 'k8s_fedora: Bump up default kube_tag to v1.15.7\n\nAlso bump up cloud_provider_tag to v1.15.0.\n\nThis is the common supported version in Fedora Atomic (now EOL) when\n`use_podman=true` label is not supplied.\n\nTask: 37817\nStory: 2005380\n\nChange-Id: I4afaf159eaf2d2ff75bd3abec4137257e0daa8f2\nSigned-off-by: Bharat Kunwar <brtknr@bath.edu>\n(cherry picked from commit 9e3be39dd5909c9b8c3e2d454f4c1269319ed583)\n'}]",0,700153,7ed86653cc3a5d998d87494d11f2f96bb0b2cd4b,13,4,1,28022,,,0,"k8s_fedora: Bump up default kube_tag to v1.15.7

Also bump up cloud_provider_tag to v1.15.0.

This is the common supported version in Fedora Atomic (now EOL) when
`use_podman=true` label is not supplied.

Task: 37817
Story: 2005380

Change-Id: I4afaf159eaf2d2ff75bd3abec4137257e0daa8f2
Signed-off-by: Bharat Kunwar <brtknr@bath.edu>
(cherry picked from commit 9e3be39dd5909c9b8c3e2d454f4c1269319ed583)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/53/700153/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml']",3,7ed86653cc3a5d998d87494d11f2f96bb0b2cd4b,bump_kube_tag-stable/train, default: v1.15.7 default: v1.15.7 default: v1.15.7 default: v1.15.0 default: v1.15.7, default: v1.14.3 default: v1.14.3 default: v1.14.3 default: v1.14.0 default: v1.14.3,11,10
openstack%2Ftripleo-ansible~master~Ibb07a0b003bffdd1c76ff5816dccdadecb684db4,openstack/tripleo-ansible,master,Ibb07a0b003bffdd1c76ff5816dccdadecb684db4,Handle null enabled_networks and role_networks,MERGED,2019-12-24 05:39:59.000000000,2019-12-24 14:39:39.000000000,2019-12-24 14:39:39.000000000,"[{'_account_id': 3153}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-24 05:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2d95a24f6193fd4c75ccd4a2f6992b0c8a19eecb', 'message': 'Handle null enabled_networks and role_networks\n\nhttps://review.opendev.org/#/c/699502/ patch caused\nissue in undercloud-minion job where role_networks is null,\nthis patch fixes it by handling null values, also this patch adds\nundercloud-minion voting job to catch such failures in future.\n\nChange-Id: Ibb07a0b003bffdd1c76ff5816dccdadecb684db4\n'}, {'number': 2, 'created': '2019-12-24 05:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/460f2999f5aa96bcdc3aca7391b6e417c695d336', 'message': 'Handle null enabled_networks and role_networks\n\nhttps://review.opendev.org/#/c/699502/ patch caused\nissue in undercloud-minion job where role_networks is null,\nthis patch fixes it by handling null values, also this patch adds\nundercloud-minion voting job to catch such failures in future.\n\nChange-Id: Ibb07a0b003bffdd1c76ff5816dccdadecb684db4\n'}, {'number': 3, 'created': '2019-12-24 05:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/885ca574b138f56fbded96c91f9fec3e3234feee', 'message': 'Handle null enabled_networks and role_networks\n\nhttps://review.opendev.org/#/c/699502/ patch caused\nissue in undercloud-minion job where role_networks is null,\nthis patch fixes it by handling null values, also this patch adds\nundercloud-minion voting job to catch such failures in future.\n\nChange-Id: Ibb07a0b003bffdd1c76ff5816dccdadecb684db4\n'}, {'number': 4, 'created': '2019-12-24 05:47:19.000000000', 'files': ['tripleo_ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a4c9f27ed7010e215c921763ffe9232834ae8098', 'message': 'Handle null enabled_networks and role_networks\n\nhttps://review.opendev.org/#/c/699502/ patch caused\nissue in undercloud-minion job where role_networks is null,\nthis patch fixes it by handling null values, also this patch adds\nundercloud-minion voting job to catch such failures in future.\n\nChange-Id: Ibb07a0b003bffdd1c76ff5816dccdadecb684db4\n'}]",0,700472,a4c9f27ed7010e215c921763ffe9232834ae8098,18,6,4,13861,,,0,"Handle null enabled_networks and role_networks

https://review.opendev.org/#/c/699502/ patch caused
issue in undercloud-minion job where role_networks is null,
this patch fixes it by handling null values, also this patch adds
undercloud-minion voting job to catch such failures in future.

Change-Id: Ibb07a0b003bffdd1c76ff5816dccdadecb684db4
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/72/700472/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo-ssh-known-hosts/tasks/main.yml', 'zuul.d/layout.yaml']",2,2d95a24f6193fd4c75ccd4a2f6992b0c8a19eecb,, - tripleo-ci-centos-7-containers-undercloud-minion: &undercloud_minion dependencies: &deps - openstack-tox-linters files: - ^tripleo_ansible/.* irrelevant-files: &irrelevant_scenario_files - .*.md$ - .*.rst$ - .*.txt$ - ^_skeleton_role_/.* - ^tripleo_ansible/.*molecule.* - ^tripleo_ansible/.*meta.* - ^tripleo_ansible/roles/test_deps/.* - tripleo-ci-centos-7-containers-undercloud-minion: *undercloud_minion,,26,10
openstack%2Fkuryr-kubernetes~master~Id1d036b80438b21a100be12282058b995c36d2c3,openstack/kuryr-kubernetes,master,Id1d036b80438b21a100be12282058b995c36d2c3,Ensure network leftovers without kuryrnet CRD obj are deleted,MERGED,2019-12-19 08:52:06.000000000,2019-12-24 13:59:58.000000000,2019-12-24 13:57:57.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-12-19 08:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/df746d1f5ea137d4fa38ab88f0eaaa9b58cd364a', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 2, 'created': '2019-12-19 14:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2ae148d05d5287fd32044beaf3299d34b8fafc50', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 3, 'created': '2019-12-20 12:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f8830155fb25983fe95f061dbea42c37c60b09cb', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 4, 'created': '2019-12-20 14:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/d4159910670034b4f04874b1a4e28915a2430a69', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 5, 'created': '2019-12-20 14:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/3e6b0baeaff8bc81c433ee393ab5de302df9f5f3', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 6, 'created': '2019-12-23 15:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5f13aa3098f252d08f8857f16ab0427e1005b64b', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}, {'number': 7, 'created': '2019-12-23 15:34:10.000000000', 'files': ['kuryr_kubernetes/controller/handlers/namespace.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/db3fcbb8b49bc728ef32c8b0677696e360c1db9a', 'message': 'Ensure network leftovers without kuryrnet CRD obj are deleted\n\nThis patch ensures that network leftovers without kuryrnet CRD\nobject associated (caused by crash/restart of the kuryr-controller\nat an unfortunate time) are also handled by the cleanup thread\ntriggered at the kuryr-controller restart.\n\nChange-Id: Id1d036b80438b21a100be12282058b995c36d2c3\nCloses-Bug: 1856843\n'}]",14,699930,db3fcbb8b49bc728ef32c8b0677696e360c1db9a,39,6,7,23567,,,0,"Ensure network leftovers without kuryrnet CRD obj are deleted

This patch ensures that network leftovers without kuryrnet CRD
object associated (caused by crash/restart of the kuryr-controller
at an unfortunate time) are also handled by the cleanup thread
triggered at the kuryr-controller restart.

Change-Id: Id1d036b80438b21a100be12282058b995c36d2c3
Closes-Bug: 1856843
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/30/699930/2 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/handlers/namespace.py'],1,df746d1f5ea137d4fa38ab88f0eaaa9b58cd364a,namespace-leftovers,"from openstack import exceptions as os_exc # NOTE(ltomasbo): to ensure we don't miss created network resources # without associated kuryrnet objects, we do a second search os_net = clients.get_network_client() tags = oslo_cfg.CONF.neutron_defaults.resource_tags if not tags: return while True: retry = False networks = os_net.networks(tags=tags) namespaces = k8s.get(constants.K8S_API_NAMESPACES) ns_nets = ['ns/' + ns['metadata']['name'] + '-net' for ns in namespaces.get('items')] for net in networks: # NOTE(ltomasbo): network name is ns/NAMESPACE_NAME-net if net.name not in ns_nets: subnets = list(net.subnets) subnet_id = None if subnets: subnet_id = subnets[0] try: self._drv_subnets._delete_namespace_network_resources( subnet_id, net.id) except (os_exc.SDKException, exceptions.ResourceNotReady): LOG.debug(""Cleanup of network namespace resources %s "" ""faiuled. A retry will be triggered."", net.id) retry = True continue",,30,0
openstack%2Fpython-troveclient~master~I469fe301f438577ee7c897dcddb28cb672e50c6b,openstack/python-troveclient,master,I469fe301f438577ee7c897dcddb28cb672e50c6b,Add IP addresses in instance list output,MERGED,2019-12-24 11:39:10.000000000,2019-12-24 12:11:19.000000000,2019-12-24 12:09:59.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 11:39:10.000000000', 'files': ['troveclient/osc/v1/database_instances.py', 'troveclient/tests/osc/v1/test_database_instances.py'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/4463f36eb0760aa042d6300fb9870e114bc2fbb8', 'message': 'Add IP addresses in instance list output\n\nChange-Id: I469fe301f438577ee7c897dcddb28cb672e50c6b\n'}]",0,700506,4463f36eb0760aa042d6300fb9870e114bc2fbb8,7,2,1,6732,,,0,"Add IP addresses in instance list output

Change-Id: I469fe301f438577ee7c897dcddb28cb672e50c6b
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/06/700506/1 && git format-patch -1 --stdout FETCH_HEAD,"['troveclient/osc/v1/database_instances.py', 'troveclient/tests/osc/v1/test_database_instances.py']",2,4463f36eb0760aa042d6300fb9870e114bc2fbb8,show-ips," ('1234', 'test-member-1', 'mysql', '5.6', 'ACTIVE', '10.0.0.13', '02', 2, 'regionOne'), ('5678', 'test-member-2', 'mysql', '5.6', 'ACTIVE', '10.0.0.14', '2', 2, 'regionOne') 'ACTIVE', '10.0.0.13', '02', 2), 'ACTIVE', '10.0.0.14', '2', 2)"," ('1234', 'test-member-1', 'mysql', '5.6', 'ACTIVE', '02', 2, 'regionOne'), ('5678', 'test-member-2', 'mysql', '5.6', 'ACTIVE', '2', 2, 'regionOne') 'ACTIVE', '02', 2), 'ACTIVE', '2', 2)",15,8
openstack%2Fkuryr-kubernetes~master~I44f7f76da692ac3002c91a1420969584b4d31cbd,openstack/kuryr-kubernetes,master,I44f7f76da692ac3002c91a1420969584b4d31cbd,Ensure LB member is removed upon pod removal,MERGED,2019-12-19 02:40:25.000000000,2019-12-24 11:59:12.000000000,2019-12-24 10:10:18.000000000,"[{'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-12-19 02:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9e291df95d8631c3ba52024ea1ba7999017e1091', 'message': 'Ensure LB member is removed upon pod removal\n\nWhen pods that run on host network and are pointed by a svc\nare removed, the removal of the load balancer member is\nignored, as right now the name of the pod is not taken into\naccount on the decision of which members to delete, and as\nand the attributes that are checked, like pod ip and port\nremains the same. This commit fixes the issue by ensuring the\npod name is also checked.\n\nChange-Id: I44f7f76da692ac3002c91a1420969584b4d31cbd\n'}, {'number': 2, 'created': '2019-12-19 02:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/aba96652ae5a0d0885a38ec22b5f3a59a354a190', 'message': 'Ensure LB member is removed upon pod removal\n\nWhen pods that run on host network and are pointed by a svc\nare removed, the removal of the load balancer member is\nignored, as right now the name of the pod is not taken into\naccount on the decision of which members to delete, and the\ncurrent attributes checked are pod ip and port, which remains\nthe same. This commit fixes the issue by ensuring the\npod name is also checked.\n\nChange-Id: I44f7f76da692ac3002c91a1420969584b4d31cbd\n'}, {'number': 3, 'created': '2019-12-23 15:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a2d768c507ac24ba1701909c1d15b1bf2ce8866c', 'message': 'Ensure LB member is removed upon pod removal\n\nWhen pods that run on host network and are pointed by a svc\nare removed, the removal of the load balancer member is\nignored, as right now the name of the pod is not taken into\naccount on the decision of which members to delete, and the\ncurrent attributes checked are pod ip and port, which remains\nthe same. This commit fixes the issue by ensuring the\npod name is also checked.\n\nCloses-Bug: 1857354\nChange-Id: I44f7f76da692ac3002c91a1420969584b4d31cbd\n'}, {'number': 4, 'created': '2019-12-23 16:28:20.000000000', 'files': ['kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_lbaas.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8c62ce5abf4559272ba8ce7def3decc4b62e8979', 'message': 'Ensure LB member is removed upon pod removal\n\nWhen pods that run on host network and are pointed by a svc\nare removed, the removal of the load balancer member is\nignored, as right now the name of the pod is not taken into\naccount on the decision of which members to delete, and the\ncurrent attributes checked are pod ip and port, which remains\nthe same. This commit fixes the issue by ensuring the\npod name is also checked.\n\nCloses-Bug: 1857354\nChange-Id: I44f7f76da692ac3002c91a1420969584b4d31cbd\n'}]",1,699903,8c62ce5abf4559272ba8ce7def3decc4b62e8979,15,5,4,27032,,,0,"Ensure LB member is removed upon pod removal

When pods that run on host network and are pointed by a svc
are removed, the removal of the load balancer member is
ignored, as right now the name of the pod is not taken into
account on the decision of which members to delete, and the
current attributes checked are pod ip and port, which remains
the same. This commit fixes the issue by ensuring the
pod name is also checked.

Closes-Bug: 1857354
Change-Id: I44f7f76da692ac3002c91a1420969584b4d31cbd
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/03/699903/4 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/handlers/lbaas.py'],1,9e291df95d8631c3ba52024ea1ba7999017e1091,ensure-member-removed," current_targets = {(a['ip'], a.get('targetRef', {}).get('name', ''), p['port'], spec_ports.get(p.get('name'))) try: member_name = member.name pod_name = member_name.split('/')[1].split(':')[0] except AttributeError: pod_name = """" if ((str(member.ip), pod_name, member.port, member.pool_id) in"," current_targets = {(a['ip'], p['port'], spec_ports.get(p.get('name'))) if ((str(member.ip), member.port, member.pool_id) in",8,3
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3,openstack/tripleo-heat-templates,stable/train,Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3,Move some common tasks to step 1,MERGED,2019-12-19 17:04:11.000000000,2019-12-24 11:04:34.000000000,2019-12-24 11:04:34.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-19 17:04:11.000000000', 'files': ['common/deploy-steps-tasks.yaml', 'common/deploy-steps-tasks-step-1.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4b6eb4ca9fedfc84411f577370b287c9296427c5', 'message': 'Move some common tasks to step 1\n\nThese tasks in deploy-steps-tasks.yaml currently run at every step, but\nthey only actually need to run once. This patch moves them to\ndeploy-steps-tasks-step-1.yaml so that they are only run at step1 and do\nnot need to be skipped at every later step.\n\nChange-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3\n(cherry picked from commit af88862d9b27657160c47c9bab249af246af76f8)\n'}]",0,700030,4b6eb4ca9fedfc84411f577370b287c9296427c5,10,5,1,25877,,,0,"Move some common tasks to step 1

These tasks in deploy-steps-tasks.yaml currently run at every step, but
they only actually need to run once. This patch moves them to
deploy-steps-tasks-step-1.yaml so that they are only run at step1 and do
not need to be skipped at every later step.

Change-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3
(cherry picked from commit af88862d9b27657160c47c9bab249af246af76f8)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/700030/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/deploy-steps-tasks.yaml', 'common/deploy-steps-tasks-step-1.yaml']",2,4b6eb4ca9fedfc84411f577370b287c9296427c5,," - name: gather facts needed by role setup: gather_subset: ""!min,python"" when: ansible_python is not defined tags: - container_config_tasks - name: set python_cmd set_fact: python_cmd: ""python{{ ansible_python.version.major }}"" cacheable: true when: python_cmd is not defined tags: - container_config_tasks - name: Set host puppet debugging fact string set_fact: host_puppet_config_debug: ""--debug --verbose"" when: - enable_puppet | bool - enable_debug | bool tags: - host_config - name: Check for /etc/puppet/check-mode directory for check mode stat: path: /etc/puppet/check-mode register: check_mode_dir when: ansible_check_mode|bool tags: - host_config - container_config - name: Create /etc/puppet/check-mode/hieradata directory for check mode file: path: /etc/puppet/check-mode/hieradata state: directory setype: svirt_sandbox_file_t selevel: s0 recurse: true check_mode: no when: - ansible_check_mode|bool - not check_mode_dir.stat.exists tags: - host_config - container_config - name: Create puppet check-mode files if they don't exist for check mode shell: | cp -a /etc/puppet/hiera.yaml /etc/puppet/check-mode/hiera.yaml cp -a /etc/puppet/hieradata/* /etc/puppet/check-mode/hieradata/ sed -i 's/\/etc\/puppet\/hieradata/\/etc\/puppet\/check-mode\/hieradata/' /etc/puppet/check-mode/hiera.yaml when: - ansible_check_mode|bool - not check_mode_dir.stat.exists check_mode: no tags: - host_config - container_config",,61,63
openstack%2Fmagnum~stable%2Ftrain~I11113d69629e1a97a58e5270f67c7404292b45c3,openstack/magnum,stable/train,I11113d69629e1a97a58e5270f67c7404292b45c3,Fix proxy issue for k8s fedora drivers,MERGED,2019-12-23 22:04:22.000000000,2019-12-24 11:02:38.000000000,2019-12-24 11:00:53.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-12-23 22:04:22.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'releasenotes/notes/fix-fedora-proxy-a4b8d5fc4ec65e80.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/start-container-agent.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/57479b18d29a2d738955bc5bb599805bb8f4aceb', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n(cherry picked from commit ad2ef4962c83a42692fb0662e4eac2484fd7cf83)\n'}]",0,700458,57479b18d29a2d738955bc5bb599805bb8f4aceb,9,4,1,28022,,,0,"Fix proxy issue for k8s fedora drivers

Due to the big changes recently to support k8s rolling upgrade, a
regression issue was introduced which is broken the proxy function
for image downloading. This patch fixes it for both fedor atomic
driver and fedora coreos driver.

Task: 37784
Story: 2007005

Change-Id: I11113d69629e1a97a58e5270f67c7404292b45c3
(cherry picked from commit ad2ef4962c83a42692fb0662e4eac2484fd7cf83)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/58/700458/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'releasenotes/notes/fix-fedora-proxy-a4b8d5fc4ec65e80.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/start-container-agent.sh']",7,57479b18d29a2d738955bc5bb599805bb8f4aceb,story/2007005-37784-stable/train," echo ""http_proxy=${HTTP_PROXY}"" >> /etc/environment echo ""https_proxy=${HTTPS_PROXY}"" >> /etc/environment echo ""no_proxy=${NO_PROXY}"" >> /etc/environment",,23,2
openstack%2Foctavia~master~I1c7b123e4708a614aaa86ec3d41dade7f34d5f3f,openstack/octavia,master,I1c7b123e4708a614aaa86ec3d41dade7f34d5f3f,Gate on octavia-v2-dsvm-tls-barbican,MERGED,2019-12-06 10:36:35.000000000,2019-12-24 10:00:53.000000000,2019-12-24 09:58:20.000000000,"[{'_account_id': 1131}, {'_account_id': 2245}, {'_account_id': 10273}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-06 10:36:35.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/eab773453f574f092db84f09debea40e141f8b70', 'message': 'Gate on octavia-v2-dsvm-tls-barbican\n\nAt the Shanghai PTG, members of the Barbican and Octavia teams seemed to\nagree that job octavia-v2-dsvm-tls-barbican could be made voting in both\nprojects. The job has proven to be quite stable over time [1].\n\nThe patch that make the job voting in Barbican is [2].\n\n[1] http://zuul.openstack.org/builds?job_name=octavia-v2-dsvm-tls-barbican\n[2] https://review.opendev.org/#/c/697640/\n\nChange-Id: I1c7b123e4708a614aaa86ec3d41dade7f34d5f3f\n'}]",0,697644,eab773453f574f092db84f09debea40e141f8b70,9,4,1,6469,,,0,"Gate on octavia-v2-dsvm-tls-barbican

At the Shanghai PTG, members of the Barbican and Octavia teams seemed to
agree that job octavia-v2-dsvm-tls-barbican could be made voting in both
projects. The job has proven to be quite stable over time [1].

The patch that make the job voting in Barbican is [2].

[1] http://zuul.openstack.org/builds?job_name=octavia-v2-dsvm-tls-barbican
[2] https://review.opendev.org/#/c/697640/

Change-Id: I1c7b123e4708a614aaa86ec3d41dade7f34d5f3f
",git fetch https://review.opendev.org/openstack/octavia refs/changes/44/697644/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,eab773453f574f092db84f09debea40e141f8b70,, - octavia-v2-dsvm-tls-barbican: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^octavia/tests/unit/.*$ - ^releasenotes/.*$ - octavia-v2-dsvm-tls-barbican, - octavia-v2-dsvm-tls-barbican: irrelevant-files: - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^octavia/tests/unit/.*$ - ^releasenotes/.*$ voting: false,8,8
openstack%2Fzaqar~master~I1c6c0cb37819f93aa6f2a46508519fb9470f80f6,openstack/zaqar,master,I1c6c0cb37819f93aa6f2a46508519fb9470f80f6,Fix the incompatibility for python3,MERGED,2019-12-20 07:40:24.000000000,2019-12-24 09:56:01.000000000,2019-12-24 09:54:17.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 07:40:24.000000000', 'files': ['zaqar/storage/redis/models.py', 'zaqar/storage/swift/claims.py', 'zaqar/storage/redis/subscriptions.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0c952ebe29bd2bd6f0cd6a479aa38efbd5590f7c', 'message': 'Fix the incompatibility for python3\n\nChange-Id: I1c6c0cb37819f93aa6f2a46508519fb9470f80f6\n'}]",0,700118,0c952ebe29bd2bd6f0cd6a479aa38efbd5590f7c,15,2,1,8846,,,0,"Fix the incompatibility for python3

Change-Id: I1c6c0cb37819f93aa6f2a46508519fb9470f80f6
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/18/700118/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/redis/models.py', 'zaqar/storage/swift/claims.py', 'zaqar/storage/redis/subscriptions.py']",3,0c952ebe29bd2bd6f0cd6a479aa38efbd5590f7c,fix-incompatibility-for-python3," 'source': record[0].decode(), 'subscriber': record[1].decode(), 'confirmed': is_confirmed.decode(), if subscription[1].decode() == subscriber: if subscription[1].decode() == subscriber:"," 'source': record[0], 'subscriber': record[1], 'confirmed': is_confirmed, if subscription[1] == subscriber: if subscription[1] == subscriber:",8,8
openstack%2Fproject-config~master~I5916c3d0618cf2d7b0cc2c3fac89b38ba69b3dd1,openstack/project-config,master,I5916c3d0618cf2d7b0cc2c3fac89b38ba69b3dd1,Normalize projects.yaml,MERGED,2019-12-24 06:04:28.000000000,2019-12-24 09:02:30.000000000,2019-12-24 09:02:30.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-24 06:04:28.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/87a6608c4be457c5db800e8a6136640284d69685', 'message': 'Normalize projects.yaml\n\nChange-Id: I5916c3d0618cf2d7b0cc2c3fac89b38ba69b3dd1\n'}]",0,700482,87a6608c4be457c5db800e8a6136640284d69685,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I5916c3d0618cf2d7b0cc2c3fac89b38ba69b3dd1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/700482/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,87a6608c4be457c5db800e8a6136640284d69685,project-yaml-normalization," description: RETIRED, Tool for collecting diagnostic snapshot from nodes (logs, databases, etc)."," description: RETIRED, Tool for collecting diagnostic snapshot from nodes (logs, databases, etc).",2,2
openstack%2Fpython-ironic-inspector-client~master~I296ea5a0f20a17ad04d31ff50caa906686a737dd,openstack/python-ironic-inspector-client,master,I296ea5a0f20a17ad04d31ff50caa906686a737dd,Stop using six library,MERGED,2019-12-18 10:16:34.000000000,2019-12-24 09:02:19.000000000,2019-12-24 09:01:01.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-18 10:16:34.000000000', 'files': ['ironic_inspector_client/v1.py', 'requirements.txt', 'ironic_inspector_client/test/functional.py', 'ironic_inspector_client/common/http.py', 'lower-constraints.txt', 'ironic_inspector_client/test/test_v1.py', 'ironic_inspector_client/test/test_shell.py', 'ironic_inspector_client/test/test_common_http.py'], 'web_link': 'https://opendev.org/openstack/python-ironic-inspector-client/commit/09e4684efedfb8215089a698b984782da22676f6', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: I296ea5a0f20a17ad04d31ff50caa906686a737dd\n""}]",0,699649,09e4684efedfb8215089a698b984782da22676f6,9,4,1,23851,,,0,"Stop using six library

Since we've dropped support for Python 2.7, it's time to look at
the bright future that Python 3.x will bring and stop forcing
compatibility with older versions.
This patch removes the six library from requirements, not
looking back.

Change-Id: I296ea5a0f20a17ad04d31ff50caa906686a737dd
",git fetch https://review.opendev.org/openstack/python-ironic-inspector-client refs/changes/49/699649/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector_client/v1.py', 'requirements.txt', 'ironic_inspector_client/test/functional.py', 'ironic_inspector_client/common/http.py', 'lower-constraints.txt', 'ironic_inspector_client/test/test_v1.py', 'ironic_inspector_client/test/test_common_http.py', 'ironic_inspector_client/test/test_shell.py']",8,09e4684efedfb8215089a698b984782da22676f6,goodbye-six,import io buf = io.StringIO(),import six buf = six.StringIO(),17,27
openstack%2Ftaskflow~master~Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2,openstack/taskflow,master,Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2,Method set_required_parents introduced for GraphFlow class,ABANDONED,2015-08-03 13:08:52.000000000,2019-12-24 08:52:26.000000000,,"[{'_account_id': 1297}, {'_account_id': 6486}, {'_account_id': 7249}, {'_account_id': 10584}, {'_account_id': 14819}]","[{'number': 1, 'created': '2015-08-03 13:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6f927241a6706b86c7bbf0cbe9e77f5006e43fd0', 'message': ""Attribute parrents_required introduced for task class\n\nTo allow user specify whether it's required that all\npedecessors to be executed successfully or not new field for\ntask base class was introduced.\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\nCloses-bug: #1480907\n""}, {'number': 2, 'created': '2015-08-04 21:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3e02dca0bccbb8fca0061a43d5ecc501669cfb08', 'message': ""[WIP]Attribute parrents_required introduced for task class\n\nTo allow user specify whether it's required that all\npedecessors to be executed successfully or not new field for\ntask base class was introduced.\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\nCloses-bug: #1480907\n""}, {'number': 3, 'created': '2015-08-09 20:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8475701f38c2edc7b71a594b83cee1b498d11b7c', 'message': ""[WIP]Attribute parrents_required introduced for task class\n\nTo allow user specify whether it's required that all\npedecessors to be executed successfully or not new field for\ntask base class was introduced.\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\nCloses-bug: #1480907\n""}, {'number': 4, 'created': '2015-08-10 08:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/309938361cb375daa3a7a0170a34841cfe2fbc55', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npedecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\nCloses-bug: #1480907\n""}, {'number': 5, 'created': '2015-08-16 18:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9fbab74996cb5d979920f810f4db503a2fcdb1e0', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 6, 'created': '2015-08-16 20:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f83f58e6dc6e207ebc7582bd2e690067d923d6f8', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 7, 'created': '2015-08-24 08:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f9c697c292ac78155e339067b0afb1e1a1d88bdc', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 8, 'created': '2015-08-24 16:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/89af40a3e94e110f0ecb5fff409c2e19cabee319', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 9, 'created': '2015-08-25 06:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1eced406d4077e7a4080f9992685f88dad458e36', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 10, 'created': '2015-08-26 07:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/20ad1c0927afd8dff1173ca9ddcd73337e02dfe1', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 11, 'created': '2015-08-27 22:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fc7e04ba4e1ba0b521458101c4647fd806182841', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}, {'number': 12, 'created': '2015-08-28 15:05:57.000000000', 'files': ['taskflow/flow.py', 'taskflow/patterns/linear_flow.py', 'taskflow/tests/unit/test_engines.py', 'taskflow/examples/required_predecessors.py', 'taskflow/engines/action_engine/compiler.py', 'taskflow/examples/simple_required_predecessors.py', 'taskflow/engines/action_engine/analyzer.py', 'taskflow/patterns/graph_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1f3407fb3be13c31e051ac183d6eb3f5e45926b8', 'message': ""Method set_required_parents introduced for GraphFlow class\n\nTo allow user specify whether it's required that all\npredecessors to be executed successfully or not new method for\nGraphFlow class was introduced.\n\nCloses-bug: #1480907\n\nChange-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2\n""}]",42,208468,1f3407fb3be13c31e051ac183d6eb3f5e45926b8,46,5,12,14819,,,0,"Method set_required_parents introduced for GraphFlow class

To allow user specify whether it's required that all
predecessors to be executed successfully or not new method for
GraphFlow class was introduced.

Closes-bug: #1480907

Change-Id: Ic9f8dd58c1265a85a822e79e9ccf23f5a7f018d2
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/68/208468/12 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/engines/action_engine/runtime.py', 'taskflow/engines/action_engine/analyzer.py', 'taskflow/examples/switch_graph_flow.py']",4,6f927241a6706b86c7bbf0cbe9e77f5006e43fd0,bug/1480907,"def allow_true(history): print(history) return True r_c = DummyTask('r-c') r_d = DummyTask('r-d', parents_required=task.Required.ANY) r.add(r_a, r_b, r_c, r_d) r.link(r_a, r_b) r.link(r_a, r_c, decider=allow) r.link(r_b, r_d) r.link(r_c, r_d)","r.add(r_a, r_b) r.link(r_a, r_b, decider=allow)",49,14
openstack%2Fpython-ironicclient~master~I4b60638bb0268e5d1cf54fdf7d61964082536f4f,openstack/python-ironicclient,master,I4b60638bb0268e5d1cf54fdf7d61964082536f4f,Stop using six library,MERGED,2019-12-18 10:01:14.000000000,2019-12-24 07:47:00.000000000,2019-12-24 07:45:24.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-18 10:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/8bae40db064ab633b4e5f7a7f368b5e2586e7514', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: I4b60638bb0268e5d1cf54fdf7d61964082536f4f\n""}, {'number': 2, 'created': '2019-12-18 11:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/911b062d5901143583d6409eea7747b9583297f8', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: I4b60638bb0268e5d1cf54fdf7d61964082536f4f\n""}, {'number': 3, 'created': '2019-12-18 13:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/97416d9c8c54045c7a4bc2b4e6c4373a31d2a003', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: I4b60638bb0268e5d1cf54fdf7d61964082536f4f\n""}, {'number': 4, 'created': '2019-12-18 14:18:31.000000000', 'files': ['ironicclient/tests/functional/osc/v1/test_baremetal_node_fields.py', 'ironicclient/common/http.py', 'ironicclient/tests/unit/common/test_utils.py', 'ironicclient/tests/unit/v1/test_create_resources.py', 'ironicclient/tests/unit/test_exc.py', 'ironicclient/tests/unit/common/apiclient/test_exceptions.py', 'ironicclient/v1/create_resources.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_node_create_negative.py', 'lower-constraints.txt', 'ironicclient/common/base.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_node_negative.py', 'requirements.txt', 'ironicclient/common/apiclient/exceptions.py', 'ironicclient/tests/unit/v1/test_node.py', 'ironicclient/tests/functional/utils.py', 'ironicclient/tests/unit/utils.py', 'ironicclient/tests/unit/common/test_http.py', 'ironicclient/tests/functional/base.py', 'ironicclient/common/utils.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_deploy_template_basic.py', 'ironicclient/common/apiclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a572ae21e72c8197fb25f05d39a5caef99d7e575', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: I4b60638bb0268e5d1cf54fdf7d61964082536f4f\n""}]",0,699645,a572ae21e72c8197fb25f05d39a5caef99d7e575,14,3,4,23851,,,0,"Stop using six library

Since we've dropped support for Python 2.7, it's time to look at
the bright future that Python 3.x will bring and stop forcing
compatibility with older versions.
This patch removes the six library from requirements, not
looking back.

Change-Id: I4b60638bb0268e5d1cf54fdf7d61964082536f4f
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/45/699645/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/functional/osc/v1/test_baremetal_node_fields.py', 'ironicclient/common/http.py', 'ironicclient/tests/unit/common/test_utils.py', 'ironicclient/tests/unit/v1/test_create_resources.py', 'ironicclient/tests/unit/test_exc.py', 'ironicclient/tests/unit/common/apiclient/test_exceptions.py', 'ironicclient/v1/create_resources.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_node_create_negative.py', 'lower-constraints.txt', 'ironicclient/common/base.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_node_negative.py', 'requirements.txt', 'ironicclient/common/apiclient/exceptions.py', 'ironicclient/tests/unit/v1/test_node.py', 'ironicclient/tests/functional/utils.py', 'ironicclient/tests/unit/utils.py', 'ironicclient/tests/unit/common/test_http.py', 'ironicclient/tests/functional/base.py', 'ironicclient/common/utils.py', 'ironicclient/tests/functional/osc/v1/test_baremetal_deploy_template_basic.py', 'ironicclient/common/apiclient/base.py']",21,8bae40db064ab633b4e5f7a7f368b5e2586e7514,goodbye-six,"from http import client as http_client from urllib import parse as urlparseclass ManagerWithFind(BaseManager, metaclass=abc.ABCMeta): 'query': '?%s' % urlparse.urlencode(kwargs) if kwargs else '', 'query': '?%s' % urlparse.urlencode(kwargs) if kwargs else '',","import six from six.moves import http_client from six.moves.urllib import parse@six.add_metaclass(abc.ABCMeta) class ManagerWithFind(BaseManager): 'query': '?%s' % parse.urlencode(kwargs) if kwargs else '', 'query': '?%s' % parse.urlencode(kwargs) if kwargs else '',",85,117
openstack%2Fos-service-types~master~I3197f32b9d85e4c9030287d41f13af752133244d,openstack/os-service-types,master,I3197f32b9d85e4c9030287d41f13af752133244d,Switch to Ussuri jobs,MERGED,2019-10-24 06:45:42.000000000,2019-12-24 06:48:50.000000000,2019-12-24 06:46:11.000000000,"[{'_account_id': 8482}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-10-24 06:45:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/495914786fe054656fc6af0dca9ef27c708acb75', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I3197f32b9d85e4c9030287d41f13af752133244d\n'}]",2,690859,495914786fe054656fc6af0dca9ef27c708acb75,14,4,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: I3197f32b9d85e4c9030287d41f13af752133244d
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/59/690859/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,495914786fe054656fc6af0dca9ef27c708acb75,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fnetworking-bgpvpn~master~Ic2c7dae150f11223b70b876f5c4b4326671b89cd,openstack/networking-bgpvpn,master,Ic2c7dae150f11223b70b876f5c4b4326671b89cd,Switch to Ussuri jobs,ABANDONED,2019-10-25 06:31:32.000000000,2019-12-24 06:31:00.000000000,,"[{'_account_id': 841}, {'_account_id': 8313}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-10-25 06:31:32.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/c449862a2a09cf542acb7b9aff915794da4c286e', 'message': 'Switch to Ussuri jobs\n\nChange-Id: Ic2c7dae150f11223b70b876f5c4b4326671b89cd\n'}]",0,691207,c449862a2a09cf542acb7b9aff915794da4c286e,7,4,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: Ic2c7dae150f11223b70b876f5c4b4326671b89cd
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/07/691207/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c449862a2a09cf542acb7b9aff915794da4c286e,ussuri, - openstack-python3-ussuri-jobs-neutron, - openstack-python3-train-jobs-neutron,1,1
openstack%2Fmurano-dashboard~master~Id31368a5d3ab1a73d1c801afb699f1776f801b8b,openstack/murano-dashboard,master,Id31368a5d3ab1a73d1c801afb699f1776f801b8b,Switch to Ussuri jobs,ABANDONED,2019-10-23 08:14:34.000000000,2019-12-24 06:30:48.000000000,,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-23 08:14:34.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7c3e767fd6acef995fea2a3d2c4054cc68f9bdd3', 'message': 'Switch to Ussuri jobs\n\nChange-Id: Id31368a5d3ab1a73d1c801afb699f1776f801b8b\n'}]",0,690506,7c3e767fd6acef995fea2a3d2c4054cc68f9bdd3,5,2,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: Id31368a5d3ab1a73d1c801afb699f1776f801b8b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/06/690506/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7c3e767fd6acef995fea2a3d2c4054cc68f9bdd3,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fmonasca-api~master~I01a199b8da9d3a5eb949fac6c0306160f20dc4ab,openstack/monasca-api,master,I01a199b8da9d3a5eb949fac6c0306160f20dc4ab,Switch to Ussuri jobs,ABANDONED,2019-10-23 08:04:36.000000000,2019-12-24 06:30:32.000000000,,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-10-23 08:04:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/75ed04a71b7fa4bf9d85f7ffb9530b94d1ceb7c7', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I01a199b8da9d3a5eb949fac6c0306160f20dc4ab\n'}]",0,690496,75ed04a71b7fa4bf9d85f7ffb9530b94d1ceb7c7,5,3,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: I01a199b8da9d3a5eb949fac6c0306160f20dc4ab
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/96/690496/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,75ed04a71b7fa4bf9d85f7ffb9530b94d1ceb7c7,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fheat-cfntools~master~I60e1ed5e02823c1b4bcdb29dbdde3424870e1f08,openstack/heat-cfntools,master,I60e1ed5e02823c1b4bcdb29dbdde3424870e1f08,Bump the openstackdocstheme extension to 1.20,ABANDONED,2019-10-11 08:49:28.000000000,2019-12-24 06:30:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-10-11 08:49:28.000000000', 'files': ['doc/source/conf.py', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat-cfntools/commit/f134b267c1c50a2957f26346606f675338e838ae', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I60e1ed5e02823c1b4bcdb29dbdde3424870e1f08\n'}]",0,688076,f134b267c1c50a2957f26346606f675338e838ae,3,1,1,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: I60e1ed5e02823c1b4bcdb29dbdde3424870e1f08
",git fetch https://review.opendev.org/openstack/heat-cfntools refs/changes/76/688076/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/requirements.txt']",2,f134b267c1c50a2957f26346606f675338e838ae,openstackdocstheme,openstackdocstheme>=1.20.0 # Apache-2.0,openstackdocstheme>=1.11.0 # Apache-2.0,1,29
openstack%2Fhacking~master~Ib7d02f4feaedd7a4fce9ccb7e316c3c13bccaaf5,openstack/hacking,master,Ib7d02f4feaedd7a4fce9ccb7e316c3c13bccaaf5,Sync Sphinx requirement,ABANDONED,2019-10-09 08:19:31.000000000,2019-12-24 06:29:54.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-10-09 08:19:31.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/hacking/commit/41421b5a71106ca8dc80c7a16f9a70f812486413', 'message': 'Sync Sphinx requirement\n\nSync sphinx dependency with global requirements. It caps python 2 since\nsphinx 2.0 no longer supports Python 2.7.\n\nChange-Id: Ib7d02f4feaedd7a4fce9ccb7e316c3c13bccaaf5\n'}]",0,687477,41421b5a71106ca8dc80c7a16f9a70f812486413,3,1,1,27822,,,0,"Sync Sphinx requirement

Sync sphinx dependency with global requirements. It caps python 2 since
sphinx 2.0 no longer supports Python 2.7.

Change-Id: Ib7d02f4feaedd7a4fce9ccb7e316c3c13bccaaf5
",git fetch https://review.opendev.org/openstack/hacking refs/changes/77/687477/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,41421b5a71106ca8dc80c7a16f9a70f812486413,sphinx,"sphinx!=1.6.6,!=1.6.7,>=1.6.2,<2.0.0;python_version=='2.7' # BSD sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD","sphinx!=1.6.6,!=1.6.7,>=1.6.2 # BSD",2,1
openstack%2Fopenstack-chef~master~I64a4a85901e330a405da61d3af7f82f1fe72f223,openstack/openstack-chef,master,I64a4a85901e330a405da61d3af7f82f1fe72f223,Update the constraints url,ABANDONED,2019-09-26 06:18:23.000000000,2019-12-24 06:29:42.000000000,,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-26 06:18:23.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/823a43715834585ae91626f89a2dd8ebec0b4fdc', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I64a4a85901e330a405da61d3af7f82f1fe72f223\n'}]",0,684941,823a43715834585ae91626f89a2dd8ebec0b4fdc,4,2,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I64a4a85901e330a405da61d3af7f82f1fe72f223
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/41/684941/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,823a43715834585ae91626f89a2dd8ebec0b4fdc,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fmanila~master~I8ef7b24ca5e50b7e2482d1eee68a0afe29741bd0,openstack/manila,master,I8ef7b24ca5e50b7e2482d1eee68a0afe29741bd0,Switch to Ussuri jobs,ABANDONED,2019-10-23 07:50:26.000000000,2019-12-24 06:29:32.000000000,,"[{'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-10-23 07:50:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/5e7af6cd183ed3c450a5a70713409353380cfac7', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I8ef7b24ca5e50b7e2482d1eee68a0afe29741bd0\n'}]",0,690491,5e7af6cd183ed3c450a5a70713409353380cfac7,12,9,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: I8ef7b24ca5e50b7e2482d1eee68a0afe29741bd0
",git fetch https://review.opendev.org/openstack/manila refs/changes/91/690491/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5e7af6cd183ed3c450a5a70713409353380cfac7,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fhacking~master~I3a0a1c675fbc747b61a4d392eafc3f51ddfc392b,openstack/hacking,master,I3a0a1c675fbc747b61a4d392eafc3f51ddfc392b,Update the constraints url,ABANDONED,2019-09-26 05:51:02.000000000,2019-12-24 06:29:13.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-26 05:51:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/hacking/commit/8f0da23dc6ba415851a82a4f6e40b474aed85a89', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I3a0a1c675fbc747b61a4d392eafc3f51ddfc392b\n'}]",0,684928,8f0da23dc6ba415851a82a4f6e40b474aed85a89,3,1,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I3a0a1c675fbc747b61a4d392eafc3f51ddfc392b
",git fetch https://review.opendev.org/openstack/hacking refs/changes/28/684928/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8f0da23dc6ba415851a82a4f6e40b474aed85a89,constraints, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt},1,1
openstack%2Fkuryr~master~Ic0603d283466ad3261e29235eb53f0c7dc2c07b6,openstack/kuryr,master,Ic0603d283466ad3261e29235eb53f0c7dc2c07b6,Blacklist sphinx 2.1.0 (autodoc bug),ABANDONED,2019-07-26 06:45:30.000000000,2019-12-24 06:28:51.000000000,,"[{'_account_id': 11600}, {'_account_id': 15197}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27781}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-07-26 06:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/aef32cc3e7d645c69d3385f99f33867313660958', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nSee https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details\nDepend-On: https://review.opendev.org/#/c/663060/\n\nChange-Id: Ic0603d283466ad3261e29235eb53f0c7dc2c07b6\n'}, {'number': 2, 'created': '2019-07-30 09:00:27.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/5ecf059825948d8b87abf85b5bcbaf15f21734d2', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nSee https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details\n\nChange-Id: Ic0603d283466ad3261e29235eb53f0c7dc2c07b6\n'}]",1,672883,5ecf059825948d8b87abf85b5bcbaf15f21734d2,11,7,2,27822,,,0,"Blacklist sphinx 2.1.0 (autodoc bug)

See https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details

Change-Id: Ic0603d283466ad3261e29235eb53f0c7dc2c07b6
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/83/672883/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,aef32cc3e7d645c69d3385f99f33867313660958,sphinx,"sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD","sphinx!=1.6.6,!=1.6.7,>=1.6.2;python_version>='3.4' # BSD",1,1
openstack%2Fmanila~master~Ibcac3ebc1d665fd8357e4716e31ac7464161e497,openstack/manila,master,Ibcac3ebc1d665fd8357e4716e31ac7464161e497,Modify the url of upper_constraints_file,ABANDONED,2019-06-19 04:29:10.000000000,2019-12-24 06:28:41.000000000,,"[{'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 15386}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 26968}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-06-19 04:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dc5f5e3c8d4bea5702e5be6e6801d65d63adbc44', 'message': 'Modify the url of upper_constraints_file\n\nDepends-On: http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 2, 'created': '2019-07-01 04:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a4b9aad67d31e5b248f9249256cc8e3d951a15df', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 3, 'created': '2019-07-02 02:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fb342fbc0247a552535350c2691ebafb66eb44c3', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 4, 'created': '2019-07-02 03:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/356a96b09e06efe1372f950cdec8625b9b5ec6ff', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 5, 'created': '2019-07-03 01:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/872f541d6fd7a2f8249a20f3099688dfbb212dfb', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 6, 'created': '2019-07-03 03:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9d6d1e55c8e3a1b35212b32ac5826b712905e1c0', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 7, 'created': '2019-07-05 01:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/04af2ce41bebc346a699f271ef8f5b77ad128634', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}, {'number': 8, 'created': '2019-07-05 03:17:40.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/962e880291c65601b8b0288f4b689b660327790f', 'message': 'Modify the url of upper_constraints_file\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497\n'}]",0,666213,962e880291c65601b8b0288f4b689b660327790f,60,19,8,27822,,,0,"Modify the url of upper_constraints_file

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: Ibcac3ebc1d665fd8357e4716e31ac7464161e497
",git fetch https://review.opendev.org/openstack/manila refs/changes/13/666213/8 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,dc5f5e3c8d4bea5702e5be6e6801d65d63adbc44,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt},3,3
openstack%2Fhorizon~master~Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7,openstack/horizon,master,Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7,Remove unnecessary dependency injection,ABANDONED,2019-06-18 09:31:15.000000000,2019-12-24 06:28:26.000000000,,"[{'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-06-18 09:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cb0f005188ed309b393948361fa8b642b556a66d', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 2, 'created': '2019-06-19 04:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/79f9ae4b77b88706b04c28d4e089bedf29fe2c60', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 3, 'created': '2019-06-20 02:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/964adc9647307cdff04b0d5989d4bcc74df56e9a', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 4, 'created': '2019-06-20 05:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/293ced6edabbb52d68cc8c6360499f358b91f378', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 5, 'created': '2019-06-20 07:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0e0eee8a4d4e3f41857b64a16f8d424668dd9f6', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 6, 'created': '2019-06-20 09:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d08fca8040e07c0039a5a87400a99be0d56b1406', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}, {'number': 7, 'created': '2019-06-21 02:03:07.000000000', 'files': ['openstack_dashboard/static/app/core/images/images.module.spec.js', 'openstack_dashboard/static/app/core/images/actions/actions.module.js', 'openstack_dashboard/static/app/core/images/details/details.module.js', 'openstack_dashboard/static/app/core/images/summary.controller.spec.js', 'openstack_dashboard/static/app/core/images/images.service.spec.js', 'openstack_dashboard/static/app/core/images/steps/update-metadata/update-metadata.controller.spec.js', 'openstack_dashboard/static/app/core/images/filters/image-visibility.filter.spec.js', 'openstack_dashboard/static/app/core/images/details/overview.controller.spec.js', 'openstack_dashboard/static/app/core/images/steps/create-volume/create-volume.controller.spec.js', 'openstack_dashboard/static/app/core/images/actions/actions.module.spec.js', 'openstack_dashboard/static/app/core/images/actions/delete-image-selected.component.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/adde8076f0e1f67c7f6d935595e1cee8dc636692', 'message': 'Remove unnecessary dependency injection\n\nChange-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7\n'}]",2,665923,adde8076f0e1f67c7f6d935595e1cee8dc636692,17,3,7,27822,,,0,"Remove unnecessary dependency injection

Change-Id: Iac18b11c7d19ab8ef3ad3499fb25e8f67ebc98c7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/23/665923/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/app/core/images/actions/actions.module.js', 'openstack_dashboard/static/app/core/images/details/details.module.js']",2,cb0f005188ed309b393948361fa8b642b556a66d,Bug#2," angular.module('horizon.app.core.images.details', [])"," angular.module('horizon.app.core.images.details', ['horizon.framework.conf', 'horizon.app.core'])",2,5
openstack%2Fheat~master~I8191bb1807100fcabeb8dff359a01f4aa520782b,openstack/heat,master,I8191bb1807100fcabeb8dff359a01f4aa520782b,Switch to Ussuri jobs,ABANDONED,2019-10-22 03:05:03.000000000,2019-12-24 06:28:14.000000000,,"[{'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-10-22 03:05:03.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/a0518003b6bbb2dea797e5dec5efe3083ebf8d51', 'message': 'Switch to Ussuri jobs\n\nChange-Id: I8191bb1807100fcabeb8dff359a01f4aa520782b\n'}]",0,689909,a0518003b6bbb2dea797e5dec5efe3083ebf8d51,5,2,1,27822,,,0,"Switch to Ussuri jobs

Change-Id: I8191bb1807100fcabeb8dff359a01f4aa520782b
",git fetch https://review.opendev.org/openstack/heat refs/changes/09/689909/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a0518003b6bbb2dea797e5dec5efe3083ebf8d51,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d,openstack/tripleo-heat-templates,stable/train,Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d,Correct invalid jinja set,MERGED,2019-12-20 17:55:20.000000000,2019-12-24 06:27:00.000000000,2019-12-24 06:27:00.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 17:55:20.000000000', 'files': ['network/service_net_map.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6fb2aa195edd157e466379e2262c858fcfaa9c97', 'message': 'Correct invalid jinja set\n\nThis change corrects an issue with the jinja expression at the\ntop of the file which is resulting in a stacktrace when the\nset attempts to update an object of the same name, which results\nin a none type.\n\nThis change also updates the jinja expression at the top of the\nfile making it more legible.\n\nChange-Id: Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d\nCloses-Bug: #1856918\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,700216,6fb2aa195edd157e466379e2262c858fcfaa9c97,8,4,1,7353,,,0,"Correct invalid jinja set

This change corrects an issue with the jinja expression at the
top of the file which is resulting in a stacktrace when the
set attempts to update an object of the same name, which results
in a none type.

This change also updates the jinja expression at the top of the
file making it more legible.

Change-Id: Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d
Closes-Bug: #1856918
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/16/700216/1 && git format-patch -1 --stdout FETCH_HEAD,['network/service_net_map.j2.yaml'],1,6fb2aa195edd157e466379e2262c858fcfaa9c97,bug/1856918-stable/train,{% set _service_nets = {} %} {% for network in networks if network.enabled|default(true) %} {% if network.service_net_map_replace is defined %} {% set _ = _service_nets.update({network.service_net_map_replace:network.name_lower}) %} {% else %} {% set _ = _service_nets.update({network.name_lower:network.name_lower}) %} {% endif %} {% endfor %},{%- set _service_nets = {} -%} {%- for network in networks if network.enabled|default(true) -%} {%- if network.service_net_map_replace is defined -%} {%- set _service_nets = _service_nets.update({network.service_net_map_replace:network.name_lower}) -%} {%- else -%} {%- set _service_nets = _service_nets.update({network.name_lower:network.name_lower}) -%} {%- endif -%} {%- endfor -%} ,8,9
openstack%2Fnetworking-generic-switch~master~Ieb2acc895b670ad0732860acf5d53cfea34a2ee7,openstack/networking-generic-switch,master,Ieb2acc895b670ad0732860acf5d53cfea34a2ee7,fix test failure,ABANDONED,2019-06-21 00:49:23.000000000,2019-12-24 06:11:51.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 29071}]","[{'number': 1, 'created': '2019-06-21 00:49:23.000000000', 'files': ['networking_generic_switch/tests/unit/netmiko/test_netmiko_base.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/6045fa7c140a75b646a64e98211333a62f94f8e3', 'message': 'fix test failure\n\ntest cases directly under tests/unit/netmiko are failed when running directly. this problem is due to the fact that some options are not correctly registered.\n\nChange-Id: Ieb2acc895b670ad0732860acf5d53cfea34a2ee7\nCloses-Bug: #1833634\n'}]",0,666745,6045fa7c140a75b646a64e98211333a62f94f8e3,9,4,1,29071,,,0,"fix test failure

test cases directly under tests/unit/netmiko are failed when running directly. this problem is due to the fact that some options are not correctly registered.

Change-Id: Ieb2acc895b670ad0732860acf5d53cfea34a2ee7
Closes-Bug: #1833634
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/45/666745/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_generic_switch/tests/unit/netmiko/test_netmiko_base.py'],1,6045fa7c140a75b646a64e98211333a62f94f8e3,bug/1833634,from networking_generic_switch import config self.cfg = self.useFixture(config_fixture.Config(conf=config.CONF)), self.cfg = self.useFixture(config_fixture.Config()),2,1
openstack%2Fcinder~master~I325519f90b1931de2b9496c0d599a0653ad6c93c,openstack/cinder,master,I325519f90b1931de2b9496c0d599a0653ad6c93c,use urljoin to form swift_url for swift backup driver,ABANDONED,2019-06-11 12:07:56.000000000,2019-12-24 06:11:37.000000000,,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 15296}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29071}]","[{'number': 1, 'created': '2019-06-11 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff66038b409a45a757959584c1530f0361ada387', 'message': 'use urljoin to form swift_url for swift backup driver\n\nusing ""%s%s"" % (url, project_id) has a problem when url is given without a\ntrailing forward slash. Use urljoin will correctly form swift-url.\n\nChange-Id: I325519f90b1931de2b9496c0d599a0653ad6c93c\n'}, {'number': 2, 'created': '2019-06-19 02:22:03.000000000', 'files': ['cinder/backup/drivers/swift.py', 'cinder/tests/unit/backup/drivers/test_backup_swift.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9551ddb839a10a91e71935b4c5897613e98979f9', 'message': 'use urljoin to form swift_url for swift backup driver\n\nusing ""%s%s"" % (url, project_id) has a problem when url is given without a\ntrailing forward slash. Use urljoin will correctly form swift-url.\n\nChange-Id: I325519f90b1931de2b9496c0d599a0653ad6c93c\n'}]",1,664563,9551ddb839a10a91e71935b4c5897613e98979f9,40,21,2,29071,,,0,"use urljoin to form swift_url for swift backup driver

using ""%s%s"" % (url, project_id) has a problem when url is given without a
trailing forward slash. Use urljoin will correctly form swift-url.

Change-Id: I325519f90b1931de2b9496c0d599a0653ad6c93c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/63/664563/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/swift.py'],1,ff66038b409a45a757959584c1530f0361ada387,urljoin_path,"import six.moves.urllib.parse as urlparse self.swift_url = urlparse.urljoin( CONF.backup_swift_url, self.context.project_id )"," self.swift_url = '%s%s' % (CONF.backup_swift_url, self.context.project_id)",5,2
openstack%2Fironic~master~I92786eaed2c3bf6fb9f25672183bd9511e7a6e6e,openstack/ironic,master,I92786eaed2c3bf6fb9f25672183bd9511e7a6e6e,Add notes on the pxe template for aarch64,MERGED,2019-12-23 06:00:21.000000000,2019-12-24 06:02:51.000000000,2019-12-23 22:28:38.000000000,"[{'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 06:00:21.000000000', 'files': ['doc/source/install/configure-pxe.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a6344d03c4ba30f4e3d430c688a09fef56a509f', 'message': 'Add notes on the pxe template for aarch64\n\nOn verifying deployment on aarch64 bare metals, the linuxefi and\ninitrdefi are not available in grubaa64.efi, update doc to note\nthe potential change required on multi-architecture setup.\n\nChange-Id: I92786eaed2c3bf6fb9f25672183bd9511e7a6e6e\n'}]",2,700371,9a6344d03c4ba30f4e3d430c688a09fef56a509f,10,3,1,24828,,,0,"Add notes on the pxe template for aarch64

On verifying deployment on aarch64 bare metals, the linuxefi and
initrdefi are not available in grubaa64.efi, update doc to note
the potential change required on multi-architecture setup.

Change-Id: I92786eaed2c3bf6fb9f25672183bd9511e7a6e6e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/700371/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/configure-pxe.rst'],1,9a6344d03c4ba30f4e3d430c688a09fef56a509f,grubaa64,".. note:: The grub implementation may vary on different architecture, you may need to tweak the pxe config template for a specific arch. For example, grubaa64.efi shipped with CentoOS7 does not support ``linuxefi`` and ``initrdefi`` commands, you'll need to switch to use ``linux`` and ``initrd`` command instead. ",,8,0
openstack%2Fkuryr-kubernetes~master~I4ebb8d5da52ff2cee8970b061e31b3f391cacc1b,openstack/kuryr-kubernetes,master,I4ebb8d5da52ff2cee8970b061e31b3f391cacc1b,Ensure LB sg update is retried when NP is enforced,MERGED,2019-12-18 02:03:28.000000000,2019-12-24 05:44:42.000000000,2019-12-24 05:43:28.000000000,"[{'_account_id': 11600}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-12-18 02:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/0efc19f05f158ff28de9e2cb377706ecd2ace913', 'message': 'Ensure LB sg update is retried when NP is enforced\n\nIn case an endpoint is not yet annotated with the lbaas\nstate, when a Network Policy enforcement is triggered,\nthe update of the lbaas SG is ignored, causing a security breach.\nThis commit fixes the issue by retrying the update of the sg.\n\nChange-Id: I4ebb8d5da52ff2cee8970b061e31b3f391cacc1b\n'}, {'number': 2, 'created': '2019-12-18 12:00:19.000000000', 'files': ['kuryr_kubernetes/controller/drivers/lbaasv2.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/4c34068b2f21b321dc9bdfd76e6091a849a47cda', 'message': 'Ensure LB sg update is retried when NP is enforced\n\nIn case an endpoint is not yet annotated with the lbaas\nstate, when a Network Policy enforcement is triggered,\nthe update of the lbaas SG is ignored, causing a security breach.\nThis commit fixes the issue by retrying the update of the sg.\n\nCloses-bug: 1856842\n\nChange-Id: I4ebb8d5da52ff2cee8970b061e31b3f391cacc1b\n'}]",0,699529,4c34068b2f21b321dc9bdfd76e6091a849a47cda,18,4,2,27032,,,0,"Ensure LB sg update is retried when NP is enforced

In case an endpoint is not yet annotated with the lbaas
state, when a Network Policy enforcement is triggered,
the update of the lbaas SG is ignored, causing a security breach.
This commit fixes the issue by retrying the update of the sg.

Closes-bug: 1856842

Change-Id: I4ebb8d5da52ff2cee8970b061e31b3f391cacc1b
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/29/699529/2 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/lbaasv2.py'],1,0efc19f05f158ff28de9e2cb377706ecd2ace913,retry-lbaas-sg-update, LOG.debug('Endpoint not yet annotated with lbaas state.') raise k_exc.ResourceNotReady(svc_name), return,2,1
openstack%2Fironic~master~Ib546f16965475c32b2f8caabd560e2c7d382ac5a,openstack/ironic,master,Ib546f16965475c32b2f8caabd560e2c7d382ac5a,Stop using six library,MERGED,2019-11-29 09:17:31.000000000,2019-12-24 05:17:57.000000000,2019-12-24 05:16:05.000000000,"[{'_account_id': 10118}, {'_account_id': 10379}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 15519}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-11-29 09:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/17ac5b052b2f0c80e4610aa4f4072e9106c7660a', 'message': ""[WIP] Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 2, 'created': '2019-11-29 11:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06a9d42e83ebe17de932be31de1db42439658718', 'message': ""[WIP] Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 3, 'created': '2019-11-29 15:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6a1b3d816a025aebf5c2f0ec8952e6149a4aa386', 'message': ""[WIP] Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 4, 'created': '2019-11-29 16:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d3feb60d9fe35fd9c458472c7f715f0de9ce43b6', 'message': ""[WIP] Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 5, 'created': '2019-11-29 17:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/66ce711c184126e764bf3f41f853ef7a334a6d17', 'message': ""[WIP] Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 6, 'created': '2019-12-02 10:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b69520dea422918544cdbbe5205d3bcc14a6667', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 7, 'created': '2019-12-12 18:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d6e1d25f7df1ef3947cac943ba50acd0a28b213e', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 8, 'created': '2019-12-23 08:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3e8cc05f9dfa4e624addf4339022621c446168ad', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}, {'number': 9, 'created': '2019-12-23 08:38:34.000000000', 'files': ['ironic/tests/unit/api/controllers/v1/test_ramdisk.py', 'ironic/tests/unit/api/test_acl.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/drivers/modules/irmc/raid.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/dhcp/base.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/snmp.py', 'ironic/tests/unit/drivers/modules/xclarity/test_management.py', 'ironic/objects/fields.py', 'ironic/drivers/modules/redfish/boot.py', 'ironic/conductor/task_manager.py', 'ironic/drivers/modules/ibmc/utils.py', 'lower-constraints.txt', 'ironic/common/utils.py', 'ironic/common/fsm.py', 'ironic/tests/unit/drivers/modules/ilo/test_firmware_processor.py', 'ironic/drivers/modules/redfish/utils.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/api/test_middleware.py', 'ironic/conductor/base_manager.py', 'ironic/tests/unit/drivers/modules/test_agent_client.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/unit/api/controllers/v1/test_volume_target.py', 'ironic/api/controllers/v1/node.py', 'ironic/tests/unit/common/test_pxe_utils.py', 'ironic/api/controllers/v1/port.py', 'ironic/tests/unit/db/test_volume_connectors.py', 'ironic/drivers/modules/irmc/common.py', 'ironic/tests/unit/api/controllers/v1/test_portgroup.py', 'ironic/api/controllers/v1/ramdisk.py', 'ironic/tests/unit/common/test_swift.py', 'ironic/tests/unit/api/controllers/v1/test_port.py', 'ironic/tests/unit/api/controllers/v1/test_volume.py', 'ironic/tests/unit/drivers/modules/test_image_cache.py', 'requirements.txt', 'ironic/tests/unit/db/test_portgroups.py', 'ironic/api/controllers/v1/deploy_template.py', 'ironic/tests/unit/drivers/modules/ilo/test_inspect.py', 'ironic/drivers/utils.py', 'ironic/tests/unit/api/controllers/v1/test_utils.py', 'ironic/drivers/modules/agent.py', 'ironic/drivers/modules/ilo/firmware_processor.py', 'ironic/tests/unit/api/controllers/v1/test_deploy_template.py', 'ironic/tests/unit/db/test_deploy_templates.py', 'ironic/api/controllers/v1/event.py', 'ironic/api/controllers/v1/volume_connector.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/tests/unit/api/controllers/v1/test_allocation.py', 'ironic/api/controllers/v1/types.py', 'ironic/common/keystone.py', 'ironic/tests/unit/common/test_images.py', 'ironic/tests/unit/dhcp/test_factory.py', 'ironic/tests/unit/drivers/modules/ansible/test_deploy.py', 'ironic/tests/unit/common/test_cinder.py', 'ironic/tests/unit/drivers/modules/test_ipmitool.py', 'ironic/tests/unit/api/test_root.py', 'ironic/api/controllers/v1/driver.py', 'ironic/tests/unit/api/controllers/v1/test_conductor.py', 'ironic/tests/unit/common/test_states.py', 'ironic/drivers/modules/ilo/boot.py', 'ironic/tests/unit/db/test_volume_targets.py', 'ironic/tests/unit/api/controllers/v1/test_driver.py', 'ironic/api/controllers/v1/allocation.py', 'ironic/tests/unit/db/test_chassis.py', 'ironic/objects/node.py', 'ironic/common/exception.py', 'ironic/drivers/modules/agent_client.py', 'ironic/api/controllers/v1/volume_target.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/conductor/utils.py', 'ironic/drivers/modules/ansible/deploy.py', 'ironic/drivers/modules/ilo/management.py', 'ironic/drivers/base.py', 'ironic/common/glance_service/service_utils.py', 'ironic/common/image_service.py', 'ironic/tests/unit/drivers/modules/ilo/test_common.py', 'ironic/api/hooks.py', 'ironic/common/swift.py', 'ironic/tests/unit/db/test_nodes.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/tests/unit/drivers/modules/ilo/test_console.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/tests/unit/objects/utils.py', 'ironic/tests/unit/common/test_release_mappings.py', 'ironic/tests/unit/api/test_hooks.py', 'ironic/api/controllers/v1/volume.py', 'ironic/tests/unit/api/controllers/v1/test_volume_connector.py', 'ironic/drivers/hardware_type.py', 'ironic/tests/unit/db/test_ports.py', 'ironic/tests/unit/api/controllers/v1/test_event.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/tests/unit/drivers/modules/irmc/test_boot.py', 'ironic/drivers/modules/irmc/boot.py', 'ironic/api/controllers/v1/utils.py', 'ironic/tests/unit/api/controllers/v1/test_chassis.py', 'ironic/tests/unit/drivers/modules/xclarity/test_power.py', 'ironic/api/controllers/v1/portgroup.py', 'ironic/tests/unit/drivers/third_party_driver_mocks.py', 'ironic/common/glance_service/image_service.py', 'ironic/drivers/modules/image_cache.py', 'ironic/tests/unit/common/test_image_service.py', 'ironic/drivers/modules/ansible/playbooks/callback_plugins/ironic_log.py', 'ironic/tests/unit/drivers/modules/ilo/test_boot.py', 'ironic/tests/unit/api/base.py', 'ironic/tests/unit/api/controllers/test_base.py', 'ironic/tests/unit/api/controllers/v1/test_types.py', 'ironic/api/middleware/parsable_error.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/78c121a5d7b6efc84d541ea4de98aa910255884e', 'message': ""Stop using six library\n\nSince we've dropped support for Python 2.7, it's time to look at\nthe bright future that Python 3.x will bring and stop forcing\ncompatibility with older versions.\nThis patch removes the six library from requirements, not\nlooking back.\n\nChange-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a\n""}]",10,696669,78c121a5d7b6efc84d541ea4de98aa910255884e,57,9,9,23851,,,0,"Stop using six library

Since we've dropped support for Python 2.7, it's time to look at
the bright future that Python 3.x will bring and stop forcing
compatibility with older versions.
This patch removes the six library from requirements, not
looking back.

Change-Id: Ib546f16965475c32b2f8caabd560e2c7d382ac5a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/696669/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/conductor/utils.py', 'ironic/conductor/base_manager.py', 'ironic/conductor/task_manager.py']",5,17ac5b052b2f0c80e4610aa4f4072e9106c7660a,goodbye-six,import functools @functools.wraps(f) 'error': str(exc)},import six @six.wraps(f) 'error': six.text_type(exc)},8,17
openstack%2Ftripleo-common~stable%2Frocky~I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,openstack/tripleo-common,stable/rocky,I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,Incorrectly derives NeutronPhysnetNUMANodesMapping,MERGED,2019-12-23 03:33:46.000000000,2019-12-24 04:21:29.000000000,2019-12-23 16:58:54.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 03:33:46.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a4aecaaca5e115b96d32b8307737d3da9d15d380', 'message': 'Incorrectly derives NeutronPhysnetNUMANodesMapping\n\nThis change is to derive the NeutronPhysnetNUMANodesMapping\nparameter as dictionary instead of list.\n\nChange-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f\nCloses-Bug: #1856068\n(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)\n(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)\n(cherry picked from commit 515eb554b48312f16c26a0d67df261454ec45df3)\n'}]",0,700363,a4aecaaca5e115b96d32b8307737d3da9d15d380,8,6,1,22865,,,0,"Incorrectly derives NeutronPhysnetNUMANodesMapping

This change is to derive the NeutronPhysnetNUMANodesMapping
parameter as dictionary instead of list.

Change-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f
Closes-Bug: #1856068
(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)
(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)
(cherry picked from commit 515eb554b48312f16c26a0d67df261454ec45df3)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/63/700363/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,a4aecaaca5e115b96d32b8307737d3da9d15d380,incorrect-phy-nw-numa-mappings-stable/train-stable/stein-stable/rocky," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes)).sum()).sum() %>"," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes))).sum() %>",1,1
openstack%2Ftripleo-docs~master~Ib9a7582bf7521304f8931a64e2d4a23b971de1f1,openstack/tripleo-docs,master,Ib9a7582bf7521304f8931a64e2d4a23b971de1f1,Remove fedora28 repo info,MERGED,2019-12-17 15:55:23.000000000,2019-12-24 02:46:58.000000000,2019-12-24 02:45:28.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-17 15:55:23.000000000', 'files': ['deploy-guide/source/repositories.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/b67f5f6f9bd1f0cf0cf8e9c99d345bafba22eae6', 'message': ""Remove fedora28 repo info\n\nWe don't support the fedora 28 bits anymore now that centos8 is on the\nway.\n\nChange-Id: Ib9a7582bf7521304f8931a64e2d4a23b971de1f1\n""}]",0,699444,b67f5f6f9bd1f0cf0cf8e9c99d345bafba22eae6,8,2,1,14985,,,0,"Remove fedora28 repo info

We don't support the fedora 28 bits anymore now that centos8 is on the
way.

Change-Id: Ib9a7582bf7521304f8931a64e2d4a23b971de1f1
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/44/699444/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/repositories.rst'],1,b67f5f6f9bd1f0cf0cf8e9c99d345bafba22eae6,remove-fedora,,.. admonition:: Fedora 28 :class: fedora28 For Fedora 28 you will need to download the python3-tripleo-repos from https://trunk.rdoproject.org/fedora/current/:: sudo yum install -y https://trunk.rdoproject.org/fedora/current/python3-tripleo-repos-<version>.fc28.noarch.rpm .. admonition:: Fedora 28 :class: fedora28 Enable the current Fedora 28 repositories .. code-block:: bash sudo -E tripleo-repos -d fedora current .. admonition:: Ceph :class: ceph Include the Ceph repo in the tripleo-repos call .. code-block:: bash sudo -E tripleo-repos -d fedora current ceph ,0,26
openstack%2Ftripleo-operator-ansible~master~I699641f65f20c7c4814632eb380525843ebcba98,openstack/tripleo-operator-ansible,master,I699641f65f20c7c4814632eb380525843ebcba98,Action plugin for timestamping a file,MERGED,2019-12-16 23:02:01.000000000,2019-12-24 02:44:55.000000000,2019-12-24 02:44:55.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-16 23:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/d6870b0f87508f8cd4dd9751391fe9b21857aa92', 'message': ""Action plugin for timestamping a file\n\nThis change adds an action plugin called timestamp_file that will\ncheck if a file exists on a remote system and copies it out of the\nway so that a new version can be created. This plugin can be used to\nensure that logs aren't overwritten or some other file you want to keep\nbefore modifying.\n\nChange-Id: I699641f65f20c7c4814632eb380525843ebcba98\n""}, {'number': 2, 'created': '2019-12-16 23:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/402d78961fe99a0f4ada2724ebe8af52c908dd75', 'message': ""Action plugin for timestamping a file\n\nThis change adds an action plugin called timestamp_file that will\ncheck if a file exists on a remote system and copies it out of the\nway so that a new version can be created. This plugin can be used to\nensure that logs aren't overwritten or some other file you want to keep\nbefore modifying.\n\nChange-Id: I699641f65f20c7c4814632eb380525843ebcba98\n""}, {'number': 3, 'created': '2019-12-16 23:09:17.000000000', 'files': ['tests/plugins/action/__init__.py', 'plugins/action/timestamp_file.py', 'tests/plugins/action/test_timestamp_file.py'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/4326b34a7d9f3e290ccc6bdd7350b5f7c79801cd', 'message': ""Action plugin for timestamping a file\n\nThis change adds an action plugin called timestamp_file that will\ncheck if a file exists on a remote system and copies it out of the\nway so that a new version can be created. This plugin can be used to\nensure that logs aren't overwritten or some other file you want to keep\nbefore modifying.\n\nChange-Id: I699641f65f20c7c4814632eb380525843ebcba98\n""}]",0,699310,4326b34a7d9f3e290ccc6bdd7350b5f7c79801cd,10,2,3,14985,,,0,"Action plugin for timestamping a file

This change adds an action plugin called timestamp_file that will
check if a file exists on a remote system and copies it out of the
way so that a new version can be created. This plugin can be used to
ensure that logs aren't overwritten or some other file you want to keep
before modifying.

Change-Id: I699641f65f20c7c4814632eb380525843ebcba98
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/10/699310/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/plugins/action/__init__.py', 'plugins/action/timestamp_file.py', 'tests/plugins/action/test_timestamp_file.py']",3,d6870b0f87508f8cd4dd9751391fe9b21857aa92,tripleo-undercloud,"# Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from ansible.errors import AnsibleActionFail from ansible.errors import AnsibleActionSkip from ansible.playbook.play_context import PlayContext from tests import base as tests_base from plugins.action import timestamp_file class TestTimestampFile(tests_base.TestCase): def test_run(self): mock_task = mock.MagicMock() mock_task.async_val = None mock_task.action = ""timestamp_file"" mock_task.args = dict(path='foo.log') mock_connection = mock.MagicMock() play_context = PlayContext() action = timestamp_file.ActionModule(mock_task, mock_connection, play_context, None, None, None) mock_datetime = mock.MagicMock() mock_datetime.return_value = 'foo' action._get_date_string = mock_datetime mock_execute = mock.MagicMock() mock_execute.side_effect = [{'stat': {'exists': True}}, {'stat': {'exists': False}}, {'dest': 'foo.log.foo', 'failed': False, 'changed': True}] action._execute_module = mock_execute result = action.run() execute_calls = [mock.call(module_args={'path': 'foo.log'}, module_name='stat', task_vars={}), mock.call(module_args={'path': 'foo.log.foo'}, module_name='stat', task_vars={}), mock.call(module_args={'src': 'foo.log', 'dest': 'foo.log.foo', 'remote_src': True}, module_name='copy', task_vars={}) ] self.assertEqual(3, mock_execute.call_count) mock_execute.assert_has_calls(execute_calls) expected_result = {'dest': 'foo.log.foo', 'changed': True} self.assertEqual(expected_result, result) def test_run_source_missing_skips(self): mock_task = mock.MagicMock() mock_task.async_val = None mock_task.action = ""timestamp_file"" mock_task.args = dict(path='foo.log') mock_connection = mock.MagicMock() play_context = PlayContext() action = timestamp_file.ActionModule(mock_task, mock_connection, play_context, None, None, None) mock_datetime = mock.MagicMock() mock_datetime.return_value = 'foo' action._get_date_string = mock_datetime mock_execute = mock.MagicMock() mock_execute.side_effect = [{'stat': {'exists': False}}] action._execute_module = mock_execute self.assertRaises(AnsibleActionSkip, action.run) execute_calls = [mock.call(module_args={'path': 'foo.log'}, module_name='stat', task_vars={}) ] self.assertEqual(1, mock_execute.call_count) mock_execute.assert_has_calls(execute_calls) def test_run_destination_exists_fails(self): mock_task = mock.MagicMock() mock_task.async_val = None mock_task.action = ""timestamp_file"" mock_task.args = dict(path='foo.log') mock_connection = mock.MagicMock() play_context = PlayContext() action = timestamp_file.ActionModule(mock_task, mock_connection, play_context, None, None, None) mock_datetime = mock.MagicMock() mock_datetime.return_value = 'foo' action._get_date_string = mock_datetime mock_execute = mock.MagicMock() mock_execute.side_effect = [{'stat': {'exists': True}}, {'stat': {'exists': True}}] action._execute_module = mock_execute self.assertRaises(AnsibleActionFail, action.run) execute_calls = [mock.call(module_args={'path': 'foo.log'}, module_name='stat', task_vars={}), mock.call(module_args={'path': 'foo.log.foo'}, module_name='stat', task_vars={}) ] self.assertEqual(2, mock_execute.call_count) mock_execute.assert_has_calls(execute_calls) def test_run_destination_exists_force(self): mock_task = mock.MagicMock() mock_task.async_val = None mock_task.action = ""timestamp_file"" mock_task.args = dict(path='foo.log', force=True) mock_connection = mock.MagicMock() play_context = PlayContext() action = timestamp_file.ActionModule(mock_task, mock_connection, play_context, None, None, None) mock_datetime = mock.MagicMock() mock_datetime.return_value = 'foo' action._get_date_string = mock_datetime mock_execute = mock.MagicMock() mock_execute.side_effect = [{'stat': {'exists': True}}, {'stat': {'exists': True}}, {'dest': 'foo.log.foo', 'failed': False, 'changed': True}] action._execute_module = mock_execute result = action.run() execute_calls = [mock.call(module_args={'path': 'foo.log'}, module_name='stat', task_vars={}), mock.call(module_args={'path': 'foo.log.foo'}, module_name='stat', task_vars={}), mock.call(module_args={'src': 'foo.log', 'dest': 'foo.log.foo', 'remote_src': True}, module_name='copy', task_vars={}) ] self.assertEqual(3, mock_execute.call_count) mock_execute.assert_has_calls(execute_calls) expected_result = {'dest': 'foo.log.foo', 'changed': True} self.assertEqual(expected_result, result) ",,355,0
openstack%2Ftripleo-ansible~master~I3aff5f25b90affceacdf95d0f2725ed740761b70,openstack/tripleo-ansible,master,I3aff5f25b90affceacdf95d0f2725ed740761b70,tripleo-keystone-resources: handle multiple roles per user,MERGED,2019-12-16 20:40:00.000000000,2019-12-24 02:31:16.000000000,2019-12-24 02:31:16.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-16 20:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fb97cf73637a3b45bb7461d489cdc4f4ca6f7bd4', 'message': 'tripleo-keystone-resources: fix a typo for user/role assignment\n\nThe role data is stored in tripleo_keystone_resources_data_role\nvariable, not tripleo_keystone_resources_data.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 2, 'created': '2019-12-16 20:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/3444b5a70cd72f2b00e06af8f3488bb6c77c3cc2', 'message': 'tripleo-keystone-resources: fix a typo for user/role assignment\n\nThe role data is stored in tripleo_keystone_resources_data_role\nvariable, not tripleo_keystone_resources_data.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 3, 'created': '2019-12-16 23:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a8f7fd318510d4a2a2cbc7b5bef82b17e338358a', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 4, 'created': '2019-12-17 02:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cd057928e6be53c391e298c18d6ae3d97f89f611', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 5, 'created': '2019-12-17 16:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/dde697871b421d8f62ccb8fe6826bda8288f1bee', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 6, 'created': '2019-12-17 20:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8151361cc3e374398c6ff0764d42dcbbe6133bf9', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 7, 'created': '2019-12-18 13:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8885c06ca94e2778830bb49722b7b0abdcf95959', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 8, 'created': '2019-12-19 16:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/de95f0260fd3d6fdad180ecbb045ab7dfa6805e4', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 9, 'created': '2019-12-19 23:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4983a2336a5a7bf14a1c85e2ed8ddd34a463f9de', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 10, 'created': '2019-12-20 03:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/5a8a40e55d99d4f8e75fa3fa1598da66e3700709', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 11, 'created': '2019-12-20 03:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/03a74fdd3af5abbec40b8db1d4ca413280e00702', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}, {'number': 12, 'created': '2019-12-23 19:37:19.000000000', 'files': ['tripleo_ansible/roles/tripleo-keystone-resources/tasks/user_to_project_per_role.yml', 'tripleo_ansible/roles/tripleo-keystone-resources/tasks/user_roles.yml', 'tripleo_ansible/roles/tripleo-keystone-resources/tasks/main.yml', 'tripleo_ansible/tests/plugins/filter/test_helpers.py', 'tripleo_ansible/ansible_plugins/filter/helpers.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/478daa5471fa3cf5261614d0ff4fdbb18fc584ae', 'message': 'tripleo-keystone-resources: handle multiple roles per user\n\nos_user_role module can only assign one role to a user.\nIf a user needs multiple roles, we need a filter to build a dict where\neach key is a user with a list of the assigned roles.\n\nChange-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70\n'}]",2,699286,478daa5471fa3cf5261614d0ff4fdbb18fc584ae,46,6,12,3153,,,0,"tripleo-keystone-resources: handle multiple roles per user

os_user_role module can only assign one role to a user.
If a user needs multiple roles, we need a filter to build a dict where
each key is a user with a list of the assigned roles.

Change-Id: I3aff5f25b90affceacdf95d0f2725ed740761b70
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/86/699286/3 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-keystone-resources/tasks/user_to_project_per_role.yml'],1,fb97cf73637a3b45bb7461d489cdc4f4ca6f7bd4,roles/assign," user: ""{{ tripleo_keystone_resources_data_role.key }}"" project: ""{{ tripleo_keystone_resources_data_role.value.project }}"""," user: ""{{ tripleo_keystone_resources_data.key }}"" project: ""{{ tripleo_keystone_resources_data.value.project }}""",2,2
openstack%2Ftripleo-heat-templates~stable%2Fstein~I6907729bca667459466834276513e9f0233d10d0,openstack/tripleo-heat-templates,stable/stein,I6907729bca667459466834276513e9f0233d10d0,Update environment var for keystone bootstrap,MERGED,2019-12-13 21:05:31.000000000,2019-12-24 00:48:47.000000000,2019-12-24 00:48:47.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-13 21:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc816c73ca6e4d72fc0a0252cdc42d16ee7ba482', 'message': 'Update environment var for keystone bootstrap\n\nRelated-Bug: #1855932\n\nChange-Id: I6907729bca667459466834276513e9f0233d10d0\nDepends-On: https://review.opendev.org/#/c/698929/\n(cherry picked from commit 6f90cd8528abbcfeb1f9f8180ca048704b6ffed0)\n'}, {'number': 2, 'created': '2019-12-17 16:47:44.000000000', 'files': ['deployment/keystone/keystone-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aa660ce845667cbb9143e1537791126850f3f150', 'message': 'Update environment var for keystone bootstrap\n\nRelated-Bug: #1855932\n\nChange-Id: I6907729bca667459466834276513e9f0233d10d0\nDepends-On: https://review.opendev.org/#/c/698929/\n(cherry picked from commit 6f90cd8528abbcfeb1f9f8180ca048704b6ffed0)\n'}]",0,699019,aa660ce845667cbb9143e1537791126850f3f150,20,4,2,14985,,,0,"Update environment var for keystone bootstrap

Related-Bug: #1855932

Change-Id: I6907729bca667459466834276513e9f0233d10d0
Depends-On: https://review.opendev.org/#/c/698929/
(cherry picked from commit 6f90cd8528abbcfeb1f9f8180ca048704b6ffed0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/19/699019/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/keystone/keystone-container-puppet.yaml'],1,dc816c73ca6e4d72fc0a0252cdc42d16ee7ba482,bug/1855932," command: [ 'keystone', '/usr/bin/bootstrap_host_exec', 'keystone' ,'keystone-manage', 'bootstrap' ] - list_join: - '' - - 'OS_BOOTSTRAP_PASSWORD=' - {get_param: AdminPassword}"," # NOTE(mwhahaha): We use $$ because we're executing in python to # call as shell script and passing the command to run as arguments # to that shell script. So when it is called via eval, the escaped # $ properly evaulates command: [ 'keystone', '/usr/bin/bootstrap_host_exec', 'keystone' ,'keystone-manage', 'bootstrap', '--bootstrap-password', '$$KEYSTONE_BOOTSTRAP_PASSWORD' ]",5,5
openstack%2Fheat~master~Ib8af29c3d45d5ffbbb21c216429ef38d0d273d05,openstack/heat,master,Ib8af29c3d45d5ffbbb21c216429ef38d0d273d05,Loadbalancer id is required in listener creation API,ABANDONED,2018-02-09 08:26:23.000000000,2019-12-24 00:41:39.000000000,,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 25395}, {'_account_id': 27248}]","[{'number': 1, 'created': '2018-02-09 08:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7bb8d5f2148ef0a793bf19950290cdcc3fed7ec', 'message': 'Loadbalancer id is required in listener creation API\n\nChange-Id: Ib8af29c3d45d5ffbbb21c216429ef38d0d273d05\nCloses-Bug: #1748389\n'}, {'number': 2, 'created': '2019-12-23 18:28:20.000000000', 'files': ['heat/engine/resources/openstack/octavia/listener.py', 'heat/tests/openstack/octavia/test_listener.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5c44134d262074db24d027993ae388073eacd31c', 'message': 'Loadbalancer id is required in listener creation API\n\nChange-Id: Ib8af29c3d45d5ffbbb21c216429ef38d0d273d05\nCloses-Bug: #1748389\n'}]",0,542711,5c44134d262074db24d027993ae388073eacd31c,10,5,2,25395,,,0,"Loadbalancer id is required in listener creation API

Change-Id: Ib8af29c3d45d5ffbbb21c216429ef38d0d273d05
Closes-Bug: #1748389
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/542711/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/octavia/listener.py', 'heat/tests/openstack/octavia/test_listener.py']",2,f7bb8d5f2148ef0a793bf19950290cdcc3fed7ec,bug/1748389," self.assertRaises(exception.StackValidationFailed, self.listener.validate)"," if prop == 'loadbalancer': self.assertRaises(exception.PropertyUnspecifiedError, self.listener.validate) else: self.assertRaises(exception.StackValidationFailed, self.listener.validate)",3,11
openstack%2Fopenstack-ansible-os_ceilometer~stable%2Ftrain~Ib3a84516e0f00e84c6869fa58e9595062c6fbede,openstack/openstack-ansible-os_ceilometer,stable/train,Ib3a84516e0f00e84c6869fa58e9595062c6fbede,Check host is within group,MERGED,2019-12-23 17:52:25.000000000,2019-12-24 00:35:47.000000000,2019-12-24 00:34:35.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-12-23 17:52:25.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/6c5da4c405b084b7886e88b6568a1f05c79f40dd', 'message': 'Check host is within group\n\nA fix on my patch: https://review.opendev.org/#/c/694055/\nIf the current host is not in the ceilometer-agent-notification group\nthen the intersection of the current hosts group_names will produce an\nempty list. This should be checked before evaluating the next conditional.\n\nChange-Id: Ib3a84516e0f00e84c6869fa58e9595062c6fbede\n(cherry picked from commit fe9208c08ad27d92c9dac7b88404abf1214327f7)\n'}]",0,700442,6c5da4c405b084b7886e88b6568a1f05c79f40dd,8,4,1,28619,,,0,"Check host is within group

A fix on my patch: https://review.opendev.org/#/c/694055/
If the current host is not in the ceilometer-agent-notification group
then the intersection of the current hosts group_names will produce an
empty list. This should be checked before evaluating the next conditional.

Change-Id: Ib3a84516e0f00e84c6869fa58e9595062c6fbede
(cherry picked from commit fe9208c08ad27d92c9dac7b88404abf1214327f7)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/42/700442/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,6c5da4c405b084b7886e88b6568a1f05c79f40dd,check-conditional-length-stable/train, - ceilometer_services['ceilometer-agent-notification']['group'] | intersect(group_names) | length > 0, - (groups[(ceilometer_services['ceilometer-agent-notification']['group'] | intersect(group_names))[0]] | intersect(ansible_play_hosts))[0] | length > 0,1,1
openstack%2Fneutron~master~I895eaf4006583fedc2657a4eb527df1ff992c5bc,openstack/neutron,master,I895eaf4006583fedc2657a4eb527df1ff992c5bc,Work around potential double row.delete() call,MERGED,2019-12-19 15:18:37.000000000,2019-12-24 00:21:41.000000000,2019-12-24 00:19:51.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-19 15:18:37.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/474bff078c9c9e736f86b7394320661bde70eaf4', 'message': 'Work around potential double row.delete() call\n\nThe update_acls code can potentially iterate over the same ACL\ntwice. This temporary workaround silently ignores an attempt to\ndelete the same row twice in the same transaction, since that\nshould be safe. Ultimately, refactoring the ACL code to use sets\nand possibly handle the fact that an ACL could be referenced from\nmultiple rows should be done.\n\nChange-Id: I895eaf4006583fedc2657a4eb527df1ff992c5bc\nRelated-bug: #1857016\n'}]",2,700007,474bff078c9c9e736f86b7394320661bde70eaf4,24,9,1,5756,,,0,"Work around potential double row.delete() call

The update_acls code can potentially iterate over the same ACL
twice. This temporary workaround silently ignores an attempt to
delete the same row twice in the same transaction, since that
should be safe. Ultimately, refactoring the ACL code to use sets
and possibly handle the fact that an ACL could be referenced from
multiple rows should be done.

Change-Id: I895eaf4006583fedc2657a4eb527df1ff992c5bc
Related-bug: #1857016
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/700007/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'],1,474bff078c9c9e736f86b7394320661bde70eaf4,," try: acl_del_obj.delete() except AssertionError: # If we try to delete a row twice, just continue pass", acl_del_obj.delete(),5,1
openstack%2Fswift~master~I415901d3a8cd24cb3cedc72235292bb9d1705bbc,openstack/swift,master,I415901d3a8cd24cb3cedc72235292bb9d1705bbc,sharder: quote() more Swift paths when logging,MERGED,2019-12-20 07:11:12.000000000,2019-12-24 00:21:34.000000000,2019-12-24 00:19:58.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 07:11:12.000000000', 'files': ['swift/container/sharder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a06c0a47574639a27ea3e4742904c522dbee7d19', 'message': 'sharder: quote() more Swift paths when logging\n\nThe lack of quoting gets extra troublesome with reserved names,\nwhere messages get truncated.\n\nChange-Id: I415901d3a8cd24cb3cedc72235292bb9d1705bbc\n'}]",0,700117,a06c0a47574639a27ea3e4742904c522dbee7d19,15,3,1,15343,,,0,"sharder: quote() more Swift paths when logging

The lack of quoting gets extra troublesome with reserved names,
where messages get truncated.

Change-Id: I415901d3a8cd24cb3cedc72235292bb9d1705bbc
",git fetch https://review.opendev.org/openstack/swift refs/changes/17/700117/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/container/sharder.py'],1,a06c0a47574639a27ea3e4742904c522dbee7d19,,"from six.moves.urllib.parse import quote quote(broker.root_path), err) quote(broker.root_path), err) quote(broker.root_path), err) 'for %s in partition %s' % (quote(shard_range.name), part)) 'Audit failed for root %s (%s): %s', broker.db_file, quote(broker.path), ', '.join(warnings)) 'Audit warnings for shard %s (%s): %s', broker.db_file, quote(broker.path), ', '.join(warnings)) 'Audit failed for shard %s (%s) - skipping: %s', broker.db_file, quote(broker.path), ', '.join(errors)) broker.db_file, quote(broker.path)) '(not removing)', dest_shard_range, quote(broker.path)) dest_shard_range, quote(broker.path)) 'in %s', unplaced, quote(src_broker.path)) quote(broker.path), broker.db_file) self.logger.debug('Scan already completed for %s', quote(broker.path)) self.logger.info('Starting scan for shard ranges on %s', quote(broker.path)) shard_range, quote(broker.path)) quote(broker.path), cleaving_context.last_cleave_to_row, quote(shard_range.name), shard_range) quote(broker.path), shard_range) quote(broker.path), shard_range) quote(shard_broker.path), shard_broker.get_own_shard_range()) '%s successes, %s required.', shard_range, quote(broker.path), quote(broker.path), shard_range, elapsed) self.logger.debug('Passing over already sharded container %s', quote(broker.path)) quote(broker.path)) quote(broker.path)) quote(broker.path)) cleaving_context.ranges_todo, quote(broker.path)) 'Cleaved %s shard ranges for %s', len(ranges_done), quote(broker.path)) quote(broker.path)) 'Repeat cleaving required for %r with context: %s', broker.db_files[0], dict(cleaving_context)) self.logger.debug('Identified %s sharding candidates', len(candidates)) quote(broker.path)) quote(broker.path), state) 'and not leader; remaining unsharded: %s', own_shard_range.state_text, quote(broker.path)) self.logger.info('Completed cleaving of %s', quote(broker.path)) quote(broker.path)) self.logger.debug('Finished processing %s state %s', quote(broker.path), broker.get_db_state())"," broker.root_path, err) broker.root_path, err) broker.root_path, err) 'for %s in partition %s' % (shard_range.name, part)) 'Audit failed for root %s (%s): %s' % (broker.db_file, broker.path, ', '.join(warnings))) 'Audit warnings for shard %s (%s): %s' % (broker.db_file, broker.path, ', '.join(warnings))) 'Audit failed for shard %s (%s) - skipping: %s' % (broker.db_file, broker.path, ', '.join(errors))) broker.db_file, broker.path) '(not removing)', dest_shard_range, broker.path) dest_shard_range, broker.path) 'in %s' % (unplaced, src_broker.path)) broker.path, broker.db_file) self.logger.debug('Scan already completed for %s', broker.path) self.logger.info('Starting scan for shard ranges on %s', broker.path) shard_range, broker.path) broker.path, cleaving_context.last_cleave_to_row, shard_range.name, shard_range) broker.path, shard_range) broker.path, shard_range) shard_broker.path, shard_broker.get_own_shard_range()) '%s successes, %s required.', shard_range, broker.path, broker.path, shard_range, elapsed) self.logger.debug('Passing over already sharded container %s/%s', broker.account, broker.container) broker.path) broker.path) broker.path) cleaving_context.ranges_todo, broker.path) 'Cleaved %s shard ranges for %s', len(ranges_done), broker.path) broker.path) 'Repeat cleaving required for %r with context: %s' % (broker.db_files[0], dict(cleaving_context))) self.logger.debug('Identified %s sharding candidates' % len(candidates)) broker.path) broker.path, state) 'and not leader; remaining unsharded: %s' % (own_shard_range.state_text, broker.path)) self.logger.info('Completed cleaving of %s', broker.path) broker.path) self.logger.debug('Finished processing %s/%s state %s', broker.account, broker.container, broker.get_db_state())",51,46
openstack%2Fkeystone~stable%2Frocky~I0a846ca85c49180099120be7cd2e3607ed638a88,openstack/keystone,stable/rocky,I0a846ca85c49180099120be7cd2e3607ed638a88,Fix token auth error if federated_groups_id is empty list,ABANDONED,2019-12-24 00:12:18.000000000,2019-12-24 00:15:17.000000000,,[],"[{'number': 1, 'created': '2019-12-24 00:12:18.000000000', 'files': ['keystone/token/provider.py', 'releasenotes/notes/bug-1856962-e0d106b226db96e4.yaml', 'keystone/token/token_formatters.py', 'keystone/tests/unit/token/test_fernet_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d68fc3417ea88f147e5a343747a30af41c23d73f', 'message': 'Fix token auth error if federated_groups_id is empty list\n\n`federation_group_ids` could be zero length list, so deciding whether\na token is federated by checking if it is none.\n\nChange-Id: I0a846ca85c49180099120be7cd2e3607ed638a88\n'}]",0,700461,d68fc3417ea88f147e5a343747a30af41c23d73f,2,0,1,29071,,,0,"Fix token auth error if federated_groups_id is empty list

`federation_group_ids` could be zero length list, so deciding whether
a token is federated by checking if it is none.

Change-Id: I0a846ca85c49180099120be7cd2e3607ed638a88
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/700461/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/provider.py', 'releasenotes/notes/bug-1856962-e0d106b226db96e4.yaml', 'keystone/tests/unit/token/test_fernet_provider.py', 'keystone/token/token_formatters.py']",4,d68fc3417ea88f147e5a343747a30af41c23d73f,, return kwargs['federated_group_ids'] is not None, return kwargs['federated_group_ids'],30,3
openstack%2Fironic~master~I510f63e626f99c4b452d316978aca94b4d445565,openstack/ironic,master,I510f63e626f99c4b452d316978aca94b4d445565,Use the rootfs image,ABANDONED,2019-08-23 20:00:14.000000000,2019-12-23 22:07:10.000000000,,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-23 20:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3cd3eb7cfe7880ce6e5348ca6e242375d58c8ea', 'message': ""Try the rootfs image\n\nThe UEC image, actually fails to work outside of always network\nbooting, because the UEC image is a blank filesytem by design.\n\nUpon start-up, the UEC image writes contents out to the disk from\nthe ramdisk, which means that we can never explicitly local boot\nas we can't setup the ramdisk for the UEC.\n\nChange-Id: I510f63e626f99c4b452d316978aca94b4d445565\n""}, {'number': 2, 'created': '2019-08-23 21:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bae600549c67db91b51bf9d03221f1e79b6cfe49', 'message': ""Use the rootfs image\n\nThe UEC image actually fails to work outside of always network\nbooting, because the UEC image is a blank filesytem by design.\n\nUpon start-up, the UEC image writes contents out to the disk from\nthe ramdisk, which means that we can never explicitly local boot\nas we can't setup the ramdisk for the UEC.\n\nChange-Id: I510f63e626f99c4b452d316978aca94b4d445565\n""}, {'number': 3, 'created': '2019-08-24 01:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8e08ab17bd467e5d52a717d3aa48e0710e8eacf3', 'message': ""Use the rootfs image\n\nThe UEC image actually fails to work outside of always network\nbooting, because the UEC image is a blank filesytem by design.\n\nUpon start-up, the UEC image writes contents out to the disk from\nthe ramdisk, which means that we can never explicitly local boot\nas we can't setup the ramdisk for the UEC.\n\nChange-Id: I510f63e626f99c4b452d316978aca94b4d445565\n""}, {'number': 4, 'created': '2019-08-26 17:50:42.000000000', 'files': ['devstack/lib/ironic', 'devstack/common_settings', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2e64ad9d9af3bf2c8f7149ba7153ab74c6c69a90', 'message': ""Use the rootfs image\n\nThe UEC image actually fails to work outside of always network\nbooting, because the UEC image is a blank filesytem by design.\n\nUpon start-up, the UEC image writes contents out to the disk from\nthe ramdisk, which means that we can never explicitly local boot\nas we can't setup the ramdisk for the UEC.\n\nChange-Id: I510f63e626f99c4b452d316978aca94b4d445565\n""}]",0,678298,2e64ad9d9af3bf2c8f7149ba7153ab74c6c69a90,15,6,4,11655,,,0,"Use the rootfs image

The UEC image actually fails to work outside of always network
booting, because the UEC image is a blank filesytem by design.

Upon start-up, the UEC image writes contents out to the disk from
the ramdisk, which means that we can never explicitly local boot
as we can't setup the ramdisk for the UEC.

Change-Id: I510f63e626f99c4b452d316978aca94b4d445565
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/678298/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack/common_settings'],1,c3cd3eb7cfe7880ce6e5348ca6e242375d58c8ea,678298," # NOTE(TheJulia) UEC images, per # https://git.launchpad.net/cirros/tree/doc/RELEASE.txt # actually deploys an empty disk and does a copy to disk # upon boot, thus is always network booting. IRONIC_DEFAULT_IMAGE_NAME=cirros-${CIRROS_VERSION}-x86_64-rootfs IRONIC_DEFAULT_IMAGE_NAME=cirros-d160722-x86_64-rootfs #add_image_link http://download.cirros-cloud.net/daily/20160722/cirros-d160722-x86_64-uec.tar.gz add_image_link http://download.cirros-cloud.net/daily/20160722/cirros-d160722-x86_64-rootfs.img.gz add_image_link http://download.cirros-cloud.net/daily/20160722/cirros-d160722-x86_64-kernel add_image_link http://download.cirros-cloud.net/daily/20160722/cirros-d160722-x86_64-initramfs # Do not restrict downloading image only for specific case. #add_image_link http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-uec.tar.gz add_image_link http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-rootfs.img.gz add_image_link http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-kernel add_image_link http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-initramfsexport IRONIC_WHOLEDISK_IMAGE_NAME=${IRONIC_WHOLEDISK_IMAGE_NAME:-${IRONIC_IMAGE_NAME/-rootfs/-disk}} export IRONIC_PARTITIONED_IMAGE_NAME=${IRONIC_PARTITIONED_IMAGE_NAME:-${IRONIC_IMAGE_NAME/-disk/-rootfs}}",IRONIC_DEFAULT_IMAGE_NAME=cirros-${CIRROS_VERSION}-x86_64-uec IRONIC_DEFAULT_IMAGE_NAME=cirros-d160722-x86_64-uec add_image_link http://download.cirros-cloud.net/daily/20160722/cirros-d160722-x86_64-uec.tar.gz # Do not restrict downloading image only for specific case. Download both disk and uec images. add_image_link http://download.cirros-cloud.net/${CIRROS_VERSION}/cirros-${CIRROS_VERSION}-x86_64-uec.tar.gzexport IRONIC_WHOLEDISK_IMAGE_NAME=${IRONIC_WHOLEDISK_IMAGE_NAME:-${IRONIC_IMAGE_NAME/-uec/-disk}} export IRONIC_PARTITIONED_IMAGE_NAME=${IRONIC_PARTITIONED_IMAGE_NAME:-${IRONIC_IMAGE_NAME/-disk/-uec}},18,7
openstack%2Fmagnum~master~I11113d69629e1a97a58e5270f67c7404292b45c3,openstack/magnum,master,I11113d69629e1a97a58e5270f67c7404292b45c3,Fix proxy issue for k8s fedora drivers,MERGED,2019-12-11 03:30:24.000000000,2019-12-23 22:04:22.000000000,2019-12-23 19:18:51.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-12-11 03:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b4eddb68769c379830adea16b2147651aa27004d', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 2, 'created': '2019-12-12 02:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/579d83a8709e7110b4b5587ebe9bd1e28f6a8564', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 3, 'created': '2019-12-15 22:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/457e3224211c9a670a5341bb240a789798212ae8', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 4, 'created': '2019-12-15 22:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4fffc1586a23ab0835ac7ef976787fed819b803c', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 5, 'created': '2019-12-18 05:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6e0036e37b21823216545568f758bf10c3f4afd5', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 6, 'created': '2019-12-19 08:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d3e04016fda460b591e259d4a2b9ea37640b4dc1', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 7, 'created': '2019-12-19 08:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c9b5838cd7fdcb2e122469a5b762e9dd5b3cd49e', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}, {'number': 8, 'created': '2019-12-19 20:40:18.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'releasenotes/notes/fix-fedora-proxy-a4b8d5fc4ec65e80.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/start-container-agent.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/ad2ef4962c83a42692fb0662e4eac2484fd7cf83', 'message': 'Fix proxy issue for k8s fedora drivers\n\nDue to the big changes recently to support k8s rolling upgrade, a\nregression issue was introduced which is broken the proxy function\nfor image downloading. This patch fixes it for both fedor atomic\ndriver and fedora coreos driver.\n\nTask: 37784\nStory: 2007005\n\nChange-Id: I11113d69629e1a97a58e5270f67c7404292b45c3\n'}]",11,698353,ad2ef4962c83a42692fb0662e4eac2484fd7cf83,31,4,8,6484,,,0,"Fix proxy issue for k8s fedora drivers

Due to the big changes recently to support k8s rolling upgrade, a
regression issue was introduced which is broken the proxy function
for image downloading. This patch fixes it for both fedor atomic
driver and fedora coreos driver.

Task: 37784
Story: 2007005

Change-Id: I11113d69629e1a97a58e5270f67c7404292b45c3
",git fetch https://review.opendev.org/openstack/magnum refs/changes/53/698353/6 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'releasenotes/notes/fix-fedora-proxy-a4b8d5fc4ec65e80.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/start-container-agent.sh']",7,b4eddb68769c379830adea16b2147651aa27004d,story/2007005-37784," echo ""http_proxy=${HTTP_PROXY}"" >> /etc/environment echo ""https_proxy=${HTTPS_PROXY}"" >> /etc/environment echo ""no_proxy=${NO_PROXY}"" >> /etc/environment",,22,1
openstack%2Ftripleo-heat-templates~master~Icc78fb96b28cd7a036d958ba78b2075e7c241207,openstack/tripleo-heat-templates,master,Icc78fb96b28cd7a036d958ba78b2075e7c241207,Make pcsd listen on PacemakerNetwork/PacemakerRemoteNetwork,MERGED,2019-12-17 01:16:51.000000000,2019-12-23 21:41:08.000000000,2019-12-21 08:42:39.000000000,"[{'_account_id': 3153}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 01:16:51.000000000', 'files': ['deployment/pacemaker/pacemaker-remote-baremetal-puppet.yaml', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3056f25bd1763a773a1acbab0f465d0f5bf5b778', 'message': 'Make pcsd listen on PacemakerNetwork/PacemakerRemoteNetwork\n\nConfigure bind address for pcsd so that it listens on a specific\nnetwork instead of all available networks.\n\nCloses-Bug: #1856626\nDepends-on: https://review.opendev.org/#/c/697942\nDepends-on: https://review.opendev.org/#/c/697943\nChange-Id: Icc78fb96b28cd7a036d958ba78b2075e7c241207\n'}]",0,699318,3056f25bd1763a773a1acbab0f465d0f5bf5b778,17,6,1,9816,,,0,"Make pcsd listen on PacemakerNetwork/PacemakerRemoteNetwork

Configure bind address for pcsd so that it listens on a specific
network instead of all available networks.

Closes-Bug: #1856626
Depends-on: https://review.opendev.org/#/c/697942
Depends-on: https://review.opendev.org/#/c/697943
Change-Id: Icc78fb96b28cd7a036d958ba78b2075e7c241207
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/699318/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/pacemaker/pacemaker-remote-baremetal-puppet.yaml', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml']",2,3056f25bd1763a773a1acbab0f465d0f5bf5b778,bug/1856626," tripleo::profile::base::pacemaker::pcsd_bind_addr: str_replace: template: ""%{hiera('$NETWORK')}"" params: $NETWORK: {get_param: [ServiceNetMap, PacemakerNetwork]}",,12,0
openstack%2Ftripleo-heat-templates~master~Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3,openstack/tripleo-heat-templates,master,Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3,Move some common tasks to step 1,MERGED,2019-12-11 01:39:29.000000000,2019-12-23 21:39:43.000000000,2019-12-23 21:39:43.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-11 01:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf1d81a1e504e44e26e49eab7ec7335854930cfb', 'message': 'Move some common tasks to step 1\n\nThese tasks in deploy-steps-tasks.yaml currently run at every step, but\nthey only actually need to run once. This patch moves them to\ndeploy-steps-tasks-step-1.yaml so that they are only run at step1 and do\nnot need to be skipped at every later step.\n\nChange-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3\n'}, {'number': 2, 'created': '2019-12-11 12:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6514046856babed11f9454ffad922222dc470705', 'message': 'Move some common tasks to step 1\n\nThese tasks in deploy-steps-tasks.yaml currently run at every step, but\nthey only actually need to run once. This patch moves them to\ndeploy-steps-tasks-step-1.yaml so that they are only run at step1 and do\nnot need to be skipped at every later step.\n\nChange-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3\n'}, {'number': 3, 'created': '2019-12-13 19:29:41.000000000', 'files': ['common/deploy-steps-tasks.yaml', 'common/deploy-steps-tasks-step-1.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/af88862d9b27657160c47c9bab249af246af76f8', 'message': 'Move some common tasks to step 1\n\nThese tasks in deploy-steps-tasks.yaml currently run at every step, but\nthey only actually need to run once. This patch moves them to\ndeploy-steps-tasks-step-1.yaml so that they are only run at step1 and do\nnot need to be skipped at every later step.\n\nChange-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3\n'}]",1,698348,af88862d9b27657160c47c9bab249af246af76f8,38,6,3,7144,,,0,"Move some common tasks to step 1

These tasks in deploy-steps-tasks.yaml currently run at every step, but
they only actually need to run once. This patch moves them to
deploy-steps-tasks-step-1.yaml so that they are only run at step1 and do
not need to be skipped at every later step.

Change-Id: Ib64d1969c5dff3901829583fc2db2f6e2a3acbb3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/698348/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/deploy-steps-tasks.yaml', 'common/deploy-steps-tasks-step-1.yaml']",2,bf1d81a1e504e44e26e49eab7ec7335854930cfb,scale-and-performance," - name: gather facts needed by role setup: gather_subset: ""!min,python"" when: ansible_python is not defined tags: - container_config_tasks - name: set python_cmd set_fact: python_cmd: ""python{{ ansible_python.version.major }}"" cacheable: true when: python_cmd is not defined tags: - container_config_tasks - name: Set host puppet debugging fact string set_fact: host_puppet_config_debug: ""--debug --verbose"" when: - enable_puppet | bool - enable_debug | bool tags: - host_config - name: Check for /etc/puppet/check-mode directory for check mode stat: path: /etc/puppet/check-mode register: check_mode_dir when: ansible_check_mode|bool tags: - host_config - container_config - name: Create /etc/puppet/check-mode/hieradata directory for check mode file: path: /etc/puppet/check-mode/hieradata state: directory setype: svirt_sandbox_file_t selevel: s0 recurse: true check_mode: no when: - ansible_check_mode|bool - not check_mode_dir.stat.exists tags: - host_config - container_config - name: Create puppet check-mode files if they don't exist for check mode shell: | cp -a /etc/puppet/hiera.yaml /etc/puppet/check-mode/hiera.yaml cp -a /etc/puppet/hieradata/* /etc/puppet/check-mode/hieradata/ sed -i 's/\/etc\/puppet\/hieradata/\/etc\/puppet\/check-mode\/hieradata/' /etc/puppet/check-mode/hiera.yaml when: - ansible_check_mode|bool - not check_mode_dir.stat.exists check_mode: no tags: - host_config - container_config",,61,63
openstack%2Fos-service-types~master~Id141cd1906b678a4ee238b10fb2fbf3850f5fa42,openstack/os-service-types,master,Id141cd1906b678a4ee238b10fb2fbf3850f5fa42,Updated from OpenStack Service Type Authority,MERGED,2019-07-23 14:20:40.000000000,2019-12-23 21:15:53.000000000,2019-12-23 21:14:38.000000000,"[{'_account_id': 8482}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-07-23 14:20:40.000000000', 'files': ['os_service_types/data/service-types.json'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/726b8ec0794dabbba5700e92930dc592c411992f', 'message': 'Updated from OpenStack Service Type Authority\n\nChange-Id: Id141cd1906b678a4ee238b10fb2fbf3850f5fa42\n'}]",1,672295,726b8ec0794dabbba5700e92930dc592c411992f,8,3,1,11131,,,0,"Updated from OpenStack Service Type Authority

Change-Id: Id141cd1906b678a4ee238b10fb2fbf3850f5fa42
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/95/672295/1 && git format-patch -1 --stdout FETCH_HEAD,['os_service_types/data/service-types.json'],1,726b8ec0794dabbba5700e92930dc592c411992f,openstack/os-service-types/sync-service-types-authority," ""sha"": ""69b5e7d5c965605dacc19ee0bc7730e232d58a3d"", ""version"": ""2019-07-23T14:12:22.205489"""," ""sha"": ""4a8e2d261fb5a4283d7d0eae9c39ead15dfd799c"", ""version"": ""2019-05-01T19:53:21.498745""",2,2
openstack%2Ftripleo-heat-templates~stable%2Ftrain~If1c7e2902c2e2ac70965e5718228cc34161ae3d2,openstack/tripleo-heat-templates,stable/train,If1c7e2902c2e2ac70965e5718228cc34161ae3d2,Enable horizon healthcheck,MERGED,2019-12-13 19:35:55.000000000,2019-12-23 21:13:54.000000000,2019-12-23 21:13:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-13 19:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a87f2087b186ef24cac09e273136ccc2587cb75', 'message': 'Enable horizon healthcheck\n\nChange-Id: If1c7e2902c2e2ac70965e5718228cc34161ae3d2\nDepends-On: https://review.opendev.org/#/c/699005/\nCloses-Bug: #1856088\n(cherry picked from commit 71b5d408620c90585d93456c45742881c6e7bf81)\n'}, {'number': 2, 'created': '2019-12-17 12:09:44.000000000', 'files': ['deployment/horizon/horizon-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b3bbc24ca19d8b7aab874479675145386794700a', 'message': 'Enable horizon healthcheck\n\nChange-Id: If1c7e2902c2e2ac70965e5718228cc34161ae3d2\nDepends-On: https://review.opendev.org/#/c/699005/\nCloses-Bug: #1856088\n(cherry picked from commit 71b5d408620c90585d93456c45742881c6e7bf81)\n'}]",0,699006,b3bbc24ca19d8b7aab874479675145386794700a,11,4,2,14985,,,0,"Enable horizon healthcheck

Change-Id: If1c7e2902c2e2ac70965e5718228cc34161ae3d2
Depends-On: https://review.opendev.org/#/c/699005/
Closes-Bug: #1856088
(cherry picked from commit 71b5d408620c90585d93456c45742881c6e7bf81)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/699006/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/horizon/horizon-container-puppet.yaml'],1,5a87f2087b186ef24cac09e273136ccc2587cb75,bug/1856088-stable/train, healthcheck: test: /openstack/healthcheck,,2,0
openstack%2Ftripleo-common~stable%2Ftrain~Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd,openstack/tripleo-common,stable/train,Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd,Add deploy_steps_tasks to PER_TASK_STEPS,MERGED,2019-12-19 16:58:08.000000000,2019-12-23 21:07:30.000000000,2019-12-23 21:05:05.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 16:58:08.000000000', 'files': ['tripleo_common/constants.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cf5b602450a1cd0f48c86436b6632718470094d6', 'message': 'Add deploy_steps_tasks to PER_TASK_STEPS\n\ndeploy_steps_tasks will now be written out in per step files in the\nconfig download directory. This will allow including the task files for\na specific step only at that step, and saving time by not having to skip\nso many tasks.\n\nChange-Id: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd\n(cherry picked from commit 03fe9dfc3d5ae8952078891bc34e44a6d2426d20)\n'}]",0,700029,cf5b602450a1cd0f48c86436b6632718470094d6,8,4,1,25877,,,0,"Add deploy_steps_tasks to PER_TASK_STEPS

deploy_steps_tasks will now be written out in per step files in the
config download directory. This will allow including the task files for
a specific step only at that step, and saving time by not having to skip
so many tasks.

Change-Id: Id5fdb4dd1a6290d1097d2d81523161c87ab6d4dd
(cherry picked from commit 03fe9dfc3d5ae8952078891bc34e44a6d2426d20)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/29/700029/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/constants.py'],1,cf5b602450a1cd0f48c86436b6632718470094d6,,"PER_STEP_TASKS = ['upgrade_tasks', 'deploy_steps_tasks']",PER_STEP_TASKS = ['upgrade_tasks'],1,1
openstack%2Ftripleo-common~stable%2Ftrain~Ie03084bb599b7b06aeeb321d2a7938a908487788,openstack/tripleo-common,stable/train,Ie03084bb599b7b06aeeb321d2a7938a908487788,config: refactor how per step tasks are generated,MERGED,2019-12-19 16:58:08.000000000,2019-12-23 21:06:25.000000000,2019-12-23 21:05:04.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-12-19 16:58:08.000000000', 'files': ['tripleo_common/constants.py', 'tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ccfa1ad1949f1473d41a218cfa3ed85d95f471ce', 'message': 'config: refactor how per step tasks are generated\n\nThe per step tasks generation was introduced by:\nI4d864f374d6f840585fafef2c7678e55c154898e\n\nThis patch is refactoring a little bit so we can easily re-use that\ninterface for the other tasks.\nIt introduces a new constant: PER_STEP_TASKS\nIt\'s a list of tasks that are ""per step"" ready.\n\nNote about the \'else\' in tripleo_common/utils/config.py :\nOnce all tasks are adapted in THT to run per step, we will be able to move this\ncondition to the upper level\nWe include it here to allow the CI to pass until THT changed is not merged.\n\nChange-Id: Ie03084bb599b7b06aeeb321d2a7938a908487788\n(cherry picked from commit d9c82d8c79c33f261e4335f2ffa09bd4e44fd719)\n'}]",0,700028,ccfa1ad1949f1473d41a218cfa3ed85d95f471ce,12,5,1,25877,,,0,"config: refactor how per step tasks are generated

The per step tasks generation was introduced by:
I4d864f374d6f840585fafef2c7678e55c154898e

This patch is refactoring a little bit so we can easily re-use that
interface for the other tasks.
It introduces a new constant: PER_STEP_TASKS
It's a list of tasks that are ""per step"" ready.

Note about the 'else' in tripleo_common/utils/config.py :
Once all tasks are adapted in THT to run per step, we will be able to move this
condition to the upper level
We include it here to allow the CI to pass until THT changed is not merged.

Change-Id: Ie03084bb599b7b06aeeb321d2a7938a908487788
(cherry picked from commit d9c82d8c79c33f261e4335f2ffa09bd4e44fd719)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/28/700028/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/constants.py', 'tripleo_common/utils/config.py']",2,ccfa1ad1949f1473d41a218cfa3ed85d95f471ce,, # NOTE(emilien): Move this condition to the # upper level once THT is adapted for all tasks to be # run per step. # We include it here to allow the CI to pass until THT # changed is not merged. if config in constants.PER_STEP_TASKS: for i in range(constants.DEFAULT_STEPS_MAX):, # NOTE(jfrancoa): Move this upgrade_tasks condition to the # upper level once THT is adapted. We include it here to # allow the CI to pass until THT changed is not merged. if config == 'upgrade_tasks': for i in range(constants.UPGRADE_STEPS_MAX):,11,6
openstack%2Fos-service-types~master~I23a99b977286921d6163174de830e59c19162c01,openstack/os-service-types,master,I23a99b977286921d6163174de830e59c19162c01,Update the constraints url,MERGED,2019-09-29 02:26:02.000000000,2019-12-23 21:04:48.000000000,2019-12-23 21:03:34.000000000,"[{'_account_id': 8482}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-29 02:26:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/248052ad65353ec6b932acba496e83cbe8213368', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I23a99b977286921d6163174de830e59c19162c01\n'}]",0,685556,248052ad65353ec6b932acba496e83cbe8213368,8,3,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I23a99b977286921d6163174de830e59c19162c01
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/56/685556/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,248052ad65353ec6b932acba496e83cbe8213368,constraints, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
openstack%2Fos-service-types~master~I84d8c93c1f3e193a5de107cd3d8cc50fbf869276,openstack/os-service-types,master,I84d8c93c1f3e193a5de107cd3d8cc50fbf869276,Blacklist sphinx 2.1.0 (autodoc bug),MERGED,2019-10-10 06:39:14.000000000,2019-12-23 20:56:08.000000000,2019-12-23 20:53:43.000000000,"[{'_account_id': 8482}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-10 06:39:14.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/67eea4b7bde1522eba22815e7affa46af4e6acf9', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nSee https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details\n\nChange-Id: I84d8c93c1f3e193a5de107cd3d8cc50fbf869276\n'}]",0,687795,67eea4b7bde1522eba22815e7affa46af4e6acf9,8,3,1,27822,,,0,"Blacklist sphinx 2.1.0 (autodoc bug)

See https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details

Change-Id: I84d8c93c1f3e193a5de107cd3d8cc50fbf869276
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/95/687795/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,67eea4b7bde1522eba22815e7affa46af4e6acf9,sphinx,"sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD","sphinx!=1.6.6,!=1.6.7,>=1.6.2;python_version>='3.4' # BSD",1,1
openstack%2Fos-service-types~master~I34b5d91bb5eea3680d915a262bee4a24e2ae2752,openstack/os-service-types,master,I34b5d91bb5eea3680d915a262bee4a24e2ae2752,Bump the openstackdocstheme extension to 1.20,MERGED,2019-10-12 07:19:07.000000000,2019-12-23 20:54:58.000000000,2019-12-23 20:53:43.000000000,"[{'_account_id': 8482}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 17130}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 07:19:07.000000000', 'files': ['test-requirements.txt', 'doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/os-service-types/commit/aa373c592f4b14ffa0db00553a4b2d233c89f784', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I34b5d91bb5eea3680d915a262bee4a24e2ae2752\n'}]",0,688250,aa373c592f4b14ffa0db00553a4b2d233c89f784,11,5,1,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: I34b5d91bb5eea3680d915a262bee4a24e2ae2752
",git fetch https://review.opendev.org/openstack/os-service-types refs/changes/50/688250/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/conf.py', 'releasenotes/source/conf.py']",3,aa373c592f4b14ffa0db00553a4b2d233c89f784,openstackdocstheme,,"project = u'os-service-types Release Notes'html_last_updated_fmt = '%Y-%m-%d %H:%M'latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } ",1,15
openstack%2Ftripleo-validations~stable%2Ftrain~Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,openstack/tripleo-validations,stable/train,Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5,Add an additional validation to check ceph-ansible repository,MERGED,2019-12-20 09:54:47.000000000,2019-12-23 20:51:26.000000000,2019-12-23 20:51:26.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7353}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-20 09:54:47.000000000', 'files': ['playbooks/ceph-ansible-installed.yaml', 'roles/ceph/tasks/ceph-ansible-installed.yaml', 'roles/ceph/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/7f9f738668b0ac03036e01c5f5b5100bfe2e799a', 'message': ""Add an additional validation to check ceph-ansible repository\n\nIn order to address the ceph-ansible potential cross-shipping,\nthis change adds an extra task to validate the repository that\nshould be used to install ceph-ansible in the undercloud.\nIf ceph-ansible is not installed or the repo doesn't match the\nspecified one, this validation raise an error.\n\nChange-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5\n(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)\n""}]",0,700135,7f9f738668b0ac03036e01c5f5b5100bfe2e799a,9,9,1,25402,,,0,"Add an additional validation to check ceph-ansible repository

In order to address the ceph-ansible potential cross-shipping,
this change adds an extra task to validate the repository that
should be used to install ceph-ansible in the undercloud.
If ceph-ansible is not installed or the repo doesn't match the
specified one, this validation raise an error.

Change-Id: Ib80b55cbd0d4b4dd83d8dbc9dc2afe1d6df2ede5
(cherry picked from commit 329f740d109b87105eac36fade70c69c15781a38)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/35/700135/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/ceph-ansible-installed.yaml', 'roles/ceph/tasks/ceph-ansible-installed.yaml', 'roles/ceph/defaults/main.yml']",3,7f9f738668b0ac03036e01c5f5b5100bfe2e799a,ceph_ansible_repo,"ceph_ansible_repo: ""centos-ceph-nautilus""",,15,0
openstack%2Fpuppet-pacemaker~master~I43e07a8fc46b915c570ecae61b0bc443e1bf9664,openstack/puppet-pacemaker,master,I43e07a8fc46b915c570ecae61b0bc443e1bf9664,Allow to disable the scaleup logic via a parameter,MERGED,2019-12-20 18:42:48.000000000,2019-12-23 20:37:00.000000000,2019-12-23 20:37:00.000000000,"[{'_account_id': 8297}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 18:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/eb3dd82d022f347f781b9cb1ddf53e20601af342', 'message': ""Allow to disable the scaleup logic via a parameter\n\nIt's probably safest to be able to quickly disable\nthe scaleup logic via a parameter in case it would trigger\nat a moment where we do not want it/expect it.\n\nChange-Id: I43e07a8fc46b915c570ecae61b0bc443e1bf9664\n""}, {'number': 2, 'created': '2019-12-23 08:18:18.000000000', 'files': ['manifests/corosync.pp'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/d118e0b9950f0e6b945aa2595c06ab189583b83e', 'message': ""Allow to disable the scaleup logic via a parameter\n\nIt's probably safest to be able to quickly disable\nthe scaleup logic via a parameter in case it would trigger\nat a moment where we do not want it/expect it.\n\nChange-Id: I43e07a8fc46b915c570ecae61b0bc443e1bf9664\n""}]",0,700223,d118e0b9950f0e6b945aa2595c06ab189583b83e,14,5,2,20172,,,0,"Allow to disable the scaleup logic via a parameter

It's probably safest to be able to quickly disable
the scaleup logic via a parameter in case it would trigger
at a moment where we do not want it/expect it.

Change-Id: I43e07a8fc46b915c570ecae61b0bc443e1bf9664
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/23/700223/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/corosync.pp'],1,eb3dd82d022f347f781b9cb1ddf53e20601af342,,"# [*disable_scaleup*] # (optional) Disables the scaleup logic of the cluster nodes (i.e. we do not add a # node via pcs if we detect a new node compared to the existing cluster) # Defaults to false # $disable_scaleup = false, if ! $disable_scaleup { # If we're rerunning this puppet manifest and $cluster_members # contains more nodes than the currently running cluster if count($nodes_added) > 0 { $nodes_added.each |$node_to_add| { $node_name = split($node_to_add, ' ')[0] if $::pacemaker::pcs_010 { exec {""Authenticating new cluster node: ${node_to_add}"": command => ""${::pacemaker::pcs_bin} host auth ${node_name} -u hacluster -p ${::pacemaker::hacluster_pwd}"", timeout => $cluster_start_timeout, tries => $cluster_start_tries, try_sleep => $cluster_start_try_sleep, require => [Service['pcsd'], User['hacluster']], tag => 'pacemaker-auth', } } exec {""Adding Cluster node: ${node_to_add} to Cluster ${cluster_name}"": unless => ""${::pacemaker::pcs_bin} status 2>&1 | grep -e \""^Online:.* ${node_name} .*\"""", command => ""${::pacemaker::pcs_bin} cluster node add ${node_to_add} ${node_add_start_part} --wait"", notify => Exec[""node-cluster-start-${node_name}""], tag => 'pacemaker-scaleup', } exec {""node-cluster-start-${node_name}"": unless => ""${::pacemaker::pcs_bin} status 2>&1 | grep -e \""^Online:.* ${node_name} .*\"""", command => ""${::pacemaker::pcs_bin} cluster start ${node_name} --wait"", timeout => $cluster_start_timeout, tries => $cluster_start_tries, try_sleep => $cluster_start_try_sleep, refreshonly => true, tag => 'pacemaker-scaleup', } } Exec <|tag == 'pacemaker-auth'|> -> Exec <|tag == 'pacemaker-scaleup'|> }"," # If we're rerunning this puppet manifest and $cluster_members # contains more nodes than the currently running cluster if count($nodes_added) > 0 { $nodes_added.each |$node_to_add| { $node_name = split($node_to_add, ' ')[0] if $::pacemaker::pcs_010 { exec {""Authenticating new cluster node: ${node_to_add}"": command => ""${::pacemaker::pcs_bin} host auth ${node_name} -u hacluster -p ${::pacemaker::hacluster_pwd}"", require => [Service['pcsd'], User['hacluster']], tag => 'pacemaker-auth', } } exec {""Adding Cluster node: ${node_to_add} to Cluster ${cluster_name}"": unless => ""${::pacemaker::pcs_bin} status 2>&1 | grep -e \""^Online:.* ${node_name} .*\"""", command => ""${::pacemaker::pcs_bin} cluster node add ${node_to_add} ${node_add_start_part} --wait"", timeout => $cluster_start_timeout, tries => $cluster_start_tries, try_sleep => $cluster_start_try_sleep, notify => Exec[""node-cluster-start-${node_name}""], tag => 'pacemaker-scaleup', } exec {""node-cluster-start-${node_name}"": unless => ""${::pacemaker::pcs_bin} status 2>&1 | grep -e \""^Online:.* ${node_name} .*\"""", command => ""${::pacemaker::pcs_bin} cluster start ${node_name} --wait"", timeout => $cluster_start_timeout, tries => $cluster_start_tries, try_sleep => $cluster_start_try_sleep, refreshonly => true, tag => 'pacemaker-scaleup', } } Exec <|tag == 'pacemaker-auth'|> -> Exec <|tag == 'pacemaker-scaleup'|>",37,29
openstack%2Ftripleo-heat-templates~master~I660d70e6007adb9093499189f5f81cd690d7c546,openstack/tripleo-heat-templates,master,I660d70e6007adb9093499189f5f81cd690d7c546,DNM Test,ABANDONED,2019-12-23 11:39:02.000000000,2019-12-23 20:24:03.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 11:39:02.000000000', 'files': ['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c6ab3538cd3db46d19bb67a548bf36d711ee76ee', 'message': 'DNM Test\n\nDepends-On: I43e07a8fc46b915c570ecae61b0bc443e1bf9664\nChange-Id: I660d70e6007adb9093499189f5f81cd690d7c546\n'}]",0,700425,c6ab3538cd3db46d19bb67a548bf36d711ee76ee,4,2,1,20172,,,0,"DNM Test

Depends-On: I43e07a8fc46b915c570ecae61b0bc443e1bf9664
Change-Id: I660d70e6007adb9093499189f5f81cd690d7c546
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/700425/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/pacemaker/pacemaker-baremetal-puppet.yaml'],1,c6ab3538cd3db46d19bb67a548bf36d711ee76ee,dnm, foo,,1,0
openstack%2Fkolla-ansible~master~Ifc3fc4103ff643a4e72104f89bb0ce791c239f71,openstack/kolla-ansible,master,Ifc3fc4103ff643a4e72104f89bb0ce791c239f71,genpwd: Refactor to reduce cyclomatic complexity,ABANDONED,2019-03-10 21:52:52.000000000,2019-12-23 20:23:33.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23942}, {'_account_id': 26008}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-03-10 21:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3cc35fae427f9dd64860889b8e7b6f58624c378f', 'message': 'genpwd: Refactor to reduce cyclomatic complexity\n\nBefore refactoring:\n radon cc -s kolla_ansible/cmd/genpwd.py\n kolla_ansible/cmd/genpwd.py\n    F 57:0 genpwd - C (13)\n    F 39:0 generate_RSA - A (1)\n    F 94:0 main - A (1)\n\nAfter refactoring:\n radon cc -s kolla_ansible/cmd/genpwd.py\n kolla_ansible/cmd/genpwd.py\n    F 149:0 genpwd - A (3)\n    M 54:4 SecretGenerator.get_by_key_name - A (3)\n    C 67:0 SecretGeneratorRegular - A (3)\n    C 77:0 SecretGeneratorRsa - A (3)\n    M 102:4 SecretGeneratorRsa.skip - A (3)\n    C 41:0 SecretGenerator - A (2)\n    M 70:4 SecretGeneratorRegular.generate - A (2)\n    C 110:0 SecretGeneratorHmac - A (2)\n    C 124:0 SecretGeneratorUuid - A (2)\n    C 140:0 SecretGeneratorFernet - A (2)\n    F 158:0 genpwd_file - A (1)\n    F 168:0 main - A (1)\n    M 43:4 SecretGenerator.keys - A (1)\n    M 47:4 SecretGenerator.generate - A (1)\n    M 51:4 SecretGenerator.skip - A (1)\n    M 85:4 SecretGeneratorRsa.generate - A (1)\n    M 116:4 SecretGeneratorHmac.generate - A (1)\n    M 136:4 SecretGeneratorUuid.generate - A (1)\n    M 145:4 SecretGeneratorFernet.generate - A (1)\n\nCalculated using radon==3.0.1\n\nChange-Id: Ifc3fc4103ff643a4e72104f89bb0ce791c239f71\nSigned-off-by: Maciej Kucia <maciej@kucia.net>\n'}, {'number': 2, 'created': '2019-10-27 20:23:03.000000000', 'files': ['kolla_ansible/cmd/genpwd.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8620626a8e44b0906da598d1cf00492870a76bf1', 'message': 'genpwd: Refactor to reduce cyclomatic complexity\n\nBefore refactoring:\n radon cc -s kolla_ansible/cmd/genpwd.py\n kolla_ansible/cmd/genpwd.py\n    F 57:0 genpwd - C (13)\n    F 39:0 generate_RSA - A (1)\n    F 94:0 main - A (1)\n\nAfter refactoring:\n radon cc -s kolla_ansible/cmd/genpwd.py\n kolla_ansible/cmd/genpwd.py\n    F 149:0 genpwd - A (3)\n    M 54:4 SecretGenerator.get_by_key_name - A (3)\n    C 67:0 SecretGeneratorRegular - A (3)\n    C 77:0 SecretGeneratorRsa - A (3)\n    M 102:4 SecretGeneratorRsa.skip - A (3)\n    C 41:0 SecretGenerator - A (2)\n    M 70:4 SecretGeneratorRegular.generate - A (2)\n    C 110:0 SecretGeneratorHmac - A (2)\n    C 124:0 SecretGeneratorUuid - A (2)\n    C 140:0 SecretGeneratorFernet - A (2)\n    F 158:0 genpwd_file - A (1)\n    F 168:0 main - A (1)\n    M 43:4 SecretGenerator.keys - A (1)\n    M 47:4 SecretGenerator.generate - A (1)\n    M 51:4 SecretGenerator.skip - A (1)\n    M 85:4 SecretGeneratorRsa.generate - A (1)\n    M 116:4 SecretGeneratorHmac.generate - A (1)\n    M 136:4 SecretGeneratorUuid.generate - A (1)\n    M 145:4 SecretGeneratorFernet.generate - A (1)\n\nCalculated using radon==3.0.1\n\nChange-Id: Ifc3fc4103ff643a4e72104f89bb0ce791c239f71\nSigned-off-by: Maciej Kucia <maciej@kucia.net>\n'}]",1,642296,8620626a8e44b0906da598d1cf00492870a76bf1,12,5,2,23942,,,0,"genpwd: Refactor to reduce cyclomatic complexity

Before refactoring:
 radon cc -s kolla_ansible/cmd/genpwd.py
 kolla_ansible/cmd/genpwd.py
    F 57:0 genpwd - C (13)
    F 39:0 generate_RSA - A (1)
    F 94:0 main - A (1)

After refactoring:
 radon cc -s kolla_ansible/cmd/genpwd.py
 kolla_ansible/cmd/genpwd.py
    F 149:0 genpwd - A (3)
    M 54:4 SecretGenerator.get_by_key_name - A (3)
    C 67:0 SecretGeneratorRegular - A (3)
    C 77:0 SecretGeneratorRsa - A (3)
    M 102:4 SecretGeneratorRsa.skip - A (3)
    C 41:0 SecretGenerator - A (2)
    M 70:4 SecretGeneratorRegular.generate - A (2)
    C 110:0 SecretGeneratorHmac - A (2)
    C 124:0 SecretGeneratorUuid - A (2)
    C 140:0 SecretGeneratorFernet - A (2)
    F 158:0 genpwd_file - A (1)
    F 168:0 main - A (1)
    M 43:4 SecretGenerator.keys - A (1)
    M 47:4 SecretGenerator.generate - A (1)
    M 51:4 SecretGenerator.skip - A (1)
    M 85:4 SecretGeneratorRsa.generate - A (1)
    M 116:4 SecretGeneratorHmac.generate - A (1)
    M 136:4 SecretGeneratorUuid.generate - A (1)
    M 145:4 SecretGeneratorFernet.generate - A (1)

Calculated using radon==3.0.1

Change-Id: Ifc3fc4103ff643a4e72104f89bb0ce791c239f71
Signed-off-by: Maciej Kucia <maciej@kucia.net>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/96/642296/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla_ansible/cmd/genpwd.py'],1,3cc35fae427f9dd64860889b8e7b6f58624c378f,,"import abcimport six@six.add_metaclass(abc.ABCMeta) class SecretGenerator(object): @abc.abstractproperty def keys(self): raise NotImplemented() @abc.abstractmethod def generate(self): raise NotImplemented() def skip(self, field): return field is not None @classmethod def get_by_key_name(cls, ansible_variable_key): for generator in ( SecretGeneratorRsa, SecretGeneratorHmac, SecretGeneratorUuid, SecretGeneratorFernet, ): if ansible_variable_key in generator.keys: return generator() return SecretGeneratorRegular() class SecretGeneratorRegular(SecretGenerator): keys = None def generate(self, length=40): choices = string.ascii_letters + string.digits return ''.join( [random.SystemRandom().choice(choices) for _ in range(length)] ) class SecretGeneratorRsa(SecretGenerator): keys = [ 'bifrost_ssh_key', 'keystone_ssh_key', 'kolla_ssh_key', 'nova_ssh_key', ] def generate(self, bits=4096): new_key = rsa.generate_private_key( public_exponent=65537, key_size=bits, backend=default_backend() ) private_key = new_key.private_bytes( encoding=serialization.Encoding.PEM, format=serialization.PrivateFormat.PKCS8, encryption_algorithm=serialization.NoEncryption() ).decode() public_key = new_key.public_key().public_bytes( encoding=serialization.Encoding.OpenSSH, format=serialization.PublicFormat.OpenSSH ).decode() return {'private_key': private_key, 'public_key': public_key} def skip(self, field): no_keys_at_all = not field one_of_keys_empty = any( field.get(x) is None for x in ('private_key', 'public_key') ) return not (no_keys_at_all or one_of_keys_empty) class SecretGeneratorHmac(SecretGenerator): keys = [ 'designate_rndc_key', 'osprofiler_secret', ] def generate(self): return hmac.new( uuidutils.generate_uuid().encode(), ''.encode(), md5 ).hexdigest() class SecretGeneratorUuid(SecretGenerator): keys = [ 'ceph_cluster_fsid', 'cinder_rbd_secret_uuid', 'designate_pool_id', 'gnocchi_project_id', 'gnocchi_resource_id', 'gnocchi_user_id', 'karbor_openstack_infra_id', 'rbd_secret_uuid', ] def generate(self): return uuidutils.generate_uuid class SecretGeneratorFernet(SecretGenerator): keys = [ 'barbican_crypto_key', ] def generate(self): return fernet.Fernet.generate_key def genpwd(passwords, generator=SecretGenerator): for ansible_variable_key, password in passwords.items(): gen = generator.get_by_key_name(ansible_variable_key) if not gen.skip(password): passwords[ansible_variable_key] = gen.generate() else: print('Skipping {}'.format(ansible_variable_key)) def genpwd_file(passwords_file, generator=SecretGenerator): genpwd(passwords, generator) genpwd_file(passwords_file, SecretGenerator)","def generate_RSA(bits=4096): new_key = rsa.generate_private_key( public_exponent=65537, key_size=bits, backend=default_backend() ) private_key = new_key.private_bytes( encoding=serialization.Encoding.PEM, format=serialization.PrivateFormat.PKCS8, encryption_algorithm=serialization.NoEncryption() ).decode() public_key = new_key.public_key().public_bytes( encoding=serialization.Encoding.OpenSSH, format=serialization.PublicFormat.OpenSSH ).decode() return private_key, public_key def genpwd(passwords_file, length, uuid_keys, ssh_keys, blank_keys, fernet_keys, hmac_md5_keys): for k, v in passwords.items(): if (k in ssh_keys and (v is None or v.get('public_key') is None and v.get('private_key') is None)): private_key, public_key = generate_RSA() passwords[k] = { 'private_key': private_key, 'public_key': public_key } continue if v is None: if k in blank_keys and v is None: continue if k in uuid_keys: passwords[k] = uuidutils.generate_uuid() elif k in hmac_md5_keys: passwords[k] = (hmac.new( uuidutils.generate_uuid().encode(), ''.encode(), md5) .hexdigest()) elif k in fernet_keys: passwords[k] = fernet.Fernet.generate_key() else: passwords[k] = ''.join([ random.SystemRandom().choice( string.ascii_letters + string.digits) for n in range(length) ]) # These keys should be random uuids uuid_keys = ['ceph_cluster_fsid', 'rbd_secret_uuid', 'cinder_rbd_secret_uuid', 'gnocchi_project_id', 'gnocchi_resource_id', 'gnocchi_user_id', 'designate_pool_id', 'karbor_openstack_infra_id'] # SSH key pair ssh_keys = ['kolla_ssh_key', 'nova_ssh_key', 'keystone_ssh_key', 'bifrost_ssh_key'] # If these keys are None, leave them as None blank_keys = ['docker_registry_password'] # HMAC-MD5 keys hmac_md5_keys = ['designate_rndc_key', 'osprofiler_secret'] # Fernet keys fernet_keys = ['barbican_crypto_key'] # length of password length = 40 genpwd(passwords_file, length, uuid_keys, ssh_keys, blank_keys, fernet_keys, hmac_md5_keys)",120,76
openstack%2Fproject-config~master~I0d28c6405ebf5209a5818c39d9d055c50086a329,openstack/project-config,master,I0d28c6405ebf5209a5818c39d9d055c50086a329,Finish retiring shotgun,MERGED,2019-12-20 20:43:24.000000000,2019-12-23 20:19:38.000000000,2019-12-23 20:19:38.000000000,"[{'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:43:24.000000000', 'files': ['zuul.d/projects.yaml', 'zuul/main.yaml', 'gerrit/acls/openstack/shotgun.config', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/042a8e02d05a9e6983e8e90ffddafbd3624892ae', 'message': 'Finish retiring shotgun\n\nRemove openstack/shotgun from infrastructure as final step in\nretirement.\n\nDepends-On: https://review.opendev.org/700243\nChange-Id: I0d28c6405ebf5209a5818c39d9d055c50086a329\n'}]",0,700244,042a8e02d05a9e6983e8e90ffddafbd3624892ae,8,4,1,6547,,,0,"Finish retiring shotgun

Remove openstack/shotgun from infrastructure as final step in
retirement.

Depends-On: https://review.opendev.org/700243
Change-Id: I0d28c6405ebf5209a5818c39d9d055c50086a329
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/700244/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/shotgun.config', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml']",4,042a8e02d05a9e6983e8e90ffddafbd3624892ae,retire-fuel,, - openstack/shotgun,2,22
openstack%2Fshotgun~master~I02c43446ad3d94e77008e67ff5bae3b000c9911b,openstack/shotgun,master,I02c43446ad3d94e77008e67ff5bae3b000c9911b,Retire repository,MERGED,2019-12-20 20:40:14.000000000,2019-12-23 20:10:51.000000000,2019-12-23 20:10:51.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:40:14.000000000', 'files': ['.gitignore', 'shotgun/config.py', 'test-requirements.txt', 'shotgun/test/base.py', 'README.rst', 'bin/example.py', 'setup.py', 'shotgun/test/test_driver.py', 'shotgun/settings.py', 'shotgun/__init__.py', 'shotgun/manager.py', 'etc/report.yaml', 'CONTRIBUTING.rst', 'requirements.txt', 'shotgun/hooks.py', 'shotgun/test/__init__.py', 'shotgun/logger.py', 'etc/short_report.yaml', 'shotgun/cli2.py', '.coveragerc', 'LICENSE', 'bin/example.json', 'shotgun/test/test_manager.py', 'shotgun/test/test_config.py', 'shotgun/driver.py', 'MANIFEST.in', 'shotgun/utils.py', 'shotgun/cli.py', 'MAINTAINERS', '.testr.conf', 'shotgun/test/test_utils.py', 'setup.cfg', 'tox.ini', 'HACKING.rst', 'specs/shotgun.spec'], 'web_link': 'https://opendev.org/openstack/shotgun/commit/dd8f76963182a7c1b2c22064e5d2d42e519f3ee5', 'message': 'Retire repository\n\nFuel repositories are all retired in openstack namespace, retire\nremaining fuel repos in x namespace since they are unused now.\n\nThis change removes all content from the repository and adds the usual\nREADME file to point out that the repository is retired following the\nprocess from\nhttps://docs.openstack.org/infra/manual/drivers.html#retiring-a-project\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-discuss/2019-December/011675.html\n\nA related change is: https://review.opendev.org/699752 .\n\nChange-Id: I02c43446ad3d94e77008e67ff5bae3b000c9911b\n'}]",0,700243,dd8f76963182a7c1b2c22064e5d2d42e519f3ee5,8,2,1,6547,,,0,"Retire repository

Fuel repositories are all retired in openstack namespace, retire
remaining fuel repos in x namespace since they are unused now.

This change removes all content from the repository and adds the usual
README file to point out that the repository is retired following the
process from
https://docs.openstack.org/infra/manual/drivers.html#retiring-a-project

See also
http://lists.openstack.org/pipermail/openstack-discuss/2019-December/011675.html

A related change is: https://review.opendev.org/699752 .

Change-Id: I02c43446ad3d94e77008e67ff5bae3b000c9911b
",git fetch https://review.opendev.org/openstack/shotgun refs/changes/43/700243/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'shotgun/config.py', 'test-requirements.txt', 'shotgun/test/base.py', 'README.rst', 'bin/example.py', 'setup.py', 'shotgun/test/test_driver.py', 'shotgun/settings.py', 'shotgun/__init__.py', 'shotgun/manager.py', 'etc/report.yaml', 'CONTRIBUTING.rst', 'requirements.txt', 'shotgun/hooks.py', 'shotgun/test/__init__.py', 'shotgun/logger.py', 'etc/short_report.yaml', 'shotgun/cli2.py', '.coveragerc', 'LICENSE', 'bin/example.json', 'shotgun/test/test_manager.py', 'shotgun/test/test_config.py', 'shotgun/driver.py', 'MANIFEST.in', 'shotgun/utils.py', 'shotgun/cli.py', 'MAINTAINERS', '.testr.conf', 'shotgun/test/test_utils.py', 'setup.cfg', 'tox.ini', 'HACKING.rst', 'specs/shotgun.spec']",35,dd8f76963182a7c1b2c22064e5d2d42e519f3ee5,retire-x-fuel,,"%define name shotgun %{!?version: %define version 10.0.0} %{!?release: %define release 1} Name: %{name} Summary: Shotgun package Version: %{version} Release: %{release} Source0: %{name}-%{version}.tar.gz URL: http://mirantis.com License: Apache Group: Development/Libraries BuildRoot: %{_tmppath}/%{name}-%{version}-buildroot Prefix: %{_prefix} BuildRequires: python-setuptools BuildRequires: python-pbr >= 1.8 Requires: postgresql Requires: python-cliff >= 1.7.0 Requires: python-fabric >= 1.10.0 Requires: python-argparse Requires: python-six >= 1.9.0 Requires: tar Requires: gzip Requires: bzip2 Requires: openssh-clients Requires: xz BuildArch: noarch %description Shotgun package. %prep %setup -cq -n %{name}-%{version} %build cd %{_builddir}/%{name}-%{version} && python setup.py build %install cd %{_builddir}/%{name}-%{version} && python setup.py install --single-version-externally-managed -O1 --root=$RPM_BUILD_ROOT --record=%{_builddir}/%{name}-%{version}/INSTALLED_FILES install -d -m 755 %{buildroot}%{_sysconfdir}/shotgun install -p -D -m 644 %{_builddir}/%{name}-%{version}/etc/report.yaml %{buildroot}%{_sysconfdir}/shotgun/report.yaml install -p -D -m 644 %{_builddir}/%{name}-%{version}/etc/short_report.yaml %{buildroot}%{_sysconfdir}/shotgun/short_report.yaml %clean rm -rf $RPM_BUILD_ROOT %files -f %{_builddir}/%{name}-%{version}/INSTALLED_FILES %defattr(-,root,root) %{_sysconfdir}/shotgun/report.yaml %{_sysconfdir}/shotgun/short_report.yaml ",8,2540
openstack%2Fnova~stable%2Ftrain~I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,openstack/nova,stable/train,I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,FUP for in-place numa rebuild,MERGED,2019-12-20 09:42:43.000000000,2019-12-23 19:32:32.000000000,2019-12-23 19:28:17.000000000,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-20 09:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae5a2fe1c711fdf94404743af3bcac20f8b3c9c1', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n'}, {'number': 2, 'created': '2019-12-20 12:09:06.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/48bb9a9663374936221144bb6a24688128a51146', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n'}]",0,700127,48bb9a9663374936221144bb6a24688128a51146,38,9,2,15334,,,0,"FUP for in-place numa rebuild

This patch addresses a number of typos and minor
issues raised during review of [1][2]. A summary
of the changes are corrections to typos in comments,
a correction to the exception message, an update to
the release note and the addition of debug logging.

[1] I0322d872bdff68936033a6f5a54e8296a6fb3434
[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132

Related-Bug: #1804502
Related-Bug: #1763766

Change-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b
(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/700127/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py']",6,ae5a2fe1c711fdf94404743af3bcac20f8b3c9c1,bug/1763766," return # if only one of the constraints are non-None (or 'set') then the action = ""removing"" if old_constraints else ""introducing"" LOG.debug(""NUMA rebuild validation failed. The requested image "" ""would alter the NUMA constraints by %s a NUMA "" ""topology."", action, instance=instance) # otherwise since both the old a new constraints are non none compare LOG.debug(""NUMA rebuild validation failed. The requested image "" ""conflicts with the existing NUMA constraints."", instance=instance)", :returns: True or raises on failure. # return true for easy unit testing return True # if only one of the constrains are non-None (or 'set') then the # otherwise since both the old a new constrains are non none compare # return true for easy unit testing return True ,41,36
openstack%2Fnova~stable%2Ftrain~I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,openstack/nova,stable/train,I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,Disable NUMATopologyFilter on rebuild,MERGED,2019-12-11 16:40:54.000000000,2019-12-23 19:30:52.000000000,2019-12-23 19:28:12.000000000,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-11 16:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8759c330c7893fb2ba94b7f5c5ac5b629f572d7', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n'}, {'number': 2, 'created': '2019-12-16 09:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/067750ca10032a5e76babb5c619d5a388d320aab', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n'}, {'number': 3, 'created': '2019-12-19 16:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e45a283e03fba10f16cc4bc234fac43a520cb46', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n'}, {'number': 4, 'created': '2019-12-19 16:47:53.000000000', 'files': ['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/94c0362918169a1fa06aa6cf5a483e9285d7b91f', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n'}]",2,698532,94c0362918169a1fa06aa6cf5a483e9285d7b91f,75,9,4,11604,,,0,"Disable NUMATopologyFilter on rebuild

This change leverages the new NUMA constraint checking added in
in I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the
NUMATopologyFilter to be skipped on rebuild.

As the new behavior of rebuild enfroces that no changes
to the numa constraints are allowed on rebuild we no longer
need to execute the NUMATopologyFilter. Previously
the NUMATopologyFilter would process the rebuild request
as if it was a request to spawn a new instnace as the
numa_fit_instance_to_host function is not rebuild aware.

As such prior to this change a rebuild would only succeed
if a host had enough additional capacity for a second instance
on the same host meeting the requirement of the new image and
existing flavor. This behavior was incorrect on two counts as
a rebuild uses a noop claim. First the resouce usage cannot
change so it was incorrect to require the addtional capacity
to rebuild an instance. Secondly it was incorrect not to assert
the resouce usage remained the same.

I0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the
rebuild against altering the resouce usage and this change
allows in place rebuild.

This change found a latent bug that will be adressed in a follow
up change and updated the functional tests to note the incorrect
behavior.

Change-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132
Closes-Bug: #1804502
Implements: blueprint inplace-rebuild-of-numa-instances
(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/698532/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py']",3,b8759c330c7893fb2ba94b7f5c5ac5b629f572d7,bug/1763766,"from testtools import skip # FIXME(sean-k-mooney): The logic of this test is incorrect. # The test was written to assert that we failed to rebuild # because the NUMA constraints were violated due to the attachment # of an interface from a second host NUMA node to an instance with # a NUMA topology of 1 that is affined to a different NUMA node. # Nova should reject the interface attachment if the NUMA constraints # would be violated and it should fail at that point not when the # instance is rebuilt. This is a latent bug which will be addressed # in a separate patch. @skip(""bug 1855332"") def test_attach_interface_with_network_affinity_violation(self): # FIXME(sean-k-mooney): This should raise an exception as this # interface attachment would violate the NUMA constraints. # NOTE(sean-k-mooney): the rest of the test is incorrect but # is left to show the currently broken behavior. # This should succeed as the numa constraints do not change. self._rebuild_server(server, self.image_ref_1)"," def test_rebuild_server_with_network_affinity(self): # TODO(sean-k-mooney): this should pass but i currently expect it to # fail because the NUMA topology filter does not support in place # rebuild and we have used all the resources on the compute node. self.assertRaises( client.OpenStackApiException, self._rebuild_server, server, self.image_ref_1)",37,9
openstack%2Fkeystonemiddleware~master~I4a5f9f48ae099291cf47f4d08c40535223761b1b,openstack/keystonemiddleware,master,I4a5f9f48ae099291cf47f4d08c40535223761b1b,Imported Translations from Zanata,MERGED,2019-12-22 07:08:58.000000000,2019-12-23 19:24:10.000000000,2019-12-23 19:22:32.000000000,"[{'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-22 07:08:58.000000000', 'files': ['keystonemiddleware/locale/en_GB/LC_MESSAGES/keystonemiddleware.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'keystonemiddleware/locale/ko_KR/LC_MESSAGES/keystonemiddleware.po'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/62c3eaf0939306b1ff17f0a045b42f86a3db5d8c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4a5f9f48ae099291cf47f4d08c40535223761b1b\n'}]",0,700304,62c3eaf0939306b1ff17f0a045b42f86a3db5d8c,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4a5f9f48ae099291cf47f4d08c40535223761b1b
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/04/700304/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/locale/en_GB/LC_MESSAGES/keystonemiddleware.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'keystonemiddleware/locale/ko_KR/LC_MESSAGES/keystonemiddleware.po']",3,62c3eaf0939306b1ff17f0a045b42f86a3db5d8c,zanata/translations,"""POT-Creation-Date: 2019-12-21 02:49+0000\n""","""POT-Creation-Date: 2018-02-20 19:27+0000\n""#, python-format msgid ""Failed to fetch token revocation list: %d"" msgstr "" revocation    : %d"" ",213,24
openstack%2Fproject-config~master~I5ab1dca48eba6d41273938f78a1072c810563f84,openstack/project-config,master,I5ab1dca48eba6d41273938f78a1072c810563f84,Add horizon-core to masakari-dashboard,MERGED,2019-12-10 05:51:01.000000000,2019-12-23 19:12:15.000000000,2019-12-23 19:12:15.000000000,"[{'_account_id': 841}, {'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 8716}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-10 05:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7fb2dab27777974299e1df976a7e3834afddf698', 'message': 'Add horizon-core to masakari-dashboard\n\nChange-Id: I5ab1dca48eba6d41273938f78a1072c810563f84\nSigned-off-by: Sampath Priyankara <sam47priya@gmail.com>\n'}, {'number': 2, 'created': '2019-12-10 08:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cdeb1b8bc2e7cc752e7db4f6a5d133d61b81bd6f', 'message': 'Add horizon-core to masakari-dashboard\n\nChange-Id: I5ab1dca48eba6d41273938f78a1072c810563f84\nSigned-off-by: Sampath Priyankara <sam47priya@gmail.com>\n'}, {'number': 3, 'created': '2019-12-20 07:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9ac14a050936a83218023b6b5ad416a63be5a3be', 'message': 'Add horizon-core to masakari-dashboard\n\nChange-Id: I5ab1dca48eba6d41273938f78a1072c810563f84\nSigned-off-by: Sampath Priyankara <sam47priya@gmail.com>\n'}, {'number': 4, 'created': '2019-12-23 08:40:48.000000000', 'files': ['gerrit/acls/openstack/masakari-dashboard.config', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2a45160871c184bd76df0a01865540c08d39e25e', 'message': 'Add horizon-core to masakari-dashboard\n\nChange-Id: I5ab1dca48eba6d41273938f78a1072c810563f84\nSigned-off-by: Sampath Priyankara <sam47priya@gmail.com>\n'}]",6,698141,2a45160871c184bd76df0a01865540c08d39e25e,22,5,4,8716,,,0,"Add horizon-core to masakari-dashboard

Change-Id: I5ab1dca48eba6d41273938f78a1072c810563f84
Signed-off-by: Sampath Priyankara <sam47priya@gmail.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/41/698141/4 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/masakari-dashboard.config', 'gerrit/projects.yaml']",2,7fb2dab27777974299e1df976a7e3834afddf698,add-horizon2masakari-dashboard, acl-config: /home/gerrit2/acls/openstack/masakari-dashboard.config, acl-config: /home/gerrit2/acls/openstack/masakari.config,33,1
openstack%2Fproject-config~master~Icebb94d60e57a651589e1f7a8de62788cac1f6dd,openstack/project-config,master,Icebb94d60e57a651589e1f7a8de62788cac1f6dd,Fuel retirement: Retire shotgun,MERGED,2019-12-20 20:39:44.000000000,2019-12-23 19:12:14.000000000,2019-12-23 19:12:14.000000000,"[{'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 20:39:44.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b0da2ab05db7231c169ac50c8a59a5ce6a248ee', 'message': 'Fuel retirement: Retire shotgun\n\nThe shotgun repo was missed in the fuel retirement, retire it now.\n\nChange-Id: Icebb94d60e57a651589e1f7a8de62788cac1f6dd\n'}]",0,700242,8b0da2ab05db7231c169ac50c8a59a5ce6a248ee,7,3,1,6547,,,0,"Fuel retirement: Retire shotgun

The shotgun repo was missed in the fuel retirement, retire it now.

Change-Id: Icebb94d60e57a651589e1f7a8de62788cac1f6dd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/700242/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,8b0da2ab05db7231c169ac50c8a59a5ce6a248ee,retire-fuel, templates: - noop-jobs, check: jobs: - openstack-tox-pep8 - openstack-tox-py27 gate: jobs: - openstack-tox-pep8 - openstack-tox-py27,2,8
openstack%2Fcinder~master~I670e29d092e925485b9091bca9c59cf43eaba17c,openstack/cinder,master,I670e29d092e925485b9091bca9c59cf43eaba17c,Rollback quota incorrect after retype volume failure,NEW,2018-08-31 09:54:49.000000000,2019-12-23 18:56:34.000000000,,"[{'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18058}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 25678}, {'_account_id': 25837}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28452}, {'_account_id': 28801}, {'_account_id': 29568}]","[{'number': 1, 'created': '2018-08-31 09:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eae8977eab3c68093f52e1ab2654ec4da8ff545d', 'message': 'Rollback quota incorrect after retype volume failure\n\nQuotas.rollback after retype volume failure use context\'s project_id,\ninstead of volume\'s project_id. This causes: when we execute ""cinder\nquota-usage"" cli, the ""reserved"" value in the result shows incorrect.\nThis patch uses volume\'s project_id in quotas.rollback.\n\nChange-Id: I670e29d092e925485b9091bca9c59cf43eaba17c\n'}, {'number': 2, 'created': '2018-09-02 08:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9fe9249b37fbbe268ba43309ccec6d70c8152dbe', 'message': 'Rollback quota incorrect after retype volume failure\n\nQuotas.rollback after retype volume failure use context\'s project_id,\ninstead of volume\'s project_id. This causes: when we execute ""cinder\nquota-usage"" cli, the ""reserved"" value in the result shows incorrect.\nThis patch uses volume\'s project_id in quotas.rollback.\n\nChange-Id: I670e29d092e925485b9091bca9c59cf43eaba17c\n'}, {'number': 3, 'created': '2018-09-04 11:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aeb84c1a52aa7c246e7d9c19ce45011052af1e23', 'message': 'Rollback quota incorrect after retype volume failure\n\nQuotas.rollback after retype volume failure use context\'s project_id,\ninstead of volume\'s project_id. This causes: when we execute ""cinder\nquota-usage"" cli, the ""reserved"" value in the result shows incorrect.\nThis patch uses volume\'s project_id in quotas.rollback.\n\nChange-Id: I670e29d092e925485b9091bca9c59cf43eaba17c\n'}, {'number': 4, 'created': '2018-09-05 03:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76db8f2a26b5dd3d91cbef1d781cd061cf6e77e3', 'message': 'Rollback quota incorrect after retype volume failure\n\nQuotas.rollback after retype volume failure use context\'s project_id,\ninstead of volume\'s project_id. This causes: when we execute ""cinder\nquota-usage"" cli, the ""reserved"" value in the result shows incorrect.\nThis patch uses volume\'s project_id in quotas.rollback.\n\nChange-Id: I670e29d092e925485b9091bca9c59cf43eaba17c\n'}, {'number': 5, 'created': '2018-10-09 09:30:28.000000000', 'files': ['cinder/volume/manager.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/scheduler/test_scheduler.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/febedf0ca1dc3e1666302496745eca5d79f194bb', 'message': 'Rollback quota incorrect after retype volume failure\n\nQuotas.rollback after retype volume failure use context\'s project_id,\ninstead of volume\'s project_id. This causes: when we execute ""cinder\nquota-usage"" cli, the ""reserved"" value in the result shows incorrect.\nThis patch uses volume\'s project_id in quotas.rollback.\n\nChange-Id: I670e29d092e925485b9091bca9c59cf43eaba17c\n'}]",4,598583,febedf0ca1dc3e1666302496745eca5d79f194bb,175,43,5,28452,,,0,"Rollback quota incorrect after retype volume failure

Quotas.rollback after retype volume failure use context's project_id,
instead of volume's project_id. This causes: when we execute ""cinder
quota-usage"" cli, the ""reserved"" value in the result shows incorrect.
This patch uses volume's project_id in quotas.rollback.

Change-Id: I670e29d092e925485b9091bca9c59cf43eaba17c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/83/598583/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/scheduler/manager.py']",2,eae8977eab3c68093f52e1ab2654ec4da8ff545d,retype-quota," project_id = volume_ref['project_id'] QUOTAS.rollback(context, reservations, project_id)"," QUOTAS.rollback(context, reservations)",5,3
openstack%2Ftripleo-ansible~master~I952df4d4a7700eccdb2d49a7fba271518058771a,openstack/tripleo-ansible,master,I952df4d4a7700eccdb2d49a7fba271518058771a,Add recursive get key from dict,MERGED,2019-12-20 21:26:03.000000000,2019-12-23 18:02:24.000000000,2019-12-23 18:02:24.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 21:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c89fa6598b4ad11937f4114e501f678bcf40b87d', 'message': 'Add recursive get key from dict\n\nThe docker_config (and other data) that we have in tripleo is a complex\ndict but we need a way to fetch a specific key from a larget structure.\nThis change adds a filter called recursive_get_key_from_dict which will\ntraverse all the dictionaries in a given dataset and return a list\ncontaining all the values of the requested key.\n\nChange-Id: I952df4d4a7700eccdb2d49a7fba271518058771a\n'}, {'number': 2, 'created': '2019-12-20 21:28:15.000000000', 'files': ['tripleo_ansible/tests/plugins/filter/test_helpers.py', 'tripleo_ansible/ansible_plugins/filter/helpers.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c072a6bf9d3ca3e264ac9055af13c2a4385895b1', 'message': 'Add recursive get key from dict\n\nThe docker_config (and other data) that we have in tripleo is a complex\ndict but we need a way to fetch a specific key from a larget structure.\nThis change adds a filter called recursive_get_key_from_dict which will\ntraverse all the dictionaries in a given dataset and return a list\ncontaining all the values of the requested key.\n\nChange-Id: I952df4d4a7700eccdb2d49a7fba271518058771a\n'}]",0,700246,c072a6bf9d3ca3e264ac9055af13c2a4385895b1,9,4,2,14985,,,0,"Add recursive get key from dict

The docker_config (and other data) that we have in tripleo is a complex
dict but we need a way to fetch a specific key from a larget structure.
This change adds a filter called recursive_get_key_from_dict which will
traverse all the dictionaries in a given dataset and return a list
containing all the values of the requested key.

Change-Id: I952df4d4a7700eccdb2d49a7fba271518058771a
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/46/700246/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/tests/plugins/filter/test_helpers.py', 'tripleo_ansible/ansible_plugins/filter/helpers.py']",2,c89fa6598b4ad11937f4114e501f678bcf40b87d,pull-images-first," 'get_key_from_dict': self.get_key_from_dict, 'recursive_get_key_from_dict': self.recursive_get_key_from_dict def recursive_get_key_from_dict(self, data, key): """"""Recursively return values for keys in a dict This filter will traverse all the dictionaries in the provided dictionary and return any values for a specified key. This is useful if you have a complex dictionary containing dynamic keys but want to fetch a commonly named key. """""" val = [] if key in data: val.append(data.get(key)) for k, v in data.items(): if isinstance(v, dict): val.extend(self.recursive_get_key_from_dict(v, key)) return val ", 'get_key_from_dict': self.get_key_from_dict,39,1
openstack%2Ftripleo-ansible~master~I878565feaedd592f66827ef20eac77a823295844,openstack/tripleo-ansible,master,I878565feaedd592f66827ef20eac77a823295844,"Jinja test ""failed"" is no longer supported as filter in ansible > 2.9.0",MERGED,2019-12-20 17:38:35.000000000,2019-12-23 18:02:23.000000000,2019-12-23 18:02:23.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 13770}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 17:38:35.000000000', 'files': ['tripleo_ansible/roles/octavia-undercloud/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ccd3bd9336692dd2d01738cb3eea5a569c786c66', 'message': 'Jinja test ""failed"" is no longer supported as filter in ansible > 2.9.0\n\nUsing ansible-provided jinja tests as filters has been removed\nin ansible 2.9 and newer\n\nsee https://docs.ansible.com/ansible/latest/porting_guides/porting_guide_2.5.html#jinja-tests-used-as-filters\n\nusing ""failed"" as a filter causes playbook to fail with\n "" no filter named \'failed\' ""\n\nChange-Id: I878565feaedd592f66827ef20eac77a823295844\n'}]",0,700213,ccd3bd9336692dd2d01738cb3eea5a569c786c66,11,5,1,13770,,,0,"Jinja test ""failed"" is no longer supported as filter in ansible > 2.9.0

Using ansible-provided jinja tests as filters has been removed
in ansible 2.9 and newer

see https://docs.ansible.com/ansible/latest/porting_guides/porting_guide_2.5.html#jinja-tests-used-as-filters

using ""failed"" as a filter causes playbook to fail with
 "" no filter named 'failed' ""

Change-Id: I878565feaedd592f66827ef20eac77a823295844
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/13/700213/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/octavia-undercloud/tasks/main.yml'],1,ccd3bd9336692dd2d01738cb3eea5a569c786c66,, - (key_file_result is failed) or (not (key_file_result.stat.exists | bool)) or (not (key_file_result.stat.readable | bool)), - (key_file_result | failed) or (not (key_file_result.stat.exists | bool)) or (not (key_file_result.stat.readable | bool)),1,1
openstack%2Fswift~master~I35614aa4b42e61d97929579dcb16f7dfc9fef96f,openstack/swift,master,I35614aa4b42e61d97929579dcb16f7dfc9fef96f,sharding: Tolerate blank limits when listing,MERGED,2019-12-20 06:28:23.000000000,2019-12-23 17:54:13.000000000,2019-12-23 17:52:08.000000000,"[{'_account_id': 1179}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 06:28:23.000000000', 'files': ['test/unit/proxy/controllers/test_container.py', 'swift/proxy/controllers/container.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d246bf20ed30047f9b285dcc3378f9c324ed938e', 'message': ""sharding: Tolerate blank limits when listing\n\nOtherwise, we can 500 with\n\n   ValueError: invalid literal for int() with base 10: ''\n\nChange-Id: I35614aa4b42e61d97929579dcb16f7dfc9fef96f\n""}]",0,700115,d246bf20ed30047f9b285dcc3378f9c324ed938e,7,2,1,15343,,,0,"sharding: Tolerate blank limits when listing

Otherwise, we can 500 with

   ValueError: invalid literal for int() with base 10: ''

Change-Id: I35614aa4b42e61d97929579dcb16f7dfc9fef96f
",git fetch https://review.opendev.org/openstack/swift refs/changes/15/700115/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/controllers/test_container.py', 'swift/proxy/controllers/container.py']",2,d246bf20ed30047f9b285dcc3378f9c324ed938e,, req_limit = int(req.params.get('limit') or CONTAINER_LISTING_LIMIT)," req_limit = int(req.params.get('limit', CONTAINER_LISTING_LIMIT))",6,5
openstack%2Fopenstack-ansible-os_ceilometer~master~Ib3a84516e0f00e84c6869fa58e9595062c6fbede,openstack/openstack-ansible-os_ceilometer,master,Ib3a84516e0f00e84c6869fa58e9595062c6fbede,Check host is within group,MERGED,2019-12-19 11:39:48.000000000,2019-12-23 17:52:25.000000000,2019-12-21 14:09:47.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31445}]","[{'number': 1, 'created': '2019-12-19 11:39:48.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/fe9208c08ad27d92c9dac7b88404abf1214327f7', 'message': 'Check host is within group\n\nA fix on my patch: https://review.opendev.org/#/c/694055/\nIf the current host is not in the ceilometer-agent-notification group\nthen the intersection of the current hosts group_names will produce an\nempty list. This should be checked before evaluating the next conditional.\n\nChange-Id: Ib3a84516e0f00e84c6869fa58e9595062c6fbede\n'}]",0,699957,fe9208c08ad27d92c9dac7b88404abf1214327f7,18,4,1,29865,,,0,"Check host is within group

A fix on my patch: https://review.opendev.org/#/c/694055/
If the current host is not in the ceilometer-agent-notification group
then the intersection of the current hosts group_names will produce an
empty list. This should be checked before evaluating the next conditional.

Change-Id: Ib3a84516e0f00e84c6869fa58e9595062c6fbede
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/57/699957/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,fe9208c08ad27d92c9dac7b88404abf1214327f7,check-conditional-length, - ceilometer_services['ceilometer-agent-notification']['group'] | intersect(group_names) | length > 0, - (groups[(ceilometer_services['ceilometer-agent-notification']['group'] | intersect(group_names))[0]] | intersect(ansible_play_hosts))[0] | length > 0,1,1
openstack%2Ftripleo-common~stable%2Ftrain~Iafecc885abac5583c07bc046bc4d541f5e1e1c00,openstack/tripleo-common,stable/train,Iafecc885abac5583c07bc046bc4d541f5e1e1c00,Ensure blacklisted nodes are not included in server_names,MERGED,2019-12-20 09:45:16.000000000,2019-12-23 17:00:17.000000000,2019-12-23 16:58:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 09:45:16.000000000', 'files': ['tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fe282fc5ff17578c0a3dd3b4cd3ea1a8d092636e', 'message': ""Ensure blacklisted nodes are not included in server_names\n\n'ServerIdData' map actually returns 'None' ids for blacklisted\nnodes for a role, as 'nova_server_resource' output is\nevaluated with condition 'server_not_blacklisted'. This\nresults in get_server_names() returning these blacklisted\nnodes with something like 'None: compute-1' and results\nin issues when we write ansible_host_vars. As we don't intend to\nwrite ansible_host_vars for blacklisted nodes, we can ignore\nthese from 'server_names'.\n\nCloses-bug: #1856661\nChange-Id: Iafecc885abac5583c07bc046bc4d541f5e1e1c00\n(cherry picked from commit d407c96d17020a15395ba4f6537e03e596caedaa)\n""}]",0,700129,fe282fc5ff17578c0a3dd3b4cd3ea1a8d092636e,9,4,1,8833,,,0,"Ensure blacklisted nodes are not included in server_names

'ServerIdData' map actually returns 'None' ids for blacklisted
nodes for a role, as 'nova_server_resource' output is
evaluated with condition 'server_not_blacklisted'. This
results in get_server_names() returning these blacklisted
nodes with something like 'None: compute-1' and results
in issues when we write ansible_host_vars. As we don't intend to
write ansible_host_vars for blacklisted nodes, we can ignore
these from 'server_names'.

Closes-bug: #1856661
Change-Id: Iafecc885abac5583c07bc046bc4d541f5e1e1c00
(cherry picked from commit d407c96d17020a15395ba4f6537e03e596caedaa)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/29/700129/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/config.py'],1,fe282fc5ff17578c0a3dd3b4cd3ea1a8d092636e,, if server_id is not None: servers[server_id] = name.lower(), servers[server_id] = name.lower(),2,1
openstack%2Fnova~master~I83937bc8a4d7665c7f435020e284e269b98985c8,openstack/nova,master,I83937bc8a4d7665c7f435020e284e269b98985c8,Move common test method up to base class,MERGED,2019-12-14 10:43:23.000000000,2019-12-23 16:59:54.000000000,2019-12-23 16:50:58.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-14 10:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b386c5e247b30ee63f1e40eafbfccd1648f764a', 'message': 'Move common test method up to base class\n\nTo be able to test cancelling a live migration we need a special virt\ndriver in the functional test which requires a separate test class to\nuse. Before this separate test class is added this patch pulls up some\nof the common test methods to an already existing base class so those\ncan be used from the new test class in a subsequent patch.\n\nChange-Id: I83937bc8a4d7665c7f435020e284e269b98985c8\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}, {'number': 2, 'created': '2019-12-19 13:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8058134d6cf7afd9845de5a4b0f68ec5fe1cb022', 'message': 'Move common test method up to base class\n\nTo be able to test cancelling a live migration we need a special virt\ndriver in the functional test which requires a separate test class to\nuse. Before this separate test class is added this patch pulls up some\nof the common test methods to an already existing base class so those\ncan be used from the new test class in a subsequent patch.\n\nChange-Id: I83937bc8a4d7665c7f435020e284e269b98985c8\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}, {'number': 3, 'created': '2019-12-19 13:20:31.000000000', 'files': ['nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d29a5f435863b9dae2e5470b965ab4dd01f128af', 'message': 'Move common test method up to base class\n\nTo be able to test cancelling a live migration we need a special virt\ndriver in the functional test which requires a separate test class to\nuse. Before this separate test class is added this patch pulls up some\nof the common test methods to an already existing base class so those\ncan be used from the new test class in a subsequent patch.\n\nChange-Id: I83937bc8a4d7665c7f435020e284e269b98985c8\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}]",0,699064,d29a5f435863b9dae2e5470b965ab4dd01f128af,28,11,3,9708,,,0,"Move common test method up to base class

To be able to test cancelling a live migration we need a special virt
driver in the functional test which requires a separate test class to
use. Before this separate test class is added this patch pulls up some
of the common test methods to an already existing base class so those
can be used from the new test class in a subsequent patch.

Change-Id: I83937bc8a4d7665c7f435020e284e269b98985c8
blueprint: support-move-ops-with-qos-ports-ussuri
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/699064/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/test_servers.py'],1,9b386c5e247b30ee63f1e40eafbfccd1648f764a,bp/support-move-ops-with-qos-ports-ussuri," def _create_server_with_ports(self, *ports): server = self._create_server( flavor=self.flavor_with_group_policy, networks=[{'port': port['id']} for port in ports], host='host1') return self._wait_for_state_change(server, 'ACTIVE') def _check_allocation( self, server, compute_rp_uuid, non_qos_port, qos_port, qos_sriov_port, flavor, migration_uuid=None, source_compute_rp_uuid=None, new_flavor=None): updated_non_qos_port = self.neutron.show_port( non_qos_port['id'])['port'] updated_qos_port = self.neutron.show_port(qos_port['id'])['port'] updated_qos_sriov_port = self.neutron.show_port( qos_sriov_port['id'])['port'] allocations = self.placement_api.get( '/allocations/%s' % server['id']).body['allocations'] # if there is new_flavor then we either have an in progress resize or # a confirmed resize. In both cases the instance allocation should be # according to the new_flavor current_flavor = (new_flavor if new_flavor else flavor) # We expect one set of allocations for the compute resources on the # compute rp and two sets for the networking resources one on the ovs # bridge rp due to the qos_port resource request and one one the # sriov pf2 due to qos_sriov_port resource request self.assertEqual(3, len(allocations)) self.assertComputeAllocationMatchesFlavor( allocations, compute_rp_uuid, current_flavor) ovs_allocations = allocations[ self.ovs_bridge_rp_per_host[compute_rp_uuid]]['resources'] self.assertPortMatchesAllocation(qos_port, ovs_allocations) sriov_allocations = allocations[ self.sriov_dev_rp_per_host[compute_rp_uuid][self.PF2]]['resources'] self.assertPortMatchesAllocation(qos_sriov_port, sriov_allocations) # We expect that only the RP uuid of the networking RP having the port # allocation is sent in the port binding for the port having resource # request qos_binding_profile = updated_qos_port['binding:profile'] self.assertEqual(self.ovs_bridge_rp_per_host[compute_rp_uuid], qos_binding_profile['allocation']) qos_sriov_binding_profile = updated_qos_sriov_port['binding:profile'] self.assertEqual(self.sriov_dev_rp_per_host[compute_rp_uuid][self.PF2], qos_sriov_binding_profile['allocation']) # And we expect not to have any allocation set in the port binding for # the port that doesn't have resource request self.assertEqual({}, updated_non_qos_port['binding:profile']) if migration_uuid: migration_allocations = self.placement_api.get( '/allocations/%s' % migration_uuid).body['allocations'] # We expect one set of allocations for the compute resources on the # compute rp and two sets for the networking resources one on the # ovs bridge rp due to the qos_port resource request and one one # the sriov pf2 due to qos_sriov_port resource request self.assertEqual(3, len(migration_allocations)) self.assertComputeAllocationMatchesFlavor( migration_allocations, source_compute_rp_uuid, flavor) ovs_allocations = migration_allocations[ self.ovs_bridge_rp_per_host[ source_compute_rp_uuid]]['resources'] self.assertPortMatchesAllocation(qos_port, ovs_allocations) sriov_allocations = migration_allocations[ self.sriov_dev_rp_per_host[ source_compute_rp_uuid][self.PF2]]['resources'] self.assertPortMatchesAllocation(qos_sriov_port, sriov_allocations) def _delete_server_and_check_allocations( self, server, qos_port, qos_sriov_port): self._delete_and_check_allocations(server) # assert that unbind removes the allocation from the binding of the # ports that got allocation during the bind updated_qos_port = self.neutron.show_port(qos_port['id'])['port'] binding_profile = updated_qos_port['binding:profile'] self.assertNotIn('allocation', binding_profile) updated_qos_sriov_port = self.neutron.show_port( qos_sriov_port['id'])['port'] binding_profile = updated_qos_sriov_port['binding:profile'] self.assertNotIn('allocation', binding_profile) def _turn_off_api_check(self): # The API actively rejecting the move operations with resource # request so we have to turn off that check. # TODO(gibi): Remove this when the move operations are supported and # the API check is removed. patcher = mock.patch( 'nova.api.openstack.common.' 'supports_port_resource_request_during_move', return_value=True) self.addCleanup(patcher.stop) patcher.start() "," def _check_allocation( self, server, compute_rp_uuid, non_qos_port, qos_port, qos_sriov_port, flavor, migration_uuid=None, source_compute_rp_uuid=None, new_flavor=None): updated_non_qos_port = self.neutron.show_port( non_qos_port['id'])['port'] updated_qos_port = self.neutron.show_port(qos_port['id'])['port'] updated_qos_sriov_port = self.neutron.show_port( qos_sriov_port['id'])['port'] allocations = self.placement_api.get( '/allocations/%s' % server['id']).body['allocations'] # if there is new_flavor then we either have an in progress resize or # a confirmed resize. In both cases the instance allocation should be # according to the new_flavor current_flavor = (new_flavor if new_flavor else flavor) # We expect one set of allocations for the compute resources on the # compute rp and two sets for the networking resources one on the ovs # bridge rp due to the qos_port resource request and one one the # sriov pf2 due to qos_sriov_port resource request self.assertEqual(3, len(allocations)) self.assertComputeAllocationMatchesFlavor( allocations, compute_rp_uuid, current_flavor) ovs_allocations = allocations[ self.ovs_bridge_rp_per_host[compute_rp_uuid]]['resources'] self.assertPortMatchesAllocation(qos_port, ovs_allocations) sriov_allocations = allocations[ self.sriov_dev_rp_per_host[compute_rp_uuid][self.PF2]]['resources'] self.assertPortMatchesAllocation(qos_sriov_port, sriov_allocations) # We expect that only the RP uuid of the networking RP having the port # allocation is sent in the port binding for the port having resource # request qos_binding_profile = updated_qos_port['binding:profile'] self.assertEqual(self.ovs_bridge_rp_per_host[compute_rp_uuid], qos_binding_profile['allocation']) qos_sriov_binding_profile = updated_qos_sriov_port['binding:profile'] self.assertEqual(self.sriov_dev_rp_per_host[compute_rp_uuid][self.PF2], qos_sriov_binding_profile['allocation']) # And we expect not to have any allocation set in the port binding for # the port that doesn't have resource request self.assertEqual({}, updated_non_qos_port['binding:profile']) if migration_uuid: migration_allocations = self.placement_api.get( '/allocations/%s' % migration_uuid).body['allocations'] # We expect one set of allocations for the compute resources on the # compute rp and two sets for the networking resources one on the # ovs bridge rp due to the qos_port resource request and one one # the sriov pf2 due to qos_sriov_port resource request self.assertEqual(3, len(migration_allocations)) self.assertComputeAllocationMatchesFlavor( migration_allocations, source_compute_rp_uuid, flavor) ovs_allocations = migration_allocations[ self.ovs_bridge_rp_per_host[ source_compute_rp_uuid]]['resources'] self.assertPortMatchesAllocation(qos_port, ovs_allocations) sriov_allocations = migration_allocations[ self.sriov_dev_rp_per_host[ source_compute_rp_uuid][self.PF2]]['resources'] self.assertPortMatchesAllocation(qos_sriov_port, sriov_allocations) def _create_server_with_ports(self, *ports): server = self._create_server( flavor=self.flavor_with_group_policy, networks=[{'port': port['id']} for port in ports], host='host1') return self._wait_for_state_change(server, 'ACTIVE') def _delete_server_and_check_allocations( self, server, qos_port, qos_sriov_port): self._delete_and_check_allocations(server) # assert that unbind removes the allocation from the binding of the # ports that got allocation during the bind updated_qos_port = self.neutron.show_port(qos_port['id'])['port'] binding_profile = updated_qos_port['binding:profile'] self.assertNotIn('allocation', binding_profile) updated_qos_sriov_port = self.neutron.show_port( qos_sriov_port['id'])['port'] binding_profile = updated_qos_sriov_port['binding:profile'] self.assertNotIn('allocation', binding_profile) def _turn_off_api_check(self): # The API actively rejecting the move operations with resource # request so we have to turn off that check. # TODO(gibi): Remove this when the move operations are supported and # the API check is removed. patcher = mock.patch( 'nova.api.openstack.common.' 'supports_port_resource_request_during_move', return_value=True) self.addCleanup(patcher.stop) patcher.start() ",100,100
openstack%2Ftripleo-common~stable%2Fqueens~I8dfc2494d35d5fce52d573f9edcafbe11ab7faac,openstack/tripleo-common,stable/queens,I8dfc2494d35d5fce52d573f9edcafbe11ab7faac,OvS DPDK parameters failing in NIC Partitioning,MERGED,2019-12-23 03:35:23.000000000,2019-12-23 16:58:53.000000000,2019-12-23 16:58:53.000000000,"[{'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-23 03:35:23.000000000', 'files': ['tripleo_common/actions/derive_params.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b7f761b14cec47c773986e8687365fda7a247ddd', 'message': ""OvS DPDK parameters failing in NIC Partitioning\n\nThis change is to fix the finding DPDK device name issue in\nOvS DPDK derive parameters logic. Currently mistral fails to\nderive OvS DPDK parameters in NIC Partitioning and getting\nerror 'Unable to determine NUMA node for DPDK NIC:'\n\nChange-Id: I8dfc2494d35d5fce52d573f9edcafbe11ab7faac\nCloses-Bug: #1855159\n(cherry picked from commit 9641cc2ccb9d6bc5757f2bb888b374dedc2d2733)\n(cherry picked from commit dd354ee4d6eb05c003de40006cbdb0895099f2c8)\n(cherry picked from commit 068f8d1ae121d63110636dc6527bd241b0ded890)\n(cherry picked from commit 0c490b8c112e112c58fc6346593ccfc9cbdf13e2)\n""}]",0,700364,b7f761b14cec47c773986e8687365fda7a247ddd,7,5,1,22865,,,0,"OvS DPDK parameters failing in NIC Partitioning

This change is to fix the finding DPDK device name issue in
OvS DPDK derive parameters logic. Currently mistral fails to
derive OvS DPDK parameters in NIC Partitioning and getting
error 'Unable to determine NUMA node for DPDK NIC:'

Change-Id: I8dfc2494d35d5fce52d573f9edcafbe11ab7faac
Closes-Bug: #1855159
(cherry picked from commit 9641cc2ccb9d6bc5757f2bb888b374dedc2d2733)
(cherry picked from commit dd354ee4d6eb05c003de40006cbdb0895099f2c8)
(cherry picked from commit 068f8d1ae121d63110636dc6527bd241b0ded890)
(cherry picked from commit 0c490b8c112e112c58fc6346593ccfc9cbdf13e2)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/64/700364/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/derive_params.py'],1,b7f761b14cec47c773986e8687365fda7a247ddd,nic-partioining-mistral-issue-stable/train-stable/stein-stable/rocky-stable/queens," type = dpdk_iface.get('type', '') if type == 'sriov_vf': name = dpdk_iface.get('device', '') else: name = dpdk_iface.get('name', '')"," name = dpdk_iface.get('name', '')",5,1
openstack%2Fnova~master~I351399f02d4d3b3e958a62fe37380577f3056d0d,openstack/nova,master,I351399f02d4d3b3e958a62fe37380577f3056d0d,Func test for qos live migration reschedule,MERGED,2019-12-13 20:41:05.000000000,2019-12-23 16:53:25.000000000,2019-12-23 16:50:52.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-13 20:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3456f53c37e65a78d5bdd2a0dffa5f0e047cb79e', 'message': 'Func test for qos live migration reschedule\n\nThis patch adds extra functional test coverage for live migration with\nqos ports. It covers live migration with target host specified and\nre-schedule success and failure cases.\n\nThere is one non test code change. In the\ncheck_can_live_migrate_destination compute manager method CONF.host was\nused to determine the destination host. This was replaced with\nself.host. This change result in identical data in a production\nenvironment. But during the functional test the CONF object is global for\nevery compute servers running in the environment. This causes that when\nthe above call runs on host2 the CONF.host is already set to host3 as\nthat host was started later in the test. Fortunately self.host is\nset on the compute manage during the compute startup so it is correct in\nthe functional test env too. It is unfortunate that we have to change\nnon test code to make the test code work but the global CONF variable is\na hard problem to resolve.\n\nChange-Id: I351399f02d4d3b3e958a62fe37380577f3056d0d\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}, {'number': 2, 'created': '2019-12-14 10:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f16c91187f4445e90146b1b1c510f342588291b5', 'message': 'Func test for qos live migration reschedule\n\nThis patch adds extra functional test coverage for live migration with\nqos ports. It covers live migration with target host specified and\nre-schedule success and failure cases.\n\nThere is one non test code change. In the\ncheck_can_live_migrate_destination compute manager method CONF.host was\nused to determine the destination host. This was replaced with\nself.host. This change result in identical data in a production\nenvironment. But during the functional test the CONF object is global for\nevery compute servers running in the environment. This causes that when\nthe above call runs on host2 the CONF.host is already set to host3 as\nthat host was started later in the test. Fortunately self.host is\nset on the compute manage during the compute startup so it is correct in\nthe functional test env too. It is unfortunate that we have to change\nnon test code to make the test code work but the global CONF variable is\na hard problem to resolve.\n\nChange-Id: I351399f02d4d3b3e958a62fe37380577f3056d0d\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}, {'number': 3, 'created': '2019-12-19 13:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f5658aa5a7c23e3c00dd858eaade141a70ce26b', 'message': 'Func test for qos live migration reschedule\n\nThis patch adds extra functional test coverage for live migration with\nqos ports. It covers live migration with target host specified and\nre-schedule success and failure cases.\n\nThere are two non test code change.\n\n1)\nIn the check_can_live_migrate_destination compute manager method CONF.host\nwas used to determine the destination host. This was replaced with\nself.host. This change result in identical data in a production\nenvironment. But during the functional test the CONF object is global for\nevery compute servers running in the environment. This causes that when\nthe above call runs on host2 the CONF.host is already set to host3 as\nthat host was started later in the test. Fortunately self.host is\nset on the compute manage during the compute startup so it is correct in\nthe functional test env too. It is unfortunate that we have to change\nnon test code to make the test code work but the global CONF variable is\na hard problem to resolve.\n\n2)\nThe InstancePCIRequest is saved in the LiveMigrationTask as the task\nupdates the request for each host it tries to move the instance. If non\nof the destination supports the migration then the rollback() of the\ntask will restore the InstancePCIRequest to its original value as the\ninstance will remain on the source host.\n\nChange-Id: I351399f02d4d3b3e958a62fe37380577f3056d0d\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}, {'number': 4, 'created': '2019-12-19 13:20:31.000000000', 'files': ['nova/conductor/tasks/live_migrate.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5f63ada309f562f3ffe9b75b6f1acf1efb80ee4e', 'message': 'Func test for qos live migration reschedule\n\nThis patch adds extra functional test coverage for live migration with\nqos ports. It covers live migration with target host specified and\nre-schedule success and failure cases.\n\nThere are two non test code changes.\n\n1)\nIn the check_can_live_migrate_destination compute manager method CONF.host\nwas used to determine the destination host. This was replaced with\nself.host. This change result in identical data in a production\nenvironment. But during the functional test the CONF object is global for\nevery compute servers running in the environment. This causes that when\nthe above call runs on host2 the CONF.host is already set to host3 as\nthat host was started later in the test. Fortunately self.host is\nset on the compute manage during the compute startup so it is correct in\nthe functional test env too. It is unfortunate that we have to change\nnon test code to make the test code work but the global CONF variable is\na hard problem to resolve.\n\n2)\nThe InstancePCIRequest is saved in the LiveMigrationTask as the task\nupdates the request for each host it tries to move the instance. If non\nof the destination supports the migration then the rollback() of the\ntask will restore the InstancePCIRequest to its original value as the\ninstance will remain on the source host.\n\nChange-Id: I351399f02d4d3b3e958a62fe37380577f3056d0d\nblueprint: support-move-ops-with-qos-ports-ussuri\n'}]",15,699015,5f63ada309f562f3ffe9b75b6f1acf1efb80ee4e,32,12,4,9708,,,0,"Func test for qos live migration reschedule

This patch adds extra functional test coverage for live migration with
qos ports. It covers live migration with target host specified and
re-schedule success and failure cases.

There are two non test code changes.

1)
In the check_can_live_migrate_destination compute manager method CONF.host
was used to determine the destination host. This was replaced with
self.host. This change result in identical data in a production
environment. But during the functional test the CONF object is global for
every compute servers running in the environment. This causes that when
the above call runs on host2 the CONF.host is already set to host3 as
that host was started later in the test. Fortunately self.host is
set on the compute manage during the compute startup so it is correct in
the functional test env too. It is unfortunate that we have to change
non test code to make the test code work but the global CONF variable is
a hard problem to resolve.

2)
The InstancePCIRequest is saved in the LiveMigrationTask as the task
updates the request for each host it tries to move the instance. If non
of the destination supports the migration then the rollback() of the
task will restore the InstancePCIRequest to its original value as the
instance will remain on the source host.

Change-Id: I351399f02d4d3b3e958a62fe37380577f3056d0d
blueprint: support-move-ops-with-qos-ports-ussuri
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/699015/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/functional/test_servers.py']",2,3456f53c37e65a78d5bdd2a0dffa5f0e047cb79e,bp/support-move-ops-with-qos-ports-ussuri," def test_live_migrate_with_qos_port(self, host=None): 'host': host, def test_live_migrate_with_qos_port_with_target_host(self): self.test_live_migrate_with_qos_port(host='host2') def test_live_migrate_with_qos_port_reschedule_success(self): # TODO(gibi): remove this when live migration is fully supported and # therefore the check is removed from the api self._turn_off_api_check() self._start_compute('host3') compute3_rp_uuid = self._get_provider_uuid_by_host('host3') self._create_networking_rp_tree('host3', compute3_rp_uuid) non_qos_normal_port = self.neutron.port_1 qos_normal_port = self.neutron.port_with_resource_request qos_sriov_port = self.neutron.port_with_sriov_resource_request server = self._create_server_with_ports( non_qos_normal_port, qos_normal_port, qos_sriov_port) # check that the server allocates from the current host properly self._check_allocation( server, self.compute1_rp_uuid, non_qos_normal_port, qos_normal_port, qos_sriov_port, self.flavor_with_group_policy) orig_check = nova.virt.fake.FakeDriver.\ check_can_live_migrate_destination def fake_check_can_live_migrate_destination( context, instance, src_compute_info, dst_compute_info, block_migration=False, disk_over_commit=False): if dst_compute_info['host'] == 'host2': raise exception.MigrationPreCheckError( reason='test_live_migrate_pre_check_fails') else: return orig_check( context, instance, src_compute_info, dst_compute_info, block_migration, disk_over_commit) with mock.patch('nova.virt.fake.FakeDriver.' 'check_can_live_migrate_destination', side_effect=fake_check_can_live_migrate_destination): self.api.post_server_action( server['id'], { 'os-migrateLive': { 'host': None, 'block_migration': 'auto' } } ) # The first migration attempt was to host2. So we expect that the # instance lands on host3. self._wait_for_server_parameter( self.api, server, {'OS-EXT-SRV-ATTR:host': 'host3', 'status': 'ACTIVE'}) self._check_allocation( server, compute3_rp_uuid, non_qos_normal_port, qos_normal_port, qos_sriov_port, self.flavor_with_group_policy) self._delete_server_and_check_allocations( server, qos_normal_port, qos_sriov_port) def test_live_migrate_with_qos_port_reschedule_fails(self): # TODO(gibi): remove this when live migration is fully supported and # therefore the check is removed from the api self._turn_off_api_check() non_qos_normal_port = self.neutron.port_1 qos_normal_port = self.neutron.port_with_resource_request qos_sriov_port = self.neutron.port_with_sriov_resource_request server = self._create_server_with_ports( non_qos_normal_port, qos_normal_port, qos_sriov_port) # check that the server allocates from the current host properly self._check_allocation( server, self.compute1_rp_uuid, non_qos_normal_port, qos_normal_port, qos_sriov_port, self.flavor_with_group_policy) with mock.patch( 'nova.virt.fake.FakeDriver.check_can_live_migrate_destination', side_effect=exception.MigrationPreCheckError( reason='test_live_migrate_pre_check_fails')): self.api.post_server_action( server['id'], { 'os-migrateLive': { 'host': None, 'block_migration': 'auto' } } ) # The every migration target host will fail the pre check so # the conductor will run out of target host and the migration will # fail self._wait_for_migration_status(server, ['error']) # the server will remain on host1 self._wait_for_server_parameter( self.api, server, {'OS-EXT-SRV-ATTR:host': 'host1', 'status': 'ACTIVE'}) self._check_allocation( server, self.compute1_rp_uuid, non_qos_normal_port, qos_normal_port, qos_sriov_port, self.flavor_with_group_policy) self._delete_server_and_check_allocations( server, qos_normal_port, qos_sriov_port) # TODO(gibi): add tests for live migration cases:"," def test_live_migrate_with_qos_port(self): 'host': None, # TODO(gibi): add tests for live migration cases: # * with target host # * re-schedule success # * re-schedule fail -> pci request cleanup?",115,6
openstack%2Ftooz~master~Ie23d88f1a05983d7465f18a329cabc23d789a628,openstack/tooz,master,Ie23d88f1a05983d7465f18a329cabc23d789a628,RedisLock release() should not check if the lock has been acquired,MERGED,2019-02-10 03:27:48.000000000,2019-12-23 16:52:56.000000000,2019-12-23 16:51:39.000000000,"[{'_account_id': 1669}, {'_account_id': 6928}, {'_account_id': 15334}, {'_account_id': 16511}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 03:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/c8d85e545d853cd962e348db37a289ce153bfc73', 'message': ""RedisLock release() should not check if the lock has been acquired\n\nThe RedisDriver coordinator _stop() method removes the lock from the\n_acquired_locks set before calling the release() method on the lock,\nso the release() method should not check to see if the lock is in the\nset, since it never will be.\n\nThis was preventing the coordinator's _stop() method from releasing\nthe locks, so they had to timeout before another group member could\ntake over as leader.\n\nChange-Id: Ie23d88f1a05983d7465f18a329cabc23d789a628\nCloses-Bug: 1815330\n""}, {'number': 2, 'created': '2019-12-19 09:12:28.000000000', 'files': ['tooz/drivers/redis.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/842c7404b2d01c5dd718c14bb55f0cd47471f0e1', 'message': ""RedisLock release() should not check if the lock has been acquired\n\nThe RedisDriver coordinator _stop() method removes the lock from the\n_acquired_locks set before calling the release() method on the lock,\nso the release() method should not check to see if the lock is in the\nset, since it never will be.\n\nThis was preventing the coordinator's _stop() method from releasing\nthe locks, so they had to timeout before another group member could\ntake over as leader.\n\nChange-Id: Ie23d88f1a05983d7465f18a329cabc23d789a628\nCloses-Bug: 1815330\n""}]",0,636038,842c7404b2d01c5dd718c14bb55f0cd47471f0e1,19,5,2,16511,,,0,"RedisLock release() should not check if the lock has been acquired

The RedisDriver coordinator _stop() method removes the lock from the
_acquired_locks set before calling the release() method on the lock,
so the release() method should not check to see if the lock is in the
set, since it never will be.

This was preventing the coordinator's _stop() method from releasing
the locks, so they had to timeout before another group member could
take over as leader.

Change-Id: Ie23d88f1a05983d7465f18a329cabc23d789a628
Closes-Bug: 1815330
",git fetch https://review.opendev.org/openstack/tooz refs/changes/38/636038/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/redis.py'],1,c8d85e545d853cd962e348db37a289ce153bfc73,bug/1815330,, if not self.acquired: return False,0,2
openstack%2Fswift~master~Icdf100dfcd006d975b49d151b99aa9272452d013,openstack/swift,master,Icdf100dfcd006d975b49d151b99aa9272452d013,sharding: Let swift-manage-shard-ranges accept a relative path,MERGED,2019-12-20 21:39:45.000000000,2019-12-23 16:52:50.000000000,2019-12-23 16:51:02.000000000,"[{'_account_id': 1179}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 21:39:45.000000000', 'files': ['swift/cli/manage_shard_ranges.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/40edf07ab347a9a73e944f4a18dd96b504f7e194', 'message': ""sharding: Let swift-manage-shard-ranges accept a relative path\n\nPreviously, passing a relative path would confuse the ContainerBroker about\nwhich DB files are available, leading to an IndexError when none were found.\n\nJust call realpath() on whatever the user provided so we don't have to muck\nwith any of the broker code.\n\nChange-Id: Icdf100dfcd006d975b49d151b99aa9272452d013\n""}]",0,700248,40edf07ab347a9a73e944f4a18dd96b504f7e194,7,2,1,15343,,,0,"sharding: Let swift-manage-shard-ranges accept a relative path

Previously, passing a relative path would confuse the ContainerBroker about
which DB files are available, leading to an IndexError when none were found.

Just call realpath() on whatever the user provided so we don't have to muck
with any of the broker code.

Change-Id: Icdf100dfcd006d975b49d151b99aa9272452d013
",git fetch https://review.opendev.org/openstack/swift refs/changes/48/700248/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/manage_shard_ranges.py'],1,40edf07ab347a9a73e944f4a18dd96b504f7e194,,"import os.path broker = ContainerBroker(os.path.realpath(args.container_db), logger=logger, skip_commits=True)"," broker = ContainerBroker(args.container_db, logger=logger, skip_commits=True)",3,2
openstack%2Finstack-undercloud~stable%2Fqueens~I5a19399e0a33091d0a0d0d35876ea8e1788821de,openstack/instack-undercloud,stable/queens,I5a19399e0a33091d0a0d0d35876ea8e1788821de,Apply firewall rule for tripleo ui if ui is really enabled,MERGED,2019-12-17 12:10:28.000000000,2019-12-23 16:52:49.000000000,2019-12-23 16:52:49.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 12:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b6e83e3a5f91a5cb102b45ff1dab0dd60ccb4dfb', 'message': 'Apply firewall rule for tripleo ui if ui is really enabled\n\nDo not set firewall rule for tripleo ui if ui is disabled in\nundercloud.\n\nChange-Id: I5a19399e0a33091d0a0d0d35876ea8e1788821de\n(cherry picked from commit 5033964bff0ee7d38801c4ee8262fdc4f66398f2)\n'}, {'number': 2, 'created': '2019-12-19 20:53:15.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/15536575bfb9ca44a1a42c21d57fb9cb99586208', 'message': 'Apply firewall rule for tripleo ui if ui is really enabled\n\nDo not set firewall rule for tripleo ui if ui is disabled in\nundercloud.\n\nChange-Id: I5a19399e0a33091d0a0d0d35876ea8e1788821de\n(cherry picked from commit 5033964bff0ee7d38801c4ee8262fdc4f66398f2)\n'}]",0,699401,15536575bfb9ca44a1a42c21d57fb9cb99586208,20,4,2,9816,,,0,"Apply firewall rule for tripleo ui if ui is really enabled

Do not set firewall rule for tripleo ui if ui is disabled in
undercloud.

Change-Id: I5a19399e0a33091d0a0d0d35876ea8e1788821de
(cherry picked from commit 5033964bff0ee7d38801c4ee8262fdc4f66398f2)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/01/699401/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,b6e83e3a5f91a5cb102b45ff1dab0dd60ccb4dfb,ui-firewall-queens,{{#ENABLE_UI}}{{/ENABLE_UI}},,2,0
openstack%2Ftripleo-heat-templates~master~Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d,openstack/tripleo-heat-templates,master,Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d,Correct invalid jinja set,MERGED,2019-12-19 02:37:03.000000000,2019-12-23 16:52:48.000000000,2019-12-23 16:52:48.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 02:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7c710719f21043317fdbf2bdd293fc763d5819df', 'message': 'Correct invalid jinja set\n\nThis change corrects an issue with the jinja expression at the\ntop of the file which is resulting in a stacktrace when the\nset attempts to update an object of the same name, which results\nin a none type.\n\nThis change also updates the jinja expression at the top of the\nfile making it more legible.\n\nChange-Id: Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d\nCloses-Bug: #1856918\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-12-20 17:55:10.000000000', 'files': ['network/service_net_map.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d088cf66be456ce3e0b58c6b866f387f2ac4cc78', 'message': 'Correct invalid jinja set\n\nThis change corrects an issue with the jinja expression at the\ntop of the file which is resulting in a stacktrace when the\nset attempts to update an object of the same name, which results\nin a none type.\n\nThis change also updates the jinja expression at the top of the\nfile making it more legible.\n\nChange-Id: Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d\nCloses-Bug: #1856918\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,699902,d088cf66be456ce3e0b58c6b866f387f2ac4cc78,19,6,2,7353,,,0,"Correct invalid jinja set

This change corrects an issue with the jinja expression at the
top of the file which is resulting in a stacktrace when the
set attempts to update an object of the same name, which results
in a none type.

This change also updates the jinja expression at the top of the
file making it more legible.

Change-Id: Ia3334c5d8a20bb3c0bc721a266a09b6c01fe7c4d
Closes-Bug: #1856918
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/699902/2 && git format-patch -1 --stdout FETCH_HEAD,['network/service_net_map.j2.yaml'],1,7c710719f21043317fdbf2bdd293fc763d5819df,bug/1856918,{% set _service_nets = {} %} {% for network in networks if network.enabled|default(true) %} {% if network.service_net_map_replace is defined %} {% set _ = _service_nets.update({network.service_net_map_replace:network.name_lower}) %} {% else %} {% set _ = _service_nets.update({network.name_lower:network.name_lower}) %} {% endif %} {% endfor %},{%- set _service_nets = {} -%} {%- for network in networks if network.enabled|default(true) -%} {%- if network.service_net_map_replace is defined -%} {%- set _service_nets = _service_nets.update({network.service_net_map_replace:network.name_lower}) -%} {%- else -%} {%- set _service_nets = _service_nets.update({network.name_lower:network.name_lower}) -%} {%- endif -%} {%- endfor -%} ,8,9
openstack%2Ftripleo-quickstart-extras~master~I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461,openstack/tripleo-quickstart-extras,master,I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461,Run upgrade-stein job on quickstart-extra changes,ABANDONED,2019-07-10 20:00:38.000000000,2019-12-23 16:47:20.000000000,,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 18846}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 26297}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-07-10 20:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/70c8023dff22a634630c4f4e269be8d071ce9a1f', 'message': 'Run upgrade-stein job on quickstart-extra changes\n\nChange-Id: I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461\nDepends-On: https://review.opendev.org/#/c/670168/\n'}, {'number': 2, 'created': '2019-07-18 09:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d0e230d44f5fe08332db38e95589472cd6194ab5', 'message': 'Run upgrade-stein job on quickstart-extra changes\n\nChange-Id: I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461\nDepends-On: https://review.opendev.org/#/c/671055/\n'}, {'number': 3, 'created': '2019-07-18 09:49:00.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fb21d95acb2db21a24636ac4452d83a94b5149f4', 'message': 'Run upgrade-stein job on quickstart-extra changes\n\nChange-Id: I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461\nDepends-On: https://review.opendev.org/#/c/671055/\n'}]",0,670176,fb21d95acb2db21a24636ac4452d83a94b5149f4,22,9,3,14985,,,0,"Run upgrade-stein job on quickstart-extra changes

Change-Id: I2b4d1981fd8a9a765b4f6e9f6c4a095d596fa461
Depends-On: https://review.opendev.org/#/c/671055/
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/76/670176/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,70c8023dff22a634630c4f4e269be8d071ce9a1f,bad-branch-upgrade-job, - tripleo-ci-centos-7-standalone-upgrade-stein: branches: master - tripleo-ci-centos-7-standalone-upgrade-stein: branches: master,,4,0
openstack%2Ftripleo-quickstart~master~I83332e9b83e9b1158fc0b06fd13aa97889f94d77,openstack/tripleo-quickstart,master,I83332e9b83e9b1158fc0b06fd13aa97889f94d77,Run upgrade-stein job on quickstart changes,ABANDONED,2019-07-10 19:59:49.000000000,2019-12-23 16:47:14.000000000,,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 26297}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-07-10 19:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/267d93bd7fa79c0e77fefb57334ab9b4a74703d4', 'message': 'Run upgrade-stein job on quickstart changes\n\nChange-Id: I83332e9b83e9b1158fc0b06fd13aa97889f94d77\nDepends-On: https://review.opendev.org/#/c/670168/\n'}, {'number': 2, 'created': '2019-07-18 09:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/112f2798a23f397114d89ee3cc0528590abaf01e', 'message': 'Run upgrade-stein job on quickstart changes\n\nChange-Id: I83332e9b83e9b1158fc0b06fd13aa97889f94d77\nDepends-On: https://review.opendev.org/#/c/671055/\n'}, {'number': 3, 'created': '2019-07-18 09:49:31.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7fdd50fbc5777e07675da76070a639e95d68b033', 'message': 'Run upgrade-stein job on quickstart changes\n\nChange-Id: I83332e9b83e9b1158fc0b06fd13aa97889f94d77\nDepends-On: https://review.opendev.org/#/c/671055/\n'}]",0,670175,7fdd50fbc5777e07675da76070a639e95d68b033,19,8,3,14985,,,0,"Run upgrade-stein job on quickstart changes

Change-Id: I83332e9b83e9b1158fc0b06fd13aa97889f94d77
Depends-On: https://review.opendev.org/#/c/671055/
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/75/670175/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,267d93bd7fa79c0e77fefb57334ab9b4a74703d4,bad-branch-upgrade-job, - tripleo-ci-centos-7-standalone-upgrade-stein: branches: master - tripleo-ci-centos-7-standalone-upgrade-stein: branches: master,,4,0
openstack%2Ftripleo-ansible~master~I994c3485bfc319148498542a395417301f0d5118,openstack/tripleo-ansible,master,I994c3485bfc319148498542a395417301f0d5118,DNM: trigger tests,ABANDONED,2019-10-28 17:10:55.000000000,2019-12-23 16:40:12.000000000,,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-28 17:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/afbf7bf456f2ca88c0ff86047dd59b700b0b0c17', 'message': 'DNM: trigger tests\n\nChange-Id: I994c3485bfc319148498542a395417301f0d5118\n'}, {'number': 2, 'created': '2019-10-28 21:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e1c76832e61b14ffe7f1c288b2913084c8c1f46c', 'message': 'DNM: trigger tests\n\nChange-Id: I994c3485bfc319148498542a395417301f0d5118\n'}, {'number': 3, 'created': '2019-10-29 19:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fb4f0797e292e992307663eaa57ac5d4e71909c3', 'message': 'DNM: trigger tests\n\nChange-Id: I994c3485bfc319148498542a395417301f0d5118\n'}, {'number': 4, 'created': '2019-10-29 21:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/41d2656eaa4a2de5554c92a1081651e5bf9bfec8', 'message': 'DNM: trigger tests\n\nChange-Id: I994c3485bfc319148498542a395417301f0d5118\n'}, {'number': 5, 'created': '2019-10-29 21:27:50.000000000', 'files': ['tripleo_ansible/roles/tripleo-create-admin/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-image-prepare/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-transfer/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-common/tasks/main.yaml', 'tripleo_ansible/roles/tuned/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-uuid/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-timezone/tasks/main.yaml', 'tripleo_ansible/roles/backup-and-restore/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-cellv2/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-kernel/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-run-ansible/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-stop/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ptp/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-config/tasks/main.yaml', '_skeleton_role_/tasks/main.yml.j2', 'tripleo_ansible/roles/test_package_action/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-tag/tasks/main.yaml', 'tripleo_ansible/roles/test_json_error_callback/tasks/main.yaml', 'tripleo_ansible/roles/aide/tasks/main.yaml', 'tripleo_ansible/roles/test_deps/tasks/main.yaml', 'tripleo_ansible/roles/octavia-undercloud/tasks/main.yaml', 'tripleo_ansible/roles/octavia-controller-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-sshd/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-fetch-dir/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-validations-package/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-securetty/tasks/main.yaml', 'tripleo_ansible/roles/login-defs/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-packages/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-persist/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-bootstrap/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-upgrade-hiera/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-work-dir/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-hieradata/tasks/main.yaml', 'tripleo_ansible/roles/octavia-controller-post-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-clients-install/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-firewall/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ovs-dpdk/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ssh-known-hosts/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-image-serve/tasks/main.yaml', 'tripleo_ansible/roles/octavia-overcloud-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-module-load/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-rm/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-podman/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/617ecf0603c80041b6101a49521c36d0837a02c5', 'message': 'DNM: trigger tests\n\nChange-Id: I994c3485bfc319148498542a395417301f0d5118\n'}]",0,691723,617ecf0603c80041b6101a49521c36d0837a02c5,16,3,5,14985,,,0,"DNM: trigger tests

Change-Id: I994c3485bfc319148498542a395417301f0d5118
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/23/691723/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo-create-admin/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-image-prepare/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-transfer/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-common/tasks/main.yaml', 'tripleo_ansible/roles/tuned/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-uuid/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-timezone/tasks/main.yaml', 'tripleo_ansible/roles/backup-and-restore/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-cellv2/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-kernel/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-run-ansible/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-stop/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ptp/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-config/tasks/main.yaml', 'tripleo_ansible/roles/test_package_action/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-tag/tasks/main.yaml', 'tripleo_ansible/roles/test_json_error_callback/tasks/main.yaml', 'tripleo_ansible/roles/aide/tasks/main.yaml', 'tripleo_ansible/roles/test_deps/tasks/main.yaml', 'tripleo_ansible/roles/octavia-undercloud/tasks/main.yaml', 'tripleo_ansible/roles/octavia-controller-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-sshd/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-fetch-dir/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-validations-package/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-securetty/tasks/main.yaml', 'tripleo_ansible/roles/login-defs/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-packages/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-persist/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-bootstrap/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-upgrade-hiera/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ceph-work-dir/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-hieradata/tasks/main.yaml', 'tripleo_ansible/roles/octavia-controller-post-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-clients-install/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-firewall/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ovs-dpdk/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-ssh-known-hosts/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-image-serve/tasks/main.yaml', 'tripleo_ansible/roles/octavia-overcloud-config/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-module-load/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-container-rm/tasks/main.yaml', 'tripleo_ansible/roles/tripleo-podman/tasks/main.yaml']",43,afbf7bf456f2ca88c0ff86047dd59b700b0b0c17,fix-ci,# # ,,88,0
openstack%2Fnova~master~I75b02757b319ea0f706a9c4167a227f5a043c37a,openstack/nova,master,I75b02757b319ea0f706a9c4167a227f5a043c37a,Fix get_request_group_mapping doc,MERGED,2019-12-19 13:15:25.000000000,2019-12-23 16:27:21.000000000,2019-12-23 16:25:03.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-19 13:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd2c59ced0a9dd0f1b46afc0b3edaed3c3c51137', 'message': ""Fix get_request_group_mapping doc\n\nThe RequestSpec.get_request_group_mapping method's doc wrongly states\nthat that return value is a dict of UUID values. Actually it is a list\nof UUIDs.\n\nChange-Id: I75b02757b319ea0f706a9c4167a227f5a043c37a\n""}, {'number': 2, 'created': '2019-12-19 13:20:31.000000000', 'files': ['nova/objects/request_spec.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0aa3a67689a7d5f4f36149011b9516f405863cb', 'message': ""Fix get_request_group_mapping doc\n\nThe RequestSpec.get_request_group_mapping method's doc wrongly states\nthat that return value is a dict of UUID values. Actually it is a list\nof UUIDs.\n\nChange-Id: I75b02757b319ea0f706a9c4167a227f5a043c37a\n""}]",2,699979,e0aa3a67689a7d5f4f36149011b9516f405863cb,24,11,2,9708,,,0,"Fix get_request_group_mapping doc

The RequestSpec.get_request_group_mapping method's doc wrongly states
that that return value is a dict of UUID values. Actually it is a list
of UUIDs.

Change-Id: I75b02757b319ea0f706a9c4167a227f5a043c37a
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/699979/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/request_spec.py'],1,bd2c59ced0a9dd0f1b46afc0b3edaed3c3c51137,bp/support-move-ops-with-qos-ports-ussuri," port_id, to a list of resource provider UUIDs which provide resource for that RequestGroup."," port_id, to resource provider UUID that provides resource for that RequestGroup.",2,2
openstack%2Fnova~master~I6a1bd1f6d173cd681a88fc333b226423b732a52f,openstack/nova,master,I6a1bd1f6d173cd681a88fc333b226423b732a52f,nova-net: Correct some broken VIF tests,MERGED,2019-11-28 11:02:05.000000000,2019-12-23 16:19:50.000000000,2019-12-23 16:08:34.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bac5300cb41297f9d5a070c22cdbe720c67d2033', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-11-28 12:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a10e49c8aa0f89138c2a17b22d5424bf5d6075d6', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-11-28 13:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/458ad8742543140a8514e2dfc93b4eb0ce1f7ef0', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-11-29 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0d9ceacb50f225beff03d887b21d6d8417293f7', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c999681107710163c27df9a658bf8aa76999b24', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 6, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/012c28c391efabf7cfff0fbc3c26165f68bae222', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 7, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce1aa718bfcc6d86c3f58535d61841d6e060d7d1', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 8, 'created': '2019-12-16 10:14:44.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ad9221fdcc4208e9e4c325260e9b07be1fd2ffe', 'message': ""nova-net: Correct some broken VIF tests\n\nDue to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method\nin the 'nova.virt.libvirt.vif' module is implemented, unsetting\n'[DEFAULT] firewall_driver' will result in some degree of filtering\nbeing added to VIFs. Correct things by simply removing the unsetting of\nthis attribute in tests. We could go further and fix the broken method\nbut given that it's being removed shortly, it hardly seems worth it.\n\nChange-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",2,696513,8ad9221fdcc4208e9e4c325260e9b07be1fd2ffe,59,10,8,15334,,,0,"nova-net: Correct some broken VIF tests

Due to how the 'LibvirtGenericVIFDriver.is_no_op_firewall' static method
in the 'nova.virt.libvirt.vif' module is implemented, unsetting
'[DEFAULT] firewall_driver' will result in some degree of filtering
being added to VIFs. Correct things by simply removing the unsetting of
this attribute in tests. We could go further and fix the broken method
but given that it's being removed shortly, it hardly seems worth it.

Change-Id: I6a1bd1f6d173cd681a88fc333b226423b732a52f
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/696513/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_vif.py'],1,bac5300cb41297f9d5a070c22cdbe720c67d2033,bp/remove-nova-network-ussuri," actualXmlstr = etree.tostring(actualXmlstr, encoding='unicode', pretty_print=True) self.vif_bridge, br_want)"," self.flags(firewall_driver=None) actualXmlstr = etree.tostring(actualXmlstr, pretty_print=True) self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") self.vif_bridge, br_want, 1) self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") self.flags(firewall_driver=""nova.virt.firewall.NoopFirewallDriver"") <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/> <filterref filter=""nova-instance-instance-00000001-22522562e2aa""/>",3,16
openstack%2Foslo.limit~master~I197d6486a3b126f616ffe2f7e3e669d922a1e337,openstack/oslo.limit,master,I197d6486a3b126f616ffe2f7e3e669d922a1e337,Trivial cleanup for tox,MERGED,2019-12-22 15:27:11.000000000,2019-12-23 16:15:56.000000000,2019-12-23 16:14:43.000000000,"[{'_account_id': 15334}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-22 15:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/34d8dfb55fbc7f00ecbe5eb1c78855e3142159fc', 'message': ""Trivial cleanup for tox\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: I197d6486a3b126f616ffe2f7e3e669d922a1e337\n""}, {'number': 2, 'created': '2019-12-23 13:04:11.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/09eadf955e50eb6a3797a0a8c32c56d5622b3835', 'message': ""Trivial cleanup for tox\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: I197d6486a3b126f616ffe2f7e3e669d922a1e337\n""}]",2,700338,09eadf955e50eb6a3797a0a8c32c56d5622b3835,12,4,2,22165,,,0,"Trivial cleanup for tox

move 'basepython' to the top-level 'testenv'

Change-Id: I197d6486a3b126f616ffe2f7e3e669d922a1e337
",git fetch https://review.opendev.org/openstack/oslo.limit refs/changes/38/700338/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,34d8dfb55fbc7f00ecbe5eb1c78855e3142159fc,,minversion = 3.1ignore_basepython_conflict = Truebasepython = python3,minversion = 2.5.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,3,7
openstack%2Fnova~master~I12a96ea659ed402cc4d1bd52a50e2e16042b6372,openstack/nova,master,I12a96ea659ed402cc4d1bd52a50e2e16042b6372,nova-net: Remove 'is_neutron_security_groups' function,MERGED,2019-11-28 11:02:05.000000000,2019-12-23 16:13:26.000000000,2019-12-23 16:07:12.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c39ba6d265f0fa6a280d06892181e2a0a48f5ec', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-11-28 12:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d7150d980a201b18b95e448dcbf6a45a46bbe56', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-11-28 13:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f424947485a5bcef6e65bb1eb2c7a45f985114ad', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-11-29 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f87ae4c6ba805f837a9c66ef3793e48716b36d8', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4328dde7055ebe8d71c579a2e58b03a7f0661dff', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 6, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06cdc68a8f98c1802b72c0d683398335c9dec7f5', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 7, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1b532f0f24dd89510b1ff209af504de157724325', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 8, 'created': '2019-12-16 10:14:44.000000000', 'files': ['nova/tests/unit/network/test_config.py', 'nova/api/openstack/compute/views/servers.py', 'nova/network/security_group/openstack_driver.py', 'nova/compute/manager.py', 'nova/objects/security_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d5c9423e40dc7e70c751baa1c3ea7c8896cb960a', 'message': ""nova-net: Remove 'is_neutron_security_groups' function\n\nWe'll always use the neutron security group driver going forward. A\nfuture change will remove the nova-network-based security group driver\nitself as well as the 'get_openstack_security_group_driver' function\nfrom the same module.\n\nChange-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",10,696511,d5c9423e40dc7e70c751baa1c3ea7c8896cb960a,69,11,8,15334,,,0,"nova-net: Remove 'is_neutron_security_groups' function

We'll always use the neutron security group driver going forward. A
future change will remove the nova-network-based security group driver
itself as well as the 'get_openstack_security_group_driver' function
from the same module.

Change-Id: I12a96ea659ed402cc4d1bd52a50e2e16042b6372
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/696511/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_config.py', 'nova/api/openstack/compute/views/servers.py', 'nova/test.py', 'nova/network/security_group/openstack_driver.py', 'nova/compute/manager.py', 'nova/objects/security_group.py']",6,6c39ba6d265f0fa6a280d06892181e2a0a48f5ec,bp/remove-nova-network-ussuri, # This is the special 'default' security group in the case of # neutron.," # This is either a nova-network security group name, or it's the # special 'default' security group in the case of neutron.",32,77
openstack%2Fnova~master~Ia05215b2e7168563c54b78263625125537b7234c,openstack/nova,master,Ia05215b2e7168563c54b78263625125537b7234c,nova-net: Remove nova-network security group driver,MERGED,2019-11-28 11:02:05.000000000,2019-12-23 16:08:29.000000000,2019-12-23 16:08:28.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfdca8e9306d0348d816ae2aa58f3e8553b3b163', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2019-11-28 12:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b3c2c8fe56aa05393acf7aca013c7ed1b542c72', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2019-11-28 13:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb77ade39f2d67266d617eb0da20f1960048cfe6', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 4, 'created': '2019-11-29 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a35e2a8f0798c5cd297e85c31c26c78c4ec82e9c', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 5, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03d6e660da94b51828d07648b558b1b589f1ba9c', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 6, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4978c72b11aace24259fbbb6c34d03af8d4a8c86', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 7, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f697e14d839bcb1f36adccf549c3c6cada4345dd', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 8, 'created': '2019-12-16 10:14:44.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_compute.py', 'nova/network/security_group/security_group_base.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf0d099f4b1891151ee1ae116642b4350903ea7f', 'message': 'nova-net: Remove nova-network security group driver\n\nThis is another self-explanatory change. We remove the driver along with\nrelated tests. Some additional API tests need to be fixed since these\nwere using the nova-network security group driver.\n\nChange-Id: Ia05215b2e7168563c54b78263625125537b7234c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",6,696512,bf0d099f4b1891151ee1ae116642b4350903ea7f,90,11,8,15334,,,0,"nova-net: Remove nova-network security group driver

This is another self-explanatory change. We remove the driver along with
related tests. Some additional API tests need to be fixed since these
were using the nova-network security group driver.

Change-Id: Ia05215b2e7168563c54b78263625125537b7234c
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/696512/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/api/openstack/compute/security_groups.py', 'nova/api/openstack/compute/views/servers.py', 'nova/network/manager.py', 'nova/tests/unit/compute/test_compute.py', 'nova/api/metadata/base.py', 'nova/network/security_group/openstack_driver.py', 'nova/network/security_group/security_group_base.py', 'nova/compute/api.py']",9,cfdca8e9306d0348d816ae2aa58f3e8553b3b163,bp/remove-nova-network-ussuri,from nova.network.security_group import neutron_driver as neutron_sg_api neutron_sg_api.SecurityGroupAPI()) security_groups.append(secgroup_dict['id']),"from nova.network.security_group import openstack_driver from nova.network.security_group import security_group_base openstack_driver.get_openstack_security_group_driver()) # Check to see if it's a nova-network or neutron type. if isinstance(secgroup_dict['id'], int): # This is nova-network so just return the requested name. security_groups.append(secgroup) else: # The id for neutron is a uuid, so we return the id (uuid). security_groups.append(secgroup_dict['id']) class SecurityGroupAPI(base.Base, security_group_base.SecurityGroupBase): """"""Sub-set of the Compute API related to managing security groups and security group rules """""" # The nova security group api does not use a uuid for the id. id_is_uuid = False def __init__(self, **kwargs): super(SecurityGroupAPI, self).__init__(**kwargs) self.compute_rpcapi = compute_rpcapi.ComputeAPI() def validate_property(self, value, property, allowed): """"""Validate given security group property. :param value: the value to validate, as a string or unicode :param property: the property, either 'name' or 'description' :param allowed: the range of characters allowed """""" try: val = value.strip() except AttributeError: msg = _(""Security group %s is not a string or unicode"") % property self.raise_invalid_property(msg) utils.check_string_length(val, name=property, min_length=1, max_length=255) if allowed and not re.match(allowed, val): # Some validation to ensure that values match API spec. # - Alphanumeric characters, spaces, dashes, and underscores. # TODO(Daviey): LP: #813685 extend beyond group_name checking, and # probably create a param validator that can be used elsewhere. msg = (_(""Value (%(value)s) for parameter Group%(property)s is "" ""invalid. Content limited to '%(allowed)s'."") % {'value': value, 'allowed': allowed, 'property': property.capitalize()}) self.raise_invalid_property(msg) def ensure_default(self, context): """"""Ensure that a context has a security group. Creates a security group for the security context if it does not already exist. :param context: the security context """""" self.db.security_group_ensure_default(context) def create_security_group(self, context, name, description): try: objects.Quotas.check_deltas(context, {'security_groups': 1}, context.project_id, user_id=context.user_id) except exception.OverQuota: msg = _(""Quota exceeded, too many security groups."") self.raise_over_quota(msg) LOG.info(""Create Security Group %s"", name) self.ensure_default(context) group = {'user_id': context.user_id, 'project_id': context.project_id, 'name': name, 'description': description} try: group_ref = self.db.security_group_create(context, group) except exception.SecurityGroupExists: msg = _('Security group %s already exists') % name self.raise_group_already_exists(msg) # NOTE(melwitt): We recheck the quota after creating the object to # prevent users from allocating more resources than their allowed quota # in the event of a race. This is configurable because it can be # expensive if strict quota limits are not required in a deployment. if CONF.quota.recheck_quota: try: objects.Quotas.check_deltas(context, {'security_groups': 0}, context.project_id, user_id=context.user_id) except exception.OverQuota: self.db.security_group_destroy(context, group_ref['id']) msg = _(""Quota exceeded, too many security groups."") self.raise_over_quota(msg) return group_ref def update_security_group(self, context, security_group, name, description): if security_group['name'] in RO_SECURITY_GROUPS: msg = (_(""Unable to update system group '%s'"") % security_group['name']) self.raise_invalid_group(msg) group = {'name': name, 'description': description} columns_to_join = ['rules.grantee_group'] group_ref = self.db.security_group_update(context, security_group['id'], group, columns_to_join=columns_to_join) return group_ref def get(self, context, name=None, id=None, map_exception=False): self.ensure_default(context) cols = ['rules'] try: if name: return self.db.security_group_get_by_name(context, context.project_id, name, columns_to_join=cols) elif id: return self.db.security_group_get(context, id, columns_to_join=cols) except exception.NotFound as exp: if map_exception: msg = exp.format_message() self.raise_not_found(msg) else: raise def list(self, context, names=None, ids=None, project=None, search_opts=None): self.ensure_default(context) groups = [] if names or ids: if names: for name in names: groups.append(self.db.security_group_get_by_name(context, project, name)) if ids: for id in ids: groups.append(self.db.security_group_get(context, id)) elif context.is_admin: # TODO(eglynn): support a wider set of search options than just # all_tenants, at least include the standard filters defined for # the EC2 DescribeSecurityGroups API for the non-admin case also if (search_opts and 'all_tenants' in search_opts): groups = self.db.security_group_get_all(context) else: groups = self.db.security_group_get_by_project(context, project) elif project: groups = self.db.security_group_get_by_project(context, project) return groups def destroy(self, context, security_group): if security_group['name'] in RO_SECURITY_GROUPS: msg = _(""Unable to delete system group '%s'"") % \ security_group['name'] self.raise_invalid_group(msg) if self.db.security_group_in_use(context, security_group['id']): msg = _(""Security group is still in use"") self.raise_invalid_group(msg) LOG.info(""Delete security group %s"", security_group['name']) self.db.security_group_destroy(context, security_group['id']) def is_associated_with_server(self, security_group, instance_uuid): """"""Check if the security group is already associated with the instance. If Yes, return True. """""" if not security_group: return False instances = security_group.get('instances') if not instances: return False for inst in instances: if (instance_uuid == inst['uuid']): return True return False def add_to_instance(self, context, instance, security_group_name): """"""Add security group to the instance."""""" security_group = self.db.security_group_get_by_name(context, context.project_id, security_group_name) instance_uuid = instance.uuid # check if the security group is associated with the server if self.is_associated_with_server(security_group, instance_uuid): raise exception.SecurityGroupExistsForInstance( security_group_id=security_group['id'], instance_id=instance_uuid) self.db.instance_add_security_group(context.elevated(), instance_uuid, security_group['id']) if instance.host: self.compute_rpcapi.refresh_instance_security_rules( context, instance, instance.host) def remove_from_instance(self, context, instance, security_group_name): """"""Remove the security group associated with the instance."""""" security_group = self.db.security_group_get_by_name(context, context.project_id, security_group_name) instance_uuid = instance.uuid # check if the security group is associated with the server if not self.is_associated_with_server(security_group, instance_uuid): raise exception.SecurityGroupNotExistsForInstance( security_group_id=security_group['id'], instance_id=instance_uuid) self.db.instance_remove_security_group(context.elevated(), instance_uuid, security_group['id']) if instance.host: self.compute_rpcapi.refresh_instance_security_rules( context, instance, instance.host) def get_rule(self, context, id): self.ensure_default(context) try: return self.db.security_group_rule_get(context, id) except exception.NotFound: msg = _(""Rule (%s) not found"") % id self.raise_not_found(msg) def add_rules(self, context, id, name, vals): """"""Add security group rule(s) to security group. Note: the Nova security group API doesn't support adding multiple security group rules at once but the EC2 one does. Therefore, this function is written to support both. """""" try: objects.Quotas.check_deltas(context, {'security_group_rules': len(vals)}, id) except exception.OverQuota: msg = _(""Quota exceeded, too many security group rules."") self.raise_over_quota(msg) msg = (""Security group %(name)s added %(protocol)s ingress "" ""(%(from_port)s:%(to_port)s)"") rules = [] for v in vals: rule = self.db.security_group_rule_create(context, v) # NOTE(melwitt): We recheck the quota after creating the object to # prevent users from allocating more resources than their allowed # quota in the event of a race. This is configurable because it can # be expensive if strict quota limits are not required in a # deployment. if CONF.quota.recheck_quota: try: objects.Quotas.check_deltas(context, {'security_group_rules': 0}, id) except exception.OverQuota: self.db.security_group_rule_destroy(context, rule['id']) msg = _(""Quota exceeded, too many security group rules."") self.raise_over_quota(msg) rules.append(rule) LOG.info(msg, {'name': name, 'protocol': rule.protocol, 'from_port': rule.from_port, 'to_port': rule.to_port}) self.trigger_rules_refresh(context, id=id) return rules def remove_rules(self, context, security_group, rule_ids): msg = (""Security group %(name)s removed %(protocol)s ingress "" ""(%(from_port)s:%(to_port)s)"") for rule_id in rule_ids: rule = self.get_rule(context, rule_id) LOG.info(msg, {'name': security_group['name'], 'protocol': rule.protocol, 'from_port': rule.from_port, 'to_port': rule.to_port}) self.db.security_group_rule_destroy(context, rule_id) # NOTE(vish): we removed some rules, so refresh self.trigger_rules_refresh(context, id=security_group['id']) def validate_id(self, id): try: return int(id) except ValueError: msg = _(""Security group id should be integer"") self.raise_invalid_property(msg) def _refresh_instance_security_rules(self, context, instances): for instance in instances: if instance.host is not None: self.compute_rpcapi.refresh_instance_security_rules( context, instance, instance.host) def trigger_rules_refresh(self, context, id): """"""Called when a rule is added to or removed from a security_group."""""" instances = objects.InstanceList.get_by_security_group_id(context, id) self._refresh_instance_security_rules(context, instances) def trigger_members_refresh(self, context, group_ids): """"""Called when a security group gains a new or loses a member. Sends an update request to each compute node for each instance for which this is relevant. """""" instances = objects.InstanceList.get_by_grantee_security_group_ids( context, group_ids) self._refresh_instance_security_rules(context, instances) def get_instance_security_groups(self, context, instance, detailed=False): if detailed: return self.db.security_group_get_by_instance(context, instance.uuid) return [{'name': group.name} for group in instance.security_groups]",36,491
openstack%2Freleases~master~Iee1179394c829b84a156d47eff21282894500b5f,openstack/releases,master,Iee1179394c829b84a156d47eff21282894500b5f,Update horizon plugin bug trackers,MERGED,2019-12-23 09:11:25.000000000,2019-12-23 16:04:56.000000000,2019-12-23 16:04:56.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 09:11:25.000000000', 'files': ['deliverables/ussuri/trove-dashboard.yaml', 'deliverables/ussuri/senlin-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3efd17f032a7ff8aef1172d65949d9874734214b', 'message': 'Update horizon plugin bug trackers\n\nChange-Id: Iee1179394c829b84a156d47eff21282894500b5f\n'}]",0,700399,3efd17f032a7ff8aef1172d65949d9874734214b,6,2,1,841,,,0,"Update horizon plugin bug trackers

Change-Id: Iee1179394c829b84a156d47eff21282894500b5f
",git fetch https://review.opendev.org/openstack/releases refs/changes/99/700399/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ussuri/trove-dashboard.yaml', 'deliverables/ussuri/senlin-dashboard.yaml']",2,3efd17f032a7ff8aef1172d65949d9874734214b,horizon-plugins-bug-tracker,launchpad: senlin-dashboard,launchpad: senlin,2,2
openstack%2Fpython-zunclient~master~I48c473905e468cb3f6bd9337c81cdccb19853fbf,openstack/python-zunclient,master,I48c473905e468cb3f6bd9337c81cdccb19853fbf,Fix:modify comment for registry_update,MERGED,2019-12-23 10:38:34.000000000,2019-12-23 16:00:47.000000000,2019-12-23 15:59:31.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 10:38:34.000000000', 'files': ['zunclient/v1/registries_shell.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/1372f15ff37d7a083efc79a5509d4c676f50b8d8', 'message': 'Fix:modify comment for registry_update\n\nChange-Id: I48c473905e468cb3f6bd9337c81cdccb19853fbf\n'}]",0,700416,1372f15ff37d7a083efc79a5509d4c676f50b8d8,7,2,1,23365,,,0,"Fix:modify comment for registry_update

Change-Id: I48c473905e468cb3f6bd9337c81cdccb19853fbf
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/16/700416/1 && git format-patch -1 --stdout FETCH_HEAD,['zunclient/v1/registries_shell.py'],1,1372f15ff37d7a083efc79a5509d4c676f50b8d8,, help='The new username for the registry.') help='The new password for the registry.') help='The new domain for the registry.'), help='The username login to the registry.') help='The domain login to the registry.') help='The domain of the registry.'),3,3
openstack%2Fkolla-ansible~master~I36ebb4e196ece8a304269e8c85e39dda72faae50,openstack/kolla-ansible,master,I36ebb4e196ece8a304269e8c85e39dda72faae50,Fix unable to connect to epmd when deploy rabbitmq by train with ipv6,MERGED,2019-12-17 16:44:18.000000000,2019-12-23 15:50:12.000000000,2019-12-23 14:43:47.000000000,"[{'_account_id': 7488}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2019-12-17 16:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5a831e9575463fdd3ae678cf03077f9c251fd239', 'message': 'Fix unable to connect to epmd when deploy rabbitmq by train with ipv6\n\ndeploy rabbitmq cluster by train with ipv6 report:\nunable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)\n\nCloses-Bug: #1856725\nChange-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 2, 'created': '2019-12-18 03:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0d167f0f56c370a06bea11c74558de4639dc9b83', 'message': 'Fix unable to connect to epmd when deploy rabbitmq by train with ipv6\n\ndeploy rabbitmq cluster by train with ipv6 report:\nunable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)\n\nCloses-Bug: #1856725\nChange-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 3, 'created': '2019-12-18 06:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4db44d87445267b7c455b562d11ad7b9a22670b0', 'message': 'Fix unable to connect to epmd when deploy rabbitmq by train with ipv6\n\ndeploy rabbitmq cluster by train with ipv6 report:\nunable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)\n\nCloses-Bug: #1856725\nChange-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 4, 'created': '2019-12-18 10:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ce3539140743976c9bfb05f7e805e0493b070ce9', 'message': 'Fix unable to connect to epmd when deploy rabbitmq by train with ipv6\n\ndeploy rabbitmq cluster by train with ipv6 report:\nunable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)\n\nCloses-Bug: #1856725\nChange-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}, {'number': 5, 'created': '2019-12-18 11:27:55.000000000', 'files': ['ansible/roles/common/templates/kolla-toolbox.json.j2', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7054b27dbb8bc893c50f66b492b7e14e5bc92237', 'message': 'Fix unable to connect to epmd when deploy rabbitmq by train with ipv6\n\ndeploy rabbitmq cluster by train with ipv6 report:\nunable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)\n\nCloses-Bug: #1856725\nChange-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50\nSigned-off-by: yj.bai <bai.yongjun@99cloud.net>\n'}]",2,699458,7054b27dbb8bc893c50f66b492b7e14e5bc92237,16,3,5,29344,,,0,"Fix unable to connect to epmd when deploy rabbitmq by train with ipv6

deploy rabbitmq cluster by train with ipv6 report:
unable to connect to epmd (port 4369) on control-1: address (cannot connect to host/port)

Closes-Bug: #1856725
Change-Id: I36ebb4e196ece8a304269e8c85e39dda72faae50
Signed-off-by: yj.bai <bai.yongjun@99cloud.net>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/58/699458/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/templates/kolla-toolbox.json.j2', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2']",3,5a831e9575463fdd3ae678cf03077f9c251fd239,Bug#1856725,export ERL_INETRC=/etc/rabbitmq/erl_inetrc,,14,1
openstack%2Fnova~master~I3d30fc9f823b02a1651646a01ad83b5c3e781325,openstack/nova,master,I3d30fc9f823b02a1651646a01ad83b5c3e781325,nova-net: Convert remaining unit tests to neutron,MERGED,2019-11-28 11:02:05.000000000,2019-12-23 15:45:58.000000000,2019-12-23 15:41:43.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9ce1b9181d3163753e65f1996e06acd7ea9ddc2', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2019-11-28 12:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c1cf880b3646ad97fb3eb775a24145ac4586b06', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2019-11-28 13:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ad3fbb4c1de2b73be548cad32448daf8fc65873', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 4, 'created': '2019-11-29 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e4b720a2b8acc2271623cbdff9cf3972e2766cd', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 5, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c70bc5578759f6bf0f067f752d0033d984abc03d', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 6, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56ddc1e3f315530324d9ee8bb5265a70860b20fb', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 7, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48e6e050441d3e64eaff0681d575479713ae35df', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 8, 'created': '2019-12-16 10:14:44.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/test_metadata.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/test_quota.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/fakes.py', 'nova/tests/unit/utils.py', 'nova/tests/unit/virt/test_virt_drivers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/80e64186e636d440c747315b516aaf9c3149e3c6', 'message': 'nova-net: Convert remaining unit tests to neutron\n\nConvert the remaining few unit test that aren\'t specific to nova-network\nto ""use neutron"". In most cases, this simply means dropping unnecessary\n\'use_neutron=True\' flag overrides, though there are some additional\nthings that need to be done.\n\nChange-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",11,696510,80e64186e636d440c747315b516aaf9c3149e3c6,63,10,8,15334,,,0,"nova-net: Convert remaining unit tests to neutron

Convert the remaining few unit test that aren't specific to nova-network
to ""use neutron"". In most cases, this simply means dropping unnecessary
'use_neutron=True' flag overrides, though there are some additional
things that need to be done.

Change-Id: I3d30fc9f823b02a1651646a01ad83b5c3e781325
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/696510/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/vmwareapi/stubs.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/test_metadata.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/test_quota.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/fakes.py', 'nova/tests/unit/utils.py', 'nova/tests/unit/virt/xenapi/test_vmops.py', 'nova/tests/unit/virt/test_virt_drivers.py']",10,c9ce1b9181d3163753e65f1996e06acd7ea9ddc2,bp/remove-nova-network-ussuri," # When using destroying an instance, os-vif will try to execute some # commands which hang tests so let's just stub out the unplug call to # os-vif since we don't care about it.", # When using CONF.use_neutron=True and destroying an instance os-vif # will try to execute some commands which hangs tests so let's just # stub out the unplug call to os-vif since we don't care about it.,95,260
openstack%2Fnova~master~Ibb84ea210795634f02997d4627e0beec5fea36ee,openstack/nova,master,Ibb84ea210795634f02997d4627e0beec5fea36ee,Support live migration with qos ports,MERGED,2019-11-25 14:08:06.000000000,2019-12-23 15:44:05.000000000,2019-12-23 15:41:37.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-25 14:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0a2204c48fcb2131bd483b31ff85c783a4041e5', 'message': 'Support live migration with qos ports\n\nTODO:\n* deduplicate code\n* add test coverage\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 2, 'created': '2019-11-27 16:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc365ff731c464876e7b5c5685ba2ff4f341b5a9', 'message': 'Support live migration with qos ports\n\nTODO:\n* deduplicate code\n* add test coverage\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 3, 'created': '2019-11-28 11:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a043bd15a933b850f43eb97d59bbcf6b031c1ee8', 'message': 'Support live migration with qos ports\n\nTODO:\n* deduplicate code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 4, 'created': '2019-11-28 14:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/254f38755851259be2d2e71762bc7460855b799c', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 5, 'created': '2019-11-29 10:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bad4cd35bf43b0a39074c839dac67ebd2543a67b', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 6, 'created': '2019-12-03 09:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/568f258ae28611e1539ffde085aabad8139276ac', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 7, 'created': '2019-12-03 11:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0cb8c8daba6501a3bc6e3a0f9bb10e74f4ce5d67', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 8, 'created': '2019-12-03 13:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a2b3ed7a6905c04a534e001e75d9086c75a4dcd', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 9, 'created': '2019-12-06 16:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5991cbf946c80349007e9228ace191e5af0aad39', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 10, 'created': '2019-12-06 17:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6131d99ee2b532b671a516d2338e37c3b4671eee', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 11, 'created': '2019-12-11 09:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d48c2bda8d580e5e581991e3d6cf85a707d88b2', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 12, 'created': '2019-12-11 09:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0109df3257d57c0b93fd1b598d3c6f982106b2ff', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nTODO:\n* do some cleanup in the port binding profile update code\n* add test coverage\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 13, 'created': '2019-12-11 16:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07051cd58e3ec866900e40ccb7bba53f2825d7c3', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 14, 'created': '2019-12-12 14:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8982293c888f10251ee03d7f472a246dd576918e', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 15, 'created': '2019-12-13 18:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/754b04431c36be74f21a11e5c8350678b0c5d777', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 16, 'created': '2019-12-14 10:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e7835a3531f41602c1b8be35ef30fd8e43ffa09', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 17, 'created': '2019-12-19 13:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61a65e35b44864c0c911b5fd8eaf003815d23761', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}, {'number': 18, 'created': '2019-12-19 13:20:31.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/conductor/tasks/live_migrate.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bd8e2fe9c80dbe39bdd03fb213148b30a9dfd36e', 'message': 'Support live migration with qos ports\n\nThis patch enhances the live_migration task in the conductor to support\nqos ports during live migration. The high level sequence of events are\nthe following:\n* when request spec is gathered before the scheduler call the resource\nrequests are collected from neutron ports and the request spec is\nupdated\n* after a successful scheduling the request group - resource provider\nmapping is calculated\n* the instance pci requests are updated to drive the pci claim on the\ntarget host to allocate VFs from the same PCI PF the bandwidth is\nallocated from\n* the inactive port binding on the target host is updated to have the RP\nUUID in the allocation key according to the resource allocation on the\ndestination host.\n\nAs the port binding is already updated in the conductor the late check\nabout the allocation key in the binding profile is turned off for live\nmigration in the neutronv2 api.\n\nNote that this patch only handles the live migration without target host\nsubsequent patches will add support for migration with target host and\nother edge case like reschedule.\n\nblueprint: support-move-ops-with-qos-ports-ussuri\n\nChange-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee\n'}]",39,695905,bd8e2fe9c80dbe39bdd03fb213148b30a9dfd36e,165,13,18,9708,,,0,"Support live migration with qos ports

This patch enhances the live_migration task in the conductor to support
qos ports during live migration. The high level sequence of events are
the following:
* when request spec is gathered before the scheduler call the resource
requests are collected from neutron ports and the request spec is
updated
* after a successful scheduling the request group - resource provider
mapping is calculated
* the instance pci requests are updated to drive the pci claim on the
target host to allocate VFs from the same PCI PF the bandwidth is
allocated from
* the inactive port binding on the target host is updated to have the RP
UUID in the allocation key according to the resource allocation on the
destination host.

As the port binding is already updated in the conductor the late check
about the allocation key in the binding profile is turned off for live
migration in the neutronv2 api.

Note that this patch only handles the live migration without target host
subsequent patches will add support for migration with target host and
other edge case like reschedule.

blueprint: support-move-ops-with-qos-ports-ussuri

Change-Id: Ibb84ea210795634f02997d4627e0beec5fea36ee
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/695905/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/conductor/tasks/live_migrate.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py']",4,b0a2204c48fcb2131bd483b31ff85c783a4041e5,bp/support-move-ops-with-qos-ports-ussuri," def _turn_off_api_check(self): # The API actively rejecting the move operations with resource # request so we have to turn off that check. # TODO(gibi): Remove this when the move operations are supported and # the API check is removed. patcher = mock.patch( 'nova.api.openstack.common.' 'supports_port_resource_request_during_move', return_value=True) self.addCleanup(patcher.stop) patcher.start() def test_live_migrate_with_qos_port(self): # TODO(gibi): remove this when live migration is fully supported and # therefore the check is removed from the api self._turn_off_api_check() non_qos_normal_port = self.neutron.port_1 qos_normal_port = self.neutron.port_with_resource_request qos_sriov_port = self.neutron.port_with_sriov_resource_request server = self._create_server_with_ports( non_qos_normal_port, qos_normal_port, qos_sriov_port) # check that the server allocates from the current host properly self._check_allocation( server, self.compute1_rp_uuid, non_qos_normal_port, qos_normal_port, qos_sriov_port, self.flavor_with_group_policy) self.api.post_server_action( server['id'], { 'os-migrateLive': { 'host': None, 'block_migration': 'auto' } } ) self._wait_for_server_parameter( self.api, server, {'OS-EXT-SRV-ATTR:host': 'host2', 'status': 'ACTIVE'}) # TODO: wait for live migrate end notification # TODO: check allocation after live migration self._delete_server_and_check_allocations( server, qos_normal_port, qos_sriov_port) # TODO(gibi): add tests for live migration cases: # * with target host # * re-schedule success # * re-schedule fail -> pci request cleanup? # * abort / cancel -> dest / pci request cleanup? ",,195,20
openstack%2Ftripleo-ansible~master~Ic30923af0630804e76323ad979e3d67ff9ae56a3,openstack/tripleo-ansible,master,Ic30923af0630804e76323ad979e3d67ff9ae56a3,"Use errors=""ignore"" instead of skip in the role template",ABANDONED,2019-12-06 22:25:00.000000000,2019-12-23 14:51:08.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-06 22:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/169c5db9846beb3e08435a361add4e62b09bf999', 'message': 'Use errors=""ignore"" instead of skip in the role template\n\nThis will fix our skeleton role so that we\'re not producing new roles\nwith a deprecation warning.\n\nChange-Id: Ic30923af0630804e76323ad979e3d67ff9ae56a3\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-12-23 14:26:14.000000000', 'files': ['_skeleton_role_/tasks/main.yml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0e25602ad79694665d894cbf8f7b296d4d8be616', 'message': 'Use errors=""ignore"" instead of skip in the role template\n\nThis will fix our skeleton role so that we\'re not producing new roles\nwith a deprecation warning.\n\nChange-Id: Ic30923af0630804e76323ad979e3d67ff9ae56a3\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,697730,0e25602ad79694665d894cbf8f7b296d4d8be616,6,2,2,7353,,,0,"Use errors=""ignore"" instead of skip in the role template

This will fix our skeleton role so that we're not producing new roles
with a deprecation warning.

Change-Id: Ic30923af0630804e76323ad979e3d67ff9ae56a3
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/30/697730/1 && git format-patch -1 --stdout FETCH_HEAD,['_skeleton_role_/tasks/main.yml.j2'],1,169c5db9846beb3e08435a361add4e62b09bf999,, - errors: ignore, - skip: true,1,1
openstack%2Fnova~master~If56842da51688476072814e6e8309cf9e0a0210c,openstack/nova,master,If56842da51688476072814e6e8309cf9e0a0210c,libvirt: flatten rbd image during cross-cell move spawn at dest,MERGED,2019-10-29 21:40:03.000000000,2019-12-23 14:34:23.000000000,2019-12-23 14:31:14.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-29 21:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1226b31d30b3529fbdcc1cdb4a72cb923ecb70b', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 2, 'created': '2019-10-29 21:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3bebdce44cc38c2d192e1326b9b942fd2070154', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 3, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/50b62154ce0d029ad9443f63057bfde744d8eb7f', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 4, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d42fa056938e75c6f7d85585b5d016961090cb89', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 5, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c9f4c9e2a0d76a1c0370efe2d5642a5043fc85e', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 6, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3511fee81260a4fd3f933cb625560609938b54f', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 7, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d32adefc569b068dc8dace4c73d6aa373b00672', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 8, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1df44958d41e31d0d61b0edcd73e34600a47f9c7', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 9, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4139b077e01e8cfd5cad9f902e5699464aae7df8', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 10, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e731a083bc4b9d193ab5715b5750f09ba59688a3', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 11, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa14c47afe4d1049a46e7ca433e6c937be73dedd', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 12, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f353eed0f525263c540d3fd4f42f58d909225c1', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 13, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63cd84315ed7a784521ae026840e1eaf24fc0ec6', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 14, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7976c535606db9194f45ce5af10080665ed41a46', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}, {'number': 15, 'created': '2019-12-12 19:07:41.000000000', 'files': ['nova/tests/unit/objects/test_migration_context.py', 'nova/virt/libvirt/driver.py', 'nova/objects/migration_context.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dae920defaeaa90bf3cac4e27d0dac41de5a1e36', 'message': ""libvirt: flatten rbd image during cross-cell move spawn at dest\n\nWhen migrating a non-volume-backed server across cells we will\ncreate a temporary snapshot image and use that to spawn the\nguest in the destination host/cell (like unshelve) and then\n_finish_snapshot_based_resize_at_dest in the ComputeManager\nwill attempt to delete the snapshot image. For rbd images,\ndeleting the snapshot image will fail if we don't flatten it\nfirst.\n\nThis builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and\nadds logic to the libvirt driver such that, like the unshelve\nscenario, if we are doing a cross-cell move we flatten the rbd\nimage so the ComputeManager can delete the temporary snapshot\nimage after the guest is spawned.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: If56842da51688476072814e6e8309cf9e0a0210c\n""}]",8,691991,dae920defaeaa90bf3cac4e27d0dac41de5a1e36,194,14,15,6873,,,0,"libvirt: flatten rbd image during cross-cell move spawn at dest

When migrating a non-volume-backed server across cells we will
create a temporary snapshot image and use that to spawn the
guest in the destination host/cell (like unshelve) and then
_finish_snapshot_based_resize_at_dest in the ComputeManager
will attempt to delete the snapshot image. For rbd images,
deleting the snapshot image will fail if we don't flatten it
first.

This builds on If3c9d1de3ce0fe394405bd1e1f0fa08ce2baeda8 and
adds logic to the libvirt driver such that, like the unshelve
scenario, if we are doing a cross-cell move we flatten the rbd
image so the ComputeManager can delete the temporary snapshot
image after the guest is spawned.

Part of blueprint cross-cell-resize

Change-Id: If56842da51688476072814e6e8309cf9e0a0210c
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/691991/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_migration_context.py', 'nova/virt/libvirt/driver.py', 'nova/objects/migration_context.py', 'nova/compute/manager.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,b1226b31d30b3529fbdcc1cdb4a72cb923ecb70b,bp/cross-cell-resize," 'migration_context': None, 'resources']: # fake_instance.fake_instance_obj drops nulls migration_context so set # it here. instance.migration_context = params.get('migration_context') def _test_noop_flatten_fetch_image_cache(self, instance): # still SHELVED_OFFLOADED or doing a cross-cell move during # _try_fetch_image_cache. def test_unshelve_noop_flatten_fetch_image_cache(self): self._test_noop_flatten_fetch_image_cache(instance) @mock.patch('nova.objects.MigrationContext.is_cross_cell_move', return_value=True) def test_cross_cell_move_noop_flatten_fetch_image_cache(self, mock_is_ccm): instance = self._create_instance( params={'migration_context': objects.MigrationContext()}) self._test_noop_flatten_fetch_image_cache(instance) mock_is_ccm.assert_called_once_with() def _test_rbd_image_flatten_during_fetch_image_cache(self, instance): # still SHELVED_OFFLOADED or doing a cross-cell move during # _try_fetch_image_cache. @mock.patch('nova.virt.libvirt.driver.LOG.debug') def test_rbd_image_flatten_during_fetch_image_cache(self, mock_debug): instance = self._create_instance( params={'vm_state': vm_states.SHELVED_OFFLOADED}) self._test_rbd_image_flatten_during_fetch_image_cache(instance) mock_debug.assert_called_once() self.assertEqual('unshelving instance', mock_debug.call_args[0][2]) @mock.patch('nova.virt.libvirt.driver.LOG.debug') @mock.patch('nova.objects.MigrationContext.is_cross_cell_move', return_value=True) def test_cross_cell_move_rbd_flatten_fetch_image_cache(self, mock_is_ccm, mock_debug): instance = self._create_instance( params={'migration_context': objects.MigrationContext()}) self._test_rbd_image_flatten_during_fetch_image_cache(instance) mock_is_ccm.assert_called_once_with() mock_debug.assert_called_once() self.assertEqual('migrating instance across cells', mock_debug.call_args[0][2]) "," 'resources', 'migration_context']: def test_unshelve_noop_flatten_fetch_image_cache(self): instance = self._create_instance( params={'vm_state': vm_states.SHELVED_OFFLOADED}) # still SHELVED_OFFLOADED during _try_fetch_image_cache. def test_unshelve_rbd_image_flatten_during_fetch_image_cache(self): # still SHELVED_OFFLOADED during _try_fetch_image_cache.",86,17
openstack%2Fmanila-ui~master~I4add35f6ca407d8c3fa8ab5bd1b96221b1f5b043,openstack/manila-ui,master,I4add35f6ca407d8c3fa8ab5bd1b96221b1f5b043,Error handling: Use exceptions.handle instead of check_message,MERGED,2019-04-23 12:16:58.000000000,2019-12-23 14:17:50.000000000,2019-12-23 14:16:38.000000000,"[{'_account_id': 841}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 19521}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-04-23 12:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/db5e23395b2930ff6605903912aed699fbb20372', 'message': '[WiP] Error handling: Remove check_message in favor of handle\n\nBecause in Horizon we already have a centralized place for handling exceptions.\n\nWe should use horizon/exceptions.py(249)handle() instead of old\nhorizon/exceptions.py(96)check_message().\n\nChange-Id: I4add35f6ca407d8c3fa8ab5bd1b96221b1f5b043\nCloses-Bug: #1339885\nDepends-On: https://review.opendev.org/652427\n'}, {'number': 2, 'created': '2019-12-23 10:41:58.000000000', 'files': ['manila_ui/dashboards/project/share_group_snapshots/tables.py', 'manila_ui/dashboards/project/share_snapshots/tables.py', 'manila_ui/dashboards/admin/share_snapshots/tables.py', 'manila_ui/dashboards/admin/share_group_snapshots/tables.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/e81a424f8715fa00e49cae902da4cd1824deaef4', 'message': 'Error handling: Use exceptions.handle instead of check_message\n\nWe already have a centralized place for handling exceptions in horizon.\nWe should use horizon/exceptions.py(249)handle() instead of old\nhorizon/exceptions.py(96)check_message().\n\nChange-Id: I4add35f6ca407d8c3fa8ab5bd1b96221b1f5b043\nCloses-Bug: #1339885\n'}]",2,655119,e81a424f8715fa00e49cae902da4cd1824deaef4,15,5,2,19521,,,0,"Error handling: Use exceptions.handle instead of check_message

We already have a centralized place for handling exceptions in horizon.
We should use horizon/exceptions.py(249)handle() instead of old
horizon/exceptions.py(96)check_message().

Change-Id: I4add35f6ca407d8c3fa8ab5bd1b96221b1f5b043
Closes-Bug: #1339885
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/19/655119/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/dashboards/project/share_group_snapshots/tables.py', 'manila_ui/dashboards/project/share_snapshots/tables.py', 'manila_ui/dashboards/admin/share_snapshots/tables.py', 'manila_ui/dashboards/admin/share_group_snapshots/tables.py']",4,db5e23395b2930ff6605903912aed699fbb20372,bug/1339885," exceptions.handle(self.request, msg)"," exceptions.check_message([""snapshots"", ""dependent""], msg % name)",4,4
openstack%2Foslo.serialization~master~Ib753a86e3d8edbe2fe4ecea83adba173f2613ca1,openstack/oslo.serialization,master,Ib753a86e3d8edbe2fe4ecea83adba173f2613ca1,tox: Trivial cleanup,MERGED,2019-12-20 10:11:02.000000000,2019-12-23 14:14:20.000000000,2019-12-23 14:13:02.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 10:11:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/350bc40cb49c5e3ae5e695265f79301bd2b4dee9', 'message': ""tox: Trivial cleanup\n\nUse the default 'install_command'\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nChange-Id: Ib753a86e3d8edbe2fe4ecea83adba173f2613ca1\n""}]",0,700143,350bc40cb49c5e3ae5e695265f79301bd2b4dee9,7,2,1,28522,,,0,"tox: Trivial cleanup

Use the default 'install_command'

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

Change-Id: Ib753a86e3d8edbe2fe4ecea83adba173f2613ca1
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/43/700143/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,350bc40cb49c5e3ae5e695265f79301bd2b4dee9,base_python,,install_command = pip install {opts} {packages},0,1
openstack%2Fkuryr-kubernetes~master~Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea,openstack/kuryr-kubernetes,master,Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea,Set defaults for certs and token on the k8s client,MERGED,2019-12-16 10:44:46.000000000,2019-12-23 14:11:28.000000000,2019-12-23 14:09:43.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-12-16 10:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/715afc34e377cd4c117714bf18500ef22b5ffbae', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 2, 'created': '2019-12-16 11:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/651f10bffd019f77e2d6ecc7291199c9132dc9de', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 3, 'created': '2019-12-18 12:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/823732d1834fbd8a8385ab7521c82dc082be4487', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 4, 'created': '2019-12-19 09:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6a39330c6cb7724d7f9854aaec9f7c94b278e64e', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 5, 'created': '2019-12-19 09:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ab1e38c8f07b76b4c0938d854c76db5dbb03579a', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 6, 'created': '2019-12-19 10:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/b9b2aa194b42d1dd1f5f7ebeee9e695f87bf778a', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 7, 'created': '2019-12-19 10:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9c5a5af250e2806643b53b32e4788a0957a97538', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 8, 'created': '2019-12-19 14:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/0f298ec5cd673262a6756f581cb1580a12b47dba', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 9, 'created': '2019-12-20 09:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/63ce9f7f7ca314e009b268a7529f9054d0d02147', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}, {'number': 10, 'created': '2019-12-20 14:10:02.000000000', 'files': ['kuryr_kubernetes/tests/unit/test_k8s_client.py', 'releasenotes/notes/k8s-client-token-default-882ec49d1faffc29.yaml', 'doc/source/installation/manual.rst', 'kuryr_kubernetes/tests/unit/cmd/test_status.py', 'kuryr_kubernetes/config.py', 'devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1e3ebc97830acba070fc81337c62292f91130a46', 'message': 'Set defaults for certs and token on the k8s client\n\nChange-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea\n'}]",3,699177,1e3ebc97830acba070fc81337c62292f91130a46,57,6,10,23567,,,0,"Set defaults for certs and token on the k8s client

Change-Id: Id74eb4d8a7b1ea7ec97085de85f29244bbda25ea
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/77/699177/9 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/tests/unit/test_k8s_client.py', 'kuryr_kubernetes/config.py', 'kuryr_kubernetes/tests/unit/cmd/test_status.py']",3,715afc34e377cd4c117714bf18500ef22b5ffbae,k8s-client-defaults," @mock.patch('kuryr_kubernetes.clients.get_kubernetes_client') @mock.patch('kuryr_kubernetes.clients.setup_kubernetes_client') def setUp(self, m_client_setup, m_client_get):", def setUp(self):,13,4
openstack%2Foslo.utils~master~I5617295e7392d9bed8881796ca5179e060aa3316,openstack/oslo.utils,master,I5617295e7392d9bed8881796ca5179e060aa3316,Ignore releasenote cache within git untracked files,MERGED,2019-12-20 10:18:06.000000000,2019-12-23 14:07:43.000000000,2019-12-23 14:06:09.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 10:18:06.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/fcee2a4f1834456412f1d4e8ec0f5aa2da29ce41', 'message': 'Ignore releasenote cache within git untracked files\n\nChange-Id: I5617295e7392d9bed8881796ca5179e060aa3316\n'}]",0,700147,fcee2a4f1834456412f1d4e8ec0f5aa2da29ce41,7,2,1,28522,,,0,"Ignore releasenote cache within git untracked files

Change-Id: I5617295e7392d9bed8881796ca5179e060aa3316
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/47/700147/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,fcee2a4f1834456412f1d4e8ec0f5aa2da29ce41,gitignore-reno,RELEASENOTES.rst releasenotes/notes/reno.cache,,2,0
openstack%2Foslo.privsep~master~Ic38130ceeaa58866b9f10a17be4baf4dbe7c8409,openstack/oslo.privsep,master,Ic38130ceeaa58866b9f10a17be4baf4dbe7c8409,tox: Trivial cleanup,ABANDONED,2019-12-22 15:53:32.000000000,2019-12-23 13:57:21.000000000,,"[{'_account_id': 15334}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 15:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/2cf97ce70844916ff36ba2c712d123c0cfab9973', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: Ic38130ceeaa58866b9f10a17be4baf4dbe7c8409\n""}, {'number': 2, 'created': '2019-12-23 13:06:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/66fbca5e030576ac71220d20c3b507af13d985e7', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: Ic38130ceeaa58866b9f10a17be4baf4dbe7c8409\n""}]",6,700349,66fbca5e030576ac71220d20c3b507af13d985e7,7,3,2,22165,,,0,"tox: Trivial cleanup

move 'basepython' to the top-level 'testenv'

Change-Id: Ic38130ceeaa58866b9f10a17be4baf4dbe7c8409
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/49/700349/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2cf97ce70844916ff36ba2c712d123c0cfab9973,,minversion = 3.1ignore_basepython_conflict = Truebasepython = python3,minversion = 2.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,3,7
openstack%2Fheat-dashboard~master~I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab,openstack/heat-dashboard,master,I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab,Generate PDF documentation,MERGED,2019-09-04 18:08:52.000000000,2019-12-23 13:56:16.000000000,2019-12-23 13:54:13.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 27336}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-09-04 18:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/5c4fc24a4f015e2fc5331cc7943a507d51556bce', 'message': '[WIP] PDF documentation build\n\nChange-Id: I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab\n'}, {'number': 2, 'created': '2019-09-05 12:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/c723869bbd0bb75b66f281440d808eab6f1d35da', 'message': '[WIP] PDF documentation build\n\nChange-Id: I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab\n'}, {'number': 3, 'created': '2019-09-05 13:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/564a2da84fbafa74130aec5a706a15824be53134', 'message': '[WIP] PDF documentation build\n\nChange-Id: I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab\n'}, {'number': 4, 'created': '2019-09-05 17:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/7902939aacfcbb3b15645fa42dd2db3eaad7fff5', 'message': '[WIP] PDF documentation build\n\nChange-Id: I1f9c3afe5d9c0e033bb053562b471fdbfb31c3ab\n'}, {'number': 5, 'created': '2019-09-11 09:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/189570ef64a9170746a52946fb3ccfbaf9efd8d7', 'message': ""[WIP] Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nStory: 2006083\nTask: 34856\n""}, {'number': 6, 'created': '2019-10-15 11:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/fcfe6a4e28f601ba0b96a7527e05dcf70650d32e', 'message': ""[WIP] Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nStory: 2006083\nTask: 34856\n""}, {'number': 7, 'created': '2019-10-15 17:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/ff8eb57f69a2b34ae23bb0f43f5433af28c56415', 'message': ""Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nStory: 2006083\nTask: 34856\n""}, {'number': 8, 'created': '2019-10-16 06:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/4e2d9e175c2885fffbd28a176ba631cc1e4899c2', 'message': ""Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nStory: 2006083\nTask: 34856\n""}, {'number': 9, 'created': '2019-10-18 08:34:34.000000000', 'files': ['doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/e0646979892bef3d1c3162aa09df3bd7722936c3', 'message': ""Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nStory: 2006083\nTask: 34856\n""}]",0,680114,e0646979892bef3d1c3162aa09df3bd7722936c3,34,7,9,29313,,,0,"Generate PDF documentation

This commit adds a new tox target to build PDF documentation.
It's a part of community goal, see storyboard for more
information.

Story: 2006083
Task: 34856
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/14/680114/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'tox.ini']",2,5c4fc24a4f015e2fc5331cc7943a507d51556bce,build-pdf-docs,[testenv:pdf-docs] basepython = python3 envdir = {toxworkdir}/docs whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,,10,1
openstack%2Fsahara-dashboard~master~Ice19d9f135ed9b0a133539f8f08e0002e406b50f,openstack/sahara-dashboard,master,Ice19d9f135ed9b0a133539f8f08e0002e406b50f,Imported Translations from Zanata,MERGED,2019-12-22 08:05:39.000000000,2019-12-23 13:49:57.000000000,2019-12-23 13:48:31.000000000,"[{'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 08:05:39.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/59f93f160cc75e9c23a53545e17c739efabf739e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ice19d9f135ed9b0a133539f8f08e0002e406b50f\n'}]",0,700314,59f93f160cc75e9c23a53545e17c739efabf739e,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ice19d9f135ed9b0a133539f8f08e0002e406b50f
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/14/700314/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,59f93f160cc75e9c23a53545e17c739efabf739e,zanata/translations,"""POT-Creation-Date: 2019-11-21 15:45+0000\n""""PO-Revision-Date: 2019-12-21 02:49+0000\n""msgid ""11.0.0-8"" msgstr ""11.0.0-8"" msgid """" ""Python 2.7 support has been dropped. Last release of sahara-dashboard to "" ""support python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by sahara-dashboard is Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Sahara-dashboard to "" ""support Python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by Sahara-dashboard is Python 3.6."" msgid ""Upgrade Notes"" msgstr ""Upgrade Notes""","""POT-Creation-Date: 2019-11-08 04:41+0000\n""""PO-Revision-Date: 2019-11-14 11:30+0000\n""",17,2
openstack%2Fkolla~stable%2Ftrain~I043e05b65622e9e9d27553c8519b40d6702964c4,openstack/kolla,stable/train,I043e05b65622e9e9d27553c8519b40d6702964c4,Bump OpenStack versions for Train,MERGED,2019-12-20 15:01:23.000000000,2019-12-23 13:28:03.000000000,2019-12-23 13:26:45.000000000,"[{'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-20 15:01:23.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/16422e1ef44239a581bbdd89ac8da7bbcd2bd5d8', 'message': 'Bump OpenStack versions for Train\n\nChange-Id: I043e05b65622e9e9d27553c8519b40d6702964c4\n'}]",0,700185,16422e1ef44239a581bbdd89ac8da7bbcd2bd5d8,8,3,1,15197,,,0,"Bump OpenStack versions for Train

Change-Id: I043e05b65622e9e9d27553c8519b40d6702964c4
",git fetch https://review.opendev.org/openstack/kolla refs/changes/85/700185/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,16422e1ef44239a581bbdd89ac8da7bbcd2bd5d8,," 'neutron-15.0.1.tar.gz')},"," 'neutron-15.0.0.tar.gz')},",1,1
openstack%2Fkolla~stable%2Frocky~I14a5398e01f590209952f768e7916f1bff4a4407,openstack/kolla,stable/rocky,I14a5398e01f590209952f768e7916f1bff4a4407,Bump OpenStack versions for Rocky,MERGED,2019-12-20 15:00:54.000000000,2019-12-23 13:03:53.000000000,2019-12-23 13:03:53.000000000,"[{'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-20 15:00:54.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8fe195b52e697cf2b51f6085aa8df0d686bc1720', 'message': 'Bump OpenStack versions for Rocky\n\nChange-Id: I14a5398e01f590209952f768e7916f1bff4a4407\n'}]",0,700183,8fe195b52e697cf2b51f6085aa8df0d686bc1720,7,3,1,15197,,,0,"Bump OpenStack versions for Rocky

Change-Id: I14a5398e01f590209952f768e7916f1bff4a4407
",git fetch https://review.opendev.org/openstack/kolla refs/changes/83/700183/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,8fe195b52e697cf2b51f6085aa8df0d686bc1720,," 'neutron-13.0.6.tar.gz')},"," 'neutron-13.0.5.tar.gz')},",1,1
openstack%2Fnova~master~Id8b82722ab46c9c97d1f59120b6a2e82e534488c,openstack/nova,master,Id8b82722ab46c9c97d1f59120b6a2e82e534488c,Add test coverage of existing admin_actions policies,MERGED,2019-05-07 22:43:49.000000000,2019-12-23 12:55:24.000000000,2019-12-23 12:53:35.000000000,"[{'_account_id': 782}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15670}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28522}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-05-07 22:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fd574f3ea8a416c10db58a7f258d7c06d09c659', 'message': 'Add functional test for admin_actions\n\nRework existing tests to use multiple context, and make a real DB query\nwith the provided context.\n\nThis is to help remove the DB level check and replace it purely with\npolicy checks in the longer term.\n\nTODO: try add system scope test, and see if it affects the tests\ncorrectly.\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 2, 'created': '2019-06-03 16:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49e01e82fc677bf54e0847f847a66c6d1abf3508', 'message': 'Add functional test for admin_actions\n\nRework existing tests to use multiple context, and make a real DB query\nwith the provided context.\n\nThis is to help remove the DB level check and replace it purely with\npolicy checks in the longer term.\n\nTODO: should we move the test now it uses the DB?\n\nblueprint policy-defaults-refresh\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 3, 'created': '2019-06-04 16:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e88b7cee835c4457e9be4cde44503b8e00aa560e', 'message': 'Add functional test for admin_actions\n\nRework existing tests to use multiple context, and make a real DB query\nwith the provided context.\n\nThis is to help remove the DB level check and replace it purely with\npolicy checks in the longer term.\n\nTODO: should we move the test now it uses the DB?\n\nblueprint policy-defaults-refresh\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 4, 'created': '2019-08-08 17:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2da25b028dda41f9a5a25c711164c7de11c5e77', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 5, 'created': '2019-08-09 06:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb6e11b9c448b1199c5115d21ef43792770c69b6', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 6, 'created': '2019-08-15 08:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc41131d73f84afea345546577af69c6fe9fe592', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 7, 'created': '2019-08-15 09:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5e8f866c6b520d8186256ae86a3d20d66330606', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 8, 'created': '2019-08-15 11:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de5556a0d3da7ec8e9796375e9b0d485fe7894e0', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 9, 'created': '2019-10-29 15:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/611933107b1fdb7677633e1142c3d8d4cdf3fb2e', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 10, 'created': '2019-10-29 20:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5e5acf4594e8414354387a9dda008ca9101d80b', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 11, 'created': '2019-10-29 20:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aac33774d94b4d70b160577643cc061e082dccea', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/train/approved/policy-default-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 12, 'created': '2019-11-26 23:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75e7946f801551d90cd3d0f99859e6e669ca96df', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 13, 'created': '2019-12-04 01:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef6a5f79686b698d627785c1e6cd96ea2315ef51', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}, {'number': 14, 'created': '2019-12-04 19:19:53.000000000', 'files': ['nova/tests/unit/policies/test_admin_actions.py', 'nova/tests/unit/api/openstack/compute/test_admin_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fcf5163ab3c32b14cbc2bab84abec8a693783935', 'message': 'Add test coverage of existing admin_actions policies\n\nCurrent tests do not have good test coverage of existing policies.\nEither tests for policies do not exist or if they exist then they\ndo not cover the actual negative and positive testing.\n\nFor Example, if any policy with default rule as admin only then\ntest should verify:\n- policy check pass with context having admin role\n- policy check fail with context having any other role than admin\n\nAs discussed in policy-defaults-refresh [1], to change the policies\nwith new default roles and scope_type, we need to have the enough\ntesting coverage of existing policy behavior.\nWhen we will add the scope_type in policies or new default roles,\nthen these test coverage will be extended to adopt the new changes\nand also make sure we do not break the existing behavior.\n\nThis commit covers the testing coverage of existing admin_actions policies.\n\nPartial implement blueprint policy-defaults-refresh\n\n[1] https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#testing\n\nChange-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c\n'}]",2,657698,fcf5163ab3c32b14cbc2bab84abec8a693783935,117,18,14,782,,,0,"Add test coverage of existing admin_actions policies

Current tests do not have good test coverage of existing policies.
Either tests for policies do not exist or if they exist then they
do not cover the actual negative and positive testing.

For Example, if any policy with default rule as admin only then
test should verify:
- policy check pass with context having admin role
- policy check fail with context having any other role than admin

As discussed in policy-defaults-refresh [1], to change the policies
with new default roles and scope_type, we need to have the enough
testing coverage of existing policy behavior.
When we will add the scope_type in policies or new default roles,
then these test coverage will be extended to adopt the new changes
and also make sure we do not break the existing behavior.

This commit covers the testing coverage of existing admin_actions policies.

Partial implement blueprint policy-defaults-refresh

[1] https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/policy-defaults-refresh.html#testing

Change-Id: Id8b82722ab46c9c97d1f59120b6a2e82e534488c
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/657698/14 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/test_admin_actions.py'],1,2fd574f3ea8a416c10db58a7f258d7c06d09c659,bp/policy-defaults-refresh,"import mock from oslo_utils.fixture import uuidsentinel as uuids from nova import contextfrom nova import objectsfrom nova.tests import fixtures as nova_fixturesfrom nova.tests.unit import policy_fixtureclass PolicyEnforcementBase(test.NoDBTestCase): USES_DB_SELF = True def setUp(self): super(PolicyEnforcementBase, self).setUp() self.policy = self.useFixture(policy_fixture.RealPolicyFixture()) self.project_id = uuids.project_id self.project_id_other = uuids.project_id_other self.legacy_admin_project = uuids.legacy_admin_project self.system_admin = context.RequestContext( ""system_admin"", None, roles=['admin'], system_scope='all') self.legacy_system_admin = context.RequestContext( ""legacy_system_admin"", self.legacy_admin_project, roles=['admin']) self.project_member = context.RequestContext( ""project_member"", self.project_id, roles=['member']) self.legacy_project_member = context.RequestContext( ""legacy_project_member"", self.project_id, roles=['foo']) self.other_project_member = context.RequestContext( ""other_project_member"", self.project_id_other, roles=['member']) self.useFixture(nova_fixtures.Database(database='api')) fix = nova_fixtures.CellDatabases() fix.add_cell_database('cell1') self.useFixture(fix) mapping = objects.CellMapping(context=self.project_member, uuid=uuids.cell_mapping, database_connection='cell1', transport_url='none:///') mapping.create() with context.target_cell(self.project_member, mapping) as cctxt: instance = objects.Instance( context=cctxt, project_id=self.project_id, uuid=uuids.fake_id) instance.create() im = objects.InstanceMapping(context=self.project_member, instance_uuid=instance.uuid, cell_mapping=mapping, project_id=self.project_id) im.create() self.fake_id = uuids.fake_id class AdminActionsPolicyEnforcementV21(PolicyEnforcementBase): def common_policy_check(self, rule_name, fun_name, req, *arg, **kwarg): def ensure_raises(req): exc = self.assertRaises( exception.PolicyNotAuthorized, func, req, *arg, **kwarg) self.assertEqual( ""Policy doesn't allow %s to be performed."" % rule_name, exc.format_message()) req.environ['nova.context'] = self.project_member ensure_raises(req) req.environ['nova.context'] = self.legacy_project_member ensure_raises(req) req.environ['nova.context'] = self.other_project_member ensure_raises(req) # TODO add required mox to make this work req.environ['nova.context'] = self.system_admin func(req, *arg, **kwarg) req.environ['nova.context'] = self.legacy_system_admin func(req, *arg, **kwarg) rule_name = ""os_compute_api:os-admin-actions:reset_network"" with mock.patch.object(self.controller.compute_api, ""reset_network""): self.common_policy_check( rule_name, ""_reset_network"", self.req, self.fake_id, body={}) rule_name = ""os_compute_api:os-admin-actions:inject_network_info"" with mock.patch.object(self.controller.compute_api, ""inject_network_info""): self.common_policy_check( rule_name, ""_inject_network_info"", self.req, self.fake_id, body={}) rule_name = ""os_compute_api:os-admin-actions:reset_state"" rule_name, ""_reset_state"", self.req,","class AdminActionsPolicyEnforcementV21(test.NoDBTestCase): self.fake_id = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' def common_policy_check(self, rule, fun_name, *arg, **kwarg): self.policy.set_rules(rule) exc = self.assertRaises( exception.PolicyNotAuthorized, func, *arg, **kwarg) self.assertEqual( ""Policy doesn't allow %s to be performed."" % rule.popitem()[0], exc.format_message()) rule = {""os_compute_api:os-admin-actions:reset_network"": ""project:non_fake""} self.common_policy_check( rule, ""_reset_network"", self.req, self.fake_id, body={}) rule = {""os_compute_api:os-admin-actions:inject_network_info"": ""project:non_fake""} self.common_policy_check( rule, ""_inject_network_info"", self.req, self.fake_id, body={}) rule = {""os_compute_api:os-admin-actions:reset_state"": ""project:non_fake""} rule, ""_reset_state"", self.req,",98,20
openstack%2Foslo.i18n~master~I28c524de7a6c29f06c042d47db5589ac64d53022,openstack/oslo.i18n,master,I28c524de7a6c29f06c042d47db5589ac64d53022,Imported Translations from Zanata,MERGED,2019-12-22 07:24:42.000000000,2019-12-23 12:52:53.000000000,2019-12-23 12:51:29.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 07:24:42.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/e154150bc7c073535f9e373604a2e8a2476baeca', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I28c524de7a6c29f06c042d47db5589ac64d53022\n'}]",0,700306,e154150bc7c073535f9e373604a2e8a2476baeca,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I28c524de7a6c29f06c042d47db5589ac64d53022
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/06/700306/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,e154150bc7c073535f9e373604a2e8a2476baeca,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-11-06 04:11+0000\n""""PO-Revision-Date: 2019-12-21 02:55+0000\n""msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" ","""POT-Creation-Date: 2018-08-13 07:24+0000\n""""PO-Revision-Date: 2018-08-13 12:05+0000\n""",9,2
openstack%2Foslo.db~master~I68d368e2e1d3eb5f0fc608b79f242a6b680570e1,openstack/oslo.db,master,I68d368e2e1d3eb5f0fc608b79f242a6b680570e1,Imported Translations from Zanata,MERGED,2019-12-22 09:28:14.000000000,2019-12-23 12:50:50.000000000,2019-12-23 12:49:08.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-22 09:28:14.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5388d22bd037380cd8101940fc416871a73ed891', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I68d368e2e1d3eb5f0fc608b79f242a6b680570e1\n'}]",0,700327,5388d22bd037380cd8101940fc416871a73ed891,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I68d368e2e1d3eb5f0fc608b79f242a6b680570e1
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/27/700327/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,5388d22bd037380cd8101940fc416871a73ed891,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-18 23:51+0000\n""""PO-Revision-Date: 2019-12-21 02:54+0000\n""msgid ""4.17.1-6"" msgstr ""4.17.1-6"" msgid ""4.25.2"" msgstr ""4.25.2"" msgid ""4.42.0"" msgstr ""4.42.0"" msgid ""5.0.0"" msgstr ""5.0.0"" msgid """" ""Added new ``.is_started`` boolean flag to enginefacade context manager and "" ""factory objects, so that double-configure scenarios can be prevented by "" ""calling code. Additionally, the ``TypeError`` raised when configure is "" ""called after the factory is started is now a specific subclass "" ""``enginefacade.AlreadyStartedError``."" msgstr """" ""Added new ``.is_started`` boolean flag to enginefacade context manager and "" ""factory objects, so that double-configure scenarios can be prevented by "" ""calling code. Additionally, the ``TypeError`` raised when configure is "" ""called after the factory is started is now a specific subclass "" ""``enginefacade.AlreadyStartedError``."" msgid ""Removed deprecated database option ``min_pool_size``."" msgstr ""Removed deprecated database option ``min_pool_size``."" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid """" ""This option had no effect and was deprecated in Rocky. For more information "" ""see bug `1764786 <https://bugs.launchpad.net/oslo.db/+bug/1764786>`_."" msgstr """" ""This option had no effect and was deprecated in Rocky. For more information "" ""see bug `1764786 <https://bugs.launchpad.net/oslo.db/+bug/1764786>`_."" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" ","""POT-Creation-Date: 2018-08-13 06:44+0000\n""""PO-Revision-Date: 2018-08-09 08:50+0000\n""",44,2
openstack%2Fvitrage-dashboard~master~I7fb589367466f37057b3cc67d367805056fdf191,openstack/vitrage-dashboard,master,I7fb589367466f37057b3cc67d367805056fdf191,Change node radius to default when searching node,MERGED,2019-12-23 11:42:09.000000000,2019-12-23 12:35:44.000000000,2019-12-23 12:34:29.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 11:42:09.000000000', 'files': ['vitrage_dashboard/dashboard/static/dashboard/project/entities/graph/entities-graph.directive.js'], 'web_link': 'https://opendev.org/openstack/vitrage-dashboard/commit/6863a5f13d0a76449526895de8195df7bea3dcd5', 'message': 'Change node radius to default when searching node\n\nWhen searching a node, the radius will be made to 14. It looks like smaller than normal.\n\nChange-Id: I7fb589367466f37057b3cc67d367805056fdf191\n'}]",0,700426,6863a5f13d0a76449526895de8195df7bea3dcd5,8,3,1,30562,,,0,"Change node radius to default when searching node

When searching a node, the radius will be made to 14. It looks like smaller than normal.

Change-Id: I7fb589367466f37057b3cc67d367805056fdf191
",git fetch https://review.opendev.org/openstack/vitrage-dashboard refs/changes/26/700426/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage_dashboard/dashboard/static/dashboard/project/entities/graph/entities-graph.directive.js'],1,6863a5f13d0a76449526895de8195df7bea3dcd5,search-node-circle-radius," .attr('r', function(item) { return circleRadius; });"," .attr('r', function(item) { return 14; });",1,1
openstack%2Fstorlets~master~I6cb87976ff4fa6caaa58cf555685f24d95f214a8,openstack/storlets,master,I6cb87976ff4fa6caaa58cf555685f24d95f214a8,Use the same python version to run storlet agents,MERGED,2019-12-18 14:39:38.000000000,2019-12-23 12:31:17.000000000,2019-12-23 08:30:23.000000000,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 14:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/3343b45507506097ab3f314edb4ab5d724dac9e6', 'message': 'Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 2, 'created': '2019-12-18 14:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/6c6b6cfc9aa92ab71003bc20c22df344d4fb1a22', 'message': 'Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 3, 'created': '2019-12-18 23:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/91c54ea0ea13effef601518f4238b34f0ffe9f91', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 4, 'created': '2019-12-19 00:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/7159ef0de426f6afaf6c35a1579bad77fc56975f', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 5, 'created': '2019-12-19 04:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/678a15ab78490aee9b48688b8dcb85ee21738ea0', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 6, 'created': '2019-12-19 04:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b9d15c92c63e86ee1e01ce788a1f8f4822e5568e', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 7, 'created': '2019-12-19 05:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/183ff7db57f8b4d1bdb596a64fb4d1b1753e0e40', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 8, 'created': '2019-12-19 05:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/131459d133b046788ea51bcad6c34c11c11c9711', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 9, 'created': '2019-12-20 12:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/68665e870c9f7cf47e51b3fc4a4b9845d01532b1', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 10, 'created': '2019-12-20 13:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/224594d8f9b98789f0f834fcaf7757fd28c5f255', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 11, 'created': '2019-12-20 14:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/302d8db7513ae3f81090c198cfe5f9a0928beb5f', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 12, 'created': '2019-12-21 02:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/68b33ce7bae75d685e62e752b73d7b5129f4ddc4', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 13, 'created': '2019-12-21 02:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b8715794943ac40afc15ff9dd46c72e49f71a9b3', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 14, 'created': '2019-12-21 23:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/d66fa20519152da5d480d8d1f7206392b534108a', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 15, 'created': '2019-12-21 23:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/17ac834907ee0b0aca436a3241cbc91f7c248abf', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 16, 'created': '2019-12-22 01:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/efb044d3b4b1ff58d2ef1165f655ff22fa039965', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 17, 'created': '2019-12-22 01:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/12271bcb9aeb9e311a7e1cc27720e3c98e4ad239', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 18, 'created': '2019-12-22 01:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/60b9884ac93e437b295e2d64b8395b86faf626e5', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 19, 'created': '2019-12-22 13:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/95d7bc93dcdd6f4203c349a8916919ca1f32ec04', 'message': 'WIP: Use devstack function for installation\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 20, 'created': '2019-12-22 13:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/8da0c7c39a3b96b7feced4ff057ad1da907788ee', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 21, 'created': '2019-12-22 23:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/9fda7a7bfcf2fda4f81e45e14cf2ffa8319fa528', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 22, 'created': '2019-12-23 00:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/9def06a034e3ba8c7951e9cd84fd9d19281bb293', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 23, 'created': '2019-12-23 00:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/f992b8f21fee68461db006786d8b998e0782bd86', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 24, 'created': '2019-12-23 00:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/d960cc0b2a04d8b0a31fd69b592022f92e336c20', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 25, 'created': '2019-12-23 01:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/cea38cfe7381333eda4eab4f4dff0c12ef0c5ec4', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 26, 'created': '2019-12-23 02:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/84d81d07c28efc915fbf1b8687b3f19cb2562c06', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 27, 'created': '2019-12-23 02:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/04020dca8826bba54abdbaa61d569a0ad7d8f5f4', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 28, 'created': '2019-12-23 02:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/0a02a5c0248421532ecef7333c721666990f4ab9', 'message': 'Refactor package installations in devstack plugin\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can use devstack functions to manage packages instead of directly\nrunnin apt-get install.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 29, 'created': '2019-12-23 03:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/15659f5baacd8654fe5e8b26d262ea242dd01908', 'message': 'Use the same python version to run storlet agents\n\nThis patch refactors package installations in storlets devstack plugin,\nso that we can run storlets agent with the same python version as the one\nwe have in host to run storlets middleware.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3 version\nfrom 3.5 to 3.6, so that we use the latest versin provided in distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}, {'number': 30, 'created': '2019-12-23 03:45:27.000000000', 'files': ['storlets/agent/common/utils.py', 'storlets/sbus/client/cli.py', 'storlets/agent/daemon/server.py', 'doc/source/engine_dev_installation.rst', 's2aio.sh', 'src/java/SBus/src/main/org/openstack/storlet/sbus/ServerSBusInDatagram.java', 'devstack/plugin.sh', 'storlets/agent/daemon_factory/server.py', 'storlets/gateway/gateways/docker/runtime.py', 'storlets/agent/common/server.py', 'install_libs.sh', 'tests/functional/java/test_thumbnail_storlet.py', 'src/java/SBus/build.xml', 'playbooks/storlets-functional/pre.yaml', 'storlets/sbus/sbus.py', 'storlets/swift_middleware/handlers/proxy.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/storlets/commit/f5815f065a8bfb91fe21dbd1e11a0ea3592673bd', 'message': 'Use the same python version to run storlet agents\n\nThis patch refactors package installations in storlets devstack\nplugin, so that we can run storlets agents with the same python\nversion as the one we have in host to run storlets middleware.\n\nThis patch also bumps up openjdk version from 8 to 11, and python3\nversion from 3.5 to 3.6, so that we use the latest versin provided\nin distro.\n\nChange-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8\n'}]",2,699693,f5815f065a8bfb91fe21dbd1e11a0ea3592673bd,59,3,30,9816,,,0,"Use the same python version to run storlet agents

This patch refactors package installations in storlets devstack
plugin, so that we can run storlets agents with the same python
version as the one we have in host to run storlets middleware.

This patch also bumps up openjdk version from 8 to 11, and python3
version from 3.5 to 3.6, so that we use the latest versin provided
in distro.

Change-Id: I6cb87976ff4fa6caaa58cf555685f24d95f214a8
",git fetch https://review.opendev.org/openstack/storlets refs/changes/93/699693/20 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3343b45507506097ab3f314edb4ab5d724dac9e6,agent-py3," if is_ubuntu; then install_package openjdk-8-jdk-headless ant else die $LINENO ""Unsupported distro"" fi if python3_enabled; then install_python3 fi pip_install .", sudo add-apt-repository -y ppa:openjdk-r/ppa sudo apt-get update sudo apt-get install -y openjdk-8-jdk-headless sudo apt-get install -y ant sudo apt-get install -y python sudo apt-get install -y python-setuptools sudo apt-get install -y python3.5 sudo apt-get install -y python3-setuptools sudo pip install -r requirements.txt sudo python setup.py install sudo pip3 install -r requirements.txt sudo python3 setup.py install sudo chown -R ${STORLETS_SWIFT_RUNTIME_USER} storlets.egg-info*,11,13
openstack%2Fstorlets~master~I98cb76e2dace3f90e82557a42984f82d1ff161fc,openstack/storlets,master,I98cb76e2dace3f90e82557a42984f82d1ff161fc,Test no USE_PYTHON3,ABANDONED,2019-12-23 07:49:41.000000000,2019-12-23 12:28:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-23 07:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/c1aa194290e0ded0ff7c77d6772d3e4fde32557b', 'message': 'Test no USE_PYTHON3\n\nChange-Id: I98cb76e2dace3f90e82557a42984f82d1ff161fc\n'}, {'number': 2, 'created': '2019-12-23 07:51:02.000000000', 'files': ['playbooks/storlets-functional/pre.yaml', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/storlets/commit/94f2640f487238c30787e25bc50d7b3850a6281c', 'message': 'Test no USE_PYTHON3\n\nChange-Id: I98cb76e2dace3f90e82557a42984f82d1ff161fc\n'}]",0,700385,94f2640f487238c30787e25bc50d7b3850a6281c,4,1,2,9816,,,0,"Test no USE_PYTHON3

Change-Id: I98cb76e2dace3f90e82557a42984f82d1ff161fc
",git fetch https://review.opendev.org/openstack/storlets refs/changes/85/700385/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/storlets-functional/pre.yaml'],1,c1aa194290e0ded0ff7c77d6772d3e4fde32557b,agent-py3,," environment: USE_PYTHON3: ""False""",0,2
openstack%2Fstorlets~master~Ib726b1dbe94818ad761e50f43460ea4138e6a2e6,openstack/storlets,master,Ib726b1dbe94818ad761e50f43460ea4138e6a2e6,DNM: Check binfile content,ABANDONED,2019-12-23 11:48:31.000000000,2019-12-23 12:28:34.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-23 11:48:31.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/storlets/commit/3e80a7a1d6829dc9f1c128d28844324bc9c05d77', 'message': 'DNM: Check binfile content\n\nChange-Id: Ib726b1dbe94818ad761e50f43460ea4138e6a2e6\n'}]",0,700428,3e80a7a1d6829dc9f1c128d28844324bc9c05d77,3,1,1,9816,,,0,"DNM: Check binfile content

Change-Id: Ib726b1dbe94818ad761e50f43460ea4138e6a2e6
",git fetch https://review.opendev.org/openstack/storlets refs/changes/28/700428/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,3e80a7a1d6829dc9f1c128d28844324bc9c05d77,dnm, sudo cat `which ${bin_file}`,,1,0
openstack%2Foslo.policy~master~Id862c601b23ddb8175f59e2136420fa3d820bc51,openstack/oslo.policy,master,Id862c601b23ddb8175f59e2136420fa3d820bc51,tox: Trivial cleanup,ABANDONED,2019-12-22 15:41:48.000000000,2019-12-23 12:19:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-12-22 15:41:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/51db08ad7b36c435c06885f86273b1d9229d545e', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: Id862c601b23ddb8175f59e2136420fa3d820bc51\n""}]",0,700344,51db08ad7b36c435c06885f86273b1d9229d545e,5,2,1,22165,,,0,"tox: Trivial cleanup

move 'basepython' to the top-level 'testenv'

Change-Id: Id862c601b23ddb8175f59e2136420fa3d820bc51
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/44/700344/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,51db08ad7b36c435c06885f86273b1d9229d545e,,minversion = 3.1ignore_basepython_conflict = Truebasepython = python3,minversion = 2.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,3,7
openstack%2Fkuryr-kubernetes~master~Ibdae122c565b294622ebdcadf2e562a37cccd4d1,openstack/kuryr-kubernetes,master,Ibdae122c565b294622ebdcadf2e562a37cccd4d1,Bump openstacksdk to 0.36.0,MERGED,2019-12-19 17:17:59.000000000,2019-12-23 12:09:50.000000000,2019-12-23 12:07:17.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2019-12-19 17:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/cd939dfb57643075e17e2fe8cc8f458fb0efd9bf', 'message': ""Bump openstacksdk to 0.36.0\n\nWe have numerous issues with openstacksdk compatibility, let's bump it\nto Train version = 0.36.0.\n\nChange-Id: Ibdae122c565b294622ebdcadf2e562a37cccd4d1\n""}, {'number': 2, 'created': '2019-12-20 11:04:26.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/fb602cd350ebb39b639aa4c71e949c8dcab96752', 'message': ""Bump openstacksdk to 0.36.0\n\nWe have numerous issues with openstacksdk compatibility, let's bump it\nto Train version = 0.36.0. Also some other deps need to be bumped too.\n\nChange-Id: Ibdae122c565b294622ebdcadf2e562a37cccd4d1\n""}]",0,700033,fb602cd350ebb39b639aa4c71e949c8dcab96752,14,5,2,11600,,,0,"Bump openstacksdk to 0.36.0

We have numerous issues with openstacksdk compatibility, let's bump it
to Train version = 0.36.0. Also some other deps need to be bumped too.

Change-Id: Ibdae122c565b294622ebdcadf2e562a37cccd4d1
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/33/700033/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,cd939dfb57643075e17e2fe8cc8f458fb0efd9bf,bump-openstacksdk,openstacksdk==0.36.0,openstacksdk==0.17.0,2,2
openstack%2Fkuryr-kubernetes~master~Iaa4d472fb4681e4d9af93561bdccdcb62ce500a0,openstack/kuryr-kubernetes,master,Iaa4d472fb4681e4d9af93561bdccdcb62ce500a0,Nested CNI: Look for leftover ifaces to remove,MERGED,2019-12-03 12:28:58.000000000,2019-12-23 12:08:40.000000000,2019-12-23 12:07:17.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 24604}, {'_account_id': 27032}, {'_account_id': 28396}]","[{'number': 1, 'created': '2019-12-03 12:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/0c4f31689c59f399bbf96dd1ecae7acd4da6b81c', 'message': ""Nested CNI: Look for leftover ifaces to remove\n\nIf kuryr-daemon was restarted during nested interface binding, after the\npod interface got created, but before returning to kubelet, such a\nrequest will get retried by kubelet. As the interface with either\nvif.vif_name or CNI request's ifname will already exist in the pod\nnamespace, the call will fail with NetlinkError: (17, 'File exists').\n\nTo prevent that this commit adds a check for such interfaces. If they\nexist - they got removed before the real binding starts.\n\nChange-Id: Iaa4d472fb4681e4d9af93561bdccdcb62ce500a0\nCloses-Bug: 1854928\n""}, {'number': 2, 'created': '2019-12-04 11:33:18.000000000', 'files': ['kuryr_kubernetes/cni/binding/bridge.py', 'kuryr_kubernetes/tests/unit/cni/test_binding.py', 'kuryr_kubernetes/cni/binding/nested.py', 'kuryr_kubernetes/cni/binding/base.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/64249af9fd4fb76864de44005ddd1ac205dea4b7', 'message': ""Nested CNI: Look for leftover ifaces to remove\n\nIf kuryr-daemon was restarted during nested interface binding, after the\npod interface got created, but before returning to kubelet, such a\nrequest will get retried by kubelet. As the interface with either\nvif.vif_name or CNI request's ifname will already exist in the pod\nnamespace, the call will fail with NetlinkError: (17, 'File exists').\n\nTo prevent that this commit adds a check for such interfaces. If they\nexist - they got removed before the real binding starts.\n\nChange-Id: Iaa4d472fb4681e4d9af93561bdccdcb62ce500a0\nCloses-Bug: 1854928\n""}]",0,697069,64249af9fd4fb76864de44005ddd1ac205dea4b7,20,8,2,11600,,,0,"Nested CNI: Look for leftover ifaces to remove

If kuryr-daemon was restarted during nested interface binding, after the
pod interface got created, but before returning to kubelet, such a
request will get retried by kubelet. As the interface with either
vif.vif_name or CNI request's ifname will already exist in the pod
namespace, the call will fail with NetlinkError: (17, 'File exists').

To prevent that this commit adds a check for such interfaces. If they
exist - they got removed before the real binding starts.

Change-Id: Iaa4d472fb4681e4d9af93561bdccdcb62ce500a0
Closes-Bug: 1854928
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/69/697069/2 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/tests/unit/cni/test_binding.py', 'kuryr_kubernetes/cni/binding/nested.py']",2,0c4f31689c59f399bbf96dd1ecae7acd4da6b81c,bug/1854928,"from oslo_log import log as logging LOG = logging.getLogger(__name__) def _remove_ifaces(self, ipdb, ifnames, netns='host'): for ifname in ifnames: if ifname in ipdb.interfaces: LOG.warning('Found hanging interface %(ifname)s inside ' '%(netns)s netns. Most likely it is a leftover ' 'from a kuryr-daemon restart. Trying to delete ' 'it.', {'ifname': ifname, 'netns': netns}) with ipdb.interfaces[ifname] as iface: iface.remove() def connect(self, vif, ifname, netns, container_id): # NOTE(vikasc): Ideally 'ifname' should be used here but instead a # temporary name is being used while creating the device for # container in host network namespace. This is because cni expects # only 'eth0' as interface name and if host already has an # interface named 'eth0', device creation will fail with 'already # exists' error. temp_name = vif.vif_name # First let's take a peek into the pod namespace and try to remove any # leftover interface in case we got restarted before CNI returned to # kubelet. with b_base.get_ipdb(netns) as c_ipdb: self._remove_ifaces(c_ipdb, (temp_name, ifname), netns) with b_base.get_ipdb() as h_ipdb: # We might also have leftover interface in the host netns, let's # try to remove it too. self._remove_ifaces(h_ipdb, (temp_name,)) "," def connect(self, vif, ifname, netns, container_id): with b_base.get_ipdb() as h_ipdb: # NOTE(vikasc): Ideally 'ifname' should be used here but instead a # temporary name is being used while creating the device for # container in host network namespace. This is because cni expects # only 'eth0' as interface name and if host already has an # interface named 'eth0', device creation will fail with 'already # exists' error. temp_name = vif.vif_name ",35,11
openstack%2Fironic-python-agent-builder~master~Ib3f6e24d0687e9da8e551355fe04faf3f86ff582,openstack/ironic-python-agent-builder,master,Ib3f6e24d0687e9da8e551355fe04faf3f86ff582,Be a bit more verbose around tinyipa for rescue,MERGED,2019-12-17 14:25:30.000000000,2019-12-23 12:03:07.000000000,2019-12-23 12:01:35.000000000,"[{'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-12-17 14:25:30.000000000', 'files': ['tinyipa/build_files/bootlocal.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/e28167a8f51d06ca09b6dbd7b71e78a135731d7c', 'message': ""Be a bit more verbose around tinyipa for rescue\n\nSeems we have no real way to grok if there was a rescue setup failure\nbecause we don't log any information to the console about the node\nonce dhcp has occured.\n\nAs such, added an additional line of text to be logged and added\nthe ip addr command which should save a list of addresses by\ninterface to the console to assist in CI job troubleshooting.\n\nChange-Id: Ib3f6e24d0687e9da8e551355fe04faf3f86ff582\n""}]",0,699427,e28167a8f51d06ca09b6dbd7b71e78a135731d7c,16,5,1,11655,,,0,"Be a bit more verbose around tinyipa for rescue

Seems we have no real way to grok if there was a rescue setup failure
because we don't log any information to the console about the node
once dhcp has occured.

As such, added an additional line of text to be logged and added
the ip addr command which should save a list of addresses by
interface to the console to assist in CI job troubleshooting.

Change-Id: Ib3f6e24d0687e9da8e551355fe04faf3f86ff582
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/27/699427/1 && git format-patch -1 --stdout FETCH_HEAD,['tinyipa/build_files/bootlocal.sh'],1,e28167a8f51d06ca09b6dbd7b71e78a135731d7c,," echo ""Completed DHCP client restart"" ip addr && true",,2,0
openstack%2Fec2-api~master~I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50,openstack/ec2-api,master,I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50,Add links to readme Change-Id: I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50,ABANDONED,2019-12-23 11:02:42.000000000,2019-12-23 11:29:40.000000000,,[],"[{'number': 1, 'created': '2019-12-23 11:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/af26b9ab380932529378dae3beb086e60516c8b0', 'message': 'Add links to readme\n\nChange-Id: I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50\n'}, {'number': 2, 'created': '2019-12-23 11:09:58.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/615c1c51d95d41b2715fd31f7cc952f346fb25a1', 'message': 'Add links to readme\nChange-Id: I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50\n'}]",0,700421,615c1c51d95d41b2715fd31f7cc952f346fb25a1,3,0,2,31027,,,0,"Add links to readme
Change-Id: I0c8c0f3ddd3fa9933c02f237845bd4f555cc4e50
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/21/700421/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,af26b9ab380932529378dae3beb086e60516c8b0,,Wiki: https://wiki.openstack.org/wiki/EC2API Bugs: https://launchpad.net/ec2-api Source: https://opendev.org/openstack/ec2-api ,,9,0
openstack%2Fmistral~master~I492ccaa876c25cdb434858cb215cc94ae5b65972,openstack/mistral,master,I492ccaa876c25cdb434858cb215cc94ae5b65972,Use MISTRAL_SERVICE_HOST as the host ip for standalone,MERGED,2019-12-19 11:44:45.000000000,2019-12-23 11:07:03.000000000,2019-12-23 11:05:25.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-19 11:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/348dcb4a01f1f59be4621bf607e43f37fbb0fb35', 'message': 'Use MISTRAL_SERVICE_HOST as the host ip for standalone\n\nThe default 0.0.0.0 will be good only ipv4\nfor ipv6 gate will fail. MISTRAL_SERVICE_HOST has always\nthe right ip, it is also used in apache mode so lets use\nit also in standalone mode.\n\nChange-Id: I492ccaa876c25cdb434858cb215cc94ae5b65972\n'}, {'number': 2, 'created': '2019-12-23 06:17:46.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/mistral/commit/e03fa281b0ffcede9f12ba08b1ee295fcfb83e29', 'message': 'Use MISTRAL_SERVICE_HOST as the host ip for standalone\n\nThe default 0.0.0.0 will be good only ipv4\nfor ipv6 gate will fail. MISTRAL_SERVICE_HOST has always\nthe right ip, it is also used in apache mode so lets use\nit also in standalone mode.\n\nChange-Id: I492ccaa876c25cdb434858cb215cc94ae5b65972\n'}]",0,699959,e03fa281b0ffcede9f12ba08b1ee295fcfb83e29,15,2,2,19134,,,0,"Use MISTRAL_SERVICE_HOST as the host ip for standalone

The default 0.0.0.0 will be good only ipv4
for ipv6 gate will fail. MISTRAL_SERVICE_HOST has always
the right ip, it is also used in apache mode so lets use
it also in standalone mode.

Change-Id: I492ccaa876c25cdb434858cb215cc94ae5b65972
",git fetch https://review.opendev.org/openstack/mistral refs/changes/59/699959/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,348dcb4a01f1f59be4621bf607e43f37fbb0fb35,ipv6, # Don't use the default 0.0.0.0 it's good only for ipv4 iniset $MISTRAL_CONF_FILE api host $MISTRAL_SERVICE_HOST ,,3,0
openstack%2Fpuppet-tripleo~master~Ib34304dada25a0be1a39f508119adbe9cca4d66f,openstack/puppet-tripleo,master,Ib34304dada25a0be1a39f508119adbe9cca4d66f,Avoid failing on rsyslog,MERGED,2019-12-02 11:20:04.000000000,2019-12-23 10:59:03.000000000,2019-12-04 18:24:25.000000000,"[{'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-02 11:20:04.000000000', 'files': ['manifests/profile/base/logging/rsyslog/file_input.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1207666e173543b63fbd76728553b31274399576', 'message': 'Avoid failing on rsyslog\n\nThis patch makes deployment pass when value of hiera variable\ntripleo_logging_sources_<enabled_service> is undef. This case should\ntechnically not happen, but currently enabled_services contains\nservices which are not being deployed, so we need to make sure that\nPuppet does not fail in this case.\n\nChange-Id: Ib34304dada25a0be1a39f508119adbe9cca4d66f\n'}]",0,696864,1207666e173543b63fbd76728553b31274399576,20,5,1,5241,,,0,"Avoid failing on rsyslog

This patch makes deployment pass when value of hiera variable
tripleo_logging_sources_<enabled_service> is undef. This case should
technically not happen, but currently enabled_services contains
services which are not being deployed, so we need to make sure that
Puppet does not fail in this case.

Change-Id: Ib34304dada25a0be1a39f508119adbe9cca4d66f
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/64/696864/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/logging/rsyslog/file_input.pp'],1,1207666e173543b63fbd76728553b31274399576,," if $sources { $rsyslog_sources = $sources.reduce([]) |$memo, $config| { if ! $config['startmsg.regex'] { $record = $config + {'startmsg.regex' => $default_startmsg} } else { $record = $config } $memo + [$record] } $rsyslog_sources.each |$config| { rsyslog::component::input{ ""${title}_${config['tag']}"": priority => $::rsyslog::input_priority, target => $::rsyslog::target_file, confdir => $::rsyslog::confdir, type => 'imfile', config => $config }"," $rsyslog_sources = $sources.reduce([]) |$memo, $config| { if ! $config['startmsg.regex'] { $record = $config + {'startmsg.regex' => $default_startmsg} } else { $record = $config } $memo + [$record] } $rsyslog_sources.each |$config| { rsyslog::component::input{ ""${title}_${config['tag']}"": priority => $::rsyslog::input_priority, target => $::rsyslog::target_file, confdir => $::rsyslog::confdir, type => 'imfile', config => $config",16,14
openstack%2Ftripleo-heat-templates~master~I7fe6456a1d2a3ba4300a82c57b76774152422250,openstack/tripleo-heat-templates,master,I7fe6456a1d2a3ba4300a82c57b76774152422250,Fix rsyslog issues,MERGED,2019-11-27 15:33:31.000000000,2019-12-23 10:58:24.000000000,2019-12-04 21:35:33.000000000,"[{'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 6926}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-27 15:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/50c142b5519b5fcd44562a848e439e85a6961809', 'message': ""Fix rsyslog issues\n\nThis patch is fixing following issues, which makes rsyslog service\nto fail to start successfully:\n\n- Changes LoggingSource configuration key 'path' to 'file' for various services\n- Fixes LoggingSource configuration key 'startmsg.regex' for pacemaker\n- Removes nonexistent log files from LoggingSource of keystone\n\nChange-Id: I7fe6456a1d2a3ba4300a82c57b76774152422250\n""}, {'number': 2, 'created': '2019-12-03 18:53:31.000000000', 'files': ['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/neutron/neutron-l2gw-agent-baremetal-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml', 'deployment/heat/heat-api-cfn-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/logging/rsyslog-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cdda44028a5895438ef7fbabc10f23579db773f6', 'message': ""Fix rsyslog issues\n\nThis patch is fixing following issues, which makes rsyslog service\nto fail to start successfully:\n\n- Changes LoggingSource configuration key 'path' to 'file' for various services\n- Fixes LoggingSource configuration key 'startmsg.regex' for pacemaker\n- Removes nonexistent log files from LoggingSource of keystone\n\nChange-Id: I7fe6456a1d2a3ba4300a82c57b76774152422250\n""}]",0,696328,cdda44028a5895438ef7fbabc10f23579db773f6,26,6,2,5241,,,0,"Fix rsyslog issues

This patch is fixing following issues, which makes rsyslog service
to fail to start successfully:

- Changes LoggingSource configuration key 'path' to 'file' for various services
- Fixes LoggingSource configuration key 'startmsg.regex' for pacemaker
- Removes nonexistent log files from LoggingSource of keystone

Change-Id: I7fe6456a1d2a3ba4300a82c57b76774152422250
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/28/696328/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/neutron/neutron-l2gw-agent-baremetal-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml', 'deployment/heat/heat-api-cfn-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/logging/rsyslog-container-puppet.yaml']",9,50c142b5519b5fcd44562a848e439e85a6961809,rsyslog-fixes," dynSearchIndex: ""on"" errorfile: '/var/log/rsyslog/omelasticsearch.log' - /var/log:/var/log/host:ro", dynSearchIndex: on errorfile: '/var/log/rsyslog-omelasticsearch.log',11,46
openstack%2Ftripleo-heat-templates~master~I85c45d442392b3c94840a9459f506c2ad9be0f0c,openstack/tripleo-heat-templates,master,I85c45d442392b3c94840a9459f506c2ad9be0f0c,Fix typos in hiera values,MERGED,2019-12-17 20:36:43.000000000,2019-12-23 10:57:30.000000000,2019-12-19 19:39:20.000000000,"[{'_account_id': 3153}, {'_account_id': 4264}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-12-17 20:36:43.000000000', 'files': ['environments/metrics/qdr-edge-only.yaml', 'environments/metrics/collectd-write-qdr.yaml', 'environments/metrics/qdr-form-controller-mesh.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0bbd78b5b22a5acf8f91df4ea8fb5c91c7212f73', 'message': 'Fix typos in hiera values\n\nThis patch wraps hiera evaluation values with %{} so they are really evaluated.\n\nChange-Id: I85c45d442392b3c94840a9459f506c2ad9be0f0c\n'}]",0,699493,0bbd78b5b22a5acf8f91df4ea8fb5c91c7212f73,10,6,1,5241,,,0,"Fix typos in hiera values

This patch wraps hiera evaluation values with %{} so they are really evaluated.

Change-Id: I85c45d442392b3c94840a9459f506c2ad9be0f0c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/93/699493/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/metrics/qdr-edge-only.yaml', 'environments/metrics/collectd-write-qdr.yaml', 'environments/metrics/qdr-form-controller-mesh.yaml']",3,0bbd78b5b22a5acf8f91df4ea8fb5c91c7212f73,typo," tripleo::profile::base::metrics::qdr::listener_addr: ""%{hiera(hiera('block_storage_hostname_resolve_network'))}"" CephStorageExtraConfig: tripleo::profile::base::metrics::qdr::listener_addr: ""%{hiera(hiera('ceph_storage_hostname_resolve_network'))}"" ObjectStorageExtraConfig: tripleo::profile::base::metrics::qdr::listener_addr: ""%{hiera(hiera('object_storage_hostname_resolve_network'))}"""," tripleo::profile::base::metrics::qdr::listener_addr: ""hiera(hiera('block_storage_hostname_resolve_network'))"" CephStorageExtraConfig: tripleo::profile::base::metrics::qdr::listener_addr: ""hiera(hiera('ceph_storage_hostname_resolve_network'))"" ObjectStorageExtraConfig: tripleo::profile::base::metrics::qdr::listener_addr: ""hiera(hiera('object_storage_hostname_resolve_network'))""",9,9
openstack%2Fpuppet-tripleo~master~Ifb839a9c0d8ffca8a97a0cc97bfc4d3319e17e48,openstack/puppet-tripleo,master,Ifb839a9c0d8ffca8a97a0cc97bfc4d3319e17e48,Fix typo in sslProfile conditional,MERGED,2019-12-17 20:28:52.000000000,2019-12-23 10:57:20.000000000,2019-12-23 01:21:38.000000000,"[{'_account_id': 3153}, {'_account_id': 4264}, {'_account_id': 5241}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-17 20:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e96dda7d1a57f8eaa2242d062be8f3f810050aaf', 'message': 'Fix typo in sslProfile conditional\n\nThe fixed typo is causing conditional to be always true.\n\nChange-Id: Ifb839a9c0d8ffca8a97a0cc97bfc4d3319e17e48\n'}, {'number': 2, 'created': '2019-12-20 23:28:44.000000000', 'files': ['manifests/profile/base/metrics/qdr.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f315d749a5cb082c5120a4f6d1821b7b727802ac', 'message': 'Fix typo in sslProfile conditional\n\nThe fixed typo is causing conditional to be always true.\n\nDepends-On: https://review.opendev.org/700250\nChange-Id: Ifb839a9c0d8ffca8a97a0cc97bfc4d3319e17e48\n'}]",0,699491,f315d749a5cb082c5120a4f6d1821b7b727802ac,35,6,2,5241,,,0,"Fix typo in sslProfile conditional

The fixed typo is causing conditional to be always true.

Depends-On: https://review.opendev.org/700250
Change-Id: Ifb839a9c0d8ffca8a97a0cc97bfc4d3319e17e48
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/91/699491/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/metrics/qdr.pp'],1,e96dda7d1a57f8eaa2242d062be8f3f810050aaf,typo, if $ssl_internal_profile_name {, if ssl_internal_profile_name {,1,1
openstack%2Fcontributor-guide~master~I919b34444cc280b859bbab5e24e91be23e5dcc60,openstack/contributor-guide,master,I919b34444cc280b859bbab5e24e91be23e5dcc60,Imported Translations from Zanata,MERGED,2019-12-23 09:09:52.000000000,2019-12-23 10:22:11.000000000,2019-12-23 10:20:18.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 09:09:52.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc-code-and-documentation.po'], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/be4ce98dcf3eabc7c8f71aebe353ba9993aa7e7a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I919b34444cc280b859bbab5e24e91be23e5dcc60\n'}]",0,700398,be4ce98dcf3eabc7c8f71aebe353ba9993aa7e7a,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I919b34444cc280b859bbab5e24e91be23e5dcc60
",git fetch https://review.opendev.org/openstack/contributor-guide refs/changes/98/700398/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/en_GB/LC_MESSAGES/doc-code-and-documentation.po'],1,be4ce98dcf3eabc7c8f71aebe353ba9993aa7e7a,zanata/translations,"""POT-Creation-Date: 2019-12-22 09:21+0000\n""""PO-Revision-Date: 2019-12-22 08:10+0000\n""msgid ""...and *amend* the current commit"" msgstr ""...and *amend* the current commit"" msgid ""...and tell ``git-restack`` to proceed"" msgstr ""...and tell ``git-restack`` to proceed"" ""After proposing changes, you can track them at `Code Review <https://review."" ""opendev.org>`_. After logging in, you will see a dashboard of \""Outgoing "" ""reviews\"" for changes you have proposed, \""Incoming reviews\"" for changes "" ""you are reviewing, and \""Recently closed\"" changes for which you were either "" ""a reviewer or owner."" msgstr """" ""After proposing changes, you can track them at `Code Review <https://review."" ""opendev.org>`_. After logging in, you will see a dashboard of \""Outgoing "" ""reviews\"" for changes you have proposed, \""Incoming reviews\"" for changes "" ""you are reviewing, and \""Recently closed\"" changes for which you were either "" ""a reviewer or owner."" msgid """"""At this point, I push my series up to gerrit. Note that it makes me confirm "" ""that I really want to push two commits at once."" msgstr """" ""At this point, I push my series up to gerrit. Note that it makes me confirm "" ""that I really want to push two commits at once."" msgid """"""But I want to edit ``d76195e``, while leaving ``f17f040`` properly stacked "" ""on top of it. Here I use a tool called `git-restack <https://docs.openstack."" ""org/infra/git-restack/>`_ (run ``pip install git-restack`` to install it)."" msgstr """" ""But I want to edit ``d76195e``, while leaving ``f17f040`` properly stacked "" ""on top of it. Here I use a tool called `git-restack <https://docs.openstack."" ""org/infra/git-restack/>`_ (run ``pip install git-restack`` to install it)."" msgid """" ""But oops, I made a mistake in my first commit. My lower constraint can't be "" ""higher than my minimum in ``requirements.txt``. If I still had my branch "" ""locally, I could skip this next step, but as a matter of rigor to avoid some "" ""common pratfalls, I will pull the whole series afresh from gerrit by asking "" ""``git-review`` to grab the *top* change:"" msgstr """" ""But oops, I made a mistake in my first commit. My lower constraint can't be "" ""higher than my minimum in ``requirements.txt``. If I still had my branch "" ""locally, I could skip this next step, but as a matter of rigor to avoid some "" ""common pratfalls, I will pull the whole series afresh from Gerrit by asking "" ""``git-review`` to grab the *top* change:"" msgid """"msgid ""Find your project in the file."" msgstr ""Find your project in the file."" ""For a more in-depth look at managing patch chains, see :doc:`/code-and-"" ""documentation/patch-series-tutorial`."" msgstr """" ""For a more in-depth look at managing patch chains, see :doc:`/code-and-"" ""documentation/patch-series-tutorial`."" msgid """" ""For the project documents to be linked to on the `OpenStack documentation "" ""portal`_, the ``www/project-data/latest.yaml`` file in the ``openstack-"" ""manuals`` repository has to be updated, following the rules of the `template "" ""generator`_."" msgstr """" ""For the project documents to be linked to on the `OpenStack documentation "" ""portal`_, the ``www/project-data/latest.yaml`` file in the ``openstack-"" ""manuals`` repository has to be updated, following the rules of the `template "" ""generator`_."" msgid """"msgid """" ""Gerrit also provides you options to edit the patch itself or only the commit "" ""message and a few more for more advanced changes, like modifying the author."" msgstr """" ""Gerrit also provides you options to edit the patch itself or only the commit "" ""message and a few more for more advanced changes, like modifying the author."" msgid ""Here we go."" msgstr ""Here we go."" msgid ""I fix ``lower-constraints.txt``:"" msgstr ""I fix ``lower-constraints.txt``:"" msgid """" ""I just made commit ``d76195e`` on top of ``3d008a3``. You'll notice my "" ""branch name (``bp/nova-cyborg-interaction``) came along with me."" msgstr """" ""I just made commit ``d76195e`` on top of ``3d008a3``. You'll notice my "" ""branch name (``bp/nova-cyborg-interaction``) came along with me."" msgid ""I want to fix the first one, so I change ``pick`` to ``edit``:"" msgstr ""I want to fix the first one, so I change ``pick`` to ``edit``:"" msgid """" ""If I had a taller series, and I had changed ``pick`` to ``edit`` for more "" ""than one commit, I would now be sitting on the next one I needed to edit. As "" ""it is, that was the only thing I needed to do, so I'm done and sitting on "" ""the top of my series again."" msgstr """" ""If I had a taller series, and I had changed ``pick`` to ``edit`` for more "" ""than one commit, I would now be sitting on the next one I needed to edit. As "" ""it is, that was the only thing I needed to do, so I'm done and sitting on "" ""the top of my series again."" ""If the above structure exists in the project repository and the ``latest."" ""yaml`` file is updated, the ``publish-openstack-sphinx-docs`` job in the "" ""``project-config`` repo automatically includes the document in the published "" ""documentation. For detailed instructions, see the `Project guide setup`_."" msgstr """" ""If the above structure exists in the project repository and the ``latest."" ""yaml`` file is updated, the ``publish-openstack-sphinx-docs`` job in the "" ""``project-config`` repo automatically includes the document in the published "" ""documentation. For detailed instructions, see the `Project guide setup`_."" msgid """" ""If you are a visual learner, you may prefer `this video <https://www.youtube."" ""com/watch?v=mHyvP7zp4Ko&list=PLR97FKPZ-mD9XJCfwDE5c-td9lZGIPfS5&index=4>`_ "" ""which does roughly the same thing (but without ``git-restack``)."" msgstr """" ""If you are a visual learner, you may prefer `this video <https://www.youtube."" ""com/watch?v=mHyvP7zp4Ko&list=PLR97FKPZ-mD9XJCfwDE5c-td9lZGIPfS5&index=4>`_ "" ""which does roughly the same thing (but without ``git-restack``)."" msgid """"""It is possible to check out other contributors' patches from Gerrit and even "" ""`make changes to them <https://docs.openstack.org/project-team-guide/review-"" ""the-openstack-way.html#modifying-a-change>`_; however, you should always "" ""discuss any changes with the contributor before you start working on their "" ""patch."" msgstr """" ""It is possible to check out other contributors' patches from Gerrit and even "" ""`make changes to them <https://docs.openstack.org/project-team-guide/review-"" ""the-openstack-way.html#modifying-a-change>`_; however, you should always "" ""discuss any changes with the contributor before you start working on their "" ""patch."" msgid """"msgid ""Launchpad is deprecated and will be superceded by StoryBoard."" msgstr ""Launchpad is deprecated and will be superceded by StoryBoard."" ""Most often, some deadline has passed and since no more changes are being "" ""accepted till the new release development begins, the patch is `being held "" ""<https://docs.openstack.org/project-team-guide/review-the-openstack-way."" ""html#procedural-minus-2>`_."" msgstr """" ""Most often, some deadline has passed and since no more changes are being "" ""accepted till the new release development begins, the patch is `being held "" ""<https://docs.openstack.org/project-team-guide/review-the-openstack-way."" ""html#procedural-minus-2>`_."" msgid """" ""Notice that the commit hashes have changed for *both* commits (but not for "" ""``master``). The top one changed because it got rebased onto the new version "" ""of the middle one."" msgstr """" ""Notice that the commit hashes have changed for *both* commits (but not for "" ""``master``). The top one changed because it got rebased onto the new version "" ""of the middle one."" msgid """" ""Now I'm going to make another change, but just part of it, a work-in-"" ""progress commit:"" msgstr """" ""Now I'm going to make another change, but just part of it, a work-in-"" ""progress commit:"" msgid """" ""Now I'm sitting on the top change (which you'll notice happens to be exactly "" ""the same as before I pushed it - again, meaning I could technically have "" ""just worked from where I was, but see above):"" msgstr """" ""Now I'm sitting on the top change (which you'll notice happens to be exactly "" ""the same as before I pushed it - again, meaning I could technically have "" ""just worked from where I was, but see above):"" msgid """" ""Now commit ``f17f040`` is on top of ``d76195e``, which is still on top of "" ""``3d008a3`` (aka ``master``). Note that my branch name came with me again."" msgstr """" ""Now commit ``f17f040`` is on top of ``d76195e``, which is still on top of "" ""``3d008a3`` (aka ``master``). Note that my branch name came with me again."" msgid """" ""Now if I push the series back up to gerrit, I get the same confirmation "" ""prompt, and both changes get a new patch set. If you look at the top patch "" ""in gerrit, you'll see that patch set 2 shows up as just a rebase."" msgstr """" ""Now if I push the series back up to Gerrit, I get the same confirmation "" ""prompt, and both changes get a new patch set. If you look at the top patch "" ""in Gerrit, you'll see that patch set 2 shows up as just a rebase."" msgid """" ""Now if you go to either of those links - e.g. https://review.opendev.org/#/"" ""c/635342/ - you'll see that the patches are stacked up in series on the top "" ""right."" msgstr """" ""Now if you go to either of those links - e.g. https://review.opendev.org/#/"" ""c/635342/ - you'll see that the patches are stacked up in series on the top "" ""right."" msgid """"""Once you've identified a message in the logs that can be used for "" ""fingerprinting you need to turn that into an elastic-search query. You can "" ""use any of the existing fingerprints as an example: `opendev/elastic-recheck "" ""<https://opendev.org/opendev/elastic-recheck/src/queries>`_"" msgstr """" ""Once you've identified a message in the logs that can be used for "" ""fingerprinting you need to turn that into an elastic-search query. You can "" ""use any of the existing fingerprints as an example: `opendev/elastic-recheck "" ""<https://opendev.org/opendev/elastic-recheck/src/queries>`_"" msgid """"msgid ""Publishing documents in project repositories"" msgstr ""Publishing documents in project repositories"" msgid ""Reference documents"" msgstr ""Reference documents"" ""Reviewing changes is often suggested as a way to get started on a project. "" ""Whether this is how you choose to get started or not, it's an important "" ""community activity. See `How to Review Changes the OpenStack Way <https://"" ""docs.openstack.org/project-team-guide/review-the-openstack-way.html>`_ for "" ""more detailed guidance on when to use which votes on a change review."" msgstr """" ""Reviewing changes is often suggested as a way to get started on a project. "" ""Whether this is how you choose to get started or not, it's an important "" ""community activity. See `How to Review Changes the OpenStack Way <https://"" ""docs.openstack.org/project-team-guide/review-the-openstack-way.html>`_ for "" ""more detailed guidance on when to use which votes on a change review."" msgid """"msgid ""Sandbox Git Repository"" msgstr ""Sandbox Git Repository"" msgid ""Sandbox Project on Launchpad"" msgstr ""Sandbox Project on Launchpad"" msgid ""Save and quit the editor, and I see:"" msgstr ""Save and quit the editor, and I see:"" msgid ""Set to 'true' all document options that apply. For example::"" msgstr ""Set to 'true' all document options that apply. For example::"" msgid ""So let's say I make an edit for my first patch and commit it:"" msgstr ""So let's say I make an edit for my first patch and commit it:"" msgid ""Start on a freshly-``pull``\\ed master branch:"" msgstr ""Start on a freshly-``pull``\\ed master branch:"" ""The ``reference`` directory contains reference information not included in "" ""the other directories, for instance, automatically generated class "" ""documentation in library projects."" msgstr """" ""The ``reference`` directory contains reference information not included in "" ""the other directories, for instance, automatically generated class "" ""documentation in library projects."" msgid """"msgid """" ""This pops me into an editor showing me all the commits between wherever I am "" ""and the main branch (now they're in top-first order):"" msgstr """" ""This pops me into an editor showing me all the commits between wherever I am "" ""and the main branch (now they're in top-first order):"" ""This tutorial walks through a simple scenario of developing multiple change "" ""sets in a series on the same branch. If you wish, you can follow along, "" ""using the `sandbox repository <https://opendev.org/openstack-dev/sandbox/"" "">`_, executing the commands exactly as they're laid out."" msgstr """" ""This tutorial walks through a simple scenario of developing multiple change "" ""sets in a series on the same branch. If you wish, you can follow along, "" ""using the `sandbox repository <https://opendev.org/openstack-dev/sandbox/"" "">`_, executing the commands exactly as they're laid out."" msgid """"msgid ""Tutorial: Developing Changes In A Series"" msgstr ""Tutorial: Developing Changes In A Series"" ""When you ``git commit`` (without ``--amend``), you're creating a new commit "" ""on top of whatever commit you started at. If you started with a clean, "" ""freshly ``pull``\\ed master branch, that'll be whatever the most recently "" ""merged commit in the master branch was. In this example, that's commit "" ""``3d008a3``."" msgstr """" ""When you ``git commit`` (without ``--amend``), you're creating a new commit "" ""on top of whatever commit you started at. If you started with a clean, "" ""freshly ``pull``\\ed master branch, that'll be whatever the most recently "" ""merged commit in the master branch was. In this example, that's commit "" ""``3d008a3``."" msgid """"""When you're working on a blueprint, you want to name your local branch after "" ""the blueprint. For this example, we'll use ``bp/nova-cyborg-interaction``."" msgstr """" ""When you're working on a blueprint, you want to name your local branch after "" ""the blueprint. For this example, we'll use ``bp/nova-cyborg-interaction``."" msgid """"msgid """" ""You can find a `sandbox Git repository <https://opendev.org/openstack-dev/"" ""sandbox>`_ where you can practice the Git commands before you put together a "" ""patch to resolve a bug or implement a new functionality."" msgstr """" ""You can find a `sandbox Git repository <https://opendev.org/openstack-dev/"" ""sandbox>`_ where you can practice the Git commands before you put together a "" ""patch to resolve a bug or implement a new functionality."" msgid """" ""You can find the same repositories using the search function here: `OpenDev "" ""git repository browser <https://opendev.org/explore/repos>`_"" msgstr """" ""You can find the same repositories using the search function here: `OpenDev "" ""git repository browser <https://opendev.org/explore/repos>`_"" ""You need as many '^' as the number of the patch you want to edit first from "" ""the top of the chain. Alternatively you may wish to use `git-restack "" ""<https://docs.openstack.org/infra/git-restack/>`_, which figures out the "" ""appropriate ``git rebase`` command for you."" msgstr """" ""You need as many '^' as the number of the patch you want to edit first from "" ""the top of the chain. Alternatively you may wish to use `git-restack "" ""<https://docs.openstack.org/infra/git-restack/>`_, which figures out the "" ""appropriate ``git rebase`` command for you."" msgid """"msgid """" ""elastic-recheck is built on top of an ELK (`Elastic Search <https://github."" ""com/elastic/elasticsearch>`_, `Logstash <https://github.com/elastic/"" ""logstash>`_, `Kibana <https://github.com/elastic/kibana>`_) stack where we "" ""use Logstash to store all logs from CI jobs in an Elastic Search cluster. We "" ""also host a `Kibana dashboard <http://logstash.openstack.org/>`_ which can "" ""be used to run queries on the cluster and interacts with the data. elastic-"" ""recheck queries the elastic-search cluster for the fingerprints."" msgstr """" ""elastic-recheck is built on top of an ELK (`Elastic Search <https://github."" ""com/elastic/elasticsearch>`_, `Logstash <https://github.com/elastic/"" ""logstash>`_, `Kibana <https://github.com/elastic/kibana>`_) stack where we "" ""use Logstash to store all logs from CI jobs in an Elastic Search cluster. We "" ""also host a `Kibana dashboard <http://logstash.openstack.org/>`_ which can "" ""be used to run queries on the cluster and interacts with the data. elastic-"" ""recheck queries the elastic-search cluster for the fingerprints."" ","""POT-Creation-Date: 2019-12-15 11:32+0000\n""""PO-Revision-Date: 2019-12-21 01:09+0000\n""",344,2
openstack%2Fnova~master~Ie556b5837e7b45b314616fd4b19dc08c8193ed54,openstack/nova,master,Ie556b5837e7b45b314616fd4b19dc08c8193ed54,Support cross-cell moves in external_instance_event,MERGED,2019-05-10 20:35:19.000000000,2019-12-23 10:01:40.000000000,2019-12-23 09:59:18.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23950}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30402}]","[{'number': 1, 'created': '2019-05-10 20:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dfcded41c944d36c451a3d83bb4bc83140a8bcf2', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 2, 'created': '2019-05-11 22:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60fec5c1d247916b24ce4160b412a3095d4a157f', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 3, 'created': '2019-05-13 19:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/934ecb68f06771444ad59606db18be8631964784', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 4, 'created': '2019-05-16 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/916b80ffea8701b6245e4a4d268b51ead86268ba', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 5, 'created': '2019-05-16 16:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f94bedc7034e808426ff9913cc91b11c3f79370', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 6, 'created': '2019-05-22 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae80ec828a374aeba8841eb7b549aee26f1feeec', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 7, 'created': '2019-05-28 23:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/facb9a91cdc9e3ed1dd76e28abc749b41f841502', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 8, 'created': '2019-05-29 21:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2964fcf9513659b14e28e66401ef45838733e8de', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 9, 'created': '2019-06-10 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2338d8f1e03b1af4ccfdfb75a89e1b5dbe8b7ee4', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 10, 'created': '2019-06-27 16:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aece676950554d2840ee951dc093475e3e775970', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 11, 'created': '2019-06-28 00:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eae01b626fe6724282dce8ac98aba3ad918a9835', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 12, 'created': '2019-07-04 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fae2609a676291eaf0a2f711241d6bf1dff8d5f', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 13, 'created': '2019-07-05 22:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c19ad4791f08745f9329a932242c92987808fc89', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 14, 'created': '2019-07-10 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c5777bb510550b232e8958acd66201b0c2667c1', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 15, 'created': '2019-07-26 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2ed6153581138539f0cac79dc6fc052607da77f', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 16, 'created': '2019-08-07 22:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8c266530e944cb1149d36aab5fc170325bf39f6', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 17, 'created': '2019-08-14 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42efb5e6d9be42c880aefa799274e72434795027', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 18, 'created': '2019-08-27 19:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2248d81012dde154867ca10348ae3cc143d116c2', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 19, 'created': '2019-09-04 18:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdabf521a591f0d49a346cb6745c0f2a9ead150b', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 20, 'created': '2019-09-21 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e21c1f00d165c4ba77fe1b1c8b161d41a55e4a4b', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 21, 'created': '2019-10-03 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/531b3abe147ae0a9bb0c162043e0e6218284e217', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 22, 'created': '2019-10-08 15:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31950ef2156ecfe487ff5386fb6b7557b1790611', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 23, 'created': '2019-10-14 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2078c2f3864e6f3b2bd4773e388770154bb72af2', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 24, 'created': '2019-10-14 18:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5152159dcb7307bc57ad843bd222cf8743b8ee2', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 25, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72e6aa6e16ae9efcd921e600f8bdcc23c79efe11', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 26, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76a105b88cbff0a68357223758f0af1c2f3aee8f', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 27, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c41c06aaf0e9245537edebabd180df5fc1531964', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 28, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd95bb133107188cef8b83b908f681e936858133', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 29, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/001270d0d3d41f52fd0861212fb91647b6c552ee', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 30, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7017600b4d9f5eae78de613abc6605f02226288', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 31, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a3e72aeb7816cdb1930af125607acc605bedee7', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 32, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd1241276657a0afed56f40b53a133e54920932d', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 33, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/518c4efed8a43d6951982d30f87fcf9dc98e47bc', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 34, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/576290aba6252ce3a050391ad1e993a65dfd73bf', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 35, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d336e4bcf23cdf010cb5f08fc7a6e98d1553dc7b', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 36, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e039826d9dfe108a36a0807381d58bf1868bcfd', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 37, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bbe2e40195237d2270e4970a67d5161ba332295', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 38, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db3bd038889fa280204e3bb3e966a9ddf6cbf7ff', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}, {'number': 39, 'created': '2019-12-12 19:07:41.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c2e315975cd33dccc8d50e46a29ea3bcd8255a14', 'message': 'Support cross-cell moves in external_instance_event\n\nThe external_instance_event method in the API assumed\nthat all events for an instance would be routed to\nhosts within the same cell the instance lives in, but\nthat is no longer the case when a cross-cell migration\nis happening.\n\nThis changes the external_instance_event flow to check\nif the instance is undergoing a cross-cell migration\nand if so, gets the host mappings for the source and\ndest host to properly target the context for the\ncast to each compute in different cells.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54\n'}]",1,658478,c2e315975cd33dccc8d50e46a29ea3bcd8255a14,367,19,39,6873,,,0,"Support cross-cell moves in external_instance_event

The external_instance_event method in the API assumed
that all events for an instance would be routed to
hosts within the same cell the instance lives in, but
that is no longer the case when a cross-cell migration
is happening.

This changes the external_instance_event flow to check
if the instance is undergoing a cross-cell migration
and if so, gets the host mappings for the source and
dest host to properly target the context for the
cast to each compute in different cells.

Part of blueprint cross-cell-resize

Change-Id: Ie556b5837e7b45b314616fd4b19dc08c8193ed54
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/658478/37 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",2,dfcded41c944d36c451a3d83bb4bc83140a8bcf2,bp/cross-cell-resize," hosts, cross_cell_move = self._get_relevant_hosts( instance._context, instance) for host in hosts: if host not in cell_contexts_by_host: # NOTE(mriedem): If the instance is being migrated across # cells then we have to get the host mapping to determine # which cell a given host is in. if cross_cell_move: hm = objects.HostMapping.get_by_host(api_context, host) ctxt = nova_context.get_admin_context() nova_context.set_target_cell(ctxt, hm.cell_mapping) cell_contexts_by_host[host] = ctxt else: # The instance is not migrating across cells so just # use the cell-targeted context already in the # instance since the host has to be in that same cell. cell_contexts_by_host[host] = instance._context """"""Get the relevant hosts for an external server event on an instance. :param context: nova auth request context targeted at the same cell that the instance lives in :param instance: Instance object which is the target of an external server event :returns: 2-item tuple of: - set of at least one host (the host where the instance lives); if the instance is being migrated the source and dest compute hostnames are in the returned set - boolean indicating if the instance is being migrated across cells """""" cross_cell_move = False cross_cell_move = migration.cross_cell_move cells_msg = ( 'across cells' if cross_cell_move else 'within the same cell') LOG.debug('Instance %(instance)s is migrating %(cells_msg)s, ' '%(hosts)s', {'cells_msg': cells_msg, 'instance': instance.uuid, return hosts, cross_cell_move"," for host in self._get_relevant_hosts(instance._context, instance): # NOTE(mdbooth): We don't currently support migrations between # cells, and given that the Migration record is hosted in the # cell _get_relevant_hosts will likely have to change before we # do. Consequently we can currently assume that the context for # both the source and destination hosts of a migration is the # same. if host not in cell_contexts_by_host: cell_contexts_by_host[host] = instance._context LOG.debug('Instance %(instance)s is migrating, ' '%(hosts)s', {'instance': instance.uuid, return hosts",105,11
openstack%2Fmurano~master~I1023589516ff90b77b7a2a848ef943bd21ff4da7,openstack/murano,master,I1023589516ff90b77b7a2a848ef943bd21ff4da7,Imported Translations from Zanata,MERGED,2019-12-22 07:06:52.000000000,2019-12-23 09:57:00.000000000,2019-12-23 09:55:27.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 07:06:52.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'murano/locale/en_GB/LC_MESSAGES/murano.po'], 'web_link': 'https://opendev.org/openstack/murano/commit/b33d398950993cbf2e73e767eade281d67cd8546', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I1023589516ff90b77b7a2a848ef943bd21ff4da7\n'}]",0,700301,b33d398950993cbf2e73e767eade281d67cd8546,9,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I1023589516ff90b77b7a2a848ef943bd21ff4da7
",git fetch https://review.opendev.org/openstack/murano refs/changes/01/700301/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'murano/locale/en_GB/LC_MESSAGES/murano.po']",2,b33d398950993cbf2e73e767eade281d67cd8546,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-19 02:15+0000\n""""PO-Revision-Date: 2019-12-21 02:43+0000\n""msgid ""Env template with specified name already exists"" msgstr ""Env template with specified name already exists"" msgid ""Sample Check"" msgstr ""Sample Check"" ","""POT-Creation-Date: 2018-02-26 12:04+0000\n""""PO-Revision-Date: 2018-02-09 11:08+0000\n""",155,4
openstack%2Fzun~master~I4b41a6afa9ef420c8195654eecfd6f3c157f3bff,openstack/zun,master,I4b41a6afa9ef420c8195654eecfd6f3c157f3bff,Add Wiki links to readme,ABANDONED,2019-12-23 09:28:48.000000000,2019-12-23 09:39:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-23 09:28:48.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/d43de0e9059529700bde7fd12edcc8f4413f98fe', 'message': 'Add Wiki links to readme\n\nChange-Id: I4b41a6afa9ef420c8195654eecfd6f3c157f3bff\n'}]",0,700400,d43de0e9059529700bde7fd12edcc8f4413f98fe,3,1,1,31027,,,0,"Add Wiki links to readme

Change-Id: I4b41a6afa9ef420c8195654eecfd6f3c157f3bff
",git fetch https://review.opendev.org/openstack/zun refs/changes/00/700400/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d43de0e9059529700bde7fd12edcc8f4413f98fe,,* Wiki: https://wiki.openstack.org/wiki/Zun,,1,0
openstack%2Foctavia~master~I2b174ef3231956037650eba19aebe5989dffa617,openstack/octavia,master,I2b174ef3231956037650eba19aebe5989dffa617,Cap hacking version to <2,ABANDONED,2019-12-20 01:55:08.000000000,2019-12-23 09:31:40.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 01:55:08.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/332ba3297a58adce420cb637512419d3fa37f4b0', 'message': 'Cap hacking version to <2\n\nHacking 2.0.0 and its dependencies like flake8 have incompatible changes\nand bumping to them leads to pep8 check failure.\nIt is good to address pep8 warnings in the master branch, but in case of\nstable branches it is good to continue to use the same version of hacking.\nThis commit is proposed to the master branch so that it can be backported.\n\nChange-Id: I2b174ef3231956037650eba19aebe5989dffa617\n(cherry picked from commit 7a7558b0583fa84f73d5ecb81204cbb76b0ef0e5)\n'}]",0,700091,332ba3297a58adce420cb637512419d3fa37f4b0,4,2,1,31027,,,0,"Cap hacking version to <2

Hacking 2.0.0 and its dependencies like flake8 have incompatible changes
and bumping to them leads to pep8 check failure.
It is good to address pep8 warnings in the master branch, but in case of
stable branches it is good to continue to use the same version of hacking.
This commit is proposed to the master branch so that it can be backported.

Change-Id: I2b174ef3231956037650eba19aebe5989dffa617
(cherry picked from commit 7a7558b0583fa84f73d5ecb81204cbb76b0ef0e5)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/91/700091/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,332ba3297a58adce420cb637512419d3fa37f4b0,,"hacking>=1.1.0,<2 # Apache-2.0",hacking>=1.1.0 # Apache-2.0,1,1
openstack%2Fdeb-python-aioeventlet~master~Ib7e4efa1eee4fce2a0dacca3e48a126829dbea01,openstack/deb-python-aioeventlet,master,Ib7e4efa1eee4fce2a0dacca3e48a126829dbea01,Update review community page,NEW,2019-12-19 06:39:33.000000000,2019-12-23 09:09:38.000000000,,[{'_account_id': 30717}],"[{'number': 1, 'created': '2019-12-19 06:39:33.000000000', 'files': ['doc/openstack.rst'], 'web_link': 'https://opendev.org/openstack/deb-python-aioeventlet/commit/c03f6b6084dfcadb7d81ee3d644c05d7eac4e0ef', 'message': 'Update review community page\n\nChange-Id: Ib7e4efa1eee4fce2a0dacca3e48a126829dbea01\n'}]",0,699918,c03f6b6084dfcadb7d81ee3d644c05d7eac4e0ef,2,1,1,30717,,,0,"Update review community page

Change-Id: Ib7e4efa1eee4fce2a0dacca3e48a126829dbea01
",git fetch https://review.opendev.org/openstack/deb-python-aioeventlet refs/changes/18/699918/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack.rst'],1,c03f6b6084dfcadb7d81ee3d644c05d7eac4e0ef,," monkey-patching with ?? <https://review.opendev.org/#/c/164035/>`_ <https://review.opendev.org/#/c/156711/>`_ <https://review.opendev.org/#/c/153298/>`_ * December 3, 2014: two patches posted to requirements: `Add aioeventlet dependency <https://review.opendev.org/#/c/138750/>`_ and `Drop greenio dependency <https://review.opendev.org/#/c/138748/>`_. * Novembre 23, 2014: two patches posted to Oslo Messaging: `Add a new aioeventlet executor <https://review.opendev.org/#/c/136653/>`_ <https://review.opendev.org/#/c/136652/>`_ <https://review.opendev.org/#/c/108652/>`_ proposed to Oslo Messaging <https://review.opendev.org/#/c/104792/>`_ merged into openstack/oslo-specs. <https://review.opendev.org/#/c/104964/>`_ merged into Oslo Messaging <https://review.opendev.org/#/c/71003/>`_ merged into Oslo Messaging <https://review.opendev.org/#/c/79901/>`_ merged into <https://review.opendev.org/#/c/77925/>`_ proposed to Heat. Heat coroutines <https://review.opendev.org/#/c/70983/>`_ merged into <https://review.opendev.org/#/c/70948/>`_ proposed to Oslo Messaging,"," monkey-patching with ?? <https://review.openstack.org/#/c/164035/>`_ <https://review.openstack.org/#/c/156711/>`_ <https://review.openstack.org/#/c/153298/>`_ * December 3, 2014: two patches posted to requirements: `Add aioeventlet dependency <https://review.openstack.org/#/c/138750/>`_ and `Drop greenio dependency <https://review.openstack.org/#/c/138748/>`_. * Novembre 23, 2014: two patches posted to Oslo Messaging: `Add a new aioeventlet executor <https://review.openstack.org/#/c/136653/>`_ <https://review.openstack.org/#/c/136652/>`_ <https://review.openstack.org/#/c/108652/>`_ proposed to Oslo Messaging <https://review.openstack.org/#/c/104792/>`_ merged into openstack/oslo-specs. <https://review.openstack.org/#/c/104964/>`_ merged into Oslo Messaging <https://review.openstack.org/#/c/71003/>`_ merged into Oslo Messaging <https://review.openstack.org/#/c/79901/>`_ merged into <https://review.openstack.org/#/c/77925/>`_ proposed to Heat. Heat coroutines <https://review.openstack.org/#/c/70983/>`_ merged into <https://review.openstack.org/#/c/70948/>`_ proposed to Oslo Messaging,",15,15
openstack%2Fpython-monascaclient~master~I8549260146ab125b4c10a812e3573e2ac8ee7bdb,openstack/python-monascaclient,master,I8549260146ab125b4c10a812e3573e2ac8ee7bdb,Stop testing python2.7,ABANDONED,2019-10-28 07:01:02.000000000,2019-12-23 09:06:59.000000000,,"[{'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-28 07:01:02.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/6a95d6b09d91d6a0dbe5b4bb138e0903ea0d0d0f', 'message': 'Stop testing python2.7\n\nChange-Id: I8549260146ab125b4c10a812e3573e2ac8ee7bdb\n'}]",0,691619,6a95d6b09d91d6a0dbe5b4bb138e0903ea0d0d0f,5,3,1,30384,,,0,"Stop testing python2.7

Change-Id: I8549260146ab125b4c10a812e3573e2ac8ee7bdb
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/19/691619/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,6a95d6b09d91d6a0dbe5b4bb138e0903ea0d0d0f,,"envlist = py37,pypy,cover,pep8","envlist = py27,py37,pypy,cover,pep8",1,3
openstack%2Fi18n~master~I5d35806ad9014c7cb1becf1c27b257be578ad724,openstack/i18n,master,I5d35806ad9014c7cb1becf1c27b257be578ad724,Imported Translations from Zanata,MERGED,2019-12-22 09:09:05.000000000,2019-12-23 09:05:12.000000000,2019-12-23 09:03:42.000000000,"[{'_account_id': 14482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 09:09:05.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc.po'], 'web_link': 'https://opendev.org/openstack/i18n/commit/a31b9c263088657afd4f0b11c43ed3980f1d8ec5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5d35806ad9014c7cb1becf1c27b257be578ad724\n'}]",0,700322,a31b9c263088657afd4f0b11c43ed3980f1d8ec5,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I5d35806ad9014c7cb1becf1c27b257be578ad724
",git fetch https://review.opendev.org/openstack/i18n refs/changes/22/700322/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/en_GB/LC_MESSAGES/doc.po'],1,a31b9c263088657afd4f0b11c43ed3980f1d8ec5,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-10-28 23:57+0000\n""""PO-Revision-Date: 2019-12-21 02:31+0000\n""msgid """" ""Currently, we do not support translations for OpenStack developer documents: "" ""http://docs.openstack.org/<project>"" msgstr """" ""Currently, we do not support translations for OpenStack developer documents: "" ""http://docs.openstack.org/<project>"" msgid """" ""Every odd week: `16:00 UTC, Thursday <https://www.timeanddate.com/worldclock/"" ""fixedtime.html?hour=16&min=00&sec=0>`_"" msgstr """" ""Every odd week: `16:00 UTC, Thursday <https://www.timeanddate.com/worldclock/"" ""fixedtime.html?hour=16&min=00&sec=0>`_"" msgid """" ""Everybody can propose agenda topics on `I18nTeamMeeting Wiki Page <https://"" ""wiki.openstack.org/wiki/Meetings/I18nTeamMeeting#Agenda_for_next_meeting>`_. "" ""If there are no topics proposed, the meeting might be canceled for that week."" msgstr """" ""Everybody can propose agenda topics on `I18nTeamMeeting Wiki Page <https://"" ""wiki.openstack.org/wiki/Meetings/I18nTeamMeeting#Agenda_for_next_meeting>`_. "" ""If there are no topics proposed, the meeting might be cancelled for that "" ""week."" msgid ""Launchpad bugs, Gerrit reviews, and broken Zuul jobs"" msgstr ""Launchpad bugs, Gerrit reviews, and broken Zuul jobs"" msgid """" ""Patch on governance repository: https://review.opendev.org/#/c/213989/ "" ""(`diff <https://opendev.org/openstack/governance/commit/"" ""a229d38469c5135af496d3c739695acbe1146a76>`__)"" msgstr """" ""Patch on governance repository: https://review.opendev.org/#/c/213989/ "" ""(`diff <https://opendev.org/openstack/governance/commit/"" ""a229d38469c5135af496d3c739695acbe1146a76>`__)"" msgid """" ""Patch on governance repository: https://review.opendev.org/#/c/281145/ "" ""(`diff <https://opendev.org/openstack/governance/"" ""commit/8b3c83f28102c7b47688fbaca970a52a76eb6de5>`__)"" msgstr """" ""Patch on governance repository: https://review.opendev.org/#/c/281145/ "" ""(`diff <https://opendev.org/openstack/governance/"" ""commit/8b3c83f28102c7b47688fbaca970a52a76eb6de5>`__)"" msgid """" ""Patch on governance repository: https://review.opendev.org/#/c/351480/ "" ""(`diff <https://opendev.org/openstack/governance/"" ""commit/3aa6cb3e52944f8bed250e0714c7373605b2ebc5>`__)"" msgstr """" ""Patch on governance repository: https://review.opendev.org/#/c/351480/ "" ""(`diff <https://opendev.org/openstack/governance/"" ""commit/3aa6cb3e52944f8bed250e0714c7373605b2ebc5>`__)"" msgid """" ""Patch on governance repository: https://review.opendev.org/#/c/417569/ "" ""(`diff <https://opendev.org/openstack/governance/commit/"" ""bd71cefff1302ed04fc21faac5cf967365a7d7c7>`__)"" msgstr """" ""Patch on governance repository: https://review.opendev.org/#/c/417569/ "" ""(`diff <https://opendev.org/openstack/governance/commit/"" ""bd71cefff1302ed04fc21faac5cf967365a7d7c7>`__)"" msgid ""Patch on governance repository: https://review.opendev.org/483452"" msgstr ""Patch on governance repository: https://review.opendev.org/483452"" msgid ""Patch on governance repository: https://review.opendev.org/532982"" msgstr ""Patch on governance repository: https://review.opendev.org/532982"" msgid ""Patch on governance repository: https://review.opendev.org/586751"" msgstr ""Patch on governance repository: https://review.opendev.org/586751"" msgid ""Patch on governance repository: https://review.opendev.org/633398"" msgstr ""Patch on governance repository: https://review.opendev.org/633398"" msgid ""Period: 2018-07-10 to 2019-01-25"" msgstr ""Period: 2018-07-10 to 2019-01-25"" msgid """" ""The I18n team holds weekly Team Meetings on Thursdays at alternating times "" ""in #openstack-meeting IRC channel. To download ICS file, please visit "" ""`eavesdrop <http://eavesdrop.openstack.org/#I18N_Team_Meeting>`_ page."" msgstr """" ""The I18n team holds weekly Team Meetings on Thursdays at alternating times "" ""in #openstack-meeting IRC channel. To download ICS file, please visit "" ""`eavesdrop <http://eavesdrop.openstack.org/#I18N_Team_Meeting>`_ page."" ""The meeting is interconnected with the `Documentation Team Meeting <http://"" ""eavesdrop.openstack.org/#Documentation_Team_Meeting>`_. The first 30 minutes "" ""are reserved for I18n topics and the second part is for Documentation Team "" ""topics."" msgstr """" ""The meeting is interconnected with the `Documentation Team Meeting <http://"" ""eavesdrop.openstack.org/#Documentation_Team_Meeting>`_. The first 30 minutes "" ""are reserved for I18n topics and the second part is for Documentation Team "" ""topics."" msgid """"""This `Script in I18n repo <https://opendev.org/openstack/i18n/src/tools/"" ""zanata/zanata_users.py>`__ collects all users and their activities."" msgstr """" ""This `Script in I18n repo <https://opendev.org/openstack/i18n/src/tools/"" ""zanata/zanata_users.py>`__ collects all users and their activities."" msgid """"""This following statistics data is calculated using up-to-date "" ""`translation_team.yaml <https://opendev.org/openstack/i18n/src/commit/"" ""a67e08d86cc78907da38d5f09b8be6f71d1979a0/tools/zanata/translation_team."" ""yaml>`__ (date: Jan 15, 2017)."" msgstr """" ""This following statistics data is calculated using up-to-date "" ""`translation_team.yaml <https://opendev.org/openstack/i18n/src/commit/"" ""a67e08d86cc78907da38d5f09b8be6f71d1979a0/tools/zanata/translation_team."" ""yaml>`__ (date: Jan 15, 2017)."" msgid """"msgid ""Train cycle"" msgstr ""Train cycle"" ""When proposing extra ATCs at that time, some translators were not included "" ""in `translation_team.yaml <https://opendev.org/openstack/i18n/src/"" ""commit/73a36041dbdc45212051c60cbeef3f7783200fd2/tools/zanata/"" ""translation_team.yaml>`__ file. It seems that 1) new translators were joined "" ""and the statistics was calculated but the file was already created, or 2) "" ""there might be some lack of communication with language coordinators, since "" ""I18n encouraged each language coordinator to update this file."" msgstr """" ""When proposing extra ATCs at that time, some translators were not included "" ""in `translation_team.yaml <https://opendev.org/openstack/i18n/src/"" ""commit/73a36041dbdc45212051c60cbeef3f7783200fd2/tools/zanata/"" ""translation_team.yaml>`__ file. It seems that 1) new translators were joined "" ""and the statistics was calculated but the file was already created, or 2) "" ""there might be some lack of communication with language coordinators, since "" ""I18n encouraged each language coordinator to update this file."" msgid """"""You can check on `Gerrit <https://review.opendev.org/#/q/topic:zanata/"" ""translations+(status:open+OR+status:merged)>`__, if the translated strings "" ""are imported by the project teams. Core reviewers in each repository are "" ""strong encouraged to approve translation sync patches but do not be sad if "" ""the translations are not accepted. Zanata Sync jobs are repeated every day "" ""until they are merged."" msgstr """" ""You can check on `Gerrit <https://review.opendev.org/#/q/topic:zanata/"" ""translations+(status:open+OR+status:merged)>`__, if the translated strings "" ""are imported by the project teams. Core reviewers in each repository are "" ""strong encouraged to approve translation sync patches but do not be sad if "" ""the translations are not accepted. Zanata Sync jobs are repeated every day "" ""until they are merged."" msgid """"msgid """" ""You can refer to `previous meeting logs with their notes <http://eavesdrop."" ""openstack.org/meetings/openstack_i18n_team_meeting/>`_."" msgstr """" ""You can refer to `previous meeting logs with their notes <http://eavesdrop."" ""openstack.org/meetings/openstack_i18n_team_meeting/>`_."" ""You can see detail member-level statistics data on `HTML version of the page "" ""<https://docs.openstack.org/i18n/latest/atc-stats.html>`_."" msgstr """" ""You can see detail member-level statistics data on `HTML version of the page "" ""<https://docs.openstack.org/i18n/latest/atc-stats.html>`_."" msgid """"msgid """" ""`Broken Translation Jobs on Zuul <http://zuul.openstack.org/builds?"" ""job_name=upstream-translation-update&job_name=propose-translation-"" ""update&result=Failure>`_"" msgstr """" ""`Broken Translation Jobs on Zuul <http://zuul.openstack.org/builds?"" ""job_name=upstream-translation-update&job_name=propose-translation-"" ""update&result=Failure>`_"" ""`Open reviews in openstack/i18n <https://review.opendev.org/#/q/status:open"" ""+project:openstack/i18n>`_"" msgstr """" ""`Open reviews in openstack/i18n <https://review.opendev.org/#/q/status:open"" ""+project:openstack/i18n>`_"" msgid """"""`https://review.opendev.org/#/c/451625/ <https://review.opendev.org/#/"" ""c/451625/>`__"" msgstr """" ""`https://review.opendev.org/#/c/451625/ <https://review.opendev.org/#/"" ""c/451625/>`__"" msgid """"","""POT-Creation-Date: 2019-08-26 10:48+0000\n""""PO-Revision-Date: 2018-08-22 10:17+0000\n""",191,2
openstack%2Fpuppet-pacemaker~master~I0c5a8de7fc131ac115efe9152fd8aea946a706aa,openstack/puppet-pacemaker,master,I0c5a8de7fc131ac115efe9152fd8aea946a706aa,Improve scaleup debug logic,MERGED,2019-12-20 18:32:04.000000000,2019-12-23 08:55:21.000000000,2019-12-23 08:55:20.000000000,"[{'_account_id': 8297}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-20 18:32:04.000000000', 'files': ['lib/puppet/parser/functions/pcmk_nodes_added.rb'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/54cb9a465ca9450a07a3c4f255adb3b80730a214', 'message': 'Improve scaleup debug logic\n\nThis can be useful if we need to debug more in detail\nwhy the debug logic was triggered.\n\nChange-Id: I0c5a8de7fc131ac115efe9152fd8aea946a706aa\n'}]",0,700220,54cb9a465ca9450a07a3c4f255adb3b80730a214,8,5,1,20172,,,0,"Improve scaleup debug logic

This can be useful if we need to debug more in detail
why the debug logic was triggered.

Change-Id: I0c5a8de7fc131ac115efe9152fd8aea946a706aa
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/20/700220/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/parser/functions/pcmk_nodes_added.rb'],1,54cb9a465ca9450a07a3c4f255adb3b80730a214,scaleup_debug," Puppet.debug(""pcmk_nodes_added: crm_nodes_output #{crm_nodes_output}"") Puppet.debug(""pcmk_nodes_added: #{ret} [#{node_list} - #{crm_nodes}]"")"," Puppet.debug(""pcmk_nodes_added: #{ret}"")",2,1
openstack%2Ftripleo-heat-templates~master~I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b,openstack/tripleo-heat-templates,master,I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b,Limit concurrency in container-puppet to image pull,MERGED,2019-12-18 17:37:38.000000000,2019-12-23 08:00:17.000000000,2019-12-20 09:01:25.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-18 17:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c363e3f107568dd92a537bb6cdffbab7896af5c3', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 2, 'created': '2019-12-18 17:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3445280b9912c5b03ec8238ee98cbd10a3f08b4b', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 3, 'created': '2019-12-18 18:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/91d590009562fb8a32e02775c88937a554e49e5c', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 4, 'created': '2019-12-18 18:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec4af322d473fdffa54f4801b5d48efcea331844', 'message': 'container-puppet: create containers sequentially to avoid race\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, create the docker-puppet containers\nsequentially to prevent any race, and make then run in detached\nmode, concurrently. This way, we keep honouring the concurrency\nsetting for image download and puppet run, so we do not degrade\nrun time overall.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 5, 'created': '2019-12-18 18:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/35ef5fef40bf5b84c720c37ad5117afaf8125043', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is only limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 6, 'created': '2019-12-19 10:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3af30e867530e30cd1029a8fc34125efe9a506fe', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is only limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}, {'number': 7, 'created': '2019-12-19 20:32:01.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/acd176e811d39aad1d5cbc64ab41e46dd825daf9', 'message': 'Limit concurrency in container-puppet to image pull\n\nDue to a race in podman 1.6.3, when containers are created in\nparallel under high disk IO, their associated overlayFS mount point\nmight become invalid, and container-puppet would fail to run.\n\nIn order to avoid the bug, run all docker-puppet containers\nsequentially to avoid concurrent container creation. Will still\npull the images concurrently, so the time loss due to lack of\nparallelism is only limited to puppet runs.\n\nChange-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b\nCloses-Bug: #1856324\n'}]",0,699737,acd176e811d39aad1d5cbc64ab41e46dd825daf9,22,5,7,20778,,,0,"Limit concurrency in container-puppet to image pull

Due to a race in podman 1.6.3, when containers are created in
parallel under high disk IO, their associated overlayFS mount point
might become invalid, and container-puppet would fail to run.

In order to avoid the bug, run all docker-puppet containers
sequentially to avoid concurrent container creation. Will still
pull the images concurrently, so the time loss due to lack of
parallelism is only limited to puppet runs.

Change-Id: I29a9ffc621bcbd5e1b09490c5fe09a363286bb8b
Closes-Bug: #1856324
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/699737/1 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,c363e3f107568dd92a537bb6cdffbab7896af5c3,bug/1856324-puppet-sequential,"def pull_container_image(*args): (config_volume, puppet_tags, manifest, config_image, volumes, privileged, check_mode, keep_container) = args[0] retval = pull_image(config_image) return retval PROCESS = multiprocessing.Pool(int(os.environ.get('PROCESS_COUNT', 2))) # Download all container images concurrently RETURNCODES = list(p.map(pull_container_image, PROCESS_MAP)) if any(RETURNCODES): log.error('Not all images could be pulled. Aborting') sys.exit(1) # https://bugzilla.redhat.com/show_bug.cgi?id=1757845 # To prevent a race in podman that could mess up overlayfs mount # points, run the containers sequentially, to create their # overlayfs mount points without concurrency. PROCESS = multiprocessing.Pool(1)"," pull_image(config_image) PROCESS = multiprocessing.Pool(int(os.environ.get('PROCESS_COUNT', 2)))",18,2
openstack%2Frequirements~master~Id66a3e4d574fa4da5fbffe6a1aa24c5ea23ab8cc,openstack/requirements,master,Id66a3e4d574fa4da5fbffe6a1aa24c5ea23ab8cc,mark regex as regex for pycodestyle,MERGED,2019-12-14 05:16:10.000000000,2019-12-23 07:34:10.000000000,2019-12-14 17:28:35.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-14 05:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c4141dc93aa59618aa823ef28ca206950c6b006f', 'message': 'mark regex as regex for pycodestyle\n\nChange-Id: Id66a3e4d574fa4da5fbffe6a1aa24c5ea23ab8cc\n'}, {'number': 2, 'created': '2019-12-14 05:17:36.000000000', 'files': ['tools/check-install.py', 'openstack_requirements/cmds/check_py2.py', 'openstack_requirements/requirement.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/698b571749982f61e65814ca3de489177c14d30e', 'message': 'mark regex as regex for pycodestyle\n\nChange-Id: Id66a3e4d574fa4da5fbffe6a1aa24c5ea23ab8cc\n'}]",0,699058,698b571749982f61e65814ca3de489177c14d30e,11,3,2,14288,,,0,"mark regex as regex for pycodestyle

Change-Id: Id66a3e4d574fa4da5fbffe6a1aa24c5ea23ab8cc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/58/699058/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_requirements/requirement.py'],1,c4141dc93aa59618aa823ef28ca206950c6b006f,fix-pep8, r'^(?P<url>\s*(?:-e\s)?\s*(?:(?:[a-z]+\+)?(?:[a-z]+))://[^#]*)' r'#egg=(?P<name>[-\.\w]+)'), '^(?P<url>\s*(?:-e\s)?\s*(?:(?:[a-z]+\+)?(?:[a-z]+))://[^#]*)' '#egg=(?P<name>[-\.\w]+)'),2,2
openstack%2Freleases~master~I1aed3c1ddd44d9a37e1365129b6b0e65667e3540,openstack/releases,master,I1aed3c1ddd44d9a37e1365129b6b0e65667e3540,Add python 2 drop schedule,MERGED,2019-12-13 19:51:40.000000000,2019-12-23 06:58:41.000000000,2019-12-20 11:06:03.000000000,"[{'_account_id': 308}, {'_account_id': 841}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 19:51:40.000000000', 'files': ['doc/source/ussuri/schedule.rst', 'doc/source/ussuri/schedule.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/680b8c3afe67dba5bfeccb9aa2f6c7e060525be0', 'message': 'Add python 2 drop schedule\n\nChange-Id: I1aed3c1ddd44d9a37e1365129b6b0e65667e3540\n'}]",2,699008,680b8c3afe67dba5bfeccb9aa2f6c7e060525be0,9,4,1,8556,,,0,"Add python 2 drop schedule

Change-Id: I1aed3c1ddd44d9a37e1365129b6b0e65667e3540
",git fetch https://review.opendev.org/openstack/releases refs/changes/08/699008/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ussuri/schedule.rst', 'doc/source/ussuri/schedule.yaml']",2,680b8c3afe67dba5bfeccb9aa2f6c7e060525be0,, - u-py-drop-1 - u-py-drop-2 - u-py-drop-3 - u-py-drop-final,,42,0
openstack%2Fnova~master~I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40,openstack/nova,master,I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40,Add functional test for anti-affinity cross-cell migration,MERGED,2019-05-28 23:08:43.000000000,2019-12-23 05:47:38.000000000,2019-12-23 05:45:16.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-05-28 23:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b8d6d38d13b82a16e621007594edec8d965424c', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 2, 'created': '2019-05-29 21:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/933b2908e862bb48e56346162381282dfb2cf91c', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 3, 'created': '2019-06-10 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99c4417bb7d215c34b70b48e6d9d154000760c4c', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 4, 'created': '2019-06-27 16:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce8b3bffa0e5582706b0ca5affd55843a37e16a0', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 5, 'created': '2019-06-28 00:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c046161907461eb8be55ca0d65c9267c7108cd2', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 6, 'created': '2019-07-04 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba859ac31c0adb3b34f2ac85a3cba415579af12b', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 7, 'created': '2019-07-05 22:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc907bb46f5469abd5927ed2a4ce1b36fac57125', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 8, 'created': '2019-07-10 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5761a0f3f27e51aca564e138894aa385d672d5ce', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 9, 'created': '2019-07-26 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a01bb8afcf418478b8828dc336b16f1d9631804', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 10, 'created': '2019-08-07 22:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e338132ec5e79eff60d8bb861bbc37c388f0088', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 11, 'created': '2019-08-14 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07e3fc1f17872abfe2c79b5f222cf269521d75c8', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 12, 'created': '2019-08-27 19:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/111f199fc026379f954246f75e6fcc30f3504c59', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 13, 'created': '2019-09-04 18:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36b5fef91d631956605bc2ab52a18d574fdf3e0a', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 14, 'created': '2019-09-21 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a582b87eaf7da7a54527c380d4373897f9bb2c5', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 15, 'created': '2019-10-03 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4956920a5af782aef864eac00e21237557f8934', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 16, 'created': '2019-10-08 15:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a121a0c2cb5ff3321f52fbb3b78b4a1ddc621af', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 17, 'created': '2019-10-14 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca2b2d83274e007e4543c0ec7f67194ac5db7da6', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 18, 'created': '2019-10-14 18:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c813b997c1a548ebaa600e2a07eaa328665b5bf', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 19, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07d973b941cdeefd111841a4f619106460102adb', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 20, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7518af8af7267730a1f5f99e6f542a679e6a485c', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 21, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7db25e8e43cb0b72e0767c382bc3ec229a28f30b', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 22, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f12370c8505e2619ca88651bcd86264a8bcecee', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 23, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7639340ad79bae049c2961a7baa67421dcd8939f', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 24, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11f0e416543349cefead9e29253b4add09df3af9', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 25, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd027a73b90ab0e47badce60e0486e5db1da3a06', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 26, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84963813070e910508d06c807d4104388eb65cf1', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 27, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8be4b4ac9ce68171089fcd61b919dc0d739be916', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 28, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95cdacb67335eb4eddc9f4e675ef5c5e3f40e271', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 29, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfd1bb232c439a2407dd8130b3b791172af13450', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 30, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3deff25217322d28c5abfd0babe3ea8789faccb7', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 31, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88eb849f42a91b61d05b55a44d5ceed1db7ffa36', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 32, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09f587565b2d51fba5af7ae68c8486df9dcfdcf4', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}, {'number': 33, 'created': '2019-12-12 19:07:41.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/functional/test_cross_cell_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fbebfcaf34a4811ed8b21f405f59fe8a5cf1a921', 'message': 'Add functional test for anti-affinity cross-cell migration\n\nThis adds a functional test to ensure that the scheduler\nproperly restricts anti-affinity group members to different\nhosts regardless of which cell those hosts are in. The comments\nin the setup_instance_group scheduler utility method assume\nthat all moves are within the same cell and as such instance\ngroup hosts will be within the same cell, which is not true in\nthe case of an anti-affinity group cross-cell move. The test\nadded here would actually fail were it not for change\nI4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the\nServerGroupAntiAffinityFilter such that the filter does not\nlook at the request_spec.instance_group.hosts but only the\nmembers. A clarifying comment is added to the scheduler utils\ncode in case we ever need to fix that.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40\n'}]",3,661859,fbebfcaf34a4811ed8b21f405f59fe8a5cf1a921,326,18,33,6873,,,0,"Add functional test for anti-affinity cross-cell migration

This adds a functional test to ensure that the scheduler
properly restricts anti-affinity group members to different
hosts regardless of which cell those hosts are in. The comments
in the setup_instance_group scheduler utility method assume
that all moves are within the same cell and as such instance
group hosts will be within the same cell, which is not true in
the case of an anti-affinity group cross-cell move. The test
added here would actually fail were it not for change
I4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in Rocky to the
ServerGroupAntiAffinityFilter such that the filter does not
look at the request_spec.instance_group.hosts but only the
members. A clarifying comment is added to the scheduler utils
code in case we ever need to fix that.

Part of blueprint cross-cell-resize

Change-Id: I29f0dfdc52fda6d0b7c378801ee40ec7ad8fdf40
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/661859/20 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/functional/test_cross_cell_migrate.py']",2,5b8d6d38d13b82a16e621007594edec8d965424c,bp/cross-cell-resize,"from nova.scheduler import utils as scheduler_utils def _create_server(self, flavor, volume_backed=False, group_id=None, no_networking=False): :param group_id: UUID of a server group in which to create the server :param no_networking: True if the server should be creating without networking, otherwise it will be created with a specific port and VIF tag if no_networking: networks = 'none' else: # Provide a VIF tag for the pre-existing port. Since VIF tags are # stored in the virtual_interfaces table in the cell DB, we want to # make sure those survive the resize to another cell. networks = [{ 'port': self.neutron.port_1['id'], 'tag': 'private' }] req = dict(server=server) if group_id: req['os:scheduler_hints'] = {'group': group_id} server = self.api.post_server(req) def test_anti_affinity_group(self): """"""Tests an anti-affinity group scenario where a server is moved across cells and then trying to move the other from the same group to the same host in the target cell should be rejected by the scheduler. """""" # Create an anti-affinity server group for our servers. body = { 'server_group': { 'name': 'test_anti_affinity_group', 'policy': 'anti-affinity' } } group_id = self.api.api_post( '/os-server-groups', body).body['server_group']['id'] # Create a server in the group in cell1 (should land on host1 due to # HostNameWeigher). flavor = self.api.get_flavors()[0] server1 = self._create_server( flavor, group_id=group_id, no_networking=True) # Start another compute host service in cell1. self._start_compute( 'host3', cell_name=self.host_to_cell_mappings['host1']) # Create another server but we want it on host3 in cell1. We cannot # use the az forced host parameter because then we will not be able to # move the server across cells later. The HostNameWeigher will prefer # host2 in cell2 so we need to temporarily force host2 down. host2_service_uuid = self.computes['host2'].service_ref.uuid self.admin_api.put_service_force_down( host2_service_uuid, forced_down=True) server2 = self._create_server( flavor, group_id=group_id, no_networking=True) self.assertEqual('host3', server2['OS-EXT-SRV-ATTR:host']) # Remove the forced-down status of the host2 compute service so we can # migrate there. self.admin_api.put_service_force_down( host2_service_uuid, forced_down=False) # Now migrate server1 which should move it to host2 in cell2 otherwise # it would violate the anti-affinity policy since server2 is on host3 # in cell1. self.admin_api.post_server_action(server1['id'], {'migrate': None}) server1 = self._wait_for_state_change( self.admin_api, server1, 'VERIFY_RESIZE') self.assertEqual('host2', server1['OS-EXT-SRV-ATTR:host']) self.admin_api.post_server_action( server1['id'], {'confirmResize': None}) self._wait_for_state_change( self.admin_api, server1, 'ACTIVE') # At this point we have: # server1: host2 in cell2 # server2: host3 in cell1 # The server group hosts should reflect that. ctxt = nova_context.get_admin_context() group = objects.InstanceGroup.get_by_uuid(ctxt, group_id) group_hosts = scheduler_utils._get_instance_group_hosts_all_cells( ctxt, group) self.assertEqual(['host2', 'host3'], sorted(group_hosts)) # Try to migrate server2 to host2 in cell2 which should fail scheduling # because it violates the anti-affinity policy. Note that without # change I4b67ec9dd4ce846a704d0f75ad64c41e693de0fb in # ServerGroupAntiAffinityFilter this would fail because the scheduler # utils setup_instance_group only looks at the group hosts in the # source cell. self.admin_api.post_server_action( server2['id'], {'migrate': {'host': 'host2'}}) self._wait_for_migration_status(server2, ['error'])"," def _create_server(self, flavor, volume_backed=False): # Provide a VIF tag for the pre-existing port. Since VIF tags are # stored in the virtual_interfaces table in the cell DB, we want to # make sure those survive the resize to another cell. networks = [{ 'port': self.neutron.port_1['id'], 'tag': 'private' }] server = self.api.post_server({'server': server}) # TODO(mriedem): Test cross-cell anti-affinity group assumptions from # scheduler utils setup_instance_group where it assumes moves are within # the same cell, so: # 0. create 2 hosts in cell1 and 1 host in cell2 # 1. create two servers in an anti-affinity group in cell1 # 2. migrate one server to cell2 # 3. migrate the other server to cell2 - this should fail during scheduling # because there is already a server from the anti-affinity group on the # host in cell2 but setup_instance_group code may not catch it.",99,18
openstack%2Fheat-templates~master~I52a34bded5f4343469cbca647707304ca05c62ec,openstack/heat-templates,master,I52a34bded5f4343469cbca647707304ca05c62ec,Drop use of git.openstack.org,MERGED,2019-04-17 08:27:50.000000000,2019-12-23 05:34:20.000000000,2019-12-23 05:34:20.000000000,"[{'_account_id': 12404}, {'_account_id': 18955}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-04-17 08:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/3ce6fa05bac876194f95678c4013e4b241b479df', 'message': ""Drop use of git.openstack.org\n\nOur cgit instance will be going away and opendev.org is the new\npreferred URL for browsing our git repos. Redirects will exist for the\nforeseeable future, but it's more efficient to just go directly to the\nnew locations.\n\nChange-Id: I52a34bded5f4343469cbca647707304ca05c62ec\n""}, {'number': 2, 'created': '2019-12-23 04:19:29.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/0440e8a9e4780dc16f392be1d06780466067d498', 'message': ""Drop use of git.openstack.org\n\nOur cgit instance will be going away and opendev.org is the new\npreferred URL for browsing our git repos. Redirects will exist for the\nforeseeable future, but it's more efficient to just go directly to the\nnew locations.\n\nChange-Id: I52a34bded5f4343469cbca647707304ca05c62ec\n""}]",1,653352,0440e8a9e4780dc16f392be1d06780466067d498,9,3,2,12404,,,0,"Drop use of git.openstack.org

Our cgit instance will be going away and opendev.org is the new
preferred URL for browsing our git repos. Redirects will exist for the
foreseeable future, but it's more efficient to just go directly to the
new locations.

Change-Id: I52a34bded5f4343469cbca647707304ca05c62ec
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/52/653352/2 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'playbooks/devstack/run.yaml']",2,3ce6fa05bac876194f95678c4013e4b241b479df,switch-git-repo, https://opendev.org \ enable_plugin heat https://opendev.org/openstack/heat, https://git.openstack.org \ enable_plugin heat https://git.openstack.org/openstack/heat,3,3
openstack%2Fironic~master~I00abb337d25a17caeea038e380f4b7fb5f4182d5,openstack/ironic,master,I00abb337d25a17caeea038e380f4b7fb5f4182d5,Correct devstack output format,ABANDONED,2019-07-01 08:07:25.000000000,2019-12-23 04:52:45.000000000,,"[{'_account_id': 10118}, {'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-07-01 08:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/55adca1c6fb4194e21c7a375f203e7d1cd4e87ee', 'message': 'Correct devstack output format\n\nChange-Id: I00abb337d25a17caeea038e380f4b7fb5f4182d5\n'}, {'number': 2, 'created': '2019-12-23 04:47:28.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/800402430b7c914230bff992d765fed46fb23b59', 'message': 'Correct devstack output format\n\nIf you check [1](L202, and L238), we define the format as example\nlike [2]. Which will provide spaces between lines. That means we not\nneed to provide spaces at the end of each line when calling `die`\nfunction.\n\n[1] https://github.com/openstack/devstack/blob/master/\nfunctions-common\n\n[2] https://github.com/openstack/devstack/blob/master/inc/python#L267\nChange-Id: I00abb337d25a17caeea038e380f4b7fb5f4182d5\n'}]",5,668383,800402430b7c914230bff992d765fed46fb23b59,14,8,2,12404,,,0,"Correct devstack output format

If you check [1](L202, and L238), we define the format as example
like [2]. Which will provide spaces between lines. That means we not
need to provide spaces at the end of each line when calling `die`
function.

[1] https://github.com/openstack/devstack/blob/master/
functions-common

[2] https://github.com/openstack/devstack/blob/master/inc/python#L267
Change-Id: I00abb337d25a17caeea038e380f4b7fb5f4182d5
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/668383/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,55adca1c6fb4194e21c7a375f203e7d1cd4e87ee,correct-devstack-output-format," die ""IRONIC_RAMDISK_TYPE 'dib' has no official pre-built""\ ""images. To fix this select a different ramdisk type, set""\ ""IRONIC_BUILD_DEPLOY_RAMDISK=True, or manually configure""\ ""IRONIC_DEPLOY_RAMDISK(_URL) and IRONIC_DEPLOY_KERNEL(_URL)""\ die ""Prebuilt ISOs are not available, provide an ISO via IRONIC_DEPLOY_ISO""\ ""or set IRONIC_BUILD_DEPLOY_RAMDISK=True to use ISOs"" die ""The deploy driver $IRONIC_DEPLOY_DRIVER is not in the list of enabled""\ ""hardware types $IRONIC_ENABLED_HARDWARE_TYPES"" die $LINENO ""SWIFT_ENABLE_TEMPURLS must be True. This is"" \ ""required either because IRONIC_DEPLOY_DRIVER was"" \ ""set to some agent_* driver OR configuration of"" \ ""Glance with Swift was explicitly requested with"" \"," die ""IRONIC_RAMDISK_TYPE 'dib' has no official pre-built ""\ ""images. To fix this select a different ramdisk type, set ""\ ""IRONIC_BUILD_DEPLOY_RAMDISK=True, or manually configure ""\ ""IRONIC_DEPLOY_RAMDISK(_URL) and IRONIC_DEPLOY_KERNEL(_URL) ""\ die ""Prebuilt ISOs are not available, provide an ISO via IRONIC_DEPLOY_ISO \ or set IRONIC_BUILD_DEPLOY_RAMDISK=True to use ISOs"" die ""The deploy driver $IRONIC_DEPLOY_DRIVER is not in the list of enabled \ hardware types $IRONIC_ENABLED_HARDWARE_TYPES"" die $LINENO ""SWIFT_ENABLE_TEMPURLS must be True. This is "" \ ""required either because IRONIC_DEPLOY_DRIVER was "" \ ""set to some agent_* driver OR configuration of "" \ ""Glance with Swift was explicitly requested with "" \",12,12
openstack%2Fheat-agents~master~I8a9c1d557b857eb1b2dc92f00414c1196b44c25f,openstack/heat-agents,master,I8a9c1d557b857eb1b2dc92f00414c1196b44c25f,Deprecate hook docker-cmd,ABANDONED,2019-08-22 18:49:02.000000000,2019-12-23 04:23:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-22 18:49:02.000000000', 'files': ['tests/test_hook_docker_cmd.py', 'heat-config-docker-cmd/install.d/hook-docker-cmd.py'], 'web_link': 'https://opendev.org/openstack/heat-agents/commit/629c4a8f68f10452652bef84deeba7e81f84739f', 'message': 'Deprecate hook docker-cmd\n\nChange-Id: I8a9c1d557b857eb1b2dc92f00414c1196b44c25f\nTask: 36336\n'}]",0,678085,629c4a8f68f10452652bef84deeba7e81f84739f,4,2,1,12404,,,0,"Deprecate hook docker-cmd

Change-Id: I8a9c1d557b857eb1b2dc92f00414c1196b44c25f
Task: 36336
",git fetch https://review.opendev.org/openstack/heat-agents refs/changes/85/678085/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_hook_docker_cmd.py', 'heat-config-docker-cmd/install.d/hook-docker-cmd.py']",2,629c4a8f68f10452652bef84deeba7e81f84739f,story/2006430, log.warning('hook-docker-cmd is deprecated and will be removed in Train ' 'cycle.'),,2,1020
openstack%2Fheat-agents~master~I7d2960801a0e079c91c5e19d0983be99286b9c25,openstack/heat-agents,master,I7d2960801a0e079c91c5e19d0983be99286b9c25,Remove support for hook docker-cmd,ABANDONED,2019-08-22 18:49:02.000000000,2019-12-23 04:22:28.000000000,,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-22 18:49:02.000000000', 'files': ['heat-config-docker-cmd/install.d/50-heat-config-hook-docker-cmd', 'doc/source/install/hooks/docker-cmd.rst', 'heat-config-docker-cmd/element-deps', 'heat-config-docker-cmd/os-refresh-config/configure.d/50-heat-config-docker-cmd', 'heat-config-docker-cmd/install.d/hook-docker-cmd.py'], 'web_link': 'https://opendev.org/openstack/heat-agents/commit/812c004df86c9418fc8e00c59b7154f6c678079f', 'message': 'Remove support for hook docker-cmd\n\nChange-Id: I7d2960801a0e079c91c5e19d0983be99286b9c25\nTask: 36335\n'}]",0,678086,812c004df86c9418fc8e00c59b7154f6c678079f,6,4,1,12404,,,0,"Remove support for hook docker-cmd

Change-Id: I7d2960801a0e079c91c5e19d0983be99286b9c25
Task: 36335
",git fetch https://review.opendev.org/openstack/heat-agents refs/changes/86/678086/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat-config-docker-cmd/install.d/50-heat-config-hook-docker-cmd', 'doc/source/install/hooks/docker-cmd.rst', 'heat-config-docker-cmd/element-deps', 'heat-config-docker-cmd/os-refresh-config/configure.d/50-heat-config-docker-cmd', 'heat-config-docker-cmd/install.d/hook-docker-cmd.py']",5,812c004df86c9418fc8e00c59b7154f6c678079f,story/2006430,,"#!/usr/bin/env python # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import collections import json import logging import os import sys import paunch import yaml DOCKER_CMD = os.environ.get('HEAT_DOCKER_CMD', 'docker') log = None def build_response(deploy_stdout, deploy_stderr, deploy_status_code): return { 'deploy_stdout': deploy_stdout, 'deploy_stderr': deploy_stderr, 'deploy_status_code': deploy_status_code, } def main(argv=sys.argv): global log log = logging.getLogger('heat-config') log.warning('hook-docker-cmd is deprecated and will be removed in Train ' 'cycle.') handler = logging.StreamHandler(sys.stderr) handler.setFormatter( logging.Formatter( '[%(asctime)s] (%(name)s) [%(levelname)s] %(message)s')) log.addHandler(handler) log.setLevel('DEBUG') c = json.load(sys.stdin) input_values = dict((i['name'], i['value']) for i in c.get('inputs', {})) if input_values.get('deploy_action') == 'DELETE': json.dump(build_response( '', '', 0), sys.stdout) return config = c.get('config', '') cid = c.get('id') if not config: log.debug(""No 'config' input found, nothing to do."") json.dump(build_response( '', '', 0), sys.stdout) return stdout = [] stderr = [] deploy_status_code = 0 # convert config to dict if not isinstance(config, dict): config = yaml.safe_load(config) labels = collections.OrderedDict() labels['deploy_stack_id'] = input_values.get('deploy_stack_id') labels['deploy_resource_name'] = input_values.get('deploy_resource_name') stdout, stderr, deploy_status_code = paunch.apply( cid, config, 'docker-cmd', labels, DOCKER_CMD ) json.dump(build_response( '\n'.join(stdout), '\n'.join(stderr), deploy_status_code), sys.stdout) if __name__ == '__main__': sys.exit(main(sys.argv)) ",0,176
openstack%2Ftripleo-common~stable%2Frocky~I8dfc2494d35d5fce52d573f9edcafbe11ab7faac,openstack/tripleo-common,stable/rocky,I8dfc2494d35d5fce52d573f9edcafbe11ab7faac,OvS DPDK parameters failing in NIC Partitioning,MERGED,2019-12-18 05:22:49.000000000,2019-12-23 03:35:23.000000000,2019-12-19 19:39:19.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-18 05:22:49.000000000', 'files': ['tripleo_common/actions/derive_params.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0c490b8c112e112c58fc6346593ccfc9cbdf13e2', 'message': ""OvS DPDK parameters failing in NIC Partitioning\n\nThis change is to fix the finding DPDK device name issue in\nOvS DPDK derive parameters logic. Currently mistral fails to\nderive OvS DPDK parameters in NIC Partitioning and getting\nerror 'Unable to determine NUMA node for DPDK NIC:'\n\nChange-Id: I8dfc2494d35d5fce52d573f9edcafbe11ab7faac\nCloses-Bug: #1855159\n(cherry picked from commit 9641cc2ccb9d6bc5757f2bb888b374dedc2d2733)\n(cherry picked from commit dd354ee4d6eb05c003de40006cbdb0895099f2c8)\n(cherry picked from commit 068f8d1ae121d63110636dc6527bd241b0ded890)\n""}]",0,699552,0c490b8c112e112c58fc6346593ccfc9cbdf13e2,8,6,1,22865,,,0,"OvS DPDK parameters failing in NIC Partitioning

This change is to fix the finding DPDK device name issue in
OvS DPDK derive parameters logic. Currently mistral fails to
derive OvS DPDK parameters in NIC Partitioning and getting
error 'Unable to determine NUMA node for DPDK NIC:'

Change-Id: I8dfc2494d35d5fce52d573f9edcafbe11ab7faac
Closes-Bug: #1855159
(cherry picked from commit 9641cc2ccb9d6bc5757f2bb888b374dedc2d2733)
(cherry picked from commit dd354ee4d6eb05c003de40006cbdb0895099f2c8)
(cherry picked from commit 068f8d1ae121d63110636dc6527bd241b0ded890)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/52/699552/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/derive_params.py'],1,0c490b8c112e112c58fc6346593ccfc9cbdf13e2,nic-partioining-mistral-issue-stable/train-stable/stein-stable/rocky," type = dpdk_iface.get('type', '') if type == 'sriov_vf': name = dpdk_iface.get('device', '') else: name = dpdk_iface.get('name', '')"," name = dpdk_iface.get('name', '')",5,1
openstack%2Ftripleo-common~stable%2Fstein~I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,openstack/tripleo-common,stable/stein,I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f,Incorrectly derives NeutronPhysnetNUMANodesMapping,MERGED,2019-12-18 05:21:22.000000000,2019-12-23 03:33:46.000000000,2019-12-19 19:38:24.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-18 05:21:22.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/515eb554b48312f16c26a0d67df261454ec45df3', 'message': 'Incorrectly derives NeutronPhysnetNUMANodesMapping\n\nThis change is to derive the NeutronPhysnetNUMANodesMapping\nparameter as dictionary instead of list.\n\nChange-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f\nCloses-Bug: #1856068\n(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)\n(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)\n'}]",0,699551,515eb554b48312f16c26a0d67df261454ec45df3,9,6,1,22865,,,0,"Incorrectly derives NeutronPhysnetNUMANodesMapping

This change is to derive the NeutronPhysnetNUMANodesMapping
parameter as dictionary instead of list.

Change-Id: I0715d9012bc50b7d0d6d555d9d8c7ba821a9b96f
Closes-Bug: #1856068
(cherry picked from commit c0771bf722dcd7d008a005e784e7b982131bca7a)
(cherry picked from commit efc53a84e25ec49eea9d97882e92d613e8180490)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/51/699551/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,515eb554b48312f16c26a0d67df261454ec45df3,incorrect-phy-nw-numa-mappings-stable/train-stable/stein," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes)).sum()).sum() %>"," phy_nw_numa_nodes_mappings: <% let(nw_bridge_mappings => $.phy_nw_bridge_mappings) -> $.bridge_numa_nodes_mappings.items().select(let(br => $[0], nodes => $[1]) -> $nw_bridge_mappings.items().where($[1]=$br).select(dict($[0] => $nodes))).sum() %>",1,1
openstack%2Fpuppet-openstack-integration~master~Ie1db791e5d4e2e3c0ceedb821e2ac472c0a74d0b,openstack/puppet-openstack-integration,master,Ie1db791e5d4e2e3c0ceedb821e2ac472c0a74d0b,Updated from Puppet OpenStack modules constraints,MERGED,2019-12-21 06:09:37.000000000,2019-12-23 01:57:27.000000000,2019-12-23 01:57:27.000000000,"[{'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-21 06:09:37.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/49025319ce6de9cda055b5caea7cfbc6e7109715', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: Ie1db791e5d4e2e3c0ceedb821e2ac472c0a74d0b\n'}]",0,700260,49025319ce6de9cda055b5caea7cfbc6e7109715,8,4,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: Ie1db791e5d4e2e3c0ceedb821e2ac472c0a74d0b
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/60/700260/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,49025319ce6de9cda055b5caea7cfbc6e7109715,openstack/puppet/constraints, :ref => 'v6.3.0', :ref => 'v6.2.0',1,1
openstack%2Fsolum-dashboard~master~I91d422644c748bfeed57bf44d4a76ad09caf2b0a,openstack/solum-dashboard,master,I91d422644c748bfeed57bf44d4a76ad09caf2b0a,Imported Translations from Zanata,MERGED,2019-12-22 06:32:41.000000000,2019-12-23 01:08:43.000000000,2019-12-23 01:08:43.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 06:32:41.000000000', 'files': ['solumdashboard/locale/en_GB/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/b69f83ddd34094f9efa80d614b89cc876ee79011', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I91d422644c748bfeed57bf44d4a76ad09caf2b0a\n'}]",0,700294,b69f83ddd34094f9efa80d614b89cc876ee79011,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I91d422644c748bfeed57bf44d4a76ad09caf2b0a
",git fetch https://review.opendev.org/openstack/solum-dashboard refs/changes/94/700294/1 && git format-patch -1 --stdout FETCH_HEAD,['solumdashboard/locale/en_GB/LC_MESSAGES/django.po'],1,b69f83ddd34094f9efa80d614b89cc876ee79011,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-11-25 09:37+0000\n""""PO-Revision-Date: 2019-12-21 02:51+0000\n""#, python-format msgid ""Unable to create application: %s"" msgstr ""Unable to create application: %s"" #, python-format msgid ""Unable to create languagepack: %s"" msgstr ""Unable to create languagepack: %s"" #, python-format msgid ""Unable to retrieve application details: %s"" msgstr ""Unable to retrieve application details: %s"" #, python-format msgid ""Unable to retrieve apps: %s"" msgstr ""Unable to retrieve apps: %s"" #, python-format msgid ""Unable to retrieve assemblies: %s"" msgstr ""Unable to retrieve assemblies: %s"" #, python-format msgid ""Unable to retrieve languagepack details: %s"" msgstr ""Unable to retrieve languagepack details: %s"" #, python-format msgid ""Unable to retrieve languagepacks: %s"" msgstr ""Unable to retrieve languagepacks: %s"" ","""POT-Creation-Date: 2019-09-09 09:03+0000\n""""PO-Revision-Date: 2017-10-15 07:46+0000\n""",31,2
openstack%2Faodh~master~I2f983982d8671f8a34e022be907f27cb7edfb98d,openstack/aodh,master,I2f983982d8671f8a34e022be907f27cb7edfb98d,Imported Translations from Zanata,MERGED,2019-12-22 10:04:11.000000000,2019-12-23 01:07:51.000000000,2019-12-23 01:06:30.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 10:04:11.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/aodh/commit/b54455f165a7fe61ddda695c8560fec88ce47fea', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I2f983982d8671f8a34e022be907f27cb7edfb98d\n'}]",0,700330,b54455f165a7fe61ddda695c8560fec88ce47fea,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I2f983982d8671f8a34e022be907f27cb7edfb98d
",git fetch https://review.opendev.org/openstack/aodh refs/changes/30/700330/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,b54455f165a7fe61ddda695c8560fec88ce47fea,zanata/translations,"""POT-Creation-Date: 2019-12-20 10:52+0000\n""""PO-Revision-Date: 2019-12-21 01:02+0000\n""msgid ""9.0.0-10"" msgstr ""9.0.0-10""","""POT-Creation-Date: 2019-12-06 07:05+0000\n""""PO-Revision-Date: 2019-12-11 03:16+0000\n""msgid ""9.0.0-8"" msgstr ""9.0.0-8""",4,4
openstack%2Fmurano-dashboard~master~I16ac7bae97e8f1f8b81a67b9a3256cab21a2c7d0,openstack/murano-dashboard,master,I16ac7bae97e8f1f8b81a67b9a3256cab21a2c7d0,Imported Translations from Zanata,MERGED,2019-12-22 09:27:46.000000000,2019-12-23 01:06:33.000000000,2019-12-23 01:05:02.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 09:27:46.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/0bc1fc042203c96b2211c6e2b4cbb446e60f41b2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I16ac7bae97e8f1f8b81a67b9a3256cab21a2c7d0\n'}]",0,700326,0bc1fc042203c96b2211c6e2b4cbb446e60f41b2,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I16ac7bae97e8f1f8b81a67b9a3256cab21a2c7d0
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/26/700326/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,0bc1fc042203c96b2211c6e2b4cbb446e60f41b2,zanata/translations,"""POT-Creation-Date: 2019-11-25 06:59+0000\n""""PO-Revision-Date: 2019-12-21 02:45+0000\n""msgid ""8.0.0.0rc1-8"" msgstr ""8.0.0.0rc1-8"" msgid """" ""Python 2.7 support has been dropped. Last release of murano-dashboard to "" ""support python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by murano-dashboardis Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Murano-dashboard to "" ""support Python 2.7 is OpenStack Train. The minimum version of Python now "" ""supported by Murano-dashboard is Python 3.6."" ","""POT-Creation-Date: 2019-10-08 01:38+0000\n""""PO-Revision-Date: 2019-11-14 11:18+0000\n""",14,2
openstack%2Fmurano-pkg-check~master~I4c5de79fc863c9b8c8fb1d871e9a254dd9f73c13,openstack/murano-pkg-check,master,I4c5de79fc863c9b8c8fb1d871e9a254dd9f73c13,Imported Translations from Zanata,MERGED,2019-12-22 08:01:15.000000000,2019-12-23 01:01:57.000000000,2019-12-23 01:01:57.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 08:01:15.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/murano-pkg-check/commit/546d00a803e4698a0c9a5a45ffee509894f6798a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4c5de79fc863c9b8c8fb1d871e9a254dd9f73c13\n'}]",0,700313,546d00a803e4698a0c9a5a45ffee509894f6798a,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4c5de79fc863c9b8c8fb1d871e9a254dd9f73c13
",git fetch https://review.opendev.org/openstack/murano-pkg-check refs/changes/13/700313/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po']",2,546d00a803e4698a0c9a5a45ffee509894f6798a,zanata/translations,,"# Grald LONLAS <g.lonlas@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: muranopkgcheck Release Notes\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2016-10-07 14:14+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-10-22 05:31+0000\n"" ""Last-Translator: Grald LONLAS <g.lonlas@gmail.com>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 3.7.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid ""Current Series Release Notes"" msgstr ""Note de la release actuelle"" msgid ""muranopkgcheck Release Notes"" msgstr ""Note de release de muranopkgcheck"" ",19,24
openstack%2Fnova~master~I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274,openstack/nova,master,I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274,Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec,MERGED,2019-11-21 01:10:40.000000000,2019-12-22 23:51:02.000000000,2019-12-22 23:38:26.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84bb06b91202d97af6f39a283ea99fc95811b6fb', 'message': 'Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec\n\nThis adds a functional test which uses AggregateInstanceExtraSpecsFilter\nto ensure a host in another cell is selected by the scheduler even\nif that host would otherwise be a lower weight from CrossCellWeigher\nif it were not for the link between the flavor and the aggregate on\nthe host in the other cell.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274\n'}, {'number': 2, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08e631a6dc16e793f1965ccb6640c20d2e314a87', 'message': 'Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec\n\nThis adds a functional test which uses AggregateInstanceExtraSpecsFilter\nto ensure a host in another cell is selected by the scheduler even\nif that host would otherwise be a lower weight from CrossCellWeigher\nif it were not for the link between the flavor and the aggregate on\nthe host in the other cell.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274\n'}, {'number': 3, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5108a1d25049cd514844630cf32129dabc169271', 'message': 'Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec\n\nThis adds a functional test which uses AggregateInstanceExtraSpecsFilter\nto ensure a host in another cell is selected by the scheduler even\nif that host would otherwise be a lower weight from CrossCellWeigher\nif it were not for the link between the flavor and the aggregate on\nthe host in the other cell.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274\n'}, {'number': 4, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d74dd19bc2d4f4fe5aefe082c207a24d0dac0ce', 'message': 'Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec\n\nThis adds a functional test which uses AggregateInstanceExtraSpecsFilter\nto ensure a host in another cell is selected by the scheduler even\nif that host would otherwise be a lower weight from CrossCellWeigher\nif it were not for the link between the flavor and the aggregate on\nthe host in the other cell.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274\n'}, {'number': 5, 'created': '2019-12-12 19:07:41.000000000', 'files': ['nova/tests/functional/test_cross_cell_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/92d4362f8ea1bd083edd8f30461821df7d90a9d5', 'message': 'Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec\n\nThis adds a functional test which uses AggregateInstanceExtraSpecsFilter\nto ensure a host in another cell is selected by the scheduler even\nif that host would otherwise be a lower weight from CrossCellWeigher\nif it were not for the link between the flavor and the aggregate on\nthe host in the other cell.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274\n'}]",0,695336,92d4362f8ea1bd083edd8f30461821df7d90a9d5,64,10,5,6873,,,0,"Add test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec

This adds a functional test which uses AggregateInstanceExtraSpecsFilter
to ensure a host in another cell is selected by the scheduler even
if that host would otherwise be a lower weight from CrossCellWeigher
if it were not for the link between the flavor and the aggregate on
the host in the other cell.

Part of blueprint cross-cell-resize

Change-Id: I6cf0e280ecdaf9090fb1a6b16572ed50ed27d274
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/695336/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/test_cross_cell_migrate.py'],1,84bb06b91202d97af6f39a283ea99fc95811b6fb,bp/cross-cell-resize,"from nova import confCONF = conf.CONF self.cell_to_aggregate = {} self.cell_to_aggregate[cell_name] = agg_id def test_resize_cross_cell_weigher_filtered_to_target_cell_by_spec(self): """"""Variant of test_cold_migrate_cross_cell_weigher_stays_in_source_cell but in this case the flavor used for the resize is restricted via aggregate metadata to host2 in cell2 so even though normally host3 in cell1 would be weigher higher the CrossCellWeigher is a no-op since host3 is filtered out. """""" # Create the server first (should go in host1). old_flavor = self.api.get_flavors()[0] server = self._create_server(old_flavor) # Start another compute host service in cell1. self._start_compute( 'host3', cell_name=self.host_to_cell_mappings['host1']) # Set foo=bar metadata on the cell2 aggregate. self.admin_api.post_aggregate_action( self.cell_to_aggregate['cell2'], {'set_metadata': {'metadata': {'foo': 'bar'}}}) # Create a flavor to use for the resize which has the foo=bar spec. new_flavor = { 'id': uuids.new_flavor, 'name': 'cell2-foo-bar-flavor', 'vcpus': old_flavor['vcpus'], 'ram': old_flavor['ram'], 'disk': old_flavor['disk'] } self.admin_api.post_flavor({'flavor': new_flavor}) self.admin_api.post_extra_spec(new_flavor['id'], {'extra_specs': {'foo': 'bar'}}) # Enable AggregateInstanceExtraSpecsFilter and restart the scheduler. enabled_filters = CONF.filter_scheduler.enabled_filters if 'AggregateInstanceExtraSpecsFilter' not in enabled_filters: enabled_filters.append('AggregateInstanceExtraSpecsFilter') self.flags(enabled_filters=enabled_filters, group='filter_scheduler') self.scheduler_service.stop() self.scheduler_service = self.start_service('scheduler') # Now resize to the new flavor and it should go to host2 in cell2. self.admin_api.post_server_action( server['id'], {'resize': {'flavorRef': new_flavor['id']}}) server = self._wait_for_state_change( self.admin_api, server, 'VERIFY_RESIZE') self.assertEqual('host2', server['OS-EXT-SRV-ATTR:host'])"," # TODO(mriedem): Add a variant of # test_cold_migrate_cross_cell_weigher_stays_in_source_cell where the # flavor being resized to is only available, via aggregate, on the host in # the other cell so the CrossCellWeigher is overruled by the filters.",47,4
openstack%2Fnova~master~Ib18752efa56cfeb860487fe6b26102bb4b1db038,openstack/nova,master,Ib18752efa56cfeb860487fe6b26102bb4b1db038,Add CrossCellWeigher,MERGED,2018-10-30 21:01:50.000000000,2019-12-22 21:31:47.000000000,2019-12-22 21:26:27.000000000,"[{'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26233}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30123}]","[{'number': 1, 'created': '2018-10-30 21:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63c7777a90fec89c4f37c21a68f6c5b5e052b8c9', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 2, 'created': '2018-11-06 17:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bd146390601497a06a74ef655e951cbdbace6fb', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 3, 'created': '2018-11-30 17:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/822c4f79e653d8f1022d4302f713c68498ed02b8', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 4, 'created': '2018-11-30 22:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33e0ed5a7361d636aef484cf8ce062205929f28c', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 5, 'created': '2018-12-18 03:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3ca69bc0d7d887d5fb1b7a40decea5d69e2acab', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 6, 'created': '2018-12-31 15:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01bd78fd386c028138cfba39299d7e1e2cb658f4', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 7, 'created': '2019-01-16 03:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7f95b9c1cbe1a31ae75f701b342473fe1ac3247', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 8, 'created': '2019-01-17 17:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2a243bd9293195353b37e8d68da4bc46f27b35a', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 9, 'created': '2019-01-25 19:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e212b92b570fd38eb0a6a1ca1a23641d489530c4', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 10, 'created': '2019-01-30 00:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd66409ee009304c4640cfd052fc9c77e0a76b71', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 11, 'created': '2019-02-05 17:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/204ef80ad0cc35bbd3de3c6b259b5d4c08772c6e', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 12, 'created': '2019-02-11 19:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e10c854526317cb544f6f8033cf7111801b7c2a5', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 13, 'created': '2019-02-12 18:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e47ded99b98a3e52795c3eb51391174ec83bb50', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell. Therefore this change adds a new CrossCellWeigher\nand related configuration option to prefer hosts within the source\ncell when moving a server. The weigher is completely noop unless\na cross-cell move is permitted by configuration, which will be\nprovided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 14, 'created': '2019-02-14 18:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96dad45ebc1aeb863444822965059e354817c772', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 15, 'created': '2019-02-26 22:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7ef3d81e0314ecf9fdf21927c3aaf5025e4778b', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 16, 'created': '2019-03-07 22:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e280eb5494ec67f24c33963bf18d5798fce8286', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 17, 'created': '2019-03-08 23:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bcd7d7d80abb81aecf954389384c057a334affa', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 18, 'created': '2019-03-11 22:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78de057b2c567ef9fbe6ae00964ef46de2559e57', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll obviously want to select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 19, 'created': '2019-03-14 20:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02921ada5761ccf46ec055dcc3c45fb84d68674f', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 20, 'created': '2019-03-14 20:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cf31e6b81268d27d4cb26cd6d2359d12fff11ed', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 21, 'created': '2019-03-15 11:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3eea35c59510e03948c46145c216c2c340d77861', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 22, 'created': '2019-04-01 22:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2aa2c6178049dce0533c1768b417d6ccd53d4b1e', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 23, 'created': '2019-04-03 21:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/98beba955f34a0ffc11a150a1eb03de998b303c6', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 24, 'created': '2019-04-06 01:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b1cd607f50b15aac8a13cb7ab421708b1b8fef6', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 25, 'created': '2019-04-08 20:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e504eca05dc6bb9d9db92283a810fc55edf09a0d', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 26, 'created': '2019-04-11 19:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78721a2d1b03620a1345d6622d3143ba7cc0090f', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 27, 'created': '2019-04-17 22:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d285a91cc3e56ad7d7f682726c518a3851cbf20a', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 28, 'created': '2019-04-19 01:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3f47b528ebe17cb55d7a90ea1ab75f27c1d214b', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 29, 'created': '2019-04-20 22:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b4afb38dcc13fab9e13a9a2aec9bf6b686014c7', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 30, 'created': '2019-04-26 20:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5d072c882091ba59b37ab56bdbc17ed34b37ef1', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 31, 'created': '2019-04-30 20:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06fc83e21be6736d6b46a5fbe634828fc0015bd1', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 32, 'created': '2019-05-01 15:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9548604335422ee5449536c1bbde082531885123', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 33, 'created': '2019-05-02 03:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e271c29623b2d13423b909dba824d5400e181cd2', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 34, 'created': '2019-05-09 22:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89e55222b8c5a83f2f1b3ec0aadedf779fb370fe', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 35, 'created': '2019-05-13 19:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4095e8a7595cc160f43ab85a75bada4846be1d4', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 36, 'created': '2019-05-16 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b0ce8c0933047395e53cffeed5f9d4de6d37a07', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 37, 'created': '2019-05-22 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ad32b276858bbb8f137115548fc4a361a18ecc7', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 38, 'created': '2019-05-28 23:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c87aa49f904726699397595c8172f0696f1d28e', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 39, 'created': '2019-05-29 21:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a71ed0438ec684a88944aebec752466df5ba938e', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to by default select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 40, 'created': '2019-06-10 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42419a5d9906a312dddde377286313a0904d8507', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 41, 'created': '2019-06-27 16:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/efe09f41b28688d8a2c881d9e1128319fa626772', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 42, 'created': '2019-06-28 00:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b7554f4b5995c04a8d7d3f39ef9267e20165754', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 43, 'created': '2019-07-04 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d787899dd28f66fd62a6bbfa257dcef97d96709', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 44, 'created': '2019-07-05 22:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65d60d87ceb2163103c68d168b7e7f4b86aba50f', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 45, 'created': '2019-07-10 01:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b5fe40f39c8d7323aa45ec3b191657a73704b39', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 46, 'created': '2019-07-26 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51176f6ccfd59b132efca2c4748246dd0beeffa5', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 47, 'created': '2019-08-07 22:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e42cf618193bfe5c85a06b25e66e1468188004a', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 48, 'created': '2019-08-14 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c3c3339a148251c76612cae9160543e1a2f7e44', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 49, 'created': '2019-08-27 19:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00d07e0959c14a02a9c96ae58362a09a92b9e02f', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 50, 'created': '2019-09-04 18:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cda23673366bd420c81cb2c084453a2734a2a7e9', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 51, 'created': '2019-09-21 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e05f900cedc233a1d2795968ecb8e8a647dfffe', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 52, 'created': '2019-10-03 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bad471bfdce7262c25969e9b50e8abdc8f2fa116', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 53, 'created': '2019-10-08 15:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3440b8f30ba7658a19ef63486e708f0e0720f61a', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 54, 'created': '2019-10-14 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c34b313ef83f6cfae490f5bc823d6ee9133bfe8', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 55, 'created': '2019-10-14 18:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94d3917461353567f57c4fcab1d24d2d9cda9cd1', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 56, 'created': '2019-10-16 01:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebf825b8e0316ed12fe2a15677eaf0f3247e80f3', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 57, 'created': '2019-10-21 19:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3875439328e31b66219c33c2612ceddb3edc9a2', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 58, 'created': '2019-11-02 23:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/515cee7157ad3c26bb76bb272a5dc85cc220e8ee', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 59, 'created': '2019-11-03 17:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1271a826e9a831c703ad8510c59d52f38fe26760', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 60, 'created': '2019-11-04 21:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c3638400f4ed44054f7f905ce0386f91609d236', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 61, 'created': '2019-11-05 18:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eacc3eb1d89f31c12c6dba5650b8d686e2a9b15c', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 62, 'created': '2019-11-05 19:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f7160c5b4317c6b36b4a946ec0869316f8a554c', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 63, 'created': '2019-11-12 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0eb832fea75685c01bfc614cb31a39a4a2587d5', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 64, 'created': '2019-11-13 15:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cdf5d38be84d7987fcbf0c5940c30ccba0daa3a', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 65, 'created': '2019-11-15 23:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c09963e6d3fe38b0c78a6b804945c0a2e3f9f392', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 66, 'created': '2019-11-21 01:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db0ae20934f10caab1c08da4469f397507f4ab69', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 67, 'created': '2019-11-27 00:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e4f8b04bef977ef7bfcee744555329627a80a40', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 68, 'created': '2019-12-09 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b66e88c4798becaa82e36e3ac47b69330e7b3069', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 69, 'created': '2019-12-09 17:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/554366b5340b70d3d5478d637967f6a62cd9a136', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}, {'number': 70, 'created': '2019-12-12 19:07:41.000000000', 'files': ['nova/tests/functional/test_cross_cell_migrate.py', 'doc/source/user/filter-scheduler.rst', 'nova/tests/unit/scheduler/weights/test_cross_cell.py', 'doc/source/admin/configuration/schedulers.rst', 'nova/conf/scheduler.py', 'nova/scheduler/weights/cross_cell.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/18179aee4ec933013bae7097fd3c2cb6023b511c', 'message': ""Add CrossCellWeigher\n\nWhen performing a resize, we'll want to (by default) select\ntarget hosts from the source cell to do a traditional resize\nif possible before considering target hosts in another cell\nwhich will be slower and more complicated. If the source cell\nis disabled or target flavor is not available in the source cell,\nthen we'll have no choice but to select a host from another cell.\nBut all things being equal between hosts, we want to stay within\nthe source cell (by default). Therefore this change adds a new\nCrossCellWeigher and related configuration option to prefer hosts\nwithin the source cell when moving a server. The weigher is\ncompletely noop unless a cross-cell move is permitted by\nconfiguration, which will be provided in a future change.\n\nPart of blueprint cross-cell-resize\n\nChange-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038\n""}]",15,614353,18179aee4ec933013bae7097fd3c2cb6023b511c,742,22,70,6873,,,0,"Add CrossCellWeigher

When performing a resize, we'll want to (by default) select
target hosts from the source cell to do a traditional resize
if possible before considering target hosts in another cell
which will be slower and more complicated. If the source cell
is disabled or target flavor is not available in the source cell,
then we'll have no choice but to select a host from another cell.
But all things being equal between hosts, we want to stay within
the source cell (by default). Therefore this change adds a new
CrossCellWeigher and related configuration option to prefer hosts
within the source cell when moving a server. The weigher is
completely noop unless a cross-cell move is permitted by
configuration, which will be provided in a future change.

Part of blueprint cross-cell-resize

Change-Id: Ib18752efa56cfeb860487fe6b26102bb4b1db038
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/614353/69 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/filter-scheduler.rst', 'nova/tests/unit/scheduler/weights/test_cross_cell.py', 'doc/source/admin/configuration/schedulers.rst', 'nova/conf/scheduler.py', 'nova/scheduler/weights/cross_cell.py']",5,63c7777a90fec89c4f37c21a68f6c5b5e052b8c9,bp/cross-cell-resize,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Cross-cell move weigher. Weighs hosts based on which cell they are in. ""Local"" cells are preferred when moving an instance. In other words, select a host from the source cell all other things being equal. """""" from nova import conf from nova.scheduler import weights CONF = conf.CONF class CrossCellWeigher(weights.BaseHostWeigher): def weight_multiplier(self): """"""How weighted this weigher should be."""""" return CONF.filter_scheduler.cross_cell_move_weight_multiplier def _weigh_object(self, host_state, weight_properties): """"""Higher weights win. Hosts within the ""preferred"" cell are weighed higher than hosts in other cells. :param host_state: nova.scheduler.host_manager.HostState object representing a ComputeNode in a cell :param weight_properties: nova.objects.RequestSpec - this is inspected to see if there is a preferred cell via the requested_destination field and if so, is the request spec allowing cross-cell move :returns: 1 if cross-cell move and host_state is within the preferred cell, -1 if cross-cell move and host_state is *not* within the preferred cell, 0 for all other cases """""" # RequestSpec.requested_destination.cell should only be set for # move operations. The cross_cell_move value will only be True if # policy allows. if ('requested_destination' in weight_properties and weight_properties.requested_destination and 'cell' in weight_properties.requested_destination and weight_properties.requested_destination.cell and weight_properties.requested_destination.cross_cell_move): # Determine if the given host is in the ""preferred"" cell from # the request spec. If it is, weigh it higher. if (host_state.cell_uuid == weight_properties.requested_destination.cell.uuid): return 1 # The host is in another cell, so weigh it lower. return -1 # We don't know or don't care what cell we're going to be in, so noop. return 0 ",,192,0
openstack%2Frequirements~master~Idd33d73dd9176b419c512e52764d28065fd793c0,openstack/requirements,master,Idd33d73dd9176b419c512e52764d28065fd793c0,Updated from generate-constraints,MERGED,2019-12-22 06:20:45.000000000,2019-12-22 20:54:02.000000000,2019-12-22 20:52:45.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 06:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2bd119ae11f154a2e7a055506333ec7691f8b943', 'message': 'Updated from generate-constraints\n\nChange-Id: Idd33d73dd9176b419c512e52764d28065fd793c0\n'}, {'number': 2, 'created': '2019-12-22 17:55:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d3959ceadc425e3b78649edb7e2e42c4f3931611', 'message': 'Updated from generate-constraints\n\nChange-Id: Idd33d73dd9176b419c512e52764d28065fd793c0\n'}]",0,700292,d3959ceadc425e3b78649edb7e2e42c4f3931611,10,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: Idd33d73dd9176b419c512e52764d28065fd793c0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/92/700292/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2bd119ae11f154a2e7a055506333ec7691f8b943,openstack/requirements/constraints/noclob,sphinxcontrib-actdiag===0.8.5;python_version=='2.7' sphinxcontrib-actdiag===2.0.0;python_version=='3.4' sphinxcontrib-actdiag===2.0.0;python_version=='3.5' sphinxcontrib-actdiag===2.0.0;python_version=='3.6' sphinxcontrib-actdiag===2.0.0;python_version=='3.7'pytest===4.6.8;python_version=='2.7' pytest===5.3.2;python_version=='3.4' pytest===5.3.2;python_version=='3.5' pytest===5.3.2;python_version=='3.6' pytest===5.3.2;python_version=='3.7'sphinxcontrib-nwdiag===0.9.5;python_version=='2.7' sphinxcontrib-nwdiag===2.0.0;python_version=='3.4' sphinxcontrib-nwdiag===2.0.0;python_version=='3.5' sphinxcontrib-nwdiag===2.0.0;python_version=='3.6' sphinxcontrib-nwdiag===2.0.0;python_version=='3.7'grpcio===1.26.0 skydive-client===0.7.0waitress===1.4.0zeroconf===0.24.2;python_version=='3.4' zeroconf===0.24.2;python_version=='3.5' zeroconf===0.24.2;python_version=='3.6' zeroconf===0.24.2;python_version=='3.7'scipy===1.4.1;python_version=='3.4' scipy===1.4.1;python_version=='3.5' scipy===1.4.1;python_version=='3.6' scipy===1.4.1;python_version=='3.7'pymongo===3.10.0pyghmi===1.5.3 sphinxcontrib-blockdiag===1.5.5;python_version=='2.7' sphinxcontrib-blockdiag===2.0.0;python_version=='3.4' sphinxcontrib-blockdiag===2.0.0;python_version=='3.5' sphinxcontrib-blockdiag===2.0.0;python_version=='3.6' sphinxcontrib-blockdiag===2.0.0;python_version=='3.7'semantic-version===2.8.4SQLAlchemy===1.3.12google-auth===1.10.0libvirt-python===5.10.0tinyrpc===1.0.4daiquiri===1.6.1cliff===2.17.0zhmcclient===0.25.1joblib===0.14.1;python_version=='3.4' joblib===0.14.1;python_version=='3.5' joblib===0.14.1;python_version=='3.6' joblib===0.14.1;python_version=='3.7'coverage===5.0importlib-metadata===1.3.0uritemplate===3.0.1mypy===0.761;python_version=='3.4' mypy===0.761;python_version=='3.5' mypy===0.761;python_version=='3.6' mypy===0.761;python_version=='3.7'sphinxcontrib-seqdiag===0.8.5;python_version=='2.7' sphinxcontrib-seqdiag===2.0.0;python_version=='3.4' sphinxcontrib-seqdiag===2.0.0;python_version=='3.5' sphinxcontrib-seqdiag===2.0.0;python_version=='3.6' sphinxcontrib-seqdiag===2.0.0;python_version=='3.7'boto3===1.10.44stestr===2.6.0infinisdk===151.1.1asgiref===3.2.3;python_version=='3.4' asgiref===3.2.3;python_version=='3.5' asgiref===3.2.3;python_version=='3.6' asgiref===3.2.3;python_version=='3.7'pifpaf===2.3.0protobuf===3.11.2python-qpid-proton===0.30.0sympy===1.5Sphinx===2.3.0;python_version=='3.4' Sphinx===2.3.0;python_version=='3.5' Sphinx===2.3.0;python_version=='3.6' Sphinx===2.3.0;python_version=='3.7'httplib2===0.15.0botocore===1.13.44Django===1.11.27;python_version=='2.7' Django===3.0.1;python_version=='3.4' Django===3.0.1;python_version=='3.5' Django===3.0.1;python_version=='3.6' Django===3.0.1;python_version=='3.7'yappi===1.2.3cachetools===3.1.1;python_version=='2.7' cachetools===4.0.0;python_version=='3.4' cachetools===4.0.0;python_version=='3.5' cachetools===4.0.0;python_version=='3.6' cachetools===4.0.0;python_version=='3.7'diskimage-builder===2.32.0alembic===1.3.2confluent-kafka===1.3.0virtualenv===16.7.9,sphinxcontrib-actdiag===0.8.5pytest===4.6.7;python_version=='2.7' pytest===5.3.1;python_version=='3.4' pytest===5.3.1;python_version=='3.5' pytest===5.3.1;python_version=='3.6' pytest===5.3.1;python_version=='3.7'sphinxcontrib-nwdiag===0.9.5grpcio===1.25.0 skydive-client===0.5.0waitress===1.3.1zeroconf===0.24.0;python_version=='3.4' zeroconf===0.24.0;python_version=='3.5' zeroconf===0.24.0;python_version=='3.6' zeroconf===0.24.0;python_version=='3.7'scipy===1.3.3;python_version=='3.4' scipy===1.3.3;python_version=='3.5' scipy===1.3.3;python_version=='3.6' scipy===1.3.3;python_version=='3.7'pymongo===3.9.0pyghmi===1.4.1 sphinxcontrib-blockdiag===1.5.5semantic-version===2.8.3SQLAlchemy===1.3.11google-auth===1.8.1libvirt-python===5.9.0tinyrpc===1.0.3daiquiri===1.6.0cliff===2.16.0zhmcclient===0.24.0joblib===0.14.0;python_version=='3.4' joblib===0.14.0;python_version=='3.5' joblib===0.14.0;python_version=='3.6' joblib===0.14.0;python_version=='3.7'coverage===4.5.4importlib-metadata===1.2.0uritemplate===3.0.0mypy===0.750;python_version=='3.4' mypy===0.750;python_version=='3.5' mypy===0.750;python_version=='3.6' mypy===0.750;python_version=='3.7'sphinxcontrib-seqdiag===0.8.5boto3===1.10.8stestr===2.5.1infinisdk===141.1.0pifpaf===2.2.2protobuf===3.11.1python-qpid-proton===0.29.0sympy===1.4Sphinx===2.2.2;python_version=='3.4' Sphinx===2.2.2;python_version=='3.5' Sphinx===2.2.2;python_version=='3.6' Sphinx===2.2.2;python_version=='3.7'httplib2===0.14.0botocore===1.13.8Django===1.11.26;python_version=='2.7' Django===2.0.13;python_version=='3.4' Django===2.0.13;python_version=='3.5' Django===2.2;python_version=='3.6' Django===2.2;python_version=='3.7'yappi===1.0cachetools===3.1.1diskimage-builder===2.31.0alembic===1.3.1confluent-kafka===1.2.0virtualenv===16.7.8,89,65
openstack%2Fironic-inspector~master~Ib977e850de2cfc88b161d9f276c1c8df6699bb45,openstack/ironic-inspector,master,Ib977e850de2cfc88b161d9f276c1c8df6699bb45,Imported Translations from Zanata,MERGED,2019-12-22 07:22:47.000000000,2019-12-22 20:01:02.000000000,2019-12-22 19:59:42.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-22 07:22:47.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'ironic_inspector/locale/en_GB/LC_MESSAGES/ironic_inspector.po'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/aff01c6685db904de56e97026b618f41047368c6', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ib977e850de2cfc88b161d9f276c1c8df6699bb45\n'}]",0,700305,aff01c6685db904de56e97026b618f41047368c6,9,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ib977e850de2cfc88b161d9f276c1c8df6699bb45
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/05/700305/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'ironic_inspector/locale/en_GB/LC_MESSAGES/ironic_inspector.po']",2,aff01c6685db904de56e97026b618f41047368c6,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-19 20:03+0000\n""""PO-Revision-Date: 2019-12-21 02:30+0000\n""msgid ""... terminating migration tool"" msgstr ""... terminating migration tool"" msgid ""BMC addresses %(addr)s correspond to more than one node: %(nodes)s"" msgstr ""BMC addresses %(addr)s correspond to more than one node: %(nodes)s"" #, python-formatmsgid """" ""Cannot find the bare metal endpoint either in Keystone or in the "" ""configuration"" msgstr """" ""Cannot find the bare metal endpoint either in Keystone or in the "" ""configuration"" ""Cannot pass reset_interfaces to set-attribute, requires API 1.46 and "" ""ironicclient >= 2.5.0"" msgstr """" ""Cannot pass reset_interfaces to set-attribute, requires API 1.46 and "" ""ironicclient >= 2.5.0"" msgid """"msgid ""Could not connect to the object storage service: %s"" msgstr ""Could not connect to the object storage service: %s"" #, python-formatmsgid """" ""Existing node cannot be found since neither MAC addresses nor BMC addresses "" ""are present in the inventory"" msgstr """" ""Existing node cannot be found since neither MAC addresses nor BMC addresses "" ""are present in the inventory"" #, python-format msgid """" ""Existing node was not found by MAC address(es) %(macs)s and BMC address(es) "" ""%(addr)s"" msgstr """" ""Existing node was not found by MAC address(es) %(macs)s and BMC address(es) "" ""%(addr)s"" #, python-format msgid ""Failed reapply for node %(node)s, Error: %(exc)s"" msgstr ""Failed reapply for node %(node)s, Error: %(exc)s"" msgid """" ""IP version of BMC address that will be used when enrolling a new node in "" ""Ironic. Defaults to \""4,6\"". Could be \""4\"" (use v4 address only), "" ""\""4,6\"" (v4 address have higher priority and if both addresses found v6 "" ""version is ignored), \""6,4\"" (v6 is desired but fall back to v4 address for "" ""BMCs having v4 address, opposite to \""4,6\""), \""6\"" (use v6 address only and "" ""ignore v4 version)."" msgstr """" ""IP version of BMC address that will be used when enrolling a new node in "" ""Ironic. Defaults to \""4,6\"". Could be \""4\"" (use v4 address only), "" ""\""4,6\"" (v4 address have higher priority and if both addresses found v6 "" ""version is ignored), \""6,4\"" (v6 is desired but fall back to v4 address for "" ""BMCs having v4 address, opposite to \""4,6\""), \""6\"" (use v6 address only and "" ""ignore v4 version)."" msgid ""IPv4"" msgstr ""IPv4"" msgid ""IPv6"" msgstr ""IPv6"" ""Inspector is not configured to store data. Set the [processing]store_data """"Inspector is not configured to store data. Set the [processing]store_data ""msgid """" ""Inspector is not configured to store introspection data. Set the "" ""[processing]store_data configuration option to change this."" msgstr """" ""Inspector is not configured to store introspection data. Set the "" ""[processing]store_data configuration option to change this."" msgid ""Introspection data not found for node %(node)s, processed=%(processed)s"" msgstr """" ""Introspection data not found for node %(node)s, processed=%(processed)s"" #, python-format#, python-format msgid """" ""MAC addresses %(mac)s and BMC addresses %(addr)s correspond to different "" ""nodes: %(node1)s and %(node2)s"" msgstr """" ""MAC addresses %(mac)s and BMC addresses %(addr)s correspond to different "" ""nodes: %(node1)s and %(node2)s"" #, python-format msgid ""MAC addresses %(macs)s correspond to more than one node: %(nodes)s"" msgstr ""MAC addresses %(macs)s correspond to more than one node: %(nodes)s"" msgid ""Malformed API version: expected string in form of X.Y or latest"" msgstr ""Malformed API version: expected string in form of X.Y or latest""""Name of this node. This can be an opaque identifier. It is not necessarily a "" ""hostname, FQDN, or IP address. However, the node name must be valid within "" ""an AMQP key, and if using ZeroMQ, a valid hostname, FQDN, or IP address.""""Name of this node. This can be an opaque identifier. It is not necessarily a "" ""hostname, FQDN, or IP address. However, the node name must be valid within "" ""an AMQP key, and if using ZeroMQ, a valid hostname, FQDN, or IP address.""msgid ""No network interfaces provided in the inventory"" msgstr ""No network interfaces provided in the inventory"" msgid ""Node %(node)s is not active, its provision state is %(state)s"" msgstr ""Node %(node)s is not active, its provision state is %(state)s"" #, python-format msgid ""Node %(uuid)s already has BMC address %(addr)s"" msgstr ""Node %(uuid)s already has BMC address %(addr)s""msgid ""Source and destination can not be the same."" msgstr ""Source and destination can not be the same.""msgid ""The IP version that will be used for iptables filter. Defaults to 4."" msgstr ""The IP version that will be used for iptables filter. Defaults to 4.""msgid ""The Swift storage backend"" msgstr ""The Swift storage backend"" msgid ""The backend URL to use for distributed coordination. EXPERIMENTAL."" msgstr ""The backend URL to use for distributed coordination. EXPERIMENTAL."" msgid ""The database storage backend"" msgstr ""The database storage backend"" msgid ""The source storage where the introspected data will be read from."" msgstr ""The source storage where the introspected data will be read from."" msgid """" ""The storage backend for storing introspection data. Possible values are: "" ""'none', 'database' and 'swift'. If set to 'none', introspection data will "" ""not be stored."" msgstr """" ""The storage backend for storing introspection data. Possible values are: "" ""'none', 'database' and 'swift'. If set to 'none', introspection data will "" ""not be stored."" msgid ""The target storage where the introspected data will be saved to."" msgstr ""The target storage where the introspected data will be saved to."" msgid ""This option is deprecated and has no effect."" msgstr ""This option is deprecated and has no effect."" msgid """" ""To run ironic-inspector in standalone mode, [DEFAULT]standalone should be "" ""set to True."" msgstr """" ""To run ironic-inspector in standalone mode, [DEFAULT]standalone should be "" ""set to True."" msgid """" ""To run ironic-inspector-api, [DEFAULT]standalone should be set to False."" msgstr """" ""To run ironic-inspector-api, [DEFAULT]standalone should be set to False."" msgid """" ""To run ironic-inspector-conductor, [DEFAULT]standalone should be set to "" ""False."" msgstr """" ""To run ironic-inspector-conductor, [DEFAULT]standalone should be set to "" ""False."" ""Whether to enable publishing the ironic-inspector API endpoint via multicast "" ""DNS."" msgstr """" ""Whether to enable publishing the Ironic-inspector API endpoint via multicast "" ""DNS."" msgid """"msgid """" ""Whether to power off a node after introspection.Nodes in active or rescue "" ""states which submit introspection data will be left on if the feature is "" ""enabled via the 'permit_active_introspection' configuration option."" msgstr """" ""Whether to power off a node after introspection.Nodes in active or rescue "" ""states which submit introspection data will be left on if the feature is "" ""enabled via the 'permit_active_introspection' configuration option."" msgid ""Whether to process nodes that are in running states."" msgstr ""Whether to process nodes that are in running states."" msgid """" ""Whether to run ironic-inspector as a standalone service. It's EXPERIMENTAL "" ""to set to False."" msgstr """" ""Whether to run Ironic-inspector as a standalone service. It's EXPERIMENTAL "" ""to set to False.""msgid ""missing required parameter(s): value"" msgstr ""missing required parameter(s): value"" ","""POT-Creation-Date: 2018-08-31 23:36+0000\n""""PO-Revision-Date: 2018-08-09 08:49+0000\n""""Inspector is not configured to store data. Set the [processing] store_data """"Inspector is not configured to store data. Set the [processing] store_data ""#, python-format msgid ""Invalid hardware inventory: %s key is missing or empty"" msgstr ""Invalid hardware inventory: %s key is missing or empty"" msgid """" ""Ironic API URL, used to set Ironic API URL when auth_strategy option is "" ""noauth or auth_type is \""none\"" to work with standalone Ironic without "" ""keystone."" msgstr """" ""Ironic API URL, used to set Ironic API URL when auth_strategy option is "" ""noauth or auth_type is \""none\"" to work with standalone Ironic without "" ""Keystone."" msgid ""Ironic endpoint type."" msgstr ""Ironic endpoint type."" msgid ""Ironic service type."" msgstr ""Ironic service type."" msgid ""Keystone region to get endpoint for."" msgstr ""Keystone region to get endpoint for."" msgid ""Keystone region used to get Ironic endpoints."" msgstr ""Keystone region used to get Ironic endpoints."" msgid ""Malformed API version: expected string in form of X.Y"" msgstr ""Malformed API version: expected string in form of X.Y""msgid ""Maximum number of times to retry a Swift request, before failing."" msgstr ""Maximum number of times to retry a Swift request, before failing."" msgid """" ""Method for storing introspection data. If set to 'none', introspection data "" ""will not be stored."" msgstr """" ""Method for storing introspection data. If set to 'none', introspection data "" ""will not be stored."" msgid ""Method to use for authentication: noauth or keystone."" msgstr ""Method to use for authentication: noauth or Keystone."" ""Name of the key to store the location of stored data in the extra column of "" ""the Ironic database.""""Name of the key to store the location of stored data in the extra column of "" ""the Ironic database.""msgid ""Node %(uuid)s already has BMC address %(ipmi_address)s, not enrolling"" msgstr ""Node %(uuid)s already has BMC address %(ipmi_address)s, not enrolling""msgid ""Path to SSL certificate"" msgstr ""Path to SSL certificate"" msgid ""Path to SSL key"" msgstr ""Path to SSL key"" msgid ""Swift endpoint type."" msgstr ""Swift endpoint type.""msgid ""Swift service type."" msgstr ""Swift service type."" msgid ""Swift support is disabled"" msgstr ""Swift support is disabled""#, python-format msgid ""The following problems encountered: %s"" msgstr ""The following problems encountered: %s"" ""Unexpected exception %(exc_class)s while fetching unprocessed introspection "" ""data from Swift: %(error)s"" msgstr """" ""Unexpected exception %(exc_class)s while fetching unprocessed introspection "" ""data from Swift: %(error)s"" #, python-format msgid """"msgid """" ""Use [ironic]/auth_type, for noauth case set [ironic]/auth_type to `none` and "" ""specify ironic API URL via [ironic]/endpoint_override option."" msgstr """" ""Use [ironic]/auth_type, for noauth case set [ironic]/auth_type to `none` and "" ""specify ironic API URL via [ironic]/endpoint_override option."" msgid ""Use [ironic]/endpoint_override option to set a specific ironic API url."" msgstr """" ""Use [ironic]/endpoint_override option to set a specific ironic API URL."" msgid ""Use [ironic]/region_name option instead to configure region."" msgstr ""Use [ironic]/region_name option instead to configure region."" msgid ""Use [ironic]/service_type option to set a specific type."" msgstr ""Use [ironic]/service_type option to set a specific type."" msgid ""Use [ironic]/valid_interfaces option to specify endpoint interfaces."" msgstr ""Use [ironic]/valid_interfaces option to specify endpoint interfaces."" msgid ""Use [swift]/region_name option to configure region."" msgstr ""Use [swift]/region_name option to configure region."" msgid ""Use [swift]/service_type option to set specific service type"" msgstr ""Use [swift]/service_type option to set specific service type"" msgid ""Use [swift]/valid_interfaces option to specify endpoint interfaces."" msgstr ""Use [swift]/valid_interfaces option to specify endpoint interfaces."" msgid ""User data processing is not supported yet"" msgstr ""User data processing is not supported yet"" msgid ""Whether to power off a node after introspection."" msgstr ""Whether to power off a node after introspection.""msgid ""malformed or missing CPU information: %s"" msgstr ""malformed or missing CPU information: %s"" #, python-format msgid """" ""malformed or missing memory information: %s; introspection requires physical "" ""memory size from dmidecode"" msgstr """" ""malformed or missing memory information: %s; introspection requires physical "" ""memory size from dmidecode"" #, python-format",392,129
openstack%2Fopenstacksdk~master~Icb64406aac362fe54a82463a9afb499233c09fe7,openstack/openstacksdk,master,Icb64406aac362fe54a82463a9afb499233c09fe7,Add return cluster_id when query actions list,MERGED,2019-12-18 10:23:02.000000000,2019-12-22 20:01:02.000000000,2019-12-22 19:59:36.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-12-18 10:23:02.000000000', 'files': ['openstack/tests/unit/clustering/v1/test_action.py', 'openstack/clustering/v1/action.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/29de7af09f6d48cb89e6a2200a5abfc5a1c05335', 'message': 'Add return cluster_id when query actions list\n\nWith Senlin API version greater than 1.14. It will return cluster_id\nin each action object\n\nChange-Id: Icb64406aac362fe54a82463a9afb499233c09fe7\n'}]",0,699650,29de7af09f6d48cb89e6a2200a5abfc5a1c05335,9,4,1,28691,,,0,"Add return cluster_id when query actions list

With Senlin API version greater than 1.14. It will return cluster_id
in each action object

Change-Id: Icb64406aac362fe54a82463a9afb499233c09fe7
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/699650/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/clustering/v1/action.py', 'openstack/tests/unit/clustering/v1/test_action.py']",2,29de7af09f6d48cb89e6a2200a5abfc5a1c05335,change_version,"FAKE_CLUSTER_ID = 'ffaed25e-46f5-4089-8e20-b3b4722fd597' 'cluster_id': FAKE_CLUSTER_ID, self.assertEqual(FAKE['cluster_id'], sot.cluster_id)",,5,0
openstack%2Fironic-ui~master~I11c7367ec7b870aea1046559ba82cd5d54e7d348,openstack/ironic-ui,master,I11c7367ec7b870aea1046559ba82cd5d54e7d348,Imported Translations from Zanata,MERGED,2019-12-22 06:33:44.000000000,2019-12-22 19:15:45.000000000,2019-12-22 19:14:25.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 06:33:44.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/70a293d31ac4fb7f465b59e7a3c539c5629a205f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I11c7367ec7b870aea1046559ba82cd5d54e7d348\n'}]",0,700295,70a293d31ac4fb7f465b59e7a3c539c5629a205f,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I11c7367ec7b870aea1046559ba82cd5d54e7d348
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/95/700295/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,70a293d31ac4fb7f465b59e7a3c539c5629a205f,zanata/translations,"""POT-Creation-Date: 2019-11-28 10:21+0000\n""""PO-Revision-Date: 2019-12-21 02:28+0000\n""msgid ""3.5.2-8"" msgstr ""3.5.2-8"" msgid """" ""Python 2.7 support has been dropped. Last release of ironic-ui to support "" ""Python 2.7 is OpenStack Train. The minimum version of Python now supported "" ""by ironic-ui is Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of ironic-ui to support "" ""Python 2.7 is OpenStack Train. The minimum version of Python now supported "" ""by Ironic-ui is Python 3.6."" msgid ""Upgrade Notes"" msgstr ""Upgrade Notes""","""POT-Creation-Date: 2019-10-29 15:16+0000\n""""PO-Revision-Date: 2019-11-14 11:17+0000\n""",17,2
openstack%2Freleases~master~Ie063c5fd3b6594afa6157d9a5764e3e45eaa7c4a,openstack/releases,master,Ie063c5fd3b6594afa6157d9a5764e3e45eaa7c4a,mistral-dashboard is released as part of mistral,MERGED,2019-12-18 14:27:05.000000000,2019-12-22 17:54:47.000000000,2019-12-19 10:04:50.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 14:27:05.000000000', 'files': ['deliverables/ussuri/mistral-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/451b9ee4bc0b652718bdefad31c6c2cf25d25b14', 'message': 'mistral-dashboard is released as part of mistral\n\nAccording to governance (and the first release in Ussuri),\nthe openstack/mistral-dashboard repository is released as part\nof the mistral deliverable, so it does not need its extra deliverable\nfile.\n\nChange-Id: Ie063c5fd3b6594afa6157d9a5764e3e45eaa7c4a\n'}]",0,699689,451b9ee4bc0b652718bdefad31c6c2cf25d25b14,11,3,1,308,,,0,"mistral-dashboard is released as part of mistral

According to governance (and the first release in Ussuri),
the openstack/mistral-dashboard repository is released as part
of the mistral deliverable, so it does not need its extra deliverable
file.

Change-Id: Ie063c5fd3b6594afa6157d9a5764e3e45eaa7c4a
",git fetch https://review.opendev.org/openstack/releases refs/changes/89/699689/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ussuri/mistral-dashboard.yaml'],1,451b9ee4bc0b652718bdefad31c6c2cf25d25b14,data-alignment,,--- launchpad: mistral release-model: cycle-with-rc team: mistral type: horizon-plugin repository-settings: openstack/mistral-dashboard: {} ,0,7
openstack%2Fneutron-tempest-plugin~master~Iec3fda32cbce00a677cb30dac3c234c99d7c27fd,openstack/neutron-tempest-plugin,master,Iec3fda32cbce00a677cb30dac3c234c99d7c27fd,Add test to attach and detach policies with regular client,MERGED,2019-11-04 14:14:34.000000000,2019-12-22 17:38:00.000000000,2019-12-22 17:38:00.000000000,"[{'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 28609}, {'_account_id': 28935}, {'_account_id': 30920}]","[{'number': 1, 'created': '2019-11-04 14:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/8224963be0e74d2c9f7839ba7809d0d3dac880b5', 'message': 'Add test to attach and detach policies with regular client\n\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 2, 'created': '2019-11-05 08:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f233f25058dfd85c49aec6fe1679eb7c3eb3f2ff', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks that were configured as ""Shared"".\n\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 3, 'created': '2019-11-05 11:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/5b54ece8a350a3044e67e833ad8764fe21fac1da', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks that were configured as ""Shared"".\n\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 4, 'created': '2019-11-06 10:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/2f2de10b9ccfe0ef11d5218882efe91466226874', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks with policies that were configured as ""Shared"".\n\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 5, 'created': '2019-12-01 08:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/74d515aa226a6b30ece7c0efa2ff2fc74a052e2a', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks with policies that were configured as ""Shared"".\n\nThe test will not be running automatically,\nSetting the create_shared_qos_policy option as \'True\' in the config file is needed.\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 6, 'created': '2019-12-01 11:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/a30462b7d0d31f413e8e968ae699819ac1f06ea2', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks with policies that were configured as ""Shared"".\n\nThe test will not be running automatically,\nSetting the create_shared_qos_policy option as \'True\' in the config.py file is needed.\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 7, 'created': '2019-12-02 08:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/149533ec1ab6859f29878810051818539252ad45', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowd to attach\\detach\nQoS policies only to\\from networks with policies that were configured as ""Shared"".\n\nThe test will not be running automatically,\nSetting the create_shared_qos_policy option as \'True\' in the config.py file is needed.\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 8, 'created': '2019-12-08 09:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/56489152f31de148db341074bdca2abcf94a0e85', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowed to attach\\detach\nQoS policies only to\\from networks with policies that were configured as ""Shared"".\n\nThe test will not be running automatically,\nSetting the create_shared_resources option as \'True\' in the config.py file is needed.\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}, {'number': 9, 'created': '2019-12-15 08:48:50.000000000', 'files': ['neutron_tempest_plugin/api/test_qos.py', 'neutron_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/07f0e788712eba07361a8675e9fb6299ead9ee38', 'message': 'Add test to attach and detach policies with regular client\n\nThe test validates that a regular client is allowed to attach\\detach\nQoS policies only to\\from networks with policies that were configured\nas ""Shared"".\n\nThis test will not be running automatically because of the creation\nof a ""Shared"" resource during the test.\nSetting the create_shared_resources option as \'True\' in the config.py\nfile is needed.\n\nChange-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd\n'}]",27,692822,07f0e788712eba07361a8675e9fb6299ead9ee38,45,7,9,30920,,,0,"Add test to attach and detach policies with regular client

The test validates that a regular client is allowed to attach\detach
QoS policies only to\from networks with policies that were configured
as ""Shared"".

This test will not be running automatically because of the creation
of a ""Shared"" resource during the test.
Setting the create_shared_resources option as 'True' in the config.py
file is needed.

Change-Id: Iec3fda32cbce00a677cb30dac3c234c99d7c27fd
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/22/692822/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/api/test_qos.py'],1,8224963be0e74d2c9f7839ba7809d0d3dac880b5,attach_and_detach_policy," @decorators.idempotent_id('d911707e-fa2c-11e9-9553-5076af30bbf5') def test_attach_and_detach_a_policy_by_a_tenant(self): # As an admin Create a policy, add a rule and associate it with a network self.network = self.create_network() policy = self.create_qos_policy(name='test-policy', description='test policy for attach', shared=False) self.admin_client.create_bandwidth_limit_rule( policy['id'], 1024, 1024)['bandwidth_limit_rule'] self.admin_client.update_network( self.network['id'], qos_policy_id=policy['id']) # As a tenant, try to detach the policy from the network - should be forbidden self.assertRaises( exceptions.Forbidden, self.client.update_network, self.network['id'], qos_policy_id=None) # As an admin, make the policy shared self.admin_client.update_qos_policy(policy['id'], shared=True) # As a tenant, try to detach the policy from the network - should be allowed self.client.update_network(self.network['id'], qos_policy_id=None) retrieved_network = self.admin_client.show_network(self.network['id']) self.assertEqual( None, retrieved_network['network']['qos_policy_id']) # As a tenant, try to delete the policy from the network - should be forbidden self.assertRaises( exceptions.Forbidden, self.client.delete_qos_policy, policy['id']) ",,37,0
openstack%2Fzun~stable%2Ftrain~I7bf9ab18421a9b9c15d9c71d4b5a71c24be6b5aa,openstack/zun,stable/train,I7bf9ab18421a9b9c15d9c71d4b5a71c24be6b5aa,Update installation guide for train release,MERGED,2019-11-30 18:09:23.000000000,2019-12-22 17:37:20.000000000,2019-12-22 17:36:15.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-30 18:09:23.000000000', 'files': ['doc/source/install/verify.rst', 'doc/source/install/controller-install.rst', 'doc/source/install/compute-install.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/eea0bae1ff8a06af754895cf37bdbd92feaab997', 'message': 'Update installation guide for train release\n\nChange-Id: I7bf9ab18421a9b9c15d9c71d4b5a71c24be6b5aa\n'}]",0,696777,eea0bae1ff8a06af754895cf37bdbd92feaab997,11,2,1,11536,,,0,"Update installation guide for train release

Change-Id: I7bf9ab18421a9b9c15d9c71d4b5a71c24be6b5aa
",git fetch https://review.opendev.org/openstack/zun refs/changes/77/696777/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/verify.rst', 'doc/source/install/controller-install.rst', 'doc/source/install/compute-install.rst']",3,eea0bae1ff8a06af754895cf37bdbd92feaab997,, # git clone -b stable/train https://git.openstack.org/openstack/zun.git, # git clone https://git.openstack.org/openstack/zun.git,3,3
openstack%2Fzun-ui~master~Ieef76c32fad41fafe17df069e72b461806a62d5e,openstack/zun-ui,master,Ieef76c32fad41fafe17df069e72b461806a62d5e,Imported Translations from Zanata,MERGED,2019-12-22 06:46:07.000000000,2019-12-22 17:20:11.000000000,2019-12-22 17:18:48.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 06:46:07.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/zun-ui/commit/aacf0cf92079ec7ad39f74b9319bfc991c546106', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ieef76c32fad41fafe17df069e72b461806a62d5e\n'}]",0,700298,aacf0cf92079ec7ad39f74b9319bfc991c546106,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ieef76c32fad41fafe17df069e72b461806a62d5e
",git fetch https://review.opendev.org/openstack/zun-ui refs/changes/98/700298/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,aacf0cf92079ec7ad39f74b9319bfc991c546106,zanata/translations,"""POT-Creation-Date: 2019-12-17 02:30+0000\n""""PO-Revision-Date: 2019-12-21 02:52+0000\n""msgid ""4.0.0-13"" msgstr ""4.0.0-13""","""POT-Creation-Date: 2019-11-01 20:09+0000\n""""PO-Revision-Date: 2019-11-14 11:34+0000\n""msgid ""4.0.0-9"" msgstr ""4.0.0-9""",4,4
openstack%2Foslo.context~master~Icd5c18a2eb0d75f015e7ea7ee3c6554055a24798,openstack/oslo.context,master,Icd5c18a2eb0d75f015e7ea7ee3c6554055a24798,tox: Trivial cleanup,MERGED,2019-12-19 14:45:00.000000000,2019-12-22 15:59:08.000000000,2019-12-20 10:24:25.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-19 14:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/52e9825bb392c3786ba33387b31902cbe136a209', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: Icd5c18a2eb0d75f015e7ea7ee3c6554055a24798\n""}, {'number': 2, 'created': '2019-12-19 14:47:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.context/commit/b53efb7fcb25bbd80b8e6581cf2725d8e14fd59e', 'message': ""tox: Trivial cleanup\n\nmove 'basepython' to the top-level 'testenv'\n\nChange-Id: Icd5c18a2eb0d75f015e7ea7ee3c6554055a24798\n""}]",0,699999,b53efb7fcb25bbd80b8e6581cf2725d8e14fd59e,11,3,2,22165,,,0,"tox: Trivial cleanup

move 'basepython' to the top-level 'testenv'

Change-Id: Icd5c18a2eb0d75f015e7ea7ee3c6554055a24798
",git fetch https://review.opendev.org/openstack/oslo.context refs/changes/99/699999/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,52e9825bb392c3786ba33387b31902cbe136a209,,minversion = 3.1 ignore_basepython_conflict = Truebasepython = python3,minversion = 2.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,3,7
openstack%2Ftrove~stable%2Ftrain~I484d45f24176c89d999864d3eb1c48860b3038bd,openstack/trove,stable/train,I484d45f24176c89d999864d3eb1c48860b3038bd,Fix delete instance,MERGED,2019-12-21 10:37:44.000000000,2019-12-22 14:08:28.000000000,2019-12-22 14:07:09.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 10:37:44.000000000', 'files': ['trove/taskmanager/models.py', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/trove/commit/3e7b8cf83af78d05f247e7113d560746ef5dde61', 'message': 'Fix delete instance\n\nDeal with the situation when Trove fails to look for the Nova server\nwhen waiting for the db instance ACTIVE\n\nChange-Id: I484d45f24176c89d999864d3eb1c48860b3038bd\n(cherry picked from commit d93a4109436af6517b9f9276b27c517a30bcd86e)\n'}]",0,700274,3e7b8cf83af78d05f247e7113d560746ef5dde61,12,2,1,6732,,,0,"Fix delete instance

Deal with the situation when Trove fails to look for the Nova server
when waiting for the db instance ACTIVE

Change-Id: I484d45f24176c89d999864d3eb1c48860b3038bd
(cherry picked from commit d93a4109436af6517b9f9276b27c517a30bcd86e)
",git fetch https://review.opendev.org/openstack/trove refs/changes/74/700274/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/taskmanager/models.py', 'devstack/plugin.sh']",2,3e7b8cf83af78d05f247e7113d560746ef5dde61,fix-delete-instance-stable/train," iniset $TROVE_CONF DEFAULT network_label_regex """"", iniset $TROVE_CONF DEFAULT network_label_regex ${PRIVATE_NETWORK_NAME},16,6
openstack%2Fmanila-ui~master~I53de57c8fd10bd89989e6122aca9cb501f265b0e,openstack/manila-ui,master,I53de57c8fd10bd89989e6122aca9cb501f265b0e,Imported Translations from Zanata,MERGED,2019-12-22 07:07:16.000000000,2019-12-22 12:18:30.000000000,2019-12-22 12:17:04.000000000,"[{'_account_id': 9003}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 07:07:16.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/d4d99891b8ddb126212dceef26c37c5b5ac7b06e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I53de57c8fd10bd89989e6122aca9cb501f265b0e\n'}]",0,700302,d4d99891b8ddb126212dceef26c37c5b5ac7b06e,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I53de57c8fd10bd89989e6122aca9cb501f265b0e
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/02/700302/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,d4d99891b8ddb126212dceef26c37c5b5ac7b06e,zanata/translations,"""POT-Creation-Date: 2019-11-15 16:30+0000\n""""PO-Revision-Date: 2019-12-21 02:39+0000\n""msgid ""2.19.0-12"" msgstr ""2.19.0-12""","""POT-Creation-Date: 2019-11-09 20:46+0000\n""""PO-Revision-Date: 2019-11-14 11:19+0000\n""msgid ""2.19.0-11"" msgstr ""2.19.0-11""",4,4
openstack%2Fceilometer~master~I4e5df45bf85cf8d15500f058143ce16bfccf65e0,openstack/ceilometer,master,I4e5df45bf85cf8d15500f058143ce16bfccf65e0,Imported Translations from Zanata,MERGED,2019-12-22 08:47:48.000000000,2019-12-22 09:42:41.000000000,2019-12-22 09:41:16.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 08:47:48.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ee092b0e7ab886fc0441902fe036b77e5286593a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4e5df45bf85cf8d15500f058143ce16bfccf65e0\n'}]",0,700317,ee092b0e7ab886fc0441902fe036b77e5286593a,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4e5df45bf85cf8d15500f058143ce16bfccf65e0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/17/700317/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,ee092b0e7ab886fc0441902fe036b77e5286593a,zanata/translations,"""POT-Creation-Date: 2019-12-09 08:14+0000\n""""PO-Revision-Date: 2019-12-21 01:04+0000\n""msgid ""12.0.0-15"" msgstr ""12.0.0-15""msgid ""13.0.0.0rc1-19"" msgstr ""13.0.0.0rc1-19"" ""Add the support for non-OpenStack APIs in the dynamic pollster system. This "" ""extension enables operators to create pollster on the fly to handle metrics "" ""from systems such as the RadosGW API."" msgstr """" ""Add the support for non-OpenStack APIs in the dynamic pollster system. This "" ""extension enables operators to create pollster on the fly to handle metrics "" ""from systems such as the RadosGW API."" msgid """"msgid """" ""Python 2.7 support has been dropped. Last release of ceilometer to support "" ""py2.7 is OpenStack Train. The minimum version of Python now supported by "" ""ceilometer is Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Ceilometer to support "" ""py2.7 is OpenStack Train. The minimum version of Python now supported by "" ""Ceilometer is Python 3.6."" ","""POT-Creation-Date: 2019-11-15 02:49+0000\n""""PO-Revision-Date: 2019-11-14 11:08+0000\n""msgid ""12.0.0-13"" msgstr ""12.0.0-13""",25,4
openstack%2Ftrove-dashboard~master~I819f5948d2abaa26bd4d99b1c9a361095c712343,openstack/trove-dashboard,master,I819f5948d2abaa26bd4d99b1c9a361095c712343,Imported Translations from Zanata,MERGED,2019-12-22 07:05:48.000000000,2019-12-22 09:41:31.000000000,2019-12-22 09:39:57.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 07:05:48.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/89cf5070c0da8c993164246b4c963fad6f9d9e98', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I819f5948d2abaa26bd4d99b1c9a361095c712343\n'}]",0,700300,89cf5070c0da8c993164246b4c963fad6f9d9e98,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I819f5948d2abaa26bd4d99b1c9a361095c712343
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/00/700300/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,89cf5070c0da8c993164246b4c963fad6f9d9e98,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-05 05:25+0000\n""""PO-Revision-Date: 2019-12-21 02:52+0000\n""msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" ","""POT-Creation-Date: 2018-10-19 14:09+0000\n""""PO-Revision-Date: 2018-10-07 08:22+0000\n""",9,2
openstack%2Fpanko~master~If4e0c4ddacc1b721d852bc572313cffba867520c,openstack/panko,master,If4e0c4ddacc1b721d852bc572313cffba867520c,Imported Translations from Zanata,MERGED,2019-12-22 09:12:49.000000000,2019-12-22 09:40:06.000000000,2019-12-22 09:38:48.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 09:12:49.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/panko/commit/f7f87fc9694ccaff5e8dc149f956679676210d09', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: If4e0c4ddacc1b721d852bc572313cffba867520c\n'}]",0,700323,f7f87fc9694ccaff5e8dc149f956679676210d09,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: If4e0c4ddacc1b721d852bc572313cffba867520c
",git fetch https://review.opendev.org/openstack/panko refs/changes/23/700323/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,f7f87fc9694ccaff5e8dc149f956679676210d09,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-12-13 03:28+0000\n""""PO-Revision-Date: 2019-12-21 02:55+0000\n""msgid ""7.0.0-3"" msgstr ""7.0.0-3"" msgid """" ""Python 2.7 support has been dropped. Last release of Panko to support py2.7 "" ""is OpenStack Train. The minimum version of Python now supported by Panko is "" ""Python 3.6."" msgstr """" ""Python 2.7 support has been dropped. Last release of Panko to support Python "" ""2.7 is OpenStack Train. The minimum version of Python now supported by Panko "" ""is Python 3.6."" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" ","""POT-Creation-Date: 2018-08-07 07:00+0000\n""""PO-Revision-Date: 2018-08-08 09:51+0000\n""",21,2
openstack%2Fcontributor-guide~master~I3208bb66c2d4a5f1898a97a6935b90ba53cd2ca2,openstack/contributor-guide,master,I3208bb66c2d4a5f1898a97a6935b90ba53cd2ca2,Imported Translations from Zanata,MERGED,2019-12-22 08:55:44.000000000,2019-12-22 09:15:26.000000000,2019-12-22 09:13:18.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-22 08:55:44.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc-code-and-documentation.po'], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/a38eed27e89a3703fae13d9c86ffb3d092750553', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3208bb66c2d4a5f1898a97a6935b90ba53cd2ca2\n'}]",0,700319,a38eed27e89a3703fae13d9c86ffb3d092750553,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3208bb66c2d4a5f1898a97a6935b90ba53cd2ca2
",git fetch https://review.opendev.org/openstack/contributor-guide refs/changes/19/700319/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/en_GB/LC_MESSAGES/doc-code-and-documentation.po'],1,a38eed27e89a3703fae13d9c86ffb3d092750553,zanata/translations,"""POT-Creation-Date: 2019-12-15 11:32+0000\n""""PO-Revision-Date: 2019-12-21 01:09+0000\n""msgid ""Administrator guide"" msgstr ""Administrator guide"" msgid ""CLI reference"" msgstr ""CLI reference"" msgid ""Configuration reference"" msgstr ""Configuration reference"" msgid ""Contributor guide"" msgstr ""Contributor guide"" ""The ``cli`` directory contains command line tool reference documentation "" ""which can be automatically generated with cliffs sphinx integration, or "" ""manually written when auto-generation is not possible. For more information, "" ""see `cliff Sphinx Integration`_."" msgstr """" ""The ``cli`` directory contains command line tool reference documentation "" ""which can be automatically generated with cliffs sphinx integration, or "" ""manually written when auto-generation is not possible. For more information, "" ""see `cliff Sphinx Integration`_."" msgid """" ""The ``configuration`` directory contains configuration reference information "" ""that is either automatically generated (if the project uses ``oslo.config``) "" ""or manually written (if ``oslo.config`` is not used). For more information, "" ""see `Sphinx Integration`_."" msgstr """" ""The ``configuration`` directory contains configuration reference information "" ""that is either automatically generated (if the project uses ``oslo.config``) "" ""or manually written (if ``oslo.config`` is not used). For more information, "" ""see `Sphinx Integration`_."" msgid """" ""The ``user`` directory contains information targeted at end-users, for "" ""instance, concept guides, tutorials, step-by-step instructions for using the "" ""CLI or the project's API, and such."" msgstr """" ""The ``user`` directory contains information targeted at end-users, for "" ""instance, concept guides, tutorials, step-by-step instructions for using the "" ""CLI or the project's API, and such."" msgid """"""The admin guide can be found in the ``admin`` directory. It contains "" ""information on the configuration and operation of the software. The "" ""project's administrator guide is included in the `OpenStack Administrator "" ""Guides`_."" msgstr """" ""The admin guide can be found in the ``admin`` directory. It contains "" ""information on the configuration and operation of the software. The "" ""project's administrator guide is included in the `OpenStack Administrator "" ""Guides`_."" msgid """"msgid """" ""The contributor guide can be found in the ``contributor`` directory. It "" ""contains project-specific information on contributing to the project and on "" ""team management. This guide appears only in the project's documentation."" msgstr """" ""The contributor guide can be found in the ``contributor`` directory. It "" ""contains project-specific information on contributing to the project and on "" ""team management. This guide appears only in the project's documentation."" ""The installation guide can be found in the ``install`` directory. It "" ""contains information on anything to do with installing a project from "" ""packages, for instance, software necessary for installing the project, like "" ""database installation and configuration, or what parameters should be set in "" ""the project's config file. If everything is configured properly (described "" ""below), the project's installation guide is included in the `OpenStack "" ""Installation Guides`_. The installation guide is not intended to be used for "" ""production system installations."" msgstr """" ""The installation guide can be found in the ``install`` directory. It "" ""contains information on anything to do with installing a project from "" ""packages, for instance, software necessary for installing the project, like "" ""database installation and configuration, or what parameters should be set in "" ""the project's config file. If everything is configured properly (described "" ""below), the project's installation guide is included in the `OpenStack "" ""Installation Guides`_. The installation guide is not intended to be used for "" ""production system installations."" msgid """"msgid ""User guide"" msgstr ""User guide"" ","""POT-Creation-Date: 2019-12-11 10:54+0000\n""""PO-Revision-Date: 2019-12-14 04:48+0000\n""",87,2
openstack%2Frequirements~master~I9abfd6fcefc73ffc40cc43c9d228e40897846378,openstack/requirements,master,I9abfd6fcefc73ffc40cc43c9d228e40897846378,Updated from generate-constraints,MERGED,2019-12-12 06:33:15.000000000,2019-12-22 08:18:51.000000000,2019-12-22 08:17:34.000000000,"[{'_account_id': 10239}, {'_account_id': 14288}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-12 06:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2a7463fb81d19577e082b128428695d5dcfb7548', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 2, 'created': '2019-12-13 07:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/835f4ec7ed11d4ebf4442d2b37bfd84b25d7725b', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 3, 'created': '2019-12-14 06:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f9810e7a5c63f5dd49c2ab9bc611cd5445f07c6f', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 4, 'created': '2019-12-15 06:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2804080680fcac6518f714d3759904d38f751521', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 5, 'created': '2019-12-16 06:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7439b468bb87641f063f8156755cd5d1bdfa3f6c', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 6, 'created': '2019-12-17 06:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fd22290222f6c27634134bfb53f316125e7732a9', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 7, 'created': '2019-12-18 06:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1a70f6f903bb9612c7e52c0099e2bed647868602', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 8, 'created': '2019-12-19 06:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1e7b956354d4effbfb913b4466af2623a66f184a', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 9, 'created': '2019-12-20 06:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/88857bf07455ec76ec86491837466320bf0d9015', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 10, 'created': '2019-12-21 06:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/285045fe7381c1c5d1ff6fdf20b58d34fd03af27', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 11, 'created': '2019-12-21 21:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2986b1f8491cba64a08f9426f5396af9b7732ece', 'message': 'Updated from generate-constraints\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}, {'number': 12, 'created': '2019-12-22 04:28:55.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c99ab09bc44818b92fe86842f98f564d54783982', 'message': 'Updated from generate-constraints\n\nheld back cliff for the following traceback\n\nException occurred:\n  File ""/home/zuul/src/opendev.org/openstack/python-openstackclient/.tox/docs/lib/python3.6/site-packages/cliff/sphinxext.py"", line 245, in _load_app\n    if not issubclass(cliff_app_class, app.App):\nTypeError: issubclass() arg 1 must be a class\n\nChange-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378\n'}]",1,698629,c99ab09bc44818b92fe86842f98f564d54783982,35,4,12,11131,,,0,"Updated from generate-constraints

held back cliff for the following traceback

Exception occurred:
  File ""/home/zuul/src/opendev.org/openstack/python-openstackclient/.tox/docs/lib/python3.6/site-packages/cliff/sphinxext.py"", line 245, in _load_app
    if not issubclass(cliff_app_class, app.App):
TypeError: issubclass() arg 1 must be a class

Change-Id: I9abfd6fcefc73ffc40cc43c9d228e40897846378
",git fetch https://review.opendev.org/openstack/requirements refs/changes/29/698629/7 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2a7463fb81d19577e082b128428695d5dcfb7548,openstack/requirements/constraints/noclob,sphinxcontrib-actdiag===2.0.0sphinxcontrib-nwdiag===2.0.0pymongo===3.10.0pyghmi===1.5.1 sphinxcontrib-blockdiag===2.0.0google-auth===1.8.2tinyrpc===1.0.4joblib===0.14.1;python_version=='3.4' joblib===0.14.1;python_version=='3.5' joblib===0.14.1;python_version=='3.6' joblib===0.14.1;python_version=='3.7'importlib-metadata===1.3.0sphinxcontrib-seqdiag===2.0.0boto3===1.10.37botocore===1.13.37,sphinxcontrib-actdiag===0.8.5sphinxcontrib-nwdiag===0.9.5pymongo===3.9.0pyghmi===1.4.1 sphinxcontrib-blockdiag===1.5.5google-auth===1.8.1tinyrpc===1.0.3joblib===0.14.0;python_version=='3.4' joblib===0.14.0;python_version=='3.5' joblib===0.14.0;python_version=='3.6' joblib===0.14.0;python_version=='3.7'importlib-metadata===1.2.0sphinxcontrib-seqdiag===0.8.5boto3===1.10.8botocore===1.13.8,15,15
openstack%2Fdesignate-dashboard~master~Id64ca1535a0c2fbeb2932ab5fc19f18966d3b975,openstack/designate-dashboard,master,Id64ca1535a0c2fbeb2932ab5fc19f18966d3b975,Imported Translations from Zanata,MERGED,2019-12-22 07:49:40.000000000,2019-12-22 08:13:48.000000000,2019-12-22 08:12:19.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-22 07:49:40.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ne/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/9d15e3f4a3ccb6cc4f5961366b19ea47495c27f3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id64ca1535a0c2fbeb2932ab5fc19f18966d3b975\n'}]",0,700310,9d15e3f4a3ccb6cc4f5961366b19ea47495c27f3,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Id64ca1535a0c2fbeb2932ab5fc19f18966d3b975
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/10/700310/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/cs/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ne/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po']",11,9d15e3f4a3ccb6cc4f5961366b19ea47495c27f3,zanata/translations,,"# TigerFang <tigerfun@126.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: designate-dashboard\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2019-09-27 18:33+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-05-15 09:55+0000\n"" ""Last-Translator: TigerFang <tigerfun@126.com>\n"" ""Language-Team: Chinese (China)\n"" ""Language: zh_CN\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=1; plural=0\n"" msgid "":ref:`genindex`"" msgstr "":ref:`genindex`"" msgid "":ref:`search`"" msgstr "":ref:`search`"" msgid ""Contents"" msgstr """" msgid ""Current Series Release Notes"" msgstr """" msgid ""Indices and tables"" msgstr """" ",31,276
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I7da826200db1b6ac7d2a60cfa2577004d27aee17,openstack/tripleo-heat-templates,stable/train,I7da826200db1b6ac7d2a60cfa2577004d27aee17,Remove unused post update and upgrade tasks,MERGED,2019-12-05 17:54:41.000000000,2019-12-22 05:39:50.000000000,2019-12-22 05:39:50.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-05 17:54:41.000000000', 'files': ['deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b6f7d0575a953038432123e07cb998e94126392', 'message': 'Remove unused post update and upgrade tasks\n\nThese tasks were incorrectly placed in post update and upgrade steps.\nThey need to be moved to tripleo-ansible.\nSee https://review.opendev.org/#/c/696727/\n\nCloses-Bug: #1836074\nChange-Id: I7da826200db1b6ac7d2a60cfa2577004d27aee17\n(cherry picked from commit 531327eec91e03c23270424b1bfc263601fb7a24)\n'}]",0,697536,3b6f7d0575a953038432123e07cb998e94126392,13,4,1,6469,,,0,"Remove unused post update and upgrade tasks

These tasks were incorrectly placed in post update and upgrade steps.
They need to be moved to tripleo-ansible.
See https://review.opendev.org/#/c/696727/

Closes-Bug: #1836074
Change-Id: I7da826200db1b6ac7d2a60cfa2577004d27aee17
(cherry picked from commit 531327eec91e03c23270424b1bfc263601fb7a24)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/697536/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml']",3,3b6f7d0575a953038432123e07cb998e94126392,,," post_upgrade_tasks: - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent post_update_tasks: - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent",0,36
openstack%2Fpuppet-tripleo~master~Iededba802be4b88e3b232a7b7474f2f981e40a08,openstack/puppet-tripleo,master,Iededba802be4b88e3b232a7b7474f2f981e40a08,Make sure neutron [placement] config section is set,MERGED,2019-12-13 08:23:40.000000000,2019-12-22 04:37:56.000000000,2019-12-22 04:37:56.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-13 08:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ca2e731f89cdca73f54a34792eed036e2d66850b', 'message': 'DNM neutron placement config\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}, {'number': 2, 'created': '2019-12-13 10:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e5f4fe336da77cf34c43e19c3b22228c07278f79', 'message': 'DNM neutron placement config\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}, {'number': 3, 'created': '2019-12-16 08:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/bea698f76e861fc637d3ee713aa218df60590261', 'message': 'DNM neutron placement config\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}, {'number': 4, 'created': '2019-12-16 11:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/51003982e45b25cc0cab1c5d2b4af6816f467f35', 'message': 'Make sure neutron [placement] config section is set\n\nEven if the hiera keys for the [placement] config section\nget created [1], the section is not being created/filles as the\n::neutron::server::placement class is not included anywhere.\n\nThis includes ::neutron::server::placement to have the section\ncreate in the neutron.conf\n\n[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}, {'number': 5, 'created': '2019-12-18 07:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/efbdd0f21b53f4ed9137f463d6765dcc0ece9e41', 'message': 'Make sure neutron [placement] config section is set\n\nEven if the hiera keys for the [placement] config section\nget created [1], the section is not being created/filles as the\n::neutron::server::placement class is not included anywhere.\n\nThis includes ::neutron::server::placement to have the section\ncreate in the neutron.conf\n\n[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400\n\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}, {'number': 6, 'created': '2019-12-20 23:28:06.000000000', 'files': ['spec/classes/tripleo_profile_base_neutron_server_spec.rb', 'manifests/profile/base/neutron/server.pp', 'spec/fixtures/hieradata/default.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4717fbea774937fa3ecb69a4d6f75d862e349270', 'message': 'Make sure neutron [placement] config section is set\n\nEven if the hiera keys for the [placement] config section\nget created [1], the section is not being created/filles as the\n::neutron::server::placement class is not included anywhere.\n\nThis includes ::neutron::server::placement to have the section\ncreate in the neutron.conf\n\n[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400\n\nDepends-On: https://review.opendev.org/700250\nChange-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08\n'}]",0,698843,4717fbea774937fa3ecb69a4d6f75d862e349270,40,8,6,17216,,,0,"Make sure neutron [placement] config section is set

Even if the hiera keys for the [placement] config section
get created [1], the section is not being created/filles as the
::neutron::server::placement class is not included anywhere.

This includes ::neutron::server::placement to have the section
create in the neutron.conf

[1] https://github.com/openstack/tripleo-heat-templates/blob/master/deployment/neutron/neutron-api-container-puppet.yaml#L391-L400

Depends-On: https://review.opendev.org/700250
Change-Id: Iededba802be4b88e3b232a7b7474f2f981e40a08
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/43/698843/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/neutron/server.pp'],1,ca2e731f89cdca73f54a34792eed036e2d66850b,neutron_placement, include ::neutron::server::placement,,1,0
openstack%2Fzun~master~Ia515de0698bbdabfd8e6a43c4da230869294b008,openstack/zun,master,Ia515de0698bbdabfd8e6a43c4da230869294b008,Add 'annotations' to db layer,MERGED,2019-12-21 19:59:05.000000000,2019-12-22 03:13:30.000000000,2019-12-22 03:12:05.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 19:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/46031362a2c1ca5a1479b740a7e2c7f4f4f36c81', 'message': ""Add 'annotations' to db layer\n\nChange-Id: Ia515de0698bbdabfd8e6a43c4da230869294b008\nImplements: blueprint add-annotations-to-capsule\n""}, {'number': 2, 'created': '2019-12-21 23:01:22.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/alembic/versions/df87dbd4846c_add_annotations_to_container.py', 'zun/db/sqlalchemy/models.py', 'zun/objects/fields.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/4a8e0301de6b45737d12a9f3488957b7b083267f', 'message': ""Add 'annotations' to db layer\n\nChange-Id: Ia515de0698bbdabfd8e6a43c4da230869294b008\nImplements: blueprint add-annotations-to-capsule\n""}]",0,700282,4a8e0301de6b45737d12a9f3488957b7b083267f,9,2,2,11536,,,0,"Add 'annotations' to db layer

Change-Id: Ia515de0698bbdabfd8e6a43c4da230869294b008
Implements: blueprint add-annotations-to-capsule
",git fetch https://review.opendev.org/openstack/zun refs/changes/82/700282/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/db/sqlalchemy/alembic/versions/df87dbd4846c_add_annotations_to_container.py', 'zun/tests/unit/db/utils.py', 'zun/db/sqlalchemy/models.py', 'zun/objects/container.py', 'zun/tests/unit/objects/test_objects.py']",5,46031362a2c1ca5a1479b740a7e2c7f4f4f36c81,bp/add-annotations-to-capsule," 'Capsule': '1.2-09d3dd7dba14b637e8fac2ba79a7f624', 'CapsuleContainer': '1.2-068254182aa6a33e6cadad60bf9e5640', 'CapsuleInitContainer': '1.2-068254182aa6a33e6cadad60bf9e5640', 'Container': '1.41-aa2199ccf568ee0a229606508c9b2d6e',"," 'Capsule': '1.1-829f8acb1ca4b57d33fa09233c9520d3', 'CapsuleContainer': '1.1-712817e2fcc085dbf0a794b3770e1907', 'CapsuleInitContainer': '1.1-712817e2fcc085dbf0a794b3770e1907', 'Container': '1.40-a24b78bcfb8c2c7e77ed24bd4a43dda1',",58,8
openstack%2Fstorlets~master~I86d893ecf7e83fe9ee85efa421ca3e3613be113c,openstack/storlets,master,I86d893ecf7e83fe9ee85efa421ca3e3613be113c,Autogenerate bin script files,ABANDONED,2019-12-21 02:25:01.000000000,2019-12-22 01:50:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-12-21 02:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/3e1d37fc2e7d3486994edb7e1431371b7b7bd73b', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 2, 'created': '2019-12-21 02:44:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/94753a43b3677216064e69c2f73c472f2f538d9d', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 3, 'created': '2019-12-21 02:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/55639b22d86e01f695f1b1d08df4b5318461ada6', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 4, 'created': '2019-12-21 23:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/45fd7808157c40d0038356dbef787912cd274a78', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 5, 'created': '2019-12-21 23:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/bedf5f9e3fb3b261e3b881f0ce714085a922cdbb', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 6, 'created': '2019-12-22 01:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/42ea154f680b5c8635ac53f6d7c767f42e307c56', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 7, 'created': '2019-12-22 01:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/46abf155b62c1732ace7f5fa85c516c6ecdbbf16', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}, {'number': 8, 'created': '2019-12-22 01:43:40.000000000', 'files': ['storlets/agent/common/utils.py', 'storlets/sbus/client/cli.py', 'storlets/agent/daemon/server.py', '.zuul.yaml', 'devstack/plugin.sh', 'storlets/agent/daemon_factory/server.py', 'setup.cfg', 'install_libs.sh'], 'web_link': 'https://opendev.org/openstack/storlets/commit/d11593546de56afe8156403172d4aec5653915dc', 'message': 'Autogenerate bin script files\n\nChange-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c\n'}]",0,700259,d11593546de56afe8156403172d4aec5653915dc,11,1,8,9816,,,0,"Autogenerate bin script files

Change-Id: I86d893ecf7e83fe9ee85efa421ca3e3613be113c
",git fetch https://review.opendev.org/openstack/storlets refs/changes/59/700259/8 && git format-patch -1 --stdout FETCH_HEAD,"['storlets/sbus/client/cli.py', 'storlets/agent/daemon/server.py', 'devstack/plugin.sh', 'storlets/agent/daemon_factory/server.py', 'setup.cfg', 'install_libs.sh']",6,3e1d37fc2e7d3486994edb7e1431371b7b7bd73b,devstack,mkdir -p -m 755 $DST,"mkdir -p $DST chmod 755 $DSTcp ""$SRC/storlets-daemon"" $DST cp ""$SRC/storlets-daemon-factory"" $DST",27,21
