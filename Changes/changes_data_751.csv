id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fopenstack-manuals~master~I0adc353d1f1c975ae788a8e38d9c9b12168b23e5,openstack/openstack-manuals,master,I0adc353d1f1c975ae788a8e38d9c9b12168b23e5,tox: Disable doc8 checks for autogenerated tables,MERGED,2017-02-22 14:37:58.000000000,2017-03-01 03:56:11.000000000,2017-03-01 03:56:11.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 9162}, {'_account_id': 10607}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-22 14:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/abc97895d9c6c39252917078073f8acc7007ea70', 'message': ""tox: Disable doc8 checks for autogenerated tables\n\nThere are some doc8 rules which would be valuable for these\nautogenerated files (like whitespace checks), however, some others do\nnot make any sense (mainly line length). As it does not appear to be\npossible to use wildcards for the 'ignore-path-errors' setting, so we\nmust disable all checks on the files themselves.\n\nChange-Id: I0adc353d1f1c975ae788a8e38d9c9b12168b23e5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2017-02-22 14:41:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/90e9b4cf67f1b9a895e81794ce92694a73a4ceef', 'message': ""tox: Disable doc8 checks for autogenerated tables\n\nThere are some doc8 rules which would be valuable for these\nautogenerated files (like whitespace checks), however, some others do\nnot make any sense (mainly line length). As it does not appear to be\npossible to use wildcards for the 'ignore-path-errors' setting, so we\nmust disable all checks on the files themselves.\n\nChange-Id: I0adc353d1f1c975ae788a8e38d9c9b12168b23e5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,436951,90e9b4cf67f1b9a895e81794ce92694a73a4ceef,10,5,2,15334,,,0,"tox: Disable doc8 checks for autogenerated tables

There are some doc8 rules which would be valuable for these
autogenerated files (like whitespace checks), however, some others do
not make any sense (mainly line length). As it does not appear to be
possible to use wildcards for the 'ignore-path-errors' setting, so we
must disable all checks on the files themselves.

Change-Id: I0adc353d1f1c975ae788a8e38d9c9b12168b23e5
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/436951/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,abc97895d9c6c39252917078073f8acc7007ea70,feat/rework-config-docs-output,"# Ignore target directories and autogenerated files ignore-path = doc/*/target,doc/*/build*,doc/install-guide/source/swift-controller-include.txt,doc/install-guide-debconf/source/swift-controller-include.txt,doc/networking-guide/source/shared/*.txt,doc/config-reference/source/tables/*.rst","# Ignore target directories ignore-path = doc/*/target,doc/*/build*,doc/install-guide/source/swift-controller-include.txt,doc/install-guide-debconf/source/swift-controller-include.txt,doc/networking-guide/source/shared/*.txt",2,2
openstack%2Ftripleo-heat-templates~master~Id325fd7eba397155eac7fb6c7410f88486173ba1,openstack/tripleo-heat-templates,master,Id325fd7eba397155eac7fb6c7410f88486173ba1,upgrades: fix ec2api conditional,MERGED,2017-02-28 16:10:51.000000000,2017-03-01 03:56:03.000000000,2017-03-01 03:56:03.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 16515}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-28 16:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c3eee5b49a176929d51b87ae99cddff97410d75d', 'message': 'upgrades: fix ec2api conditional\n\nRename ec2-api_enabled to ec2_api_enabled so we avoid this error:\nThe conditional check \'ec2-api_enabled.rc == 0\' failed.\nThe error was: error while evaluating conditional\n(ec2-api_enabled.rc == 0): \'api_enabled\' is undefined""}\n\nChange-Id: Id325fd7eba397155eac7fb6c7410f88486173ba1\n'}, {'number': 2, 'created': '2017-02-28 18:20:57.000000000', 'files': ['puppet/services/ec2-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d54532679edce04a5bdc3159489b77baf90b14ca', 'message': 'upgrades: fix ec2api conditional\n\nRename ec2-api_enabled to ec2_api_enabled so we avoid this error:\nThe conditional check \'ec2-api_enabled.rc == 0\' failed.\nThe error was: error while evaluating conditional\n(ec2-api_enabled.rc == 0): \'api_enabled\' is undefined""}\n\nChange-Id: Id325fd7eba397155eac7fb6c7410f88486173ba1\n'}]",0,439037,d54532679edce04a5bdc3159489b77baf90b14ca,16,5,2,3153,,,0,"upgrades: fix ec2api conditional

Rename ec2-api_enabled to ec2_api_enabled so we avoid this error:
The conditional check 'ec2-api_enabled.rc == 0' failed.
The error was: error while evaluating conditional
(ec2-api_enabled.rc == 0): 'api_enabled' is undefined""}

Change-Id: Id325fd7eba397155eac7fb6c7410f88486173ba1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/439037/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/ec2-api.yaml'],1,c3eee5b49a176929d51b87ae99cddff97410d75d,bp/overcloud-upgrades-per-service, register: ec2_api_enabled when: ec2_api_enabled.rc == 0, register: ec2-api_enabled when: ec2-api_enabled.rc == 0,2,2
openstack%2Frequirements~master~I3ce139b04853cd2f58fd10adfca4415537433d42,openstack/requirements,master,I3ce139b04853cd2f58fd10adfca4415537433d42,Bump oslo.utils,MERGED,2017-02-28 21:24:04.000000000,2017-03-01 03:47:42.000000000,2017-03-01 03:47:42.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 11904}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-28 21:24:04.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9961a42699b87ead891eccc8669162f3b754355f', 'message': 'Bump oslo.utils\n\nThe 3.20.0 release of oslo.utils includes a new parameter for generating\nUUIDs that indicates if dashes should be included in the resulting UUID.\n\nThis is needed by python-barbicanclient:\nI95a4a8c8e9b4501d4f9796309beb50971f2a7222\n\nChange-Id: I3ce139b04853cd2f58fd10adfca4415537433d42\n'}]",0,439161,9961a42699b87ead891eccc8669162f3b754355f,8,4,1,8623,,,0,"Bump oslo.utils

The 3.20.0 release of oslo.utils includes a new parameter for generating
UUIDs that indicates if dashes should be included in the resulting UUID.

This is needed by python-barbicanclient:
I95a4a8c8e9b4501d4f9796309beb50971f2a7222

Change-Id: I3ce139b04853cd2f58fd10adfca4415537433d42
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/439161/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,9961a42699b87ead891eccc8669162f3b754355f,oslo.utils,oslo.utils>=3.20.0 # Apache-2.0,oslo.utils>=3.18.0 # Apache-2.0,1,1
openstack%2Fmagnum-ui~master~I8f48c0dbcab93c929610acabd343e519ad34d7d8,openstack/magnum-ui,master,I8f48c0dbcab93c929610acabd343e519ad34d7d8,py34 isn't using with python3.5 and change hom-page for security.,ABANDONED,2017-03-01 01:52:56.000000000,2017-03-01 03:42:47.000000000,,"[{'_account_id': 3}, {'_account_id': 15905}]","[{'number': 1, 'created': '2017-03-01 01:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/fb2b7b7ab38d9e82ec8d594a1c0e9cb33b3d497b', 'message': ""py34 isn't using with python3.5\n\nChange-Id: I8f48c0dbcab93c929610acabd343e519ad34d7d8\n""}, {'number': 2, 'created': '2017-03-01 03:41:12.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/75f017ef34c4a2e8294c91cbb195b9b46b96666c', 'message': ""py34 isn't using with python3.5 and change hom-page for security.\n\nChange-Id: I8f48c0dbcab93c929610acabd343e519ad34d7d8\n""}]",0,439268,75f017ef34c4a2e8294c91cbb195b9b46b96666c,5,2,2,25254,,,0,"py34 isn't using with python3.5 and change hom-page for security.

Change-Id: I8f48c0dbcab93c929610acabd343e519ad34d7d8
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/68/439268/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,fb2b7b7ab38d9e82ec8d594a1c0e9cb33b3d497b,mag/v01,"envlist = py27,py27dj18,pep8,py35","envlist = py27,py27dj18,pep8,py34,py35",2,2
openstack%2Freleases~master~I99d251672b256f4c929627c85951f52036675608,openstack/releases,master,I99d251672b256f4c929627c85951f52036675608,Release os-api-ref/openstack-doc-tools for Sphinx 1.5.x support,MERGED,2017-02-20 01:28:54.000000000,2017-03-01 03:38:18.000000000,2017-03-01 03:38:18.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 8099}, {'_account_id': 12686}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-20 01:28:54.000000000', 'files': ['deliverables/_independent/openstack-doc-tools.yaml', 'deliverables/_independent/os-api-ref.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a6cd1e88f722a92b78d67d24a7d1ff956349697b', 'message': 'Release os-api-ref/openstack-doc-tools for Sphinx 1.5.x support\n\nChange-Id: I99d251672b256f4c929627c85951f52036675608\n'}]",0,435814,a6cd1e88f722a92b78d67d24a7d1ff956349697b,14,8,1,6593,,,0,"Release os-api-ref/openstack-doc-tools for Sphinx 1.5.x support

Change-Id: I99d251672b256f4c929627c85951f52036675608
",git fetch https://review.opendev.org/openstack/releases refs/changes/14/435814/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/_independent/openstack-doc-tools.yaml', 'deliverables/_independent/os-api-ref.yaml']",2,a6cd1e88f722a92b78d67d24a7d1ff956349697b,, - version: 1.3.0 projects: - repo: openstack/os-api-ref hash: bca739ce6f47767ff4dac8e0ada585778038b226,,8,0
openstack%2Fsenlin-dashboard~master~I37a06c7f4e56233293ecbff02237476bc45558e0,openstack/senlin-dashboard,master,I37a06c7f4e56233293ecbff02237476bc45558e0,Add the CONTRIBUTING.rst file,ABANDONED,2017-02-23 03:19:09.000000000,2017-03-01 03:36:51.000000000,,"[{'_account_id': 3}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-23 03:19:09.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/fd2ed4092fd7e3b69970bb6d929fb027d8a91648', 'message': 'Add the CONTRIBUTING.rst file\n\nAdd the CONTRIBUTING.rst file which the module\nmiss.\n\nChange-Id: I37a06c7f4e56233293ecbff02237476bc45558e0\n'}]",0,437231,fd2ed4092fd7e3b69970bb6d929fb027d8a91648,4,2,1,21511,,,0,"Add the CONTRIBUTING.rst file

Add the CONTRIBUTING.rst file which the module
miss.

Change-Id: I37a06c7f4e56233293ecbff02237476bc45558e0
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/31/437231/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,fd2ed4092fd7e3b69970bb6d929fb027d8a91648,senlin_dashboard2017,"If you would like to contribute to the development of OpenStack, you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html Once those steps have been completed, changes to OpenStack should be submitted for review via the Gerrit tool, following the workflow documented at: http://docs.openstack.org/infra/manual/developers.html#development-workflow Pull requests submitted through GitHub will be ignored. Bugs should be filed on Launchpad, not GitHub: https://bugs.launchpad.net/senlin_dashboard ",,16,0
openstack%2Fnova~master~I2485a4e5fbe826b3dc73ff205bbb4a725801256a,openstack/nova,master,I2485a4e5fbe826b3dc73ff205bbb4a725801256a,Updated from global requirements,MERGED,2017-02-28 23:22:43.000000000,2017-03-01 03:35:25.000000000,2017-03-01 03:35:25.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-28 23:22:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/5245fba88d68deb08b0066aa92fd5acb7d8e3dad', 'message': 'Updated from global requirements\n\nChange-Id: I2485a4e5fbe826b3dc73ff205bbb4a725801256a\n'}]",0,439227,5245fba88d68deb08b0066aa92fd5acb7d8e3dad,17,4,1,11131,,,0,"Updated from global requirements

Change-Id: I2485a4e5fbe826b3dc73ff205bbb4a725801256a
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/439227/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5245fba88d68deb08b0066aa92fd5acb7d8e3dad,openstack/requirements,oslo.middleware>=3.10.0 # Apache-2.0,oslo.middleware>=3.0.0 # Apache-2.0,1,1
openstack%2Fopenstacksdk~master~I3f220829ae7039a38bf76dee59131fce11af95f0,openstack/openstacksdk,master,I3f220829ae7039a38bf76dee59131fce11af95f0,Reorganize workflow docs,MERGED,2017-02-28 15:46:21.000000000,2017-03-01 03:34:12.000000000,2017-03-01 03:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-28 15:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/901a2d04c21b53298763f53652821e7bea617b11', 'message': 'Reorganize workflow docs\n\nThis change organizes the workflow docs by topic rather than letting\nautodoc organize methods by the order they appear in the _proxy.py file.\n\nChange-Id: I3f220829ae7039a38bf76dee59131fce11af95f0\n'}, {'number': 2, 'created': '2017-02-28 17:46:09.000000000', 'files': ['doc/source/users/proxies/workflow.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1ddaa6bef9467097cbd3f2b8ed76b8cb1e8a7995', 'message': 'Reorganize workflow docs\n\nThis change organizes the workflow docs by topic rather than letting\nautodoc organize methods by the order they appear in the _proxy.py file.\n\nChange-Id: I3f220829ae7039a38bf76dee59131fce11af95f0\n'}]",1,439028,1ddaa6bef9467097cbd3f2b8ed76b8cb1e8a7995,10,3,2,8257,,,0,"Reorganize workflow docs

This change organizes the workflow docs by topic rather than letting
autodoc organize methods by the order they appear in the _proxy.py file.

Change-Id: I3f220829ae7039a38bf76dee59131fce11af95f0
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/28/439028/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/users/proxies/workflow.rst'],1,901a2d04c21b53298763f53652821e7bea617b11,reorg_workflow_docs,"For details on how to use block_store, see :doc:`/users/guides/workflow`Workflow Operations ^^^^^^^^^^^^^^^^^^^ .. automethod:: openstack.workflow.v2._proxy.Proxy.create_workflow .. automethod:: openstack.workflow.v2._proxy.Proxy.delete_workflow .. automethod:: openstack.workflow.v2._proxy.Proxy.get_workflow .. automethod:: openstack.workflow.v2._proxy.Proxy.find_workflow .. automethod:: openstack.workflow.v2._proxy.Proxy.workflows Execution Operations ^^^^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.workflow.v2._proxy.Proxy .. automethod:: openstack.workflow.v2._proxy.Proxy.create_execution .. automethod:: openstack.workflow.v2._proxy.Proxy.delete_execution .. automethod:: openstack.workflow.v2._proxy.Proxy.get_execution .. automethod:: openstack.workflow.v2._proxy.Proxy.find_execution .. automethod:: openstack.workflow.v2._proxy.Proxy.executions","For details on how to use block_store, see :doc:`/users/guides/block_store` :members:",21,2
openstack%2Fopenstacksdk~master~Ieca92ea97d5bfcb781fcb614275d947e222a8783,openstack/openstacksdk,master,Ieca92ea97d5bfcb781fcb614275d947e222a8783,Reorganize cluster docs,MERGED,2017-02-28 18:59:44.000000000,2017-03-01 03:33:24.000000000,2017-03-01 03:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-28 18:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c170e5ec43b1d59e208f998dcc745a74c2b4c3b2', 'message': 'Reorganize cluster docs\n\nThis change organizes the cluster docs by topic rather than letting\nautodoc organize methods by the order they appear in the _proxy.py file.\n\nChange-Id: Ieca92ea97d5bfcb781fcb614275d947e222a8783\n'}, {'number': 2, 'created': '2017-03-01 01:55:22.000000000', 'files': ['doc/source/users/proxies/cluster.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/87f5b3b3cb9d8e56bc12315e0ff40d3ecd3bb9f4', 'message': 'Reorganize cluster docs\n\nThis change organizes the cluster docs by topic rather than letting\nautodoc organize methods by the order they appear in the _proxy.py file.\n\nChange-Id: Ieca92ea97d5bfcb781fcb614275d947e222a8783\n'}]",0,439110,87f5b3b3cb9d8e56bc12315e0ff40d3ecd3bb9f4,8,2,2,8257,,,0,"Reorganize cluster docs

This change organizes the cluster docs by topic rather than letting
autodoc organize methods by the order they appear in the _proxy.py file.

Change-Id: Ieca92ea97d5bfcb781fcb614275d947e222a8783
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/10/439110/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/users/proxies/cluster.rst'],1,c170e5ec43b1d59e208f998dcc745a74c2b4c3b2,reorg_cluster_docs, Cluster Operations ^^^^^^^^^^^^^^^^^^ .. automethod:: openstack.cluster.v1._proxy.Proxy.create_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.update_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.delete_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.get_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.find_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.clusters .. automethod:: openstack.cluster.v1._proxy.Proxy.check_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.add_nodes_to_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.remove_nodes_from_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.replace_nodes_in_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.attach_policy_to_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.detach_policy_from_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.collect_cluster_attrs .. automethod:: openstack.cluster.v1._proxy.Proxy.recover_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.perform_operation_on_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.resize_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.scale_in_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.scale_out_cluster .. automethod:: openstack.cluster.v1._proxy.Proxy.update_cluster_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_cluster_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_add_nodes .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_attach_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_del_nodes .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_detach_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_operation .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_policies .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_replace_nodes .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_resize .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_scale_in .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_scale_out .. automethod:: openstack.cluster.v1._proxy.Proxy.cluster_update_policy Node Operations ^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.create_node .. automethod:: openstack.cluster.v1._proxy.Proxy.update_node .. automethod:: openstack.cluster.v1._proxy.Proxy.delete_node .. automethod:: openstack.cluster.v1._proxy.Proxy.get_node .. automethod:: openstack.cluster.v1._proxy.Proxy.find_node .. automethod:: openstack.cluster.v1._proxy.Proxy.nodes .. automethod:: openstack.cluster.v1._proxy.Proxy.check_node .. automethod:: openstack.cluster.v1._proxy.Proxy.recover_node .. automethod:: openstack.cluster.v1._proxy.Proxy.perform_operation_on_node .. automethod:: openstack.cluster.v1._proxy.Proxy.node_operation Policy Operations ^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.create_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.update_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.delete_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_policy_type .. automethod:: openstack.cluster.v1._proxy.Proxy.find_policy .. automethod:: openstack.cluster.v1._proxy.Proxy.policies .. automethod:: openstack.cluster.v1._proxy.Proxy.policy_types .. automethod:: openstack.cluster.v1._proxy.Proxy.validate_policy Action Operations ^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_action .. automethod:: openstack.cluster.v1._proxy.Proxy.actions Profile Operations ^^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.create_profile .. automethod:: openstack.cluster.v1._proxy.Proxy.update_profile .. automethod:: openstack.cluster.v1._proxy.Proxy.delete_profile .. automethod:: openstack.cluster.v1._proxy.Proxy.get_profile .. automethod:: openstack.cluster.v1._proxy.Proxy.get_profile_type .. automethod:: openstack.cluster.v1._proxy.Proxy.find_profile .. automethod:: openstack.cluster.v1._proxy.Proxy.profile_types .. automethod:: openstack.cluster.v1._proxy.Proxy.profiles .. automethod:: openstack.cluster.v1._proxy.Proxy.validate_profile Receiver Operations ^^^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.create_receiver .. automethod:: openstack.cluster.v1._proxy.Proxy.delete_receiver .. automethod:: openstack.cluster.v1._proxy.Proxy.get_receiver .. automethod:: openstack.cluster.v1._proxy.Proxy.find_receiver .. automethod:: openstack.cluster.v1._proxy.Proxy.receivers Build Info Operations ^^^^^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_build_info Event Operations ^^^^^^^^^^^^^^^^ .. autoclass:: openstack.cluster.v1._proxy.Proxy .. automethod:: openstack.cluster.v1._proxy.Proxy.get_event .. automethod:: openstack.cluster.v1._proxy.Proxy.events, :members:,123,1
openstack%2Freleases~master~Icf86a3d768ec4c0788c62c277a4dc83373332eb0,openstack/releases,master,Icf86a3d768ec4c0788c62c277a4dc83373332eb0,Release pbr 2.0.0,MERGED,2017-02-08 07:52:12.000000000,2017-03-01 03:30:28.000000000,2017-03-01 03:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4162}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 15334}]","[{'number': 1, 'created': '2017-02-08 07:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8431c21b50ba994bef53b2f7da4d0b23aa04cc01', 'message': 'Release pbr 1.11.0\n\nOne note: This fixes the usage of warnerrors flag for building sphinx\ndocumentation.\n\nChange-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0\n'}, {'number': 2, 'created': '2017-02-08 12:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d03b819de2290fe388dc215ca558c89fb869ee65', 'message': 'Release pbr 1.11.0\n\nOne note: This fixes the usage of warnerrors flag for building sphinx\ndocumentation.\n\nChange-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0\n'}, {'number': 3, 'created': '2017-02-28 18:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/dbaadac145b99ff73f7b4bd9be6172c266a5c8fd', 'message': 'Release pbr 1.11.0\n\nOne note: This stops using warnerrors for Sphinx and supports\nthe Sphinx 1.5.1 warning-is-error option instead.\n\nChange-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0\n'}, {'number': 4, 'created': '2017-02-28 18:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e2f58e15f1377be5ce3ef7cdbb603d107a3b8c5f', 'message': 'Release pbr 1.11.0\n\nOne note: This stops using warnerrors for Sphinx and supports\nthe Sphinx 1.5.1 warning-is-error option instead.\n\nChange-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0\n'}, {'number': 5, 'created': '2017-02-28 21:45:05.000000000', 'files': ['deliverables/_independent/pbr.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1bdf78b55a5789a990c528ba908c0fbd2fbb7e00', 'message': 'Release pbr 2.0.0\n\nOne note: This stops using warnerrors for Sphinx and supports\nthe Sphinx 1.5.1 warning-is-error option instead.\n\nWe bump the major version as we are dropping a feature, even though it\nwas broken\n\nChange-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0\n'}]",1,430618,1bdf78b55a5789a990c528ba908c0fbd2fbb7e00,29,8,5,6547,,,0,"Release pbr 2.0.0

One note: This stops using warnerrors for Sphinx and supports
the Sphinx 1.5.1 warning-is-error option instead.

We bump the major version as we are dropping a feature, even though it
was broken

Change-Id: Icf86a3d768ec4c0788c62c277a4dc83373332eb0
",git fetch https://review.opendev.org/openstack/releases refs/changes/18/430618/4 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/pbr.yaml'],1,8431c21b50ba994bef53b2f7da4d0b23aa04cc01,pbr, - version: 1.11.0 projects: - repo: openstack-dev/pbr hash: 7122fd77f6df534554f6de397482e3f3db6fc415,,4,0
openstack%2Freleases~master~I8809978b23430daacfc6a48d1f4bc84cce24c003,openstack/releases,master,I8809978b23430daacfc6a48d1f4bc84cce24c003,use tox env when asking pbr for its name,MERGED,2017-02-08 12:53:40.000000000,2017-03-01 03:29:48.000000000,2017-03-01 03:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-08 12:53:40.000000000', 'files': ['openstack_releases/pythonutils.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/d1566749d69653c094c3e3c73f29e1101e993ba5', 'message': 'use tox env when asking pbr for its name\n\nIt seems pbr needs to be installed in order to get its name, so use tox\ninstead of the system python.\n\nChange-Id: I8809978b23430daacfc6a48d1f4bc84cce24c003\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,430889,d1566749d69653c094c3e3c73f29e1101e993ba5,8,3,1,2472,,,0,"use tox env when asking pbr for its name

It seems pbr needs to be installed in order to get its name, so use tox
instead of the system python.

Change-Id: I8809978b23430daacfc6a48d1f4bc84cce24c003
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/89/430889/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_releases/pythonutils.py'],1,d1566749d69653c094c3e3c73f29e1101e993ba5,pbr," use_tox = repo.endswith('/pbr') if use_tox and not os.path.exists(os.path.join(dest, '.tox', 'venv')): # Use tox to set up a virtualenv so we can install the # dependencies for the package. This only seems to be # necessary for pbr, but... subprocess.check_output( ['tox', '-e', 'venv', '--notest'], cwd=dest, ) if use_tox: python = '.tox/venv/bin/python' else: python = 'python' cmd = [python, 'setup.py', '--name']"," cmd = ['python', 'setup.py', '--name']",14,1
openstack%2Fzun~master~I0aa27222023d00109c127018cbdd4c408980ae67,openstack/zun,master,I0aa27222023d00109c127018cbdd4c408980ae67,Let API listen to 0.0.0.0 in devstack,MERGED,2017-02-27 18:43:59.000000000,2017-03-01 03:24:49.000000000,2017-03-01 03:24:49.000000000,"[{'_account_id': 3}, {'_account_id': 12175}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-02-27 18:43:59.000000000', 'files': ['devstack/lib/zun'], 'web_link': 'https://opendev.org/openstack/zun/commit/e7ea7bf7ff181f2b04f2110c5005f120a6db03e5', 'message': 'Let API listen to 0.0.0.0 in devstack\n\nIn dev environment, it is convient to let zun-api listen to all\naddresses.\n\nChange-Id: I0aa27222023d00109c127018cbdd4c408980ae67\n'}]",0,438670,e7ea7bf7ff181f2b04f2110c5005f120a6db03e5,7,3,1,11536,,,0,"Let API listen to 0.0.0.0 in devstack

In dev environment, it is convient to let zun-api listen to all
addresses.

Change-Id: I0aa27222023d00109c127018cbdd4c408980ae67
",git fetch https://review.opendev.org/openstack/zun refs/changes/70/438670/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/zun'],1,e7ea7bf7ff181f2b04f2110c5005f120a6db03e5,, iniset $ZUN_CONF api host_ip 0.0.0.0," iniset $ZUN_CONF api host_ip ""$ZUN_SERVICE_HOST""",1,1
openstack%2Fzun~master~I08818e417945338d5de5de473f8adc9bf9d63bdc,openstack/zun,master,I08818e417945338d5de5de473f8adc9bf9d63bdc,Add wsgi script file and sample config,MERGED,2017-02-22 23:37:38.000000000,2017-03-01 03:24:44.000000000,2017-03-01 03:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-02-22 23:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/fc9ea51c6b9785a11e7cb2ec83d88ff394d13f59', 'message': '[WIP] Add wsgi script file and sample config\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}, {'number': 2, 'created': '2017-02-22 23:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8a77fb4dcccf78162776a4404085fb7d574f5610', 'message': '[WIP] Add wsgi script file and sample config\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}, {'number': 3, 'created': '2017-02-23 00:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/f226a78954c8f9d8221ffbd45e59dff995f27534', 'message': '[WIP] Add wsgi script file and sample config\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}, {'number': 4, 'created': '2017-02-23 21:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2c5460afc7a866fafe4b9149e5571942b2bd6daf', 'message': 'Add wsgi script file and sample config\n\nIn addition, the port of zun-api is inconsistent. The devstack\nscript used 9517 and others used 9512. This commit changed to\nport 9517 in everywhere.\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}, {'number': 5, 'created': '2017-02-24 23:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/1310137de8f9cc9c204f517eb68101114fb1a949', 'message': 'Add wsgi script file and sample config\n\nIn addition, the port of zun-api is inconsistent. The devstack\nscript used 9517 and others used 9512. This commit changed to\nport 9517 in everywhere.\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}, {'number': 6, 'created': '2017-02-27 22:17:22.000000000', 'files': ['doc/source/dev/manual-devstack.rst', 'zun/api/app.wsgi', 'doc/source/index.rst', 'etc/apache2/zun.conf', 'zun/conf/api.py', 'doc/source/mod_wsgi.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/a270964a50e4e8d5b2afb73bc1576d58f895c9e8', 'message': 'Add wsgi script file and sample config\n\nIn addition, the port of zun-api is inconsistent. The devstack\nscript used 9517 and others used 9512. This commit changed to\nport 9517 in everywhere.\n\nImplements: blueprint deploy-zun-api-in-wsgi\nChange-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc\n'}]",12,437190,a270964a50e4e8d5b2afb73bc1576d58f895c9e8,24,4,6,11536,,,0,"Add wsgi script file and sample config

In addition, the port of zun-api is inconsistent. The devstack
script used 9517 and others used 9512. This commit changed to
port 9517 in everywhere.

Implements: blueprint deploy-zun-api-in-wsgi
Change-Id: I08818e417945338d5de5de473f8adc9bf9d63bdc
",git fetch https://review.opendev.org/openstack/zun refs/changes/90/437190/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/api/app.wsgi', 'etc/apache2/zun', 'doc/source/mod_wsgi.rst']",3,fc9ea51c6b9785a11e7cb2ec83d88ff394d13f59,bp/deploy-zun-api-in-wsgi,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. =================================== Installing the API behind mod_wsgi =================================== Zun comes with a few example files for configuring the API service to run behind Apache with ``mod_wsgi``. app.wsgi ======== The file ``zun/api/app.wsgi`` sets up the V2 API WSGI application. The file is installed with the rest of the zun application code, and should not need to be modified. etc/apache2/zun ====================== The ``etc/apache2/zun`` file contains example settings that work with a copy of zun installed via devstack. .. literalinclude:: ../../../etc/apache2/zun 1. On deb-based systems copy or symlink the file to ``/etc/apache2/sites-available``. For rpm-based systems the file will go in ``/etc/httpd/conf.d``. 2. Modify the ``WSGIDaemonProcess`` directive to set the ``user`` and ``group`` values to an appropriate user on your server. In many installations ``zun`` will be correct. 3. Enable the zun site. On deb-based systems:: $ a2ensite zun $ service apache2 reload On rpm-based systems:: $ service httpd reload ",,112,0
openstack%2Fzun~master~I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363,openstack/zun,master,I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363,Implement etcd API for ResourceClass,MERGED,2017-02-16 13:20:43.000000000,2017-03-01 03:24:34.000000000,2017-03-01 03:24:34.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 13248}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-02-16 13:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/a53d020d0985aa9afa1514bc192f4ddff8d275c8', 'message': 'Implement etcd API for ResourceClass\n\nThis commit adds etcd db model and implements etcd API\nfor ResourceClass.\n\nPart of blueprint expose-host-capabilities\n\nChange-Id: I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363\n'}, {'number': 2, 'created': '2017-02-17 02:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/0f3a8ec2cfc7f2cde4525e826fce1c66dacbd9fa', 'message': 'Implement etcd API for ResourceClass\n\nThis commit adds etcd db model and implements etcd API\nfor ResourceClass.\n\nPart of blueprint expose-host-capabilities\n\nChange-Id: I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363\n'}, {'number': 3, 'created': '2017-02-28 10:38:08.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/objects/resource_class.py', 'zun/db/api.py', 'zun/tests/unit/objects/test_resource_class.py', 'zun/db/sqlalchemy/models.py', 'zun/tests/unit/db/test_resource_class.py', 'zun/db/sqlalchemy/api.py', 'zun/db/sqlalchemy/alembic/versions/8192905fd835_add_uuid_to_resource_class.py', 'zun/db/etcd/api.py', 'zun/db/etcd/models.py', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/cf1ad08b0f1ef1ca0e4f41a7df407d3811a7dea6', 'message': ""Implement etcd API for ResourceClass\n\nPorposed change of this commit is:\n\n1.Add etcd db model and implements etcd API for\n  ResourceClass.\n2.Add 'uuid' field into ResourceClass.\n\nPart of blueprint expose-host-capabilities\n\nChange-Id: I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363\n""}]",3,434909,cf1ad08b0f1ef1ca0e4f41a7df407d3811a7dea6,18,4,3,13248,,,0,"Implement etcd API for ResourceClass

Porposed change of this commit is:

1.Add etcd db model and implements etcd API for
  ResourceClass.
2.Add 'uuid' field into ResourceClass.

Part of blueprint expose-host-capabilities

Change-Id: I9e5678e8742fd4c6a26b9ced6d6eccd6b7976363
",git fetch https://review.opendev.org/openstack/zun refs/changes/09/434909/3 && git format-patch -1 --stdout FETCH_HEAD,"['zun/objects/resource_class.py', 'zun/db/api.py', 'zun/tests/unit/db/test_resource_class.py', 'zun/tests/unit/objects/test_resource_class.py', 'zun/db/etcd/api.py', 'zun/db/etcd/models.py']",6,a53d020d0985aa9afa1514bc192f4ddff8d275c8,bp/expose-host-capabilities," class ResourceClass(Base): """"""Represents a resource class."""""" _path = '/resource_classes' _fields = objects.ResourceClass.fields.keys() def __init__(self, resource_class_data): self.path = ResourceClass.path() for f in ResourceClass.fields(): setattr(self, f, None) self.id = 1 self.update(resource_class_data) @classmethod def path(cls): return cls._path @classmethod def fields(cls): return cls._fields def save(self, session=None): if session is None: session = db.api.get_connection() client = session.client path = self.etcd_path(self.name) if self.path_already_exist(client, path): raise exception.ResourceClassAlreadyExists( resource_class=self.name) client.write(path, json.dumps(self.as_dict())) return",,283,57
openstack%2Fheat~master~Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28,openstack/heat,master,Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28,There is some resource with lower priority than default. So we should set the resource priority to DEFAULT_TASK_PRIORITY in file heat/engine/resoruce.py,ABANDONED,2017-02-18 03:27:50.000000000,2017-03-01 03:18:05.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}]","[{'number': 1, 'created': '2017-02-18 03:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a210a8fcfaeb13bc2db58bef582b8d24a2bba214', 'message': 'There is some resource with lower priority than default. So we should set the resource priority to\nDEFAULT_TASK_PRIORITY in heat/engine/resoruce.py\n\nChange-Id: Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28\nClose-Bugs: #1665832\n'}, {'number': 2, 'created': '2017-02-18 03:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e731c7464f2b2b85c025ade314258d7bd113a6b4', 'message': 'There is some resource with lower priority than default.\nSo we should set the resource priority to\nDEFAULT_TASK_PRIORITY in heat/engine/resoruce.py\n\nChange-Id: Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28\nClose-Bugs: #1665832\n'}, {'number': 3, 'created': '2017-02-18 03:32:18.000000000', 'files': ['heat/engine/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a7af96e13cbbc58785e1a776e97380ae417adf66', 'message': 'There is some resource with lower priority than default.\nSo we should set the resource priority to\nDEFAULT_TASK_PRIORITY in file heat/engine/resoruce.py\n\nChange-Id: Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28\nClose-Bugs: #1665832\n'}]",0,435646,a7af96e13cbbc58785e1a776e97380ae417adf66,6,2,3,19910,,,0,"There is some resource with lower priority than default.
So we should set the resource priority to
DEFAULT_TASK_PRIORITY in file heat/engine/resoruce.py

Change-Id: Ic8f3b3536486a20d7de9593a9d4a76b19e6fec28
Close-Bugs: #1665832
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/435646/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resource.py'],1,a210a8fcfaeb13bc2db58bef582b8d24a2bba214,bug/1665832, # Value of the resource priority. The resource with lower priority # should start after the resource with higher priority. resource_priority = scheduler.DEFAULT_TASK_PRIORITY,,4,0
openstack%2Fpython-openstackclient~stable%2Fnewton~I8b140f0b0a60681fc2a35a013bb0c84ff8cb9589,openstack/python-openstackclient,stable/newton,I8b140f0b0a60681fc2a35a013bb0c84ff8cb9589,Fix OSC networking commands help errors,MERGED,2017-02-06 11:24:14.000000000,2017-03-01 03:06:31.000000000,2017-03-01 03:06:31.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-06 11:24:14.000000000', 'files': ['releasenotes/notes/bug-1650026-0ce6a77e69d24424.yaml', 'functional/tests/common/test_help.py', 'openstackclient/common/clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e79eca55aae02206bd10e663b1540078424d9734', 'message': 'Fix OSC networking commands help errors\n\nOSC networking commands need to authenticate to get\nservice catalog, then decide to show nova-network or\nneutron command help message. Fake token and fake\nauth_type in prepare_to_run_command() casue os-cloud-config\nuse AdminToken auth plugin, but pass all the auth information\n(include: username, password and so on) to it, that casue the\nclass initialization error. Pop the fake token and url, then\ntry to load auth plugin again to fix the issue.\n\nChange-Id: I8b140f0b0a60681fc2a35a013bb0c84ff8cb9589\nCloses-Bug: #1650026\n(cherry picked from commit 4d9da2c40ae02086258cfde852b297754d8085fa)\n'}]",0,429653,e79eca55aae02206bd10e663b1540078424d9734,9,3,1,8276,,,0,"Fix OSC networking commands help errors

OSC networking commands need to authenticate to get
service catalog, then decide to show nova-network or
neutron command help message. Fake token and fake
auth_type in prepare_to_run_command() casue os-cloud-config
use AdminToken auth plugin, but pass all the auth information
(include: username, password and so on) to it, that casue the
class initialization error. Pop the fake token and url, then
try to load auth plugin again to fix the issue.

Change-Id: I8b140f0b0a60681fc2a35a013bb0c84ff8cb9589
Closes-Bug: #1650026
(cherry picked from commit 4d9da2c40ae02086258cfde852b297754d8085fa)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/53/429653/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1650026-0ce6a77e69d24424.yaml', 'functional/tests/common/test_help.py', 'openstackclient/common/clientmanager.py']",3,e79eca55aae02206bd10e663b1540078424d9734,bug/1650026," # store original auth_type self._original_auth_type = cli_options.auth_type try: self._cli_options._auth = \ self._cli_options._openstack_config.load_auth_plugin( self._cli_options.config, ) except TypeError as e: self._fallback_load_auth_plugin(e) return super(ClientManager, self).setup_auth() def _fallback_load_auth_plugin(self, e): # NOTES(RuiChen): Hack to avoid auth plugins choking on data they don't # expect, delete fake token and endpoint, then try to # load auth plugin again with user specified options. # We know it looks ugly, but it's necessary. if self._cli_options.config['auth']['token'] == 'x': # restore original auth_type self._cli_options.config['auth_type'] = \ self._original_auth_type del self._cli_options.config['auth']['token'] del self._cli_options.config['auth']['endpoint'] else: raise e"," return super(ClientManager, self).setup_auth()",38,2
openstack%2Fpython-pankoclient~master~I20b758622710fe2a292ad29b4494bd56fd817877,openstack/python-pankoclient,master,I20b758622710fe2a292ad29b4494bd56fd817877,Fix issues after changing the package name to pankoclient,MERGED,2017-03-01 02:23:04.000000000,2017-03-01 03:04:35.000000000,2017-03-01 03:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 8290}]","[{'number': 1, 'created': '2017-03-01 02:23:04.000000000', 'files': ['pankoclient/__init__.py', 'doc/source/installation.rst'], 'web_link': 'https://opendev.org/openstack/python-pankoclient/commit/aa014b61e70f2190f2c54562071bb930df29688f', 'message': 'Fix issues after changing the package name to pankoclient\n\n- Correct the pip installation command\n- Fix the pbr version querying\n\nChange-Id: I20b758622710fe2a292ad29b4494bd56fd817877\n'}]",0,439277,aa014b61e70f2190f2c54562071bb930df29688f,6,2,1,8290,,,0,"Fix issues after changing the package name to pankoclient

- Correct the pip installation command
- Fix the pbr version querying

Change-Id: I20b758622710fe2a292ad29b4494bd56fd817877
",git fetch https://review.opendev.org/openstack/python-pankoclient refs/changes/77/439277/1 && git format-patch -1 --stdout FETCH_HEAD,"['pankoclient/__init__.py', 'doc/source/installation.rst']",2,aa014b61e70f2190f2c54562071bb930df29688f,fix-version, $ pip install pankoclient, $ pip install python-pankoclient,2,2
openstack%2Fopenstack-manuals~master~Idca1e0dcf2c2abdf280c9ef3ecaed1ca7ef9fc1b,openstack/openstack-manuals,master,Idca1e0dcf2c2abdf280c9ef3ecaed1ca7ef9fc1b,[common] Recommend readers installing the clients with pip,ABANDONED,2017-02-24 11:46:14.000000000,2017-03-01 03:03:17.000000000,,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 20156}]","[{'number': 1, 'created': '2017-02-24 11:46:14.000000000', 'files': ['doc/common/cli-install-openstack-command-line-clients.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c274f4aafa1954f9ec733fb87986658cfe62972', 'message': '[common] Recommend readers installing the clients with pip\n\nChange-Id: Idca1e0dcf2c2abdf280c9ef3ecaed1ca7ef9fc1b\nCloses-Bug: #1665712\n'}]",2,437877,1c274f4aafa1954f9ec733fb87986658cfe62972,5,4,1,19779,,,0,"[common] Recommend readers installing the clients with pip

Change-Id: Idca1e0dcf2c2abdf280c9ef3ecaed1ca7ef9fc1b
Closes-Bug: #1665712
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/77/437877/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/cli-install-openstack-command-line-clients.rst'],1,1c274f4aafa1954f9ec733fb87986658cfe62972,bug/1665712,.. note:: Installing the clients from packages may get the older version. We recommend installing the clients with ``pip``. ,,5,0
openstack%2Fzun~master~I8de4d3e7fbee7068dd534f69942e1ef259fe6383,openstack/zun,master,I8de4d3e7fbee7068dd534f69942e1ef259fe6383,changed the home page address,ABANDONED,2017-02-17 06:50:53.000000000,2017-03-01 02:52:51.000000000,,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 16277}, {'_account_id': 23365}]","[{'number': 1, 'created': '2017-02-17 06:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/532a61c8e9120ec5293c0f283380a50c894a3dcf', 'message': 'changed the home page address\n\nChange-Id: I8de4d3e7fbee7068dd534f69942e1ef259fe6383\n'}, {'number': 2, 'created': '2017-02-17 11:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/006a5a00cf6e2f0c37b2ae11eab433d813b998cf', 'message': 'changed the home page address\n\nChange-Id: I8de4d3e7fbee7068dd534f69942e1ef259fe6383\n'}]",2,435274,006a5a00cf6e2f0c37b2ae11eab433d813b998cf,10,5,2,24925,,,0,"changed the home page address

Change-Id: I8de4d3e7fbee7068dd534f69942e1ef259fe6383
",git fetch https://review.opendev.org/openstack/zun refs/changes/74/435274/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,532a61c8e9120ec5293c0f283380a50c894a3dcf,homepage,home-page = https://launchpad.net/zun,home-page = https://wiki.openstack.org/wiki/Zun,1,1
openstack%2Fdragonflow~master~Id5acc31f5e8bc7a97de536938939224ec903e0a3,openstack/dragonflow,master,Id5acc31f5e8bc7a97de536938939224ec903e0a3,[11/xx] Refactor Chassis model,MERGED,2016-12-05 15:03:01.000000000,2017-03-01 02:51:39.000000000,2017-03-01 02:51:39.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 18347}, {'_account_id': 18903}, {'_account_id': 20153}, {'_account_id': 20229}, {'_account_id': 20297}, {'_account_id': 23766}]","[{'number': 1, 'created': '2016-12-05 15:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5733fde1643f3ad6037e757f9a0da8a8141186af', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 2, 'created': '2016-12-05 16:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3b39f4e715c1030f4a66a56c822c8c18bf1e6c25', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 3, 'created': '2016-12-06 12:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/75dc82d786fd2dc54950bfd6016964506f7d3414', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 4, 'created': '2016-12-06 13:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3f5edfe96f216e80789f2130c03322860b0c9ede', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 5, 'created': '2016-12-06 14:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/807eb0c4af3390fd30f2d4a973134282ea22f7c9', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 6, 'created': '2016-12-06 16:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e64b4c053920e85d8be78a24a694c7cededebc3b', 'message': '[WIP] Refactor chassis northbound API methods\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 7, 'created': '2016-12-08 09:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/af2e3dd4b990dae416e9902c6b6b9165b49e083c', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 8, 'created': '2016-12-08 13:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/24dbc045aab6ad8c0201a2d46bcb9efe65d57a57', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 9, 'created': '2016-12-08 13:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f54a9602821e7e4bd6d9e73b575ad4c02df02540', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 10, 'created': '2016-12-08 15:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2dd23bd1dd1463d696425b2aa1735a6ef21fe4b8', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 11, 'created': '2016-12-08 17:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4a1b4fd3b6fc02fd8870816fb6cfad895755e8ff', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 12, 'created': '2016-12-11 13:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/26b450ae7571e58ea2c54ccf32acc6a9114e832a', 'message': '[WIP] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 13, 'created': '2016-12-12 13:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/834d0d8d348d1d37f9697930250875605ea5f36c', 'message': '[04/10] Refactor chassis northbound API methods\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 14, 'created': '2017-01-09 11:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e58f487ea64fecc0f0a55357911257ccbb9bfd25', 'message': 'Refactor Chassis model\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 15, 'created': '2017-01-09 14:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dcd80326f48c57dc3ccc6c3ca432f217c163e148', 'message': 'Refactor Chassis model\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 16, 'created': '2017-01-09 16:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/709928fc17e8ee12d47a9e8541fcc149ec595617', 'message': 'Refactor Chassis model\n\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 17, 'created': '2017-01-11 09:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/121ba05d5334b0a1b0693e578e8d0db812d9101b', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 18, 'created': '2017-01-11 11:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/85477fd11fb49f9ae525d82ad3e012ce435a7502', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 19, 'created': '2017-01-14 10:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0c42008469f13fdf02a8ba5c55a8b4db2112167c', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 20, 'created': '2017-01-15 15:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/aea5d158bf67d7e0b967cb3e789345904b441c80', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 21, 'created': '2017-01-16 14:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/74b6c405d4285bf2430c62661d0cad48cb9ee65f', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 22, 'created': '2017-01-17 16:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/75c93850e68de608a862b81f9c2d3ba424b9efe0', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 23, 'created': '2017-01-18 09:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/219fa1f5bfeaeb672c533bf08f0b6cbb59e342ac', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 24, 'created': '2017-01-18 10:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/24372bc35be96b1e4cec70c94daebcf29c6647c9', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 25, 'created': '2017-01-19 13:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/939c999a67e02accfac6b7a4ed39ef64ff651c44', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 26, 'created': '2017-01-22 16:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/825d7a8199f8ff502dd5ac64abfcc40112c965c9', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 27, 'created': '2017-01-22 20:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1d23450012ebcac9dfe240a5967376fcb9f7d8a4', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 28, 'created': '2017-01-23 14:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bdc8ee2f4551ad7c217d3052e298f422705cd5c4', 'message': '[8/8] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 29, 'created': '2017-01-25 09:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/aeb0110db633c140c116248b1369467e17d57953', 'message': '[09/13] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 30, 'created': '2017-01-25 13:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1fd54fc6033f19732dcec6ac1397c8dd8a6b9070', 'message': '[09/13] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 31, 'created': '2017-01-25 14:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/45e533211a9e6a6c4fcb55b9cc2a6313c792ed2b', 'message': '[09/13] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 32, 'created': '2017-01-26 09:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0545dc0a1067de34f5824bf7ccbdad27f48b8c1a', 'message': '[09/13] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 33, 'created': '2017-01-26 11:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9f571b8f098b5bdecf24bc1052ae7e4bad77bfe7', 'message': '[09/13] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 34, 'created': '2017-01-29 14:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/048d66214b8cbc8b43a3d836fa3a5cd0b08b54de', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 35, 'created': '2017-01-29 15:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a8022dd7dd4951c41f09b539697d8f9391fb07b0', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 36, 'created': '2017-01-29 17:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5604ebe0803c29d63f9190bfb49a83821277f0b1', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 37, 'created': '2017-01-30 13:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f95fc809e8a8c3870d9fd5745ad1ff4b62d92d27', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 38, 'created': '2017-02-01 20:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b01a8cc6fe4242ea087ac1a3bd6c927f957a8810', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: bp refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 39, 'created': '2017-02-02 11:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bafe36e3cf81662e0ae2c9ef3c37d3747995d073', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 40, 'created': '2017-02-05 19:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b5c9ecca75ba808c9c57dbe95d49cc51d999253c', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 41, 'created': '2017-02-06 07:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6b6a139d8b4a468173ed597bbb047fa1b0ea5337', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 42, 'created': '2017-02-12 16:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6a7fc1addcf7243674db1cc5bb8e5f02ac4bd7d1', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 43, 'created': '2017-02-12 16:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d54fb3c1cf7b7ff7e8fd136a1afd3a9137f2ad91', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 44, 'created': '2017-02-14 06:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/05575212b9b02155b7c2d80d9a96037d57daff3a', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 45, 'created': '2017-02-14 09:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7f31cdab22a6572a2ead4edf38c3415baaa12dc8', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 46, 'created': '2017-02-14 15:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cfa45d97ebe9e3853ed3253d16b8508ee0d0e07f', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 47, 'created': '2017-02-15 13:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6408736e609959d4020386e392015e179e8587ef', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 48, 'created': '2017-02-16 12:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/80644b08edf6731b10187e17c702560c85656bb2', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 49, 'created': '2017-02-16 15:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c0c120422b9e50a9fcd3a3bab67f6dd9a8c7197f', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 50, 'created': '2017-02-19 07:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cdd2fd3df7abff8425c8a438f3fcde72591fe423', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 51, 'created': '2017-02-20 15:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/927fa4cfdec190644267a2205a83da2a5524b9fc', 'message': '[08/12] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 52, 'created': '2017-02-21 17:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fd751769ec35e4725177893486c434ae02edc15e', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 53, 'created': '2017-02-22 09:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7cf0f1ead8ccada36099fbf98ac3d194ce268e25', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 54, 'created': '2017-02-22 09:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/99825572c52346d0692d0eb81e46c73050e90690', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 55, 'created': '2017-02-23 08:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b385d07d72e0354661c9c4b1dd35150a5bf52b7c', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 56, 'created': '2017-02-23 16:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/46129e3585af0d535bd4981a5cc5e1466d33b1d4', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 57, 'created': '2017-02-24 15:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/16154ad106216b1636f12a0c0aeec705b9eac5a1', 'message': '[10/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 58, 'created': '2017-02-26 15:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bc0875bf2b24030cfe76b0c68d685211c4149cd3', 'message': '[11/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 59, 'created': '2017-02-26 15:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/35dfdeb76eaacba3fabf2152bd7de210fbcf04dc', 'message': '[11/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 60, 'created': '2017-02-26 16:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/49dd00490e6f5db80501db1bb770c310e1d8479f', 'message': '[11/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 61, 'created': '2017-02-26 21:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bf1344b27b03557789deb9a08aaa21510592bf0c', 'message': '[11/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}, {'number': 62, 'created': '2017-02-28 08:26:29.000000000', 'files': ['dragonflow/db/models/core_models.py', 'dragonflow/tests/unit/test_df_local_controller.py', 'dragonflow/tests/unit/test_db_store.py', 'dragonflow/db/pub_sub_api.py', 'dragonflow/tests/unit/test_app_base.py', 'dragonflow/db/models/legacy_models.py', 'dragonflow/controller/df_local_controller.py', 'dragonflow/db/api_nb.py', 'dragonflow/db/models/__init__.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b5f26872b66807455de5cf582c0e735ed41aaad6', 'message': '[11/xx] Refactor Chassis model\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3\n'}]",26,407011,b5f26872b66807455de5cf582c0e735ed41aaad6,158,10,62,23766,,,0,"[11/xx] Refactor Chassis model

Partially-Implements: blueprint refactor-nb-api
Change-Id: Id5acc31f5e8bc7a97de536938939224ec903e0a3
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/11/407011/56 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/tests/unit/test_df_local_controller.py', 'dragonflow/controller/df_local_controller.py', 'dragonflow/db/api_nb.py']",3,5733fde1643f3ad6037e757f9a0da8a8141186af,bp/refactor-nb-api,," def get_chassis(self, id): try: chassis_value = self.driver.get_key(db_models.Chassis.table_name, id, None) return db_models.Chassis(chassis_value) except Exception: return None def get_all_chassis(self): res = [] for entry_value in self.driver.get_all_entries( db_models.Chassis.table_name, None): res.append(db_models.Chassis(entry_value)) return res def update_chassis(self, id, **columns): chassis_json = self.driver.get_key('chassis', id) chassis = jsonutils.loads(chassis_json) for col, val in columns.items(): chassis[col] = val chassis_json = jsonutils.dumps(chassis) self.driver.set_key('chassis', id, chassis_json, None)",5,28
openstack%2Fkolla~stable%2Focata~I1b351ccfea5684aeb1394e5a12ee848eb62447fe,openstack/kolla,stable/ocata,I1b351ccfea5684aeb1394e5a12ee848eb62447fe,Use correct inventory file for Bifrost,MERGED,2017-02-17 10:21:11.000000000,2017-03-01 02:44:50.000000000,2017-03-01 02:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 14826}, {'_account_id': 16233}, {'_account_id': 17643}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 23717}]","[{'number': 1, 'created': '2017-02-17 10:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ac3bdcee3e1cdfba5bafde7ce473018377fb3213', 'message': ""Use correct inventory file for Bifrost\n\nBifrost now targets the play in the install.yml playbook at the\ntarget Ansible group instead of localhost.\n\nThis change uses the target inventory file to pick up this group\nand avoid a 'noop' playbook.\n\nChange-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe\nCloses-Bug: #1665413\n(cherry picked from commit 39e48f2cf9380144e1d12bf3738752f9f0cce9ce)\n""}, {'number': 2, 'created': '2017-02-27 12:20:41.000000000', 'files': ['docker/bifrost/bifrost-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d198b689bc93634463be5d02247363c99ca0f84b', 'message': ""Use correct inventory file for Bifrost\n\nBifrost now targets the play in the install.yml playbook at the\ntarget Ansible group instead of localhost.\n\nThis change uses the target inventory file to pick up this group\nand avoid a 'noop' playbook.\n\nChange-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe\nCloses-Bug: #1665413\n(cherry picked from commit 39e48f2cf9380144e1d12bf3738752f9f0cce9ce)\n""}]",0,435348,d198b689bc93634463be5d02247363c99ca0f84b,32,10,2,14826,,,0,"Use correct inventory file for Bifrost

Bifrost now targets the play in the install.yml playbook at the
target Ansible group instead of localhost.

This change uses the target inventory file to pick up this group
and avoid a 'noop' playbook.

Change-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe
Closes-Bug: #1665413
(cherry picked from commit 39e48f2cf9380144e1d12bf3738752f9f0cce9ce)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/48/435348/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/bifrost/bifrost-base/Dockerfile.j2'],1,ac3bdcee3e1cdfba5bafde7ce473018377fb3213,bug/1665413, ansible-playbook -vvvv -i /bifrost/playbooks/inventory/target /bifrost/playbooks/install.yaml \, ansible-playbook -vvvv -i /bifrost/playbooks/inventory/localhost /bifrost/playbooks/install.yaml \,1,1
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Fnewton~I99ac362cbc862e24025a5ede04c441a4cffbc640,openstack/openstack-ansible-lxc_hosts,stable/newton,I99ac362cbc862e24025a5ede04c441a4cffbc640,Add Trusty backports repo if it is not enabled,MERGED,2017-02-28 16:52:14.000000000,2017-03-01 02:27:16.000000000,2017-03-01 02:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 11268}, {'_account_id': 21314}]","[{'number': 1, 'created': '2017-02-28 16:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0f1aec5c551c56e798460ffce7a7f7a25696335c', 'message': 'Add Trusty backports repo if it is not enabled\n\nOur implementation of LXC requires v2, which on Ubuntu\nTrusty is only available in the backports repo.\n\nThis patch attempts to determine whether the backports\nrepo is enabled, and if not it will enable it.\n\nChange-Id: I99ac362cbc862e24025a5ede04c441a4cffbc640\n'}, {'number': 2, 'created': '2017-02-28 17:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/3061fb46f3af22992bbb5dc75e26336a5df2a065', 'message': 'Add Trusty backports repo if it is not enabled\n\nOur implementation of LXC requires v2, which on Ubuntu\nTrusty is only available in the backports repo.\n\nThis patch attempts to determine whether the backports\nrepo is enabled, and if not it will enable it.\n\nChange-Id: I99ac362cbc862e24025a5ede04c441a4cffbc640\n'}, {'number': 3, 'created': '2017-02-28 17:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0cbefc3ddc716f9d54de40ccf20e3247184b7a1f', 'message': 'Add Trusty backports repo if it is not enabled\n\nOur implementation of LXC requires v2, which on Ubuntu\nTrusty is only available in the backports repo.\n\nThis patch attempts to determine whether the backports\nrepo is enabled, and if not it will enable it.\n\nChange-Id: I99ac362cbc862e24025a5ede04c441a4cffbc640\n'}, {'number': 4, 'created': '2017-02-28 17:23:56.000000000', 'files': ['tasks/lxc_install_apt_repo.yml', 'tasks/lxc_install_apt.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/6c9041c02b277eebc18817d0b681ae7928f98c31', 'message': 'Add Trusty backports repo if it is not enabled\n\nOur implementation of LXC requires v2, which on Ubuntu\nTrusty is only available in the backports repo.\n\nThis patch attempts to determine whether the backports\nrepo is enabled, and if not it will enable it.\n\nChange-Id: I99ac362cbc862e24025a5ede04c441a4cffbc640\n'}]",2,439053,6c9041c02b277eebc18817d0b681ae7928f98c31,19,6,4,6816,,,0,"Add Trusty backports repo if it is not enabled

Our implementation of LXC requires v2, which on Ubuntu
Trusty is only available in the backports repo.

This patch attempts to determine whether the backports
repo is enabled, and if not it will enable it.

Change-Id: I99ac362cbc862e24025a5ede04c441a4cffbc640
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/53/439053/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/lxc_install_apt_repo.yml', 'tasks/lxc_install_apt.yml', 'defaults/main.yml']",3,0f1aec5c551c56e798460ffce7a7f7a25696335c,,"# Optionally set the URL for the Ubuntu Trusty backports repository # lxc_package_repo_url: http://archive.ubuntu.com/ubuntu/ lxc_package_repo_filename: ""/etc/apt/sources.list.d/trusty-backports.list"" ",,63,0
openstack%2Fopenstack-ansible-pip_install~stable%2Fnewton~Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,openstack/openstack-ansible-pip_install,stable/newton,Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,Use an explicit version of urrlib3,MERGED,2017-02-28 18:23:25.000000000,2017-03-01 02:26:57.000000000,2017-03-01 02:26:57.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 18:23:25.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/5532092fd1fd6c4ddf0b84ae3e2e4091224fc9a8', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the target node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and the get_url/uri modules with https had SSL issues.\nMoving to a more recent version urllib3 fixed it.\n\nChange-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b\n(cherry picked from commit 3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44)\n""}]",0,439092,5532092fd1fd6c4ddf0b84ae3e2e4091224fc9a8,8,4,1,6816,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the target node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and the get_url/uri modules with https had SSL issues.
Moving to a more recent version urllib3 fixed it.

Change-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b
(cherry picked from commit 3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44)
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/92/439092/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,5532092fd1fd6c4ddf0b84ae3e2e4091224fc9a8,urllib3, - urllib3 # SSL SNI support,,1,0
openstack%2Fopenstack-ansible-pip_install~stable%2Focata~I3e127a4451a0ab47588a213e9721bc2f36b12387,openstack/openstack-ansible-pip_install,stable/ocata,I3e127a4451a0ab47588a213e9721bc2f36b12387,Optimize pip_install,MERGED,2017-02-28 23:48:14.000000000,2017-03-01 02:26:52.000000000,2017-03-01 02:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-28 23:48:14.000000000', 'files': ['tasks/pre_install.yml', 'tasks/pre_install_yum.yml', 'tasks/install.yml', 'tasks/pre_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/45192427023676d45d74539e3cee2fcc00a3705d', 'message': 'Optimize pip_install\n\nThis patch optimizes the pip_install tasks to avoid lots of skipped\ntasks. This role is run *many* times during the integrated gate and\nadds a signficant amount of time to gate jobs.\n\nInstalling the RDO RPM still takes quite a bit of time (~ 6min) in\nthe integrated build, so further optimization is needed.\n\nChange-Id: I3e127a4451a0ab47588a213e9721bc2f36b12387\n(cherry picked from commit badf50295112a7d962adf648d8f650a4729feb19)\n'}]",0,439242,45192427023676d45d74539e3cee2fcc00a3705d,7,3,1,6816,,,0,"Optimize pip_install

This patch optimizes the pip_install tasks to avoid lots of skipped
tasks. This role is run *many* times during the integrated gate and
adds a signficant amount of time to gate jobs.

Installing the RDO RPM still takes quite a bit of time (~ 6min) in
the integrated build, so further optimization is needed.

Change-Id: I3e127a4451a0ab47588a213e9721bc2f36b12387
(cherry picked from commit badf50295112a7d962adf648d8f650a4729feb19)
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/42/439242/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/pre_install.yml', 'tasks/pre_install_yum.yml', 'tasks/install.yml', 'tasks/pre_install_apt.yml']",4,45192427023676d45d74539e3cee2fcc00a3705d,urllib3,"--- # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Ensure apt cache is up to date apt: update_cache: yes cache_valid_time: ""{{ cache_timeout }}"" # Under Ubuntu, this will only add the key - name: Install external repo key with package apt: name: ""{{ pip_install_external_repo_key_package }}"" state: ""{{ pip_install_external_repo_key_package_state | default('present') }}"" when: - user_external_repo_key is not defined tags: - add-repo-keys - name: Install repo for distro binaries apt_repository: repo: ""{{ uca_repo }}"" state: present update_cache: yes filename: ""{{ uca_apt_source_list_filename | default(omit) }}"" register: uca_add_repo until: uca_add_repo|success retries: 5 delay: 2 when: - uca_enable tags: - add-uca-repo - name: Install external repo key manually (apt) apt_key: id: ""{{ item.id | default(omit) }}"" keyserver: ""{{ item.keyserver | default(omit) }}"" url: ""{{ item.url | default(omit) }}"" state: ""{{ item.state | default('present') }}"" register: add_keys until: add_keys|success retries: 5 delay: 2 with_items: ""{{ user_external_repo_keys_list }}"" when: - user_external_repo_keys_list is defined tags: - add-repo-keys - name: Install external repo manually (apt) apt_repository: repo: ""{{ item.repo }}"" state: ""{{ item.state | default('present') }}"" update_cache: yes filename: ""{{ item.filename | default(omit) }}"" register: use_external_repo_apt until: use_external_repo_apt|success retries: 5 delay: 2 with_items: ""{{ user_external_repos_list }}"" when: - user_external_repos_list is defined tags: - add-external-repo ",,135,108
openstack%2Fopenstack-ansible-pip_install~stable%2Focata~Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,openstack/openstack-ansible-pip_install,stable/ocata,Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,Use an explicit version of urrlib3,MERGED,2017-02-28 18:02:25.000000000,2017-03-01 02:26:33.000000000,2017-03-01 02:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 18:02:25.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/73504cef24ae26a92cf4d9c8b2fde029e3720f7a', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the target node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and the get_url/uri modules with https had SSL issues.\nMoving to a more recent version urllib3 fixed it.\n\nChange-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b\n(cherry picked from commit 3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44)\n""}]",0,439086,73504cef24ae26a92cf4d9c8b2fde029e3720f7a,10,5,1,6816,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the target node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and the get_url/uri modules with https had SSL issues.
Moving to a more recent version urllib3 fixed it.

Change-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b
(cherry picked from commit 3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44)
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/86/439086/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml']",2,73504cef24ae26a92cf4d9c8b2fde029e3720f7a,urllib3, pip_required_pip_packages: - urllib3 # SSL SNI support - requests # SSL SNI support,,5,0
openstack%2Fopenstack-ansible-galera_client~stable%2Fnewton~I953764b7bb95df0625993a31ba4effc8b81499aa,openstack/openstack-ansible-galera_client,stable/newton,I953764b7bb95df0625993a31ba4effc8b81499aa,Use dynamic includes to save time,MERGED,2017-03-01 01:09:20.000000000,2017-03-01 02:26:22.000000000,2017-03-01 02:26:22.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-03-01 01:09:20.000000000', 'files': ['tasks/galera_client_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/caae17502d8155ca0dbfd58929a61e78ce712ae2', 'message': 'Use dynamic includes to save time\n\nThis patch adds a dynamic include for installing packages\nvia yum or apt. It avoids having so many skipped tasks and\nshould save some time during gate runs.\n\nChange-Id: I953764b7bb95df0625993a31ba4effc8b81499aa\n(cherry picked from commit 1bfb4553adda4cddbffa9da4e144dbb3ffdf929f)\n'}]",0,439258,caae17502d8155ca0dbfd58929a61e78ce712ae2,7,3,1,6816,,,0,"Use dynamic includes to save time

This patch adds a dynamic include for installing packages
via yum or apt. It avoids having so many skipped tasks and
should save some time during gate runs.

Change-Id: I953764b7bb95df0625993a31ba4effc8b81499aa
(cherry picked from commit 1bfb4553adda4cddbffa9da4e144dbb3ffdf929f)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/58/439258/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_client_install.yml'],1,caae17502d8155ca0dbfd58929a61e78ce712ae2,,"- include: ""galera_client_install_{{ ansible_pkg_mgr }}.yml""",- include: galera_client_install_apt.yml when: - ansible_pkg_mgr == 'apt' - include: galera_client_install_yum.yml when: - ansible_pkg_mgr == 'yum' tags:,1,8
openstack%2Fopenstack-ansible~stable%2Fnewton~Ia07969ac9aee90724eecc6657affd1dbe16045a7,openstack/openstack-ansible,stable/newton,Ia07969ac9aee90724eecc6657affd1dbe16045a7,Use an explicit version of urrlib3,MERGED,2017-02-28 17:57:10.000000000,2017-03-01 02:26:10.000000000,2017-03-01 02:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 17:57:10.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c44f34af92b68e25103eddd6963d5a3da8534284', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the deploy node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and all the lookups with https had SSL issues. Moving to\nurllib3 fixed the thing.\n\nThis only cares about the ansible side, to ensure ansible venv\nhas the proper version. Hosts targetted by ansible (for example\nwhen using get_url), also need a fix. This will be done in\ndifferent patches.\n\nChange-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7\n(cherry picked from commit be08a064b609d24fe61fa7d187bd9c88bc4a3b3a)\n""}]",0,439080,c44f34af92b68e25103eddd6963d5a3da8534284,8,4,1,6816,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the deploy node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and all the lookups with https had SSL issues. Moving to
urllib3 fixed the thing.

This only cares about the ansible side, to ensure ansible venv
has the proper version. Hosts targetted by ansible (for example
when using get_url), also need a fix. This will be done in
different patches.

Change-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7
(cherry picked from commit be08a064b609d24fe61fa7d187bd9c88bc4a3b3a)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/80/439080/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c44f34af92b68e25103eddd6963d5a3da8534284,urllib3,urllib3>=1.15.1 # MIT,,1,0
openstack%2Fpython-openstackclient~master~Ied7ed88ea79da0b778cccf19d087b5ee06edcb71,openstack/python-openstackclient,master,Ied7ed88ea79da0b778cccf19d087b5ee06edcb71,Update doc/source/command-objects/image.rst,MERGED,2017-02-28 20:36:22.000000000,2017-03-01 02:22:21.000000000,2017-03-01 02:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17776}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-28 20:36:22.000000000', 'files': ['doc/source/command-objects/image.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/56c981e7fbd236600085e66af5c7fba9bf9b5251', 'message': ""Update doc/source/command-objects/image.rst\n\nUpdate doc/source/command-objects/image.rst to match\noutput of 'openstack help image create' again.\n\nForgot this in:\nhttps://review.openstack.org/#/c/437335/\n\nChange-Id: Ied7ed88ea79da0b778cccf19d087b5ee06edcb71\n""}]",0,439142,56c981e7fbd236600085e66af5c7fba9bf9b5251,8,4,1,23913,,,0,"Update doc/source/command-objects/image.rst

Update doc/source/command-objects/image.rst to match
output of 'openstack help image create' again.

Forgot this in:
https://review.openstack.org/#/c/437335/

Change-Id: Ied7ed88ea79da0b778cccf19d087b5ee06edcb71
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/42/439142/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/command-objects/image.rst'],1,56c981e7fbd236600085e66af5c7fba9bf9b5251,, [--file <file> | --volume <volume>], [--file <file>] [--volume <volume>],1,2
openstack%2Fpuppet-congress~master~I2b8032079c512bee9e8010f0ff20bf5209328714,openstack/puppet-congress,master,I2b8032079c512bee9e8010f0ff20bf5209328714,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:16:17.000000000,2017-03-01 02:21:55.000000000,2017-03-01 02:21:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/bcc2c39d395bfbb2a07dc6e5a8c969b25859f469', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I2b8032079c512bee9e8010f0ff20bf5209328714\n'}, {'number': 2, 'created': '2017-02-28 17:11:31.000000000', 'files': ['spec/classes/congress_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/a8e8f6b8eb842a2a02356d62a7f87097aa8c0782', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I2b8032079c512bee9e8010f0ff20bf5209328714\n'}]",0,439002,a8e8f6b8eb842a2a02356d62a7f87097aa8c0782,13,2,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: I2b8032079c512bee9e8010f0ff20bf5209328714
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/02/439002/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/congress_init_spec.rb'],1,bcc2c39d395bfbb2a07dc6e5a8c969b25859f469,remove-rpc_backend,, is_expected.to contain_congress_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Fkolla~stable%2Fnewton~I7cbbb8ecc7e330854ca5dd503f3f1bb2d59e6c41,openstack/kolla,stable/newton,I7cbbb8ecc7e330854ca5dd503f3f1bb2d59e6c41,Updated from global requirements,MERGED,2017-02-27 14:48:02.000000000,2017-03-01 02:20:22.000000000,2017-03-01 02:20:22.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 16620}]","[{'number': 1, 'created': '2017-02-27 14:48:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1e6acf44ef15ac2c143b4428ff5054aee21f1d26', 'message': 'Updated from global requirements\n\nChange-Id: I7cbbb8ecc7e330854ca5dd503f3f1bb2d59e6c41\n'}]",0,438523,1e6acf44ef15ac2c143b4428ff5054aee21f1d26,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I7cbbb8ecc7e330854ca5dd503f3f1bb2d59e6c41
",git fetch https://review.opendev.org/openstack/kolla refs/changes/23/438523/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1e6acf44ef15ac2c143b4428ff5054aee21f1d26,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fopenstack-ansible-galera_server~stable%2Focata~I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,openstack/openstack-ansible-galera_server,stable/ocata,I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,Update galera running check for CentOS,MERGED,2017-02-28 20:55:24.000000000,2017-03-01 02:08:39.000000000,2017-03-01 02:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-28 20:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/6c5880902150c167d9e868bea28267b98ee8a228', 'message': 'Update galera running check for CentOS\n\nThis patch fixes the galera running checks so that they work\nproperly on CentOS.\n\nCloses-Bug: 1660445\nChange-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa\n(cherry picked from commit d898abff4e5bcb3aacd64837bbf28e83ed54a265)\n'}, {'number': 2, 'created': '2017-02-28 20:57:07.000000000', 'files': ['tasks/galera_running_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/98537ae776031715bfa5b4e59255a80e0192af2e', 'message': 'Update galera running check for CentOS\n\nThis patch fixes the galera running checks so that they work\nproperly on CentOS.\n\nCloses-Bug: 1660445\nChange-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa\n(cherry picked from commit d898abff4e5bcb3aacd64837bbf28e83ed54a265)\n'}]",0,439149,98537ae776031715bfa5b4e59255a80e0192af2e,12,3,2,6816,,,0,"Update galera running check for CentOS

This patch fixes the galera running checks so that they work
properly on CentOS.

Closes-Bug: 1660445
Change-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa
(cherry picked from commit d898abff4e5bcb3aacd64837bbf28e83ed54a265)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/49/439149/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_running_check.yml'],1,6c5880902150c167d9e868bea28267b98ee8a228,one-step-packages,"- name: Set fact for extra arguments in MySQL commands set_fact: mysql_extra_args: ""{{ ansible_os_family == 'Debian' | ternary('--defaults-file=/etc/mysql/debian.cnf', '') }}"" tags: - galera-cluster-state-check - galera-bootstrap command: ""/usr/bin/mysqladmin {{ mysql_extra_args }} ping"" shell: ""/usr/bin/mysqladmin {{ mysql_extra_args }} extended-status | egrep '(wsrep_ready|wsrep_evs_state)'"""," command: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf ping"" shell: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf extended-status | egrep '(wsrep_ready|wsrep_evs_state)'""",9,2
openstack%2Fcinder~master~Ifde42508b0239c2a7e3e91f3af64bed9e228333e,openstack/cinder,master,Ifde42508b0239c2a7e3e91f3af64bed9e228333e,[WIP] Improvement in handling of rpc & object versions of services,ABANDONED,2016-09-16 03:28:24.000000000,2017-03-01 02:06:26.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 11600}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14208}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16595}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19933}, {'_account_id': 20140}, {'_account_id': 21193}, {'_account_id': 21976}]","[{'number': 1, 'created': '2016-09-16 03:28:24.000000000', 'files': ['cinder/objects/service.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d3e2a38bad647bef664f9fa7a7666a475658411', 'message': '[WIP] Improvement in handling of rpc & object versions of services\n\nCurrently at the start of each cycle, we update message for older\nservices asking operators to upgrade to n+1 version. It helps to\nautomatically discover if the service is running on older version\nbecause of its rpc and object version and then display the\nappropiate message. This commit addresses that.\n\nThis requires in creation of mapping of release names to object &\nrpc version. This is also helpful for historical purposes\n\nChange-Id: Ifde42508b0239c2a7e3e91f3af64bed9e228333e\n'}]",0,371251,7d3e2a38bad647bef664f9fa7a7666a475658411,27,25,1,20140,,,0,"[WIP] Improvement in handling of rpc & object versions of services

Currently at the start of each cycle, we update message for older
services asking operators to upgrade to n+1 version. It helps to
automatically discover if the service is running on older version
because of its rpc and object version and then display the
appropiate message. This commit addresses that.

This requires in creation of mapping of release names to object &
rpc version. This is also helpful for historical purposes

Change-Id: Ifde42508b0239c2a7e3e91f3af64bed9e228333e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/51/371251/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/objects/service.py'],1,7d3e2a38bad647bef664f9fa7a7666a475658411,upgradematrix,"from collections import OrderedDict upgrade_matrix = OrderedDict( [(""Liberty"", {""cinder-volume"": {""object_current_version"": None, ""rpc_current_version"": ""1.3""}, ""cinder-scheduler"": {""object_current_version"": None, ""rpc_current_version"": ""1.8""}, ""cinder-backup"": {""object_current_version"": None, ""rpc_current_version"": ""1.1""} } ), (""Mitaka"", {""cinder-volume"": {""object_current_version"": ""1.3"", ""rpc_current_version"": ""2.0""}, ""cinder-scheduler"": {""object_current_version"": ""1.3"", ""rpc_current_version"": ""2.0""}, ""cinder-backup"": {""object_current_version"": ""1.3"", ""rpc_current_version"": ""2.0""} } ), (""Newton"", {""cinder-volume"": {""object_current_version"": ""1.11"", ""rpc_current_version"": ""3.0""}, ""cinder-scheduler"": {""object_current_version"": ""1.11"", ""rpc_current_version"": ""3.0""}, ""cinder-backup"": {""object_current_version"": ""1.11"", ""rpc_current_version"": ""3.0""} } ) ]) @classmethod def release_check(cls, binary, attribute, artifact_version=None): for k, v in cls.upgrade_matrix.items(): for m, n in v.items(): z = {k: p for k, p in n.items() if p == artifact_version and k == attribute and m == binary} if z != {}: verkeys = cls.upgrade_matrix.keys() if verkeys[-3] == k: return k, verkeys[-1] return -1, -1 curr_ver, next_ver = cls.release_check(binary, attribute, ver_str) if (curr_ver, next_ver) != (-1, -1): msg = (_('One of the services is in %(curr_ver)s version.' 'We do not provide backward compatibility with' '%(curr_ver)s now, you need to upgrade to ' '%(next_ver)s first.') % {'curr_ver': curr_ver})"," if ver_str is None: msg = _('One of the services is in Liberty version. We do not ' 'provide backward compatibility with Liberty now, you ' 'need to upgrade to Mitaka first.')",57,4
openstack%2Fopenstack-ansible~stable%2Focata~Ia07969ac9aee90724eecc6657affd1dbe16045a7,openstack/openstack-ansible,stable/ocata,Ia07969ac9aee90724eecc6657affd1dbe16045a7,Use an explicit version of urrlib3,MERGED,2017-02-28 17:54:38.000000000,2017-03-01 01:59:02.000000000,2017-03-01 01:59:02.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 17:54:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/976b9600e3a58adc93a0677a27e2bb7f63724948', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the deploy node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and all the lookups with https had SSL issues. Moving to\nurllib3 fixed the thing.\n\nThis only cares about the ansible side, to ensure ansible venv\nhas the proper version. Hosts targetted by ansible (for example\nwhen using get_url), also need a fix. This will be done in\ndifferent patches.\n\nChange-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7\n(cherry picked from commit be08a064b609d24fe61fa7d187bd9c88bc4a3b3a)\n""}]",0,439079,976b9600e3a58adc93a0677a27e2bb7f63724948,7,4,1,6816,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the deploy node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and all the lookups with https had SSL issues. Moving to
urllib3 fixed the thing.

This only cares about the ansible side, to ensure ansible venv
has the proper version. Hosts targetted by ansible (for example
when using get_url), also need a fix. This will be done in
different patches.

Change-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7
(cherry picked from commit be08a064b609d24fe61fa7d187bd9c88bc4a3b3a)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/79/439079/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,976b9600e3a58adc93a0677a27e2bb7f63724948,urllib3,urllib3>=1.15.1 # MIT,,1,0
openstack%2Fpuppet-tripleo~master~I24e4c195a31109835739e78a6b53d36f661f9fd0,openstack/puppet-tripleo,master,I24e4c195a31109835739e78a6b53d36f661f9fd0,Configure MySQL client SSL connections via the config file,MERGED,2017-02-23 13:05:05.000000000,2017-03-01 01:49:24.000000000,2017-03-01 01:20:42.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 20172}]","[{'number': 1, 'created': '2017-02-23 13:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1fa79285a61fdc8ed805ff85b909b01af1ff723b', 'message': 'Configure MySQL client SSL connections via the config file\n\nThis does the actual configuration for the mysql client to use SSL if\nthe parameter is set via t-h-t.\n\nChange-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0\nDepends-On: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 2, 'created': '2017-02-23 15:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ea0483532a3f7fd3ccb69ea5bc08b69dd2e389b7', 'message': 'Configure MySQL client SSL connections via the config file\n\nThis does the actual configuration for the mysql client to use SSL if\nthe parameter is set via t-h-t.\n\nChange-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0\nDepends-On: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 3, 'created': '2017-02-24 09:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/cf378458991e78bc50c339922075c9c738bb0c74', 'message': 'Configure MySQL client SSL connections via the config file\n\nThis does the actual configuration for the mysql client to use SSL if\nthe parameter is set via t-h-t.\n\nChange-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0\nDepends-On: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 4, 'created': '2017-02-28 05:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/45f8834130498c0668759408263d8e972f284f0c', 'message': 'Configure MySQL client SSL connections via the config file\n\nThis does the actual configuration for the mysql client to use SSL if\nthe parameter is set via t-h-t.\n\nChange-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0\nDepends-On: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 5, 'created': '2017-02-28 06:57:05.000000000', 'files': ['manifests/profile/base/database/mysql/client.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/fb40fb82f4f98d563af12737a1c433ee4260a43c', 'message': 'Configure MySQL client SSL connections via the config file\n\nThis does the actual configuration for the mysql client to use SSL if\nthe parameter is set via t-h-t.\n\nChange-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0\nDepends-On: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}]",2,437365,fb40fb82f4f98d563af12737a1c433ee4260a43c,36,9,5,10873,,,0,"Configure MySQL client SSL connections via the config file

This does the actual configuration for the mysql client to use SSL if
the parameter is set via t-h-t.

Change-Id: I24e4c195a31109835739e78a6b53d36f661f9fd0
Depends-On: Ifd1a06e0749a05a65f6314255843f572d2209067
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/65/437365/5 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/database/mysql/client.pp'],1,1fa79285a61fdc8ed805ff85b909b01af1ff723b,mysql-ssl," $enable_ssl = false, $step = hiera('step'), if $enable_ssl { $changes_ssl = [ ""set ${mysql_read_default_group}/ssl '1'"", ""set ${mysql_read_default_group}/ssl-mode 'REQUIRED'"", ""set ${mysql_read_default_group}/ssl-ca '/etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt'"" ] } else { $changes_ssl = [ ""rm ${mysql_read_default_group}/ssl"", ""rm ${mysql_read_default_group}/ssl-mode"", ""rm ${mysql_read_default_group}/ssl-ca"" ] } augeas { 'mysql-ssl-options': incl => $mysql_read_default_file, lens => 'Puppet.lns', changes => $changes_ssl, }"," $step = hiera('step'),",22,1
openstack%2Fsolum~master~Ibc7c8a3d6e80a870964ea24fd8238c64d313bb54,openstack/solum,master,Ibc7c8a3d6e80a870964ea24fd8238c64d313bb54,Updated from global requirements,MERGED,2017-02-28 23:26:59.000000000,2017-03-01 01:44:53.000000000,2017-03-01 01:44:52.000000000,"[{'_account_id': 3}, {'_account_id': 14107}]","[{'number': 1, 'created': '2017-02-28 23:26:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/solum/commit/9a116ae9c51f379397dd1d7d95d53e3ce38d34c3', 'message': 'Updated from global requirements\n\nChange-Id: Ibc7c8a3d6e80a870964ea24fd8238c64d313bb54\n'}]",0,439234,9a116ae9c51f379397dd1d7d95d53e3ce38d34c3,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ibc7c8a3d6e80a870964ea24fd8238c64d313bb54
",git fetch https://review.opendev.org/openstack/solum refs/changes/34/439234/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9a116ae9c51f379397dd1d7d95d53e3ce38d34c3,openstack/requirements,oslo.middleware>=3.10.0 # Apache-2.0,oslo.middleware>=3.0.0 # Apache-2.0,1,1
openstack%2Fpuppet-tripleo~master~I870caf20103b044655e699aac09f6621414f5326,openstack/puppet-tripleo,master,I870caf20103b044655e699aac09f6621414f5326,mysqlclient: Drop hiera calls in favor of getting these via t-h-t,MERGED,2017-02-28 12:54:48.000000000,2017-03-01 01:20:52.000000000,2017-03-01 01:20:52.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-28 12:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0bf8acafcb008005ec0b4bc764fade299b6c0c10', 'message': 'mysqlclient: Drop hiera calls in favor of getting these via t-h-t\n\nChange-Id: I870caf20103b044655e699aac09f6621414f5326\nDepends-On: I5af5ccb88e644f4dd25503d8e7a93796695d3039\n'}, {'number': 2, 'created': '2017-02-28 12:56:27.000000000', 'files': ['manifests/profile/base/database/mysql/client.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0c00789351a64f9416a9ca6eb68432a445083c9d', 'message': 'mysqlclient: Drop hiera calls in favor of getting these via t-h-t\n\nThis also updates a leftover comment.\n\nChange-Id: I870caf20103b044655e699aac09f6621414f5326\nDepends-On: I5af5ccb88e644f4dd25503d8e7a93796695d3039\n'}]",0,438952,0c00789351a64f9416a9ca6eb68432a445083c9d,10,4,2,10873,,,0,"mysqlclient: Drop hiera calls in favor of getting these via t-h-t

This also updates a leftover comment.

Change-Id: I870caf20103b044655e699aac09f6621414f5326
Depends-On: I5af5ccb88e644f4dd25503d8e7a93796695d3039
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/52/438952/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/database/mysql/client.pp'],1,0bf8acafcb008005ec0b4bc764fade299b6c0c10,mysql-ssl,"# Defaults to '/etc/my.cnf.d/tripleo.cnf'# Defaults to 'tripleo'# Defaults to undef $mysql_read_default_file = '/etc/my.cnf.d/tripleo.cnf', $mysql_read_default_group = 'tripleo', $mysql_client_bind_address = undef,","# Defaults to hiera('tripleo::profile::base:database::mysql::read_default_file', '/etc/my.cnf.d/tripleo.cnf')# Defaults to hiera('tripleo::profile::base:database::mysql::read_default_group', 'tripleo')# Defaults to hiera('tripleo::profile::base:database::mysql::client_bind_address', undef) $mysql_read_default_file = hiera('tripleo::profile::base:database::mysql::read_default_file', '/etc/my.cnf.d/tripleo.cnf'), $mysql_read_default_group = hiera('tripleo::profile::base:database::mysql::read_default_group', 'tripleo'), $mysql_client_bind_address = hiera('tripleo::profile::base:database::mysql::client_bind_address', undef),",6,6
openstack%2Ftripleo-heat-templates~master~I5af5ccb88e644f4dd25503d8e7a93796695d3039,openstack/tripleo-heat-templates,master,I5af5ccb88e644f4dd25503d8e7a93796695d3039,mysqlclient: Use actual parameter in puppet to set bind-address,MERGED,2017-02-28 12:50:09.000000000,2017-03-01 01:06:57.000000000,2017-03-01 01:06:57.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-28 12:50:09.000000000', 'files': ['puppet/services/database/mysql-client.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c3afe6b01b0b01878625e5648fd8651ba2317ce', 'message': 'mysqlclient: Use actual parameter in puppet to set bind-address\n\nIt was using a hiera key, and fetching that from a hiera call in the\npuppet manfiest. But we can remove that if we set it via hiera from\nt-h-t.\n\nChange-Id: I5af5ccb88e644f4dd25503d8e7a93796695d3039\n'}]",0,438950,3c3afe6b01b0b01878625e5648fd8651ba2317ce,14,4,1,10873,,,0,"mysqlclient: Use actual parameter in puppet to set bind-address

It was using a hiera key, and fetching that from a hiera call in the
puppet manfiest. But we can remove that if we set it via hiera from
t-h-t.

Change-Id: I5af5ccb88e644f4dd25503d8e7a93796695d3039
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/438950/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/database/mysql-client.yaml'],1,3c3afe6b01b0b01878625e5648fd8651ba2317ce,mysql-ssl," tripleo::profile::base::database::mysql::client::mysql_client_bind_address: {get_param: [ServiceNetMap, MysqlNetwork]}"," tripleo::profile::base:database::mysql::client_bind_address: {get_param: [ServiceNetMap, MysqlNetwork]}",1,1
openstack%2Ftripleo-heat-templates~master~Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb,openstack/tripleo-heat-templates,master,Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb,Adding keystone parameters for Congress,MERGED,2017-02-27 17:55:32.000000000,2017-03-01 01:06:09.000000000,2017-03-01 01:06:09.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5792}, {'_account_id': 6924}, {'_account_id': 10873}, {'_account_id': 12715}, {'_account_id': 14985}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-27 17:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4da85f76ba7191bfd37d6f73f957f1c62376a52a', 'message': 'Adding keystone parameters for Congress\n\nChange-Id: Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb\n'}, {'number': 2, 'created': '2017-02-28 14:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/91cc2e92c8bf50c87424bf9884ab16d6867bb34b', 'message': 'Adding keystone parameters for Congress\n\nChange-Id: Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb\n'}, {'number': 3, 'created': '2017-02-28 15:55:58.000000000', 'files': ['puppet/services/congress.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/242fd3072dd31effa4305567163469ec83e7a532', 'message': 'Adding keystone parameters for Congress\n\nChange-Id: Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb\n'}]",6,438646,242fd3072dd31effa4305567163469ec83e7a532,21,8,3,5792,,,0,"Adding keystone parameters for Congress

Change-Id: Ic50aee9e635f62f06fa757fa3d88d9d8c5b28fcb
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/438646/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/congress.yaml'],1,4da85f76ba7191bfd37d6f73f957f1c62376a52a,add-congress," congress::keystone::auth::public_url: {get_param: [EndpointMap, CongressPublic, uri]} congress::keystone::auth::internal_url: {get_param: [EndpointMap, CongressInternal, uri]} congress::keystone::auth::admin_url: {get_param: [EndpointMap, CongressAdmin, uri]} congress::keystone::authtoken::project_name: 'service' congress::keystone::authtoken::auth_url: {get_param: [EndpointMap, KeystoneAdmin, uri_no_suffix]}",,5,0
openstack%2Fpuppet-openstack-integration~stable%2Fnewton~I923ba0c29fd41274e2d2b5477accfc1c308a37bc,openstack/puppet-openstack-integration,stable/newton,I923ba0c29fd41274e2d2b5477accfc1c308a37bc,Bump tempest to 14.0.0 in stable/newton when using RDO,MERGED,2017-02-27 09:05:34.000000000,2017-03-01 01:05:59.000000000,2017-03-01 01:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-27 09:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b7942c7a6868b9e44461a973629baf5ab1c1a024', 'message': 'Bump ceilometer to 14.0.0 in stable/newton\n\nAfter last update in RDO Newton CloudSIG stable repos,\nceilometer tempest plugin is not longer working with\ntempest 13.0.0 and requires 14.0.0.\n\nChange-Id: I923ba0c29fd41274e2d2b5477accfc1c308a37bc\n'}, {'number': 2, 'created': '2017-02-27 09:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8601ccf1a80528378f9b03cbba98f3941be47f07', 'message': 'Bump tempest to 14.0.0 in stable/newton\n\nAfter last update in RDO Newton CloudSIG stable repos,\nceilometer tempest plugin is not longer working with\ntempest 13.0.0 and requires 14.0.0.\n\nChange-Id: I923ba0c29fd41274e2d2b5477accfc1c308a37bc\n'}, {'number': 3, 'created': '2017-02-27 13:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/62494fc40a7b64ad7be9fccf19a487f6e0be4f48', 'message': 'Bump tempest to 14.0.0 in stable/newton when using RDO\n\nAfter last update in RDO Newton CloudSIG stable repos,\nceilometer tempest plugin is not longer working with\ntempest 13.0.0 and requires 14.0.0.\n\nChange-Id: I923ba0c29fd41274e2d2b5477accfc1c308a37bc\n'}, {'number': 4, 'created': '2017-02-28 17:33:54.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/0ab3f87e20e98a7f93375966884273fb80ffc35c', 'message': 'Bump tempest to 14.0.0 in stable/newton when using RDO\n\nAfter last update in RDO Newton CloudSIG stable repos,\nceilometer tempest plugin is not longer working with\ntempest 13.0.0 and requires 14.0.0.\n\nUCA deployment keeps using 13.0.0.\n\nChange-Id: I923ba0c29fd41274e2d2b5477accfc1c308a37bc\n'}]",2,438378,0ab3f87e20e98a7f93375966884273fb80ffc35c,14,3,4,16312,,,0,"Bump tempest to 14.0.0 in stable/newton when using RDO

After last update in RDO Newton CloudSIG stable repos,
ceilometer tempest plugin is not longer working with
tempest 13.0.0 and requires 14.0.0.

UCA deployment keeps using 13.0.0.

Change-Id: I923ba0c29fd41274e2d2b5477accfc1c308a37bc
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/78/438378/4 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,b7942c7a6868b9e44461a973629baf5ab1c1a024,bump-tempest-newton,# Ceilometer tempest plugin required tempest version 14.0.0 export TEMPEST_VERSION=${TEMPEST_VERSION:-14.0.0},# Tempest 13.0.0 is the latest releast that supports Newton. # http://docs.openstack.org/releasenotes/tempest/v13.0.0.html # Ceilometer stable/newton is not compatible with v13.0.0 since https://review.openstack.org/#/c/395506/ # We might eventually need to move the pin to something later than 13.0.0 export TEMPEST_VERSION=${TEMPEST_VERSION:-13.0.0},2,5
openstack%2Ftripleo-common~master~I5f93006a104048464321844a6df4a8bba131d0bb,openstack/tripleo-common,master,I5f93006a104048464321844a6df4a8bba131d0bb,Use kwargs to pass in 'error' to a Mistral Result,MERGED,2017-02-13 15:06:28.000000000,2017-03-01 01:05:33.000000000,2017-03-01 01:05:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 8532}, {'_account_id': 9712}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-13 15:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2881873dbb51013607a18a58b7b17906bfb956ad', 'message': ""Use kwargs to pass in 'error' to a Mistral Result\n\nThis standardises how we create mistral.workflow.utils.Result instances.\nPreviously we used a combination of passing empty strings or None values\nto pass errors only. Using kwargs makes this clearer and cleaner. This\nis also means we use the Result class in the same way as the builtin\nMistral actions.\n\nChange-Id: I5f93006a104048464321844a6df4a8bba131d0bb\n""}, {'number': 2, 'created': '2017-02-17 16:28:49.000000000', 'files': ['tripleo_common/actions/package_update.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/13d97c24496459e17307e418f4b4dab8dfc3b25a', 'message': ""Use kwargs to pass in 'error' to a Mistral Result\n\nThis standardises how we create mistral.workflow.utils.Result instances.\nPreviously we used a combination of passing empty strings or None values\nto pass errors only. Using kwargs makes this clearer and cleaner. This\nis also means we use the Result class in the same way as the builtin\nMistral actions.\n\nChange-Id: I5f93006a104048464321844a6df4a8bba131d0bb\n""}]",0,433106,13d97c24496459e17307e418f4b4dab8dfc3b25a,19,6,2,9712,,,0,"Use kwargs to pass in 'error' to a Mistral Result

This standardises how we create mistral.workflow.utils.Result instances.
Previously we used a combination of passing empty strings or None values
to pass errors only. Using kwargs makes this clearer and cleaner. This
is also means we use the Result class in the same way as the builtin
Mistral actions.

Change-Id: I5f93006a104048464321844a6df4a8bba131d0bb
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/06/433106/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/package_update.py'],1,2881873dbb51013607a18a58b7b17906bfb956ad,, return mistral_workflow_utils.Result(error=msg) return mistral_workflow_utils.Result(error=msg)," return mistral_workflow_utils.Result("""", msg) return mistral_workflow_utils.Result("""", msg)",2,2
openstack%2Ftripleo-ci~master~I6c8bfebcc8e0379e0c400cd30eaa5ca6fe5e321d,openstack/tripleo-ci,master,I6c8bfebcc8e0379e0c400cd30eaa5ca6fe5e321d,Add postci metric,MERGED,2017-02-08 22:31:38.000000000,2017-03-01 01:04:54.000000000,2017-03-01 01:04:54.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-02-08 22:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5886652a7a017d2e060ab72d3f70ce9f53e63fb3', 'message': ""Add postci metric\n\nWill allow us to keep track of how long it's taking to collect logs\nand such after a run, which can be a non-trivial amount of time.\n\nChange-Id: I6c8bfebcc8e0379e0c400cd30eaa5ca6fe5e321d\n""}, {'number': 2, 'created': '2017-02-23 15:16:05.000000000', 'files': ['scripts/common_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/12998562fcd2c7aac3df7d48dc34b31f262ed5df', 'message': ""Add postci metric\n\nWill allow us to keep track of how long it's taking to collect logs\nand such after a run, which can be a non-trivial amount of time.\n\nChange-Id: I6c8bfebcc8e0379e0c400cd30eaa5ca6fe5e321d\n""}]",2,431209,12998562fcd2c7aac3df7d48dc34b31f262ed5df,37,5,2,6928,,,0,"Add postci metric

Will allow us to keep track of how long it's taking to collect logs
and such after a run, which can be a non-trivial amount of time.

Change-Id: I6c8bfebcc8e0379e0c400cd30eaa5ca6fe5e321d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/09/431209/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/common_functions.sh'],1,5886652a7a017d2e060ab72d3f70ce9f53e63fb3,organize-metrics," start_metric ""tripleo.${STABLE_RELEASE:-master}.${TOCI_JOBTYPE}.postci.seconds"" stop_metric ""tripleo.${STABLE_RELEASE:-master}.${TOCI_JOBTYPE}.postci.seconds""",,2,0
openstack%2Fdragonflow~stable%2Fnewton~Ifc475cd98a48d5c7dd80606c2fb94097ade8a326,openstack/dragonflow,stable/newton,Ifc475cd98a48d5c7dd80606c2fb94097ade8a326,"[Test] Revert ""Remove the deprecation warning of neutron.db.l3_db""",ABANDONED,2017-02-28 07:54:28.000000000,2017-03-01 01:04:31.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-28 07:54:28.000000000', 'files': ['dragonflow/neutron/services/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bdc43e1a04b4714824113e4e069c180560cd514f', 'message': '[Test] Revert ""Remove the deprecation warning of neutron.db.l3_db""\n\nThis reverts commit e14002df6d05ace46f009b122a097f77f8784b25.\n\nSince neutron newton version doesn\'t have neutron.db.models.l3,\nuse the old fasion l3_db.\n\nChange-Id: Ifc475cd98a48d5c7dd80606c2fb94097ade8a326\n'}]",0,438835,bdc43e1a04b4714824113e4e069c180560cd514f,3,1,1,11159,,,0,"[Test] Revert ""Remove the deprecation warning of neutron.db.l3_db""

This reverts commit e14002df6d05ace46f009b122a097f77f8784b25.

Since neutron newton version doesn't have neutron.db.models.l3,
use the old fasion l3_db.

Change-Id: Ifc475cd98a48d5c7dd80606c2fb94097ade8a326
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/35/438835/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/services/l3_router_plugin.py'],1,bdc43e1a04b4714824113e4e069c180560cd514f,,from neutron.db import l3_db,from neutron.db.models import l3 as l3_db,1,1
openstack%2Fopenstack-ansible-lxc_hosts~master~I90f9d95c5dadd0966a04dd7b02b540372d1807cf,openstack/openstack-ansible-lxc_hosts,master,I90f9d95c5dadd0966a04dd7b02b540372d1807cf,Use block-rescue for cache create,MERGED,2017-02-28 22:48:28.000000000,2017-03-01 00:59:22.000000000,2017-03-01 00:49:27.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-28 22:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/0942b8adba800fbee069adada908bb58abd30d93', 'message': 'Use block-rescue for cache create\n\nInstead of using two tasks, skipping the second if the first\nsucceeds, this will execute the first and totally ignore the\nsecond if the first succeeds. The second will only execute if\nthe first fails.\n\nChange-Id: I90f9d95c5dadd0966a04dd7b02b540372d1807cf\n'}, {'number': 2, 'created': '2017-02-28 22:49:11.000000000', 'files': ['tasks/lxc_cache.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/39889dfc2b75c3f039b6bd8da46654063b466095', 'message': ""Use block-rescue for cache create\n\nInstead of using two tasks, skipping the second if the first\nsucceeds, this will execute the first and totally ignore the\nsecond if the first succeeds. The second will only execute if\nthe first fails.\n\nThis is more efficient to execute and gets rid of the rather\nhorrible 'failed_when: false' on the first task.\n\nChange-Id: I90f9d95c5dadd0966a04dd7b02b540372d1807cf\n""}]",0,439199,39889dfc2b75c3f039b6bd8da46654063b466095,10,3,2,6816,,,0,"Use block-rescue for cache create

Instead of using two tasks, skipping the second if the first
succeeds, this will execute the first and totally ignore the
second if the first succeeds. The second will only execute if
the first fails.

This is more efficient to execute and gets rid of the rather
horrible 'failed_when: false' on the first task.

Change-Id: I90f9d95c5dadd0966a04dd7b02b540372d1807cf
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/99/439199/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_cache.yml'],1,0942b8adba800fbee069adada908bb58abd30d93,block-rescue,"- block: - name: Create base container lxc_container: name: ""LXC_NAME"" template: ""download"" state: stopped backing_store: ""dir"" template_options: ""{{ lxc_cache_download_template_options }} --keyserver {{ lxc_image_cache_primary_keyserver }}"" register: cache_download_primary retries: 3 delay: 10 until: cache_download_primary | success environment: ""{{ lxc_cache_environment }}"" tags: - lxc-cache - lxc-cache-download - lxc_hosts-install rescue: - name: Create base container lxc_container: name: ""LXC_NAME"" template: ""download"" state: stopped backing_store: ""dir"" template_options: ""{{ lxc_cache_download_template_options }} --keyserver {{ lxc_image_cache_secondary_keyserver }}"" register: cache_download_secondary retries: 3 delay: 10 until: cache_download_secondary | success environment: ""{{ lxc_cache_environment }}"" tags: - lxc-cache - lxc-cache-download - lxc_hosts-install","- name: Create base container lxc_container: name: ""LXC_NAME"" template: ""download"" state: stopped backing_store: ""dir"" template_options: ""{{ lxc_cache_download_template_options }} --keyserver {{ lxc_image_cache_primary_keyserver }}"" register: cache_download_primary retries: 3 delay: 10 until: cache_download_primary | success failed_when: false environment: ""{{ lxc_cache_environment }}"" tags: - lxc-cache - lxc-cache-download - lxc_hosts-install - name: Create base container lxc_container: name: ""LXC_NAME"" template: ""download"" state: stopped backing_store: ""dir"" template_options: ""{{ lxc_cache_download_template_options }} --keyserver {{ lxc_image_cache_secondary_keyserver }}"" when: cache_download_primary | failed register: cache_download_secondary retries: 3 delay: 10 until: cache_download_secondary | success environment: ""{{ lxc_cache_environment }}"" tags: - lxc-cache - lxc-cache-download - lxc_hosts-install",34,34
openstack%2Fdevstack-gate~master~Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a,openstack/devstack-gate,master,Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a,Gather /proc/cpuinfo,MERGED,2017-02-14 22:05:02.000000000,2017-03-01 00:45:39.000000000,2017-03-01 00:45:39.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5803}, {'_account_id': 9656}, {'_account_id': 17120}]","[{'number': 1, 'created': '2017-02-14 22:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2b14aba6bcf48ee90dffad5320f2c555202e3847', 'message': 'Gather /proc/cpuinfo\n\nThis information was once collected for gate jobs, but was removed by\nI916e075d8ed3ee6079e4c4621f6eb10f1d30bf95 rework. Turned out that the\ninfo collected by ansible itself does not provide some crucial data,\nlike cpu flags supported by the machine that may become handy when\ndebugging some performance related gate issues.\n\nThis patch restores collecting the info, using ansible.\n\nChange-Id: Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a\n'}, {'number': 2, 'created': '2017-02-28 20:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ec23b5577e017a5a9d611ab7734e506f406cf9de', 'message': 'Gather /proc/cpuinfo\n\nThis information was once collected for gate jobs, but was removed by\nI916e075d8ed3ee6079e4c4621f6eb10f1d30bf95 rework. Turned out that the\ninfo collected by ansible itself does not provide some crucial data,\nlike cpu flags supported by the machine that may become handy when\ndebugging some performance related gate issues.\n\nThis patch restores collecting the info, using ansible.\n\nChange-Id: Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a\n'}, {'number': 3, 'created': '2017-02-28 20:16:07.000000000', 'files': ['playbooks/roles/gather_host_info/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f4c9f1049acaf7bf39ff325c075f1dd6bdc7906c', 'message': 'Gather /proc/cpuinfo\n\nThis information was once collected for gate jobs, but was removed by\nI916e075d8ed3ee6079e4c4621f6eb10f1d30bf95 rework. Turned out that the\ninfo collected by ansible itself does not provide some crucial data,\nlike cpu flags supported by the machine that may become handy when\ndebugging some performance related gate issues.\n\nThis patch restores collecting the info, using ansible.\n\nChange-Id: Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a\n'}]",0,433949,f4c9f1049acaf7bf39ff325c075f1dd6bdc7906c,17,6,3,9656,,,0,"Gather /proc/cpuinfo

This information was once collected for gate jobs, but was removed by
I916e075d8ed3ee6079e4c4621f6eb10f1d30bf95 rework. Turned out that the
info collected by ansible itself does not provide some crucial data,
like cpu flags supported by the machine that may become handy when
debugging some performance related gate issues.

This patch restores collecting the info, using ansible.

Change-Id: Icd2bc68eb723ba2f3fc0d8a113fb247bc478121a
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/49/433949/3 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/gather_host_info/tasks/main.yaml'],1,2b14aba6bcf48ee90dffad5320f2c555202e3847,," - debug: var=hostvars[inventory_hostname] - command: cat /proc/cpuinfo name: ""Gather kernel cpu info""",,4,0
openstack%2Fopenstack-manuals~master~I2213a0020272b8b034c9068cd7f38ecfcb62a77a,openstack/openstack-manuals,master,I2213a0020272b8b034c9068cd7f38ecfcb62a77a,Add the missing hyperlink markup for the title,MERGED,2017-02-28 15:23:21.000000000,2017-03-01 00:45:26.000000000,2017-03-01 00:45:26.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10705}]","[{'number': 1, 'created': '2017-02-28 15:23:21.000000000', 'files': ['doc/arch-design/source/hybrid-prescriptive-examples.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bc51797fc9ef98f21cb3cb38f98f25e7257bc702', 'message': 'Add the missing hyperlink markup for the title\n\nChange-Id: I2213a0020272b8b034c9068cd7f38ecfcb62a77a\n'}]",0,439016,bc51797fc9ef98f21cb3cb38f98f25e7257bc702,7,3,1,14151,,,0,"Add the missing hyperlink markup for the title

Change-Id: I2213a0020272b8b034c9068cd7f38ecfcb62a77a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/439016/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/source/hybrid-prescriptive-examples.rst'],1,bc51797fc9ef98f21cb3cb38f98f25e7257bc702,,`Add volume metadata support to Cinder backup <https://blueprints.launchpad.net/cinder/+spec/cinder-backup-volume-metadata-support>`_.,https://blueprints.launchpad.net/cinder/+spec/cinder-backup-volume-metadata-support.,2,1
openstack%2Fopenstack-ansible-os_neutron~stable%2Fnewton~I7b580db0496ff009a2f64c71447b2977f22d6bf6,openstack/openstack-ansible-os_neutron,stable/newton,I7b580db0496ff009a2f64c71447b2977f22d6bf6,Implementation Neutron SR-IOV,MERGED,2017-02-20 22:09:41.000000000,2017-03-01 00:38:39.000000000,2017-03-01 00:38:39.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14552}]","[{'number': 1, 'created': '2017-02-20 22:09:41.000000000', 'files': ['templates/plugins/ml2/sriov_nic_agent.ini.j2', 'templates/plugins/ml2/linuxbridge_agent.ini.j2', 'templates/plugins/ml2/ml2_conf.ini.j2', 'releasenotes/notes/neutron-sriov-50c0099554574d01.yaml', 'tasks/neutron_post_install.yml', 'doc/source/configure-network-services.rst', 'tasks/neutron_init.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/7b8c3bb041a88cd6455d7c899916652c0228518a', 'message': 'Implementation Neutron SR-IOV\n\nThis change implements SR-IOV support inside Neutron via\nthe new ``ml2.sriov`` plugin.\nThe current implementation automatically configures the ML2\nmechanism drivers via the enabled neutron_plugins and\nconfigured mechanisms attribute inside the dictionary.\nThe implementation is based off the neutron-sriov-nic-agent\nand configures physical device mappings over a new\nattribute ``sriov_host_interface`` as part of the\nprovider_networks configuration.\nAdditionally the FDB agent inside the ``linuxbridge_agent.ini``\nis enabled to support the linuxbridge and sriov-nic-agent on the\nsame interface.\n\nCloses-Bug: #1653283\n\nCo-Authored-By: James Denton <james.denton@rackspace.com>\n\nChange-Id: I7b580db0496ff009a2f64c71447b2977f22d6bf6\nDepends-On: Ia62725e2369f75000157e0ab2c3f858e61fef10d\nImplements: sriov support\n(cherry picked from commit 7454e6040c45b58bca46bcce0c1634df6cefd681)\n'}]",0,436225,7b8c3bb041a88cd6455d7c899916652c0228518a,10,4,1,14552,,,0,"Implementation Neutron SR-IOV

This change implements SR-IOV support inside Neutron via
the new ``ml2.sriov`` plugin.
The current implementation automatically configures the ML2
mechanism drivers via the enabled neutron_plugins and
configured mechanisms attribute inside the dictionary.
The implementation is based off the neutron-sriov-nic-agent
and configures physical device mappings over a new
attribute ``sriov_host_interface`` as part of the
provider_networks configuration.
Additionally the FDB agent inside the ``linuxbridge_agent.ini``
is enabled to support the linuxbridge and sriov-nic-agent on the
same interface.

Closes-Bug: #1653283

Co-Authored-By: James Denton <james.denton@rackspace.com>

Change-Id: I7b580db0496ff009a2f64c71447b2977f22d6bf6
Depends-On: Ia62725e2369f75000157e0ab2c3f858e61fef10d
Implements: sriov support
(cherry picked from commit 7454e6040c45b58bca46bcce0c1634df6cefd681)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/25/436225/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/plugins/ml2/sriov_nic_agent.ini.j2', 'templates/plugins/ml2/linuxbridge_agent.ini.j2', 'templates/plugins/ml2/ml2_conf.ini.j2', 'releasenotes/notes/neutron-sriov-50c0099554574d01.yaml', 'tasks/neutron_post_install.yml', 'doc/source/configure-network-services.rst', 'tasks/neutron_init.yml', 'defaults/main.yml']",8,7b8c3bb041a88cd6455d7c899916652c0228518a,bug/1653283,"# The neutron core plugin (ML2) is defined with neutron_plugin_type, # you can not load multiple ML2 plugins as core. # Additional ML2 plugins can be loaded with neutron_plugin_types (as list) neutron_plugin_type: 'ml2.lxb' neutron_plugin_types: [] neutron_ml2_mechanism_drivers: >- {%- set _var = [] -%} {%- for plugin in [neutron_plugin_type]|union(neutron_plugin_types) -%} {%- if _var.append(neutron_plugins[plugin].mechanisms) -%}{%- endif -%} {%- endfor -%} {%- if neutron_l2_population | bool -%} {%- if _var.append('l2population') -%}{%- endif -%} {%- endif -%} {{ _var | join(',') }} mechanisms: ""linuxbridge"" mechanisms: ""openvswitch"" mechanisms: ""openvswitch"" ml2.sriov: driver_types: ""{{ neutron_ml2_drivers_type }}"" mechanisms: ""sriovnicswitch"" plugin_ini: plugins/ml2/sriov_nic_agent.ini plugin_conf_ini_overrides: ""{{ neutron_sriov_nic_agent_ini_overrides }}"" neutron-sriov-nic-agent: group: neutron_sriov_nic_agent service_name: neutron-sriov-nic-agent service_en: ""{{ 'ml2.sriov' in neutron_plugin_types }}"" service_conf_path: ""{{ neutron_conf_dir }}"" service_conf: plugins/ml2/sriov_nic_agent.ini config_options: ""--config-file {{ neutron_conf_dir }}/neutron.conf --config-file {{ neutron_conf_dir }}/plugins/ml2/ml2_conf.ini --config-file {{ neutron_conf_dir }}/plugins/ml2/sriov_nic_agent.ini --log-file=/var/log/neutron/neutron-sriov-nic-agent.log"" config_overrides: ""{{ neutron_sriov_nic_agent_ini_overrides }}"" config_type: ""ini""# network_sriov_mappings: ""vlan:p4p1""neutron_sriov_excluded_devices: """" neutron_sriov_nic_agent_ini_overrides: {}","neutron_plugin_type: ml2.lxb mechanisms: ""linuxbridge{% if neutron_l2_population | bool %},l2population{% endif %}"" mechanisms: ""openvswitch{% if neutron_l2_population | bool %},l2population{% endif %}"" mechanisms: ""openvswitch{% if neutron_l2_population | bool %},l2population{% endif %}""",218,6
openstack%2Fopenstack-manuals~master~I753e4e02f21b7e02df1eed1ee4f43f2a0f5492fe,openstack/openstack-manuals,master,I753e4e02f21b7e02df1eed1ee4f43f2a0f5492fe,modify the doc/install-guide/source/nova-compute-install.rst,ABANDONED,2017-02-28 08:38:03.000000000,2017-03-01 00:31:47.000000000,,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 22165}, {'_account_id': 23946}, {'_account_id': 23950}, {'_account_id': 23975}, {'_account_id': 23976}, {'_account_id': 24015}, {'_account_id': 24547}]","[{'number': 1, 'created': '2017-02-28 08:38:03.000000000', 'files': ['doc/install-guide/source/nova-compute-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/19eabf5ed825f8ca089ca5bc469a3c01be73c13e', 'message': 'modify the doc/install-guide/source/nova-compute-install.rst\n\nChange-Id: I753e4e02f21b7e02df1eed1ee4f43f2a0f5492fe\n'}]",2,438850,19eabf5ed825f8ca089ca5bc469a3c01be73c13e,8,9,1,23975,,,0,"modify the doc/install-guide/source/nova-compute-install.rst

Change-Id: I753e4e02f21b7e02df1eed1ee4f43f2a0f5492fe
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/438850/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/nova-compute-install.rst'],1,19eabf5ed825f8ca089ca5bc469a3c01be73c13e,Compute nodes installation guide the lack of placement configuration section that lead to computing services start-up failure in the Ocata version,, api_servers = http://controller:9292 ,0,2
openstack%2Fopenstack-manuals~master~I1c13aefb7119decfd822ce2b9e91c5936ffed612,openstack/openstack-manuals,master,I1c13aefb7119decfd822ce2b9e91c5936ffed612,add nova compute configue on the placement,ABANDONED,2017-02-28 08:29:03.000000000,2017-03-01 00:31:21.000000000,,"[{'_account_id': 3}, {'_account_id': 20156}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-28 08:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/65da01f25dbc7e68b673a6db17b546f65bbd4412', 'message': 'add nova compute configue on the placement\n\nChange-Id: I1c13aefb7119decfd822ce2b9e91c5936ffed612\n'}, {'number': 2, 'created': '2017-02-28 09:25:54.000000000', 'files': ['doc/install-guide/source/nova-compute-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/74f9111dc6c26d3a66d89b7536469c1b709c6ecc', 'message': 'add nova compute configue on the placement\n\nChange-Id: I1c13aefb7119decfd822ce2b9e91c5936ffed612\n'}]",0,438847,74f9111dc6c26d3a66d89b7536469c1b709c6ecc,8,3,2,23975,,,0,"add nova compute configue on the placement

Change-Id: I1c13aefb7119decfd822ce2b9e91c5936ffed612
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/438847/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/nova-compute-install.rst'],1,65da01f25dbc7e68b673a6db17b546f65bbd4412,Compute nodes installation guide the lack of placement configuration section that lead to computing services start-up failure in the Ocata version," * In the ``[placement]`` section, configure placement service access: .. path /etc/nova/nova.conf .. code-block:: ini [placement] # ... api_servers = http://controller:9292 auth_uri = http://controller:5000 auth_url = http://controller:35357 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = NOVA_PASS Replace ``NOVA_PASS`` with the password you chose for the ``nova`` user in the Identity service. .. note:: Comment out or remove any other options in the ``[keystone_authtoken]`` section. ",,27,0
openstack%2Fkolla~master~I08b6d7f11e505441d8b766a076fd451a2708c062,openstack/kolla,master,I08b6d7f11e505441d8b766a076fd451a2708c062,Add reconfigure file to Congress,ABANDONED,2016-09-27 09:44:43.000000000,2017-03-01 00:31:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-09-27 09:44:43.000000000', 'files': ['ansible/roles/congress/tasks/reconfigure.yml', 'ansible/roles/congress/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9f822280c14efb6c0b30c9b246cc72d9450f5340', 'message': 'Add reconfigure file to Congress\n\nTrivialFix\n\nChange-Id: I08b6d7f11e505441d8b766a076fd451a2708c062\n'}]",0,377412,9f822280c14efb6c0b30c9b246cc72d9450f5340,4,1,1,22165,,,0,"Add reconfigure file to Congress

TrivialFix

Change-Id: I08b6d7f11e505441d8b766a076fd451a2708c062
",git fetch https://review.opendev.org/openstack/kolla refs/changes/12/377412/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/congress/tasks/reconfigure.yml', 'ansible/roles/congress/tasks/do_reconfigure.yml']",2,9f822280c14efb6c0b30c9b246cc72d9450f5340,,"--- - name: Ensuring the containers up kolla_docker: name: ""{{ item.name }}"" action: ""get_container_state"" register: container_state failed_when: container_state.Running == false when: inventory_hostname in groups[item.group] with_items: - { name: congress-api, group: congress-api } - { name: congress-datasource, group: congress-datasource } - { name: congress-policy-engine, group: congress-policy-engine } - include: config.yml - name: Check the configs command: docker exec {{ item.name }} /usr/local/bin/kolla_set_configs --check changed_when: false failed_when: false register: check_results when: inventory_hostname in groups[item.group] with_items: - { name: congress-api, group: congress-api } - { name: congress-datasource, group: congress-datasource } - { name: congress-policy-engine, group: congress-policy-engine } # NOTE: when config_strategy == 'COPY_ALWAYS' # and container env['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE', # just remove the container and start again - name: Containers config strategy kolla_docker: name: ""{{ item.name }}"" action: ""get_container_env"" register: container_envs when: inventory_hostname in groups[item.group] with_items: - { name: congress-api, group: congress-api } - { name: congress-datasource, group: congress-datasource } - { name: congress-policy-engine, group: congress-policy-engine } - name: Remove the containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""remove_container"" register: remove_containers when: - inventory_hostname in groups[item[0]['group']] - config_strategy == ""COPY_ONCE"" or item[1]['KOLLA_CONFIG_STRATEGY'] == 'COPY_ONCE' - item[2]['rc'] == 1 with_together: - [{ name: congress-api, group: congress-api }, { name: congress-datasource, group: congress-datasource }, { name: congress-policy-engine, group: congress-policy-engine }] - ""{{ container_envs.results }}"" - ""{{ check_results.results }}"" - include: start.yml when: remove_containers.changed - name: Restart containers kolla_docker: name: ""{{ item[0]['name'] }}"" action: ""restart_container"" when: - inventory_hostname in groups[item[0]['group']] - config_strategy == 'COPY_ALWAYS' - item[1]['KOLLA_CONFIG_STRATEGY'] != 'COPY_ONCE' - item[2]['rc'] == 1 with_together: - [{ name: congress-api, group: congress-api }, { name: congress-datasource, group: congress-datasource }, { name: congress-policy-engine, group: congress-policy-engine }] - ""{{ container_envs.results }}"" - ""{{ check_results.results }}"" ",,79,0
openstack%2Fopenstack-manuals~master~Ica73d37638cdd4f5dd856289f578fecca2b4e99e,openstack/openstack-manuals,master,Ica73d37638cdd4f5dd856289f578fecca2b4e99e,Make up for those incomplete commands,MERGED,2017-02-27 15:25:43.000000000,2017-03-01 00:23:52.000000000,2017-03-01 00:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 9162}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-02-27 15:25:43.000000000', 'files': ['doc/admin-guide/source/identity-keystone-usage-and-features.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/061aa36f9fd8af8cf55401760131fbba097034d9', 'message': 'Make up for those incomplete commands\n\nChange-Id: Ica73d37638cdd4f5dd856289f578fecca2b4e99e\n'}]",0,438555,061aa36f9fd8af8cf55401760131fbba097034d9,8,4,1,14151,,,0,"Make up for those incomplete commands

Change-Id: Ica73d37638cdd4f5dd856289f578fecca2b4e99e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/55/438555/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/identity-keystone-usage-and-features.rst'],1,061aa36f9fd8af8cf55401760131fbba097034d9,,"example, the :command:`openstack user list` and :command:`openstack project create` commands can be invoked as follows:","example, the :command:`user list` and :command:`project create` commands can be invoked as follows:",2,2
openstack%2Fpython-tricircleclient~master~Ifd650f8ecae049cc1a244da1fa10983d3affb01c,openstack/python-tricircleclient,master,Ifd650f8ecae049cc1a244da1fa10983d3affb01c,Fix all tox execution,MERGED,2017-02-24 18:10:43.000000000,2017-03-01 00:22:23.000000000,2017-03-01 00:22:23.000000000,"[{'_account_id': 3}, {'_account_id': 8726}, {'_account_id': 11819}, {'_account_id': 22218}]","[{'number': 1, 'created': '2017-02-24 18:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/cbe10aeaba88d50b99cd697fc7b246c6b59baff4', 'message': 'Fix all tox execution\n\n1. What is the problem?\nThere are missing files and folders that causes failures during the\nexecution of the job gates.\n\n2. What is the solution to the problem?\nAdd the required folders and files to enable the creation of\ndocumentation and execution of unit tests.\n\n3. What the features need to be implemented to the Tricircle\n   to realize the solution?\nNone\n\nChange-Id: Ifd650f8ecae049cc1a244da1fa10983d3affb01c\n'}, {'number': 2, 'created': '2017-02-28 15:52:22.000000000', 'files': ['doc/source/index.rst', 'test-requirements.txt', 'tricircleclient/tests/unit/test_exceptions.py', 'tricircleclient/exceptions.py', 'tricircleclient/tests/unit/__init__.py', 'doc/source/api.rst', 'tricircleclient/tests/__init__.py', 'doc/source/conf.py', 'tricircleclient/i18n.py', 'tox.ini', 'tricircleclient/v1/routings.py'], 'web_link': 'https://opendev.org/openstack/python-tricircleclient/commit/833564c8957362556b4c07711efde8ea81c3c8db', 'message': 'Fix all tox execution\n\n1. What is the problem?\nThere are missing files and folders that causes failures during the\nexecution of the job gates.\n\n2. What is the solution to the problem?\nAdd the required folders and files to enable the creation of\ndocumentation and execution of unit tests.\n\n3. What the features need to be implemented to the Tricircle\n   to realize the solution?\nNone\n\nChange-Id: Ifd650f8ecae049cc1a244da1fa10983d3affb01c\n'}]",13,438029,833564c8957362556b4c07711efde8ea81c3c8db,13,4,2,8726,,,0,"Fix all tox execution

1. What is the problem?
There are missing files and folders that causes failures during the
execution of the job gates.

2. What is the solution to the problem?
Add the required folders and files to enable the creation of
documentation and execution of unit tests.

3. What the features need to be implemented to the Tricircle
   to realize the solution?
None

Change-Id: Ifd650f8ecae049cc1a244da1fa10983d3affb01c
",git fetch https://review.opendev.org/openstack/python-tricircleclient refs/changes/29/438029/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tricircleclient/tests/unit/test_exceptions.py', 'tricircleclient/tests/unit/__init__.py', 'doc/source/api.rst', 'tricircleclient/tests/__init__.py', 'doc/source/conf.py', 'tricircleclient/i18n.py', 'doc/source/index.rst', 'tricircleclient/v1/pods_cli.py', 'tricircleclient/exceptions.py', 'tox.ini', 'tricircleclient/v1/routings.py']",12,cbe10aeaba88d50b99cd697fc7b246c6b59baff4,438029, data=jsonutils.dumps(routing)).json() , data=jsonutils.dumps(routing)).json(),273,12
openstack%2Fopenstack-ansible-os_horizon~master~Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7,openstack/openstack-ansible-os_horizon,master,Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7,Make long-running tasks use async,MERGED,2017-02-20 19:11:58.000000000,2017-03-01 00:18:29.000000000,2017-02-21 19:27:45.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 4268}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-20 19:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/8abaa1db37f9fe0c9237b62183888c89bce0efc0', 'message': 'Make long-running tasks use async\n\nThis patch makes two long-running Horizon tasks use async:\n\n  - compressing static files\n  - compiling messages for translation\n\nCombined, these steps take anywhere from 60-120 seconds to complete,\ndepending on the CI environment.\n\nChange-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7\n'}, {'number': 2, 'created': '2017-02-20 20:38:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/85fa36a9fee973b6dd7d67153916a6065cd52ef7', 'message': 'Make long-running tasks use async\n\nThis patch makes two long-running Horizon tasks use async:\n\n  - compressing static files\n  - compiling messages for translation\n\nCombined, these steps take anywhere from 60-120 seconds to complete,\ndepending on the CI environment.\n\nChange-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7\n'}, {'number': 3, 'created': '2017-02-20 21:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/6251f31354d9fc22011e47831096d3b6ec3c9c9d', 'message': 'Make long-running tasks use async\n\nThis patch makes two long-running Horizon tasks use async:\n\n  - compressing static files\n  - compiling messages for translation\n\nCombined, these steps take anywhere from 60-120 seconds to complete,\ndepending on the CI environment.\n\nChange-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7\n'}, {'number': 4, 'created': '2017-02-21 14:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/a245641fac80cc03b7d4f62772f848996d545d83', 'message': 'Make long-running tasks use async\n\nThis patch makes two long-running Horizon tasks use async:\n\n  - compressing static files\n  - compiling messages for translation\n\nCombined, these steps take anywhere from 60-120 seconds to complete,\ndepending on the CI environment.\n\nChange-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7\n'}, {'number': 5, 'created': '2017-02-21 15:50:44.000000000', 'files': ['tasks/main.yml', 'tasks/horizon_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/1ed153273d89c93de0ee9483e2687c24b7f3be33', 'message': 'Make long-running tasks use async\n\nThis patch makes two long-running Horizon tasks use async:\n\n  - compressing static files\n  - compiling messages for translation\n\nCombined, these steps take anywhere from 60-120 seconds to complete,\ndepending on the CI environment.\n\nChange-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7\n'}]",1,436145,1ed153273d89c93de0ee9483e2687c24b7f3be33,20,5,5,538,,,0,"Make long-running tasks use async

This patch makes two long-running Horizon tasks use async:

  - compressing static files
  - compiling messages for translation

Combined, these steps take anywhere from 60-120 seconds to complete,
depending on the CI environment.

Change-Id: Ibee0a0f5ebfe575d1e336c2e98322bc0a85a7af7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/45/436145/3 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/horizon_post_install.yml']",2,8abaa1db37f9fe0c9237b62183888c89bce0efc0,async_jobs, register: async_compile_messages async: 600 poll: 0 register: async_compress_static_files async: 600 poll: 0,,16,0
openstack%2Fopenstack-ansible-galera_server~stable%2Fnewton~I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,openstack/openstack-ansible-galera_server,stable/newton,I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,Update galera running check for CentOS,MERGED,2017-02-28 21:00:55.000000000,2017-03-01 00:16:35.000000000,2017-03-01 00:16:35.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-28 21:00:55.000000000', 'files': ['tasks/galera_running_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/0f8c2ef0cdcc53fe1e0f4a88ca7893e0732bc712', 'message': 'Update galera running check for CentOS\n\nThis patch fixes the galera running checks so that they work\nproperly on CentOS.\n\nCloses-Bug: 1660445\nChange-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa\n(cherry picked from commit d898abff4e5bcb3aacd64837bbf28e83ed54a265)\n'}]",0,439153,0f8c2ef0cdcc53fe1e0f4a88ca7893e0732bc712,7,3,1,6816,,,0,"Update galera running check for CentOS

This patch fixes the galera running checks so that they work
properly on CentOS.

Closes-Bug: 1660445
Change-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa
(cherry picked from commit d898abff4e5bcb3aacd64837bbf28e83ed54a265)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/53/439153/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_running_check.yml'],1,0f8c2ef0cdcc53fe1e0f4a88ca7893e0732bc712,bug/1660445,"- name: Set fact for extra arguments in MySQL commands set_fact: mysql_extra_args: ""{{ ansible_os_family == 'Debian' | ternary('--defaults-file=/etc/mysql/debian.cnf', '') }}"" tags: - galera-cluster-state-check - galera-bootstrap command: ""/usr/bin/mysqladmin {{ mysql_extra_args }} ping"" shell: ""/usr/bin/mysqladmin {{ mysql_extra_args }} extended-status | egrep '(wsrep_ready|wsrep_evs_state)'"""," command: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf ping"" shell: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf extended-status | egrep '(wsrep_ready|wsrep_evs_state)'""",9,2
openstack%2Fpyeclib~master~Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c,openstack/pyeclib,master,Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c,Use py35 tox environment by default,MERGED,2017-02-28 04:51:25.000000000,2017-03-01 00:16:18.000000000,2017-03-01 00:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 15343}]","[{'number': 1, 'created': '2017-02-28 04:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/735c81be929024f31a79e091530cf67efd5fedc1', 'message': 'Add py35 tox environment\n\nChange-Id: Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c\n'}, {'number': 2, 'created': '2017-02-28 16:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/561f74d8b1662344c072db7141239759a127ecc8', 'message': 'Add py35 tox environment\n\nChange-Id: Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c\n'}, {'number': 3, 'created': '2017-02-28 16:47:15.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/37d43c7c73fcdfdcd303246f0e098c5ae0e717f7', 'message': 'Use py35 tox environment by default\n\nChange-Id: Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c\n'}]",2,438799,37d43c7c73fcdfdcd303246f0e098c5ae0e717f7,14,4,3,1179,,,0,"Use py35 tox environment by default

Change-Id: Ieb54b0b38f04a3502cf08206f1ce036fe2cb671c
",git fetch https://review.opendev.org/openstack/pyeclib refs/changes/99/438799/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,735c81be929024f31a79e091530cf67efd5fedc1,py35,"envlist = py27,py34,py35,pep8","envlist = py27,py34,pep8",1,1
openstack%2Fswift~master~I007425301914144e228b9cfece5533443e851b6e,openstack/swift,master,I007425301914144e228b9cfece5533443e851b6e,Always set swift processes to use UTC,MERGED,2016-06-17 22:33:17.000000000,2017-03-01 00:10:44.000000000,2017-03-01 00:10:43.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 12279}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 21231}]","[{'number': 1, 'created': '2016-06-17 22:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e8b58b36d470bd622cb7f6aea3be9afc7aec159d', 'message': 'Always set swift processes to use UTC\n\nPreviously, we would set the TZ environment variable to the result of\n\n    time.strftime(""%z"", time.gmtime())\n\nThis has a few problems.\n\n 1. The ""%z"" format  does not appear in the table of formatting\n    directives for strftime [1]. While it *does* appear in a\n    footnote [2] for that section, it is described as ""not supported by\n    all ANSI C libraries."" This may explain the next point.\n\n 2. On the handful of Linux platforms I\'ve tested, the above produces\n    ""+0000"" regardless of the system\'s timezone. This seems to run\n    counter to the intent of the patches that introduced the TZ\n    mangling. (See related changes.)\n\n 3. The above does not produce a valid Posix TZ format, which expects\n    (at minimum) a name consisting of three or more alphabetic\n    characters followed by the offset to be added to the local time to\n    get Coordinated Universal Time (UTC).\n\nFurther, while we would change os.environ[\'TZ\'], we would *not* call\ntime.tzset [3], which seems like a Bad Thing\n\nSome combination of the above has the net effect of changing some of the\nfunctions in the time module to use UTC. (Maybe all of them? At the very\nleast, time.localtime and time.mktime.) However, it does *not* change\nthe offset stored in time.timezone, which causes bad behavior when\ndealing with local timestamps [4].\n\nNow, set TZ to ""UTC+0"" and call tzset. Apparently we don\'t have a good\nway of getting local timezone info, we were (unintentionally?) using UTC\nbefore, and you should probably be running your servers in UTC anyway.\n\n[1] https://docs.python.org/2/library/time.html#time.strftime\n[2] https://docs.python.org/2/library/time.html#id2\n[3] https://docs.python.org/2/library/time.html#time.tzset\n[4] Like in email.utils.mktime_tz, prior to being fixed in\n    https://hg.python.org/cpython/rev/a283563c8cc4\n\nChange-Id: I007425301914144e228b9cfece5533443e851b6e\nRelated-Change: Ifc78236a99ed193a42389e383d062b38f57a5a31\nRelated-Change: I8ec80202789707f723abfe93ccc9cf1e677e4dc6\n'}, {'number': 2, 'created': '2016-09-16 02:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5b23f2ac439511a30900f4043a1b1a04401246ff', 'message': 'Always set swift processes to use UTC\n\nPreviously, we would set the TZ environment variable to the result of\n\n    time.strftime(""%z"", time.gmtime())\n\nThis has a few problems.\n\n 1. The ""%z"" format does not appear in the table of formatting\n    directives for strftime [1]. While it *does* appear in a\n    footnote [2] for that section, it is described as ""not supported by\n    all ANSI C libraries."" This may explain the next point.\n\n 2. On the handful of Linux platforms I\'ve tested, the above produces\n    ""+0000"" regardless of the system\'s timezone. This seems to run\n    counter to the intent of the patches that introduced the TZ\n    mangling. (See the first two related changes.)\n\n 3. The above does not produce a valid Posix TZ format, which expects\n    (at minimum) a name consisting of three or more alphabetic\n    characters followed by the offset to be added to the local time to\n    get Coordinated Universal Time (UTC).\n\nFurther, while we would change os.environ[\'TZ\'], we would *not* call\ntime.tzset like it says in the docs [3], which seems like a Bad Thing.\n\nSome combination of the above has the net effect of changing some of the\nfunctions in the time module to use UTC. (Maybe all of them? At the very\nleast, time.localtime and time.mktime.) However, it does *not* change\nthe offset stored in time.timezone, which causes bad behavior when\ndealing with local timestamps [4].\n\nNow, set TZ to ""UTC+0"" and call tzset. Apparently we don\'t have a good\nway of getting local timezone info, we were (unintentionally?) using UTC\nbefore, and you should probably be running your servers in UTC anyway.\n\n[1] https://docs.python.org/2/library/time.html#time.strftime\n[2] https://docs.python.org/2/library/time.html#id2\n[3] https://docs.python.org/2/library/time.html#time.tzset\n[4] Like in email.utils.mktime_tz, prior to being fixed in\n    https://hg.python.org/cpython/rev/a283563c8cc4\n\nChange-Id: I007425301914144e228b9cfece5533443e851b6e\nRelated-Change: Ifc78236a99ed193a42389e383d062b38f57a5a31\nRelated-Change: I8ec80202789707f723abfe93ccc9cf1e677e4dc6\nRelated-Change: Iee7488d03ab404072d3d0c1a262f004bb0f2da26\n'}, {'number': 3, 'created': '2016-11-07 20:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f371376fa79475505d57367ca55dc53366f30367', 'message': 'Always set swift processes to use UTC\n\nPreviously, we would set the TZ environment variable to the result of\n\n    time.strftime(""%z"", time.gmtime())\n\nThis has a few problems.\n\n 1. The ""%z"" format does not appear in the table of formatting\n    directives for strftime [1]. While it *does* appear in a\n    footnote [2] for that section, it is described as ""not supported by\n    all ANSI C libraries."" This may explain the next point.\n\n 2. On the handful of Linux platforms I\'ve tested, the above produces\n    ""+0000"" regardless of the system\'s timezone. This seems to run\n    counter to the intent of the patches that introduced the TZ\n    mangling. (See the first two related changes.)\n\n 3. The above does not produce a valid Posix TZ format, which expects\n    (at minimum) a name consisting of three or more alphabetic\n    characters followed by the offset to be added to the local time to\n    get Coordinated Universal Time (UTC).\n\nFurther, while we would change os.environ[\'TZ\'], we would *not* call\ntime.tzset like it says in the docs [3], which seems like a Bad Thing.\n\nSome combination of the above has the net effect of changing some of the\nfunctions in the time module to use UTC. (Maybe all of them? At the very\nleast, time.localtime and time.mktime.) However, it does *not* change\nthe offset stored in time.timezone, which causes bad behavior when\ndealing with local timestamps [4].\n\nNow, set TZ to ""UTC+0"" and call tzset. Apparently we don\'t have a good\nway of getting local timezone info, we were (unintentionally?) using UTC\nbefore, and you should probably be running your servers in UTC anyway.\n\n[1] https://docs.python.org/2/library/time.html#time.strftime\n[2] https://docs.python.org/2/library/time.html#id2\n[3] https://docs.python.org/2/library/time.html#time.tzset\n[4] Like in email.utils.mktime_tz, prior to being fixed in\n    https://hg.python.org/cpython/rev/a283563c8cc4\n\nChange-Id: I007425301914144e228b9cfece5533443e851b6e\nRelated-Change: Ifc78236a99ed193a42389e383d062b38f57a5a31\nRelated-Change: I8ec80202789707f723abfe93ccc9cf1e677e4dc6\nRelated-Change: Iee7488d03ab404072d3d0c1a262f004bb0f2da26\n'}, {'number': 4, 'created': '2016-12-20 00:23:27.000000000', 'files': ['swift/common/daemon.py', 'swift/common/wsgi.py', 'test/unit/common/test_daemon.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/523bc0ab71a4d976782a03c2beb46e5e8a25706b', 'message': 'Always set swift processes to use UTC\n\nPreviously, we would set the TZ environment variable to the result of\n\n    time.strftime(""%z"", time.gmtime())\n\nThis has a few problems.\n\n 1. The ""%z"" format does not appear in the table of formatting\n    directives for strftime [1]. While it *does* appear in a\n    footnote [2] for that section, it is described as ""not supported by\n    all ANSI C libraries."" This may explain the next point.\n\n 2. On the handful of Linux platforms I\'ve tested, the above produces\n    ""+0000"" regardless of the system\'s timezone. This seems to run\n    counter to the intent of the patches that introduced the TZ\n    mangling. (See the first two related changes.)\n\n 3. The above does not produce a valid Posix TZ format, which expects\n    (at minimum) a name consisting of three or more alphabetic\n    characters followed by the offset to be added to the local time to\n    get Coordinated Universal Time (UTC).\n\nFurther, while we would change os.environ[\'TZ\'], we would *not* call\ntime.tzset like it says in the docs [3], which seems like a Bad Thing.\n\nSome combination of the above has the net effect of changing some of the\nfunctions in the time module to use UTC. (Maybe all of them? At the very\nleast, time.localtime and time.mktime.) However, it does *not* change\nthe offset stored in time.timezone, which causes bad behavior when\ndealing with local timestamps [4].\n\nNow, set TZ to ""UTC+0"" and call tzset. Apparently we don\'t have a good\nway of getting local timezone info, we were (unintentionally?) using UTC\nbefore, and you should probably be running your servers in UTC anyway.\n\n[1] https://docs.python.org/2/library/time.html#time.strftime\n[2] https://docs.python.org/2/library/time.html#id2\n[3] https://docs.python.org/2/library/time.html#time.tzset\n[4] Like in email.utils.mktime_tz, prior to being fixed in\n    https://hg.python.org/cpython/rev/a283563c8cc4\n\nChange-Id: I007425301914144e228b9cfece5533443e851b6e\nRelated-Change: Ifc78236a99ed193a42389e383d062b38f57a5a31\nRelated-Change: I8ec80202789707f723abfe93ccc9cf1e677e4dc6\nRelated-Change: Iee7488d03ab404072d3d0c1a262f004bb0f2da26\n'}]",4,331369,523bc0ab71a4d976782a03c2beb46e5e8a25706b,26,7,4,15343,,,0,"Always set swift processes to use UTC

Previously, we would set the TZ environment variable to the result of

    time.strftime(""%z"", time.gmtime())

This has a few problems.

 1. The ""%z"" format does not appear in the table of formatting
    directives for strftime [1]. While it *does* appear in a
    footnote [2] for that section, it is described as ""not supported by
    all ANSI C libraries."" This may explain the next point.

 2. On the handful of Linux platforms I've tested, the above produces
    ""+0000"" regardless of the system's timezone. This seems to run
    counter to the intent of the patches that introduced the TZ
    mangling. (See the first two related changes.)

 3. The above does not produce a valid Posix TZ format, which expects
    (at minimum) a name consisting of three or more alphabetic
    characters followed by the offset to be added to the local time to
    get Coordinated Universal Time (UTC).

Further, while we would change os.environ['TZ'], we would *not* call
time.tzset like it says in the docs [3], which seems like a Bad Thing.

Some combination of the above has the net effect of changing some of the
functions in the time module to use UTC. (Maybe all of them? At the very
least, time.localtime and time.mktime.) However, it does *not* change
the offset stored in time.timezone, which causes bad behavior when
dealing with local timestamps [4].

Now, set TZ to ""UTC+0"" and call tzset. Apparently we don't have a good
way of getting local timezone info, we were (unintentionally?) using UTC
before, and you should probably be running your servers in UTC anyway.

[1] https://docs.python.org/2/library/time.html#time.strftime
[2] https://docs.python.org/2/library/time.html#id2
[3] https://docs.python.org/2/library/time.html#time.tzset
[4] Like in email.utils.mktime_tz, prior to being fixed in
    https://hg.python.org/cpython/rev/a283563c8cc4

Change-Id: I007425301914144e228b9cfece5533443e851b6e
Related-Change: Ifc78236a99ed193a42389e383d062b38f57a5a31
Related-Change: I8ec80202789707f723abfe93ccc9cf1e677e4dc6
Related-Change: Iee7488d03ab404072d3d0c1a262f004bb0f2da26
",git fetch https://review.opendev.org/openstack/swift refs/changes/69/331369/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/daemon.py', 'swift/common/wsgi.py', 'test/unit/common/test_daemon.py', 'test/unit/common/test_wsgi.py']",4,e8b58b36d470bd622cb7f6aea3be9afc7aec159d,331369," with mock.patch('time.tzset') as mock_tzset: conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assertEqual(os.environ['TZ'], 'UTC+0') self.assertEqual(mock_tzset.mock_calls, [mock.call()])"," conf = wsgi.appconfig(conf_dir) logger = logging.getLogger('test') sock = listen(('localhost', 0)) wsgi.run_server(conf, logger, sock) self.assertTrue(os.environ['TZ'] is not '')",21,18
openstack%2Ftap-as-a-service~master~I3959f953431149bbc8821e9ea9788278bc49c425,openstack/tap-as-a-service,master,I3959f953431149bbc8821e9ea9788278bc49c425,tempest: Switch to our own copy of manager.py,ABANDONED,2017-02-28 23:39:57.000000000,2017-03-01 00:08:21.000000000,,[],"[{'number': 1, 'created': '2017-02-28 23:39:57.000000000', 'files': ['neutron_taas/tests/tempest_plugin/tests/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/eaed5f9559edec5840f82600fb7ca8d4afe423af', 'message': 'tempest: Switch to our own copy of manager.py\n\nChange-Id: I3959f953431149bbc8821e9ea9788278bc49c425\n'}]",0,439239,eaed5f9559edec5840f82600fb7ca8d4afe423af,2,0,1,6854,,,0,"tempest: Switch to our own copy of manager.py

Change-Id: I3959f953431149bbc8821e9ea9788278bc49c425
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/39/439239/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_taas/tests/tempest_plugin/tests/scenario/base.py'],1,eaed5f9559edec5840f82600fb7ca8d4afe423af,tempest-manager,from neutron_taas.tests.tempest_plugin.tests.scenario import manager,from tempest.scenario import manager,1,1
openstack%2Fopenstack-ansible~master~Ib85ae24ee50513c02cd32f09b0bf48b95aab20dc,openstack/openstack-ansible,master,Ib85ae24ee50513c02cd32f09b0bf48b95aab20dc,Update keystone SHA to support db_sync check,MERGED,2017-02-28 19:21:21.000000000,2017-02-28 23:58:29.000000000,2017-02-28 23:58:29.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 19:21:21.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/448b9ce5360b60bced19ec49b24e6ed783d5a9eb', 'message': 'Update keystone SHA to support db_sync check\n\nIn https://review.openstack.org/432134 we added support\nfor more specific reactions to the db sync check, but\nthe current SHA we have for keystone does not include\nfixes for a new deployment.\n\nThis updates the keystone SHA to include that support.\n\nChange-Id: Ib85ae24ee50513c02cd32f09b0bf48b95aab20dc\n'}]",0,439123,448b9ce5360b60bced19ec49b24e6ed783d5a9eb,8,3,1,6816,,,0,"Update keystone SHA to support db_sync check

In https://review.openstack.org/432134 we added support
for more specific reactions to the db sync check, but
the current SHA we have for keystone does not include
fixes for a new deployment.

This updates the keystone SHA to include that support.

Change-Id: Ib85ae24ee50513c02cd32f09b0bf48b95aab20dc
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/23/439123/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,448b9ce5360b60bced19ec49b24e6ed783d5a9eb,,"keystone_git_install_branch: 66c8612fb120134477ff26e42150599d168e93bf # HEAD of ""master"" as of 24.02.2017","keystone_git_install_branch: 9c474958b16ca1775fd1f1c09b870817708d1ea2 # HEAD of ""master"" as of 15.02.2017",1,1
openstack%2Ftripleo-heat-templates~master~I965f0ec21075cd540de061ec96a52dd919762368,openstack/tripleo-heat-templates,master,I965f0ec21075cd540de061ec96a52dd919762368,Temporary UCSM mapping files should be opened with write mode,MERGED,2016-10-25 15:19:30.000000000,2017-02-28 23:47:00.000000000,2017-02-02 13:32:49.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6928}, {'_account_id': 10068}]","[{'number': 1, 'created': '2016-10-25 15:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3ef491405212d6b4ca46f4f6576fc9ac9681699c', 'message': 'Opening tepmorary ucsm mapping files with write mode instead of append mode\n\nChange-Id: I965f0ec21075cd540de061ec96a52dd919762368\nCloses-Bug: #1636542\nSigned-off-by: krogon-intel <kamil.rogon@intel.com>\n'}, {'number': 2, 'created': '2016-10-25 15:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6551142afdf3701e92323a7f9983011967db2e43', 'message': 'Temporary UCSM mapping files should be opened with write mode\n\nChange-Id: I965f0ec21075cd540de061ec96a52dd919762368\nCloses-Bug: #1636542\nSigned-off-by: krogon-intel <kamil.rogon@intel.com>\n'}, {'number': 3, 'created': '2016-11-08 13:47:56.000000000', 'files': ['puppet/extraconfig/all_nodes/neutron-ml2-cisco-nexus-ucsm.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b0f964d5475d21e7778e1ff5c2007b45383b5619', 'message': 'Temporary UCSM mapping files should be opened with write mode\n\nChange-Id: I965f0ec21075cd540de061ec96a52dd919762368\nCloses-Bug: #1636542\nSigned-off-by: krogon-intel <kamil.rogon@intel.com>\n'}]",1,390591,b0f964d5475d21e7778e1ff5c2007b45383b5619,17,5,3,14545,,,0,"Temporary UCSM mapping files should be opened with write mode

Change-Id: I965f0ec21075cd540de061ec96a52dd919762368
Closes-Bug: #1636542
Signed-off-by: krogon-intel <kamil.rogon@intel.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/390591/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet/extraconfig/all_nodes/neutron-ml2-cisco-nexus-ucsm.yaml'],1,3ef491405212d6b4ca46f4f6576fc9ac9681699c,bug/1636542," with open(f_name, 'w') as f: with open('/root/mac2host', 'w') as f:"," with open(f_name, 'a') as f: with open('/root/mac2host', 'a') as f:",2,2
openstack%2Fpuppet-tacker~master~I89a27880a04eefb1bcdd79368c9eb19a16a81a10,openstack/puppet-tacker,master,I89a27880a04eefb1bcdd79368c9eb19a16a81a10,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:19:16.000000000,2017-02-28 23:40:12.000000000,2017-02-28 23:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tacker/commit/99bdf6419906debfc8a5d30f89a315e4b5aa8dda', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I89a27880a04eefb1bcdd79368c9eb19a16a81a10\n'}, {'number': 2, 'created': '2017-02-28 17:12:21.000000000', 'files': ['spec/classes/tacker_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tacker/commit/8fd07664abbb40860e1a7d88babb7ed809d7645c', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I89a27880a04eefb1bcdd79368c9eb19a16a81a10\n'}]",0,439011,8fd07664abbb40860e1a7d88babb7ed809d7645c,9,2,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: I89a27880a04eefb1bcdd79368c9eb19a16a81a10
",git fetch https://review.opendev.org/openstack/puppet-tacker refs/changes/11/439011/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/tacker_init_spec.rb'],1,99bdf6419906debfc8a5d30f89a315e4b5aa8dda,remove-rpc_backend,, is_expected.to contain_tacker_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Fmolteniron~master~Ie0d6d1184976bd17adc8816aad586d7acac463f8,openstack/molteniron,master,Ie0d6d1184976bd17adc8816aad586d7acac463f8,Add ansible playbook example for a molteniron server,MERGED,2017-01-17 00:10:43.000000000,2017-02-28 23:35:48.000000000,2017-02-28 23:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 11929}]","[{'number': 1, 'created': '2017-01-17 00:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/97d97c24aa3ddb89869f8a5e1b36bdb4e3f588bb', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}, {'number': 2, 'created': '2017-01-17 15:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/7bb8d16597161a323e46deccc9884acdb7763df8', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}, {'number': 3, 'created': '2017-01-17 20:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/f00845e7c6dabd56aabdcb0f27bd07bba4230f33', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}, {'number': 4, 'created': '2017-01-17 21:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/3a546e30a2623874d71b9b41fa06727715976b40', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}, {'number': 5, 'created': '2017-01-18 19:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/5537fe8b4f351fdf2932e70b3b5b5b48bb64ad94', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}, {'number': 6, 'created': '2017-02-28 21:22:15.000000000', 'files': ['utils/molteniron-playbook.yml'], 'web_link': 'https://opendev.org/openstack/molteniron/commit/a271f09ef1bda17545d8703a49eb65459afec232', 'message': 'Add ansible playbook example for a molteniron server\n\nChange-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8\n'}]",4,421001,a271f09ef1bda17545d8703a49eb65459afec232,17,2,6,18242,,,0,"Add ansible playbook example for a molteniron server

Change-Id: Ie0d6d1184976bd17adc8816aad586d7acac463f8
",git fetch https://review.opendev.org/openstack/molteniron refs/changes/01/421001/3 && git format-patch -1 --stdout FETCH_HEAD,['utils/molteniron-playbook.yml'],1,97d97c24aa3ddb89869f8a5e1b36bdb4e3f588bb,add_molteniron_playbook,"# Copyright (c) 2017 IBM Corporation. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # # Example commands to configure the ansible controller: # # ubuntu@hamzy-dev:~$ cat << __EOF__ | sudo tee -a /etc/ansible/hosts # # @BEGIN # 9.114.111.114 # hamzy-test ansible_host=9.114.111.114 # # [molteniron] # hamzy-test # # @END # __EOF__ # ubuntu@hamzy-dev:~$ ansible molteniron -m ping # hamzy-test | SUCCESS => { # ""changed"": false, # ""ping"": ""pong"" # } # # Remember to add the controller's public ssh key to: # ubuntu@9.114.111.114/24:/home/ubuntu/.ssh/authorized_keys # # Example command to deploy a molteniron server on a fresh install of # Ubuntu 16.04: # # ubuntu@hamzy-dev:~$ ansible-playbook molteniron-playbook.yml -f 10 # --- - name: deploy molteniron server hosts: molteniron strategy: debug gather_facts: yes become: true become_user: root become_method: 'sudo' tasks: - name: install base packages apt: pkg={{item}} state=present update_cache=yes cache_valid_time=604800 with_items: - sysstat - build-essential - python-dev - python3-dev - libmysqlclient-dev - tox - python2.7 - python3.5 - python-pip - python-mysqldb - mysql-server - name: start mysql server service: name=mysql state=started enabled=yes - name: instal molteniron source code from git git: repo=git://git.openstack.org/openstack/molteniron.git dest=/home/ubuntu/molteniron version=HEAD - name: pip install molteniron from git repository shell: pip install -U --force-reinstall -r requirements.txt > pip_install.log 2>&1 args: chdir: /home/ubuntu/molteniron creates: /home/ubuntu/molteniron/pip_install.log - name: python install molteniron from git repository shell: python setup.py install > python_install.log 2>&1 args: chdir: /home/ubuntu/molteniron creates: /home/ubuntu/molteniron/python_install.log - name: authorize openstack_citest MYSQL access mysql_user: login_user=root login_password="""" check_implicit_admin=yes name=openstack_citest password=openstack_citest priv=""*.*:ALL,GRANT"" state=present # @TODO(hamzy) handle case where server is already running - name: start molteniron server shell: moltenirond-helper start - name: run the molteniron status command shell: molteniron --output=result status --type=human ",,95,0
openstack%2Fpuppet-aodh~master~I45209060dc2726cdb7e69450126d7ab242aaddf3,openstack/puppet-aodh,master,I45209060dc2726cdb7e69450126d7ab242aaddf3,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:12:18.000000000,2017-02-28 23:31:45.000000000,2017-02-28 23:31:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}]","[{'number': 1, 'created': '2017-02-28 15:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/a2a111547b919b420af711d19e81642c9d75b58a', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I45209060dc2726cdb7e69450126d7ab242aaddf3\n'}, {'number': 2, 'created': '2017-02-28 17:10:27.000000000', 'files': ['spec/classes/aodh_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/f394d4e29832c82bee4e6cec46a7bc5055d14c30', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I45209060dc2726cdb7e69450126d7ab242aaddf3\n'}]",0,438995,f394d4e29832c82bee4e6cec46a7bc5055d14c30,11,3,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: I45209060dc2726cdb7e69450126d7ab242aaddf3
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/95/438995/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/aodh_init_spec.rb'],1,a2a111547b919b420af711d19e81642c9d75b58a,remove-rpc_backend,, is_expected.to contain_aodh_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Fopenstack-ansible-pip_install~master~I3e127a4451a0ab47588a213e9721bc2f36b12387,openstack/openstack-ansible-pip_install,master,I3e127a4451a0ab47588a213e9721bc2f36b12387,Optimize pip_install,MERGED,2017-02-28 17:52:50.000000000,2017-02-28 23:27:57.000000000,2017-02-28 23:27:57.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-28 17:52:50.000000000', 'files': ['tasks/pre_install.yml', 'tasks/pre_install_yum.yml', 'tasks/install.yml', 'tasks/pre_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/badf50295112a7d962adf648d8f650a4729feb19', 'message': 'Optimize pip_install\n\nThis patch optimizes the pip_install tasks to avoid lots of skipped\ntasks. This role is run *many* times during the integrated gate and\nadds a signficant amount of time to gate jobs.\n\nInstalling the RDO RPM still takes quite a bit of time (~ 6min) in\nthe integrated build, so further optimization is needed.\n\nChange-Id: I3e127a4451a0ab47588a213e9721bc2f36b12387\n'}]",0,439078,badf50295112a7d962adf648d8f650a4729feb19,7,3,1,538,,,0,"Optimize pip_install

This patch optimizes the pip_install tasks to avoid lots of skipped
tasks. This role is run *many* times during the integrated gate and
adds a signficant amount of time to gate jobs.

Installing the RDO RPM still takes quite a bit of time (~ 6min) in
the integrated build, so further optimization is needed.

Change-Id: I3e127a4451a0ab47588a213e9721bc2f36b12387
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/78/439078/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/pre_install.yml', 'tasks/pre_install_yum.yml', 'tasks/install.yml', 'tasks/pre_install_apt.yml']",4,badf50295112a7d962adf648d8f650a4729feb19,optimize_skipping,"--- # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Ensure apt cache is up to date apt: update_cache: yes cache_valid_time: ""{{ cache_timeout }}"" # Under Ubuntu, this will only add the key - name: Install external repo key with package apt: name: ""{{ pip_install_external_repo_key_package }}"" state: ""{{ pip_install_external_repo_key_package_state | default('present') }}"" when: - user_external_repo_key is not defined tags: - add-repo-keys - name: Install repo for distro binaries apt_repository: repo: ""{{ uca_repo }}"" state: present update_cache: yes filename: ""{{ uca_apt_source_list_filename | default(omit) }}"" register: uca_add_repo until: uca_add_repo|success retries: 5 delay: 2 when: - uca_enable tags: - add-uca-repo - name: Install external repo key manually (apt) apt_key: id: ""{{ item.id | default(omit) }}"" keyserver: ""{{ item.keyserver | default(omit) }}"" url: ""{{ item.url | default(omit) }}"" state: ""{{ item.state | default('present') }}"" register: add_keys until: add_keys|success retries: 5 delay: 2 with_items: ""{{ user_external_repo_keys_list }}"" when: - user_external_repo_keys_list is defined tags: - add-repo-keys - name: Install external repo manually (apt) apt_repository: repo: ""{{ item.repo }}"" state: ""{{ item.state | default('present') }}"" update_cache: yes filename: ""{{ item.filename | default(omit) }}"" register: use_external_repo_apt until: use_external_repo_apt|success retries: 5 delay: 2 with_items: ""{{ user_external_repos_list }}"" when: - user_external_repos_list is defined tags: - add-external-repo ",,135,111
openstack%2Ftempest~master~Ifbb3403cc68cf0ea4bd1f84e5972c74598c8d329,openstack/tempest,master,Ifbb3403cc68cf0ea4bd1f84e5972c74598c8d329,Remove unnecessary show_server in TestServerAdvancedOps,MERGED,2017-02-22 09:31:30.000000000,2017-02-28 23:22:03.000000000,2017-02-28 23:22:03.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 8556}]","[{'number': 1, 'created': '2017-02-22 09:31:30.000000000', 'files': ['tempest/scenario/test_server_advanced_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/96daca7133bc0288a337946a5bec6e23ca8f5567', 'message': ""Remove unnecessary show_server in TestServerAdvancedOps\n\nIn test_server_sequence_suspend_resume, show_server follows\nwait_for_server_status which is meaningless, because in\nwait_for_server_status if server didn't reach the expected\nstate, an exception will be raised.\n\nThis is to remove the unnecessary show_server and rearrange\nthe code so it can look clearer.\n\nChange-Id: Ifbb3403cc68cf0ea4bd1f84e5972c74598c8d329\n""}]",6,436842,96daca7133bc0288a337946a5bec6e23ca8f5567,27,3,1,20190,,,0,"Remove unnecessary show_server in TestServerAdvancedOps

In test_server_sequence_suspend_resume, show_server follows
wait_for_server_status which is meaningless, because in
wait_for_server_status if server didn't reach the expected
state, an exception will be raised.

This is to remove the unnecessary show_server and rearrange
the code so it can look clearer.

Change-Id: Ifbb3403cc68cf0ea4bd1f84e5972c74598c8d329
",git fetch https://review.opendev.org/openstack/tempest refs/changes/42/436842/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_server_advanced_ops.py'],1,96daca7133bc0288a337946a5bec6e23ca8f5567,simplify_code," instance_id = self.create_server()['id'] for _ in range(2): LOG.debug(""Suspending instance %s"", instance_id) self.servers_client.suspend_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'SUSPENDED') LOG.debug(""Resuming instance %s"", instance_id) self.servers_client.resume_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'ACTIVE')"," instance = self.create_server() instance_id = instance['id'] LOG.debug(""Suspending instance %s. Current status: %s"", instance_id, instance['status']) self.servers_client.suspend_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'SUSPENDED') fetched_instance = (self.servers_client.show_server(instance_id) ['server']) LOG.debug(""Resuming instance %s. Current status: %s"", instance_id, fetched_instance['status']) self.servers_client.resume_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'ACTIVE') fetched_instance = (self.servers_client.show_server(instance_id) ['server']) LOG.debug(""Suspending instance %s. Current status: %s"", instance_id, fetched_instance['status']) self.servers_client.suspend_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'SUSPENDED') fetched_instance = (self.servers_client.show_server(instance_id) ['server']) LOG.debug(""Resuming instance %s. Current status: %s"", instance_id, fetched_instance['status']) self.servers_client.resume_server(instance_id) waiters.wait_for_server_status(self.servers_client, instance_id, 'ACTIVE')",12,28
openstack%2Fbarbican~master~I1207c5dcf38c66d6f48e27c41853f62fd5f57f7c,openstack/barbican,master,I1207c5dcf38c66d6f48e27c41853f62fd5f57f7c,Change misc to test_utils in tempest test,ABANDONED,2017-02-10 02:05:39.000000000,2017-02-28 23:16:11.000000000,,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-10 02:05:39.000000000', 'files': ['functionaltests/common/client.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/77bad37d33d1be7886f5edb066be8feb2c880198', 'message': 'Change misc to test_utils in tempest test\n\ntempest.lib.common.utils.misc.find_test_caller has been moved into\nthe tempest.lib.common.utils.test_utils module. Calling the\nfind_test_caller function with its old location is deprecated.\n\nChange-Id: I1207c5dcf38c66d6f48e27c41853f62fd5f57f7c\n'}]",0,431808,77bad37d33d1be7886f5edb066be8feb2c880198,6,3,1,15054,,,0,"Change misc to test_utils in tempest test

tempest.lib.common.utils.misc.find_test_caller has been moved into
the tempest.lib.common.utils.test_utils module. Calling the
find_test_caller function with its old location is deprecated.

Change-Id: I1207c5dcf38c66d6f48e27c41853f62fd5f57f7c
",git fetch https://review.opendev.org/openstack/barbican refs/changes/08/431808/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/common/client.py'],1,77bad37d33d1be7886f5edb066be8feb2c880198,move_misc,from tempest.lib.common.utils import test_utils test_name = test_utils.find_test_caller(),from tempest.lib.common.utils import misc as misc_utils test_name = misc_utils.find_test_caller(),2,2
openstack%2Frequirements~master~I6979a1089bdce84d8f9b0fd9322000a5d45a493a,openstack/requirements,master,I6979a1089bdce84d8f9b0fd9322000a5d45a493a,Bump oslo.middleware,MERGED,2017-02-28 16:41:13.000000000,2017-02-28 23:14:23.000000000,2017-02-28 23:14:23.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 11904}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-28 16:41:13.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a05d3e1c358bb6035f482d4d0f61225222ebb256', 'message': 'Bump oslo.middleware\n\nThe 3.10.0 release of oslo.middleware introduced a new method for cors,\nset_defaults, which allows the setting of defaults more easily.\n\nAt least two projects trying to take advantage of this feature:\nBarbican: https://review.openstack.org/#/c/394064/1\nCinder: https://review.openstack.org/#/c/393577/15\n\nChange-Id: I6979a1089bdce84d8f9b0fd9322000a5d45a493a\n'}]",0,439051,a05d3e1c358bb6035f482d4d0f61225222ebb256,8,4,1,8623,,,0,"Bump oslo.middleware

The 3.10.0 release of oslo.middleware introduced a new method for cors,
set_defaults, which allows the setting of defaults more easily.

At least two projects trying to take advantage of this feature:
Barbican: https://review.openstack.org/#/c/394064/1
Cinder: https://review.openstack.org/#/c/393577/15

Change-Id: I6979a1089bdce84d8f9b0fd9322000a5d45a493a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/439051/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,a05d3e1c358bb6035f482d4d0f61225222ebb256,oslo.middleware,oslo.middleware>=3.10.0 # Apache-2.0,oslo.middleware>=3.0.0 # Apache-2.0,1,1
openstack%2Ftempest~master~Ide11a7434a4714e5d2211af1803333535f557370,openstack/tempest,master,Ide11a7434a4714e5d2211af1803333535f557370,Remove call_until_true from test module,MERGED,2017-02-09 18:28:47.000000000,2017-02-28 23:13:34.000000000,2017-02-28 23:13:34.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 3153}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 6854}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-09 18:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/651653335cc593ae971b1d9f1ee86cd133563199', 'message': ""WIP: Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}, {'number': 2, 'created': '2017-02-10 17:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d8f7dc02e47b8d2af5a1e63f85ebad2898f0a75c', 'message': ""Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nNOTE: To avoid continuous puppet job failures, this patch depends\n      on the corresponding neutron-fwaas patch.\n\nDepends-On: I75d289f27d4e5e02243150dfaca08824d9e5aafa\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}, {'number': 3, 'created': '2017-02-10 22:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/12f18cb343979f27a33c275cf1a45a95b3654e93', 'message': ""Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nNOTE: To avoid continuous puppet job failures, this patch depends\n      on the corresponding neutron-fwaas patch.\n\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}, {'number': 4, 'created': '2017-02-20 14:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bfe8663dbc7da8c4fb87e74fe7060caf7ebc4582', 'message': ""Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nNOTE: To avoid continuous puppet job failures, this patch depends\n      on the corresponding neutron-fwaas patch.\n\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}, {'number': 5, 'created': '2017-02-20 16:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3f640ab523e9d3a84cec7d5b7fc8c483629e0817', 'message': ""Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nNOTE: To avoid continuous puppet job failures, this patch depends\n      on the corresponding neutron-fwaas patch.\n\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}, {'number': 6, 'created': '2017-02-22 15:51:33.000000000', 'files': ['releasenotes/notes/remove-call_until_true-of-test-de9c13bc8f969921.yaml', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f2ba23f7834facb2bfe7c376840e7630881d1bf9', 'message': ""Remove call_until_true from test module\n\nThe call_until_true of test module is marked as deprecated and\nwe have a plan to remove it in Ocata cycle.\nThis patch removes it after switching to use test_utils' one on\nall OpenStack projects.\n\nChange-Id: Ide11a7434a4714e5d2211af1803333535f557370\n""}]",2,431701,f2ba23f7834facb2bfe7c376840e7630881d1bf9,56,11,6,6167,,,0,"Remove call_until_true from test module

The call_until_true of test module is marked as deprecated and
we have a plan to remove it in Ocata cycle.
This patch removes it after switching to use test_utils' one on
all OpenStack projects.

Change-Id: Ide11a7434a4714e5d2211af1803333535f557370
",git fetch https://review.opendev.org/openstack/tempest refs/changes/01/431701/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,651653335cc593ae971b1d9f1ee86cd133563199,switch-call_until_true,,"from tempest.lib.common.utils import test_utils call_until_true = debtcollector.moves.moved_function( test_utils.call_until_true, 'call_until_true', __name__, version='Newton', removal_version='Ocata')",0,6
openstack%2Fproject-config~master~I92e6e6502c2c516babf2bf66f3514875f77c460e,openstack/project-config,master,I92e6e6502c2c516babf2bf66f3514875f77c460e,Remove final db setup,MERGED,2017-02-01 20:19:42.000000000,2017-02-28 23:12:14.000000000,2017-02-28 23:12:14.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-01 20:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ae537ffe4553bcfa45b349a7d83b518e8ce7d144', 'message': 'trove: Use normal python jobs\n\nThe repo now uses tools/test-setup.sh we do not need the db jobs\nanymore, change to the standard python unit jobs.\n\nAlso use standard pylint job-template which does the same as the tox\ntemplate.\n\nChange-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e\nDepends-On: I3463e75057d0d4544f6a0212da888759ab5e171b\n'}, {'number': 2, 'created': '2017-02-10 17:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a1c4a304b3d0aae4857d5189a3697f2c330756ce', 'message': 'trove: Use normal python jobs\n\nThe repo now uses tools/test-setup.sh we do not need the db jobs\nanymore, change to the standard python unit jobs.\n\nAlso use standard pylint job-template which does the same as the tox\ntemplate.\n\nChange-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e\nDepends-On: I3463e75057d0d4544f6a0212da888759ab5e171b\n'}, {'number': 3, 'created': '2017-02-10 17:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/04076b511df166d2d87bea6bba9ee052538d64d4', 'message': 'trove: Use normal python jobs\n\nThe repo now uses tools/test-setup.sh we do not need the db jobs\nanymore, change to the standard python unit jobs.\n\nAlso use standard pylint job-template which does the same as the tox\ntemplate.\n\nChange-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e\nDepends-On: I3463e75057d0d4544f6a0212da888759ab5e171b\n'}, {'number': 4, 'created': '2017-02-17 18:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/68d8d74422f9c773e266d7f6dc13e4dcd043910e', 'message': ""Remove final db setup\n\nThe trove repo now uses tools/test-setup.sh we do not need the db jobs\nanymore, change to the standard python unit jobs.\n\nAlso use standard pylint job-template which does the same as the tox\ntemplate.\n\nRemove all templates and job-groups for the db-jobs since it's last user\nhas been removed.\n\nOnly leave mysql setup jobs for bifrost in.\n\nChange-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e\nDepends-On: I3463e75057d0d4544f6a0212da888759ab5e171b\n""}, {'number': 5, 'created': '2017-02-28 08:10:19.000000000', 'files': ['jenkins/jobs/python-bitrot-jobs.yaml', 'jenkins/jobs/python-jobs.yaml', 'jenkins/jobs/projects.yaml', 'jenkins/jobs/macros.yaml', 'jenkins/jobs/neutron.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9fc2f0eda8ee68edb385010045b19100d70efbf1', 'message': ""Remove final db setup\n\nThe trove repo now uses tools/test-setup.sh we do not need the db jobs\nanymore, change to the standard python unit jobs.\n\nAlso use standard pylint job-template which does the same as the tox\ntemplate.\n\nRemove all templates and job-groups for the db-jobs since it's last user\nhas been removed.\n\nOnly leave mysql setup jobs for bifrost in.\n\nChange-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e\nDepends-On: I3463e75057d0d4544f6a0212da888759ab5e171b\n""}]",0,427895,9fc2f0eda8ee68edb385010045b19100d70efbf1,22,4,5,6547,,,0,"Remove final db setup

The trove repo now uses tools/test-setup.sh we do not need the db jobs
anymore, change to the standard python unit jobs.

Also use standard pylint job-template which does the same as the tox
template.

Remove all templates and job-groups for the db-jobs since it's last user
has been removed.

Only leave mysql setup jobs for bifrost in.

Change-Id: I92e6e6502c2c516babf2bf66f3514875f77c460e
Depends-On: I3463e75057d0d4544f6a0212da888759ab5e171b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/427895/4 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,ae537ffe4553bcfa45b349a7d83b518e8ce7d144,test-setup, - name: python-jobs - name: python35-jobs - name: periodic-mitaka - name: periodic-newton - gate-trove-tox-fakemodetests-ubuntu-xenial - gate-trove-tox-apiexamples-ubuntu-xenial - gate-trove-pylint-ubuntu-xenial - gate-trove-tox-fakemodetests-ubuntu-xenial - gate-trove-tox-apiexamples-ubuntu-xenial - gate-trove-pylint-ubuntu-xenial post: - trove-coverage-ubuntu-trusty - trove-coverage-ubuntu-xenial, - name: python-db-jobs - name: python35-db-jobs - name: periodic-db-mitaka - name: periodic-db-newton - gate-trove-tox-db-fakemodetests-ubuntu-xenial - gate-trove-tox-db-apiexamples-ubuntu-xenial - gate-trove-tox-pylint-ubuntu-xenial - gate-trove-tox-db-fakemodetests-ubuntu-xenial - gate-trove-tox-db-apiexamples-ubuntu-xenial - gate-trove-tox-pylint-ubuntu-xenial post: - trove-coverage-db-ubuntu-trusty - trove-coverage-db-ubuntu-xenial,18,20
openstack%2Fshade~master~I895fdea5a0164de48a12352ca1ae0be3b3af82e7,openstack/shade,master,I895fdea5a0164de48a12352ca1ae0be3b3af82e7,Partially revert floating ip wait change,ABANDONED,2017-02-28 23:00:08.000000000,2017-02-28 23:08:14.000000000,,[],"[{'number': 1, 'created': '2017-02-28 23:00:08.000000000', 'files': ['shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/bc2f09a064dee675197c26fd24479e56532520f6', 'message': ""Partially revert floating ip wait change\n\nThe tests found what seemed to be a logic error, which we then fixed.\nHowever, it's entirely possible that the tests did not, in fact, find a\nlogic error, and the fix broke the world.\n\nPartially reverts Ia38294cf48bcb46c18892605fd52da7dadaeefc8\n\nChange-Id: I895fdea5a0164de48a12352ca1ae0be3b3af82e7\n""}]",0,439202,bc2f09a064dee675197c26fd24479e56532520f6,2,0,1,2,,,0,"Partially revert floating ip wait change

The tests found what seemed to be a logic error, which we then fixed.
However, it's entirely possible that the tests did not, in fact, find a
logic error, and the fix broke the world.

Partially reverts Ia38294cf48bcb46c18892605fd52da7dadaeefc8

Change-Id: I895fdea5a0164de48a12352ca1ae0be3b3af82e7
",git fetch https://review.opendev.org/openstack/shade refs/changes/02/439202/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/openstackcloud.py'],1,bc2f09a064dee675197c26fd24479e56532520f6,,, # Wait for cache invalidation time so that we don't try # to attach the FIP a second time below time.sleep(self._SERVER_AGE) server = self.get_server(server.id),0,4
openstack%2Fsecurity-doc~master~I84caa0005d815e749154d0c3d7da07df6a1f1492,openstack/security-doc,master,I84caa0005d815e749154d0c3d7da07df6a1f1492,Updated from openstack-manuals,MERGED,2017-02-28 13:05:12.000000000,2017-02-28 23:05:39.000000000,2017-02-28 23:05:39.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-28 13:05:12.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/cf24e2754f802ba79908eec6d8838065d128796a', 'message': 'Updated from openstack-manuals\n\nChange-Id: I84caa0005d815e749154d0c3d7da07df6a1f1492\n'}]",0,438958,cf24e2754f802ba79908eec6d8838065d128796a,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I84caa0005d815e749154d0c3d7da07df6a1f1492
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/58/438958/1 && git format-patch -1 --stdout FETCH_HEAD,['common/source/locale/ja/LC_MESSAGES/common.po'],1,cf24e2754f802ba79908eec6d8838065d128796a,openstack/openstack-manuals,"""POT-Creation-Date: 2017-02-28 05:57+0000\n""""PO-Revision-Date: 2017-02-27 10:14+0000\n""msgid ""Get summary statistics for each project:"" msgstr """"""The OpenStack Object Storage is a multi-project object storage system. It is """"OpenStack Object Storage "" ""RESTful HTTP API "" """"""The procedure for volume transfer is intended for projects (both the volume """" () "" """"""projects.""""""","""POT-Creation-Date: 2017-02-27 00:08+0000\n""""PO-Revision-Date: 2017-02-24 10:10+0000\n""msgid ""Creates and manages Hadoop clusters on OpenStack."" msgstr ""OpenStack  Hadoop "" msgid ""Data Processing service"" msgstr ""Data Processing "" msgid ""Get summary statistics for each tenant:"" msgstr """"""OpenStack project that aims to provide a flexible and scalable resource "" ""optimization service for multi-tenant OpenStack-based clouds."" msgstr """" "" OpenStack "" "" OpenStack "" msgid """"""The OpenStack Object Storage is a multi-tenant object storage system. It is """"OpenStack Object Storage "" ""RESTful HTTP API "" """"""The OpenStack service that provides a multi-tenant, highly scalable, "" ""performant, fault-tolerant monitoring-as-a-service solution for metrics, "" ""complex event processing and logging. To build an extensible platform for "" ""advanced monitoring services that can be used by both operators and tenants "" ""to gain operational insight and visibility, ensuring availability and "" ""stability."" msgstr """" """" ""monitoring-as-a-service  OpenStack  "" "" (complex event processing)"" """" """" """" msgid """"""The procedure for volume transfer is intended for tenants (both the volume """" () "" """"""The project that facilitates API client authentication, service discovery, "" ""distributed multi-tenant authorization, and auditing. It provides a central "" ""directory of users mapped to the OpenStack services they can access. It also "" ""registers endpoints for OpenStack services and acts as a common "" ""authentication system."" msgstr """" ""API "" "" OpenStack "" ""OpenStack "" """" msgid """"""The service that provides a set of services for management of shared file "" ""systems in a multi-tenant cloud environment, similar to how OpenStack "" ""provides block-based storage management through the OpenStack :term:`Block "" ""Storage service<Block Storage service (cinder)>` project. With the Shared "" ""File Systems service, you can create a remote file system and mount the file "" ""system on your instances. You can also read and write data from your "" ""instances to and from your file system."" msgstr """" """" "" OpenStack  "" ""OpenStack :term:`Block Storage  <Block Storage service (cinder)>` "" "" Shared File Systems "" """" """" """" msgid """"""tenants.""""""msgid ""``sahara`` - Data Processing API"" msgstr ""``sahara`` - Data Processing API"" msgid ""python-saharaclient"" msgstr ""python-saharaclient"" ",13,76
openstack%2Fpatrole~master~I84358aa1e2a76c95a3e5e416770f3053faa2cf3f,openstack/patrole,master,I84358aa1e2a76c95a3e5e416770f3053faa2cf3f,Assisted Volume snapshot RBAC test for Compute v2.1 API roles,MERGED,2017-02-24 17:32:05.000000000,2017-02-28 23:01:31.000000000,2017-02-28 23:01:31.000000000,"[{'_account_id': 3}, {'_account_id': 17896}, {'_account_id': 20809}, {'_account_id': 23184}, {'_account_id': 23185}, {'_account_id': 23186}, {'_account_id': 24816}]","[{'number': 1, 'created': '2017-02-24 17:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/279aea47d1cde417ed5e55d7d17b1d18042d31f8', 'message': 'Assisted Volume snapshot RBAC test for Compute v2.1 API roles\n\n- migrated out common clients and internal methods to the base\n- fixes to projects rbac test to use tempest base instead\n- migrated volume assistend snapshot rbac tempest test to Patrole\n\nChange-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f\n'}, {'number': 2, 'created': '2017-02-27 20:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/d1ffedb190765ae443e693c9de9b628767df68ab', 'message': 'Assisted Volume snapshot RBAC test for Compute v2.1 API roles\n\n- migrated out common clients and internal methods to the base\n- fixes to projects rbac test to use tempest base instead\n- migrated volume assistend snapshot rbac tempest test to Patrole\n\nChange-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f\n'}, {'number': 3, 'created': '2017-02-27 21:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/2825e6ab28d821689f17187481860f6ec9c0fb47', 'message': 'Assisted Volume snapshot RBAC test for Compute v2.1 API roles\n\n- migrated out common clients and internal methods to the base\n- fixes to projects rbac test to use tempest base instead\n- migrated volume assistend snapshot rbac tempest test to Patrole\n\nNOTE: This requires a new API client in tempest/lib. A bug is added\nfor tracking and is used as a reason for skipping.\nhttps://bugs.launchpad.net/tempest/+bug/1668407\n\nChange-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f\n'}, {'number': 4, 'created': '2017-02-27 22:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/51e1a69937b5cc5513ef29e267bb285bf4dd812a', 'message': 'Assisted Volume snapshot RBAC test for Compute v2.1 API roles\n\n- migrated out common clients and internal methods to the base\n- fixes to projects rbac test to use tempest base instead\n- migrated volume assistend snapshot rbac tempest test to Patrole\n\nNOTE: This requires a new API client in tempest/lib. A bug is added\nfor tracking and is used as a reason for skipping.\nhttps://bugs.launchpad.net/tempest/+bug/1668407\n\nSome assistance provided by Rick Bartra!\n\nChange-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f\n'}, {'number': 5, 'created': '2017-02-28 20:49:25.000000000', 'files': ['patrole_tempest_plugin/tests/api/compute/test_assisted_volume_snapshot_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/89cc76d7fd4c3c78aec6432ebf9b93dcdcb7d15c', 'message': 'Assisted Volume snapshot RBAC test for Compute v2.1 API roles\n\n- migrated out common clients and internal methods to the base\n- fixes to projects rbac test to use tempest base instead\n- migrated volume assistend snapshot rbac tempest test to Patrole\n\nNOTE: This requires a new API client in tempest/lib. A bug is added\nfor tracking and is used as a reason for skipping.\nhttps://bugs.launchpad.net/tempest/+bug/1668407\n\nChange-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f\n'}]",31,438016,89cc76d7fd4c3c78aec6432ebf9b93dcdcb7d15c,24,7,5,20809,,,0,"Assisted Volume snapshot RBAC test for Compute v2.1 API roles

- migrated out common clients and internal methods to the base
- fixes to projects rbac test to use tempest base instead
- migrated volume assistend snapshot rbac tempest test to Patrole

NOTE: This requires a new API client in tempest/lib. A bug is added
for tracking and is used as a reason for skipping.
https://bugs.launchpad.net/tempest/+bug/1668407

Change-Id: I84358aa1e2a76c95a3e5e416770f3053faa2cf3f
",git fetch https://review.opendev.org/openstack/patrole refs/changes/16/438016/5 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/compute/test_assisted_volume_snapshot_rbac.py'],1,279aea47d1cde417ed5e55d7d17b1d18042d31f8,,"# Copyright 2017 AT&T Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""RBAC tests for assisted volume snapshot."""""" import logging import uuid from patrole_tempest_plugin import rbac_rule_validation from patrole_tempest_plugin.rbac_utils import rbac_utils from patrole_tempest_plugin.tests.api.compute import rbac_base from tempest import config from tempest.lib import decorators from tempest.lib.common.utils import data_utils CONF = config.CONF LOG = logging.getLogger(__name__) class RbacAssistedVolumesSnapshotV21Test(rbac_base.BaseV2ComputeRbacTest): """"""Delete Role Test. Assisted volume Test class """""" _api_version = 2.1 @classmethod def setup_clients(cls): """"""Setup clients."""""" super(RbacAssistedVolumesSnapshotV21Test, cls).setup_clients() cls.client = cls.servers_client cls.admin_client = cls.os_adm.agents_client cls.auth_provider = cls.os.auth_provider def tearDown(self): """"""Cleanup and reset RBAC role."""""" rbac_utils.switch_role(self, switchToRbacRole=False) super(RbacAssistedVolumesSnapshotV21Test, self).tearDown() def _create_and_attach(self): self.server = self.create_test_server(wait_until='ACTIVE') self.addCleanup(self.delete_server, self.server['id']) # Create a volume and wait for it to become ready vol_name = data_utils.rand_name('vol') self.volume = self.volumes_client.create_volume( CONF.volume.volume_size, display_name=vol_name)['volume'] self.addCleanup(self._delete_volume, self.volumes_client, self.volume['id']) self.volumes_client.wait_for_volume_status(self.volume['id'], 'available') # Attach the volume to the server self.attachment = self.client.attach_volume( self.server['id'], volumeId=self.volume['id'])['volumeAttachment'] self.volumes_client.wait_for_volume_status(self.volume['id'], 'in-use') @decorators.idempotent_id('74f64957-912d-4537-983b-cea4a31c5c9f') @rbac_rule_validation.action( service=""nova"", rule=""os_compute_api:os-assisted-volume-snapshots:create"") def test_assisted_volume_snapshot_create(self): """"""Create Role Test. RBAC test for assisted volume snapshot role-create """""" self._create_and_attach() rbac_utils.switch_role(self, switchToRbacRole=True) self.assisted_volume_snapshot_client.\ create_volume_attachments(self.volume['id'], uuid.uuid4()) @decorators.idempotent_id('01323040-c5df-4e15-8b1a-3df98fa7d998') @rbac_rule_validation.action( service=""nova"", rule=""os_compute_api:os-assisted-volume-snapshots:delete"") def test_assisted_volume_snapshot_delete(self): """"""Delete Role Test. RBAC test for assisted volume snapshot role-delete """""" self._create_and_attach() snapshot_id = uuid.uuid4() self.assisted_volume_snapshot_client.\ create_volume_attachments(self.volume['id'], snapshot_id) rbac_utils.switch_role(self, switchToRbacRole=True) self.assisted_volume_snapshot_client.\ delete_volume_attachments(snapshot_id, self.volume['id']) ",,101,0
openstack%2Fglance~master~Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131,openstack/glance,master,Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131,remove useless EVENTLET_NO_GREENDNS,MERGED,2017-01-17 09:19:36.000000000,2017-02-28 22:48:36.000000000,2017-02-28 16:42:07.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 8158}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2017-01-17 09:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1c9d613c96a6d632f468c7057f126bdc19ef01f9', 'message': 'remove useless EVENTLET_NO_GREENDNS\n\nSince eventlet 0.17, ipv6 is support for dns and getaddrinfo.\n\nGlance depends on 0.18.2, so the workaround is no more needed.\n\nhttps://github.com/eventlet/eventlet/commit/a6ce444265d36fb23361809d40da73caf4864487\n\nChange-Id: Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131\n'}, {'number': 2, 'created': '2017-01-17 09:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e82f68fdb70bfb61c0635cfd31fcbd8f39d7f6b3', 'message': 'remove useless EVENTLET_NO_GREENDNS\n\nSince eventlet 0.17, ipv6 is support for dns and getaddrinfo.\n\nGlance depends on 0.18.2, so the workaround is no more needed.\n\nhttps://github.com/eventlet/eventlet/commit/a6ce444265d36fb23361809d40da73caf4864487\n\nRelated-bug: #1655727\nChange-Id: Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131\n'}, {'number': 3, 'created': '2017-01-17 09:29:05.000000000', 'files': ['glance/cmd/__init__.py', 'glance/tests/unit/common/test_wsgi_ipv6.py', 'glance/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3988a9956e40a5b2f739eb8851ccb1d0b431a2e8', 'message': 'remove useless EVENTLET_NO_GREENDNS\n\nSince eventlet 0.17, ipv6 is support for dns and getaddrinfo.\n\nGlance depends on 0.18.2, so the workaround is no more needed.\n\nhttps://github.com/eventlet/eventlet/commit/a6ce444265d36fb23361809d40da73caf4864487\n\nRelated-bug: #1655727\nChange-Id: Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131\n'}]",0,421162,3988a9956e40a5b2f739eb8851ccb1d0b431a2e8,17,10,3,2813,,,0,"remove useless EVENTLET_NO_GREENDNS

Since eventlet 0.17, ipv6 is support for dns and getaddrinfo.

Glance depends on 0.18.2, so the workaround is no more needed.

https://github.com/eventlet/eventlet/commit/a6ce444265d36fb23361809d40da73caf4864487

Related-bug: #1655727
Change-Id: Ic2bdc9a780ee98df87a7cdd5413a9db42e5e7131
",git fetch https://review.opendev.org/openstack/glance refs/changes/62/421162/3 && git format-patch -1 --stdout FETCH_HEAD,"['glance/cmd/__init__.py', 'glance/tests/unit/common/test_wsgi_ipv6.py']",2,1c9d613c96a6d632f468c7057f126bdc19ef01f9,bug/1655727,,"# Copyright 2010-2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import subprocess from glance.tests import utils as test_utils script = """""" import os import sys # Spoof module installed sys.modules['%s'] = object %s os.environ['EVENTLET_NO_GREENDNS'] = '%s' if 'eventlet' %s in sys.modules: sys.exit(2) try: import glance.cmd except ImportError: sys.exit(%d) else: sys.exit(%d) """""" eventlet_no_dns = script % ('fake', 'import eventlet', 'foo', 'not', 1, 0) no_eventlet_no_dns = script % ('fake', '', 'foo', '', 1, 0) no_eventlet_no_greendns = script % ('dns', '', 'yes', '', 1, 0) eventlet_no_greendns = script % ('dns', 'import eventlet', 'yes', 'not', 1, 0) no_eventlet_greendns = script % ('dns', '', 'no', '', 1, 0) eventlet_greendns = script % ('dns', 'import eventlet', 'no', 'not', 0, 1) class IPv6ServerTest(test_utils.BaseTestCase): def test_no_evnetlet_no_dnspython(self): """"""Test eventlet not imported and dnspython not installed"""""" rc = subprocess.call(['python', '-c', no_eventlet_no_dns]) self.assertEqual(0, rc) def test_evnetlet_no_dnspython(self): """"""Test eventlet pre-imported but dnspython not installed"""""" rc = subprocess.call(['python', '-c', eventlet_no_dns]) self.assertEqual(0, rc) def test_no_eventlet_no_greendns(self): """"""Test eventlet not imported with EVENTLET_NO_GREENDNS='yes'"""""" rc = subprocess.call(['python', '-c', no_eventlet_no_greendns]) self.assertEqual(0, rc) def test_eventlet_no_greendns(self): """"""Test eventlet pre-imported with EVENTLET_NO_GREENDNS='yes'"""""" rc = subprocess.call(['python', '-c', eventlet_no_greendns]) self.assertEqual(0, rc) def test_no_eventlet_w_greendns(self): """"""Test eventlet not imported with EVENTLET_NO_GREENDNS='no'"""""" rc = subprocess.call(['python', '-c', no_eventlet_greendns]) self.assertEqual(0, rc) def test_eventlet_w_greendns(self): """"""Test eventlet pre-imported with EVENTLET_NO_GREENDNS='no'"""""" rc = subprocess.call(['python', '-c', eventlet_greendns]) self.assertEqual(0, rc) ",0,116
openstack%2Fglance~master~I99557a031f9760081659a6e0a74a080c24adb704,openstack/glance,master,I99557a031f9760081659a6e0a74a080c24adb704,Change identifiers in data migration tests,MERGED,2017-02-27 23:26:15.000000000,2017-02-28 22:42:58.000000000,2017-02-28 22:42:58.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 8158}, {'_account_id': 21722}]","[{'number': 1, 'created': '2017-02-27 23:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fdc0da72cf397eb0ee3e93502ace91a814aa305d', 'message': ""Change identifiers in data migration tests\n\nThe migration identifiers used throughout the class\nTestDataMigrationFramework are modified so that they're clearly\nnot identifiers for existing migrations, as this was causing some\nconfusion.\n\nCo-Authored-By: Brian Rosmaita <brian.rosmaita@rackspace.com>\nCo-Authored-By: Hemanth Makkapati <hemanth.makkapati@rackspace.com>\n\nChange-Id: I99557a031f9760081659a6e0a74a080c24adb704\nDepends-On: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}, {'number': 2, 'created': '2017-02-28 17:16:05.000000000', 'files': ['glance/tests/unit/test_data_migration_framework.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c3df4cfe7aee06b03fb470dcd14e68f1d8d0cafd', 'message': ""Change identifiers in data migration tests\n\nThe migration identifiers used throughout the class\nTestDataMigrationFramework are modified so that they're clearly\nnot identifiers for existing migrations, as this was causing some\nconfusion.\n\nCo-Authored-By: Brian Rosmaita <brian.rosmaita@rackspace.com>\nCo-Authored-By: Hemanth Makkapati <hemanth.makkapati@rackspace.com>\n\nChange-Id: I99557a031f9760081659a6e0a74a080c24adb704\nDepends-On: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}]",0,438734,c3df4cfe7aee06b03fb470dcd14e68f1d8d0cafd,13,5,2,8158,,,0,"Change identifiers in data migration tests

The migration identifiers used throughout the class
TestDataMigrationFramework are modified so that they're clearly
not identifiers for existing migrations, as this was causing some
confusion.

Co-Authored-By: Brian Rosmaita <brian.rosmaita@rackspace.com>
Co-Authored-By: Hemanth Makkapati <hemanth.makkapati@rackspace.com>

Change-Id: I99557a031f9760081659a6e0a74a080c24adb704
Depends-On: I2a7dc86b88afaf0e5b878d79607f54125a35eb16
",git fetch https://review.opendev.org/openstack/glance refs/changes/34/438734/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_data_migration_framework.py'],1,fdc0da72cf397eb0ee3e93502ace91a814aa305d,fix-data-migration-test," yield 'blah', 'zebra01', 'blah' yield 'blah', 'zebra02', 'blah' yield 'blah', 'yellow01', 'blah' yield 'blah', 'xray01', 'blah' yield 'blah', 'wrinkle01', 'blah' zebra1 = mock.Mock() zebra1.has_migrations.return_value = mock.Mock() zebra1.migrate.return_value = mock.Mock() zebra2 = mock.Mock() zebra2.has_migrations.return_value = mock.Mock() zebra2.migrate.return_value = mock.Mock() fake_imported_modules = [zebra1, zebra2] actual = data_migrations._find_migration_modules('zebra') yield 'blah', 'zebra01', 'blah' yield 'blah', 'yellow01', 'blah' yield 'blah', 'xray01', 'blah' yield 'blah', 'wrinkle01', 'blah' yield 'blah', 'victor01', 'blah' actual = data_migrations._find_migration_modules('umbrella') zebra1 = mock.Mock() zebra1.has_migrations.return_value = True zebra1.migrate.return_value = 100 zebra2 = mock.Mock() zebra2.has_migrations.return_value = True zebra2.migrate.return_value = 50 migrations = [zebra1, zebra2] zebra1.has_migrations.assert_called_once_with(engine) zebra1.migrate.assert_called_once_with(engine) zebra2.has_migrations.assert_called_once_with(engine) zebra2.migrate.assert_called_once_with(engine) zebra1 = mock.Mock() zebra1.has_migrations.return_value = False zebra1.migrate.return_value = 0 zebra2 = mock.Mock() zebra2.has_migrations.return_value = True zebra2.migrate.return_value = 50 migrations = [zebra1, zebra2] zebra1.has_migrations.assert_called_once_with(engine) zebra1.migrate.assert_not_called() zebra2.has_migrations.assert_called_once_with(engine) zebra2.migrate.assert_called_once_with(engine) yield 'blah', 'zebra01', 'blah' yield 'blah', 'zebra02', 'blah' yield 'blah', 'yellow01', 'blah' yield 'blah', 'xray01', 'blah' yield 'blah', 'xray02', 'blah' zebra1 = mock.Mock() zebra1.has_migrations.return_value = True zebra1.migrate.return_value = 100 zebra2 = mock.Mock() zebra2.has_migrations.return_value = True zebra2.migrate.return_value = 50 fake_imported_modules = [zebra1, zebra2] zebra1.has_migrations.assert_called_once_with(engine) zebra1.migrate.assert_called_once_with(engine) zebra2.has_migrations.assert_called_once_with(engine) zebra2.migrate.assert_called_once_with(engine)"," yield 'blah', 'ocata01', 'blah' yield 'blah', 'ocata02', 'blah' yield 'blah', 'pike01', 'blah' yield 'blah', 'newton', 'blah' yield 'blah', 'mitaka456', 'blah' ocata1 = mock.Mock() ocata1.has_migrations.return_value = mock.Mock() ocata1.migrate.return_value = mock.Mock() ocata2 = mock.Mock() ocata2.has_migrations.return_value = mock.Mock() ocata2.migrate.return_value = mock.Mock() fake_imported_modules = [ocata1, ocata2] actual = data_migrations._find_migration_modules('ocata') yield 'blah', 'liberty01', 'blah' yield 'blah', 'kilo01', 'blah' yield 'blah', 'mitaka01', 'blah' yield 'blah', 'newton01', 'blah' yield 'blah', 'pike01', 'blah' actual = data_migrations._find_migration_modules('ocata') ocata1 = mock.Mock() ocata1.has_migrations.return_value = True ocata1.migrate.return_value = 100 ocata2 = mock.Mock() ocata2.has_migrations.return_value = True ocata2.migrate.return_value = 50 migrations = [ocata1, ocata2] ocata1.has_migrations.assert_called_once_with(engine) ocata1.migrate.assert_called_once_with(engine) ocata2.has_migrations.assert_called_once_with(engine) ocata2.migrate.assert_called_once_with(engine) ocata1 = mock.Mock() ocata1.has_migrations.return_value = False ocata1.migrate.return_value = 0 ocata2 = mock.Mock() ocata2.has_migrations.return_value = True ocata2.migrate.return_value = 50 migrations = [ocata1, ocata2] ocata1.has_migrations.assert_called_once_with(engine) ocata1.migrate.assert_not_called() ocata2.has_migrations.assert_called_once_with(engine) ocata2.migrate.assert_called_once_with(engine) yield 'blah', 'ocata01', 'blah' yield 'blah', 'ocata02', 'blah' yield 'blah', 'pike01', 'blah' yield 'blah', 'newton', 'blah' yield 'blah', 'mitaka456', 'blah' ocata1 = mock.Mock() ocata1.has_migrations.return_value = True ocata1.migrate.return_value = 100 ocata2 = mock.Mock() ocata2.has_migrations.return_value = True ocata2.migrate.return_value = 50 fake_imported_modules = [ocata1, ocata2] ocata1.has_migrations.assert_called_once_with(engine) ocata1.migrate.assert_called_once_with(engine) ocata2.has_migrations.assert_called_once_with(engine) ocata2.migrate.assert_called_once_with(engine)",57,57
openstack%2Fironic~master~I9be01a7862c44521f3315232855b304861d035e2,openstack/ironic,master,I9be01a7862c44521f3315232855b304861d035e2,WIP/DNM: Debugging stuff,ABANDONED,2017-02-28 21:56:55.000000000,2017-02-28 22:38:26.000000000,,[],"[{'number': 1, 'created': '2017-02-28 21:56:55.000000000', 'files': ['ironic/common/driver_factory.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c6759a18acdea1fceb92ef328393b27c69483af2', 'message': 'WIP/DNM: Debugging stuff\n\nChange-Id: I9be01a7862c44521f3315232855b304861d035e2\n'}]",0,439183,c6759a18acdea1fceb92ef328393b27c69483af2,2,0,1,14760,,,0,"WIP/DNM: Debugging stuff

Change-Id: I9be01a7862c44521f3315232855b304861d035e2
",git fetch https://review.opendev.org/openstack/ironic refs/changes/83/439183/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/driver_factory.py'],1,c6759a18acdea1fceb92ef328393b27c69483af2,,"import inspect import pprint try: jlv_info = pprint.pformat(inspect.getmembers(_)) LOG.error(""JLV: {}\n{!r}"".format(jlv_info, _)) except: LOG.exception()",,7,0
openstack%2Ftrove~master~I963e0f03875a1b93e2e1214bcb6580c507fa45fe,openstack/trove,master,I963e0f03875a1b93e2e1214bcb6580c507fa45fe,Fix module-instances command,MERGED,2016-11-25 22:35:59.000000000,2017-02-28 22:28:28.000000000,2017-02-28 22:28:28.000000000,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 14576}, {'_account_id': 20378}]","[{'number': 1, 'created': '2016-11-25 22:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/dc985c5f4bd304fa2d7a66939b987ee4297054b3', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 2, 'created': '2016-11-26 22:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/284831113b73978067cf94b68ee2b0010695af9a', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 3, 'created': '2016-11-27 00:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0c9a79e60c481119d329f1e63da1c751bb6dac81', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 4, 'created': '2016-11-27 00:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/74700f8a6b1a0634b0fc4eb724f57bd863bfe9ef', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 5, 'created': '2016-12-07 19:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7d5f85675b1466197bb3b67d36216f7e5b5d8632', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 6, 'created': '2016-12-12 16:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8e9383d2e6992608c3f5d3c806014c9005150765', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 7, 'created': '2016-12-12 18:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/09d342e877b479e8d1915b44d9aca59529007014', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 8, 'created': '2016-12-12 20:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/04f4d00443c9c49d84d4f087a19f2fa39368fb39', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 9, 'created': '2016-12-12 21:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8cb13464e94edc3e5bf2374ebf618438af3a198c', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 10, 'created': '2016-12-13 15:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/16ec57a6c5873d2ac206664011201fbc7a9e00dc', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 11, 'created': '2016-12-14 21:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/66807c1e5059af61f3d8746e00e09e85569af7d9', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 12, 'created': '2016-12-14 21:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ff6792c8f5dff3411fc21edc7130c868488f1175', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nCloses-Bug: #1554900\n""}, {'number': 13, 'created': '2016-12-16 15:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0b5fe5895fe9da959ecf0aca248cbe7fecc893b3', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nDepends-On: I3bbe3bafa7ea3e627272103ac16a38f6a32a8a06\nCloses-Bug: #1554900\n""}, {'number': 14, 'created': '2016-12-17 22:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3209358287702bdfddcf0037487a1e4e8fef83c3', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nDepends-On: Iea661166bf3a4f3520a590da5954aedcd0036243\nDepends-On: I3bbe3bafa7ea3e627272103ac16a38f6a32a8a06\nCloses-Bug: #1554900\n""}, {'number': 15, 'created': '2017-01-06 21:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/54990d63209a4766feb9cb6d782ed22b5876ee48', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 16, 'created': '2017-01-07 07:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bcf8f14b2215516a72757e1f7f56c46b7b920a23', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 17, 'created': '2017-01-09 22:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c8c82c8e7d94c7f5fc225561cddd9bb485988ca4', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 18, 'created': '2017-01-13 18:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ddb2349cdada7f3347db598c234a436ca902020e', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 19, 'created': '2017-01-13 20:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/193f8f7726583520b3e843747afe228a14f95c75', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 20, 'created': '2017-01-13 20:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cac2e0b744c745c65a13b9c6747bd54ee9c8c542', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 21, 'created': '2017-02-06 16:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e27151d7ebcdb16eae677a4e91b68f010a84e1ab', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}, {'number': 22, 'created': '2017-02-27 18:42:34.000000000', 'files': ['trove/tests/unittests/datastore/test_datastore.py', 'trove/db/sqlalchemy/api.py', 'releasenotes/notes/fix_mod_inst_cmd-3a46c7233e3.yaml', 'trove/datastore/models.py', 'trove/instance/models.py', 'trove/module/views.py', 'trove/instance/service.py', 'trove/tests/unittests/instance/test_instance_models.py', 'trove/tests/scenario/runners/module_runners.py', 'trove/module/models.py', 'trove/instance/views.py', 'tools/trove-pylint.config', 'trove/module/service.py', 'trove/tests/unittests/module/test_module_models.py', 'trove/tests/scenario/groups/module_group.py', 'trove/db/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/a9a4ae4bba71db5e95070aad7009ebdffa7e20eb', 'message': ""Fix module-instances command\n\nFixed the module-instances command to return a paginated\nlist of instances.  Also added a --count_only flag to the\ncommand to return a summary of the applied instances\nbased on the MD5 of the module (this is most useful\nfor live_update modules, to see which ones haven't been\nupdated).\n\nAlso cleaned up the code a bit, putting some methods\ninto files where they made more sense (and would cause\nless potential collisions during import).\n\nChange-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe\nCloses-Bug: #1554900\n""}]",6,403287,a9a4ae4bba71db5e95070aad7009ebdffa7e20eb,85,5,22,10215,,,0,"Fix module-instances command

Fixed the module-instances command to return a paginated
list of instances.  Also added a --count_only flag to the
command to return a summary of the applied instances
based on the MD5 of the module (this is most useful
for live_update modules, to see which ones haven't been
updated).

Also cleaned up the code a bit, putting some methods
into files where they made more sense (and would cause
less potential collisions during import).

Change-Id: I963e0f03875a1b93e2e1214bcb6580c507fa45fe
Closes-Bug: #1554900
",git fetch https://review.opendev.org/openstack/trove refs/changes/87/403287/20 && git format-patch -1 --stdout FETCH_HEAD,"['trove/db/sqlalchemy/api.py', 'releasenotes/notes/fix_mod_inst_cmd-3a46c7233e3.yaml', 'trove/datastore/models.py', 'trove/instance/models.py', 'trove/module/views.py', 'trove/instance/service.py', 'trove/tests/scenario/runners/module_runners.py', 'trove/module/models.py', 'trove/instance/views.py', 'trove/module/service.py', 'trove/tests/scenario/groups/module_group.py', 'trove/db/models.py']",12,dc985c5f4bd304fa2d7a66939b987ee4297054b3,bug/1554900," def find_by_filter(cls, **kwargs): return db_query.find_by_filter(cls, **cls._process_conditions(kwargs)) @classmethod",,242,76
openstack%2Fironic~master~I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db,openstack/ironic,master,I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db,Add ironic port group CRUD notifications,MERGED,2017-01-31 16:35:55.000000000,2017-02-28 22:22:41.000000000,2017-02-28 22:22:41.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 10118}, {'_account_id': 11878}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 19593}, {'_account_id': 19686}]","[{'number': 1, 'created': '2017-01-31 16:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f6658b903c68232b0003ac836a7f1cf59c0f8fbb', 'message': 'Add ironic portgroup CRUD notifications\n\nThis patch adds notifications for create, update or delete\nportgroups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}, {'number': 2, 'created': '2017-02-02 13:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1527d0f9266808d2b12b43f8979a1acfa4599efd', 'message': 'Add ironic portgroup CRUD notifications\n\nThis patch adds notifications for create, update or delete\nportgroups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}, {'number': 3, 'created': '2017-02-07 11:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9e1d86a19b88716979a0ec8b6e8d25a06c1e0ed4', 'message': 'Add ironic portgroup CRUD notifications\n\nThis patch adds notifications for create, update or delete\nportgroups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}, {'number': 4, 'created': '2017-02-08 12:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cd55e7dee63b7e95cf31a378f3a5c9783c002270', 'message': 'Add ironic portgroup CRUD notifications\n\nThis patch adds notifications for create, update or delete\nportgroups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}, {'number': 5, 'created': '2017-02-13 10:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ec13f7ebeb4036598241dc37d8b7ae9ed0026c0', 'message': 'Add ironic portgroup CRUD notifications\n\nThis patch adds notifications for create, update or delete\nportgroups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}, {'number': 6, 'created': '2017-02-15 09:53:06.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/objects/portgroup.py', 'ironic/api/controllers/v1/portgroup.py', 'ironic/tests/unit/api/v1/test_notification_utils.py', 'ironic/tests/unit/objects/test_portgroup.py', 'ironic/tests/unit/objects/test_port.py', 'ironic/tests/unit/api/v1/test_ports.py', 'ironic/tests/unit/objects/test_chassis.py', 'doc/source/deploy/notifications.rst', 'ironic/api/controllers/v1/notification_utils.py', 'releasenotes/notes/portgroup-crud-notifications-91204635528972b2.yaml', 'ironic/objects/port.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/tests/unit/api/v1/test_portgroups.py', 'ironic/tests/unit/objects/test_node.py', 'ironic/tests/unit/objects/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f9d9b334dab309156eed75ce93693152018746bd', 'message': 'Add ironic port group CRUD notifications\n\nThis patch adds notifications for create, update or delete\nport groups. Event types are:\nbaremetal.portgroup.{create, update, delete}.{start,end,error}.\nDeveloper documentation updated. ""portgroup_uuid"" field added to\nport payload.\n\nCloses-Bug: #1660292\nChange-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db\n'}]",42,427281,f9d9b334dab309156eed75ce93693152018746bd,71,14,6,7711,,,0,"Add ironic port group CRUD notifications

This patch adds notifications for create, update or delete
port groups. Event types are:
baremetal.portgroup.{create, update, delete}.{start,end,error}.
Developer documentation updated. ""portgroup_uuid"" field added to
port payload.

Closes-Bug: #1660292
Change-Id: I9a8ce6c34e9c704b1aeeb526babcb20a5b1261db
",git fetch https://review.opendev.org/openstack/ironic refs/changes/81/427281/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/objects/portgroup.py', 'ironic/api/controllers/v1/portgroup.py', 'ironic/tests/unit/api/v1/test_notification_utils.py', 'ironic/tests/unit/objects/test_portgroup.py', 'ironic/tests/unit/objects/test_port.py', 'ironic/tests/unit/api/v1/test_ports.py', 'ironic/tests/unit/objects/test_chassis.py', 'doc/source/deploy/notifications.rst', 'ironic/api/controllers/v1/notification_utils.py', 'releasenotes/notes/portgroup-crud-notifications-91204635528972b2.yaml', 'ironic/objects/port.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/tests/unit/api/v1/test_portgroups.py', 'ironic/tests/unit/objects/test_node.py', 'ironic/tests/unit/objects/utils.py']",16,f6658b903c68232b0003ac836a7f1cf59c0f8fbb,bug/1660292," class SchemasTestMixIn(object): def _check_payload_schemas(self, from_module, fields): """"""Assert that the Payload SCHEMAs have the expected properties. A payload's SCHEMA should: 1. Have each of its keys in the payload's fields 2. Have each member of the schema match with a corresponding field in the object """""" resource = from_module.__name__.split('.')[-1] payloads = get_payloads_with_schemas(from_module) for payload in payloads: for schema_key in payload.SCHEMA: self.assertIn(schema_key, payload.fields, ""for %s, schema key %s is not in fields"" % (payload, schema_key)) key = payload.SCHEMA[schema_key][1] self.assertIn(key, fields, ""for %s, schema key %s has invalid %s "" ""field %s"" % (payload, schema_key, resource, key))",,343,112
openstack%2Ftempest~master~Icc007047a8e9a527d48374b3efcec8cc5fd1be08,openstack/tempest,master,Icc007047a8e9a527d48374b3efcec8cc5fd1be08,Fix the removal of config.skip_(unless|if)_config decorators,MERGED,2017-02-21 20:30:13.000000000,2017-02-28 22:09:48.000000000,2017-02-28 22:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 13252}]","[{'number': 1, 'created': '2017-02-21 20:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b9eb6303a4e0f53f68cf86226f5243e6cb53459e', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 2, 'created': '2017-02-21 20:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e172476aaca2c49cc829e8da422d9b26031d9be', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 3, 'created': '2017-02-21 21:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fb4f3f50553e623cd34c9e5001afbf43683a9778', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 4, 'created': '2017-02-22 03:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd47125a4a4dd0ecd148d52d4430900455db3e2e', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 5, 'created': '2017-02-22 15:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c3472b5bd299fd81d13ca1fe32a1057ba88011e8', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 6, 'created': '2017-02-22 19:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4cb1b1b3368fad86b5b301f841fb7de478093b8', 'message': 'Fix the removal of config.skip_unless_config decorator\n\nThat decorator was removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad. (I must have only checked the\nusage of the skip_if_config decorator accross plugins.).\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 7, 'created': '2017-02-23 20:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fb391e51b9b84f169f44b5f16a5662073e65eaf4', 'message': 'Fix the removal of config.skip_(unless|if)_config decorators\n\nThese decorators were removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad.\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 8, 'created': '2017-02-23 20:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c408aad7b18a9c033773a513f4b4a9b2c07477a', 'message': 'Fix the removal of config.skip_(unless|if)_config decorators\n\nThese decorators were removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad.\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}, {'number': 9, 'created': '2017-02-25 14:57:01.000000000', 'files': ['releasenotes/notes/deprecate-skip_unless_config-decorator-64c32d588043ab12.yaml', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd4361dd192f54399f3440845b12eab54a793385', 'message': 'Fix the removal of config.skip_(unless|if)_config decorators\n\nThese decorators were removed in I54a001cb562a8aac91537bf61e82a7e7d3498788\nwithout a proper deprecation period. My bad.\n\nChange-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08\n'}]",6,436654,bd4361dd192f54399f3440845b12eab54a793385,44,8,9,7350,,,0,"Fix the removal of config.skip_(unless|if)_config decorators

These decorators were removed in I54a001cb562a8aac91537bf61e82a7e7d3498788
without a proper deprecation period. My bad.

Change-Id: Icc007047a8e9a527d48374b3efcec8cc5fd1be08
",git fetch https://review.opendev.org/openstack/tempest refs/changes/54/436654/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,b9eb6303a4e0f53f68cf86226f5243e6cb53459e,436612,"import debtcollector.removalsimport testtools@debtcollector.removals.remove( message='use testtools.skipUnless instead', version='Queen') def skip_unless_config(*args): config_key = '%s.%s' % (args[0], args[1]) return testtools.skipUnless(getattr(CONF, config_key)) ",,9,0
openstack%2Fkeystone~master~Ia386675010b725723f464fa3cf9f74fcf2d8a619,openstack/keystone,master,Ia386675010b725723f464fa3cf9f74fcf2d8a619,Use pdkfd_sha512 instead of sha512_crypt,ABANDONED,2017-02-28 05:46:28.000000000,2017-02-28 21:57:18.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5263}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 13478}, {'_account_id': 17860}, {'_account_id': 18338}]","[{'number': 1, 'created': '2017-02-28 05:46:28.000000000', 'files': ['keystone/tests/unit/common/test_utils.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2009a85bc063f299c2389434008be81a017cea13', 'message': 'Use pdkfd_sha512 instead of sha512_crypt\n\nsha512_crypt is considered insufficient (even with significant rounds)\nin comparison to pdkfd_sha512, bcrypt, or scrypt for password hashing.\n\nThis patch makes all future password hashing use pdkfd_sha512 instead\nof sha512_crypt while still supporting decrypting any/all passwords\noriginally hashed with sha512_crypt. It is recommended users change\npasswords to ensure a more secure hashing algorithm (based on\nkey-derivation function) is in place.\n\nChange-Id: Ia386675010b725723f464fa3cf9f74fcf2d8a619\nCloses-Bug: #1668503\nRelated-Bug: #1543048\n'}]",6,438808,2009a85bc063f299c2389434008be81a017cea13,5,16,1,2903,,,0,"Use pdkfd_sha512 instead of sha512_crypt

sha512_crypt is considered insufficient (even with significant rounds)
in comparison to pdkfd_sha512, bcrypt, or scrypt for password hashing.

This patch makes all future password hashing use pdkfd_sha512 instead
of sha512_crypt while still supporting decrypting any/all passwords
originally hashed with sha512_crypt. It is recommended users change
passwords to ensure a more secure hashing algorithm (based on
key-derivation function) is in place.

Change-Id: Ia386675010b725723f464fa3cf9f74fcf2d8a619
Closes-Bug: #1668503
Related-Bug: #1543048
",git fetch https://review.opendev.org/openstack/keystone refs/changes/08/438808/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/common/test_utils.py', 'keystone/common/utils.py']",2,2009a85bc063f299c2389434008be81a017cea13,bug/1668503,"SUPPORTED_HASHERS = frozenset([passlib.hash.pbkdf2_sha512, passlib.hash.sha512_crypt]) # NOTE(notmorgan): Build the list of prefixes. All hashed passwords are # '$<ident>$<metadata>$<hash>') so we can do a fast-lookup on the hasher to # use. If has hasher has multiple ident options it is encoded in the # .ident_values attribute whereas hashers that have a single option # (sha512_crypt) only has the .ident attribute. This is only used for # verification of passwords, not for actual hashing. _HASHER_IDENT_MAP = {} for mod in SUPPORTED_HASHERS: for prefix in getattr(mod, 'ident_valuse', (mod.ident,)): _HASHER_IDENT_MAP[prefix] = mod def _get_hasher_based_on_ident(hashed_pw): ident = hashed_pw[0:hashed_pw.index('$', 1) + 1] try: return _HASHER_IDENT_MAP[ident] except KeyError: raise ValueError(_('Unknown password hasher for ident %s') % ident) params = {'rounds': CONF.crypt_strength} return passlib.hash.pbkdf2_sha512.using(**params).hash(password_utf8) hasher = _get_hasher_based_on_ident(hashed) return hasher.verify(password_utf8, hashed)"," return passlib.hash.sha512_crypt.hash( password_utf8, rounds=CONF.crypt_strength) return passlib.hash.sha512_crypt.verify(password_utf8, hashed)",39,3
openstack%2Fbifrost~master~I8838c9e69c5cc874abee965bf685c13ffb9a4db0,openstack/bifrost,master,I8838c9e69c5cc874abee965bf685c13ffb9a4db0,Add '-E' options to pass proxy env for sudo,MERGED,2017-02-28 09:52:22.000000000,2017-02-28 21:52:58.000000000,2017-02-28 21:52:58.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 14372}, {'_account_id': 22474}]","[{'number': 1, 'created': '2017-02-28 09:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/409c5055b8809716ef7f2d61df7bd446adfbdc43', 'message': 'Add \'-E\' options to pass proxy env for sudo\n\nscript install-deps.sh doesn\'t pass proxy options\n INSTALLER_CMD=""sudo -H ${PKG_MANAGER} -y install""\n\nAdded -E (similar to elsewhere in script) to allow dnf/yum\ninstallation of packages.\n\nAdded for both OS_FAMILY=""Debian"" and OS_FAMILY=""RedHat""\nfor consistency.\n\nChange-Id: I8838c9e69c5cc874abee965bf685c13ffb9a4db0\nCloses-bug: #1668544\n'}, {'number': 2, 'created': '2017-02-28 10:10:43.000000000', 'files': ['scripts/install-deps.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1bb4bc9816387d9450385b0a56087b9b83dc6c21', 'message': 'Add \'-E\' options to pass proxy env for sudo\n\nscript install-deps.sh doesn\'t pass proxy options\n INSTALLER_CMD=""sudo -H ${PKG_MANAGER} -y install""\n\nAdded -E (similar to elsewhere in script) to allow dnf/yum\ninstallation of packages.\n\nUpdated OS_FAMILY ""Suse"", ""Debian"" and ""RedHat"" for consistency.\n\nChange-Id: I8838c9e69c5cc874abee965bf685c13ffb9a4db0\nCloses-bug: #1668544\n'}]",0,438884,1bb4bc9816387d9450385b0a56087b9b83dc6c21,15,5,2,16704,,,0,"Add '-E' options to pass proxy env for sudo

script install-deps.sh doesn't pass proxy options
 INSTALLER_CMD=""sudo -H ${PKG_MANAGER} -y install""

Added -E (similar to elsewhere in script) to allow dnf/yum
installation of packages.

Updated OS_FAMILY ""Suse"", ""Debian"" and ""RedHat"" for consistency.

Change-Id: I8838c9e69c5cc874abee965bf685c13ffb9a4db0
Closes-bug: #1668544
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/84/438884/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/install-deps.sh'],1,409c5055b8809716ef7f2d61df7bd446adfbdc43,," INSTALLER_CMD=""sudo -H -E apt-get -y install"" INSTALLER_CMD=""sudo -H -E ${PKG_MANAGER} -y install"""," INSTALLER_CMD=""sudo -H apt-get -y install"" INSTALLER_CMD=""sudo -H ${PKG_MANAGER} -y install""",2,2
openstack%2Fglance-specs~master~I58f39d4729e783a86999b1fe18debd97a3ebe544,openstack/glance-specs,master,I58f39d4729e783a86999b1fe18debd97a3ebe544,"Update ""narrative"" api docs for visibility changes",MERGED,2017-01-29 21:17:29.000000000,2017-02-28 21:50:55.000000000,2017-02-28 21:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 12807}, {'_account_id': 21722}, {'_account_id': 22448}]","[{'number': 1, 'created': '2017-01-29 21:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/32e9d2978e5acfa6ac27a3a32f1e6da073500f32', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}, {'number': 2, 'created': '2017-02-03 17:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/9bb50a5ee891ff7a40c9d29fb84c8c0d216e53ad', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also\nadded some text to clarify the implications of the owner_is_tenant\nconfiguration option when identifying an image producer or consumer.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}, {'number': 3, 'created': '2017-02-03 19:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/17168daabe4d65cc61467ad68d4ae9856b2115f5', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also\nadded some text to clarify the implications of the owner_is_tenant\nconfiguration option when identifying an image producer or consumer.\nAdded an introductory section about the kinds of sharing available.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}, {'number': 4, 'created': '2017-02-03 22:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/8ed1c19d8914383fd30511f5c44cee2f4a6c73cd', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also\nadded some text to clarify the implications of the owner_is_tenant\nconfiguration option when identifying an image producer or consumer.\nAdded an introductory section about the kinds of sharing available.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}, {'number': 5, 'created': '2017-02-10 05:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/666915d614308053049e525e04e034fc1c72794b', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also\nadded some text to clarify the implications of the owner_is_tenant\nconfiguration option when identifying an image producer or consumer.\nAdded an introductory section about the kinds of sharing available.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}, {'number': 6, 'created': '2017-02-16 21:26:50.000000000', 'files': ['specs/api/v2/sharing-image-api-v2.rst', 'specs/api/v2/image-metadata-api-v2.rst', 'specs/api/v2/shared-viz-note.inc'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/fbdd3381ca2f05e340b0439abdbcacfe7d88fd89', 'message': 'Update ""narrative"" api docs for visibility changes\n\nAdd documentation for the changes introduced by ""Implement and Enable\nCommunity Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also\nadded some text to clarify the implications of the owner_is_tenant\nconfiguration option when identifying an image producer or consumer.\nAdded an introductory section about the kinds of sharing available.\n\nChange-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544\n'}]",57,426605,fbdd3381ca2f05e340b0439abdbcacfe7d88fd89,38,6,6,5314,,,0,"Update ""narrative"" api docs for visibility changes

Add documentation for the changes introduced by ""Implement and Enable
Community Images"", I94bc7708b291ce37319539e27b3e88c9a17e1a9f.  Also
added some text to clarify the implications of the owner_is_tenant
configuration option when identifying an image producer or consumer.
Added an introductory section about the kinds of sharing available.

Change-Id: I58f39d4729e783a86999b1fe18debd97a3ebe544
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/05/426605/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/api/v2/sharing-image-api-v2.rst'],1,32e9d2978e5acfa6ac27a3a32f1e6da073500f32,update-docs-for-viz-change,"producer of shared images. A necessary condition for these calls to succeed is that the ``visibility`` field of the image referred to in the call has the value ``shared``.shared images. A necessary condition for these calls to succeed is that the ``visibility`` field of the image referred to in the call has the value ``shared``.consumers of shared images. A necessary condition for these calls to succeed is that the ``visibility`` field of the image referred to in the call has the value ``shared``. Image API v2 Community Images ----------------------------- Since version 2.5, the Image Service API v2 offers another kind of image sharing, *Community Images*. A community image is made available to all users in a cloud without the requirement of creating members on the image. A community image is an image whose ``visibility`` value is ``community``. The ability to communitize an image may be prohibited or restricted to specific users at the discreation of the cloud operator. Community images do not appear in the default image list of any user other than the image owner. In order to discover community images, make the image-list call with a 'visibility' filter: ``GET v2/images?visibility=community`` As with the standard image-list call, other filters may be applied to the request. For example, to see the community images supplied by the image producer identified by ``931efe8a-0ad7-4610-9116-c199f8807cda``, the following call would be made: ``GET v2/images?visibility=community&owner=931efe8a-0ad7-4610-9116-c199f8807cda``",producer of shared images.shared images.consumers of shared images.,34,3
openstack%2Ftripleo-quickstart~master~If76a4884b2376b8f13bcfa815d41ec279a7d261e,openstack/tripleo-quickstart,master,If76a4884b2376b8f13bcfa815d41ec279a7d261e,Update repo and image links for master release config,MERGED,2017-02-27 16:24:51.000000000,2017-02-28 21:50:48.000000000,2017-02-28 21:50:47.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 12715}]","[{'number': 1, 'created': '2017-02-27 16:24:51.000000000', 'files': ['config/release/master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7159f9f5191e77cf56ad13466aec1feae502b6dc', 'message': 'Update repo and image links for master release config\n\nThe repos and images for master release config, which\nwere linked to previously, were not being updated\nconsistently. This review changes the config file to point\nto the lastest master repos and images.\n\nChange-Id: If76a4884b2376b8f13bcfa815d41ec279a7d261e\n'}]",0,438582,7159f9f5191e77cf56ad13466aec1feae502b6dc,10,5,1,9976,,,0,"Update repo and image links for master release config

The repos and images for master release config, which
were linked to previously, were not being updated
consistently. This review changes the config file to point
to the lastest master repos and images.

Change-Id: If76a4884b2376b8f13bcfa815d41ec279a7d261e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/82/438582/1 && git format-patch -1 --stdout FETCH_HEAD,['config/release/master.yml'],1,7159f9f5191e77cf56ad13466aec1feae502b6dc,master-links-update,undercloud_image_url: https://images.rdoproject.org/master/delorean/current-tripleo/stable/undercloud.qcow2 overcloud_image_url: https://images.rdoproject.org/master/delorean/current-tripleo/stable/overcloud-full.tar ipa_image_url: https://images.rdoproject.org/master/delorean/current-tripleo/stable/ironic-python-agent.tar baseurl: https://trunk.rdoproject.org/centos7-master/current-tripleo-rdo/ hash_url: https://trunk.rdoproject.org/centos7-master/current-tripleo-rdo/delorean.repo,undercloud_image_url: http://buildlogs.centos.org/centos/7/cloud/x86_64/tripleo_images/master/delorean/undercloud.qcow2 overcloud_image_url: http://buildlogs.centos.org/centos/7/cloud/x86_64/tripleo_images/master/delorean/overcloud-full.tar ipa_image_url: http://buildlogs.centos.org/centos/7/cloud/x86_64/tripleo_images/master/delorean/ironic-python-agent.tar baseurl: http://buildlogs.centos.org/centos/7/cloud/x86_64/rdo-trunk-master-tested/ hash_url: http://buildlogs.centos.org/centos/7/cloud/x86_64/rdo-trunk-master-tested/delorean.repo,5,5
openstack%2Fvitrage~master~I82059975368007733de3087ea29903c5febb1881,openstack/vitrage,master,I82059975368007733de3087ea29903c5febb1881,Typo fix: Remove redundant quote mark,MERGED,2017-02-08 09:16:01.000000000,2017-02-28 21:48:07.000000000,2017-02-28 21:48:07.000000000,"[{'_account_id': 3}, {'_account_id': 19159}, {'_account_id': 20667}]","[{'number': 1, 'created': '2017-02-08 09:16:01.000000000', 'files': ['doc/source/add-new-datasource.rst'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b8cd6311e6661727d7fe5a5b637ebd8a47f4339e', 'message': 'Typo fix: Remove redundant quote mark\n\nChange-Id: I82059975368007733de3087ea29903c5febb1881\n'}]",0,430671,b8cd6311e6661727d7fe5a5b637ebd8a47f4339e,7,3,1,19935,,,0,"Typo fix: Remove redundant quote mark

Change-Id: I82059975368007733de3087ea29903c5febb1881
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/71/430671/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/add-new-datasource.rst'],1,b8cd6311e6661727d7fe5a5b637ebd8a47f4339e,, b. Edge that connects the vertex to its neighbor., b. Edge that connects the vertex to its' neighbor.,1,1
openstack%2Frpm-packaging~master~I399a91499afb1e5cc126c79e8bd674c315d83cc2,openstack/rpm-packaging,master,I399a91499afb1e5cc126c79e8bd674c315d83cc2,Update os-apply-config to 5.0.0,MERGED,2017-02-22 11:19:53.000000000,2017-02-28 21:43:15.000000000,2017-02-28 21:41:34.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-22 11:19:53.000000000', 'files': ['openstack/os-apply-config/os-apply-config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2f05e85a3aba92f973717e66ab30c60d90c3ff1f', 'message': 'Update os-apply-config to 5.0.0\n\nChange-Id: I399a91499afb1e5cc126c79e8bd674c315d83cc2\n'}]",0,436879,2f05e85a3aba92f973717e66ab30c60d90c3ff1f,14,6,1,6593,,,0,"Update os-apply-config to 5.0.0

Change-Id: I399a91499afb1e5cc126c79e8bd674c315d83cc2
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/79/436879/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-apply-config/os-apply-config.spec.j2'],1,2f05e85a3aba92f973717e66ab30c60d90c3ff1f,os_apply,Version: 5.0.0,Version: 0.1.32,1,1
openstack%2Ffuel-web~master~I4cd23769b7643aae7b149ba30e5b0e91a3021563,openstack/fuel-web,master,I4cd23769b7643aae7b149ba30e5b0e91a3021563,Fixed switch to deploying state for nodes which will not be deployed,MERGED,2017-01-23 15:27:06.000000000,2017-02-28 21:35:56.000000000,2017-02-28 21:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 18205}, {'_account_id': 19158}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2017-01-23 15:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/87493849b9652e76281f391c9af45e16401ea39d', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 2, 'created': '2017-01-23 19:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cb8df1dcb8f73559e14753b0d258f8129db77826', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 3, 'created': '2017-02-02 09:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/850c8b3b6df9dda2cbb535bbc7bed88e0952f764', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 4, 'created': '2017-02-07 16:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/afd70cb02c2b6dda8572b1545df583e54045f2f7', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 5, 'created': '2017-02-08 08:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e77f14efc95d3ad1b88ba24ee92c81da8017a4a6', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 6, 'created': '2017-02-08 09:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a087da47cce678b62e6f5d2b3fa26086078daaad', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}, {'number': 7, 'created': '2017-02-08 13:20:22.000000000', 'files': ['nailgun/nailgun/transactions/manager.py', 'nailgun/nailgun/test/unit/test_transactions_manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dc8fd092d3ac194fcd98888df42ce28de2b85e49', 'message': 'Fixed switch to deploying state for nodes which will not be deployed\n\nNodes can be exluded from deployment, if there is no tasks to run on this nodes.\nSuch nodes should not be switched to deployment state.\n\nChange-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563\n'}]",2,424192,dc8fd092d3ac194fcd98888df42ce28de2b85e49,146,10,7,18205,,,0,"Fixed switch to deploying state for nodes which will not be deployed

Nodes can be exluded from deployment, if there is no tasks to run on this nodes.
Such nodes should not be switched to deployment state.

Change-Id: I4cd23769b7643aae7b149ba30e5b0e91a3021563
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/92/424192/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/transactions/manager.py', 'nailgun/nailgun/test/unit/test_transactions_manager.py']",2,87493849b9652e76281f391c9af45e16401ea39d,," class TestPrepareNodes(BaseUnitTest): def test_apply_only_for_involved_nodes(self): nodes = [ mock.MagicMock(uid=1, progress=0, error_type='deployment', error_msg='test'), mock.MagicMock(uid=2, progress=0, error_type='provision', error_msg='test2') ] manager._prepare_nodes(nodes, False, {2}) self.assertEqual(0, nodes[0].progress) self.assertEqual('deployment', nodes[0].error_type) self.assertEqual('test', nodes[0].error_msg) self.assertEqual(1, nodes[0].progress) self.assertIsNone(nodes[1].error_type) self.assertIsNone(nodes[1].error_msg) def test_not_reset_error_if_dry_run(self): nodes = [mock.MagicMock(uid=1, progress=0, error_type='deployment', error_msg='test')] manager._prepare_nodes(nodes, True, {}) self.assertEqual(1, nodes[0].progress) self.assertEqual('deployment', nodes[0].error_type) self.assertEqual('test', nodes[0].error_msg)",,33,7
openstack%2Frpm-packaging~stable%2Focata~I7b0afa020b414d9faef279eb3b37a382ab888212,openstack/rpm-packaging,stable/ocata,I7b0afa020b414d9faef279eb3b37a382ab888212,Bump monasca-common to 1.5.0,MERGED,2017-02-27 12:39:15.000000000,2017-02-28 21:34:56.000000000,2017-02-28 21:33:34.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 13404}, {'_account_id': 16168}, {'_account_id': 19648}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-27 12:39:15.000000000', 'files': ['openstack/monasca-common/monasca-common.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5b1bb42d160f5411b4ba3050e36ad06e57a96db6', 'message': 'Bump monasca-common to 1.5.0\n\nmonasca-common 1.5.0 has been released,\nbumping version to latest tag\n\nChange-Id: I7b0afa020b414d9faef279eb3b37a382ab888212\n(cherry picked from commit 6548fdf5b145eb6fdb671d4568cd4f0f61b3eb65)\n'}]",0,438474,5b1bb42d160f5411b4ba3050e36ad06e57a96db6,13,6,1,16222,,,0,"Bump monasca-common to 1.5.0

monasca-common 1.5.0 has been released,
bumping version to latest tag

Change-Id: I7b0afa020b414d9faef279eb3b37a382ab888212
(cherry picked from commit 6548fdf5b145eb6fdb671d4568cd4f0f61b3eb65)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/74/438474/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-common/monasca-common.spec.j2'],1,5b1bb42d160f5411b4ba3050e36ad06e57a96db6,update-monasca-common,"Version: 1.5.0%if ""%{version}"" != ""1.5.0""","Version: 1.4.0%if ""%{version}"" != ""1.4.0""",2,2
openstack%2Frpm-packaging~stable%2Focata~I5cba9842a4a3d28d864928ac11525c90c30ddcae,openstack/rpm-packaging,stable/ocata,I5cba9842a4a3d28d864928ac11525c90c30ddcae,Update python-magnumclient to 2.4.0,MERGED,2017-02-23 19:21:12.000000000,2017-02-28 21:34:49.000000000,2017-02-28 21:33:11.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-23 19:21:12.000000000', 'files': ['openstack/python-magnumclient/0001-Add-magnum.bash_completion.patch', 'openstack/python-magnumclient/python-magnumclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a7858b440df36537d55dc85a3fadb8eef0c50ec6', 'message': 'Update python-magnumclient to 2.4.0\n\nRemove 0001-Add-magnum.bash_completion.patch which is now upstream.\n\nCo-Authored-by: Thomas Bechtold <tbechtold@suse.com>\nChange-Id: I5cba9842a4a3d28d864928ac11525c90c30ddcae\nDepends-on: I7dfbd87afba4f6bd3e9cf698fd0b9f53cb499eb4\n(cherry picked from commit e0b882019b4d33562200621ccafd765e63f009a6)\n'}]",0,437564,a7858b440df36537d55dc85a3fadb8eef0c50ec6,17,5,1,7102,,,0,"Update python-magnumclient to 2.4.0

Remove 0001-Add-magnum.bash_completion.patch which is now upstream.

Co-Authored-by: Thomas Bechtold <tbechtold@suse.com>
Change-Id: I5cba9842a4a3d28d864928ac11525c90c30ddcae
Depends-on: I7dfbd87afba4f6bd3e9cf698fd0b9f53cb499eb4
(cherry picked from commit e0b882019b4d33562200621ccafd765e63f009a6)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/64/437564/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/python-magnumclient/0001-Add-magnum.bash_completion.patch', 'openstack/python-magnumclient/python-magnumclient.spec.j2']",2,a7858b440df36537d55dc85a3fadb8eef0c50ec6,python-magnumclient,Version: 2.4.0BuildRequires: {{ py2pkg('osprofiler') }},Version: 2.3.1Patch0: 0001-Add-magnum.bash_completion.patch,2,51
openstack%2Fpython-barbicanclient~master~Icc56feab767e5154588f2e3e32e1ded3d8c62f09,openstack/python-barbicanclient,master,Icc56feab767e5154588f2e3e32e1ded3d8c62f09,Fix serializable issues when retrieving json format resources,MERGED,2017-02-09 09:31:32.000000000,2017-02-28 21:32:08.000000000,2017-02-28 21:32:08.000000000,"[{'_account_id': 3}, {'_account_id': 7973}, {'_account_id': 8623}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 16046}]","[{'number': 1, 'created': '2017-02-09 09:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/ec6ee9984c145913101ad3bf31bd6c70100e7f0d', 'message': 'Fix serializable issues when retrieving json format resources\n\nChange-Id: Icc56feab767e5154588f2e3e32e1ded3d8c62f09\nCloses-Bug: #1662144\n'}, {'number': 2, 'created': '2017-02-25 05:27:52.000000000', 'files': ['barbicanclient/cas.py', 'barbicanclient/acls.py', 'barbicanclient/tests/test_cas.py', 'barbicanclient/containers.py', 'barbicanclient/tests/test_acls.py', 'barbicanclient/orders.py', 'barbicanclient/tests/test_orders.py', 'barbicanclient/secrets.py', 'barbicanclient/tests/test_secrets.py', 'barbicanclient/tests/test_containers.py'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/2d745ee892a80928373bd8a6ea844e8e212a4a15', 'message': 'Fix serializable issues when retrieving json format resources\n\nChange-Id: Icc56feab767e5154588f2e3e32e1ded3d8c62f09\nCloses-Bug: #1662144\n'}]",0,431405,2d745ee892a80928373bd8a6ea844e8e212a4a15,10,7,2,21797,,,0,"Fix serializable issues when retrieving json format resources

Change-Id: Icc56feab767e5154588f2e3e32e1ded3d8c62f09
Closes-Bug: #1662144
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/05/431405/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbicanclient/cas.py', 'barbicanclient/acls.py', 'barbicanclient/containers.py', 'barbicanclient/tests/test_acls.py', 'barbicanclient/orders.py', 'barbicanclient/secrets.py']",6,ec6ee9984c145913101ad3bf31bd6c70100e7f0d,bug/1662144," created = self.created.isoformat() if self.created else None expiration = self.expiration.isoformat() if self.expiration else None created, expiration,"," self.created, self.expiration,",19,10
openstack%2Fglance~master~Id4ffcaaa79b6abe7c23b8d2f7ab628a99014a3a3,openstack/glance,master,Id4ffcaaa79b6abe7c23b8d2f7ab628a99014a3a3,Open Pike for data migrations,MERGED,2017-02-27 23:34:46.000000000,2017-02-28 21:29:58.000000000,2017-02-28 21:29:58.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 12807}, {'_account_id': 21722}]","[{'number': 1, 'created': '2017-02-27 23:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/17afb167ce5daacec24697b59c0eaaa22c521a21', 'message': 'Open Pike for data migrations\n\nChange CURRENT_RELEASE from ocata to pike to open Pike for data\nmigrations.\n\nChange-Id: Id4ffcaaa79b6abe7c23b8d2f7ab628a99014a3a3\n'}, {'number': 2, 'created': '2017-02-28 17:21:43.000000000', 'files': ['glance/db/migration.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0a400d07a44b721c68115652adefacd85b15f02a', 'message': 'Open Pike for data migrations\n\nChange CURRENT_RELEASE from ocata to pike to open Pike for data\nmigrations.\n\nChange-Id: Id4ffcaaa79b6abe7c23b8d2f7ab628a99014a3a3\nDepends-On: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n'}]",1,438736,0a400d07a44b721c68115652adefacd85b15f02a,18,5,2,8158,,,0,"Open Pike for data migrations

Change CURRENT_RELEASE from ocata to pike to open Pike for data
migrations.

Change-Id: Id4ffcaaa79b6abe7c23b8d2f7ab628a99014a3a3
Depends-On: I2a7dc86b88afaf0e5b878d79607f54125a35eb16
",git fetch https://review.opendev.org/openstack/glance refs/changes/36/438736/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/db/migration.py'],1,17afb167ce5daacec24697b59c0eaaa22c521a21,open-pike-for-migrations,CURRENT_RELEASE = 'pike',CURRENT_RELEASE = 'ocata',1,1
openstack%2Fnova~master~Ia826591a416774a777e08f286f257962fa776258,openstack/nova,master,Ia826591a416774a777e08f286f257962fa776258,api-ref: Body verification for os-hypervisors.inc,MERGED,2016-10-07 11:59:17.000000000,2017-02-28 21:29:29.000000000,2017-02-28 21:29:29.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15293}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17922}, {'_account_id': 19590}, {'_account_id': 20040}, {'_account_id': 20217}]","[{'number': 1, 'created': '2016-10-07 11:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f07a30c75a52d9649cb35193c87c643319442502', 'message': 'pi-ref: Body verification for os-hypervisors.inc\n\nChange-Id: Ia826591a416774a777e08f286f257962fa776258\nImplements: blueprint api-ref-in-rst-ocata\n'}, {'number': 2, 'created': '2016-12-08 10:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca0c9ea583c928865201e27c0b55ed36a9ed3045', 'message': 'pi-ref: Body verification for os-hypervisors.inc\n\nChange-Id: Ia826591a416774a777e08f286f257962fa776258\nImplements: blueprint api-ref-in-rst-ocata\n'}, {'number': 3, 'created': '2017-02-21 07:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6451786c175f762fce13010faa54869a5d04e11', 'message': 'pi-ref: Body verification for os-hypervisors.inc\n\nChange-Id: Ia826591a416774a777e08f286f257962fa776258\nImplements: blueprint api-ref-in-rst-ocata\n'}, {'number': 4, 'created': '2017-02-23 08:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5a5851608616943943b504839c8baa2e9626412', 'message': 'api-ref: Body verification for os-hypervisors.inc\n\nChange-Id: Ia826591a416774a777e08f286f257962fa776258\nImplements: blueprint api-ref-in-rst-pike\n'}, {'number': 5, 'created': '2017-02-28 11:36:05.000000000', 'files': ['api-ref/source/os-hypervisors.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/70f39ab57fd2b5903dd587aca3cf29263db7ed08', 'message': 'api-ref: Body verification for os-hypervisors.inc\n\nChange-Id: Ia826591a416774a777e08f286f257962fa776258\nImplements: blueprint api-ref-in-rst-pike\n'}]",8,383691,70f39ab57fd2b5903dd587aca3cf29263db7ed08,73,25,5,6062,,,0,"api-ref: Body verification for os-hypervisors.inc

Change-Id: Ia826591a416774a777e08f286f257962fa776258
Implements: blueprint api-ref-in-rst-pike
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/383691/4 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-hypervisors.inc'],1,f07a30c75a52d9649cb35193c87c643319442502,bp/api-ref-in-rst-pike,"for a hypervisor, list all servers on a given hypervisor or search hypervisor by given id.Shows details for a given hypervisor.Shows the uptime for a given hypervisor.List all servers belong to a given hypervisor.",.. needs:body_verificationfor a hypervisor.Shows details for a hypervisor.Shows the uptime for a hypervisor.List all servers belong to given hypervisor.,5,5
openstack%2Fnova~master~I3bc75d00d368a9c229d312ed6525fa8ddd5d4844,openstack/nova,master,I3bc75d00d368a9c229d312ed6525fa8ddd5d4844,Remove mox from nova.tests.unit.virt.xenapi.test_vmops[1],MERGED,2017-02-27 19:33:00.000000000,2017-02-28 21:29:00.000000000,2017-02-28 21:29:00.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 15334}, {'_account_id': 15751}]","[{'number': 1, 'created': '2017-02-27 19:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c004e03932b90881c9656480c01e27c3ebd771f0', 'message': 'Remove mox from nova.tests.unit.virt.xenapi.test_vmops.GetConsoleOutputTestCase\n\nPart of blueprint remove-mox-pike\n\nChange-Id: I3bc75d00d368a9c229d312ed6525fa8ddd5d4844\n'}, {'number': 2, 'created': '2017-02-27 19:35:03.000000000', 'files': ['nova/tests/unit/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/263b8e69704560beb54acf899545dbcd9b937cfb', 'message': 'Remove mox from nova.tests.unit.virt.xenapi.test_vmops[1]\n\nRemove mox from GetConsoleOutputTestCase in\nnova/tests/unit/virt/xenapi/test_vmops.py\n\nPart of blueprint remove-mox-pike\n\nChange-Id: I3bc75d00d368a9c229d312ed6525fa8ddd5d4844\n'}]",0,438678,263b8e69704560beb54acf899545dbcd9b937cfb,14,4,2,18337,,,0,"Remove mox from nova.tests.unit.virt.xenapi.test_vmops[1]

Remove mox from GetConsoleOutputTestCase in
nova/tests/unit/virt/xenapi/test_vmops.py

Part of blueprint remove-mox-pike

Change-Id: I3bc75d00d368a9c229d312ed6525fa8ddd5d4844
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/438678/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/xenapi/test_vmops.py'],1,c004e03932b90881c9656480c01e27c3ebd771f0,bp/remove-mox-pike," with mock.patch.object(self.vmops, '_get_last_dom_id', return_value=42) as mock_last_dom: self.assertEqual(b""dom_id: 42"", self.vmops.get_console_output(instance)) mock_last_dom.assert_called_once_with(instance, check_rescue=True) with mock.patch.object(self.vmops, '_get_last_dom_id', return_value=0) as mock_last_dom: self.assertRaises(exception.ConsoleNotAvailable, self.vmops.get_console_output, instance) mock_last_dom.assert_called_once_with(instance, check_rescue=True)"," self.mox.StubOutWithMock(self.vmops, '_get_last_dom_id') self.vmops._get_last_dom_id(instance, check_rescue=True).AndReturn(42) self.mox.ReplayAll() self.assertEqual(b""dom_id: 42"", self.vmops.get_console_output(instance)) self.mox.StubOutWithMock(self.vmops, '_get_last_dom_id') self.vmops._get_last_dom_id(instance, check_rescue=True).AndReturn(0) self.mox.ReplayAll() self.assertRaises(exception.ConsoleNotAvailable, self.vmops.get_console_output, instance)",10,14
openstack%2Fneutron-lbaas-dashboard~stable%2Focata~Ia791acfabfb6165eebcbc9dee53de96c7c21f033,openstack/neutron-lbaas-dashboard,stable/ocata,Ia791acfabfb6165eebcbc9dee53de96c7c21f033,Imported Translations from Zanata,MERGED,2017-02-23 07:25:30.000000000,2017-02-28 21:23:00.000000000,2017-02-28 21:23:00.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11628}]","[{'number': 1, 'created': '2017-02-23 07:25:30.000000000', 'files': ['neutron_lbaas_dashboard/locale/fr/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/a2e63f8488be5687722708489e7f63e5d5c487a0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Ia791acfabfb6165eebcbc9dee53de96c7c21f033\n'}]",0,437267,a2e63f8488be5687722708489e7f63e5d5c487a0,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Ia791acfabfb6165eebcbc9dee53de96c7c21f033
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/67/437267/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas_dashboard/locale/fr/LC_MESSAGES/django.po'],1,a2e63f8488be5687722708489e7f63e5d5c487a0,zanata/translations,"""Project-Id-Version: neutron-lbaas-dashboard 2.0.1.dev3\n""""POT-Creation-Date: 2017-02-21 16:09+0000\n""""PO-Revision-Date: 2017-02-22 03:44+0000\n""msgstr ""Impossible de crer un rpartiteur de charge complet""msgstr ""LB dsactivs""msgstr ""LB activs""msgstr ""Intervalle de test de l'tat de sant (en secondes)""msgstr ""Protocole de LB""msgstr ""Mthode de rpartition de charge""""Nombre de tentatives de vrification de l'tat de sant avant d'exclure un "" ""membre.""msgstr ""Fournir tous les paramtres du certificat.""msgstr ""Fournir le port de l'instance""""Slectionner une liste d'instances qui greront le trafic pour ce "" ""rpartiteur de charge. Toutes les instances doivent tre localises dans le "" ""mme Projet que le rpartiteur de charge.""msgstr ""Slectionner au moins un membre""msgstr ""Fournir une description du rpartiteur de charge""msgstr ""Statut du provisioning""msgstr ""Chane de caractres  recevoir""msgstr ""Nombre de tentatives avant d'exclure""msgstr ""SSL""msgstr ""Fin planifie de ""msgstr ""Slectionner parmi les VIP existantes""msgstr ""Chane de caractres  envoyer""msgstr ""Terminer""","""Project-Id-Version: neutron-lbaas-dashboard 2.0.1.dev2\n""""POT-Creation-Date: 2017-02-10 17:36+0000\n""""PO-Revision-Date: 2017-02-09 05:10+0000\n""msgstr ""Impossible de crer un rpartiteurs de charge complet""msgstr ""Dsactiver le LB""msgstr ""Activer le LB""msgstr ""Interval (en secondes) de l'tat de sant""msgstr ""Protocole du LB""msgstr ""Mthode d'quilibrage de charge""""Nombre de fois o nous devons vrifier l'tat de sant avant de marquer le "" ""membre comme mort.""msgstr ""Merci de fournir tous les paramtres du certificat.""msgstr ""Merci de fournir le port de l'instance""""Slectionner une liste d'instances qui greront le trafic pour ce load "" ""balancer. Toutes les instances doivent tre localises dans le mme Projet "" ""que le load balancer.""msgstr ""Merci de slectionner au moins un membre""msgstr ""Fournir une description pour le rpartiteur de charge""msgstr ""Statut de Dploiement""msgstr ""Chaine de caractres reue""msgstr ""Nombre d'essais avant de rduire""msgstr ""pas de support du ssl""msgstr ""Planification de la fin de""msgstr ""Slection depuis les IPs VIP existantes""msgstr ""Chaine de caractres envoye""msgstr ""Termin""",26,26
openstack%2Fneutron-fwaas~master~Ib53550b578ff5890eee3f32577692e81336110b3,openstack/neutron-fwaas,master,Ib53550b578ff5890eee3f32577692e81336110b3,Updated from global requirements,MERGED,2017-02-27 16:46:26.000000000,2017-02-28 21:12:15.000000000,2017-02-28 21:12:15.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 10850}]","[{'number': 1, 'created': '2017-02-27 16:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/1d799a627b22e29b1cb5f0b6dada029a08952d58', 'message': 'Updated from global requirements\n\nChange-Id: Ib53550b578ff5890eee3f32577692e81336110b3\n'}, {'number': 2, 'created': '2017-02-28 05:43:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/6f184936d9a041a69b162b6bfc5dfe77e9653e0c', 'message': 'Updated from global requirements\n\nChange-Id: Ib53550b578ff5890eee3f32577692e81336110b3\n'}]",0,438615,6f184936d9a041a69b162b6bfc5dfe77e9653e0c,11,4,2,11131,,,0,"Updated from global requirements

Change-Id: Ib53550b578ff5890eee3f32577692e81336110b3
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/15/438615/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1d799a627b22e29b1cb5f0b6dada029a08952d58,openstack/requirements,neutron-lib>=1.2.0 # Apache-2.0,neutron-lib>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-ansible-tests~master~I91cf30e4441900869e89eadf59814309da50e6d4,openstack/openstack-ansible-tests,master,I91cf30e4441900869e89eadf59814309da50e6d4,Use file lookup to store contents of key files,ABANDONED,2017-02-28 18:53:23.000000000,2017-02-28 21:04:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-28 18:53:23.000000000', 'files': ['test-prepare-keys.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/dfc9146d2554fb6b38c3a1e3660a21f67d5e1c82', 'message': 'Use file lookup to store contents of key files\n\nInstead of registering output from cat commands, use file lookups to\nstore the contents of the local public and private SSH keys.\n\nChange-Id: I91cf30e4441900869e89eadf59814309da50e6d4\n'}]",0,439105,dfc9146d2554fb6b38c3a1e3660a21f67d5e1c82,5,2,1,14805,,,0,"Use file lookup to store contents of key files

Instead of registering output from cat commands, use file lookups to
store the contents of the local public and private SSH keys.

Change-Id: I91cf30e4441900869e89eadf59814309da50e6d4
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/05/439105/1 && git format-patch -1 --stdout FETCH_HEAD,['test-prepare-keys.yml'],1,dfc9146d2554fb6b38c3a1e3660a21f67d5e1c82,lookup_keys," root_public_key: ""{{ lookup('file', '/root/.ssh/id_rsa.pub') }}"" root_private_key: ""{{ lookup('file', '/root/.ssh/id_rsa') }}"" lxc_container_ssh_key: ""{{ lookup('file', '/root/.ssh/id_rsa.pub') }}"""," - name: Get root private key command: cat /root/.ssh/id_rsa register: private_key_get changed_when: false - name: Get root public key command: cat /root/.ssh/id_rsa.pub register: public_key_get changed_when: false root_public_key: ""{{ public_key_get.stdout }}"" root_private_key: ""{{ private_key_get.stdout }}"" lxc_container_ssh_key: ""{{ public_key_get.stdout }}""",3,13
openstack%2Fopenstack-ansible-galera_server~master~I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,openstack/openstack-ansible-galera_server,master,I7638456239aa23a7e5cd6027d1a399cfdadf4aaa,Update galera running check for CentOS,MERGED,2017-01-30 21:33:19.000000000,2017-02-28 21:00:55.000000000,2017-02-03 10:33:12.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-01-30 21:33:19.000000000', 'files': ['tasks/galera_running_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/d898abff4e5bcb3aacd64837bbf28e83ed54a265', 'message': 'Update galera running check for CentOS\n\nThis patch fixes the galera running checks so that they work\nproperly on CentOS.\n\nCloses-Bug: 1660445\nChange-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa\n'}]",0,426934,d898abff4e5bcb3aacd64837bbf28e83ed54a265,10,3,1,538,,,0,"Update galera running check for CentOS

This patch fixes the galera running checks so that they work
properly on CentOS.

Closes-Bug: 1660445
Change-Id: I7638456239aa23a7e5cd6027d1a399cfdadf4aaa
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/34/426934/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_running_check.yml'],1,d898abff4e5bcb3aacd64837bbf28e83ed54a265,bug/1660445,"- name: Set fact for extra arguments in MySQL commands set_fact: mysql_extra_args: ""{{ ansible_os_family == 'Debian' | ternary('--defaults-file=/etc/mysql/debian.cnf', '') }}"" tags: - galera-cluster-state-check - galera-bootstrap command: ""/usr/bin/mysqladmin {{ mysql_extra_args }} ping"" shell: ""/usr/bin/mysqladmin {{ mysql_extra_args }} extended-status | egrep '(wsrep_ready|wsrep_evs_state)'"""," command: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf ping"" shell: ""/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf extended-status | egrep '(wsrep_ready|wsrep_evs_state)'""",9,2
openstack%2Fopenstack-ansible-galera_server~master~I4809ded8b6fe738f8fa700434739ee0b1f6d3af1,openstack/openstack-ansible-galera_server,master,I4809ded8b6fe738f8fa700434739ee0b1f6d3af1,Fix fact set using ternary filter,MERGED,2017-02-28 18:36:16.000000000,2017-02-28 20:50:18.000000000,2017-02-28 20:50:18.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-28 18:36:16.000000000', 'files': ['tasks/galera_install_apt.yml', 'tasks/galera_running_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/2f68deee8935d5bc24cb12819c464ba48fbfc5e2', 'message': ""Fix fact set using ternary filter\n\nWhen the set_fact module is used with the ternary filter the evaluated\ncondition must be surrounded in parentheses, otherwise the fact will\nalways be set to False.\n\nWhile other uses of ternary within this role don't seem to be effected,\nupdate them also for consistency and readability.\n\nChange-Id: I4809ded8b6fe738f8fa700434739ee0b1f6d3af1\n""}]",0,439098,2f68deee8935d5bc24cb12819c464ba48fbfc5e2,7,3,1,14805,,,0,"Fix fact set using ternary filter

When the set_fact module is used with the ternary filter the evaluated
condition must be surrounded in parentheses, otherwise the fact will
always be set to False.

While other uses of ternary within this role don't seem to be effected,
update them also for consistency and readability.

Change-Id: I4809ded8b6fe738f8fa700434739ee0b1f6d3af1
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/98/439098/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_install_apt.yml', 'tasks/galera_running_check.yml']",2,2f68deee8935d5bc24cb12819c464ba48fbfc5e2,fix_ternary_fact," mysql_extra_args: ""{{ (ansible_os_family == 'Debian') | ternary('--defaults-file=/etc/mysql/debian.cnf', '') }}"""," mysql_extra_args: ""{{ ansible_os_family == 'Debian' | ternary('--defaults-file=/etc/mysql/debian.cnf', '') }}""",3,3
openstack%2Fnetworking-sfc~master~I72b2561b3eac0eb28e6286e7ebcb3418a827034f,openstack/networking-sfc,master,I72b2561b3eac0eb28e6286e7ebcb3418a827034f,Sync the flake8 extensions with neutron-lib,MERGED,2017-02-28 17:06:47.000000000,2017-02-28 20:49:48.000000000,2017-02-28 20:49:48.000000000,"[{'_account_id': 3}, {'_account_id': 7776}, {'_account_id': 9396}, {'_account_id': 11313}]","[{'number': 1, 'created': '2017-02-28 17:06:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/f308fef5b1263520fa45fd123c45b7eb44029547', 'message': 'Sync the flake8 extensions with neutron-lib\n\nAs per https://docs.openstack.org/developer/neutron-lib/usage.html we\nshould enable any flake8 extensions neutron-libs tox.ini does\n\nChange-Id: I72b2561b3eac0eb28e6286e7ebcb3418a827034f\n'}]",0,439061,f308fef5b1263520fa45fd123c45b7eb44029547,9,4,1,21798,,,0,"Sync the flake8 extensions with neutron-lib

As per https://docs.openstack.org/developer/neutron-lib/usage.html we
should enable any flake8 extensions neutron-libs tox.ini does

Change-Id: I72b2561b3eac0eb28e6286e7ebcb3418a827034f
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/61/439061/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f308fef5b1263520fa45fd123c45b7eb44029547,hacking_checks,# From neutron-lib flake8 # H904: Delay string interpolations at logging calls enable-extensions=H904,,3,0
openstack%2Ftrove~master~I1a604b15ade815cdb51c5484d4285e504508a6c4,openstack/trove,master,I1a604b15ade815cdb51c5484d4285e504508a6c4,Install Redis 3.2.6 by compilation,MERGED,2017-01-03 21:58:56.000000000,2017-02-28 20:36:24.000000000,2017-02-28 20:36:24.000000000,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 14576}, {'_account_id': 20378}, {'_account_id': 22694}]","[{'number': 1, 'created': '2017-01-03 21:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/08f3cf991d1de80a5cf9e730b1e49800480cbdcb', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 2, 'created': '2017-01-05 22:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/86482d6b3cf382bad0a7985b404a7268cd92dd3a', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was also bumped to 3.2.6 and the Redis\ncluster tests reenabled.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 3, 'created': '2017-01-06 03:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7b75d7fece645043d01bd3ecd86923c27e222514', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was also bumped to 3.2.6 and the Redis\ncluster tests reenabled.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 4, 'created': '2017-01-06 14:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4ce4d983b65e102bd17cf13987a70668a6636d0d', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was also bumped to 3.2.6 and the Redis\ncluster tests reenabled.\n\nNew config options were added to the template,\nhowever these may need to be updated to make\nsure all the new ones are there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 5, 'created': '2017-01-06 16:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8a435269a8d51b63ba56ce57cbf0f7f77efde05a', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was also bumped to 3.2.6 and the Redis\ncluster tests reenabled.\n\nNew config options were added to the template,\nhowever these may need to be updated to make\nsure all the new ones are there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 6, 'created': '2017-01-07 07:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1b885b08d959919867daae8c07737e700726acaa', 'message': 'Install Redis by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was also bumped to 3.2.6 and the Redis\ncluster tests reenabled.\n\nNew config options were added to the template,\nhowever these may need to be updated to make\nsure all the new ones are there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 7, 'created': '2017-01-07 16:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ed7ee0eb94cbfc55c2e9a716f77be03b5a474190', 'message': 'Install Redis 3.2.6 by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was bumped to 3.2.6 (latest stable) however\nthe Redis cluster tests were not reenabled as there still\nseems to be an issue with them.\n\nNew config options were added to the template; these\nmay need to be updated to make sure all the new ones\nare there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 8, 'created': '2017-01-07 17:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/499f2ef6e7ba788998740500c090c4a147310ff3', 'message': 'Install Redis 3.2.6 by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was bumped to 3.2.6 (latest stable) however\nthe Redis cluster tests were not reenabled as there still\nseems to be an issue with them.\n\nNew config options were added to the template; these\nmay need to be updated to make sure all the new ones\nare there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 9, 'created': '2017-01-10 01:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/81d72087cd09bd51f90c75b9e320696d7b3b2ef9', 'message': 'Install Redis 3.2.6 by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was bumped to 3.2.6 (latest stable) however\nthe Redis cluster tests were not reenabled as there still\nseems to be an issue with them.\n\nNew config options were added to the template; these\nmay need to be updated to make sure all the new ones\nare there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 10, 'created': '2017-01-20 14:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d93fdfd7b55b100f1b0fff5850484a1b4f8d08ce', 'message': 'Install Redis 3.2.6 by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was bumped to 3.2.6 (latest stable) however\nthe Redis cluster tests were not reenabled as there still\nseems to be an issue with them.\n\nNew config options were added to the template; these\nmay need to be updated to make sure all the new ones\nare there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}, {'number': 11, 'created': '2017-02-16 17:10:06.000000000', 'files': ['integration/scripts/files/elements/ubuntu-redis/install.d/30-redis', 'trove/templates/redis/config.template', 'integration/scripts/trovestack', 'trove/tests/int_tests.py', 'trove/guestagent/datastore/experimental/redis/service.py', 'trove/tests/scenario/helpers/test_helper.py', 'trove/guestagent/datastore/experimental/redis/system.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/55d8598d206cdfbc7cc7c07fdf9ba2f5fa59e81d', 'message': 'Install Redis 3.2.6 by compilation\n\nThe version of Redis installed by the current elements\nuses a ppa that is stalled at 3.0.7.  This seems to\nhave some issues that are fixed in later versions.\n\nThe recommended method of installing Redis is to compile\nthe code yourself, so the elements have been changed\nto do this.\n\nThe version was bumped to 3.2.6 (latest stable) however\nthe Redis cluster tests were not reenabled as there still\nseems to be an issue with them.\n\nNew config options were added to the template; these\nmay need to be updated to make sure all the new ones\nare there.\n\nChange-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4\nPartial-Bug: 1652964\n'}]",2,416361,55d8598d206cdfbc7cc7c07fdf9ba2f5fa59e81d,55,7,11,10215,,,0,"Install Redis 3.2.6 by compilation

The version of Redis installed by the current elements
uses a ppa that is stalled at 3.0.7.  This seems to
have some issues that are fixed in later versions.

The recommended method of installing Redis is to compile
the code yourself, so the elements have been changed
to do this.

The version was bumped to 3.2.6 (latest stable) however
the Redis cluster tests were not reenabled as there still
seems to be an issue with them.

New config options were added to the template; these
may need to be updated to make sure all the new ones
are there.

Change-Id: I1a604b15ade815cdb51c5484d4285e504508a6c4
Partial-Bug: 1652964
",git fetch https://review.opendev.org/openstack/trove refs/changes/61/416361/4 && git format-patch -1 --stdout FETCH_HEAD,['integration/scripts/files/elements/ubuntu-redis/install.d/30-redis'],1,08f3cf991d1de80a5cf9e730b1e49800480cbdcb,bug/1652964,ARCH_SAV=$ARCH unset ARCH apt-get update apt-get --allow-unauthenticated install -y build-essential tcl curl cd /tmp curl -O http://download.redis.io/redis-stable.tar.gz tar xzvf redis-stable.tar.gz cd redis-stable make distclean make make install export ARCH=$ARCH_SAV,add-apt-repository -y ppa:chris-lea/redis-server apt-get -y update apt-get --allow-unauthenticated install -y redis-server,12,3
openstack%2Fopenstack-ansible-ceph_client~master~I5755e1e29dfa64ead729b6327135160dbecfe883,openstack/openstack-ansible-ceph_client,master,I5755e1e29dfa64ead729b6327135160dbecfe883,Add var for libvirt-bin package,MERGED,2017-02-28 14:05:10.000000000,2017-02-28 20:35:57.000000000,2017-02-28 20:35:57.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 14:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/d1a229cf9ac2eaf4bcfe38341de4eb53c8507c12', 'message': 'Remove libvirt-bin package from ceph_client role\n\nNova role should always be installed before ceph_client.\n\nChange-Id: I5755e1e29dfa64ead729b6327135160dbecfe883\n'}, {'number': 2, 'created': '2017-02-28 19:05:03.000000000', 'files': ['vars/redhat.yml', 'vars/ubuntu-16.04.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/d2453943c2dd411ab1b62411640dfe16002a4311', 'message': 'Add var for libvirt-bin package\n\nIn case of cinder being installed on compute_host libvirt needs to be installed\nby the ceph_client role.\n\nChange-Id: I5755e1e29dfa64ead729b6327135160dbecfe883\n'}]",0,438969,d2453943c2dd411ab1b62411640dfe16002a4311,13,4,2,13095,,,0,"Add var for libvirt-bin package

In case of cinder being installed on compute_host libvirt needs to be installed
by the ceph_client role.

Change-Id: I5755e1e29dfa64ead729b6327135160dbecfe883
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/69/438969/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/main.yml'],1,d1a229cf9ac2eaf4bcfe38341de4eb53c8507c12,fix-ceph-centos,, - libvirt-bin,0,1
openstack%2Ffuel-devops~release%2F2.9~I38f06021d488e282046e8d9d8233f56ef813ff0e,openstack/fuel-devops,release/2.9,I38f06021d488e282046e8d9d8233f56ef813ff0e,Move time-calculation based timeout check back to wait functions,MERGED,2017-02-27 12:51:12.000000000,2017-02-28 20:27:08.000000000,2017-02-28 20:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 11969}, {'_account_id': 15984}]","[{'number': 1, 'created': '2017-02-27 12:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a37aefa85611ceea99850ca02318da9971a0d30d', 'message': 'Move time-calculation based timeout check back to wait functions\n\nSeveral latest runs shows that paramiko interrupts signals set by\nRunLimit making it useless. Unfortunately there is no way to fix it\nin proper way fast. We can add time calculation back to ""wait"" functions\nfor preventing not catched timeouts.\n\nChange-Id: I38f06021d488e282046e8d9d8233f56ef813ff0e\nCloses-bug: 1668235\n'}, {'number': 2, 'created': '2017-02-27 12:56:12.000000000', 'files': ['devops/helpers/helpers.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/3449e7000e144e2bbba5693a4ebc2f1569e93f56', 'message': 'Move time-calculation based timeout check back to wait functions\n\nSeveral latest runs shows that paramiko interrupts signals set by\nRunLimit making it useless. Unfortunately there is no way to fix it\nin proper way fast. We can add time calculation back to ""wait"" functions\nfor preventing not catched timeouts.\n\nChange-Id: I38f06021d488e282046e8d9d8233f56ef813ff0e\nCloses-bug: 1668235\n'}]",0,438477,3449e7000e144e2bbba5693a4ebc2f1569e93f56,10,3,2,15984,,,0,"Move time-calculation based timeout check back to wait functions

Several latest runs shows that paramiko interrupts signals set by
RunLimit making it useless. Unfortunately there is no way to fix it
in proper way fast. We can add time calculation back to ""wait"" functions
for preventing not catched timeouts.

Change-Id: I38f06021d488e282046e8d9d8233f56ef813ff0e
Closes-bug: 1668235
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/77/438477/2 && git format-patch -1 --stdout FETCH_HEAD,['devops/helpers/helpers.py'],1,a37aefa85611ceea99850ca02318da9971a0d30d,bug/1668235," logger.debug(""RunLimit.__init__(timeout={0}, timeout_msg='{1}'"" .format(timeout, timeout_msg)) logger.debug(""RunLimit.handle_timeout reached!"") raise TimeoutError(self.error_message.format(spent=self.seconds)) time_remained = signal.alarm(0) logger.debug(""RunLimit.__exit__ , remained '{0}' sec"" .format(time_remained)) predicate_args, predicate_kwargs, interval, timeout): raise TypeError(""Not callable raising_predicate has been posted: '{0}'"" .format(predicate)) if not isinstance(predicate_args, (list, tuple)): raise TypeError(""Incorrect predicate_args type for '{0}', should be "" ""list or tuple, got '{1}'"" .format(predicate, type(predicate_args))) if interval <= 0: raise ValueError(""For '{0}(*{1}, **{2})', waiting interval '{3}'sec is"" "" wrong"".format(predicate, predicate_args, predicate_kwargs, interval)) if timeout <= 0: raise ValueError(""For '{0}(*{1}, **{2})', timeout '{3}'sec is "" ""wrong"".format(predicate, predicate_args, predicate_kwargs, timeout)) _check_wait_args(predicate, predicate_args, predicate_kwargs, interval, timeout) msg = ( ""{msg}\nWaited for pass {cmd}: {spent} seconds."" """".format( msg=timeout_msg, cmd=repr(predicate), spent=""{spent:0.3f}"" )) start_time = time.time() with RunLimit(timeout, msg): logger.debug(""wait() completed with result='{0}'"" .format(result)) if start_time + timeout < time.time(): err_msg = msg.format(spent=time.time() - start_time) logger.error(err_msg) raise TimeoutError(err_msg) time.sleep(interval) interval=5, timeout=60, timeout_msg=""Waiting timed out"", _check_wait_args(raising_predicate, predicate_args, predicate_kwargs, interval, timeout) msg = ( ""{msg}\nWaited for pass {cmd}: {spent} seconds."" """".format( msg=timeout_msg, cmd=repr(raising_predicate), spent=""{spent:0.3f}"" )) start_time = time.time() with RunLimit(timeout, msg): result = raising_predicate(*predicate_args, **predicate_kwargs) logger.debug(""wait_pass() completed with result='{0}'"" .format(result)) return result except expected as e: if start_time + timeout < time.time(): err_msg = msg.format(spent=time.time() - start_time) logger.error(err_msg) raise TimeoutError(err_msg) "," raise TimeoutError(self.error_message) signal.alarm(0) predicate_args=None, predicate_kwargs=None): raise TypeError('Not callable raising_predicate has been posted') if not isinstance(predicate_args, (list, tuple)): raise TypeError(""Incorrect predicate_args type, should be "" ""list or tuple, got {}"".format(type(predicate_args))) _check_wait_args(predicate, predicate_args, predicate_kwargs) with RunLimit(timeout, timeout_msg): else: time.sleep(interval) interval=5, timeout=None, timeout_msg=""Waiting timed out"", _check_wait_args(raising_predicate, predicate_args, predicate_kwargs) with RunLimit(timeout, timeout_msg): return raising_predicate(*predicate_args, **predicate_kwargs) except expected as e:",69,16
openstack%2Fproject-config~master~Ic5d1f0ebf7eb92c841ec09502e5134d89c8f6e97,openstack/project-config,master,Ic5d1f0ebf7eb92c841ec09502e5134d89c8f6e97,Add nodepool-id to infracloud-chocolate,MERGED,2017-02-28 15:14:34.000000000,2017-02-28 20:18:14.000000000,2017-02-28 20:18:14.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2017-02-28 15:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5a36195e42c58468eff7e269017781184aa68359', 'message': ""Add nodepool-id to infracloud-chocolate\n\nBecause we want to share infracloud-chocolate between nodepool.o.o and\nnl01.o.o, we need to use the new 'nodepool-id' for the provider.\nOtherwise, nodepool.o.o will proceed to delete the instances that\nnl01.o.o launches.\n\nChange-Id: Ic5d1f0ebf7eb92c841ec09502e5134d89c8f6e97\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 2, 'created': '2017-02-28 17:35:51.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/bf29a5b40636eab9dded23336145cf44559c450b', 'message': ""Add nodepool-id to infracloud-chocolate\n\nBecause we want to share infracloud-chocolate between nodepool.o.o and\nnl01.o.o, we need to use the new 'nodepool-id' for the provider.\nOtherwise, nodepool.o.o will proceed to delete the instances that\nnl01.o.o launches.\n\nChange-Id: Ic5d1f0ebf7eb92c841ec09502e5134d89c8f6e97\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,438998,bf29a5b40636eab9dded23336145cf44559c450b,9,3,2,4162,,,0,"Add nodepool-id to infracloud-chocolate

Because we want to share infracloud-chocolate between nodepool.o.o and
nl01.o.o, we need to use the new 'nodepool-id' for the provider.
Otherwise, nodepool.o.o will proceed to delete the instances that
nl01.o.o launches.

Change-Id: Ic5d1f0ebf7eb92c841ec09502e5134d89c8f6e97
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/438998/2 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,5a36195e42c58468eff7e269017781184aa68359,, max-servers: 50 nodepool-id: 'nodepool.openstack.org', max-servers: 100,2,1
openstack%2Fbarbican~master~I494a5138c67eccb159619e6a4a90dad2a0454f8d,openstack/barbican,master,I494a5138c67eccb159619e6a4a90dad2a0454f8d,Remove unused logging import,MERGED,2017-02-16 03:31:48.000000000,2017-02-28 20:14:30.000000000,2017-02-28 20:14:30.000000000,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 11561}]","[{'number': 1, 'created': '2017-02-16 03:31:48.000000000', 'files': ['barbican/common/quota.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/a1c563c1e4951d895f608e8f256730e21c1ead9b', 'message': 'Remove unused logging import\n\nChange-Id: I494a5138c67eccb159619e6a4a90dad2a0454f8d\n'}]",0,434613,a1c563c1e4951d895f608e8f256730e21c1ead9b,7,3,1,19935,,,0,"Remove unused logging import

Change-Id: I494a5138c67eccb159619e6a4a90dad2a0454f8d
",git fetch https://review.opendev.org/openstack/barbican refs/changes/13/434613/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/common/quota.py'],1,a1c563c1e4951d895f608e8f256730e21c1ead9b,,,from oslo_log import log as logging LOG = logging.getLogger(__name__),0,3
openstack%2Fbarbican~master~I7b62231bd862406eae40db50abe02b3713c9e228,openstack/barbican,master,I7b62231bd862406eae40db50abe02b3713c9e228,Updated from global requirements,MERGED,2017-02-27 10:53:33.000000000,2017-02-28 20:14:19.000000000,2017-02-28 20:14:19.000000000,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 11561}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-27 10:53:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c5a4462b5fa235d450aba77cbaba0695da790e60', 'message': 'Updated from global requirements\n\nChange-Id: I7b62231bd862406eae40db50abe02b3713c9e228\n'}]",0,438425,c5a4462b5fa235d450aba77cbaba0695da790e60,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I7b62231bd862406eae40db50abe02b3713c9e228
",git fetch https://review.opendev.org/openstack/barbican refs/changes/25/438425/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c5a4462b5fa235d450aba77cbaba0695da790e60,openstack/requirements,cryptography>=1.6 # BSD/Apache-2.0,"cryptography!=1.3.0,>=1.0 # BSD/Apache-2.0",1,1
openstack%2Fnova~master~I2834a33961b90821ac8084f65133c16210ee097d,openstack/nova,master,I2834a33961b90821ac8084f65133c16210ee097d,Stop using mox in compute/test_hypervisors.py,MERGED,2016-06-08 04:01:55.000000000,2017-02-28 20:13:33.000000000,2017-02-28 20:13:33.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 13719}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 18320}, {'_account_id': 20040}, {'_account_id': 20217}, {'_account_id': 21239}]","[{'number': 1, 'created': '2016-06-08 04:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a64cc2201889407270e35a20a7d0a76975e2eb18', 'message': 'Stop using mox from compute/test_hypervisors.py\n\nReplaced stubs.Set(obj, func) with MagicMock in\nnova/tests/unit/api/openstack/compute/test_hypervisors.py\n\nPart of blueprint remove-mox-newton\n\nChange-Id: I2834a33961b90821ac8084f65133c16210ee097d\n'}, {'number': 2, 'created': '2016-09-07 09:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/629981615cf85fe1ff1d15dd4c8aca9f26ba8d75', 'message': 'Stop using mox in compute/test_hypervisors.py\n\nPartially-Implements: blueprint remove-mox-ocata\n\nChange-Id: I2834a33961b90821ac8084f65133c16210ee097d\n'}, {'number': 3, 'created': '2017-01-16 09:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aac780fac4148639a3adcf6cfeb8c65b0bdecd47', 'message': 'Stop using mox in compute/test_hypervisors.py\n\nPartially-Implements: blueprint remove-mox-ocata\n\nChange-Id: I2834a33961b90821ac8084f65133c16210ee097d\n'}, {'number': 4, 'created': '2017-02-28 13:32:09.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_hypervisors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/407b92cc6a710788a5b58255fe756a75ea4889e8', 'message': 'Stop using mox in compute/test_hypervisors.py\n\nChange-Id: I2834a33961b90821ac8084f65133c16210ee097d\nPartially-Implements: blueprint remove-mox-pike'}]",10,326814,407b92cc6a710788a5b58255fe756a75ea4889e8,52,17,4,18320,,,0,"Stop using mox in compute/test_hypervisors.py

Change-Id: I2834a33961b90821ac8084f65133c16210ee097d
Partially-Implements: blueprint remove-mox-pike",git fetch https://review.opendev.org/openstack/nova refs/changes/14/326814/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/test_hypervisors.py'],1,a64cc2201889407270e35a20a7d0a76975e2eb18,bp/remove-mox-pike," host_api = self.controller.host_api host_api.compute_node_get_all = mock.MagicMock( side_effect=fake_compute_node_get_all) host_api.service_get_by_compute_host = mock.MagicMock( side_effect=fake_service_get_by_compute_host) host_api.compute_node_search_by_hypervisor = mock.MagicMock( side_effect=fake_compute_node_search_by_hypervisor) host_api.compute_node_get = mock.MagicMock( side_effect=fake_compute_node_get) self.assertEqual(self.INDEX_HYPER_DICTS[0], result) self.assertEqual(self.DETAIL_HYPERS_DICTS[0], result) self.assertEqual(expected_dict, result) self.assertEqual(dict(hypervisors=self.INDEX_HYPER_DICTS), result) self.assertEqual(dict(hypervisors=self.DETAIL_HYPERS_DICTS), result) self.assertEqual(dict(hypervisor=self.DETAIL_HYPERS_DICTS[0]), result) with mock.patch.object(self.controller.host_api, 'get_host_uptime', side_effect=exc.HTTPNotImplemented() ) as mock_get_uptime: req = self._get_request(True) self.assertRaises(exc.HTTPNotImplemented, self.controller.uptime, req, self.TEST_HYPERS_OBJ[0].id) self.assertEqual(1, mock_get_uptime.call_count) with mock.patch.object(self.controller.host_api, 'get_host_uptime', return_value=""fake uptime"" ) as mock_get_uptime: req = self._get_request(True) result = self.controller.uptime(req, self.TEST_HYPERS_OBJ[0].id) expected_dict = copy.deepcopy(self.INDEX_HYPER_DICTS[0]) expected_dict.update({'uptime': ""fake uptime""}) self.assertEqual(dict(hypervisor=expected_dict), result) self.assertEqual(1, mock_get_uptime.call_count) with mock.patch.object(self.controller.host_api, 'get_host_uptime', side_effect=exception.ComputeServiceUnavailable(host='dummy') ) as mock_get_uptime: req = self._get_request(True) self.assertRaises(exc.HTTPBadRequest, self.controller.uptime, req, self.TEST_HYPERS_OBJ[0].id) self.assertEqual(1, mock_get_uptime.call_count) self.assertEqual(dict(hypervisors=self.INDEX_HYPER_DICTS), result) with mock.patch.object(self.controller.host_api, 'compute_node_search_by_hypervisor', return_value=[]) as mock_node_search: req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.search, req, 'a') self.assertEqual(1, mock_node_search.call_count) self.assertEqual(dict(hypervisors=expected_dict), result) with mock.patch.object(self.controller.host_api, 'compute_node_search_by_hypervisor', return_value=[]) as mock_node_search: req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.servers, req, '115') self.assertEqual(1, mock_node_search.call_count) with mock.patch.object(self.controller.host_api, 'compute_node_search_by_hypervisor', return_value=[]) as mock_node_search: req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.servers, req, 'abc') self.assertEqual(1, mock_node_search.call_count) with mock.patch.object(self.controller.host_api, 'instance_get_all_by_host', return_value=[]) as mock_inst_get_all: req = self._get_request(True) result = self.controller.servers(req, self.TEST_HYPERS_OBJ[0].id) self.assertEqual(dict(hypervisors=self.INDEX_HYPER_DICTS), result) self.assertTrue(mock_inst_get_all.called) self.assertEqual(dict(hypervisor_statistics=dict( disk_available_least=200)), result) host_api = self.controller.host_api host_api.compute_node_get_all = mock.MagicMock( side_effect=self.fake_compute_node_get_all) host_api.service_get_by_compute_host = mock.MagicMock( side_effect=self.fake_service_get_by_compute_host) host_api.compute_node_search_by_hypervisor = mock.MagicMock( side_effect=self.fake_compute_node_search_by_hypervisor) host_api.compute_node_get = mock.MagicMock( side_effect=self.fake_compute_node_get) host_api.compute_node_statistics = mock.MagicMock( side_effect=fake_compute_node_statistics) host_api.instance_get_all_by_host = mock.MagicMock( side_effect=self.fake_instance_get_all_by_host)"," self.stubs.Set(self.controller.host_api, 'compute_node_get_all', fake_compute_node_get_all) self.stubs.Set(self.controller.host_api, 'service_get_by_compute_host', fake_service_get_by_compute_host) self.stubs.Set(self.controller.host_api, 'compute_node_search_by_hypervisor', fake_compute_node_search_by_hypervisor) self.stubs.Set(self.controller.host_api, 'compute_node_get', fake_compute_node_get) self.assertEqual(result, self.INDEX_HYPER_DICTS[0]) self.assertEqual(result, self.DETAIL_HYPERS_DICTS[0]) self.assertEqual(result, expected_dict) self.assertEqual(result, dict(hypervisors=self.INDEX_HYPER_DICTS)) self.assertEqual(result, dict(hypervisors=self.DETAIL_HYPERS_DICTS)) self.assertEqual(result, dict(hypervisor=self.DETAIL_HYPERS_DICTS[0])) def fake_get_host_uptime(context, hyp): raise exc.HTTPNotImplemented() self.stubs.Set(self.controller.host_api, 'get_host_uptime', fake_get_host_uptime) req = self._get_request(True) self.assertRaises(exc.HTTPNotImplemented, self.controller.uptime, req, self.TEST_HYPERS_OBJ[0].id) def fake_get_host_uptime(context, hyp): return ""fake uptime"" self.stubs.Set(self.controller.host_api, 'get_host_uptime', fake_get_host_uptime) req = self._get_request(True) result = self.controller.uptime(req, self.TEST_HYPERS_OBJ[0].id) expected_dict = copy.deepcopy(self.INDEX_HYPER_DICTS[0]) expected_dict.update({'uptime': ""fake uptime""}) self.assertEqual(result, dict(hypervisor=expected_dict)) def fake_get_host_uptime(context, hyp): raise exception.ComputeServiceUnavailable(host='dummy') self.stubs.Set(self.controller.host_api, 'get_host_uptime', fake_get_host_uptime) req = self._get_request(True) self.assertRaises(exc.HTTPBadRequest, self.controller.uptime, req, self.TEST_HYPERS_OBJ[0].id) self.assertEqual(result, dict(hypervisors=self.INDEX_HYPER_DICTS)) def fake_compute_node_search_by_hypervisor_return_empty(context, hypervisor_re): return [] self.stubs.Set(self.controller.host_api, 'compute_node_search_by_hypervisor', fake_compute_node_search_by_hypervisor_return_empty) req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.search, req, 'a') self.assertEqual(result, dict(hypervisors=expected_dict)) def fake_compute_node_search_by_hypervisor_return_empty(context, hypervisor_re): return [] self.stubs.Set(self.controller.host_api, 'compute_node_search_by_hypervisor', fake_compute_node_search_by_hypervisor_return_empty) req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.servers, req, '115') def fake_compute_node_search_by_hypervisor_return_empty(context, hypervisor_re): return [] self.stubs.Set(self.controller.host_api, 'compute_node_search_by_hypervisor', fake_compute_node_search_by_hypervisor_return_empty) req = self._get_request(True) self.assertRaises(exc.HTTPNotFound, self.controller.servers, req, 'abc') def fake_instance_get_all_by_host_return_empty(context, hypervisor_re): return [] self.stubs.Set(self.controller.host_api, 'instance_get_all_by_host', fake_instance_get_all_by_host_return_empty) req = self._get_request(True) result = self.controller.servers(req, self.TEST_HYPERS_OBJ[0].id) self.assertEqual(result, dict(hypervisors=self.INDEX_HYPER_DICTS)) self.assertEqual(result, dict(hypervisor_statistics=dict( disk_available_least=200))) self.stubs.Set(self.controller.host_api, 'compute_node_get_all', self.fake_compute_node_get_all) self.stubs.Set(self.controller.host_api, 'service_get_by_compute_host', self.fake_service_get_by_compute_host) self.stubs.Set(self.controller.host_api, 'compute_node_search_by_hypervisor', self.fake_compute_node_search_by_hypervisor) self.stubs.Set(self.controller.host_api, 'compute_node_get', self.fake_compute_node_get) self.stubs.Set(self.controller.host_api, 'compute_node_statistics', fake_compute_node_statistics) self.stubs.Set(self.controller.host_api, 'instance_get_all_by_host', self.fake_instance_get_all_by_host)",88,98
openstack%2Ftempest~master~I74c75baeecc4ae05d3769a9c19090d98cbff9998,openstack/tempest,master,I74c75baeecc4ae05d3769a9c19090d98cbff9998,Use base.attach_volume in test_attach_volume,MERGED,2017-02-28 07:13:37.000000000,2017-02-28 20:11:58.000000000,2017-02-28 20:11:57.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 8556}]","[{'number': 1, 'created': '2017-02-28 07:13:37.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/36f0a977cffa9a35e4cdec9dc2fce202f520996d', 'message': ""Use base.attach_volume in test_attach_volume\n\nThis is to use base.attach_volume to replace the internal\nfunction _attach_volume.\nBesides, in _detach_volume NotFound exception shouldn't be\nignored, so this is also to remove _detach_volume.\n\nChange-Id: I74c75baeecc4ae05d3769a9c19090d98cbff9998\n""}]",0,438821,36f0a977cffa9a35e4cdec9dc2fce202f520996d,8,3,1,20190,,,0,"Use base.attach_volume in test_attach_volume

This is to use base.attach_volume to replace the internal
function _attach_volume.
Besides, in _detach_volume NotFound exception shouldn't be
ignored, so this is also to remove _detach_volume.

Change-Id: I74c75baeecc4ae05d3769a9c19090d98cbff9998
",git fetch https://review.opendev.org/openstack/tempest refs/changes/21/438821/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/api/compute/volumes/test_attach_volume.py']",2,36f0a977cffa9a35e4cdec9dc2fce202f520996d,base_attach_volume," attachment = self.attach_volume(server, volume, device=('/dev/%s' % self.device)) self.servers_client.detach_volume(server['id'], attachment['volumeId']) waiters.wait_for_volume_resource_status( self.volumes_client, attachment['volumeId'], 'available') attachment = self.attach_volume(server, volume, device=('/dev/%s' % self.device)) attachment_1st = self.attach_volume(server, volume_1st) attachment_2nd = self.attach_volume(server, volume_2nd) attachment = self.attach_volume(server, volume, device=('/dev/%s' % self.device)) # Attach and then detach the volume self.attach_volume(server, volume, device=('/dev/%s' % self.device)) self.servers_client.detach_volume(server['id'], volume['id']) waiters.wait_for_volume_resource_status(self.volumes_client, volume['id'], 'available')","from tempest.lib import exceptions as lib_exc def _detach_volume(self, server_id, volume_id): try: self.servers_client.detach_volume(server_id, volume_id) waiters.wait_for_volume_resource_status(self.volumes_client, volume_id, 'available') except lib_exc.NotFound: LOG.warning(""Unable to detach volume %s from server %s "" ""possibly it was already detached"", volume_id, server_id) def _attach_volume(self, server_id, volume_id, device=None): # Attach the volume to the server kwargs = {'volumeId': volume_id} if device: kwargs.update({'device': '/dev/%s' % device}) attachment = self.servers_client.attach_volume( server_id, **kwargs)['volumeAttachment'] waiters.wait_for_volume_resource_status(self.volumes_client, volume_id, 'in-use') self.addCleanup(self._detach_volume, server_id, volume_id) return attachment attachment = self._attach_volume(server['id'], volume['id'], device=self.device) self._detach_volume(server['id'], attachment['volumeId']) attachment = self._attach_volume(server['id'], volume['id'], device=self.device) attachment_1st = self._attach_volume(server['id'], volume_1st['id']) attachment_2nd = self._attach_volume(server['id'], volume_2nd['id']) attachment = self._attach_volume(server['id'], volume['id'], device=self.device) self._attach_volume(server['id'], volume['id'], device=self.device) # Detach the volume self._detach_volume(server['id'], volume['id'])",21,39
openstack%2Fgovernance~master~Iff2156a09cb6aac25d6650d3fe561b78eb4fac1b,openstack/governance,master,Iff2156a09cb6aac25d6650d3fe561b78eb4fac1b,move the UX team to legacy status,MERGED,2017-02-24 16:02:05.000000000,2017-02-28 20:07:49.000000000,2017-02-28 20:07:49.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 970}, {'_account_id': 3153}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 5623}, {'_account_id': 5638}, {'_account_id': 6159}]","[{'number': 1, 'created': '2017-02-24 16:02:05.000000000', 'files': ['reference/legacy.yaml', 'reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/f42a93d7fcd81093d6805c846f029fb9e8bd686a', 'message': 'move the UX team to legacy status\n\nBased on earlier discussions [1], move the UX team information to the\nlegacy list.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2017-January/109622.html\n\nChange-Id: Iff2156a09cb6aac25d6650d3fe561b78eb4fac1b\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",1,437957,f42a93d7fcd81093d6805c846f029fb9e8bd686a,18,11,1,2472,,,0,"move the UX team to legacy status

Based on earlier discussions [1], move the UX team information to the
legacy list.

[1] http://lists.openstack.org/pipermail/openstack-dev/2017-January/109622.html

Change-Id: Iff2156a09cb6aac25d6650d3fe561b78eb4fac1b
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/57/437957/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/legacy.yaml', 'reference/projects.yaml']",2,f42a93d7fcd81093d6805c846f029fb9e8bd686a,formal-vote,,OpenStack UX: ptl: name: Piet Kruithof irc: Piet email: pkruithofjr@gmail.com irc-channel: openstack-ux mission: > The mission of the UX Program is to help the teams improve the overall user experience of their projects. url: https://wiki.openstack.org/wiki/UX deliverables: openstack-ux: repos: - openstack/openstack-ux ,15,15
openstack%2Fkolla-ansible~stable%2Focata~Idcdff687df84dc11c7855187c25d7c240aae2d8e,openstack/kolla-ansible,stable/ocata,Idcdff687df84dc11c7855187c25d7c240aae2d8e,Map cell0 and sync None cell before nova database upgrade,MERGED,2017-02-17 09:27:12.000000000,2017-02-28 19:59:07.000000000,2017-02-28 19:59:07.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-02-17 09:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/36c85c53a05e82b1b34d0939719909ca5b23dea1', 'message': 'Map cell0 and sync None cell before nova database upgrade\n\ncell0 is required as of Ocata release in nova,\nbefore upgrade need to be created.\nBy default in Newton cell0 is mapped to nova_api_cell0 database.\nTo avoid future issues, first map cell0 to default database\nin Ocata nova_cell0, then discover and sync None cell.\nNOTE: None cell is where current instances are running.\n\nTasks:\n* Map nova_cell0 before upgrade\n* Run simple_cell_setup to map and sync None cell\n* Follow common upgrade proceidure\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nCloses-Bug: #1665011\nChange-Id: Idcdff687df84dc11c7855187c25d7c240aae2d8e\n'}, {'number': 2, 'created': '2017-02-28 10:25:05.000000000', 'files': ['releasenotes/notes/create-nova-cells-upgrade-ccddf7259eba16dd.yaml', 'ansible/roles/nova/tasks/bootstrap.yml', 'ansible/roles/nova/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4265833cf8a31a38a54d43358d36221cf014da86', 'message': 'Map cell0 and sync None cell before nova database upgrade\n\ncell0 is required as of Ocata release in nova,\nbefore upgrade need to be created.\nBy default in Newton cell0 is mapped to nova_api_cell0 database.\nTo avoid future issues, first map cell0 to default database\nin Ocata nova_cell0, then discover and sync None cell.\nNOTE: None cell is where current instances are running.\n\nTasks:\n* Map nova_cell0 before upgrade\n* Run simple_cell_setup to map and sync None cell\n* Follow common upgrade proceidure\n\nCo-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>\nCloses-Bug: #1665011\nChange-Id: Idcdff687df84dc11c7855187c25d7c240aae2d8e\n'}]",0,435326,4265833cf8a31a38a54d43358d36221cf014da86,13,4,2,19316,,,0,"Map cell0 and sync None cell before nova database upgrade

cell0 is required as of Ocata release in nova,
before upgrade need to be created.
By default in Newton cell0 is mapped to nova_api_cell0 database.
To avoid future issues, first map cell0 to default database
in Ocata nova_cell0, then discover and sync None cell.
NOTE: None cell is where current instances are running.

Tasks:
* Map nova_cell0 before upgrade
* Run simple_cell_setup to map and sync None cell
* Follow common upgrade proceidure

Co-Authored-By: Eduardo Gonzalez <dabarren@gmail.com>
Closes-Bug: #1665011
Change-Id: Idcdff687df84dc11c7855187c25d7c240aae2d8e
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/26/435326/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/create-nova-cells-upgrade-ccddf7259eba16dd.yaml', 'ansible/roles/nova/tasks/bootstrap.yml', 'ansible/roles/nova/tasks/upgrade.yml']",3,36c85c53a05e82b1b34d0939719909ca5b23dea1,bug/1665011,"# TODO(Jeffrey4l): since nova need cell0 database in N->O, we need to call it. # It should be removed later - include: bootstrap.yml bootstrap_service=no # TODO(Jeffrey4l): Since nova need cell0 in N->O, we need to create it first. # This should be removed later # In newton branch, map_cell0 return nothing. So simple ignore any error here. - name: Creating nova cell0 command: > docker exec nova_api nova-manage cell_v2 map_cell0 --database_connection mysql+pymysql://{{ nova_database_user }}:{{ nova_database_password }}@{{ nova_database_address }}/{{ nova_database_name }}_cell0 failed_when: false run_once: True delegate_to: ""{{ groups['nova-api'][0] }}"" # Newton need transport-url, thats why is not using simple_cell_setup.yml file - name: Running nova simple cell setup command: > docker exec nova_api nova-manage cell_v2 simple_cell_setup --transport-url rabbit://{% for host in groups['rabbitmq'] %}{{ rabbitmq_user }}:{{ rabbitmq_password }}@{{ hostvars[host]['ansible_' + hostvars[host]['api_interface']]['ipv4']['address'] }}:{{ rabbitmq_port }}{% if not loop.last %},{% endif %}{% endfor %} register: cell_setup changed_when: - cell_setup | success - '""Cell0 is already setup"" not in cell_setup.stdout' run_once: True delegate_to: ""{{ groups['nova-api'][0] }}"" ","# TODO(inc0): since nova is creating new database in L->M, we need to call it. # It should be removed later - include: bootstrap.yml # TODO(Jeffrey4l): Since nova need setup nova cell in N->O, we need to call it. # This should be removed later - include: simple_cell_setup.yml ",38,9
openstack%2Fbarbican~master~I3947c566a24bfcf73a6a8076afccf77a2542848b,openstack/barbican,master,I3947c566a24bfcf73a6a8076afccf77a2542848b,Use https instead of http in git.openstack.org,ABANDONED,2017-02-23 07:29:59.000000000,2017-02-28 19:44:08.000000000,,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 11561}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-23 07:29:59.000000000', 'files': ['api-guide/source/conf.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/9856fc45c21e74395ca737455fe78bd61c1518f6', 'message': 'Use https instead of http in git.openstack.org\n\nChange-Id: I3947c566a24bfcf73a6a8076afccf77a2542848b\n'}]",0,437268,9856fc45c21e74395ca737455fe78bd61c1518f6,7,4,1,24924,,,0,"Use https instead of http in git.openstack.org

Change-Id: I3947c566a24bfcf73a6a8076afccf77a2542848b
",git fetch https://review.opendev.org/openstack/barbican refs/changes/68/437268/1 && git format-patch -1 --stdout FETCH_HEAD,['api-guide/source/conf.py'],1,9856fc45c21e74395ca737455fe78bd61c1518f6,barbican,"giturl = (u""https://git.openstack.org/cgit/openstack/barbican/tree/""","giturl = (u""http://git.openstack.org/cgit/openstack/barbican/tree/""",1,1
openstack%2Fbarbican~stable%2Fmitaka~Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,openstack/barbican,stable/mitaka,Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,** TEST - Do Not Merge **,ABANDONED,2016-10-12 15:08:48.000000000,2017-02-28 19:41:36.000000000,,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 8623}]","[{'number': 1, 'created': '2016-10-12 15:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/d2b5eae225e4d9b69cac750b9a457cf8701e1288', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}, {'number': 2, 'created': '2016-10-18 12:36:04.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/barbican/commit/11932ad730bb379c52391092807e207dd44dc0e9', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}]",0,385516,11932ad730bb379c52391092807e207dd44dc0e9,8,3,2,11561,,,0,"** TEST - Do Not Merge **

Change-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11
",git fetch https://review.opendev.org/openstack/barbican refs/changes/16/385516/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,d2b5eae225e4d9b69cac750b9a457cf8701e1288,stable/newton,,,1,0
openstack%2Fbarbican~stable%2Fnewton~Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,openstack/barbican,stable/newton,Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,** TEST - Do Not Merge **,ABANDONED,2016-10-12 14:39:51.000000000,2017-02-28 19:41:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 8623}, {'_account_id': 11561}]","[{'number': 1, 'created': '2016-10-12 14:39:51.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/barbican/commit/1e5218c6a84a2799cecb505f93c0cfaa9d0cde41', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}]",0,385502,1e5218c6a84a2799cecb505f93c0cfaa9d0cde41,8,4,1,11561,,,0,"** TEST - Do Not Merge **

Change-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11
",git fetch https://review.opendev.org/openstack/barbican refs/changes/02/385502/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,1e5218c6a84a2799cecb505f93c0cfaa9d0cde41,,,,1,0
openstack%2Ffuel-astute~stable%2Fnewton~I17db392ac4c73a3c08505fcbaf17dbcce96ebd91,openstack/fuel-astute,stable/newton,I17db392ac4c73a3c08505fcbaf17dbcce96ebd91,Fail tolerance behavior for upload file tasks,MERGED,2017-02-28 09:08:40.000000000,2017-02-28 19:39:37.000000000,2017-02-28 19:38:14.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 10959}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2017-02-28 09:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/4609a453f91cf5d01ef3bb960b728ccf897ba92c', 'message': 'Fail tolerance behavior for upload file tasks\n\nAdditional changes:\n\n- decrease number of ""reset undefined retries"" messages;\n- rewriting log messages for better understanding.\n\nChange-Id: I17db392ac4c73a3c08505fcbaf17dbcce96ebd91\nBlueprint: graph-concept-extension\n'}, {'number': 2, 'created': '2017-02-28 16:15:57.000000000', 'files': ['lib/astute/task_node.rb', 'lib/astute/mclients/upload_file_mclient.rb', 'lib/astute/mclients/shell_mclient.rb', 'lib/astute/puppet_job.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/3c0bc71a87eb0d623f182c943e83def9cf909229', 'message': 'Fail tolerance behavior for upload file tasks\n\nAdditional changes:\n\n- decrease number of ""reset undefined retries"" messages;\n- rewriting log messages for better understanding.\n\nChange-Id: I17db392ac4c73a3c08505fcbaf17dbcce96ebd91\nBlueprint: graph-concept-extension\n(cherry picked from commit 48ee1f746752e47b8d1735bbf25ba5ab3b0f1d4d)\n'}]",0,438866,3c0bc71a87eb0d623f182c943e83def9cf909229,31,8,2,3009,,,0,"Fail tolerance behavior for upload file tasks

Additional changes:

- decrease number of ""reset undefined retries"" messages;
- rewriting log messages for better understanding.

Change-Id: I17db392ac4c73a3c08505fcbaf17dbcce96ebd91
Blueprint: graph-concept-extension
(cherry picked from commit 48ee1f746752e47b8d1735bbf25ba5ab3b0f1d4d)
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/66/438866/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/task_node.rb', 'lib/astute/mclients/upload_file_mclient.rb', 'lib/astute/mclients/shell_mclient.rb', 'lib/astute/puppet_job.rb']",4,4609a453f91cf5d01ef3bb960b728ccf897ba92c,bp/graph-concept-extension, return if @undefined_retries == @original_undefined_retries ,,30,11
openstack%2Fcharm-percona-cluster~master~Iff998c4c23fcad71cffe9bbee60df7f00d2c9893,openstack/charm-percona-cluster,master,Iff998c4c23fcad71cffe9bbee60df7f00d2c9893,Ensure bootstrap-pxc mysqld not in unit cgroup,MERGED,2017-02-28 11:05:45.000000000,2017-02-28 19:37:53.000000000,2017-02-28 19:37:53.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20805}]","[{'number': 1, 'created': '2017-02-28 11:05:45.000000000', 'files': ['hooks/percona_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/fddc1b78f4251db97129f5246fff92fefb18353f', 'message': 'Ensure bootstrap-pxc mysqld not in unit cgroup\n\nThe bootstrap process for percona-xtradb-cluster requires execution\nof a non-standard init.d scrip target to start the mysqld in wsrep\nnew cluster mode.\n\nThe processes started by the operation where ending up in the cgroup\nassociated with the Juju unit daemon, which on restart (as a result\nof a upgrade to juju for example) would result in the mysql daemon\nbeing killed and not restarted.\n\nUse systemd-run to ensure that the bootstrap-pxc operation ends up\nin a distinct cgroup so that this does not happen.\n\nChange-Id: Iff998c4c23fcad71cffe9bbee60df7f00d2c9893\nCloses-Bug: 1664025\n'}]",0,438917,fddc1b78f4251db97129f5246fff92fefb18353f,11,4,1,935,,,0,"Ensure bootstrap-pxc mysqld not in unit cgroup

The bootstrap process for percona-xtradb-cluster requires execution
of a non-standard init.d scrip target to start the mysqld in wsrep
new cluster mode.

The processes started by the operation where ending up in the cgroup
associated with the Juju unit daemon, which on restart (as a result
of a upgrade to juju for example) would result in the mysql daemon
being killed and not restarted.

Use systemd-run to ensure that the bootstrap-pxc operation ends up
in a distinct cgroup so that this does not happen.

Change-Id: Iff998c4c23fcad71cffe9bbee60df7f00d2c9893
Closes-Bug: 1664025
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/17/438917/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/percona_utils.py'],1,fddc1b78f4251db97129f5246fff92fefb18353f,bug/1664025," # NOTE(jamespage): execute under systemd-run to ensure # that the bootstrap-pxc mysqld does # not end up in the juju unit daemons # cgroup scope. cmd = ['systemd-run', '-t', '--service-type=forking', 'service', 'mysql', 'bootstrap-pxc']"," cmd = ['service', 'mysql', 'bootstrap-pxc']",6,1
openstack%2Foctavia~master~I901baea1010f05f393919e5ecdd16dc1b322b213,openstack/octavia,master,I901baea1010f05f393919e5ecdd16dc1b322b213,Don't use Tempest internal methods,MERGED,2017-02-24 23:08:00.000000000,2017-02-28 19:34:06.000000000,2017-02-28 19:29:40.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 6854}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-24 23:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3596770c28c838c39bd18fde79dfbe8439cfa432', 'message': ""Don't use Tempest internal methods\n\nAll changed methods are clearly internal methods of Tempest, and the\nTempest commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb has removed\nthe internal methods and now the gate issue happens.\nThis patch makes this project to use better ones instead.\n\nChange-Id: I901baea1010f05f393919e5ecdd16dc1b322b213\n""}, {'number': 2, 'created': '2017-02-24 23:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/25cc919edcc9b211cd38e31ed810b5f2018752ad', 'message': ""Don't use Tempest internal methods\n\nAll changed methods are clearly internal methods of Tempest, and the\nTempest commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb has removed\nthe internal methods and now the gate issue happens.\nThis patch makes this project to use better ones instead.\n\nRelated-Bug: #1667824\nChange-Id: I901baea1010f05f393919e5ecdd16dc1b322b213\n""}, {'number': 3, 'created': '2017-02-24 23:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d3ae891274d7e6318335fe9d2cbc81ef863827ed', 'message': ""Don't use Tempest internal methods\n\nAll changed methods are clearly internal methods of Tempest, and the\nTempest commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb has removed\nthe internal methods and now the gate issue happens.\nThis patch makes this project to use better ones instead.\n\nRelated-Bug: #1667824\nChange-Id: I901baea1010f05f393919e5ecdd16dc1b322b213\n""}, {'number': 4, 'created': '2017-02-28 01:09:29.000000000', 'files': ['octavia/tests/tempest/v2/scenario/base.py', 'octavia/tests/tempest/v1/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6ea36282f4d88f347c82b4e1c0b64b4941d67dc8', 'message': ""Don't use Tempest internal methods\n\nAll changed methods are clearly internal methods of Tempest, and the\nTempest commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb has removed\nthe internal methods and now the gate issue happens.\nThis patch makes this project to use better ones instead.\n\nRelated-Bug: #1667824\nChange-Id: I901baea1010f05f393919e5ecdd16dc1b322b213\n""}]",3,438112,6ea36282f4d88f347c82b4e1c0b64b4941d67dc8,25,6,4,6167,,,0,"Don't use Tempest internal methods

All changed methods are clearly internal methods of Tempest, and the
Tempest commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb has removed
the internal methods and now the gate issue happens.
This patch makes this project to use better ones instead.

Related-Bug: #1667824
Change-Id: I901baea1010f05f393919e5ecdd16dc1b322b213
",git fetch https://review.opendev.org/openstack/octavia refs/changes/12/438112/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/tempest/v2/scenario/base.py', 'octavia/tests/tempest/v1/scenario/base.py']",2,3596770c28c838c39bd18fde79dfbe8439cfa432,bug/1667824, tenant_net = self.admin_manager.networks_client.list_networks( tenant_id=tenant_id)['networks'][0] tenant_subnet = self.admin_manager.subnets_client.list_subnets( tenant_id=tenant_id)['subnets'][0] subnet = self.admin_manager.networks_client.list_subnets( network_id=self.network['id'])['subnets'][0], tenant_net = self._list_networks(tenant_id=tenant_id)[0] tenant_subnet = self._list_subnets(tenant_id=tenant_id)[0] subnet = self._list_subnets(network_id=self.network['id'])[0],12,6
openstack%2Fpython-swiftclient~master~I9ef177aa96e4829196b5200dd8e9d0d2f7f89b63,openstack/python-swiftclient,master,I9ef177aa96e4829196b5200dd8e9d0d2f7f89b63,Expose --prefix as an option for st_delete,MERGED,2017-02-23 11:02:32.000000000,2017-02-28 19:22:01.000000000,2017-02-28 19:22:01.000000000,"[{'_account_id': 3}, {'_account_id': 15343}]","[{'number': 1, 'created': '2017-02-23 11:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/db6b0b1e4bc7d34e509a04d4b4d29c38d1105168', 'message': ""Expose --prefix as an option for st_delete\n\nThe SwiftService supports the ability to limit deletions\nto only those objects that match a specified prefix, so\nlet's expose that (really useful) behaviour to command\nline users as well :)\n\nChange-Id: I9ef177aa96e4829196b5200dd8e9d0d2f7f89b63\n""}, {'number': 2, 'created': '2017-02-23 11:10:10.000000000', 'files': ['swiftclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/91de5e8a385178b58cfeeb702c005ec2f2c5068a', 'message': ""Expose --prefix as an option for st_delete\n\nThe SwiftService and shell support the ability to limit\ndeletions to only those objects that match a specified\nprefix, so let's expose that (really useful) behaviour\nin the command line help as well :)\n\nChange-Id: I9ef177aa96e4829196b5200dd8e9d0d2f7f89b63\n""}]",0,437332,91de5e8a385178b58cfeeb702c005ec2f2c5068a,10,2,2,9216,,,0,"Expose --prefix as an option for st_delete

The SwiftService and shell support the ability to limit
deletions to only those objects that match a specified
prefix, so let's expose that (really useful) behaviour
in the command line help as well :)

Change-Id: I9ef177aa96e4829196b5200dd8e9d0d2f7f89b63
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/32/437332/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/shell.py'],1,db6b0b1e4bc7d34e509a04d4b4d29c38d1105168,delete-prefix," [--prefix <prefix>] --prefix <prefix> Only delete objects beginning with <prefix>. parser.add_argument( '-p', '--prefix', dest='prefix', help='Only delete objects beginning with <prefix>.')",,5,0
openstack%2Fbarbican~master~Icd576d9c40c7d75b6df3d2f27c94287ee235b0ab,openstack/barbican,master,Icd576d9c40c7d75b6df3d2f27c94287ee235b0ab,Allow for proper processing of command line arguments for all common executables.,ABANDONED,2016-11-08 23:24:53.000000000,2017-02-28 18:39:10.000000000,,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 24100}]","[{'number': 1, 'created': '2016-11-08 23:24:53.000000000', 'files': ['barbican/common/config.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/af74b1cfaa438f1e07023b157673d2a1f30a1830', 'message': 'Allow for proper processing of command line arguments for all common executables.\n\nChange-Id: Icd576d9c40c7d75b6df3d2f27c94287ee235b0ab\n'}]",0,395250,af74b1cfaa438f1e07023b157673d2a1f30a1830,5,3,1,24100,,,0,"Allow for proper processing of command line arguments for all common executables.

Change-Id: Icd576d9c40c7d75b6df3d2f27c94287ee235b0ab
",git fetch https://review.opendev.org/openstack/barbican refs/changes/50/395250/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/common/config.py'],1,af74b1cfaa438f1e07023b157673d2a1f30a1830,bug/1603499," conf(args,"," conf(args=args if args else [],",1,1
openstack%2Ftripleo-heat-templates~master~I88d7977fc67b8e4176ba97c988ea7ecace22c6c7,openstack/tripleo-heat-templates,master,I88d7977fc67b8e4176ba97c988ea7ecace22c6c7,Make sure we don't stop service when pacemaker is handling them.,ABANDONED,2017-02-24 21:45:00.000000000,2017-02-28 18:38:03.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6681}, {'_account_id': 8297}, {'_account_id': 18851}, {'_account_id': 20172}]","[{'number': 1, 'created': '2017-02-24 21:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8aacf016869284037ea29b93245a4b129af9c348', 'message': ""Make sure we don't stop service when pacemaker is handling them.\n\nWhen pacemaker is enabled we don't want to trigger the systemd stop\ncommand.\n\nChange-Id: I88d7977fc67b8e4176ba97c988ea7ecace22c6c7\n""}, {'number': 2, 'created': '2017-02-27 13:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87261a40e76d781406a91f64ca1cf09fb3e2ebc3', 'message': ""Make sure we don't stop service when pacemaker is handling them.\n\nWhen pacemaker is enabled we don't want to trigger the systemd stop\ncommand.\n\nChange-Id: I88d7977fc67b8e4176ba97c988ea7ecace22c6c7\n""}, {'number': 3, 'created': '2017-02-28 10:55:26.000000000', 'files': ['puppet/services/rabbitmq.yaml', 'puppet/services/haproxy.yaml', 'puppet/services/cinder-volume.yaml', 'puppet/services/database/mysql.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d197dc8662bc85b4925075fb334557aedae4281', 'message': ""Make sure we don't stop service when pacemaker is handling them.\n\nWhen pacemaker is enabled we don't want to trigger the systemd stop\ncommand.\n\nChange-Id: I88d7977fc67b8e4176ba97c988ea7ecace22c6c7\n""}]",0,438091,4d197dc8662bc85b4925075fb334557aedae4281,22,7,3,8297,,,0,"Make sure we don't stop service when pacemaker is handling them.

When pacemaker is enabled we don't want to trigger the systemd stop
command.

Change-Id: I88d7977fc67b8e4176ba97c988ea7ecace22c6c7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/438091/3 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/rabbitmq.yaml', 'puppet/services/haproxy.yaml', 'puppet/services/cinder-volume.yaml', 'puppet/services/database/mysql.yaml']",4,8aacf016869284037ea29b93245a4b129af9c348,bp/overcloud-upgrades-per-service, - name: get galera status command: hiera enable_galera register: enable_galera - name: set enable_galera fact tags: common set_fact: not_enable_galera={{enable_galera.stdout == 'false'}} when: not_enable_galera,,28,0
openstack%2Finstack-undercloud~master~Ic7928e5f7317e38a996d3573712898018ed80ae6,openstack/instack-undercloud,master,Ic7928e5f7317e38a996d3573712898018ed80ae6,Turn off propagation for undercloud logger,MERGED,2017-02-08 21:31:32.000000000,2017-02-28 18:35:16.000000000,2017-02-15 00:19:36.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-08 21:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/25c6c6e67c8cbbe287502cf347723e0ac0023be2', 'message': 'Turn off propagation for undercloud logger\n\nBecause we have our own log handler, if we allow messages to\npropagate to the parent loggers we may end up with duplicate log\nentries.\n\nChange-Id: Ic7928e5f7317e38a996d3573712898018ed80ae6\n'}, {'number': 2, 'created': '2017-02-09 17:49:23.000000000', 'files': ['instack_undercloud/undercloud.py', 'instack_undercloud/tests/test_undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/e28f501142c9e12b28eb59b26559ae682b547966', 'message': 'Turn off propagation for undercloud logger\n\nBecause we have our own log handler, if we allow messages to\npropagate to the parent loggers we may end up with duplicate log\nentries.\n\nChange-Id: Ic7928e5f7317e38a996d3573712898018ed80ae6\n'}]",0,431185,e28f501142c9e12b28eb59b26559ae682b547966,27,5,2,6928,,,0,"Turn off propagation for undercloud logger

Because we have our own log handler, if we allow messages to
propagate to the parent loggers we may end up with duplicate log
entries.

Change-Id: Ic7928e5f7317e38a996d3573712898018ed80ae6
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/85/431185/2 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,25c6c6e67c8cbbe287502cf347723e0ac0023be2,no-propagate, LOG.propagate = False,,1,0
openstack%2Fproject-config~master~I79ced2532d03701f50afc9d2a6e4a6e533e8228a,openstack/project-config,master,I79ced2532d03701f50afc9d2a6e4a6e533e8228a,layout: fix typo for tripleo/upgrade jobs,ABANDONED,2017-02-27 12:40:03.000000000,2017-02-28 18:30:14.000000000,,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 12:40:03.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5e2363f3f94f619babcf67dfbbfa2f1d49d9aa36', 'message': 'layout: fix typo for tripleo/upgrade jobs\n\nFix an empty space that cause the rule not applied for TripleO upgrade\njobs in stable branches.\n\nChange-Id: I79ced2532d03701f50afc9d2a6e4a6e533e8228a\n'}]",0,438475,5e2363f3f94f619babcf67dfbbfa2f1d49d9aa36,6,4,1,3153,,,0,"layout: fix typo for tripleo/upgrade jobs

Fix an empty space that cause the rule not applied for TripleO upgrade
jobs in stable branches.

Change-Id: I79ced2532d03701f50afc9d2a6e4a6e533e8228a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/75/438475/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5e2363f3f94f619babcf67dfbbfa2f1d49d9aa36,tripleo-ci/upgrades/scenarios, - name: ^gate-tripleo-ci-centos-7.*-upgrades.*$, - name : ^gate-tripleo-ci-centos-7.*-upgrades.*$,1,1
openstack%2Fpuppet-octavia~master~I9e4347c4ebf27d4b021bef15e9eff6b5e94d7e8e,openstack/puppet-octavia,master,I9e4347c4ebf27d4b021bef15e9eff6b5e94d7e8e,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:18:28.000000000,2017-02-28 18:25:38.000000000,2017-02-28 18:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/2b3cc27cfda8c1fccab8322395365c317e2f70e3', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I9e4347c4ebf27d4b021bef15e9eff6b5e94d7e8e\n'}, {'number': 2, 'created': '2017-02-28 17:10:45.000000000', 'files': ['spec/classes/octavia_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/12776513503a3ebcac99c027e5618b6a268e8c9e', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I9e4347c4ebf27d4b021bef15e9eff6b5e94d7e8e\n'}]",0,439009,12776513503a3ebcac99c027e5618b6a268e8c9e,9,2,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: I9e4347c4ebf27d4b021bef15e9eff6b5e94d7e8e
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/09/439009/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/octavia_init_spec.rb'],1,2b3cc27cfda8c1fccab8322395365c317e2f70e3,remove-rpc_backend,, is_expected.to contain_octavia_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Fpuppet-sahara~master~Ief45743d2c6a37cf30096ed0cd7c74e2baab6472,openstack/puppet-sahara,master,Ief45743d2c6a37cf30096ed0cd7c74e2baab6472,Remove rpc_backend check for amqp,ABANDONED,2017-02-28 15:18:54.000000000,2017-02-28 18:25:11.000000000,,[{'_account_id': 8971}],"[{'number': 1, 'created': '2017-02-28 15:18:54.000000000', 'files': ['spec/classes/sahara_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/81809184f0734aac07f7384329f6daec1a38ce54', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: Ief45743d2c6a37cf30096ed0cd7c74e2baab6472\n'}]",0,439010,81809184f0734aac07f7384329f6daec1a38ce54,3,1,1,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: Ief45743d2c6a37cf30096ed0cd7c74e2baab6472
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/10/439010/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/sahara_init_spec.rb'],1,81809184f0734aac07f7384329f6daec1a38ce54,remove-rpc_backend,, it { is_expected.to contain_sahara_config('DEFAULT/rpc_backend').with_value('amqp') },0,1
openstack%2Fpuppet-cloudkitty~master~I00e7c28b55ee4c0ae6b7e5c5f32e1da1b8261c76,openstack/puppet-cloudkitty,master,I00e7c28b55ee4c0ae6b7e5c5f32e1da1b8261c76,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:15:45.000000000,2017-02-28 18:19:04.000000000,2017-02-28 18:19:04.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/267512cecc4d8746bbff2bb38efc5e73ad1220a6', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I00e7c28b55ee4c0ae6b7e5c5f32e1da1b8261c76\n'}, {'number': 2, 'created': '2017-02-28 17:07:24.000000000', 'files': ['spec/classes/cloudkitty_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/a96ae153a73cf655682853de8d6de47a3bbcb1da', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: I00e7c28b55ee4c0ae6b7e5c5f32e1da1b8261c76\n'}]",0,439001,a96ae153a73cf655682853de8d6de47a3bbcb1da,9,2,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: I00e7c28b55ee4c0ae6b7e5c5f32e1da1b8261c76
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/01/439001/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/cloudkitty_init_spec.rb'],1,267512cecc4d8746bbff2bb38efc5e73ad1220a6,remove-rpc_backend,, is_expected.to contain_cloudkitty_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Fpuppet-vitrage~master~Idfd435bcf9e427cca824dc4809f3395b12f31b7e,openstack/puppet-vitrage,master,Idfd435bcf9e427cca824dc4809f3395b12f31b7e,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:21:22.000000000,2017-02-28 18:18:50.000000000,2017-02-28 18:18:50.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/7c9ac264aca58dd22faf145f34a7598c6c2847e3', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: Idfd435bcf9e427cca824dc4809f3395b12f31b7e\n'}, {'number': 2, 'created': '2017-02-28 17:11:05.000000000', 'files': ['spec/classes/vitrage_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/98f26f5b8f63a91ca3a196991daa81f0e3af12f0', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: Idfd435bcf9e427cca824dc4809f3395b12f31b7e\n'}]",0,439014,98f26f5b8f63a91ca3a196991daa81f0e3af12f0,9,2,2,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: Idfd435bcf9e427cca824dc4809f3395b12f31b7e
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/14/439014/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/vitrage_init_spec.rb'],1,7c9ac264aca58dd22faf145f34a7598c6c2847e3,remove-rpc_backend,, is_expected.to contain_vitrage_config('DEFAULT/rpc_backend').with_value('amqp'),0,1
openstack%2Ftripleo-ci~master~I0426f7d5213b41139a07ecc468d64e5d00a0f9f8,openstack/tripleo-ci,master,I0426f7d5213b41139a07ecc468d64e5d00a0f9f8,Nothing to see here,ABANDONED,2017-02-14 16:22:28.000000000,2017-02-28 18:18:14.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-14 16:22:28.000000000', 'files': ['toci_instack_ovb.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/af9d8cdf7b0e6cee46bc2281c96ca464a4d64be0', 'message': 'Nothing to see here\n\nChange-Id: I0426f7d5213b41139a07ecc468d64e5d00a0f9f8\nRelated-Bug: 1664418\n'}]",0,433755,af9d8cdf7b0e6cee46bc2281c96ca464a4d64be0,7,2,1,6928,,,0,"Nothing to see here

Change-Id: I0426f7d5213b41139a07ecc468d64e5d00a0f9f8
Related-Bug: 1664418
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/55/433755/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_instack_ovb.sh'],1,af9d8cdf7b0e6cee46bc2281c96ca464a4d64be0,bug/1664418,temprevert puppet-tripleo 3b00ffc728b47e132b3ed8bc460f8697ddb32047 1234567 temprevert puppet-tripleo bb63f514d22ea82d17947a5972b4da16e66b5a36 1234567,,2,0
openstack%2Fglance~master~I2a7dc86b88afaf0e5b878d79607f54125a35eb16,openstack/glance,master,I2a7dc86b88afaf0e5b878d79607f54125a35eb16,Mock CURRENT_RELEASE for migration unit test,MERGED,2017-02-21 19:14:38.000000000,2017-02-28 18:01:49.000000000,2017-02-28 18:01:49.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 8158}, {'_account_id': 21722}]","[{'number': 1, 'created': '2017-02-21 19:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7e805bc7740c3b9f2bb4cd4f761d17a37b302b5f', 'message': ""Mock CURRENT_RELEASE for migration unit test\n\nThe test_migrate unit test assumes that the CURRENT_VERSION set\nin migrations.py is 'ocata'.  Thus this test will break when\nthe alembic constants are updated for the Pike release.  This\npatch fixes the test by mocking the CURRENT_VERSION constant to\nbe what the test expects.\n\nChange-Id: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}, {'number': 2, 'created': '2017-02-27 17:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f3f72d20f9b49f0b48296bc028b12475dfb3b882', 'message': ""Mock CURRENT_RELEASE for migration unit test\n\nThe test_migrate unit test assumes that the CURRENT_VERSION set\nin migrations.py is 'ocata'.  Thus this test will break when\nthe alembic constants are updated for the Pike release.  This\npatch fixes the test by mocking the CURRENT_VERSION constant.\nThe migration identifiers are also renamed so that it's more\nobvious what this test is doing.\n\nChange-Id: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}, {'number': 3, 'created': '2017-02-27 22:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7078ba6f4df883c240dffde7c8a2f9c9625b9b96', 'message': ""Mock CURRENT_RELEASE for migration unit test\n\nThe test_migrate unit test assumes that the CURRENT_VERSION set\nin migrations.py is 'ocata'.  Thus this test will break when\nthe alembic constants are updated for the Pike release.  This\npatch fixes the test by mocking the CURRENT_VERSION constant\nwith an appropriate value.\n\nAdditionally, the migration identifiers used throughout the class\nTestDataMigrationFramework are modified so that they're clearly\nnot identifiers for existing migrations, as this was causing some\nconfusion.\n\nChange-Id: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}, {'number': 4, 'created': '2017-02-28 00:01:11.000000000', 'files': ['glance/tests/unit/test_data_migration_framework.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/83a565250976c86023a65808a2979638ac497d4b', 'message': ""Mock CURRENT_RELEASE for migration unit test\n\nThe test_migrate unit test assumes that the CURRENT_VERSION set\nin migrations.py is 'ocata'.  Thus this test will break when\nthe alembic constants are updated for the Pike release.  This\npatch fixes the test by mocking the CURRENT_VERSION constant\nwith an appropriate value.\n\nChange-Id: I2a7dc86b88afaf0e5b878d79607f54125a35eb16\n""}]",2,436593,83a565250976c86023a65808a2979638ac497d4b,22,5,4,5314,,,0,"Mock CURRENT_RELEASE for migration unit test

The test_migrate unit test assumes that the CURRENT_VERSION set
in migrations.py is 'ocata'.  Thus this test will break when
the alembic constants are updated for the Pike release.  This
patch fixes the test by mocking the CURRENT_VERSION constant
with an appropriate value.

Change-Id: I2a7dc86b88afaf0e5b878d79607f54125a35eb16
",git fetch https://review.opendev.org/openstack/glance refs/changes/93/436593/4 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/unit/test_data_migration_framework.py'],1,7e805bc7740c3b9f2bb4cd4f761d17a37b302b5f,fix-data-migration-test," @mock.patch('glance.db.migration.CURRENT_RELEASE', 'ocata')",,1,0
openstack%2Fpatrole~master~Icbc26b5a46e4b211d0c7dce12bd322932c0c3683,openstack/patrole,master,Icbc26b5a46e4b211d0c7dce12bd322932c0c3683,Add floating IP test cases for RBAC.,MERGED,2017-02-22 23:18:18.000000000,2017-02-28 17:55:22.000000000,2017-02-28 17:55:22.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 19391}, {'_account_id': 23184}, {'_account_id': 23185}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-02-22 23:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/14128d6fb6d26418e7efd07266208b3eff2e5e32', 'message': 'Add floating IP test cases for RBAC.\n\nChange-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683\n'}, {'number': 2, 'created': '2017-02-22 23:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/0b60172d173994a3d03c8e40534b2d8be25669b0', 'message': 'Add floating IP test cases for RBAC.\n\nChange-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683\n'}, {'number': 3, 'created': '2017-02-23 23:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/4dd841185a47f8bcce3452bf389e493c7a28f9f4', 'message': 'Add floating IP test cases for RBAC.\n\nChange-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683\nPartially-Implements: blueprint blueprint initial-tests-neutron\n'}, {'number': 4, 'created': '2017-02-27 21:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/2ad97dac492184d1ea84323c1a28ff0f5bd2f24b', 'message': 'Add floating IP test cases for RBAC.\n\nChange-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683\nPartially-Implements: blueprint blueprint initial-tests-neutron\n'}, {'number': 5, 'created': '2017-02-28 17:33:55.000000000', 'files': ['patrole_tempest_plugin/tests/api/network/test_floating_ips_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/48c36cea56df097f76cc3a6ce9f2aa74ac32a487', 'message': 'Add floating IP test cases for RBAC.\n\nChange-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683\nPartially-Implements: blueprint blueprint initial-tests-neutron\n'}]",36,437186,48c36cea56df097f76cc3a6ce9f2aa74ac32a487,34,6,5,19391,,,0,"Add floating IP test cases for RBAC.

Change-Id: Icbc26b5a46e4b211d0c7dce12bd322932c0c3683
Partially-Implements: blueprint blueprint initial-tests-neutron
",git fetch https://review.opendev.org/openstack/patrole refs/changes/86/437186/2 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/network/test_floating_ips_rbac.py'],1,14128d6fb6d26418e7efd07266208b3eff2e5e32,bp/blueprint,"# Copyright 2017 AT&T Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from patrole_tempest_plugin import rbac_rule_validation from patrole_tempest_plugin.rbac_utils import rbac_utils from patrole_tempest_plugin.tests.api.network import rbac_base as base from tempest import config from tempest.lib import decorators from tempest.lib.common.utils import data_utils from tempest.lib.common.utils import test_utils CONF = config.CONF class RbacFloatingIpsTest(base.BaseNetworkRbacTest): @classmethod def resource_setup(cls): super(RbacFloatingIpsTest, cls).resource_setup() # Create an external network for floating ip creation name = data_utils.rand_name('rbac-fip-extnet') post_body = {'name': name} post_body['router:external'] = True body = cls.networks_client.create_network(**post_body) cls.fip_extnet = body['network'] cls.fip_extnet_id = cls.fip_extnet['id'] cls.networks.append(cls.fip_extnet) # Create a subnet for the external network cls.cidr = netaddr.IPNetwork(CONF.network.rbac_network_cidr) cls.create_subnet(cls.fip_extnet, cidr=cls.cidr, mask_bits=24, implicit_clean=True) # Create resources for testing update floating ip network_name = data_utils.rand_name('rbac-fip-net') cls.network = cls.create_network(network_name=network_name) cls.subnet = cls.create_subnet(cls.network) cls.router = cls.create_router(data_utils.rand_name('rbac-router'), external_network_id=cls.fip_extnet_id) cls.create_router_interface(cls.router['id'], cls.subnet['id']) # Create two ports one each for Creation and Updating of floating ip cls.port = list() cls.create_port(cls.network) cls.create_port(cls.network) @classmethod def resource_cleanup(cls): cls.routers_client.remove_router_interface( cls.router['id'], subnet_id=cls.subnet['id']) super(RbacFloatingIpsTest, cls).resource_cleanup() def _create_floatingip(self, floating_ip_address=None): if floating_ip_address is not None: body = self.floating_ips_client.create_floatingip( floating_network_id=self.fip_extnet_id, port_id=self.ports[0]['id'], floating_ip_address=floating_ip_address) else: body = self.floating_ips_client.create_floatingip( floating_network_id=self.fip_extnet_id, port_id=self.ports[0]['id']) floating_ip = body['floatingip'] self.addCleanup(test_utils.call_and_ignore_notfound_exc, self.floating_ips_client.delete_floatingip, floating_ip['id']) return floating_ip def tearDown(self): rbac_utils.switch_role(self, switchToRbacRole=False) super(RbacFloatingIpsTest, self).tearDown() @rbac_rule_validation.action(service=""neutron"", rule=""create_floatingip"") @decorators.idempotent_id('f8f7474c-b8a5-4174-af84-73097d6ced38') def test_create_floating_ip(self): """"""Create floating IP. RBAC test for the neutron create_floatingip policy """""" rbac_utils.switch_role(self, switchToRbacRole=True) self._create_floatingip() @rbac_rule_validation.action(service=""neutron"", rule=""create_floatingip:floating_ip_address"") @decorators.idempotent_id('a8bb826a-403d-4130-a55d-120a0a660806') def test_create_floating_ip_floatingip_address(self): """"""Create floating IP with address. RBAC test for the neutron create_floatingip:floating_ip_address policy """""" fip = str(netaddr.IPAddress(self.cidr) + 10) rbac_utils.switch_role(self, switchToRbacRole=True) self._create_floatingip(floating_ip_address=fip) @rbac_rule_validation.action(service=""neutron"", rule=""update_floatingip"") @decorators.idempotent_id('2ab1b060-19f8-4ef6-a838-e2ab7b377c63') def test_update_floating_ip(self): """"""Update floating IP. RBAC test for the neutron update_floatingip policy """""" floating_ip = self._create_floatingip() rbac_utils.switch_role(self, switchToRbacRole=True) # Associate floating IP to the other port self.floating_ips_client.update_floatingip( floating_ip['id'], port_id=self.ports[1]['id']) @rbac_rule_validation.action(service=""neutron"", rule=""get_floatingip"") @decorators.idempotent_id('f8846fd0-c976-48fe-a148-105303931b32') def test_show_floating_ip(self): """"""Show floating IP. RBAC test for the neutron get_floatingip policy """""" floating_ip = self._create_floatingip() rbac_utils.switch_role(self, switchToRbacRole=True) # Show floating IP self.floating_ips_client.show_floatingip(floating_ip['id']) @rbac_rule_validation.action(service=""neutron"", rule=""delete_floatingip"") @decorators.idempotent_id('2611b068-30d4-4241-a78f-1b801a14db7e') def test_delete_floating_ip(self): """"""Delete floating IP. RBAC test for the neutron delete_floatingip policy """""" floating_ip = self._create_floatingip() rbac_utils.switch_role(self, switchToRbacRole=True) # Delete the floating IP self.floating_ips_client.delete_floatingip(floating_ip['id']) ",,161,0
openstack%2Fopenstack-ansible~master~Ia07969ac9aee90724eecc6657affd1dbe16045a7,openstack/openstack-ansible,master,Ia07969ac9aee90724eecc6657affd1dbe16045a7,Use an explicit version of urrlib3,MERGED,2017-02-28 14:26:17.000000000,2017-02-28 17:54:38.000000000,2017-02-28 16:06:00.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 22405}]","[{'number': 1, 'created': '2017-02-28 14:26:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/be08a064b609d24fe61fa7d187bd9c88bc4a3b3a', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the deploy node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and all the lookups with https had SSL issues. Moving to\nurllib3 fixed the thing.\n\nThis only cares about the ansible side, to ensure ansible venv\nhas the proper version. Hosts targetted by ansible (for example\nwhen using get_url), also need a fix. This will be done in\ndifferent patches.\n\nChange-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7\n""}]",0,438977,be08a064b609d24fe61fa7d187bd9c88bc4a3b3a,10,4,1,17068,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the deploy node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and all the lookups with https had SSL issues. Moving to
urllib3 fixed the thing.

This only cares about the ansible side, to ensure ansible venv
has the proper version. Hosts targetted by ansible (for example
when using get_url), also need a fix. This will be done in
different patches.

Change-Id: Ia07969ac9aee90724eecc6657affd1dbe16045a7
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/77/438977/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,be08a064b609d24fe61fa7d187bd9c88bc4a3b3a,urllib3,urllib3>=1.15.1 # MIT,,1,0
openstack%2Ffreezer~stable%2Focata~Ib5195bfcc7c087efe6abc39679ec03635c9b8913,openstack/freezer,stable/ocata,Ib5195bfcc7c087efe6abc39679ec03635c9b8913,Fix Cinder restore,MERGED,2017-02-28 14:52:32.000000000,2017-02-28 17:41:31.000000000,2017-02-28 17:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 14340}, {'_account_id': 14509}]","[{'number': 1, 'created': '2017-02-28 14:52:32.000000000', 'files': ['freezer/openstack/restore.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/e10cbe01efac96c509b18b5437b93e964bc869b1', 'message': ""Fix Cinder restore\n\nProvide alternative names to newly restored volume in case of the\nprevious name doesn't exists in the metadata\n\nChange-Id: Ib5195bfcc7c087efe6abc39679ec03635c9b8913\n""}]",0,438988,e10cbe01efac96c509b18b5437b93e964bc869b1,7,3,1,13940,,,0,"Fix Cinder restore

Provide alternative names to newly restored volume in case of the
previous name doesn't exists in the metadata

Change-Id: Ib5195bfcc7c087efe6abc39679ec03635c9b8913
",git fetch https://review.opendev.org/openstack/freezer refs/changes/88/438988/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/openstack/restore.py'],1,e10cbe01efac96c509b18b5437b93e964bc869b1,,"from oslo_config import cfgCONF = cfg.CONF volume = cinder_client.volumes.create( size, imageRef=image.id, name=info.get('volume_name', CONF.get('backup_name', CONF.get('cinder_vol_id', None) ) ) )"," volume = cinder_client.volumes.create(size, imageRef=image.id, name=info['volume_name'])",11,3
openstack%2Fnetworking-calico~master~Iab62d0d54be99c3f64cbf26c5dc665ae9aa7197f,openstack/networking-calico,master,Iab62d0d54be99c3f64cbf26c5dc665ae9aa7197f,Removes unnecessary utf-8 coding,MERGED,2016-12-26 07:59:41.000000000,2017-02-28 17:35:20.000000000,2017-02-28 17:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 13734}, {'_account_id': 25173}]","[{'number': 1, 'created': '2016-12-26 07:59:41.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/bd97477b2f37d70a7b44fc24b308ebd1b9c568df', 'message': 'Removes unnecessary utf-8 coding\n\nThe file was added redundant utf-8 coding by some editor.\nwe can delete it .\n\nChange-Id: Iab62d0d54be99c3f64cbf26c5dc665ae9aa7197f\n'}]",1,414872,bd97477b2f37d70a7b44fc24b308ebd1b9c568df,17,4,1,22484,,,0,"Removes unnecessary utf-8 coding

The file was added redundant utf-8 coding by some editor.
we can delete it .

Change-Id: Iab62d0d54be99c3f64cbf26c5dc665ae9aa7197f
",git fetch https://review.opendev.org/openstack/networking-calico refs/changes/72/414872/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,bd97477b2f37d70a7b44fc24b308ebd1b9c568df,bug/gengchc,,# -*- coding: utf-8 -*-,0,1
openstack%2Ftripleo-heat-templates~master~I61b4ac064185e8ddb1ce4d0ea61768419c86621c,openstack/tripleo-heat-templates,master,I61b4ac064185e8ddb1ce4d0ea61768419c86621c,Move horizon httpd to be stopped at step1,ABANDONED,2017-02-28 17:31:07.000000000,2017-02-28 17:32:19.000000000,,[{'_account_id': 3153}],"[{'number': 1, 'created': '2017-02-28 17:31:07.000000000', 'files': ['puppet/services/horizon.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4fd2db039c40e6750caf06d72dc02af99d84cc46', 'message': 'Move horizon httpd to be stopped at step1\n\nAs we agreed on IRC httpd should be stopped at\nstep1\n\nChange-Id: I61b4ac064185e8ddb1ce4d0ea61768419c86621c\n'}]",0,439069,4fd2db039c40e6750caf06d72dc02af99d84cc46,2,1,1,20775,,,0,"Move horizon httpd to be stopped at step1

As we agreed on IRC httpd should be stopped at
step1

Change-Id: I61b4ac064185e8ddb1ce4d0ea61768419c86621c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/69/439069/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/horizon.yaml'],1,4fd2db039c40e6750caf06d72dc02af99d84cc46,, tags: step1, tags: step2,1,1
openstack%2Ftripleo-ci~master~I17dbd0028451d3441274bcd3eb1d247eb29d1fba,openstack/tripleo-ci,master,I17dbd0028451d3441274bcd3eb1d247eb29d1fba,Add gate-tripleo-ci-centos-7-ovb-updates into promotion pipeline,MERGED,2017-02-14 17:07:45.000000000,2017-02-28 17:31:21.000000000,2017-02-28 17:31:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2017-02-14 17:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/edc9a5111befbbd6d19cbfa4344f633113cc9cdd', 'message': ""Add gate-tripleo-ci-centos-7-ovb-updates into promotion pipeline\n\nWhen Ocata will be released, we want to add\ngate-tripleo-ci-centos-7-ovb-updates in the promotion pipeline to be\nable to detect issues related to networking & IPv6 when testing new\nversions of OpenStack.\n\nWe have seen some cases where gate-tripleo-ci-centos-7-ovb-updates broke\nbecause of some changes in OpenStack. Let's add it into the pipeline to\navoid this situation again.\n\nChange-Id: I17dbd0028451d3441274bcd3eb1d247eb29d1fba\n""}, {'number': 2, 'created': '2017-02-27 19:01:23.000000000', 'files': ['scripts/mirror-server/mirror-server.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/646daa0a5abff94f1bf5512754d3d7b20ce7031a', 'message': ""Add gate-tripleo-ci-centos-7-ovb-updates into promotion pipeline\n\nWhen Ocata will be released, we want to add\ngate-tripleo-ci-centos-7-ovb-updates in the promotion pipeline to be\nable to detect issues related to networking & IPv6 when testing new\nversions of OpenStack.\n\nWe have seen some cases where gate-tripleo-ci-centos-7-ovb-updates broke\nbecause of some changes in OpenStack. Let's add it into the pipeline to\navoid this situation again.\n\nChange-Id: I17dbd0028451d3441274bcd3eb1d247eb29d1fba\n""}]",0,433796,646daa0a5abff94f1bf5512754d3d7b20ce7031a,15,4,2,3153,,,0,"Add gate-tripleo-ci-centos-7-ovb-updates into promotion pipeline

When Ocata will be released, we want to add
gate-tripleo-ci-centos-7-ovb-updates in the promotion pipeline to be
able to detect issues related to networking & IPv6 when testing new
versions of OpenStack.

We have seen some cases where gate-tripleo-ci-centos-7-ovb-updates broke
because of some changes in OpenStack. Let's add it into the pipeline to
avoid this situation again.

Change-Id: I17dbd0028451d3441274bcd3eb1d247eb29d1fba
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/96/433796/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/mirror-server/mirror-server.pp'],1,edc9a5111befbbd6d19cbfa4344f633113cc9cdd,ovb/promo," command => ""timeout 10m /opt/stack/tripleo-ci/scripts/mirror-server/promote.sh current-tripleo periodic-tripleo-ci-centos-7-ovb-ha periodic-tripleo-ci-centos-7-ovb-nonha periodic-tripleo-ci-centos-7-ovb-updates &>/var/log/last_promotion.log"","," command => ""timeout 10m /opt/stack/tripleo-ci/scripts/mirror-server/promote.sh current-tripleo periodic-tripleo-ci-centos-7-ovb-ha periodic-tripleo-ci-centos-7-ovb-nonha &>/var/log/last_promotion.log"",",1,1
openstack%2Ftripleo-ci~master~I8ed295d42135f235c4550fa23f4ddd88c418e67f,openstack/tripleo-ci,master,I8ed295d42135f235c4550fa23f4ddd88c418e67f,upgrade jobs: execute stable pingtest (and not master),ABANDONED,2017-02-27 17:47:04.000000000,2017-02-28 17:30:17.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-27 17:47:04.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/59103a0019e57b9a9ffc3d647cc2fa643b0c2a18', 'message': 'upgrade jobs: execute stable pingtest (and not master)\n\nFor now, we don\'t deploy new services when upgrading scenarios, so we\nwant to run the pingtest from stable/newton.\n\nThis patch will be reverted once our CI jobs deploy new services during\nthe upgrade process. The blocker for that is we need to change the way\nupgrade is done, because Ansible Validations verifies that new services\nare actually working, so we need to use systemctl to validate that\nbefore. We could also use ""SkipUpgradeConfigTags: validation"" parameter\nso the upgrade won\'t fail with new services, but we\'re loosing nice\ncoverage.\n\nSo in the meantime we figure all of this, let\'s run pingtest from\nstable/newton and iterate later.\n\nChange-Id: I8ed295d42135f235c4550fa23f4ddd88c418e67f\n'}]",0,438642,59103a0019e57b9a9ffc3d647cc2fa643b0c2a18,5,2,1,3153,,,0,"upgrade jobs: execute stable pingtest (and not master)

For now, we don't deploy new services when upgrading scenarios, so we
want to run the pingtest from stable/newton.

This patch will be reverted once our CI jobs deploy new services during
the upgrade process. The blocker for that is we need to change the way
upgrade is done, because Ansible Validations verifies that new services
are actually working, so we need to use systemctl to validate that
before. We could also use ""SkipUpgradeConfigTags: validation"" parameter
so the upgrade won't fail with new services, but we're loosing nice
coverage.

So in the meantime we figure all of this, let's run pingtest from
stable/newton and iterate later.

Change-Id: I8ed295d42135f235c4550fa23f4ddd88c418e67f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/42/438642/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,59103a0019e57b9a9ffc3d647cc2fa643b0c2a18,pingtest," if [[ ""$TOCI_JOBTYPE"" =~ upgrades ]]; then # For now, we want to run pingtest on things we know it worked on the stable deployment # and see if we're still able to create resources like before. # In the future, we'll run pingtest from master so we can validate new services have been added # and actually work. TENANT_PINGTEST_TEMPLATE=$TRIPLEO_ROOT/$UPGRADE_RELEASE/usr/share/openstack-tripleo-heat-templates/ci/pingtests/$MULTINODE_ENV_NAME.yaml else TENANT_PINGTEST_TEMPLATE=/usr/share/openstack-tripleo-heat-templates/ci/pingtests/$MULTINODE_ENV_NAME.yaml fi", TENANT_PINGTEST_TEMPLATE=/usr/share/openstack-tripleo-heat-templates/ci/pingtests/$MULTINODE_ENV_NAME.yaml,9,1
openstack%2Ftripleo-heat-templates~master~Ia2092de2792fa62319ed78521c6219c9effdfb79,openstack/tripleo-heat-templates,master,Ia2092de2792fa62319ed78521c6219c9effdfb79,DNM - test upgrades with stable pingtest,ABANDONED,2017-02-27 17:49:52.000000000,2017-02-28 17:30:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-27 17:49:52.000000000', 'files': ['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/20e4b5aea6ec333745be3dae085573d927231437', 'message': 'DNM - test upgrades with stable pingtest\n\nChange-Id: Ia2092de2792fa62319ed78521c6219c9effdfb79\nDepends-On: I8ed295d42135f235c4550fa23f4ddd88c418e67f\n'}]",0,438644,20e4b5aea6ec333745be3dae085573d927231437,4,1,1,3153,,,0,"DNM - test upgrades with stable pingtest

Change-Id: Ia2092de2792fa62319ed78521c6219c9effdfb79
Depends-On: I8ed295d42135f235c4550fa23f4ddd88c418e67f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/438644/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml']",3,20e4b5aea6ec333745be3dae085573d927231437,stable/test,,#test #,0,5
openstack%2Ftripleo-heat-templates~master~Ifccae8a73566ab159d48a2a1b8871b4161c600b3,openstack/tripleo-heat-templates,master,Ifccae8a73566ab159d48a2a1b8871b4161c600b3,DNM - test scenario upgrades with pingtest,ABANDONED,2017-02-27 12:31:15.000000000,2017-02-28 17:29:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-27 12:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f40733234fe879d49dc43c261c34a0940514de9', 'message': 'DNM - test scenario upgrades with pingtest\n\nChange-Id: Ifccae8a73566ab159d48a2a1b8871b4161c600b3\nDepends-On: I83f45efd0b4608ec29489b8f8e717945b22469d4\n'}, {'number': 2, 'created': '2017-02-27 15:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3830b265546f4f74612cceaea49b2e409dee6b7c', 'message': 'DNM - test scenario upgrades with pingtest\n\nChange-Id: Ifccae8a73566ab159d48a2a1b8871b4161c600b3\nDepends-On: I0ac0dac42286994241700f803159764fa3a6aee6\n'}, {'number': 3, 'created': '2017-02-27 18:59:17.000000000', 'files': ['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8458f2b1e9af8578ad77792902101ca02aa27500', 'message': 'DNM - test scenario upgrades with pingtest\n\nChange-Id: Ifccae8a73566ab159d48a2a1b8871b4161c600b3\nDepends-On: I0ac0dac42286994241700f803159764fa3a6aee6\n'}]",0,438471,8458f2b1e9af8578ad77792902101ca02aa27500,10,1,3,3153,,,0,"DNM - test scenario upgrades with pingtest

Change-Id: Ifccae8a73566ab159d48a2a1b8871b4161c600b3
Depends-On: I0ac0dac42286994241700f803159764fa3a6aee6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/71/438471/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml']",3,3f40733234fe879d49dc43c261c34a0940514de9,upgrade/pingtest,,#test #,0,5
openstack%2Ftripleo-heat-templates~master~Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551,openstack/tripleo-heat-templates,master,Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551,DNM: test scenario001 upgrade from newton to ocata,ABANDONED,2017-02-18 22:26:14.000000000,2017-02-28 17:29:30.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}]","[{'number': 1, 'created': '2017-02-18 22:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23905a2c053b356c253ed86bb03132f32e4f5c9e', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 2, 'created': '2017-02-20 22:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0beff80b8a9f9a6d09b59885924ecdd374a5a931', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 3, 'created': '2017-02-21 21:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/186a09e9dc7f87b00e3bd1f0c5b2a4da84917465', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nDepends-On: I33b21aa1c5c2164e98c696de4fdfbfb6cc2c943e\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 4, 'created': '2017-02-22 13:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e06f045c3d794185f0c3c8caf016601c10a81aa', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 5, 'created': '2017-02-22 13:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f770d02cefc2ab8e249c93ae6ec8de27da1381b8', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 6, 'created': '2017-02-25 01:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fa7169052d24999fa35010edb02b01ee297ab5ec', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 7, 'created': '2017-02-26 03:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6578b0cbad21513ffa4d3d771ff5ce2e48bee91a', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 8, 'created': '2017-02-27 12:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3dca59fa3a53a3d070bb91aca25b22cea6cf91d5', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 9, 'created': '2017-02-27 12:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ef5a696ba43594872c9b2260d20f3925350af72b', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\n.\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}, {'number': 10, 'created': '2017-02-27 18:59:07.000000000', 'files': ['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a954f65a3e56befd1defd99e08be0a088e410e91', 'message': 'DNM: test scenario001 upgrade from newton to ocata\n\n.\n\nChange-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551\n'}]",0,435738,a954f65a3e56befd1defd99e08be0a088e410e91,52,3,10,3153,,,0,"DNM: test scenario001 upgrade from newton to ocata

.

Change-Id: Ie9ddcd48deef1f48d3ac23d2a658c5497cbee551
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/435738/8 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario001-multinode.yaml'],1,23905a2c053b356c253ed86bb03132f32e4f5c9e,composable/scenario/upgrades,#test,,1,0
openstack%2Fpbr~master~I543f0c6679c39c7ae438fd1e5fca7175b92ed193,openstack/pbr,master,I543f0c6679c39c7ae438fd1e5fca7175b92ed193,tox: Don't set skipsdist=True,MERGED,2017-02-27 14:32:03.000000000,2017-02-28 17:23:31.000000000,2017-02-28 17:23:31.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-27 14:32:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/pbr/commit/882875a66e644e36feb2d864ae231f43bcd39e8c', 'message': 'tox: Don\'t set skipsdist=True\n\nskipsdist is used to ""avoid expensive sdist"" but prevents the software\npackage from being installed in the virtualenv. We currently have this\nenabled, but then skip the step by including the current package in the\nrequirements section, which mitigates the entire thing.\n\nStop setting skipsdist to True, allowing us to remove \'.\' from\nrequirements and use tox the way it\'s meant to be used.\n\nChange-Id: I543f0c6679c39c7ae438fd1e5fca7175b92ed193\n'}]",0,438511,882875a66e644e36feb2d864ae231f43bcd39e8c,8,3,1,15334,,,0,"tox: Don't set skipsdist=True

skipsdist is used to ""avoid expensive sdist"" but prevents the software
package from being installed in the virtualenv. We currently have this
enabled, but then skip the step by including the current package in the
requirements section, which mitigates the entire thing.

Stop setting skipsdist to True, allowing us to remove '.' from
requirements and use tox the way it's meant to be used.

Change-Id: I543f0c6679c39c7ae438fd1e5fca7175b92ed193
",git fetch https://review.opendev.org/openstack/pbr refs/changes/11/438511/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,882875a66e644e36feb2d864ae231f43bcd39e8c,feat/remove-warnerrors,deps = -r{toxinidir}/test-requirements.txt,skipsdist = Truedeps = . -r{toxinidir}/test-requirements.txt,1,3
openstack%2Fironic-inspector~master~Ibead87ad4016a6aa8406be6f6c8604e8f18cd383,openstack/ironic-inspector,master,Ibead87ad4016a6aa8406be6f6c8604e8f18cd383,Update HTTP API docs with missing 1.9 API microversion,MERGED,2017-02-28 09:15:24.000000000,2017-02-28 17:20:58.000000000,2017-02-28 17:20:58.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 18653}]","[{'number': 1, 'created': '2017-02-28 09:15:24.000000000', 'files': ['doc/source/http-api.rst'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/762c4045461f34bace940f5ffd3460f993481705', 'message': 'Update HTTP API docs with missing 1.9 API microversion\n\nChange-Id: Ibead87ad4016a6aa8406be6f6c8604e8f18cd383\n'}]",0,438870,762c4045461f34bace940f5ffd3460f993481705,7,3,1,13636,,,0,"Update HTTP API docs with missing 1.9 API microversion

Change-Id: Ibead87ad4016a6aa8406be6f6c8604e8f18cd383
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/70/438870/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/http-api.rst'],1,762c4045461f34bace940f5ffd3460f993481705,docs-add-1.9-api-desc,"* **1.9** de-activate setting IPMI credentials, if IPMI credentials are requested, API gets HTTP 400 response.",,2,0
openstack%2Fpbr~master~Ia4b6adefcd437cb1ceb4558b004c17359df2486d,openstack/pbr,master,Ia4b6adefcd437cb1ceb4558b004c17359df2486d,Stop using 'warnerrors',MERGED,2017-02-27 14:32:03.000000000,2017-02-28 17:20:55.000000000,2017-02-28 16:38:48.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 15334}]","[{'number': 1, 'created': '2017-02-27 14:32:03.000000000', 'files': ['pbr/tests/test_setup.py', 'pbr/tests/test_integration.py', 'doc/source/compatibility.rst', 'pbr/builddoc.py', 'pbr/tests/testpackage/setup.cfg', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/pbr/commit/72e8e42a34217e7f6847d221dc9751d0c350baa9', 'message': ""Stop using 'warnerrors'\n\nThis legacy option provided the ability to fail on doc warnings.\nHowever, this functionality is broken in recent releases and now exists\nin Sphinx itself (since 1.5.0). Rather that fixing it and causing a\nwhole load of doc build errors introduced in the time since this option\nwas broken, remove it, preferring the new Sphinx option instead.\n\nThis allows us to remove a lot of test code which is essentially testing\nSphinx functionality only now, based on the assumption that Sphinx do\nadequate testing themselves.\n\nChange-Id: Ia4b6adefcd437cb1ceb4558b004c17359df2486d\n""}]",7,438510,72e8e42a34217e7f6847d221dc9751d0c350baa9,12,4,1,15334,,,0,"Stop using 'warnerrors'

This legacy option provided the ability to fail on doc warnings.
However, this functionality is broken in recent releases and now exists
in Sphinx itself (since 1.5.0). Rather that fixing it and causing a
whole load of doc build errors introduced in the time since this option
was broken, remove it, preferring the new Sphinx option instead.

This allows us to remove a lot of test code which is essentially testing
Sphinx functionality only now, based on the assumption that Sphinx do
adequate testing themselves.

Change-Id: Ia4b6adefcd437cb1ceb4558b004c17359df2486d
",git fetch https://review.opendev.org/openstack/pbr refs/changes/10/438510/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'pbr/tests/test_integration.py', 'doc/source/compatibility.rst', 'pbr/builddoc.py', 'pbr/tests/testpackage/setup.cfg', 'setup.cfg']",6,72e8e42a34217e7f6847d221dc9751d0c350baa9,feat/remove-warnerrors,all-files = 1# enable the below once Sphinx is bumped to 1.5.0+ in g-r # warning-is-error = 1,warnerrors = Trueall_files = 1,20,100
openstack%2Ffreezer~master~Ib5195bfcc7c087efe6abc39679ec03635c9b8913,openstack/freezer,master,Ib5195bfcc7c087efe6abc39679ec03635c9b8913,Fix Cinder restore,MERGED,2017-02-28 14:51:09.000000000,2017-02-28 17:16:16.000000000,2017-02-28 17:16:16.000000000,"[{'_account_id': 3}, {'_account_id': 14340}, {'_account_id': 14509}]","[{'number': 1, 'created': '2017-02-28 14:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e42e66388100911a8aad37bec89047f450508adc', 'message': ""Fix Cinder restore\n\nProvide alternative names to newly restored volume in case of the\nprevious name doesn't exists in the metadata\n\nChange-Id: Ib5195bfcc7c087efe6abc39679ec03635c9b8913\n""}, {'number': 2, 'created': '2017-02-28 14:51:27.000000000', 'files': ['freezer/openstack/restore.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/7b05af4835d738aa717eee2de100b6b1a40e6909', 'message': ""Fix Cinder restore\n\nProvide alternative names to newly restored volume in case of the\nprevious name doesn't exists in the metadata\n\nChange-Id: Ib5195bfcc7c087efe6abc39679ec03635c9b8913\n""}]",0,438987,7b05af4835d738aa717eee2de100b6b1a40e6909,8,3,2,13940,,,0,"Fix Cinder restore

Provide alternative names to newly restored volume in case of the
previous name doesn't exists in the metadata

Change-Id: Ib5195bfcc7c087efe6abc39679ec03635c9b8913
",git fetch https://review.opendev.org/openstack/freezer refs/changes/87/438987/2 && git format-patch -1 --stdout FETCH_HEAD,['freezer/openstack/restore.py'],1,e42e66388100911a8aad37bec89047f450508adc,fix-cinder-restore,"from oslo_config import cfgCONF = cfg.CONF volume = cinder_client.volumes.create( size, imageRef=image.id, name=info.get('volume_name', CONF.get('backup_name', CONF.get('cinder_vol_id', None) ) ) )"," volume = cinder_client.volumes.create(size, imageRef=image.id, name=info['volume_name'])",11,3
openstack%2Foctavia~master~I5f6c9d0cade152fb20455220666925cdccba7691,openstack/octavia,master,I5f6c9d0cade152fb20455220666925cdccba7691,Updated from global requirements,MERGED,2017-02-27 11:00:33.000000000,2017-02-28 17:13:22.000000000,2017-02-28 17:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-27 11:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9c9658a93737609dfe94e03af06a3411583ed7c8', 'message': 'Updated from global requirements\n\nChange-Id: I5f6c9d0cade152fb20455220666925cdccba7691\n'}, {'number': 2, 'created': '2017-02-28 05:44:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f7426dcf96874b6e3ce15009d251866f6de01116', 'message': 'Updated from global requirements\n\nChange-Id: I5f6c9d0cade152fb20455220666925cdccba7691\n'}]",0,438436,f7426dcf96874b6e3ce15009d251866f6de01116,12,4,2,11131,,,0,"Updated from global requirements

Change-Id: I5f6c9d0cade152fb20455220666925cdccba7691
",git fetch https://review.opendev.org/openstack/octavia refs/changes/36/438436/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9c9658a93737609dfe94e03af06a3411583ed7c8,openstack/requirements,cryptography>=1.6 # BSD/Apache-2.0,"cryptography!=1.3.0,>=1.0 # BSD/Apache-2.0",1,1
openstack%2Fvitrage~master~I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae,openstack/vitrage,master,I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae,Using oslo_log instead of logging.,MERGED,2017-01-24 06:54:40.000000000,2017-02-28 17:11:13.000000000,2017-02-28 17:11:13.000000000,"[{'_account_id': 3}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 22959}]","[{'number': 1, 'created': '2017-01-24 06:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/ef76a2332647dd0ba7d9c842bf42ddfe8815ecde', 'message': 'Using oslo_log instead of logging\n\nOptimize the code\n\nChange-Id: I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae\n'}, {'number': 2, 'created': '2017-01-24 08:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/8c2324bd33e4656233a15c85590b0cecc4171fc5', 'message': 'Using oslo_log instead of logging\n\nOptimize the code\n\nChange-Id: I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae\n'}, {'number': 3, 'created': '2017-01-25 02:02:27.000000000', 'files': ['vitrage/api/app.py', 'vitrage/service.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/231c88452995590cb2218961f282d9495c6f5cf9', 'message': 'Using oslo_log instead of logging.\n\nOptimize the code\n\nChange-Id: I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae\n'}]",0,424461,231c88452995590cb2218961f282d9495c6f5cf9,16,4,3,22959,,,0,"Using oslo_log instead of logging.

Optimize the code

Change-Id: I59a8934bc9c81c3b5e4d4e861e3a29ff8cffbaae
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/61/424461/3 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/tests/unit/evaluator/test_template_content_validator.py', 'vitrage/api/app.py', 'vitrage/tests/unit/evaluator/test_template_syntax_validator.py', 'vitrage/service.py']",4,ef76a2332647dd0ba7d9c842bf42ddfe8815ecde,," conf.log_opt_values(LOG, log.DEBUG)","import logging conf.log_opt_values(LOG, logging.DEBUG)",4,7
openstack%2Fpuppet-heat~master~I294ba6b2c3c086be616eaf13ca43e02f9ce6a007,openstack/puppet-heat,master,I294ba6b2c3c086be616eaf13ca43e02f9ce6a007,TESTING,ABANDONED,2017-02-28 14:43:34.000000000,2017-02-28 17:09:50.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2017-02-28 14:43:34.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/7a4b31f8ad38e52acc786b6c27954490af1e3013', 'message': 'TESTING\n\nChange-Id: I294ba6b2c3c086be616eaf13ca43e02f9ce6a007\n'}]",0,438981,7a4b31f8ad38e52acc786b6c27954490af1e3013,4,2,1,10873,,,0,"TESTING

Change-Id: I294ba6b2c3c086be616eaf13ca43e02f9ce6a007
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/81/438981/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,7a4b31f8ad38e52acc786b6c27954490af1e3013,test,#,,1,0
openstack%2Fneutron-lbaas~master~I152664fc754efaa3f74d36bbc73dd9b57a18dd01,openstack/neutron-lbaas,master,I152664fc754efaa3f74d36bbc73dd9b57a18dd01,Updated from global requirements,MERGED,2017-02-27 10:58:53.000000000,2017-02-28 17:04:34.000000000,2017-02-28 17:04:34.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10273}, {'_account_id': 10850}]","[{'number': 1, 'created': '2017-02-27 10:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1b2497ce863af283b86977d11e0a66b7d11aa55d', 'message': 'Updated from global requirements\n\nChange-Id: I152664fc754efaa3f74d36bbc73dd9b57a18dd01\n'}, {'number': 2, 'created': '2017-02-27 16:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/51c65b80efcd65368e291ad349489ba8f2e502d9', 'message': 'Updated from global requirements\n\nChange-Id: I152664fc754efaa3f74d36bbc73dd9b57a18dd01\n'}, {'number': 3, 'created': '2017-02-28 05:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/834d1155b33982c75eee109593afcd0d9f883de3', 'message': 'Updated from global requirements\n\nChange-Id: I152664fc754efaa3f74d36bbc73dd9b57a18dd01\n'}, {'number': 4, 'created': '2017-02-28 14:01:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/054423be12bfdd30c61516953db2a7c5ea3e89d6', 'message': 'Updated from global requirements\n\nChange-Id: I152664fc754efaa3f74d36bbc73dd9b57a18dd01\n'}]",0,438435,054423be12bfdd30c61516953db2a7c5ea3e89d6,18,4,4,11131,,,0,"Updated from global requirements

Change-Id: I152664fc754efaa3f74d36bbc73dd9b57a18dd01
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/35/438435/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1b2497ce863af283b86977d11e0a66b7d11aa55d,openstack/requirements,cryptography>=1.6 # BSD/Apache-2.0,"cryptography!=1.3.0,>=1.0 # BSD/Apache-2.0",1,1
openstack%2Fbarbican~master~I62da8c5b2013aaa21a1b7819bc1ae73fe412fe32,openstack/barbican,master,I62da8c5b2013aaa21a1b7819bc1ae73fe412fe32,Fix coverage gate,MERGED,2017-02-24 20:33:37.000000000,2017-02-28 17:00:17.000000000,2017-02-28 17:00:17.000000000,"[{'_account_id': 3}, {'_account_id': 8623}, {'_account_id': 11561}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-24 20:33:37.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/b7e5dc2835054de523554dc80fa8dacc4e723937', 'message': 'Fix coverage gate\n\nThe ""coverage combine --append"" command was failing and it does\nnot seem to be required here.  The coverage gate works correctly\nwhen this command is removed.\n\nChange-Id: I62da8c5b2013aaa21a1b7819bc1ae73fe412fe32\n'}]",0,438066,b7e5dc2835054de523554dc80fa8dacc4e723937,8,4,1,11561,,,0,"Fix coverage gate

The ""coverage combine --append"" command was failing and it does
not seem to be required here.  The coverage gate works correctly
when this command is removed.

Change-Id: I62da8c5b2013aaa21a1b7819bc1ae73fe412fe32
",git fetch https://review.opendev.org/openstack/barbican refs/changes/66/438066/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b7e5dc2835054de523554dc80fa8dacc4e723937,fix-coverage-gate,, coverage combine --append,0,1
openstack%2Fpython-tripleoclient~stable%2Fmitaka~I30a75c47cb401456fcef5aba3a0c62df44045e54,openstack/python-tripleoclient,stable/mitaka,I30a75c47cb401456fcef5aba3a0c62df44045e54,Updated from global requirements,MERGED,2017-02-28 10:59:42.000000000,2017-02-28 16:59:02.000000000,2017-02-28 16:59:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}]","[{'number': 1, 'created': '2017-02-28 10:59:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c7d4a2d14e24221029a83d3ce82e7c60083eebac', 'message': 'Updated from global requirements\n\nChange-Id: I30a75c47cb401456fcef5aba3a0c62df44045e54\n'}]",0,438912,c7d4a2d14e24221029a83d3ce82e7c60083eebac,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: I30a75c47cb401456fcef5aba3a0c62df44045e54
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/12/438912/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c7d4a2d14e24221029a83d3ce82e7c60083eebac,openstack/requirements,"tripleo-common<3.0.0,>=2.0.0 # Apache-2.0 os-cloud-config # Apache-2.0","tripleo-common>=2.0.0,<3.0.0 # Apache-2.0 os-cloud-config # Apache-2.0",2,2
openstack%2Fpuppet-heat~master~Ib7e30196d8b336aafc5ce92f7c5d62fe31adc5a8,openstack/puppet-heat,master,Ib7e30196d8b336aafc5ce92f7c5d62fe31adc5a8,Remove checking for rpc_backend,MERGED,2017-02-28 14:49:39.000000000,2017-02-28 16:58:57.000000000,2017-02-28 16:58:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-28 14:49:39.000000000', 'files': ['spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/d5ca9fb1b338144558ddd34326512bce9c107cb8', 'message': ""Remove checking for rpc_backend\n\nA recent commit removed it from puppet-oslo. We shouldn't be checking it\nany more here.\n\n[1] I7ccd995ef01c2d54427684718adba054260fdd52\n\nChange-Id: Ib7e30196d8b336aafc5ce92f7c5d62fe31adc5a8\n""}]",0,438985,d5ca9fb1b338144558ddd34326512bce9c107cb8,9,3,1,10873,,,0,"Remove checking for rpc_backend

A recent commit removed it from puppet-oslo. We shouldn't be checking it
any more here.

[1] I7ccd995ef01c2d54427684718adba054260fdd52

Change-Id: Ib7e30196d8b336aafc5ce92f7c5d62fe31adc5a8
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/85/438985/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/heat_init_spec.rb'],1,d5ca9fb1b338144558ddd34326512bce9c107cb8,rpc-backend,, it { is_expected.to contain_heat_config('DEFAULT/rpc_backend').with_value('amqp') } it { is_expected.to contain_heat_config('DEFAULT/rpc_backend').with_value('amqp') },0,2
openstack%2Fpuppet-keystone~master~Id578980cae370ad46187ea2ced0ae8dada1ef3ee,openstack/puppet-keystone,master,Id578980cae370ad46187ea2ced0ae8dada1ef3ee,Fix shibboleth tests,MERGED,2017-02-27 21:55:40.000000000,2017-02-28 16:58:26.000000000,2017-02-28 02:54:17.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-27 21:55:40.000000000', 'files': ['spec/classes/keystone_federation_shibboleth_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d369e3ab0fdc6d8a69b8a6428deaa89fc9066368', 'message': 'Fix shibboleth tests\n\nThis patch basically rewrites the shibboleth unit tests. The previous\nversion was not properly running the invalid parameters cases and the\ncases for installing under Red Hat were not properly being exercised.\n\nChange-Id: Id578980cae370ad46187ea2ced0ae8dada1ef3ee\nCloses-Bug: #1667866\n'}]",0,438716,d369e3ab0fdc6d8a69b8a6428deaa89fc9066368,14,2,1,14985,,,0,"Fix shibboleth tests

This patch basically rewrites the shibboleth unit tests. The previous
version was not properly running the invalid parameters cases and the
cases for installing under Red Hat were not properly being exercised.

Change-Id: Id578980cae370ad46187ea2ced0ae8dada1ef3ee
Closes-Bug: #1667866
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/16/438716/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/keystone_federation_shibboleth_spec.rb'],1,d369e3ab0fdc6d8a69b8a6428deaa89fc9066368,bug/1667866," let :default_params do { :methods => 'password, token, saml2', :template_order => 331, } shared_examples 'keystone::federation::shibboleth with invalid parameters' do context 'external method' do let (:params) { default_params.merge(:methods => ['external']) } it_raises 'a Puppet::Error', /The external method/ context 'method missing saml2' do let (:params) { default_params.merge(:methods => ['password', 'token', 'oauth1']) } context 'wrong plugin' do let (:params) { default_params.merge(:methods => ['password', 'token', 'oauth1', 'saml2'], :module_plugin => 'keystone.auth.plugins') } it_raises 'a Puppet::Error', /The plugin for saml and shibboleth should be keystone.auth.plugins.mapped.Mapped/ context 'no ports' do let (:params) { default_params.merge(:admin_port => false, :main_port => false) } it_raises 'a Puppet::Error', /No VirtualHost port to configure, please choose at least one./ context 'template port too low' do let(:params) { default_params.merge(:template_order => 330) } it_raises 'a Puppet::Error', /The template order should be greater than 330 and less than 999./ context 'template port too high' do let(:params) { default_params.merge(:template_order => 999) } it_raises 'a Puppet::Error', /The template order should be greater than 330 and less than 999./ shared_examples 'keystone::federation::shibboleth' do let(:pre_condition) do <<-EOS include apache class { 'keystone::wsgi::apache': } EOS end let (:params) { default_params } let (:params) { default_params.merge({ :methods => ['password', 'token', 'saml2', 'somethingelse'], }) } is_expected.to contain_keystone_config('auth/methods').with_value('password,token,saml2,somethingelse') end end end shared_examples 'keystone::federation::shibboleth on RedHat' do context 'with shibboleth package' do let(:pre_condition) do <<-EOS include apache package { 'shibboleth': ensure => present } class { 'keystone::wsgi::apache': } EOS context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it {is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], }) } end end context 'with shibboleth repo' do let(:pre_condition) do <<-EOS include apache yumrepo { 'shibboleth': ensure => present } class { 'keystone::wsgi::apache': } EOS end context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it { is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], }) } end end context 'without repo or package' do context 'with defaults' do let (:params) { default_params } it { is_expected.to_not contain_apache__mod('shib2') } it { is_expected.to_not contain_concat__fragment('configure_shibboleth_on_port_5000') } end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it { is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to_not contain_concat__fragment('configure_shibboleth_on_port_35357') } end end end shared_examples 'keystone::federation::shibboleth on Debian' do context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} context ""on #{os}"" do let (:facts) do facts.merge(OSDefaults.get_facts({ :concat_basedir => '/var/lib/puppet/concat' })) end it_behaves_like 'keystone::federation::shibboleth' it_behaves_like 'keystone::federation::shibboleth with invalid parameters' it_behaves_like ""keystone::federation::shibboleth on #{facts[:osfamily]}"" end"," let :params do { :methods => 'password, token, saml2', :template_order => 331 } describe 'with invalid params' do before do params.merge!(:methods => 'external, password, token, oauth1') it_raises 'a Puppet::Error', /The external method should be dropped to avoid any interference with some Apache + Shibboleth SP setups, where a REMOTE_USER env variable is always set, even as an empty value./ before do params.merge!(:methods => 'password, token, oauth1') before do params.merge!(:methods => 'password, token, oauth1, saml2', :module_plugin => 'keystone.auth.plugins') it_raises 'a Puppet:Error', /The plugin for saml and shibboleth should be keystone.auth.plugins.mapped.Mapped/ before do params.merge!(:admin_port => false, :main_port => false) it_raises 'a Puppet:Error', /No VirtualHost port to configure, please choose at least one./ before do params.merge!(:template_port => 330) it_raises 'a Puppet:Error', /The template order should be greater than 330 and less than 999./ before do params.merge!(:template_port => 999) it_raises 'a Puppet:Error', /The template order should be greater than 330 and less than 999./ shared_examples 'Federation Shibboleth' do it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} before do params.merge!({ :admin_port => true }) end is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') it { is_expected.to contain_class('apache::mod::shib') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], })} let (:facts) do facts.merge!(OSDefaults.get_facts({})) end it_behaves_like 'Federation Shibboleth'",155,50
openstack%2Fheat~master~I886a9458e72aa1ffdb2cc6dcf20331f468778032,openstack/heat,master,I886a9458e72aa1ffdb2cc6dcf20331f468778032,Encode exception message in tests,MERGED,2017-02-01 13:25:22.000000000,2017-02-28 16:54:39.000000000,2017-02-28 16:54:39.000000000,"[{'_account_id': 3}, {'_account_id': 7385}, {'_account_id': 8833}, {'_account_id': 12404}]","[{'number': 1, 'created': '2017-02-01 13:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/06d60e1e3c8574ad9e04d9945a55ab8e754b9f93', 'message': ""Encode exception message in tests\n\nassertIn is failing on exception messages as apparently they are bytes\nin Python3. Let's encode it before the check.\n\nChange-Id: I886a9458e72aa1ffdb2cc6dcf20331f468778032\n""}, {'number': 2, 'created': '2017-02-28 08:47:26.000000000', 'files': ['heat_integrationtests/functional/test_conditional_exposure.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b111627dc24a71a13486597f5b94daaea022eb05', 'message': ""Encode exception message in tests\n\nassertIn is failing on exception messages as apparently they are bytes\nin Python3. Let's encode it before the check.\n\nChange-Id: I886a9458e72aa1ffdb2cc6dcf20331f468778032\n""}]",0,427690,b111627dc24a71a13486597f5b94daaea022eb05,17,4,2,7385,,,0,"Encode exception message in tests

assertIn is failing on exception messages as apparently they are bytes
in Python3. Let's encode it before the check.

Change-Id: I886a9458e72aa1ffdb2cc6dcf20331f468778032
",git fetch https://review.opendev.org/openstack/heat refs/changes/90/427690/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_conditional_exposure.py'],1,06d60e1e3c8574ad9e04d9945a55ab8e754b9f93,py3-exception-check," self.assertIn('ResourceTypeUnavailable', ex.message.decode('utf-8')) self.assertIn('OS::Sahara::NodeGroupTemplate', ex.message.decode('utf-8')) self.assertIn(self.forbidden_r_type, ex.message.decode('utf-8'))"," self.assertIn('ResourceTypeUnavailable', ex.message) self.assertIn('OS::Sahara::NodeGroupTemplate', ex.message) self.assertIn(self.forbidden_r_type, ex.message)",4,3
openstack%2Fglance-specs~master~I734a5c245218e380860127db9a657793f1337afa,openstack/glance-specs,master,I734a5c245218e380860127db9a657793f1337afa,Add spec-lite for Glare code removal,MERGED,2017-02-28 15:12:52.000000000,2017-02-28 16:54:31.000000000,2017-02-28 16:54:31.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}]","[{'number': 1, 'created': '2017-02-28 15:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d49f61351f655ca3283694848f593f4a1cf923e4', 'message': 'Add spec-lite for Glare code removal\n\nAdds a spec-lite to document the reasons for the removal of the\nGlare legacy code left behind in Glance after Glare became its\nown project with its own code repository in Newton.\n\nChange-Id: I734a5c245218e380860127db9a657793f1337afa\n'}, {'number': 2, 'created': '2017-02-28 15:52:10.000000000', 'files': ['specs/pike/approved/glance/lite-specs.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/05222388255bdc95cdf262b55702de19be1e97b9', 'message': 'Add spec-lite for Glare code removal\n\nAdds a spec-lite to document the reasons for the removal of the\nGlare legacy code left behind in Glance after Glare became its\nown project with its own code repository in Newton.\n\nChange-Id: I734a5c245218e380860127db9a657793f1337afa\n'}]",4,438996,05222388255bdc95cdf262b55702de19be1e97b9,10,3,2,5314,,,0,"Add spec-lite for Glare code removal

Adds a spec-lite to document the reasons for the removal of the
Glare legacy code left behind in Glance after Glare became its
own project with its own code repository in Newton.

Change-Id: I734a5c245218e380860127db9a657793f1337afa
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/96/438996/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/glance/lite-specs.rst'],1,d49f61351f655ca3283694848f593f4a1cf923e4,glare-ectomy,"Remove Glare code from the Glance repository -------------------------------------------- :problem: Glare became a separate project with its own code repository during Newton. The code was copied out of the Glance tree, but remained in the Glance repository. It is no longer being maintained, and that has begun to cause some problems, for example, blocking a recent stevedore upper constraints change; see Change-Id: `I141b17f9dd2acebe2b23f8fc93206e23bc70b568 <https://review.openstack.org/#q,I141b17f9dd2acebe2b23f8fc93206e23bc70b568,n,z>`_. :solution: Remove all Glare code from the Glance repository and drop all artifacts tables from the Glance database. :impacts: No API Impact as the Glare API was EXPERIMENTAL in both versions that ran on the code being removed ('/v3' on the Glance endpoint in Liberty, '/v0.1' on its own endpoint in Mitaka). As a courtesy to projects/packagers/deployers that may have consumed Glare from the Glance code repository, an `openstack-dev announcement <http://lists.openstack.org/pipermail/openstack-dev/2017-February/112427.html>`_ and an `openstack-operators announcement <http://lists.openstack.org/pipermail/openstack-operators/2017-February/012689.html>`_ were sent out on 16 February 2017. There has been no response. A detailed release note will be included in the patch. :timeline: Pike-1 :link: Change-Id: `I3026ca6287a65ab5287bf3843f2a9d756ce15139 <https://review.openstack.org/#q,I3026ca6287a65ab5287bf3843f2a9d756ce15139,n,z>`_ :assignee: rosmaita End of `Remove Glare code from the Glance repository` +++++++++++++++++++++++++++++++++++++++++++++++++++++ ",,37,0
openstack%2Ffreezer~master~Ic9ac913097bcc45a7c792a6d7dc3a670a4d55074,openstack/freezer,master,Ic9ac913097bcc45a7c792a6d7dc3a670a4d55074,Removing obsolete oslo.log configuration settings,MERGED,2016-07-08 14:29:11.000000000,2017-02-28 16:53:18.000000000,2017-02-28 16:53:18.000000000,"[{'_account_id': 3}, {'_account_id': 13940}, {'_account_id': 14509}, {'_account_id': 21644}, {'_account_id': 22589}]","[{'number': 1, 'created': '2016-07-08 14:29:11.000000000', 'files': ['doc/source/user/freezer-agent.rst', 'README.rst', 'etc/scheduler.conf.sample'], 'web_link': 'https://opendev.org/openstack/freezer/commit/27fee2057f2bc12bf2b0a1c54b69177365456d69', 'message': 'Removing obsolete oslo.log configuration settings\n\nChange-Id: Ic9ac913097bcc45a7c792a6d7dc3a670a4d55074\nCloses-Bug: #1600244\n'}]",0,339583,27fee2057f2bc12bf2b0a1c54b69177365456d69,10,5,1,15041,,,0,"Removing obsolete oslo.log configuration settings

Change-Id: Ic9ac913097bcc45a7c792a6d7dc3a670a4d55074
Closes-Bug: #1600244
",git fetch https://review.opendev.org/openstack/freezer refs/changes/83/339583/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/freezer-agent.rst', 'README.rst', 'etc/scheduler.conf.sample']",3,27fee2057f2bc12bf2b0a1c54b69177365456d69,bug/1600244,# configuration file and other logging configuration options are ignored. # (string value)# Use syslog for logging. Previous syslog format (without APP-NAME being # specified in log messages) is DEPRECATED and format will now honor RFC5424. # This option is ignored if log_config_append is set. (boolean value),"# configuration file and other logging configuration options are ignored (for # example, log_format). (string value)# DEPRECATED. A logging.Formatter log message format string which may use any # of the available logging.LogRecord attributes. This option is deprecated. # Please use logging_context_format_string and logging_default_format_string # instead. This option is ignored if log_config_append is set. (string value) #log_format = <None> # Use syslog for logging. Existing syslog format is DEPRECATED and will be # changed later to honor RFC5424. This option is ignored if log_config_append # is set. (boolean value)# Enables or disables syslog rfc5424 format for logging. If enabled, prefixes # the MSG part of the syslog message with APP-NAME (RFC5424). This option is # ignored if log_config_append is set. (boolean value) # This option is deprecated for removal. # Its value may be silently ignored in the future. # Reason: The format without the APP-NAME is deprecated in Kilo, and will be # removed in Mitaka, along with this option. #use_syslog_rfc_format = true ",7,24
openstack%2Fpython-monascaclient~master~Ib8300530a3a17d9cb96962c1ffdf5362ed0553ca,openstack/python-monascaclient,master,Ib8300530a3a17d9cb96962c1ffdf5362ed0553ca,Fix: CLI metric-create using project-id fails,MERGED,2017-02-14 01:28:42.000000000,2017-02-28 16:46:50.000000000,2017-02-28 16:46:50.000000000,"[{'_account_id': 3}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 18179}]","[{'number': 1, 'created': '2017-02-14 01:28:42.000000000', 'files': ['monascaclient/v2_0/shell.py', 'monascaclient/tests/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/3736d114be403f7f0f22476ca457e3b9dd93b992', 'message': 'Fix: CLI metric-create using project-id fails\n\nThe tenant-id query parameter was being passed as a list instead\nof as a string\n\nAdded test\n\nChange-Id: Ib8300530a3a17d9cb96962c1ffdf5362ed0553ca\nCloses-Bug:#1664415\n'}]",0,433380,3736d114be403f7f0f22476ca457e3b9dd93b992,9,5,1,11809,,,0,"Fix: CLI metric-create using project-id fails

The tenant-id query parameter was being passed as a list instead
of as a string

Added test

Change-Id: Ib8300530a3a17d9cb96962c1ffdf5362ed0553ca
Closes-Bug:#1664415
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/80/433380/1 && git format-patch -1 --stdout FETCH_HEAD,"['monascaclient/v2_0/shell.py', 'monascaclient/tests/test_shell.py']",2,3736d114be403f7f0f22476ca457e3b9dd93b992,bug/1664415,"# (C) Copyright 2014-2017 Hewlett Packard Enterprise Development LP def test_good_metrics_create_subcommand_with_tenant_id(self): self._script_keystone_client() self.m.ReplayAll() headers = {'location': 'http://no.where/v2.0/metrics'} self.requests_mock.post('http://192.168.1.5:8004/v1/f14b41234/metrics', status_code=204, headers=headers) proj = 'd48e63e76a5c4e05ba26a1185f31d4aa' argstrings = [ 'metric-create metric1 123 --time 1395691090 --project-id ' + proj, ] for argstr in argstrings: retvalue = self.shell(argstr) self.assertRegexpMatches(retvalue, ""^Success"") data = {'timestamp': 1395691090, 'name': 'metric1', 'value': 123.0} self.assertHeaders() self.assertEqual(data, self.requests_mock.last_request.json()) request_url = self.requests_mock.last_request.url query_arg = request_url[request_url.index('?') + 1:] self.assertEqual('tenant_id=' + proj, query_arg) ",# (C) Copyright 2014-2016 Hewlett Packard Enterprise Development LP,31,4
openstack%2Fpuppet-tripleo~master~I3f79c881d8aeda361a59f9952948355986a7c835,openstack/puppet-tripleo,master,I3f79c881d8aeda361a59f9952948355986a7c835,"Revert ""Add httpchk for http services""",MERGED,2017-02-28 05:06:23.000000000,2017-02-28 16:46:47.000000000,2017-02-28 14:32:17.000000000,"[{'_account_id': 3}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-28 05:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/199fd65a7d08bb420c33d340718263a2bd0722b2', 'message': 'Revert ""Add httpchk for http services""\n\nhttps://bugs.launchpad.net/tripleo/+bug/1668493\nI thought about a fix for ceph_rgw, but I realized\nwe might have missed other services too, specially\nthe ones we\'re not testing in CI.\nWe need to revisit this work and probably\nmake the code more robust for the services where\nno CI coverage is done.\n\nRelated-Bug: #1668493\nThis reverts commit ebcc470ea8a632e6d5c13561a97e817d5f290aac.\n\nChange-Id: I3f79c881d8aeda361a59f9952948355986a7c835\n'}, {'number': 2, 'created': '2017-02-28 05:06:28.000000000', 'files': ['manifests/haproxy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3b78e1cd9717ac8bb4e36fd292477e4373caabec', 'message': 'Revert ""Add httpchk for http services""\n\nhttps://bugs.launchpad.net/tripleo/+bug/1668493\nI thought about a fix for ceph_rgw, but I realized\nwe might have missed other services too, specially\nthe ones we\'re not testing in CI.\nWe need to revisit this work and probably\nmake the code more robust for the services where\nno CI coverage is done.\n\nRelated-Bug: #1668493\nThis reverts commit ebcc470ea8a632e6d5c13561a97e817d5f290aac.\n\nChange-Id: I3f79c881d8aeda361a59f9952948355986a7c835\n'}]",0,438801,3b78e1cd9717ac8bb4e36fd292477e4373caabec,15,3,2,3153,,,0,"Revert ""Add httpchk for http services""

https://bugs.launchpad.net/tripleo/+bug/1668493
I thought about a fix for ceph_rgw, but I realized
we might have missed other services too, specially
the ones we're not testing in CI.
We need to revisit this work and probably
make the code more robust for the services where
no CI coverage is done.

Related-Bug: #1668493
This reverts commit ebcc470ea8a632e6d5c13561a97e817d5f290aac.

Change-Id: I3f79c881d8aeda361a59f9952948355986a7c835
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/01/438801/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/haproxy.pp'],1,199fd65a7d08bb420c33d340718263a2bd0722b2,bug/1629052," 'option' => 'forwardfor', 'option' => 'forwardfor', listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, $keystone_listen_opts = { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], } $keystone_public_tls_listen_opts = {} listen_options => merge($keystone_listen_opts, $keystone_public_tls_listen_opts), listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, $heat_base_options = { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }']} $heat_options = merge($heat_base_options, $heat_ssl_options) } else { $heat_options = $heat_base_options"," 'option' => [ 'forwardfor', 'httpchk' ], 'option' => [ 'forwardfor', 'httpchk' ], $default_listen_options = { 'option' => [ 'httpchk', ], 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], } listen_options => $default_listen_options, listen_options => merge($default_listen_options, { 'option' => [ 'httpchk GET /v3' ] }), $keystone_public_tls_listen_opts = { 'option' => [ 'httpchk GET /v3', ], } listen_options => merge($default_listen_options, $keystone_public_tls_listen_opts), listen_options => merge($default_listen_options, { 'option' => [ 'httpchk GET /healthcheck', ]}), listen_options => { 'option' => [ 'httpchk', ], }, listen_options => merge($default_listen_options, { 'option' => [ 'tcpka' ], }), 'option' => [ 'httpchk GET /healthcheck', ], $heat_options = merge($default_listen_options, $heat_ssl_options) } else { $heat_options = $default_listen_options",87,25
openstack%2Fnova~master~Ie697ad6520622d6f01f06b19b143d5f8ac21e053,openstack/nova,master,Ie697ad6520622d6f01f06b19b143d5f8ac21e053,Add device_id when creating ports,MERGED,2017-02-09 13:52:13.000000000,2017-02-28 16:42:28.000000000,2017-02-28 16:37:57.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6849}, {'_account_id': 7166}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-09 13:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d75701b85cb124d7c32fa0bed819b00fc9f8f7a3', 'message': ""Add device_id when creating ports\n\nCurrently, when nova is creating ports, we don't update the device_id\nuntil we bind the port much later in the process. Its better to set the\ndevice_id when we create the port for a variety of reasons, such as it\nstops other instances trying to use the port we just created.\n\nThe real reason it is changed here is because in a few edge cases Nova\nstill fails to correctly clean up ports we created. By adding the\ndevice_id we should be able to more easily track down the cause of the\nleaking ports, and it may help fix the issue too.\n\nChange-Id: Ie697ad6520622d6f01f06b19b143d5f8ac21e053\nRelated-Bug: 1603909\n""}, {'number': 2, 'created': '2017-02-09 16:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dea447552f0542c2562de31d6f3339315e53631e', 'message': ""Add device_id when creating ports\n\nCurrently, when nova is creating ports, we don't update the device_id\nuntil we bind the port much later in the process. It's better to set the\ndevice_id when we create the port for a variety of reasons, such as it\nstops other instances trying to use the port we just created.\n\nThe real reason it is changed here is because in a few edge cases Nova\nstill fails to correctly clean up ports we created. By adding the\ndevice_id we should be able to more easily track down the cause of the\nleaking ports, and it may help fix the issue too.\n\nChange-Id: Ie697ad6520622d6f01f06b19b143d5f8ac21e053\nRelated-Bug: 1603909\n""}, {'number': 3, 'created': '2017-02-28 13:19:20.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/15280bde1d4b3927a5b5912677c9576f96b2ed51', 'message': ""Add device_id when creating ports\n\nCurrently, when nova is creating ports, we don't update the device_id\nuntil we bind the port much later in the process. It's better to set the\ndevice_id when we create the port for a variety of reasons, such as it\nstops other instances trying to use the port we just created.\n\nThe real reason it is changed here is because in a few edge cases Nova\nstill fails to correctly clean up ports we created. By adding the\ndevice_id we should be able to more easily track down the cause of the\nleaking ports, and it may help fix the issue too.\n\nChange-Id: Ie697ad6520622d6f01f06b19b143d5f8ac21e053\nRelated-Bug: 1603909\n""}]",5,431545,15280bde1d4b3927a5b5912677c9576f96b2ed51,59,15,3,782,,,0,"Add device_id when creating ports

Currently, when nova is creating ports, we don't update the device_id
until we bind the port much later in the process. It's better to set the
device_id when we create the port for a variety of reasons, such as it
stops other instances trying to use the port we just created.

The real reason it is changed here is because in a few edge cases Nova
still fails to correctly clean up ports we created. By adding the
device_id we should be able to more easily track down the cause of the
leaking ports, and it may help fix the issue too.

Change-Id: Ie697ad6520622d6f01f06b19b143d5f8ac21e053
Related-Bug: 1603909
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/431545/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,d75701b85cb124d7c32fa0bed819b00fc9f8f7a3,bug/1603909," port_req_body_create = {'port': {'device_id': self.instance.uuid}} 'admin_state_up': True, 'device_id': self.instance.uuid}}) 'admin_state_up': True, 'security_groups': security_groups, 'device_id': self.instance.uuid}})"," port_req_body_create = {'port': {}} 'admin_state_up': True}}) 'admin_state_up': True, 'security_groups': security_groups}})",8,4
openstack%2Fnova~master~Ice138c8ebbf526cd18ebba1e13cb939172b91154,openstack/nova,master,Ice138c8ebbf526cd18ebba1e13cb939172b91154,Remove run_tests.sh,MERGED,2017-02-24 15:27:37.000000000,2017-02-28 16:38:24.000000000,2017-02-28 16:38:24.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5196}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15334}, {'_account_id': 18337}, {'_account_id': 20223}]","[{'number': 1, 'created': '2017-02-24 15:27:37.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/nova/commit/e896db1844f56cf17c7274d94a0653241c3e5884', 'message': 'Remove run_tests.sh\n\nrun_tests.sh has been deprecated for a long time. All tests are run\nthrough tox now, so run_tests.sh can go away for good.\n\nChange-Id: Ice138c8ebbf526cd18ebba1e13cb939172b91154\n'}]",0,437947,e896db1844f56cf17c7274d94a0653241c3e5884,25,9,1,11803,,,0,"Remove run_tests.sh

run_tests.sh has been deprecated for a long time. All tests are run
through tox now, so run_tests.sh can go away for good.

Change-Id: Ice138c8ebbf526cd18ebba1e13cb939172b91154
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/437947/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,e896db1844f56cf17c7274d94a0653241c3e5884,remove-run_tests,,"#!/bin/bash set -eu cat <<EOF run_tests.sh is deprecated and this script will be removed before the Mitaka release. All tests should be run through tox. To run style checks: tox -e pep8 To run python 2.7 unit tests tox -e py27 To run functional tests tox -e functional To run a subset of any of these tests: tox -e py27 someregex i.e.: tox -e py27 test_servers Use following to replace './run_test.sh -8' to do pep8 check with changed files tox -e pep8 -- -HEAD Additional tox targets are available in tox.ini. For more information see: http://docs.openstack.org/project-team-guide/project-setup/python.html NOTE: if you really really don't want to use tox to run tests, you can instead use: testr run Documentation on using testr directly can be found at http://testrepository.readthedocs.org/en/latest/MANUAL.html EOF exit 1 ",0,46
openstack%2Fdevstack~master~Ibb0f7a68d21081bf7652a0c1515080c0c54888ca,openstack/devstack,master,Ibb0f7a68d21081bf7652a0c1515080c0c54888ca,install LIBS_FROM_GIT using python 2 and 3 where appropriate,MERGED,2017-01-09 22:13:11.000000000,2017-02-28 16:37:49.000000000,2017-02-28 16:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5638}, {'_account_id': 10118}, {'_account_id': 14511}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-01-09 22:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8857b18178bc6e53d046f6de66c180d1db8534f2', 'message': 'install LIBS_FROM_GIT using python 2 and 3 where appropriate\n\nWhen installing a library from source and python 3 is enabled, repeat\nthe installation process with python 2 enabled to ensure the library is\nalso installed under python 2 for any services not yet running under 3.\n\nChange-Id: Ibb0f7a68d21081bf7652a0c1515080c0c54888ca\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2017-01-09 22:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7dd4fc836e486d54b8201efd3687193b5246773', 'message': 'install LIBS_FROM_GIT using python 2 and 3 where appropriate\n\nWhen installing a library from source and python 3 is enabled, first run\nthe installation process with python 2 enabled to ensure the library is\nalso installed under python 2 for any services not yet running under\n3. The python 3 version is installed second so that command line tools\ninstalled with libraries are installed under python 3 when python 3 is\nenabled.\n\nChange-Id: Ibb0f7a68d21081bf7652a0c1515080c0c54888ca\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 3, 'created': '2017-01-10 16:08:54.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a2eb89417fbb6d61526b1819cbe3d0a60537eedd', 'message': 'install LIBS_FROM_GIT using python 2 and 3 where appropriate\n\nWhen installing a library from source and python 3 is enabled, first run\nthe installation process with python 2 enabled to ensure the library is\nalso installed under python 2 for any services not yet running under\n3. The python 3 version is installed second so that command line tools\ninstalled with libraries are installed under python 3 when python 3 is\nenabled.\n\nChange-Id: Ibb0f7a68d21081bf7652a0c1515080c0c54888ca\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",2,418135,a2eb89417fbb6d61526b1819cbe3d0a60537eedd,19,8,3,2472,,,0,"install LIBS_FROM_GIT using python 2 and 3 where appropriate

When installing a library from source and python 3 is enabled, first run
the installation process with python 2 enabled to ensure the library is
also installed under python 2 for any services not yet running under
3. The python 3 version is installed second so that command line tools
installed with libraries are installed under python 3 when python 3 is
enabled.

Change-Id: Ibb0f7a68d21081bf7652a0c1515080c0c54888ca
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/35/418135/1 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,8857b18178bc6e53d046f6de66c180d1db8534f2,python3-whitelist," if python3_enabled; then # Turn off Python 3 mode and install the package again, # forcing a Python 2 installation. This ensures that all libs # being used for development are installed under both versions # of Python. echo ""Installing $name again without Python 3 enabled"" USE_PYTHON3=False setup_develop $dir USE_PYTHON3=True fi",,10,0
openstack%2Fdevstack~master~I69857d4e11f4767928614a3b637c894bcd03491f,openstack/devstack,master,I69857d4e11f4767928614a3b637c894bcd03491f,allow config to manage python3 use explicitly,MERGED,2017-01-09 21:42:33.000000000,2017-02-28 16:37:20.000000000,2017-02-28 16:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 10118}, {'_account_id': 14511}, {'_account_id': 14760}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-01-09 21:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4b35820b7561221d9fd22f2c49ab656261e69770', 'message': 'allow config to manage python3 use explicitly\n\nAdd variables ENABLED_PYTHON3 and DISABLED_PYTHON3 to work like\nENABLED_SERVICES and DISABLED_SERVICES and to manage which packages are\ninstalled using Python 3. Move the list of whitelisted packages in\npip_install to the default for ENABLED_PYTHON3, except swift which is\nnot enabled by default for now.\n\nAdd enable_python3 and disable_python3 functions to make editing the\nvariables from local.conf easier.\n\nAdd python3_enabled_for and python3_disabled_for functions to check the\nsettings against packages being installed by pip.\n\nUpdate pip_install to check if python3 is disabled for a service, then\nsee if it is explicitly enabled, and only then fall back to looking at\nthe classifiers in the packaging metadata.\n\nUpdate pip_install messages to give more detail about why the choice\nbetween python 2 and 3 is being made for a given package.\n\nChange-Id: I69857d4e11f4767928614a3b637c894bcd03491f\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2017-01-10 16:08:54.000000000', 'files': ['inc/python', 'stackrc', 'tests/test_python.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/94129c7d02902e0f000c09c8245be341df1c5965', 'message': 'allow config to manage python3 use explicitly\n\nAdd variables ENABLED_PYTHON3_PACKAGES and DISABLED_PYTHON3_PACKAGES to\nwork like ENABLED_SERVICES and DISABLED_SERVICES and to manage which\npackages are installed using Python 3. Move the list of whitelisted\npackages in pip_install to the default for ENABLED_PYTHON3_PACKAGES,\nexcept swift which is not enabled by default for now.\n\nAdd enable_python3_package and disable_python3_package functions to make\nediting the variables from local.conf easier.\n\nAdd python3_enabled_for and python3_disabled_for functions to check the\nsettings against packages being installed by pip.\n\nUpdate pip_install to check if python3 is disabled for a service, then\nsee if it is explicitly enabled, and only then fall back to looking at\nthe classifiers in the packaging metadata.\n\nUpdate pip_install messages to give more detail about why the choice\nbetween python 2 and 3 is being made for a given package.\n\nChange-Id: I69857d4e11f4767928614a3b637c894bcd03491f\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",3,418125,94129c7d02902e0f000c09c8245be341df1c5965,23,8,2,2472,,,0,"allow config to manage python3 use explicitly

Add variables ENABLED_PYTHON3_PACKAGES and DISABLED_PYTHON3_PACKAGES to
work like ENABLED_SERVICES and DISABLED_SERVICES and to manage which
packages are installed using Python 3. Move the list of whitelisted
packages in pip_install to the default for ENABLED_PYTHON3_PACKAGES,
except swift which is not enabled by default for now.

Add enable_python3_package and disable_python3_package functions to make
editing the variables from local.conf easier.

Add python3_enabled_for and python3_disabled_for functions to check the
settings against packages being installed by pip.

Update pip_install to check if python3 is disabled for a service, then
see if it is explicitly enabled, and only then fall back to looking at
the classifiers in the packaging metadata.

Update pip_install messages to give more detail about why the choice
between python 2 and 3 is being made for a given package.

Change-Id: I69857d4e11f4767928614a3b637c894bcd03491f
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/25/418125/2 && git format-patch -1 --stdout FETCH_HEAD,"['inc/python', 'stackrc']",2,4b35820b7561221d9fd22f2c49ab656261e69770,python3-whitelist,"# Control whether Python 3 should be used at all.# Control whether Python 3 is enabled for specific services by the # base name of the directory from which they are installed. See # enable_python3 to edit this variable and use_python3_for to test # membership. export ENABLED_PYTHON3=""nova,glance,cinder,uwsgi"" # Explicitly list services not to run under Python 3. See # disable_python3 to edit this variable. export DISABLED_PYTHON3="""" ",# Control whether Python 3 should be used.,123,8
openstack%2Fmagnum~stable%2Fnewton~I7e62c5d27008baeed2c617dccd9428c5fbffbe77,openstack/magnum,stable/newton,I7e62c5d27008baeed2c617dccd9428c5fbffbe77,Updated from global requirements,MERGED,2017-02-27 14:48:07.000000000,2017-02-28 16:35:59.000000000,2017-02-28 16:35:59.000000000,"[{'_account_id': 3}, {'_account_id': 7230}, {'_account_id': 13861}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-27 14:48:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/324c8bcf5bc7f9138a60ff035583fcaf28680463', 'message': 'Updated from global requirements\n\nChange-Id: I7e62c5d27008baeed2c617dccd9428c5fbffbe77\n'}]",0,438525,324c8bcf5bc7f9138a60ff035583fcaf28680463,16,4,1,11131,,,0,"Updated from global requirements

Change-Id: I7e62c5d27008baeed2c617dccd9428c5fbffbe77
",git fetch https://review.opendev.org/openstack/magnum refs/changes/25/438525/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,324c8bcf5bc7f9138a60ff035583fcaf28680463,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fgnocchi~master~I7692d604a6c6273f96237699eb3d02ef22d3edd5,openstack/gnocchi,master,I7692d604a6c6273f96237699eb3d02ef22d3edd5,You should change tox version into latest version for test code,ABANDONED,2017-02-28 16:21:39.000000000,2017-02-28 16:33:44.000000000,,[{'_account_id': 1669}],"[{'number': 1, 'created': '2017-02-28 16:21:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a09de5fefe27f46eaf9c85e1cc7fc007e590892d', 'message': 'You should change tox version into latest version for test code\n\nChange-Id: I7692d604a6c6273f96237699eb3d02ef22d3edd5\n'}]",0,439043,a09de5fefe27f46eaf9c85e1cc7fc007e590892d,3,1,1,25291,,,0,"You should change tox version into latest version for test code

Change-Id: I7692d604a6c6273f96237699eb3d02ef22d3edd5
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/43/439043/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a09de5fefe27f46eaf9c85e1cc7fc007e590892d,gno/v001,# Up-to-Date tox version minversion = 1.9,minversion = 1.8,2,1
openstack%2Fpuppet-manila~master~Iba227143a561d5808686c5e73a9299e73bf82d52,openstack/puppet-manila,master,Iba227143a561d5808686c5e73a9299e73bf82d52,Remove rpc_backend check for amqp,MERGED,2017-02-28 15:17:03.000000000,2017-02-28 16:33:29.000000000,2017-02-28 16:33:29.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-28 15:17:03.000000000', 'files': ['spec/classes/manila_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/a9515d39d81acd2fb81d25bdfa9ce922dba5ae1b', 'message': 'Remove rpc_backend check for amqp\n\nI7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend\ndeclaration for amqp so we need to stop checking for it in the unit\ntests.\n\nChange-Id: Iba227143a561d5808686c5e73a9299e73bf82d52\n'}]",0,439004,a9515d39d81acd2fb81d25bdfa9ce922dba5ae1b,7,2,1,14985,,,0,"Remove rpc_backend check for amqp

I7ccd995ef01c2d54427684718adba054260fdd52 removed the rpc_backend
declaration for amqp so we need to stop checking for it in the unit
tests.

Change-Id: Iba227143a561d5808686c5e73a9299e73bf82d52
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/04/439004/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/manila_init_spec.rb'],1,a9515d39d81acd2fb81d25bdfa9ce922dba5ae1b,remove-rpc_backend,, it { is_expected.to contain_manila_config('DEFAULT/rpc_backend').with_value('amqp') },0,1
openstack%2Fpython-freezerclient~master~I69a05772728ae7ef1741083242a399c43a0b58d6,openstack/python-freezerclient,master,I69a05772728ae7ef1741083242a399c43a0b58d6,Updated from global requirements,MERGED,2017-02-24 00:15:42.000000000,2017-02-28 16:32:07.000000000,2017-02-28 16:32:07.000000000,"[{'_account_id': 3}, {'_account_id': 13940}, {'_account_id': 14509}]","[{'number': 1, 'created': '2017-02-24 00:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/c0368e5e9f28d35a39cf65a5efa23e6ab70dfe58', 'message': 'Updated from global requirements\n\nChange-Id: I69a05772728ae7ef1741083242a399c43a0b58d6\n'}, {'number': 2, 'created': '2017-02-27 01:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/a81733d1911facbcb14cd02853809acd00c3f686', 'message': 'Updated from global requirements\n\nChange-Id: I69a05772728ae7ef1741083242a399c43a0b58d6\n'}, {'number': 3, 'created': '2017-02-28 14:05:46.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/bd90fdb5bba68c42fb05322a5d65405f18d6ca7e', 'message': 'Updated from global requirements\n\nChange-Id: I69a05772728ae7ef1741083242a399c43a0b58d6\n'}]",0,437736,bd90fdb5bba68c42fb05322a5d65405f18d6ca7e,11,3,3,11131,,,0,"Updated from global requirements

Change-Id: I69a05772728ae7ef1741083242a399c43a0b58d6
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/36/437736/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c0368e5e9f28d35a39cf65a5efa23e6ab70dfe58,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fbarbican~master~Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,openstack/barbican,master,Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11,** TEST - Do Not Merge **,ABANDONED,2016-10-03 12:57:13.000000000,2017-02-28 16:29:58.000000000,,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 11561}]","[{'number': 1, 'created': '2016-10-03 12:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c473d4248c1bf8a9b6d259a7035aa4e7bfdc750b', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}, {'number': 2, 'created': '2016-10-11 13:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3c58ec80bd0f367cd7d4532c4bb8d1b3eee7ca63', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}, {'number': 3, 'created': '2016-10-26 11:58:52.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3d849806270b2d25f04279ec2e128047d6da580b', 'message': '** TEST - Do Not Merge **\n\nChange-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11\n'}]",0,381099,3d849806270b2d25f04279ec2e128047d6da580b,13,3,3,11561,,,0,"** TEST - Do Not Merge **

Change-Id: Icefe61f8cbbd04d418142f5e84b22d2ddeec9c11
",git fetch https://review.opendev.org/openstack/barbican refs/changes/99/381099/3 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,c473d4248c1bf8a9b6d259a7035aa4e7bfdc750b,,,,1,0
openstack%2Ftripleo-heat-templates~master~Iaa56eb40ed80d20744cf8bab18504d700466d26e,openstack/tripleo-heat-templates,master,Iaa56eb40ed80d20744cf8bab18504d700466d26e,Add auditd upgrate steps,MERGED,2017-02-26 20:37:24.000000000,2017-02-28 16:25:52.000000000,2017-02-28 15:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 8449}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-26 20:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/56a875318f30f94db0c00219f8d2814f36b47792', 'message': 'Add auditd upgrate steps\n\nAdd base upgrade steps for auditd\n\nChange-Id: Iaa56eb40ed80d20744cf8bab18504d700466d26e\n'}, {'number': 2, 'created': '2017-02-26 21:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f88910c1e0b3f46c00f0e81c12d571f8c2b96292', 'message': 'Add auditd upgrate steps\n\nAdd base upgrade steps for auditd\n\nChange-Id: Iaa56eb40ed80d20744cf8bab18504d700466d26e\n'}, {'number': 3, 'created': '2017-02-26 21:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c86cd794f956ff7d276b261870bd650dc897a7d1', 'message': 'Add auditd upgrate steps\n\nAdd base upgrade steps for auditd\n\nChange-Id: Iaa56eb40ed80d20744cf8bab18504d700466d26e\n'}, {'number': 4, 'created': '2017-02-28 08:42:54.000000000', 'files': ['puppet/services/auditd.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5838d6f765a1ca9535b5d57c1299439040a5def2', 'message': 'Add auditd upgrate steps\n\nAdd base upgrade steps for auditd\n\nChange-Id: Iaa56eb40ed80d20744cf8bab18504d700466d26e\n'}]",0,438289,5838d6f765a1ca9535b5d57c1299439040a5def2,20,5,4,20775,,,0,"Add auditd upgrate steps

Add base upgrade steps for auditd

Change-Id: Iaa56eb40ed80d20744cf8bab18504d700466d26e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/438289/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/auditd.yaml'],1,56a875318f30f94db0c00219f8d2814f36b47792,bp/overcloud-upgrades-per-service," upgrade_tasks: - name: ""PreUpgrade step0,validation: Check if auditd is running"" shell: > /usr/bin/systemctl show 'auditd' --property ActiveState | grep '\bactive\b' tags: step0,validation - name: Stop auditd service tags: step2 service: name=auditd state=stopped",,9,0
openstack%2Ftripleo-heat-templates~master~I316e14317e0586e895dcb4e084aa54e7665f6a20,openstack/tripleo-heat-templates,master,I316e14317e0586e895dcb4e084aa54e7665f6a20,Add zaqar service for composable upgrade,MERGED,2017-02-20 09:45:48.000000000,2017-02-28 16:25:37.000000000,2017-02-28 15:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-20 09:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c417e1cb3b48e46b07ced056bef57ab46e1883b1', 'message': 'Add zaqar service for composable upgrade\n\nChange-Id: I316e14317e0586e895dcb4e084aa54e7665f6a20\n'}, {'number': 2, 'created': '2017-02-28 08:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7a1dbc5da2733474c895d9454978ef99b6132de', 'message': 'Add zaqar service for composable upgrade\n\nChange-Id: I316e14317e0586e895dcb4e084aa54e7665f6a20\n'}, {'number': 3, 'created': '2017-02-28 10:08:25.000000000', 'files': ['puppet/services/zaqar.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2cebb99729005a31fbe24a957d2db84397f1952a', 'message': 'Add zaqar service for composable upgrade\n\nChange-Id: I316e14317e0586e895dcb4e084aa54e7665f6a20\n'}]",0,435906,2cebb99729005a31fbe24a957d2db84397f1952a,17,4,3,20775,,,0,"Add zaqar service for composable upgrade

Change-Id: I316e14317e0586e895dcb4e084aa54e7665f6a20
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/435906/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/zaqar.yaml'],1,c417e1cb3b48e46b07ced056bef57ab46e1883b1,bp/overcloud-upgrades-per-service," upgrade_tasks: - name: ""PreUpgrade step0,validation: Check if openstack-zaqar is running"" shell: > /usr/bin/systemctl show 'openstack-zaqar' --property ActiveState | grep '\bactive\b' tags: step0,validation - name: Stop zaqar service tags: step2 service: name=openstack-zaqar state=stopped",,9,0
openstack%2Fkolla-ansible~master~Id542971057a9116eef679f1eb0827266eb18ba30,openstack/kolla-ansible,master,Id542971057a9116eef679f1eb0827266eb18ba30,"Add the missing ""ironic_inspector"" into precheks",MERGED,2017-02-26 06:40:15.000000000,2017-02-28 16:20:51.000000000,2017-02-28 16:20:50.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-02-26 06:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/adcf652815a788402790d4c05edd801f727734e9', 'message': 'Add the missing ""ironic_inspector"" into precheks\n\n- remove the unnecessary blank\n- add ""ironic_inspector"" into its own prechecks and haproxy prechecks\n\nChange-Id: Id542971057a9116eef679f1eb0827266eb18ba30\n'}, {'number': 2, 'created': '2017-02-27 07:57:47.000000000', 'files': ['ansible/group_vars/all.yml', 'ansible/roles/ironic/tasks/precheck.yml', 'ansible/roles/haproxy/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a82aadd9822ecf1b66d24b88a48a5215a65e1440', 'message': 'Add the missing ""ironic_inspector"" into precheks\n\n- remove the unnecessary blank\n- add ""ironic_inspector"" into its own prechecks and haproxy prechecks\n\nChange-Id: Id542971057a9116eef679f1eb0827266eb18ba30\nCloses-bug: #1668178\n'}]",0,438233,a82aadd9822ecf1b66d24b88a48a5215a65e1440,14,3,2,22165,,,0,"Add the missing ""ironic_inspector"" into precheks

- remove the unnecessary blank
- add ""ironic_inspector"" into its own prechecks and haproxy prechecks

Change-Id: Id542971057a9116eef679f1eb0827266eb18ba30
Closes-bug: #1668178
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/33/438233/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'ansible/roles/ironic/tasks/precheck.yml', 'ansible/roles/haproxy/tasks/precheck.yml']",3,adcf652815a788402790d4c05edd801f727734e9,bug/1668178,"- name: Checking free port for Ironic Inspector HAProxy wait_for: host: ""{{ kolla_internal_vip_address }}"" port: ""{{ ironic_inspector_port }}"" connect_timeout: 1 state: stopped when: - enable_ironic | bool - inventory_hostname in groups['haproxy'] - ""{{ 'ironic_inspector' not in haproxy_stat }}"" ",,22,1
openstack%2Ftripleo-heat-templates~master~I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915,openstack/tripleo-heat-templates,master,I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915,Add support for upgrading ec2-api,MERGED,2017-01-25 16:57:34.000000000,2017-02-28 16:18:39.000000000,2017-02-28 14:32:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-01-25 16:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f96a04f527b92ba0b0d30adbb9b7c2615d085637', 'message': 'Add support for upgrading ec2-api\n\nChange-Id: I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915\n'}, {'number': 2, 'created': '2017-02-20 10:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/25f5e5ef27d2a703d7eb7e9d53a471dbfd93e83a', 'message': 'Add support for upgrading ec2-api\n\nChange-Id: I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915\n'}, {'number': 3, 'created': '2017-02-28 08:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/998c4c706bf55b238316ce846ae0b53fa8d8b1db', 'message': 'Add support for upgrading ec2-api\n\nChange-Id: I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915\n'}, {'number': 4, 'created': '2017-02-28 10:07:03.000000000', 'files': ['puppet/services/ec2-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b6214b0c5b92c85dbfa45007295db70888b509ab', 'message': 'Add support for upgrading ec2-api\n\nChange-Id: I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915\n'}]",0,425285,b6214b0c5b92c85dbfa45007295db70888b509ab,27,4,4,20775,,,0,"Add support for upgrading ec2-api

Change-Id: I2703dd1a7e3eefa0ad6f7b74183101de6c1ad915
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/425285/4 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/ec2-api.yaml'],1,f96a04f527b92ba0b0d30adbb9b7c2615d085637,bp/overcloud-upgrades-per-service, upgrade_tasks: - name: Stop ec2_api service tags: step2 service: name=openstack-ec2-api state=stopped ,,5,0
openstack%2Fbarbican~master~I0b7299f10495533fd7b442d76c7c0aaad141dad4,openstack/barbican,master,I0b7299f10495533fd7b442d76c7c0aaad141dad4,Improve error handling for invalid resource ID,ABANDONED,2016-07-20 15:58:48.000000000,2017-02-28 16:13:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-07-20 15:58:48.000000000', 'files': ['barbican/api/controllers/secrets.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/5038b7b0d7fa5fe000dc15ce1707b0baf6a4f673', 'message': 'Improve error handling for invalid resource ID\n\nWhen retrieving secret with invalid formatted UUID, added checks\nto validate UUID format and only then make request to db.\n\nChange-Id: I0b7299f10495533fd7b442d76c7c0aaad141dad4\nCloses-Bug: #1603828\n'}]",0,344902,5038b7b0d7fa5fe000dc15ce1707b0baf6a4f673,3,1,1,17536,,,0,"Improve error handling for invalid resource ID

When retrieving secret with invalid formatted UUID, added checks
to validate UUID format and only then make request to db.

Change-Id: I0b7299f10495533fd7b442d76c7c0aaad141dad4
Closes-Bug: #1603828
",git fetch https://review.opendev.org/openstack/barbican refs/changes/02/344902/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/api/controllers/secrets.py'],1,5038b7b0d7fa5fe000dc15ce1707b0baf6a4f673,,"def _invalid_secret_id(): """"""Throw exception that secret id format is invalid."""""" pecan.abort(404, u._(""Invalid secret id format."")) def _valid_secret_id_format(self, secret_id): if len(secret_id) != 36: return False idParts = secret_id.split('-') if len(idParts) != 5: return False if ((len(idParts[0]) != 8) or (len(idParts[1]) != 4) or (len(idParts[2]) != 4) or (len(idParts[3]) != 4) or (len(idParts[4]) != 12)): return False return True # Check for valid secret_id format before making call to db. if not self._valid_secret_id_format(str(secret_id)): _invalid_secret_id() ",,24,0
openstack%2Fpbr~master~Icfb58195c58813e98ab48943119f53c7711331ec,openstack/pbr,master,Icfb58195c58813e98ab48943119f53c7711331ec,doc: Clarify sections in 'setup.cfg',MERGED,2017-02-27 14:32:03.000000000,2017-02-28 16:12:08.000000000,2017-02-28 16:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2017-02-27 14:32:03.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/pbr/commit/028f82e6a7584127ae4590be1b0d42e50d60e539', 'message': ""doc: Clarify sections in 'setup.cfg'\n\nClarify what tools provide what sections in 'setup.cfg', thus explaining\nwhy, for example, I couldn't find any references to '[build_sphinx]' in\neither the pbr or setuptools source.\n\nComments are not a section, so this little bit of info is moved to a\n'note'.\n\nChange-Id: Icfb58195c58813e98ab48943119f53c7711331ec\n""}]",0,438509,028f82e6a7584127ae4590be1b0d42e50d60e539,7,3,1,15334,,,0,"doc: Clarify sections in 'setup.cfg'

Clarify what tools provide what sections in 'setup.cfg', thus explaining
why, for example, I couldn't find any references to '[build_sphinx]' in
either the pbr or setuptools source.

Comments are not a section, so this little bit of info is moved to a
'note'.

Change-Id: Icfb58195c58813e98ab48943119f53c7711331ec
",git fetch https://review.opendev.org/openstack/pbr refs/changes/09/438509/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,028f82e6a7584127ae4590be1b0d42e50d60e539,feat/remove-warnerrors,"pbr provides its own section in these documents, ostensibly called `pbr`. Most other sections are provided by setuptools and may influence either the build itself or the output of various `setuptools commands`__. The remaining sections are provided by libraries that provide setuptools extensions, such as `extract_mesages` (provided by `Babel`__) or `sphinx_build` (provided by `Sphinx`__). Some of these are described below. __ https://setuptools.readthedocs.io/en/latest/setuptools.html#command-reference __ http://babel.pocoo.org/en/latest/setup.html __ http://www.sphinx-doc.org/en/stable/setuptools.html .. note:: Comments may be used in `setup.cfg`, however all comments should start with a `#` and may be on a single line, or in line, with at least one white space character immediately preceding the `#`. Semicolons are not a supported comment delimiter. For instance:: [section] # A comment at the start of a dedicated line key = value1 # An in line comment value2 # A comment on a dedicated line value3The ``pbr`` section controls pbr specific options and behaviours. This is especially true if the ``[sphinx_build] warning-is-error`` option is set. See the `Sphinx build configuration file`_ documentation for more information on configuring Sphinx. entry_points ~~~~~~~~~~~~ The ``entry_points`` section defines entry points for generated console scripts and python libraries. This is actually provided by `setuptools`__ but is documented here owing to its importance. The general syntax of specifying entry points is a top level name indicating the entry point group name, followed by one or more key value pairs naming the entry point to be installed. For instance:: [entry_points] console_scripts = pbr = pbr.cmd:main pbr.config.drivers = plain = pbr.cfg.driver:Plain fancy = pbr.cfg.driver:Fancy Will cause a console script called `pbr` to be installed that executes the `main` function found in `pbr.cmd`. Additionally, two entry points will be installed for `pbr.config.drivers`, one called `plain` which maps to the `Plain` class in `pbr.cfg.driver` and one called `fancy` which maps to the `Fancy` class in `pbr.cfg.driver`. __ https://setuptools.readthedocs.io/en/latest/setuptools.html#options","There are a number of sections in these documents. These are: * metadata * files * entry_points * pbrentry_points ~~~~~~~~~~~~ The `entry_points` section defines entry points for generated console scripts and python libraries. The general syntax of specifying entry points is a top level name indicating the entry point group name, followed by one or more key value pairs naming the entry point to be installed. For instance:: [entry_points] console_scripts = pbr = pbr.cmd:main pbr.config.drivers = plain = pbr.cfg.driver:Plain fancy = pbr.cfg.driver:Fancy Will cause a console script called `pbr` to be installed that executes the `main` function found in `pbr.cmd`. Additionally, two entry points will be installed for `pbr.config.drivers`, one called `plain` which maps to the `Plain` class in `pbr.cfg.driver` and one called `fancy` which maps to the `Fancy` class in `pbr.cfg.driver`. The pbr section controls pbr specific options and behaviours.The ``warnerrors`` boolean option is used to tell Sphinx builders to treat warnings as errors which will cause sphinx-build to fail if it encounters warnings. This is generally useful to ensure your documentation stays clean once you have a good docs build. This is especially true if the ``warnerrors=True`` option is set. See the `Sphinx build configuration file`_ documentation for more information on configuring Sphinx. Comments ~~~~~~~~ Comments may be used in `setup.cfg`, however all comments should start with a `#` and may be on a single line, or in line, with at least one white space character immediately preceding the `#`. Semicolons are not a supported comment delimiter. For instance:: [section] # A comment at the start of a dedicated line key = value1 # An in line comment value2 # A comment on a dedicated line value3",51,51
openstack%2Ftripleo-heat-templates~master~Ida247fe29500ff02b76602c785a3f42fa4291227,openstack/tripleo-heat-templates,master,Ida247fe29500ff02b76602c785a3f42fa4291227,Switch central and compute templates to use polling agent,MERGED,2017-02-07 21:16:48.000000000,2017-02-28 16:09:58.000000000,2017-02-28 16:09:58.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-07 21:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/167f8cced46f97e3d8915de770a8892439fd3bcb', 'message': 'Switch central and compute templates to use polling agent\n\nCeilometer central and compute agent classes are deprecated. Instead\npolling agent should be used with relevant namespaces.\n\nChange-Id: Ida247fe29500ff02b76602c785a3f42fa4291227\nDepends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 2, 'created': '2017-02-08 00:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/25889fc2feab69f6a1b6df189b57fc2c55b32d88', 'message': 'Switch central and compute templates to use polling agent\n\nCeilometer central and compute agent classes are deprecated. Instead\npolling agent should be used with relevant namespaces.\n\nChange-Id: Ida247fe29500ff02b76602c785a3f42fa4291227\nDepends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 3, 'created': '2017-02-15 15:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/57b953bd43a6108561197ee797699560ab2b2fbe', 'message': 'Switch central and compute templates to use polling agent\n\nCeilometer central and compute agent classes are deprecated. Instead\npolling agent should be used with relevant namespaces.\n\nChange-Id: Ida247fe29500ff02b76602c785a3f42fa4291227\nDepends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 4, 'created': '2017-02-22 16:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/376b8735c996eb3e04c42976d0d2c420eb3f9441', 'message': 'Switch central and compute templates to use polling agent\n\nCeilometer central and compute agent classes are deprecated. Instead\npolling agent should be used with relevant namespaces.\n\nChange-Id: Ida247fe29500ff02b76602c785a3f42fa4291227\nDepends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 5, 'created': '2017-02-25 17:19:52.000000000', 'files': ['puppet/services/ceilometer-agent-central.yaml', 'puppet/services/ceilometer-agent-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/873ab8eb4c49274d92b0c29f3e08b696e05082d6', 'message': 'Switch central and compute templates to use polling agent\n\nCeilometer central and compute agent classes are deprecated. Instead\npolling agent should be used with relevant namespaces.\n\nChange-Id: Ida247fe29500ff02b76602c785a3f42fa4291227\nDepends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}]",0,430444,873ab8eb4c49274d92b0c29f3e08b696e05082d6,33,4,5,6924,,,0,"Switch central and compute templates to use polling agent

Ceilometer central and compute agent classes are deprecated. Instead
polling agent should be used with relevant namespaces.

Change-Id: Ida247fe29500ff02b76602c785a3f42fa4291227
Depends-On: I1ee50124bf8936e12414f984e1bcd4545d92e953
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/430444/5 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/ceilometer-agent-central.yaml', 'puppet/services/ceilometer-agent-compute.yaml']",2,167f8cced46f97e3d8915de770a8892439fd3bcb,polling-agent, compute_namespace: true include ::tripleo::profile::base::ceilometer::agent::polling, include ::tripleo::profile::base::ceilometer::agent::compute,4,2
openstack%2Fbarbican~master~I22350508ae898acf3f09485f00183659d63fcc61,openstack/barbican,master,I22350508ae898acf3f09485f00183659d63fcc61,Update git url in README,ABANDONED,2016-07-14 01:34:14.000000000,2017-02-28 16:09:47.000000000,,"[{'_account_id': 3}, {'_account_id': 7973}, {'_account_id': 21242}, {'_account_id': 21797}]","[{'number': 1, 'created': '2016-07-14 01:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/96e60d5cb37134bb7108b34cd8108b470282e91c', 'message': 'Update git url in README\n\nChange-Id: I22350508ae898acf3f09485f00183659d63fcc61\n'}, {'number': 2, 'created': '2016-07-15 00:14:18.000000000', 'files': ['devstack/README.md'], 'web_link': 'https://opendev.org/openstack/barbican/commit/f9408b56f1171c87db92855ea330b84668f33aa0', 'message': 'Update git url in README\n\nChange-Id: I22350508ae898acf3f09485f00183659d63fcc61\nCloses-Bug: #1602903\n'}]",1,341898,f9408b56f1171c87db92855ea330b84668f33aa0,8,4,2,21423,,,0,"Update git url in README

Change-Id: I22350508ae898acf3f09485f00183659d63fcc61
Closes-Bug: #1602903
",git fetch https://review.opendev.org/openstack/barbican refs/changes/98/341898/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/README.md'],1,96e60d5cb37134bb7108b34cd8108b470282e91c,bug/1602903, enable_plugin barbican https://github.com/openstack/barbican.git stable/liberty, enable_plugin barbican https://git.openstack.org/openstack/barbican stable/liberty,1,1
openstack%2Ftripleo-heat-templates~stable%2Focata~I700a711473d10a50fad6b1797453a74c0cdff54b,openstack/tripleo-heat-templates,stable/ocata,I700a711473d10a50fad6b1797453a74c0cdff54b,Install openstack-panko-api on upgrade,MERGED,2017-02-27 12:02:19.000000000,2017-02-28 16:07:34.000000000,2017-02-28 15:23:08.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 18851}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-27 12:02:19.000000000', 'files': ['puppet/services/panko-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/74561e6909907be589b189d599f36d880b0f097e', 'message': ""Install openstack-panko-api on upgrade\n\nThis doesn't exist in newton images, so install it via the\nansible tasks during step3 (when all other packages are updated).\n\nChange-Id: I700a711473d10a50fad6b1797453a74c0cdff54b\nCloses-Bug: 1667965\n(cherry picked from commit 63cb515c602d8a231a086b1db098c129ed81eaff)\n""}]",0,438462,74561e6909907be589b189d599f36d880b0f097e,16,4,1,3153,,,0,"Install openstack-panko-api on upgrade

This doesn't exist in newton images, so install it via the
ansible tasks during step3 (when all other packages are updated).

Change-Id: I700a711473d10a50fad6b1797453a74c0cdff54b
Closes-Bug: 1667965
(cherry picked from commit 63cb515c602d8a231a086b1db098c129ed81eaff)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/438462/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/panko-api.yaml'],1,74561e6909907be589b189d599f36d880b0f097e,bp/overcloud-upgrades-per-service," upgrade_tasks: # The panko API isn't installed in newton images, so install # it on upgrade - name: Install openstack-panko-api packages on upgrade tags: step3 yum: name=openstack-panko-api state=latest",,6,0
openstack%2Fbarbican~master~Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11,openstack/barbican,master,Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11,Clean up methods for secrets and containers,ABANDONED,2016-05-20 19:36:47.000000000,2017-02-28 16:07:34.000000000,,"[{'_account_id': 3}, {'_account_id': 10873}, {'_account_id': 10928}]","[{'number': 1, 'created': '2016-05-20 19:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/980e9fd8aab8cfa8ed625ac68f60342383a16380', 'message': 'Clean up methods for secrets and containers\n\nThis CR is adding calls to the clean up methods of secrets and\ncontainers before the functional tests, making sure that there\nare no resources for the test users (using quota) when the tests\nrun.\n\nChange-Id: Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11\n'}, {'number': 2, 'created': '2016-06-01 15:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0ee2939dfef06246eabdcbaeeda1499608a3e3ee', 'message': 'Clean up methods for secrets and containers\n\nThis CR is adding calls to the clean up methods of secrets and\ncontainers before the functional tests, making sure that there\nare no resources for the test users (using quota) when the tests\nrun.\n\nChange-Id: Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11\n'}, {'number': 3, 'created': '2016-06-02 03:19:30.000000000', 'files': ['functionaltests/api/v1/functional/test_containers.py', 'functionaltests/api/v1/functional/test_secrets.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/419308c116a8fa59298bf8f564d2885975808426', 'message': 'Clean up methods for secrets and containers\n\nThis CR is adding calls to the clean up methods of secrets and\ncontainers before the functional tests, making sure that there\nare no resources for the test users (using quota) when the tests\nrun.\n\nChange-Id: Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11\n'}]",0,319424,419308c116a8fa59298bf8f564d2885975808426,13,3,3,10928,,,0,"Clean up methods for secrets and containers

This CR is adding calls to the clean up methods of secrets and
containers before the functional tests, making sure that there
are no resources for the test users (using quota) when the tests
run.

Change-Id: Idf47f71cfefb33b4e995eb1c4f0604d8326a4a11
",git fetch https://review.opendev.org/openstack/barbican refs/changes/24/319424/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/v1/functional/test_containers.py', 'functionaltests/api/v1/functional/test_secrets.py']",2,980e9fd8aab8cfa8ed625ac68f60342383a16380,CleanUp, self._cleanup_all_secrets(),,2,0
openstack%2Fopenstack-ansible~stable%2Fnewton~Iacefb4f2768a4b58af6a2c7565502f2ca4cacd79,openstack/openstack-ansible,stable/newton,Iacefb4f2768a4b58af6a2c7565502f2ca4cacd79,Bump BIRD and etcd role pins,MERGED,2017-02-27 20:17:22.000000000,2017-02-28 16:05:55.000000000,2017-02-28 16:05:55.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-27 20:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/37e415197f24d1f3ea0a76bcf80e0da37426da5e', 'message': 'Bump BIRD and etcd role pins\n\nPull in updated tags for the BIRD and etcd roles that include minor\nbugfixes.\n\nDiff for bird:\nhttps://github.com/Logan2211/ansible-bird/compare/1.1...1.2\n\nDiff for etcd:\nhttps://github.com/Logan2211/ansible-etcd/compare/1.1...1.2\n\nChange-Id: Iacefb4f2768a4b58af6a2c7565502f2ca4cacd79\n'}, {'number': 2, 'created': '2017-02-28 08:12:36.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8faa249c940fd5455e1063680c642207301c0d97', 'message': 'Bump BIRD and etcd role pins\n\nPull in updated tags for the BIRD and etcd roles that include minor\nbugfixes.\n\nDiff for bird:\nhttps://github.com/Logan2211/ansible-bird/compare/1.1...1.2\n\nDiff for etcd:\nhttps://github.com/Logan2211/ansible-etcd/compare/1.1...1.2\n\nChange-Id: Iacefb4f2768a4b58af6a2c7565502f2ca4cacd79\n'}]",0,438688,8faa249c940fd5455e1063680c642207301c0d97,9,3,2,17799,,,0,"Bump BIRD and etcd role pins

Pull in updated tags for the BIRD and etcd roles that include minor
bugfixes.

Diff for bird:
https://github.com/Logan2211/ansible-bird/compare/1.1...1.2

Diff for etcd:
https://github.com/Logan2211/ansible-etcd/compare/1.1...1.2

Change-Id: Iacefb4f2768a4b58af6a2c7565502f2ca4cacd79
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/88/438688/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible-role-requirements.yml'],1,37e415197f24d1f3ea0a76bcf80e0da37426da5e,bump-upstream-role, version: '1.2' version: '1.2', version: '1.1' version: '1.1',2,2
openstack%2Fkolla~stable%2Focata~Ibe78c1f3e0179d36b54839c6135d05cc6f0f84a0,openstack/kolla,stable/ocata,Ibe78c1f3e0179d36b54839c6135d05cc6f0f84a0,Updated from global requirements,MERGED,2017-02-27 15:14:39.000000000,2017-02-28 16:05:23.000000000,2017-02-28 16:05:23.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 16620}, {'_account_id': 22165}, {'_account_id': 23717}]","[{'number': 1, 'created': '2017-02-27 15:14:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/79f50996e488e70bbf1eb2f87c2033e93bfb678a', 'message': 'Updated from global requirements\n\nChange-Id: Ibe78c1f3e0179d36b54839c6135d05cc6f0f84a0\n'}]",0,438542,79f50996e488e70bbf1eb2f87c2033e93bfb678a,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ibe78c1f3e0179d36b54839c6135d05cc6f0f84a0
",git fetch https://review.opendev.org/openstack/kolla refs/changes/42/438542/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,79f50996e488e70bbf1eb2f87c2033e93bfb678a,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Freleases~master~Ic8e0a9d28afb0eee435dec48559799bcd0392640,openstack/releases,master,Ic8e0a9d28afb0eee435dec48559799bcd0392640,Prepare etherpad output for manual formatting,MERGED,2017-02-17 14:42:41.000000000,2017-02-28 16:04:37.000000000,2017-02-28 16:04:37.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2017-02-17 14:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7979a35130658acfce8f674a40e958265b33b752', 'message': 'Prepare etherpad output for manual formatting\n\nTo facilitate manual formatting, just output the content once\nand expect the user to apply formatting in bulk, then copy paste\nto every week.\n\nChange-Id: Ic8e0a9d28afb0eee435dec48559799bcd0392640\n'}, {'number': 2, 'created': '2017-02-17 14:59:14.000000000', 'files': ['openstack_releases/cmds/make_tracking_pad.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/b9760f819065cff13c2ce73519911986da5f2924', 'message': 'Prepare etherpad output for manual formatting\n\nTo facilitate manual formatting, just output the content once\nand expect the user to apply formatting in bulk, then copy paste\nto every week.\n\nChange-Id: Ic8e0a9d28afb0eee435dec48559799bcd0392640\n'}]",0,435476,b9760f819065cff13c2ce73519911986da5f2924,8,2,2,308,,,0,"Prepare etherpad output for manual formatting

To facilitate manual formatting, just output the content once
and expect the user to apply formatting in bulk, then copy paste
to every week.

Change-Id: Ic8e0a9d28afb0eee435dec48559799bcd0392640
",git fetch https://review.opendev.org/openstack/releases refs/changes/76/435476/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_releases/cmds/make_tracking_pad.py'],1,7979a35130658acfce8f674a40e958265b33b752,add-make-tracking-pad," print('First apply title formatting to all week titles. Then apply list') print('format to the following content, and copy-paste it in every week:') print() print('Team availability notes') print('Tasks') print('Meeting Agenda') print('Countdown email content to send this week') print() ", print() print('Team availability notes') print('Tasks') print('Meeting Agenda') print('Countdown email content to send this week') print(),9,6
openstack%2Fironic-ui~master~If75b79927e9cbb269057dc5311ef8f5ccc6a1f32,openstack/ironic-ui,master,If75b79927e9cbb269057dc5311ef8f5ccc6a1f32,Replace ironic with ironic-ui in contributing doc,MERGED,2017-02-14 02:29:26.000000000,2017-02-28 15:59:06.000000000,2017-02-28 15:59:06.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-14 02:29:26.000000000', 'files': ['doc/source/contributing.rst'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/de0e12581d78c1c89a0d109d196d17c148d53c5c', 'message': 'Replace ironic with ironic-ui in contributing doc\n\nIn contributing doc, some links and informations are still for\nironic, we should change to use ironic-ui.\n\nChange-Id: If75b79927e9cbb269057dc5311ef8f5ccc6a1f32\n'}]",0,433401,de0e12581d78c1c89a0d109d196d17c148d53c5c,8,3,1,6610,,,0,"Replace ironic with ironic-ui in contributing doc

In contributing doc, some links and informations are still for
ironic, we should change to use ironic-ui.

Change-Id: If75b79927e9cbb269057dc5311ef8f5ccc6a1f32
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/01/433401/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributing.rst'],1,de0e12581d78c1c89a0d109d196d17c148d53c5c,correct-doc,"In order to contribute to the Ironic UI project, you need to have * https://launchpad.net/ironic-ui","In order to contribute to the Ironic project, you need to have * https://launchpad.net/ironic",2,2
openstack%2Fironic-ui~master~I2af9385e2d9532a9ec46993d65f8c510e419b6c9,openstack/ironic-ui,master,I2af9385e2d9532a9ec46993d65f8c510e419b6c9,Add support for manual cleaning of nodes,MERGED,2017-02-09 16:46:25.000000000,2017-02-28 15:58:59.000000000,2017-02-28 15:58:59.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-09 16:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/fc42b077c1068faa3baae90cb04de5d7430c77b6', 'message': 'Add support for manual cleaning of nodes\n\n- The action list associated with a node in manageable state will have\na ""Clean"" item.\n- When the clean action is initiated the user is prompted with a modal\ndialog in which he or she enters or copies a set of cleaning steps\nin JSON format.\n- Basic validation is performed on the JSON. The user is able to\nsubmit the cleaning request only when validation is successful.\n- Cleaning is not currently available as a batch action.\n\nChange-Id: I2af9385e2d9532a9ec46993d65f8c510e419b6c9\nCloses-Bug: #1648559\n'}, {'number': 2, 'created': '2017-02-14 16:56:47.000000000', 'files': ['ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/api/ironic_rest_api.py', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-state-transition.service.js', 'ironic_ui/api/ironic.py', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.service.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.html'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/736c2dab5466a5187cea36732c35a5834d9978eb', 'message': 'Add support for manual cleaning of nodes\n\n- The action list associated with a node in manageable state will have\na ""Clean"" item.\n- When the clean action is initiated the user is prompted with a modal\ndialog in which he or she enters or copies a set of cleaning steps\nin JSON format.\n- Basic validation is performed on the JSON. The user is able to\nsubmit the cleaning request only when validation is successful.\n- Cleaning is not currently available as a batch action.\n\nChange-Id: I2af9385e2d9532a9ec46993d65f8c510e419b6c9\nCloses-Bug: #1648559\n'}]",0,431642,736c2dab5466a5187cea36732c35a5834d9978eb,9,3,2,19380,,,0,"Add support for manual cleaning of nodes

- The action list associated with a node in manageable state will have
a ""Clean"" item.
- When the clean action is initiated the user is prompted with a modal
dialog in which he or she enters or copies a set of cleaning steps
in JSON format.
- Basic validation is performed on the JSON. The user is able to
submit the cleaning request only when validation is successful.
- Cleaning is not currently available as a batch action.

Change-Id: I2af9385e2d9532a9ec46993d65f8c510e419b6c9
Closes-Bug: #1648559
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/42/431642/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/api/ironic_rest_api.py', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-state-transition.service.js', 'ironic_ui/api/ironic.py', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.service.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js', 'ironic_ui/static/dashboard/admin/ironic/clean-node/clean-node.html']",8,fc42b077c1068faa3baae90cb04de5d7430c77b6,bug/1648559,"<div class=""modal-header"" modal-draggable> <h3 class=""modal-title"" translate>Clean Node</h3> </div> <div class=""modal-body clearfix""> <div class=""content""> <div translate class=""subtitle"">Provide a list of cleaning steps in JSON format</div> <div class=""form-group"" ng-init=""cleanSteps=''""> <div class=""form-field""> <textarea type=""text"" class=""form-control input-sm"" ng-model=""cleanSteps"" ng-change=""ctrl.errMsg=''"" auto-focus rows=""8"" required placeholder=""""/> </div> </div> <div uib-alert ng-hide=""ctrl.errMsg === ''"" ng-class=""'alert-danger'""> {$ ctrl.errMsg $} </div> </div> </div> <div class=""modal-footer""> <button class=""btn btn-default secondary"" type=""button"" ng-click=""ctrl.cancel()"" translate> Cancel </button> <button class=""btn btn-primary"" type=""button"" ng-disabled=""cleanSteps === '' || ctrl.errMsg !== ''"" ng-click=""ctrl.clean(cleanSteps)"" translate> Clean node </button> </div> ",,200,9
openstack%2Fironic-ui~master~I148f965618ab43f93732ac82cd5663a76bef1b9e,openstack/ironic-ui,master,I148f965618ab43f93732ac82cd5663a76bef1b9e,Maintenance processing code cleanup,MERGED,2017-02-09 14:33:24.000000000,2017-02-28 15:58:53.000000000,2017-02-28 15:58:53.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-09 14:33:24.000000000', 'files': ['ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.html', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.controller.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js', 'ironic_ui/static/dashboard/admin/ironic/maintenance/maintenance.service.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.html'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/d92d573f543379157ab695a990ce0ea22a542837', 'message': 'Maintenance processing code cleanup\n\nMade the following changes:\n- Eliminate separate functions for single node processing. Functions\nthat set node maintenance mode now accept a list of nodes\n- Eliminate service thin wrapper functions inside controllers that\ndont manipulate controller state.\n\nChange-Id: I148f965618ab43f93732ac82cd5663a76bef1b9e\n'}]",0,431573,d92d573f543379157ab695a990ce0ea22a542837,7,3,1,19380,,,0,"Maintenance processing code cleanup

Made the following changes:
- Eliminate separate functions for single node processing. Functions
that set node maintenance mode now accept a list of nodes
- Eliminate service thin wrapper functions inside controllers that
dont manipulate controller state.

Change-Id: I148f965618ab43f93732ac82cd5663a76bef1b9e
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/73/431573/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/static/dashboard/admin/ironic/node-actions.service.js', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.html', 'ironic_ui/static/dashboard/admin/ironic/node-list/node-list.controller.js', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js', 'ironic_ui/static/dashboard/admin/ironic/maintenance/maintenance.service.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.controller.js', 'ironic_ui/static/dashboard/admin/ironic/node-details/node-details.html']",7,d92d573f543379157ab695a990ce0ea22a542837,maintenance-update," callback=""ctrl.maintenanceService.putNodeInMaintenanceMode"" item=""[ctrl.node]"" callback=""ctrl.maintenanceService.removeNodeFromMaintenanceMode"" item=""[ctrl.node]"""," callback=""ctrl.putNodeInMaintenanceMode"" callback=""ctrl.removeNodeFromMaintenanceMode""",71,132
openstack%2Fironic-ui~master~Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7,openstack/ironic-ui,master,Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7,Imported Translations from Zanata,MERGED,2017-02-14 09:17:51.000000000,2017-02-28 15:58:48.000000000,2017-02-28 15:58:48.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-14 09:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/2c6da7ed8ca78092aabef97ae07043b5bbf21b46', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7\n'}, {'number': 2, 'created': '2017-02-17 09:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/73d4cb945cd92f0918946348cb6784b4d5ad1e98', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7\n'}, {'number': 3, 'created': '2017-02-18 09:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/8dd6521cf6add92a9fe571aa58dac1671df08940', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7\n'}, {'number': 4, 'created': '2017-02-21 09:26:36.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/a36d815fe6399297ac573e5bfc8154a4995f1663', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7\n'}]",0,433518,a36d815fe6399297ac573e5bfc8154a4995f1663,15,3,4,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Icaa86c0086aa049e6cddff52b5581a1b5d27b2f7
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/18/433518/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po']",7,2c6da7ed8ca78092aabef97ae07043b5bbf21b46,zanata/translations,"""POT-Creation-Date: 2017-02-13 18:51+0000\n""","""POT-Creation-Date: 2017-02-06 20:16+0000\n""msgid ""2.1.0-44"" msgstr ""2.1.0-44"" msgid ""Newton Series Release Notes"" msgstr ""Newton"" ",17,41
openstack%2Freleases~master~Ie032dd64f71f4624886fb5e787b1bc3a029204cf,openstack/releases,master,Ie032dd64f71f4624886fb5e787b1bc3a029204cf,mitaka: release nova 13.1.3,MERGED,2017-02-27 15:52:17.000000000,2017-02-28 15:58:09.000000000,2017-02-28 15:58:09.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6873}, {'_account_id': 10135}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-02-27 15:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/64a68d78bba861fa6066cf3416997ced7932d7d6', 'message': 'mitaka: release nova 13.1.3\n\nThis contains some important fixes to the API and\nfor upgrades when you have PCI devices.\n\nChange-Id: Ie032dd64f71f4624886fb5e787b1bc3a029204cf\n'}, {'number': 2, 'created': '2017-02-27 21:23:05.000000000', 'files': ['deliverables/mitaka/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b6070333ce06b548263267b29f568abf492b8c18', 'message': 'mitaka: release nova 13.1.3\n\nThis contains some important fixes to the API and\nfor upgrades when you have PCI devices.\n\nChange-Id: Ie032dd64f71f4624886fb5e787b1bc3a029204cf\n'}]",0,438570,b6070333ce06b548263267b29f568abf492b8c18,11,5,2,6873,,,0,"mitaka: release nova 13.1.3

This contains some important fixes to the API and
for upgrades when you have PCI devices.

Change-Id: Ie032dd64f71f4624886fb5e787b1bc3a029204cf
",git fetch https://review.opendev.org/openstack/releases refs/changes/70/438570/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/nova.yaml'],1,64a68d78bba861fa6066cf3416997ced7932d7d6,nova-mitaka-13.1.3, - version: 13.1.3 projects: - repo: openstack/nova hash: fb1b9f224d6f05674667a7ddf7c8ba77f4f257aa highlights: > - Bug fixes and translation updates.,,6,0
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Fnewton~Ibd3796cc78060016d4099ccb4ed176f6666f73f8,openstack/openstack-ansible-lxc_hosts,stable/newton,Ibd3796cc78060016d4099ccb4ed176f6666f73f8,Support user shell commands during cache prep,MERGED,2017-02-28 14:49:20.000000000,2017-02-28 15:56:51.000000000,2017-02-28 15:56:51.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-28 14:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/3ec3fb6decda11a5ed2a5d78dde5175f38ab334e', 'message': 'Support user shell commands during cache prep\n\nSupport running user shell comamnds before/after the LXC cache build\nprocess without requiring a complete override of the cache map dict.\n\nChange-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8\n(cherry picked from commit ba800949ed712b5245e7471ba9834384a5cd9a5d)\n'}, {'number': 2, 'created': '2017-02-28 15:20:12.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-14.04.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/c5ad7fbdcff3a94230056bcd931fea56478da574', 'message': 'Support user shell commands during cache prep\n\nSupport running user shell comamnds before/after the LXC cache build\nprocess without requiring a complete override of the cache map dict.\n\nChange-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8\n(cherry picked from commit ba800949ed712b5245e7471ba9834384a5cd9a5d)\n'}]",0,438984,c5ad7fbdcff3a94230056bcd931fea56478da574,11,4,2,17799,,,0,"Support user shell commands during cache prep

Support running user shell comamnds before/after the LXC cache build
process without requiring a complete override of the cache map dict.

Change-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8
(cherry picked from commit ba800949ed712b5245e7471ba9834384a5cd9a5d)
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/84/438984/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml']",3,3ec3fb6decda11a5ed2a5d78dde5175f38ab334e,cache-prep-user-cmd,# Custom shell commands to run before/after the LXC cache prep process has taken # place. lxc_cache_prep_pre_commands: '## pre command skipped ##' lxc_cache_prep_post_commands: '## post command skipped ##' ,,9,0
openstack%2Freleases~master~I745298869dc0b21500b61ccf7f59428bc67657c6,openstack/releases,master,I745298869dc0b21500b61ccf7f59428bc67657c6,Release Aodh 3.0.2 on stable/newton,MERGED,2017-02-17 10:17:53.000000000,2017-02-28 15:56:05.000000000,2017-02-28 15:56:05.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-02-17 10:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/821844aab451a4501e36e42b5248f828ca0e7eb6', 'message': 'Release Aodh 3.0.2 on stable/newton\n\nChange-Id: I745298869dc0b21500b61ccf7f59428bc67657c6\n'}, {'number': 2, 'created': '2017-02-23 13:56:33.000000000', 'files': ['deliverables/newton/aodh.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/4d605dd9fe407457381ef2d5d60a3726888fd2f9', 'message': 'Release Aodh 3.0.2 on stable/newton\n\nChange-Id: I745298869dc0b21500b61ccf7f59428bc67657c6\n'}]",0,435347,4d605dd9fe407457381ef2d5d60a3726888fd2f9,15,4,2,2813,,,0,"Release Aodh 3.0.2 on stable/newton

Change-Id: I745298869dc0b21500b61ccf7f59428bc67657c6
",git fetch https://review.opendev.org/openstack/releases refs/changes/47/435347/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/aodh.yaml'],1,821844aab451a4501e36e42b5248f828ca0e7eb6,sileht/aodh-newton, - version: 3.0.2 projects: - repo: openstack/aodh hash: bb5103e567de04fae62dd10380739455712a7b3c,,4,0
openstack%2Freleases~master~I5ed61520c54d436f6dc43a4eab69e236ab4f43ee,openstack/releases,master,I5ed61520c54d436f6dc43a4eab69e236ab4f43ee,Release Ceilometer 7.0.2 for Newton,MERGED,2017-02-17 10:08:28.000000000,2017-02-28 15:55:57.000000000,2017-02-28 15:55:57.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-02-17 10:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fe64b17d14f5e7d412aad2d32fae9253110d1699', 'message': 'Release Ceilometer 7.0.2 for Newton\n\nChange-Id: I5ed61520c54d436f6dc43a4eab69e236ab4f43ee\n'}, {'number': 2, 'created': '2017-02-23 10:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e3a5aa9bf3030ee9e00b6e970b7618361ce94488', 'message': 'Release Ceilometer 7.0.2 for Newton\n\nChange-Id: I5ed61520c54d436f6dc43a4eab69e236ab4f43ee\n'}, {'number': 3, 'created': '2017-02-23 10:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/dacec1c1506c26974743a95838b74fcbd0bd172f', 'message': 'Release Ceilometer 7.0.2 for Newton\n\nChange-Id: I5ed61520c54d436f6dc43a4eab69e236ab4f43ee\n'}, {'number': 4, 'created': '2017-02-23 13:56:56.000000000', 'files': ['deliverables/newton/ceilometer.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/325700094b62595b4c905a8da8c4fa32ca611eff', 'message': 'Release Ceilometer 7.0.2 for Newton\n\nChange-Id: I5ed61520c54d436f6dc43a4eab69e236ab4f43ee\n'}]",0,435343,325700094b62595b4c905a8da8c4fa32ca611eff,13,4,4,2813,,,0,"Release Ceilometer 7.0.2 for Newton

Change-Id: I5ed61520c54d436f6dc43a4eab69e236ab4f43ee
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/435343/4 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/ceilometer.yaml'],1,fe64b17d14f5e7d412aad2d32fae9253110d1699,sileht/ceilometer-newton, - version: 7.0.2 projects: - repo: openstack/ceilometer hash: 43cbac39cf7b19216d5767d46ea434e50ba416d8,,4,0
openstack%2Fdesignate-dashboard~stable%2Focata~Iee91e7a11a5405ee6d601717a00f007da552052c,openstack/designate-dashboard,stable/ocata,Iee91e7a11a5405ee6d601717a00f007da552052c,Imported Translations from Zanata,MERGED,2017-02-19 08:47:23.000000000,2017-02-28 15:52:56.000000000,2017-02-28 15:52:56.000000000,"[{'_account_id': 3}, {'_account_id': 8099}]","[{'number': 1, 'created': '2017-02-19 08:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/51cf09100a2ec307a1b592de91c7889f61ea2066', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Iee91e7a11a5405ee6d601717a00f007da552052c\n'}, {'number': 2, 'created': '2017-02-23 08:41:06.000000000', 'files': ['designatedashboard/locale/fr/LC_MESSAGES/django.po', 'designatedashboard/locale/es/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/d2b5f69f41219b75965dd401de6c8ae46af0f04a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Iee91e7a11a5405ee6d601717a00f007da552052c\n'}]",0,435753,d2b5f69f41219b75965dd401de6c8ae46af0f04a,9,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Iee91e7a11a5405ee6d601717a00f007da552052c
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/53/435753/1 && git format-patch -1 --stdout FETCH_HEAD,['designatedashboard/locale/fr/LC_MESSAGES/django.po'],1,51cf09100a2ec307a1b592de91c7889f61ea2066,zanata/translations,"# JF Taltavull <jftalta@gmail.com>, 2017. #zanata""Project-Id-Version: designate-dashboard 4.0.0.0rc2.dev3\n""""POT-Creation-Date: 2017-02-13 16:51+0000\n""""PO-Revision-Date: 2017-02-18 06:51+0000\n"" ""Last-Translator: JF Taltavull <jftalta@gmail.com>\n"""" Ici vous pouvez diter l'adresse email e t le TTL associs  un """" point \"".\"" de terminaison).\n"""" La valeur du champ optionnel TTL doit tre comprise entre 1 et """" Le TTL est le time-to-live de l'enregistrement, en secondes.\n""""target=\""_designate_record_defs\"">plus de dtails</a> sur les types ""msgstr ""A - Enregistrement d'Adresse""msgstr ""AAAA - Enregistrement d'Adresse IPv6""msgstr ""CNAME - Enregistrement de Nom Canonique""msgstr ""Donnes""msgstr ""Domaine %(name)s mis  jour.""msgstr ""Enregistrements de domaine""msgstr ""Enregistrement Domaine %(name)s cr""msgstr ""Enregistrement Domaine %(name)s mis  jour.""msgstr ""Editer l'enregistrement""""et des chiffres, et ne doit pas dpasser 63 caractres.""msgstr ""MX - Enregistrement de Serveur de messagerie""msgstr ""Serveurs de nom""msgstr ""PTR - Enregistrement de Pointeur""msgstr ""Enregistrer les donnes""msgstr ""Dtail de l'enregistrement""msgstr ""SPF - Politique dmission""msgstr ""SRV - Enregistrement de Service""msgstr ""SSHFP - Somme de contrle de la cl SSH publique""msgstr ""Slectionner une IP""msgstr ""TXT - Enregistrement Texte""msgstr ""Impossible de rcuprer l'enregistrement de domaine.""msgstr ""Mettre  jour le domaine""msgstr ""Mettre  jour l'enregistrement de domaine""msgstr ""Mettre  jour l'enregistrement""","""Project-Id-Version: designate-dashboard 3.0.0.0rc2.dev9\n""""POT-Creation-Date: 2016-10-27 17:27+0000\n""""PO-Revision-Date: 2016-10-27 03:47+0000\n"" ""Last-Translator: Grald LONLAS <g.lonlas@gmail.com>\n"""" Depuis ici vous pouvez diter l'adresse email et le TTL associ au """" point \"".\""  la fin).\n"""" Le champ optionnel TLL ne peut avoir une valeur qu'entre 1 et """" Le TTL est le time-to-live pour une enregistrement, en secondes.\n""""target=\""_designate_record_defs\"">pour plus de dtails</a> sur les types ""msgstr ""A - Enregistrement d'adresse""msgstr ""AAAA - Enregistrement d'adresse IPv6""msgstr ""CNAME - Enregistrement de nom canonique""msgstr ""Donne""msgstr ""Domaine %(name)s mis  jour""msgstr ""Enregistrements domaine""msgstr ""Enregistrement du domaine %(name)s cr""msgstr ""Enregistrement du domaine %(name)s mis  jour.""msgstr ""Editer un enregistrement""""et des chiffres, et ne doit pas contenir plus de 63 caractres.""msgstr ""MX - Enregistrement de serveur de messagerie""msgstr ""Serveurs de nom DNS""msgstr ""PTR - Enregistrement pointeur""#, fuzzymsgstr ""Record Data""msgstr ""Dtail de l'enregistrement du domaine""msgstr ""SPF - Rgle et politique dmission""msgstr ""SRV - Enregistrement de service""msgstr ""SSHFP - Empreinte digitale de la cl SSH publique""msgstr ""Slectionnez une IP""msgstr ""TXT - Enregistrement de texte""msgstr ""Impossible de rcuprer l'enregistrement du domaine.""msgstr ""Mise  jour du domaine""msgstr ""Mise  jour des enregistrements du domaine""msgstr ""Enregistrer""",34,34
openstack%2Fkolla-ansible~master~Ide9d265e15672ceba72d7c0b1c1a273098819d94,openstack/kolla-ansible,master,Ide9d265e15672ceba72d7c0b1c1a273098819d94,Remove Heka yaml file,MERGED,2017-02-27 07:06:21.000000000,2017-02-28 15:52:21.000000000,2017-02-28 15:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 22959}]","[{'number': 1, 'created': '2017-02-27 07:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e6785f047ca3d904d9abe1bb7250af1750f3edd6', 'message': 'Remove Heka docs and yaml file\n\nHeka is removed and replaced by fluentd.\n\nChange-Id: Ide9d265e15672ceba72d7c0b1c1a273098819d94\n'}, {'number': 2, 'created': '2017-02-27 07:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9b9d2fd237082dd431b38c88a3367a5a1c9eaec3', 'message': 'Remove Heka docs and yaml file\n\nHeka is removed and replaced by fluentd.\nrefer to https://review.openstack.org/#/c/437874/\n\nChange-Id: Ide9d265e15672ceba72d7c0b1c1a273098819d94\n'}, {'number': 3, 'created': '2017-02-27 09:53:23.000000000', 'files': ['ansible/roles/common/tasks/upgrade.yml', 'ansible/roles/common/tasks/clean_heka.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b8dbdb2714c670eaaece9f5793f1c3f63ae64460', 'message': 'Remove Heka yaml file\n\nHeka is removed and replaced by fluentd.\nrefer to https://review.openstack.org/#/c/437874/\n\nChange-Id: Ide9d265e15672ceba72d7c0b1c1a273098819d94\n'}]",1,438346,b8dbdb2714c670eaaece9f5793f1c3f63ae64460,13,5,3,22165,,,0,"Remove Heka yaml file

Heka is removed and replaced by fluentd.
refer to https://review.openstack.org/#/c/437874/

Change-Id: Ide9d265e15672ceba72d7c0b1c1a273098819d94
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/46/438346/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/tasks/upgrade.yml', 'specs/kubernetes-deployment.rst', 'specs/logging-with-heka.rst', 'ansible/roles/common/tasks/clean_heka.yml', 'specs/logging-with-heka.svg']",5,e6785f047ca3d904d9abe1bb7250af1750f3edd6,,,"<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?> <svg xmlns:dc=""http://purl.org/dc/elements/1.1/"" xmlns:cc=""http://creativecommons.org/ns#"" xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#"" xmlns:svg=""http://www.w3.org/2000/svg"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xmlns:sodipodi=""http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"" xmlns:inkscape=""http://www.inkscape.org/namespaces/inkscape"" version=""1.1"" viewBox=""0.0 0.0 1280.0 960.0"" fill=""none"" stroke=""none"" stroke-linecap=""square"" stroke-miterlimit=""10"" id=""svg2"" inkscape:version=""0.48.4 r9939"" width=""100%"" height=""100%"" sodipodi:docname=""logging-with-heka.svg""> <metadata id=""metadata232""> <rdf:RDF> <cc:Work rdf:about=""""> <dc:format>image/svg+xml</dc:format> <dc:type rdf:resource=""http://purl.org/dc/dcmitype/StillImage"" /> </cc:Work> </rdf:RDF> </metadata> <defs id=""defs230"" /> <sodipodi:namedview pagecolor=""#ffffff"" bordercolor=""#666666"" borderopacity=""1"" objecttolerance=""10"" gridtolerance=""10"" guidetolerance=""10"" inkscape:pageopacity=""0"" inkscape:pageshadow=""2"" inkscape:window-width=""1918"" inkscape:window-height=""1179"" id=""namedview228"" showgrid=""false"" inkscape:zoom=""0.69532167"" inkscape:cx=""755.07998"" inkscape:cy=""317.28813"" inkscape:window-x=""1920"" inkscape:window-y=""19"" inkscape:window-maximized=""0"" inkscape:current-layer=""svg2"" /> <clipPath id=""p.0""> <path d=""m0 0l1280.0 0l0 960.0l-1280.0 0l0 -960.0z"" clip-rule=""nonzero"" id=""path5"" /> </clipPath> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path9"" d=""m -1496.9492,-553.22034 2776.9491,0 0,1513.22035 -2776.9491,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path11"" d=""m 39.598639,64.681443 231.380471,0 0,245.366467 -231.380471,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path13"" d=""m 39.598639,64.681443 231.380471,0 0,245.366467 -231.380471,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path15"" d=""m 59.290115,94.199222 231.380495,0 0,245.366458 -231.380495,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path17"" d=""m 59.290115,94.199222 231.380495,0 0,245.366458 -231.380495,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path19"" d=""m 78.981591,123.71699 231.380459,0 0,245.36645 -231.380459,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path21"" d=""m 78.981591,123.71699 231.380459,0 0,245.36645 -231.380459,0 z"" /> <path style=""fill:#ffd966;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path23"" d=""m 102.08119,148.88258 188.5957,0 0,182.1728 -188.5957,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path25"" d=""m 102.08119,148.88258 188.5957,0 0,182.1728 -188.5957,0 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path27"" d=""m 115.96626,251.255 160.82565,0 0,38.88209 -160.82565,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path29"" d=""m 115.96626,251.255 160.82565,0 0,38.88209 -160.82565,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path31"" d=""m 170.11638,279.68844 0,-17.6648 2.09721,0 0,7.24865 8.1719,0 0,-7.24865 2.07913,0 0,17.6648 -2.07913,0 0,-8.32479 -8.1719,0 0,8.32479 -2.09721,0 z m 23.09229,-4.12179 1.98873,0.28426 q -0.47003,1.94922 -1.75369,3.04566 -1.26557,1.07613 -3.2543,1.07613 -2.49498,0 -3.95938,-1.72587 -1.46446,-1.72587 -1.46446,-4.85274 0,-3.22841 1.46446,-5.01519 1.48248,-1.78679 3.8509,-1.78679 2.2961,0 3.74247,1.74618 1.44632,1.74618 1.44632,4.93397 0,0.18273 -0.0181,0.56852 l -8.49734,0 q 0.10843,2.11166 1.06669,3.22839 0.9582,1.11675 2.38644,1.11675 1.04861,0 1.78991,-0.60913 0.75932,-0.62944 1.21133,-2.01014 z m -6.34588,-3.51265 6.36396,0 q -0.12656,-1.60406 -0.72316,-2.41623 -0.92205,-1.25887 -2.40458,-1.25887 -1.31981,0 -2.24186,1.01522 -0.90396,0.99492 -0.99436,2.65988 z m 10.55924,7.63444 0,-17.6648 1.93449,0 0,10.07097 4.57412,-5.21823 2.49493,0 -4.35716,4.75122 4.79108,8.06084 -2.3865,0 -3.76049,-6.53801 -1.35598,1.46192 0,5.07609 -1.93449,0 z m 18.22409,-1.58374 q -1.08477,1.03552 -2.07914,1.46192 -0.99436,0.40608 -2.13337,0.40608 -1.86222,0 -2.87467,-1.01521 -1.01245,-1.03553 -1.01245,-2.63957 0,-0.95431 0.37969,-1.72588 0.37969,-0.77156 0.99437,-1.23856 0.61468,-0.46701 1.39213,-0.71066 0.57852,-0.18273 1.71753,-0.32487 2.35034,-0.32487 3.45319,-0.75126 0,-0.44669 0,-0.56852 0,-1.31979 -0.54242,-1.868 -0.74124,-0.73096 -2.20569,-0.73096 -1.35592,0 -2.00681,0.52791 -0.65084,0.52792 -0.95821,1.90862 l -1.89833,-0.30458 q 0.27121,-1.36038 0.84972,-2.19287 0.59666,-0.83247 1.6995,-1.27917 1.12093,-0.46701 2.60341,-0.46701 1.46446,0 2.36842,0.38579 0.90397,0.38578 1.3379,0.97461 0.43387,0.58882 0.59659,1.48222 0.10843,0.54822 0.10843,1.98983 l 0,2.90353 q 0,3.02534 0.10843,3.83752 0.12656,0.79188 0.5062,1.52283 l -2.02489,0 q -0.30737,-0.67005 -0.37969,-1.58374 z m -0.16272,-4.83244 q -1.04861,0.467 -3.16391,0.81217 -1.19325,0.18274 -1.68142,0.42639 -0.48811,0.24365 -0.75932,0.71066 -0.2712,0.467 -0.2712,1.03552 0,0.87309 0.57857,1.46191 0.5966,0.56853 1.71753,0.56853 1.12092,0 1.98873,-0.54821 0.86785,-0.56853 1.28365,-1.50253 0.30737,-0.75127 0.30737,-2.17257 l 0,-0.79187 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path33"" d=""m 151.24369,167.93015 90.27083,0 0,38.88207 -90.27083,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path35"" d=""m 151.24369,167.93015 90.27083,0 0,38.88207 -90.27083,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path37"" d=""m 175.26155,196.36359 0,-17.6648 2.07913,0 0,15.57344 7.7561,0 0,2.09136 -9.83523,0 z m 11.11968,-6.39589 q 0,-3.55325 1.77182,-5.27913 1.46446,-1.4213 3.5797,-1.4213 2.35034,0 3.83287,1.74617 1.50062,1.72587 1.50062,4.77154 0,2.47713 -0.66898,3.89843 -0.65083,1.401 -1.91641,2.19288 -1.24749,0.77156 -2.7481,0.77156 -2.38645,0 -3.86898,-1.72587 -1.48254,-1.72587 -1.48254,-4.95428 z m 1.98879,0 q 0,2.45684 0.9582,3.6751 0.95821,1.21827 2.40453,1.21827 1.44637,0 2.3865,-1.21827 0.9582,-1.23857 0.9582,-3.75631 0,-2.37561 -0.9582,-3.59387 -0.95821,-1.21826 -2.3865,-1.21826 -1.44632,0 -2.40453,1.21826 -0.9582,1.21826 -0.9582,3.67508 z m 10.39646,7.45172 1.86223,0.32487 q 0.12656,0.97461 0.66892,1.42131 0.70508,0.58882 1.95257,0.58882 1.35597,0 2.07913,-0.60913 0.72322,-0.58882 0.99437,-1.66496 0.14464,-0.67004 0.12656,-2.802 -1.26557,1.68526 -3.14582,1.68526 -2.35034,0 -3.65202,-1.90861 -1.28365,-1.90861 -1.28365,-4.56849 0,-1.82739 0.5966,-3.37053 0.59665,-1.56343 1.71758,-2.39592 1.12093,-0.85277 2.62149,-0.85277 2.02489,0 3.32662,1.82739 l 0,-1.54313 1.78985,0 0,11.06589 q 0,3.00505 -0.54236,4.24361 -0.54241,1.25887 -1.71752,1.96952 -1.17517,0.73097 -2.89275,0.73097 -2.04298,0 -3.30855,-1.03553 -1.24743,-1.03552 -1.19325,-3.10657 z m 1.59102,-7.69537 q 0,2.53806 0.88589,3.69541 0.90396,1.15735 2.24185,1.15735 1.31981,0 2.22378,-1.15735 0.90396,-1.15735 0.90396,-3.61419 0,-2.3553 -0.94012,-3.53296 -0.92205,-1.19795 -2.22378,-1.19795 -1.28365,0 -2.18761,1.17765 -0.90397,1.15735 -0.90397,3.47204 z m 9.98068,2.82232 1.91641,-0.34518 q 0.16272,1.29948 0.88593,1.98983 0.74124,0.67005 2.06106,0.67005 1.33784,0 1.97065,-0.60913 0.65084,-0.60914 0.65084,-1.4213 0,-0.73097 -0.56044,-1.15736 -0.39777,-0.28427 -1.97071,-0.73096 -2.13337,-0.60913 -2.96501,-1.03552 -0.81357,-0.4467 -1.24744,-1.21826 -0.41585,-0.79188 -0.41585,-1.72588 0,-0.85278 0.34353,-1.58374 0.36155,-0.73096 0.9582,-1.21827 0.45196,-0.36547 1.22936,-0.62943 0.77746,-0.26395 1.66334,-0.26395 1.35597,0 2.36842,0.44669 1.01245,0.4264 1.48248,1.17766 0.48817,0.73095 0.66897,1.96952 l -1.8803,0.28427 q -0.12651,-0.97461 -0.75932,-1.52284 -0.61468,-0.56852 -1.73561,-0.56852 -1.33789,0 -1.89833,0.50762 -0.56049,0.4873 -0.56049,1.13704 0,0.42638 0.23505,0.77157 0.23504,0.34517 0.74124,0.56852 0.28928,0.12176 1.6995,0.56852 2.04297,0.60913 2.85653,0.99491 0.81356,0.38579 1.26557,1.13705 0.47004,0.75127 0.47004,1.868 0,1.07613 -0.56044,2.05075 -0.56049,0.95429 -1.62718,1.48221 -1.06668,0.50761 -2.40452,0.50761 -2.22378,0 -3.39895,-1.03553 -1.15709,-1.03551 -1.48253,-3.06595 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path39"" d=""m 60.991055,10.099311 188.595695,0 0,56.645065 -188.595695,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path41"" d=""m 84.331617,38.888492 2.079133,0.58882 q -0.650839,2.883221 -2.350339,4.406055 -1.699448,1.502522 -4.158269,1.502522 -2.549169,0 -4.140187,-1.157353 -1.590964,-1.177649 -2.422607,-3.370524 -0.831696,-2.21318 -0.831696,-4.751224 0,-2.761399 0.922044,-4.812139 0.940125,-2.05074 2.675786,-3.106567 1.735607,-1.076132 3.814741,-1.076132 2.368419,0 3.977518,1.360394 1.609045,1.340089 2.241857,3.776608 l -2.043026,0.548219 q -0.542357,-1.92891 -1.590964,-2.802001 -1.048609,-0.893395 -2.621546,-0.893395 -1.807929,0 -3.037339,0.974615 -1.21133,0.974607 -1.717527,2.639569 -0.488169,1.644656 -0.488169,3.390829 0,2.25379 0.578571,3.939048 0.596598,1.664962 1.826009,2.497442 1.247491,0.832481 2.675732,0.832481 1.75374,0 2.965072,-1.116743 1.21133,-1.137047 1.645206,-3.370524 z m 3.385719,-0.20305 q 0,-3.553261 1.771767,-5.279138 1.464456,-1.421309 3.57975,-1.421309 2.350339,0 3.832821,1.746181 1.500616,1.725868 1.500616,4.771529 0,2.477137 -0.66892,3.898438 -0.650892,1.401004 -1.916464,2.192875 -1.247437,0.771566 -2.748053,0.771566 -2.3865,0 -3.868982,-1.725869 -1.482535,-1.725876 -1.482535,-4.954273 z m 1.988732,0 q 0,2.456832 0.958205,3.675091 0.958205,1.218267 2.40458,1.218267 1.446375,0 2.3865,-1.218267 0.958205,-1.238564 0.958205,-3.756303 0,-2.375612 -0.958205,-3.593879 -0.958206,-1.21826 -2.3865,-1.21826 -1.446375,0 -2.40458,1.21826 -0.958205,1.218267 -0.958205,3.675091 z m 10.740052,6.39588 0,-12.812065 1.7356,0 0,1.827401 q 1.26557,-2.111663 3.63399,-2.111663 1.03053,0 1.89833,0.426397 0.86781,0.406084 1.28366,1.096437 0.43387,0.670041 0.61467,1.583742 0.10843,0.609133 0.10843,2.111655 l 0,7.878096 -1.93449,0 0,-7.796876 q 0,-1.319785 -0.23504,-1.969529 -0.21697,-0.670048 -0.79548,-1.055827 -0.57858,-0.385787 -1.35598,-0.385787 -1.22941,0 -2.13337,0.873091 -0.88589,0.87309 -0.88589,3.350227 l 0,6.984701 -1.93449,0 z m 16.23615,-1.949215 0.27121,1.92891 q -0.81362,0.182745 -1.46446,0.182745 -1.04861,0 -1.62712,-0.365482 -0.57857,-0.385787 -0.81362,-0.974608 -0.23499,-0.609133 -0.23499,-2.578661 l 0,-7.350183 -1.4283,0 0,-1.705571 1.4283,0 0,-3.167482 1.91641,-1.29948 0,4.466962 1.95257,0 0,1.705571 -1.95257,0 0,7.472013 q 0,0.933997 0.0904,1.197954 0.10843,0.263957 0.34353,0.426397 0.23504,0.162431 0.66892,0.162431 0.30736,0 0.84977,-0.101525 z m 1.74884,1.949215 0,-12.812065 1.73566,0 0,1.949223 q 0.66892,-1.360394 1.22941,-1.786783 0.56044,-0.446702 1.24744,-0.446702 0.97628,0 1.98873,0.710659 l -0.66892,2.01013 q -0.70508,-0.466999 -1.42829,-0.466999 -0.63276,0 -1.13896,0.426389 -0.48817,0.426397 -0.70513,1.177657 -0.32545,1.157353 -0.32545,2.538044 l 0,6.700447 -1.93449,0 z m 6.48349,-6.39588 q 0,-3.553261 1.77182,-5.279138 1.4644,-1.421309 3.57969,-1.421309 2.35034,0 3.83288,1.746181 1.50056,1.725868 1.50056,4.771529 0,2.477137 -0.66892,3.898438 -0.65084,1.401004 -1.91641,2.192875 -1.24749,0.771566 -2.74811,0.771566 -2.38644,0 -3.86898,-1.725869 -1.48253,-1.725876 -1.48253,-4.954273 z m 1.98878,0 q 0,2.456832 0.95821,3.675091 0.9582,1.218267 2.40452,1.218267 1.44638,0 2.3865,-1.218267 0.95821,-1.238564 0.95821,-3.756303 0,-2.375612 -0.95821,-3.593879 -0.9582,-1.21826 -2.3865,-1.21826 -1.44632,0 -2.40452,1.21826 -0.95821,1.218267 -0.95821,3.675091 z m 10.70384,6.39588 0,-17.664805 1.93449,0 0,17.664805 -1.93449,0 z m 10.82959,0 0,-12.812065 1.73561,0 0,1.827401 q 1.26557,-2.111663 3.63399,-2.111663 1.03053,0 1.89833,0.426397 0.8678,0.406084 1.28365,1.096437 0.43393,0.670041 0.61468,1.583742 0.10843,0.609133 0.10843,2.111655 l 0,7.878096 -1.93449,0 0,-7.796876 q 0,-1.319785 -0.23505,-1.969529 -0.21696,-0.670048 -0.79548,-1.055827 -0.57852,-0.385787 -1.35597,-0.385787 -1.22941,0 -2.13338,0.873091 -0.88588,0.87309 -0.88588,3.350227 l 0,6.984701 -1.93449,0 z m 11.28241,-6.39588 q 0,-3.553261 1.77177,-5.279138 1.46445,-1.421309 3.57975,-1.421309 2.35033,0 3.83282,1.746181 1.50061,1.725868 1.50061,4.771529 0,2.477137 -0.66892,3.898438 -0.65089,1.401004 -1.91646,2.192875 -1.24749,0.771566 -2.74805,0.771566 -2.3865,0 -3.86899,-1.725869 -1.48253,-1.725876 -1.48253,-4.954273 z m 1.98873,0 q 0,2.456832 0.95821,3.675091 0.9582,1.218267 2.40458,1.218267 1.44637,0 2.3865,-1.218267 0.9582,-1.238564 0.9582,-3.756303 0,-2.375612 -0.9582,-3.593879 -0.95826,-1.21826 -2.3865,-1.21826 -1.44638,0 -2.40458,1.21826 -0.95821,1.218267 -0.95821,3.675091 z m 18.13454,6.39588 0,-1.624352 q -1.08477,1.908614 -3.18198,1.908614 -1.35598,0 -2.51306,-0.832481 -1.13901,-0.852778 -1.77177,-2.355307 -0.61473,-1.522826 -0.61473,-3.492354 0,-1.908613 0.56049,-3.47205 0.57851,-1.563436 1.69944,-2.395916 1.13901,-0.832481 2.54923,-0.832481 1.03052,0 1.826,0.487312 0.81357,0.487304 1.31982,1.279174 l 0,-6.334964 1.91641,0 0,17.664805 -1.78985,0 z m -6.11089,-6.39588 q 0,2.456832 0.9221,3.675091 0.94012,1.218267 2.18756,1.218267 1.26557,0 2.15145,-1.157352 0.88594,-1.157344 0.88594,-3.553261 0,-2.619272 -0.90402,-3.837531 -0.90396,-1.238565 -2.22372,-1.238565 -1.28365,0 -2.15151,1.17765 -0.8678,1.177657 -0.8678,3.715701 z m 18.53225,2.274095 1.98879,0.284262 q -0.47009,1.949214 -1.75374,3.045652 -1.26558,1.076133 -3.25431,1.076133 -2.49493,0 -3.95938,-1.725869 -1.46446,-1.725876 -1.46446,-4.852748 0,-3.228398 1.46446,-5.015181 1.48253,-1.786791 3.8509,-1.786791 2.2961,0 3.74247,1.746181 1.44632,1.746173 1.44632,4.933961 0,0.182745 -0.0181,0.568524 l -8.49734,0 q 0.10843,2.111655 1.06669,3.228397 0.9582,1.116742 2.3865,1.116742 1.04861,0 1.78985,-0.609133 0.75932,-0.629431 1.21133,-2.01013 z m -6.34588,-3.51266 6.36401,0 q -0.12656,-1.604046 -0.72321,-2.416221 -0.92204,-1.25887 -2.40458,-1.25887 -1.31976,0 -2.24186,1.015218 -0.90396,0.994912 -0.99436,2.659873 z m 9.76376,3.817227 1.91641,-0.345177 q 0.16272,1.299479 0.88589,1.989825 0.74124,0.670048 2.06105,0.670048 1.33789,0 1.97065,-0.609133 0.65089,-0.609134 0.65089,-1.421301 0,-0.730964 -0.56049,-1.157353 -0.39771,-0.284262 -1.97065,-0.730955 -2.13337,-0.609134 -2.96502,-1.035523 -0.81356,-0.446702 -1.24749,-1.218268 -0.41585,-0.79187 -0.41585,-1.725868 0,-0.852785 0.34353,-1.583741 0.36161,-0.730964 0.95821,-1.218267 0.452,-0.365482 1.22941,-0.629439 0.7774,-0.263957 1.66328,-0.263957 1.35597,0 2.36842,0.446702 1.01245,0.426389 1.48254,1.177649 0.48811,0.730964 0.66892,1.969528 l -1.88025,0.284262 q -0.12657,-0.974607 -0.75933,-1.522826 -0.61473,-0.568524 -1.73566,-0.568524 -1.33783,0 -1.89833,0.507609 -0.56043,0.487304 -0.56043,1.137048 0,0.426388 0.23504,0.771565 0.23499,0.345169 0.74124,0.568524 0.28923,0.121822 1.69945,0.568515 2.04297,0.609134 2.85653,0.994921 0.81362,0.385779 1.26558,1.137039 0.47008,0.751269 0.47008,1.868004 0,1.076132 -0.56049,2.050748 -0.56043,0.954302 -1.62712,1.482216 -1.06669,0.507609 -2.40458,0.507609 -2.22378,0 -3.39895,-1.035523 -1.15709,-1.035522 -1.48248,-3.065957 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path43"" d=""m 186.54843,230.6494 4.91989,0 0,-8.90195 9.83981,0 0,8.90195 4.91983,0 -9.83976,8.90196 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path45"" d=""m 186.54843,230.6494 4.91989,0 0,-8.90195 9.83981,0 0,8.90195 4.91983,0 -9.83976,8.90196 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path47"" d=""m 346.22618,64.679308 231.38052,0 0,245.366452 -231.38052,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path49"" d=""m 346.22618,64.679308 231.38052,0 0,245.366452 -231.38052,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path51"" d=""m 365.91765,94.197087 231.38053,0 0,245.366423 -231.38053,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path53"" d=""m 365.91765,94.197087 231.38053,0 0,245.366423 -231.38053,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path55"" d=""m 385.60917,123.71488 231.38048,0 0,245.36647 -231.38048,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path57"" d=""m 385.60917,123.71488 231.38048,0 0,245.36647 -231.38048,0 z"" /> <path style=""fill:#ffd966;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path59"" d=""m 408.70863,148.879 188.59568,0 0,182.17282 -188.59568,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path61"" d=""m 408.70863,148.879 188.59568,0 0,182.17282 -188.59568,0 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path63"" d=""m 422.59378,251.25285 160.82568,0 0,38.88209 -160.82568,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path65"" d=""m 422.59378,251.25285 160.82568,0 0,38.88209 -160.82568,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path67"" d=""m 476.74393,279.6863 0,-17.66481 2.09722,0 0,7.24866 8.17191,0 0,-7.24866 2.07913,0 0,17.66481 -2.07913,0 0,-8.32479 -8.17191,0 0,8.32479 -2.09722,0 z m 23.0923,-4.1218 1.98874,0.28427 q -0.47007,1.94922 -1.75371,3.04566 -1.26557,1.07613 -3.2543,1.07613 -2.49497,0 -3.9594,-1.72588 -1.46444,-1.72586 -1.46444,-4.85274 0,-3.2284 1.46444,-5.01519 1.48252,-1.78678 3.85092,-1.78678 2.29609,0 3.74245,1.74617 1.44636,1.74619 1.44636,4.93397 0,0.18274 -0.018,0.56853 l -8.49735,0 q 0.10843,2.11165 1.0667,3.22839 0.9582,1.11675 2.38649,1.11675 1.0486,0 1.78986,-0.60914 0.75933,-0.62944 1.21133,-2.01014 z m -6.34589,-3.51265 6.36396,0 q -0.12655,-1.60405 -0.72317,-2.41623 -0.92205,-1.25887 -2.40456,-1.25887 -1.31981,0 -2.24186,1.01522 -0.90397,0.99492 -0.99437,2.65988 z m 10.55924,7.63445 0,-17.66481 1.9345,0 0,10.07097 4.5741,-5.21823 2.49496,0 -4.35714,4.75123 4.79105,8.06084 -2.38649,0 -3.76052,-6.53801 -1.35596,1.46191 0,5.0761 -1.9345,0 z m 18.22408,-1.58374 q -1.08476,1.03552 -2.07913,1.46192 -0.99438,0.40608 -2.13337,0.40608 -1.86219,0 -2.87464,-1.01522 -1.01245,-1.03553 -1.01245,-2.63957 0,-0.95431 0.37967,-1.72587 0.37967,-0.77157 0.99437,-1.23857 0.6147,-0.467 1.39212,-0.71066 0.57854,-0.18273 1.71754,-0.32487 2.35033,-0.32487 3.45318,-0.75125 0,-0.44669 0,-0.56852 0,-1.3198 -0.54238,-1.86801 -0.74126,-0.73095 -2.20569,-0.73095 -1.35597,0 -2.00683,0.52791 -0.65086,0.52792 -0.9582,1.90861 l -1.89835,-0.30457 q 0.2712,-1.36039 0.84974,-2.19288 0.59662,-0.83247 1.69947,-1.27916 1.12092,-0.46701 2.60344,-0.46701 1.46443,0 2.3684,0.38579 0.90397,0.38578 1.33788,0.97461 0.4339,0.58882 0.59663,1.48221 0.10842,0.54823 0.10842,1.98984 l 0,2.90352 q 0,3.02535 0.10841,3.83752 0.12656,0.79188 0.50623,1.52284 l -2.0249,0 q -0.30736,-0.67005 -0.37967,-1.58374 z m -0.16271,-4.83245 q -1.0486,0.467 -3.1639,0.81218 -1.19325,0.18274 -1.68139,0.42639 -0.48815,0.24365 -0.75933,0.71066 -0.2712,0.467 -0.2712,1.03551 0,0.8731 0.57854,1.46192 0.59663,0.56852 1.71755,0.56852 1.12093,0 1.98874,-0.54821 0.86782,-0.56852 1.28364,-1.50253 0.30735,-0.75127 0.30735,-2.17257 l 0,-0.79187 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path69"" d=""m 457.87124,167.92801 90.27082,0 0,38.88209 -90.27082,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path71"" d=""m 457.87124,167.92801 90.27082,0 0,38.88209 -90.27082,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path73"" d=""m 481.8891,196.36147 0,-17.6648 2.07914,0 0,15.57345 7.75609,0 0,2.09135 -9.83523,0 z m 11.11971,-6.39588 q 0,-3.55326 1.77179,-5.27914 1.46443,-1.4213 3.57973,-1.4213 2.35033,0 3.83284,1.74617 1.50059,1.72588 1.50059,4.77154 0,2.47713 -0.66893,3.89843 -0.65086,1.401 -1.91642,2.19288 -1.24749,0.77157 -2.74808,0.77157 -2.38648,0 -3.869,-1.72588 -1.48252,-1.72587 -1.48252,-4.95427 z m 1.98875,0 q 0,2.45684 0.9582,3.6751 0.95822,1.21826 2.40457,1.21826 1.44636,0 2.38649,-1.21826 0.95821,-1.23858 0.95821,-3.75632 0,-2.3756 -0.95821,-3.59387 -0.95822,-1.21826 -2.38649,-1.21826 -1.44635,0 -2.40457,1.21826 -0.9582,1.21827 -0.9582,3.67509 z m 10.39648,7.45171 1.86219,0.32487 q 0.12655,0.97461 0.66893,1.42131 0.70511,0.58882 1.95258,0.58882 1.35597,0 2.07915,-0.60913 0.72318,-0.58882 0.99436,-1.66496 0.14464,-0.67003 0.12656,-2.802 -1.26556,1.68526 -3.14582,1.68526 -2.35033,0 -3.65205,-1.90861 -1.28365,-1.9086 -1.28365,-4.56849 0,-1.82739 0.59663,-3.37052 0.59662,-1.56344 1.71754,-2.39592 1.12093,-0.85278 2.62153,-0.85278 2.0249,0 3.32661,1.82739 l 0,-1.54313 1.78987,0 0,11.06589 q 0,3.00505 -0.54238,4.24361 -0.54239,1.25887 -1.71755,1.96953 -1.17517,0.73096 -2.89271,0.73096 -2.04298,0 -3.30854,-1.03553 -1.24748,-1.03552 -1.19325,-3.10657 z m 1.59099,-7.69537 q 0,2.53806 0.8859,3.69541 0.90398,1.15735 2.24185,1.15735 1.3198,0 2.22377,-1.15735 0.90397,-1.15735 0.90397,-3.61419 0,-2.3553 -0.94013,-3.53296 -0.92205,-1.19795 -2.22377,-1.19795 -1.28364,0 -2.18761,1.17765 -0.90398,1.15735 -0.90398,3.47204 z m 9.98071,2.82233 1.91642,-0.34519 q 0.16272,1.29948 0.88589,1.98983 0.74127,0.67005 2.06106,0.67005 1.33788,0 1.97066,-0.60913 0.65087,-0.60913 0.65087,-1.4213 0,-0.73097 -0.56047,-1.15736 -0.39775,-0.28427 -1.97066,-0.73096 -2.13337,-0.60913 -2.96502,-1.03551 -0.81359,-0.44671 -1.24749,-1.21827 -0.41583,-0.79188 -0.41583,-1.72588 0,-0.85278 0.34351,-1.58374 0.36158,-0.73095 0.95822,-1.21827 0.45198,-0.36547 1.2294,-0.62942 0.77741,-0.26396 1.66331,-0.26396 1.35595,0 2.3684,0.44669 1.01245,0.4264 1.48251,1.17766 0.48815,0.73095 0.66895,1.96953 l -1.88026,0.28426 q -0.12657,-0.97461 -0.75934,-1.52284 -0.6147,-0.56852 -1.73563,-0.56852 -1.33788,0 -1.89835,0.50762 -0.56045,0.4873 -0.56045,1.13704 0,0.42638 0.23502,0.77157 0.23504,0.34517 0.74127,0.56852 0.28927,0.12176 1.69946,0.56852 2.04298,0.60913 2.85656,0.99491 0.81357,0.38579 1.26556,1.13705 0.47006,0.75127 0.47006,1.868 0,1.07613 -0.56046,2.05075 -0.56046,0.95429 -1.62715,1.48221 -1.06668,0.50762 -2.40457,0.50762 -2.22377,0 -3.39893,-1.03554 -1.15709,-1.03551 -1.48252,-3.06594 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path75"" d=""m 379.82113,10.100597 188.59569,0 0,56.645065 -188.59569,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path77"" d=""m 391.22927,39.397378 1.95258,-0.182736 q 0.14464,1.319784 0.65086,2.17257 0.50622,0.852785 1.57291,1.380699 1.08476,0.527914 2.42264,0.527914 1.19325,0 2.09722,-0.406092 0.92206,-0.406084 1.37404,-1.096438 0.45199,-0.690345 0.45199,-1.502521 0,-0.832481 -0.43391,-1.441614 -0.4339,-0.629431 -1.42828,-1.055828 -0.63278,-0.284262 -2.80231,-0.852777 -2.16953,-0.588829 -3.03735,-1.116743 -1.12092,-0.670049 -1.68139,-1.644656 -0.54238,-0.974607 -0.54238,-2.192875 0,-1.340089 0.66894,-2.497434 0.68702,-1.177657 1.97066,-1.766486 1.30172,-0.609133 2.89271,-0.609133 1.75371,0 3.09159,0.629438 1.33788,0.629439 2.04297,1.868003 0.72318,1.218268 0.77742,2.781704 l -1.98874,0.162432 q -0.16272,-1.664962 -1.10285,-2.517739 -0.92205,-0.873091 -2.72999,-0.873091 -1.88026,0 -2.74807,0.791871 -0.86782,0.771566 -0.86782,1.868003 0,0.954303 0.6147,1.563436 0.59662,0.609134 3.12774,1.25887 2.54921,0.649744 3.48934,1.137047 1.37404,0.710651 2.0249,1.807088 0.66893,1.076133 0.66893,2.497442 0,1.421301 -0.72317,2.680179 -0.72319,1.238564 -2.07914,1.92891 -1.33787,0.690354 -3.01927,0.690354 -2.13338,0 -3.57973,-0.690354 -1.44636,-0.710651 -2.27801,-2.111655 -0.81357,-1.400996 -0.84973,-3.187788 z m 19.08084,3.736007 0.27119,1.928918 q -0.81356,0.182737 -1.46443,0.182737 -1.04861,0 -1.62715,-0.365474 -0.57854,-0.385787 -0.81358,-0.974616 -0.23502,-0.609125 -0.23502,-2.578653 l 0,-7.350183 -1.42829,0 0,-1.705571 1.42829,0 0,-3.167482 1.91642,-1.29948 0,4.466962 1.95257,0 0,1.705571 -1.95257,0 0,7.472013 q 0,0.933997 0.0904,1.197954 0.10843,0.263957 0.34352,0.426397 0.23503,0.162432 0.66893,0.162432 0.30736,0 0.84974,-0.101525 z m 1.04378,-4.446657 q 0,-3.55327 1.77178,-5.279138 1.46443,-1.421309 3.57974,-1.421309 2.35032,0 3.83284,1.746181 1.50059,1.725868 1.50059,4.771529 0,2.477129 -0.66894,3.898438 -0.65086,1.401004 -1.91642,2.192875 -1.24749,0.771566 -2.74807,0.771566 -2.38649,0 -3.86901,-1.725877 -1.48251,-1.725868 -1.48251,-4.954265 z m 1.98874,0 q 0,2.456832 0.9582,3.675091 0.95822,1.218267 2.40458,1.218267 1.44635,0 2.38648,-1.218267 0.95821,-1.238564 0.95821,-3.756311 0,-2.375612 -0.95821,-3.593871 -0.95822,-1.218268 -2.38648,-1.218268 -1.44636,0 -2.40458,1.218268 -0.9582,1.218259 -0.9582,3.675091 z m 10.72191,6.39588 0,-12.812065 1.73563,0 0,1.949223 q 0.66895,-1.360394 1.2294,-1.786783 0.56047,-0.446702 1.24749,-0.446702 0.97629,0 1.98874,0.710659 l -0.66894,2.01013 q -0.7051,-0.466999 -1.42828,-0.466999 -0.63278,0 -1.13901,0.426389 -0.48814,0.426397 -0.70509,1.177657 -0.32543,1.157345 -0.32543,2.538044 l 0,6.700447 -1.93451,0 z m 14.65542,-1.583742 q -1.08477,1.035523 -2.07914,1.461912 -0.99437,0.406092 -2.13338,0.406092 -1.86218,0 -2.87462,-1.015218 -1.01246,-1.035522 -1.01246,-2.639568 0,-0.954311 0.37967,-1.725877 0.37967,-0.771565 0.99437,-1.238564 0.6147,-0.466999 1.39211,-0.710659 0.57855,-0.182737 1.71756,-0.324864 2.35033,-0.324871 3.45317,-0.75126 0,-0.446702 0,-0.568524 0,-1.319784 -0.54239,-1.868003 -0.74125,-0.730964 -2.20569,-0.730964 -1.35595,0 -2.00681,0.527914 -0.65086,0.527914 -0.95822,1.908613 l -1.89834,-0.304567 q 0.27119,-1.360386 0.84973,-2.192867 0.59663,-0.83248 1.69947,-1.279182 1.12092,-0.466999 2.60344,-0.466999 1.46444,0 2.36841,0.385787 0.90398,0.385779 1.33788,0.974607 0.43391,0.588829 0.59662,1.482225 0.10842,0.54821 0.10842,1.989825 l 0,2.903525 q 0,3.025356 0.10842,3.837531 0.12656,0.791871 0.50622,1.522827 l -2.02489,0 q -0.30735,-0.670041 -0.37967,-1.583742 z m -0.16272,-4.832443 q -1.04861,0.466999 -3.1639,0.812175 -1.19325,0.182737 -1.6814,0.426389 -0.48813,0.24366 -0.75933,0.710659 -0.27119,0.466999 -0.27119,1.035523 0,0.87309 0.57854,1.461911 0.59662,0.568523 1.71755,0.568523 1.12092,0 1.98873,-0.548218 0.86782,-0.568524 1.28365,-1.502521 0.30735,-0.751261 0.30735,-2.172571 l 0,-0.79187 z m 4.37607,7.472012 1.86219,0.324872 q 0.12655,0.974608 0.66893,1.421301 0.70511,0.588829 1.95258,0.588829 1.35596,0 2.07914,-0.609125 0.72318,-0.588829 0.99437,-1.664962 0.14463,-0.670049 0.12656,-2.802009 -1.26556,1.685267 -3.14583,1.685267 -2.35033,0 -3.65204,-1.908613 -1.28365,-1.908613 -1.28365,-4.568487 0,-1.827393 0.59663,-3.370525 0.59661,-1.563436 1.71754,-2.395916 1.12092,-0.852786 2.62152,-0.852786 2.0249,0 3.32662,1.827393 l 0,-1.543131 1.78986,0 0,11.065892 q 0,3.005042 -0.54238,4.243615 -0.54238,1.258869 -1.71754,1.96952 -1.17517,0.730956 -2.89271,0.730956 -2.04299,0 -3.30855,-1.035523 -1.24748,-1.035523 -1.19324,-3.106568 z m 1.59099,-7.695359 q 0,2.538044 0.8859,3.695396 0.90397,1.157353 2.24185,1.157353 1.31979,0 2.22377,-1.157353 0.90397,-1.157352 0.90397,-3.614176 0,-2.355315 -0.94013,-3.532964 -0.92205,-1.197963 -2.22377,-1.197963 -1.28365,0 -2.18762,1.177658 -0.90397,1.157352 -0.90397,3.472049 z m 18.56841,2.517739 1.98873,0.284262 q -0.47006,1.949223 -1.75369,3.04566 -1.26556,1.076133 -3.25431,1.076133 -2.49496,0 -3.9594,-1.725877 -1.46443,-1.725868 -1.46443,-4.85274 0,-3.228398 1.46443,-5.015189 1.48251,-1.786783 3.85093,-1.786783 2.29608,0 3.74244,1.746181 1.44635,1.746173 1.44635,4.933961 0,0.182737 -0.018,0.568524 l -8.49733,0 q 0.10841,2.111655 1.06668,3.228397 0.95821,1.116742 2.38648,1.116742 1.04861,0 1.78988,-0.609133 0.75933,-0.629439 1.21131,-2.010138 z m -6.34589,-3.512651 6.36397,0 q -0.12656,-1.604047 -0.72318,-2.416222 -0.92205,-1.258878 -2.40457,-1.258878 -1.31979,0 -2.24185,1.015226 -0.90397,0.994912 -0.99437,2.659874 z m 16.53867,7.634444 0,-12.812065 1.73563,0 0,1.827393 q 1.26556,-2.111655 3.63397,-2.111655 1.03052,0 1.89834,0.426397 0.86781,0.406084 1.28364,1.096429 0.43391,0.670049 0.6147,1.58375 0.10842,0.609125 0.10842,2.111655 l 0,7.878096 -1.9345,0 0,-7.796885 q 0,-1.319784 -0.23503,-1.969519 -0.21695,-0.670049 -0.7955,-1.055828 -0.57854,-0.385787 -1.35596,-0.385787 -1.22941,0 -2.13338,0.873091 -0.88588,0.87309 -0.88588,3.350219 l 0,6.984709 -1.93451,0 z m 11.28242,-6.39588 q 0,-3.55327 1.77178,-5.279138 1.46445,-1.421309 3.57974,-1.421309 2.35032,0 3.83284,1.746181 1.5006,1.725868 1.5006,4.771529 0,2.477129 -0.66895,3.898438 -0.65086,1.401004 -1.91642,2.192875 -1.24747,0.771566 -2.74807,0.771566 -2.38649,0 -3.86901,-1.725877 -1.48251,-1.725868 -1.48251,-4.954265 z m 1.98874,0 q 0,2.456832 0.95821,3.675091 0.95821,1.218267 2.40457,1.218267 1.44635,0 2.38648,-1.218267 0.95822,-1.238564 0.95822,-3.756311 0,-2.375612 -0.95822,-3.593871 -0.95821,-1.218268 -2.38648,-1.218268 -1.44636,0 -2.40457,1.218268 -0.95821,1.218259 -0.95821,3.675091 z m 18.1345,6.39588 0,-1.624352 q -1.08477,1.908614 -3.18198,1.908614 -1.35596,0 -2.51304,-0.832481 -1.13901,-0.852786 -1.77179,-2.355307 -0.6147,-1.522826 -0.6147,-3.492354 0,-1.908613 0.56046,-3.47205 0.57854,-1.563436 1.69947,-2.395916 1.13901,-0.832481 2.5492,-0.832481 1.03053,0 1.82602,0.487304 0.81358,0.487312 1.31981,1.279182 l 0,-6.334973 1.91642,0 0,17.664814 -1.78987,0 z m -6.11086,-6.39588 q 0,2.456832 0.92206,3.675091 0.94013,1.218267 2.18761,1.218267 1.26556,0 2.15146,-1.157352 0.88589,-1.157352 0.88589,-3.553269 0,-2.619264 -0.90398,-3.837523 -0.90397,-1.238573 -2.22376,-1.238573 -1.28365,0 -2.15146,1.177658 -0.86782,1.177657 -0.86782,3.715701 z m 18.53229,2.274087 1.98874,0.284262 q -0.47007,1.949223 -1.75371,3.04566 -1.26556,1.076133 -3.25431,1.076133 -2.49496,0 -3.95939,-1.725877 -1.46444,-1.725868 -1.46444,-4.85274 0,-3.228398 1.46444,-5.015189 1.48252,-1.786783 3.85092,-1.786783 2.29609,0 3.74245,1.746181 1.44636,1.746173 1.44636,4.933961 0,0.182737 -0.0181,0.568524 l -8.49734,0 q 0.10842,2.111655 1.06669,3.228397 0.95821,1.116742 2.38649,1.116742 1.04861,0 1.78986,-0.609133 0.75934,-0.629439 1.21133,-2.010138 z m -6.3459,-3.512651 6.36397,0 q -0.12655,-1.604047 -0.72317,-2.416222 -0.92205,-1.258878 -2.40457,-1.258878 -1.3198,0 -2.24185,1.015226 -0.90397,0.994912 -0.99438,2.659874 z m 9.76372,3.817218 1.91642,-0.345169 q 0.16272,1.299479 0.8859,1.989825 0.74125,0.670048 2.06105,0.670048 1.33789,0 1.97066,-0.609133 0.65086,-0.609134 0.65086,-1.421309 0,-0.730956 -0.56046,-1.157345 -0.39774,-0.284262 -1.97066,-0.730964 -2.13338,-0.609125 -2.96503,-1.035522 -0.81357,-0.446694 -1.24748,-1.218259 -0.41583,-0.791871 -0.41583,-1.725877 0,-0.852777 0.34352,-1.583741 0.36158,-0.730956 0.9582,-1.218259 0.45199,-0.365482 1.2294,-0.629439 0.77742,-0.263957 1.66331,-0.263957 1.35597,0 2.36841,0.446702 1.01245,0.426389 1.48252,1.177649 0.48814,0.730956 0.66893,1.969528 l -1.88026,0.284262 q -0.12655,-0.974615 -0.75934,-1.522834 -0.6147,-0.568524 -1.73562,-0.568524 -1.33788,0 -1.89834,0.507617 -0.56047,0.487304 -0.56047,1.137039 0,0.426397 0.23504,0.771566 0.23503,0.345177 0.74125,0.568524 0.28927,0.12183 1.69947,0.568523 2.04298,0.609134 2.85655,0.994913 0.81358,0.385787 1.26556,1.137047 0.47007,0.751261 0.47007,1.868004 0,1.076132 -0.56046,2.050739 -0.56047,0.954311 -1.62715,1.482225 -1.06669,0.507609 -2.40457,0.507609 -2.22377,0 -3.39894,-1.035523 -1.15708,-1.035522 -1.48251,-3.065965 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path79"" d=""m 493.17598,230.6473 4.9199,0 0,-8.90194 9.83978,0 0,8.90194 4.91987,0 -9.83977,8.90196 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path81"" d=""m 493.17598,230.6473 4.9199,0 0,-8.90194 9.83978,0 0,8.90194 4.91987,0 -9.83977,8.90196 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path83"" d=""m 659.79625,64.679308 231.38044,0 0,245.366452 -231.38044,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path85"" d=""m 659.79625,64.679308 231.38044,0 0,245.366452 -231.38044,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path87"" d=""m 679.48778,94.197087 231.38044,0 0,245.366423 -231.38044,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path89"" d=""m 679.48778,94.197087 231.38044,0 0,245.366423 -231.38044,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path91"" d=""m 699.17915,123.71488 231.38049,0 0,245.36647 -231.38049,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path93"" d=""m 699.17915,123.71488 231.38049,0 0,245.36647 -231.38049,0 z"" /> <path style=""fill:#ffd966;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path95"" d=""m 722.27858,148.87902 188.59566,0 0,182.1728 -188.59566,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path97"" d=""m 722.27858,148.87902 188.59566,0 0,182.1728 -188.59566,0 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path99"" d=""m 736.16386,251.25285 160.82564,0 0,38.88209 -160.82564,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path101"" d=""m 736.16386,251.25285 160.82564,0 0,38.88209 -160.82564,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path103"" d=""m 790.31398,279.6863 0,-17.66481 2.09722,0 0,7.24866 8.17189,0 0,-7.24866 2.07913,0 0,17.66481 -2.07913,0 0,-8.32479 -8.17189,0 0,8.32479 -2.09722,0 z m 23.09234,-4.1218 1.98874,0.28427 q -0.47009,1.94922 -1.75374,3.04566 -1.26552,1.07613 -3.25431,1.07613 -2.49493,0 -3.95938,-1.72588 -1.4644,-1.72586 -1.4644,-4.85274 0,-3.2284 1.4644,-5.01519 1.48253,-1.78678 3.85095,-1.78678 2.29605,0 3.74242,1.74617 1.44638,1.74619 1.44638,4.93397 0,0.18274 -0.0181,0.56853 l -8.49733,0 q 0.10842,2.11165 1.06668,3.22839 0.95821,1.11675 2.3865,1.11675 1.04861,0 1.78985,-0.60914 0.75932,-0.62944 1.21133,-2.01014 z m -6.34588,-3.51265 6.36396,0 q -0.12656,-1.60405 -0.72321,-2.41623 -0.92204,-1.25887 -2.40453,-1.25887 -1.31981,0 -2.24185,1.01522 -0.90397,0.99492 -0.99437,2.65988 z m 10.55914,7.63445 0,-17.66481 1.93449,0 0,10.07097 4.57412,-5.21823 2.49498,0 -4.35715,4.75123 4.79102,8.06084 -2.38644,0 -3.76056,-6.53801 -1.35597,1.46191 0,5.0761 -1.93449,0 z m 18.22409,-1.58374 q -1.08477,1.03552 -2.07914,1.46192 -0.99436,0.40608 -2.13337,0.40608 -1.86217,0 -2.87462,-1.01522 -1.01244,-1.03553 -1.01244,-2.63957 0,-0.95431 0.37963,-1.72587 0.37969,-0.77157 0.99437,-1.23857 0.61473,-0.467 1.39213,-0.71066 0.57857,-0.18273 1.71753,-0.32487 2.35034,-0.32487 3.45318,-0.75125 0,-0.44669 0,-0.56852 0,-1.3198 -0.54235,-1.86801 -0.7413,-0.73095 -2.2057,-0.73095 -1.35597,0 -2.00681,0.52791 -0.65089,0.52792 -0.95821,1.90861 l -1.89838,-0.30457 q 0.2712,-1.36039 0.84978,-2.19288 0.59659,-0.83247 1.69944,-1.27916 1.12093,-0.46701 2.60347,-0.46701 1.4644,0 2.36836,0.38579 0.90397,0.38578 1.33789,0.97461 0.43393,0.58882 0.59666,1.48221 0.10837,0.54823 0.10837,1.98984 l 0,2.90352 q 0,3.02535 0.10843,3.83752 0.12656,0.79188 0.50625,1.52284 l -2.02489,0 q -0.30737,-0.67005 -0.37969,-1.58374 z m -0.16273,-4.83245 q -1.0486,0.467 -3.1639,0.81218 -1.19325,0.18274 -1.68136,0.42639 -0.48817,0.24365 -0.75932,0.71066 -0.27121,0.467 -0.27121,1.03551 0,0.8731 0.57852,1.46192 0.59665,0.56852 1.71758,0.56852 1.12093,0 1.98873,-0.54821 0.8678,-0.56852 1.28365,-1.50253 0.30731,-0.75127 0.30731,-2.17257 l 0,-0.79187 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path105"" d=""m 771.4413,167.92801 90.27082,0 0,38.88209 -90.27082,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path107"" d=""m 771.4413,167.92801 90.27082,0 0,38.88209 -90.27082,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path109"" d=""m 795.45915,196.36147 0,-17.6648 2.07913,0 0,15.57345 7.7561,0 0,2.09135 -9.83523,0 z m 11.11974,-6.39588 q 0,-3.55326 1.77176,-5.27914 1.4644,-1.4213 3.57975,-1.4213 2.35029,0 3.83282,1.74617 1.50057,1.72588 1.50057,4.77154 0,2.47713 -0.66892,3.89843 -0.65084,1.401 -1.91641,2.19288 -1.2475,0.77157 -2.74806,0.77157 -2.3865,0 -3.86903,-1.72588 -1.48248,-1.72587 -1.48248,-4.95427 z m 1.98873,0 q 0,2.45684 0.9582,3.6751 0.95821,1.21826 2.40458,1.21826 1.44632,0 2.38645,-1.21826 0.9582,-1.23858 0.9582,-3.75632 0,-2.3756 -0.9582,-3.59387 -0.95821,-1.21826 -2.38645,-1.21826 -1.44637,0 -2.40458,1.21826 -0.9582,1.21827 -0.9582,3.67509 z m 10.39652,7.45171 1.86217,0.32487 q 0.12656,0.97461 0.66892,1.42131 0.70513,0.58882 1.95257,0.58882 1.35597,0 2.07919,-0.60913 0.72316,-0.58882 0.99436,-1.66496 0.14459,-0.67003 0.12657,-2.802 -1.26558,1.68526 -3.14583,1.68526 -2.35034,0 -3.65207,-1.90861 -1.28365,-1.9086 -1.28365,-4.56849 0,-1.82739 0.59665,-3.37052 0.5966,-1.56344 1.71753,-2.39592 1.12093,-0.85278 2.62154,-0.85278 2.0249,0 3.32658,1.82739 l 0,-1.54313 1.7899,0 0,11.06589 q 0,3.00505 -0.54241,4.24361 -0.54236,1.25887 -1.71753,1.96953 -1.17517,0.73096 -2.8927,0.73096 -2.04302,0 -3.30854,-1.03553 -1.24749,-1.03552 -1.19325,-3.10657 z m 1.59096,-7.69537 q 0,2.53806 0.88589,3.69541 0.90401,1.15735 2.24185,1.15735 1.31982,0 2.22378,-1.15735 0.90396,-1.15735 0.90396,-3.61419 0,-2.3553 -0.94012,-3.53296 -0.92204,-1.19795 -2.22378,-1.19795 -1.28365,0 -2.18761,1.17765 -0.90397,1.15735 -0.90397,3.47204 z m 9.98062,2.82233 1.91647,-0.34519 q 0.16267,1.29948 0.88588,1.98983 0.74124,0.67005 2.06106,0.67005 1.33789,0 1.97065,-0.60913 0.65084,-0.60913 0.65084,-1.4213 0,-0.73097 -0.56044,-1.15736 -0.39777,-0.28427 -1.97065,-0.73096 -2.13338,-0.60913 -2.96507,-1.03551 -0.81357,-0.44671 -1.24744,-1.21827 -0.41585,-0.79188 -0.41585,-1.72588 0,-0.85278 0.34353,-1.58374 0.36155,-0.73095 0.9582,-1.21827 0.45196,-0.36547 1.22941,-0.62942 0.7774,-0.26396 1.66329,-0.26396 1.35597,0 2.36842,0.44669 1.01244,0.4264 1.48253,1.17766 0.48812,0.73095 0.66892,1.96953 l -1.88025,0.28426 q -0.12656,-0.97461 -0.75937,-1.52284 -0.61468,-0.56852 -1.73561,-0.56852 -1.33789,0 -1.89833,0.50762 -0.56049,0.4873 -0.56049,1.13704 0,0.42638 0.23504,0.77157 0.23505,0.34517 0.74125,0.56852 0.28928,0.12176 1.6995,0.56852 2.04297,0.60913 2.85653,0.99491 0.81356,0.38579 1.26557,1.13705 0.47004,0.75127 0.47004,1.868 0,1.07613 -0.56044,2.05075 -0.56044,0.95429 -1.62712,1.48221 -1.06669,0.50762 -2.40458,0.50762 -2.22378,0 -3.39895,-1.03554 -1.15709,-1.03551 -1.48254,-3.06594 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path111"" d=""m 698.65124,8.033707 188.59567,0 0,56.645065 -188.59567,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path113"" d=""m 710.74641,43.015718 0,-17.664814 2.13337,0 8.26235,13.867893 0,-13.867893 1.98873,0 0,17.664814 -2.13337,0 -8.26235,-13.888197 0,13.888197 -1.98873,0 z m 23.16456,-4.121793 1.98873,0.284262 q -0.47004,1.949223 -1.75369,3.04566 -1.26557,1.076124 -3.2543,1.076124 -2.49493,0 -3.95939,-1.725867 -1.46445,-1.725877 -1.46445,-4.852749 0,-3.228398 1.46445,-5.015181 1.48254,-1.786783 3.85091,-1.786783 2.29609,0 3.74247,1.746173 1.44632,1.746181 1.44632,4.933969 0,0.182737 -0.0181,0.568524 l -8.49734,0 q 0.10843,2.111655 1.06669,3.228389 0.9582,1.116742 2.38649,1.116742 1.04861,0 1.78985,-0.609133 0.75932,-0.629431 1.21133,-2.01013 z m -6.34589,-3.51266 6.36397,0 q -0.12657,-1.604046 -0.72316,-2.416222 -0.92205,-1.258869 -2.40458,-1.258869 -1.31976,0 -2.24186,1.015218 -0.90396,0.994912 -0.99437,2.659873 z m 14.77181,5.68523 0.27115,1.928918 q -0.81356,0.182737 -1.4644,0.182737 -1.04861,0 -1.62718,-0.365482 -0.57852,-0.385779 -0.81356,-0.974608 -0.23504,-0.609133 -0.23504,-2.578653 l 0,-7.350191 -1.4283,0 0,-1.705563 1.4283,0 0,-3.167482 1.91641,-1.299488 0,4.46697 1.95262,0 0,1.705563 -1.95262,0 0,7.472012 q 0,0.934006 0.0904,1.197963 0.10843,0.263957 0.34347,0.426389 0.23505,0.16244 0.66897,0.16244 0.30737,0 0.84973,-0.101533 z m 3.88216,1.949223 -3.4893,-12.812065 1.98873,0 1.80793,7.390792 0.68706,2.761399 q 0.0363,-0.20305 0.57851,-2.639577 l 1.82601,-7.512614 1.98873,0 1.6995,7.431402 0.56044,2.456832 0.66897,-2.477137 1.95258,-7.411097 1.88025,0 -3.56167,12.812065 -2.00682,0 -1.82601,-7.675063 -0.43392,-2.172561 -2.31413,9.847624 -2.00686,0 z m 12.75091,-6.39588 q 0,-3.55327 1.77177,-5.279146 1.46445,-1.421301 3.57975,-1.421301 2.35034,0 3.83282,1.746173 1.50061,1.725876 1.50061,4.771529 0,2.477137 -0.66892,3.898446 -0.65089,1.400996 -1.91646,2.192867 -1.24749,0.771565 -2.74805,0.771565 -2.3865,0 -3.86898,-1.725867 -1.48254,-1.725877 -1.48254,-4.954266 z m 1.98873,0 q 0,2.456824 0.95821,3.675091 0.9582,1.218259 2.40458,1.218259 1.44637,0 2.3865,-1.218259 0.9582,-1.238572 0.9582,-3.756311 0,-2.375612 -0.9582,-3.59388 -0.95826,-1.218259 -2.3865,-1.218259 -1.44638,0 -2.40458,1.218259 -0.95821,1.218268 -0.95821,3.6751 z m 10.72197,6.39588 0,-12.812065 1.73561,0 0,1.949215 q 0.66897,-1.360395 1.22941,-1.786783 0.56049,-0.446694 1.24749,-0.446694 0.97628,0 1.98873,0.710651 l -0.66892,2.010138 q -0.70513,-0.467007 -1.42829,-0.467007 -0.63282,0 -1.13901,0.426397 -0.48812,0.426388 -0.70508,1.177649 -0.32545,1.157353 -0.32545,2.538052 l 0,6.700447 -1.93449,0 z m 7.22473,0 0,-17.664814 1.93449,0 0,10.070971 4.57406,-5.218222 2.49498,0 -4.35715,4.751224 4.79108,8.060841 -2.3865,0 -3.7605,-6.538015 -1.35597,1.461919 0,5.076096 -1.93449,0 z m 16.77291,0 0,-12.812065 1.73561,0 0,1.827393 q 1.26557,-2.111655 3.63399,-2.111655 1.03052,0 1.89833,0.426389 0.8678,0.406092 1.28365,1.096437 0.43393,0.670049 0.61468,1.583741 0.10843,0.609134 0.10843,2.111655 l 0,7.878105 -1.93449,0 0,-7.796885 q 0,-1.319784 -0.23505,-1.969528 -0.21696,-0.67004 -0.79548,-1.055827 -0.57857,-0.385779 -1.35597,-0.385779 -1.22941,0 -2.13338,0.873083 -0.88588,0.87309 -0.88588,3.350227 l 0,6.984709 -1.93449,0 z m 11.28235,-6.39588 q 0,-3.55327 1.77177,-5.279146 1.46446,-1.421301 3.57975,-1.421301 2.35034,0 3.83282,1.746173 1.50062,1.725876 1.50062,4.771529 0,2.477137 -0.66898,3.898446 -0.65084,1.400996 -1.91641,2.192867 -1.24749,0.771565 -2.74805,0.771565 -2.3865,0 -3.86904,-1.725867 -1.48248,-1.725877 -1.48248,-4.954266 z m 1.98873,0 q 0,2.456824 0.95821,3.675091 0.95821,1.218259 2.40458,1.218259 1.44632,0 2.3865,-1.218259 0.9582,-1.238572 0.9582,-3.756311 0,-2.375612 -0.9582,-3.59388 -0.95821,-1.218259 -2.3865,-1.218259 -1.44637,0 -2.40458,1.218259 -0.95821,1.218268 -0.95821,3.6751 z m 18.13454,6.39588 0,-1.624351 q -1.08476,1.908604 -3.18198,1.908604 -1.35597,0 -2.51306,-0.832472 -1.13901,-0.852785 -1.77177,-2.355315 -0.61473,-1.522826 -0.61473,-3.492346 0,-1.908613 0.56049,-3.472049 0.57852,-1.563445 1.69945,-2.395917 1.13901,-0.832481 2.54922,-0.832481 1.03053,0 1.82601,0.487304 0.81356,0.487303 1.31981,1.279174 l 0,-6.334965 1.91641,0 0,17.664814 -1.78985,0 z m -6.11084,-6.39588 q 0,2.456824 0.92205,3.675091 0.94012,1.218259 2.18762,1.218259 1.26551,0 2.15145,-1.157344 0.88588,-1.157352 0.88588,-3.553269 0,-2.619264 -0.90396,-3.837532 -0.90396,-1.238564 -2.22378,-1.238564 -1.28365,0 -2.15145,1.177658 -0.86781,1.177649 -0.86781,3.715701 z m 18.53226,2.274087 1.98873,0.284262 q -0.47004,1.949223 -1.75369,3.04566 -1.26557,1.076124 -3.2543,1.076124 -2.49498,0 -3.95938,-1.725867 -1.46446,-1.725877 -1.46446,-4.852749 0,-3.228398 1.46446,-5.015181 1.48248,-1.786783 3.8509,-1.786783 2.2961,0 3.74247,1.746173 1.44632,1.746181 1.44632,4.933969 0,0.182737 -0.0181,0.568524 l -8.49734,0 q 0.10843,2.111655 1.06669,3.228389 0.9582,1.116742 2.3865,1.116742 1.0486,0 1.78984,-0.609133 0.75938,-0.629431 1.21133,-2.01013 z m -6.34589,-3.51266 6.36397,0 q -0.12656,-1.604046 -0.72316,-2.416222 -0.92205,-1.258869 -2.40458,-1.258869 -1.31981,0 -2.24186,1.015218 -0.90396,0.994912 -0.99437,2.659873 z m 9.76377,3.817227 1.91641,-0.345177 q 0.16272,1.299479 0.88588,1.989833 0.74124,0.67004 2.06106,0.67004 1.33789,0 1.97065,-0.609133 0.65089,-0.609126 0.65089,-1.421302 0,-0.730955 -0.56049,-1.157352 -0.39772,-0.284262 -1.97065,-0.730956 -2.13338,-0.609133 -2.96502,-1.035522 -0.81356,-0.446702 -1.24749,-1.218268 -0.41585,-0.79187 -0.41585,-1.725868 0,-0.852785 0.34353,-1.583741 0.3616,-0.730956 0.9582,-1.218268 0.45201,-0.365473 1.22941,-0.62943 0.77741,-0.263957 1.66329,-0.263957 1.35597,0 2.36842,0.446694 1.01244,0.426388 1.48253,1.177657 0.48812,0.730956 0.66892,1.96952 l -1.88025,0.284262 q -0.12656,-0.974607 -0.75932,-1.522826 -0.61473,-0.568524 -1.73566,-0.568524 -1.33784,0 -1.89833,0.507609 -0.56044,0.487304 -0.56044,1.137047 0,0.426389 0.235,0.771566 0.23504,0.345177 0.74129,0.568524 0.28923,0.121822 1.69945,0.568523 2.04297,0.609126 2.85653,0.994913 0.81362,0.385787 1.26557,1.137048 0.47009,0.75126 0.47009,1.868003 0,1.076132 -0.56049,2.05074 -0.56044,0.954302 -1.62712,1.482216 -1.06669,0.507608 -2.40458,0.507608 -2.22378,0 -3.39895,-1.035522 -1.15709,-1.035522 -1.48248,-3.065957 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path115"" d=""m 806.74604,230.6473 4.91982,0 0,-8.90194 9.83982,0 0,8.90194 4.91988,0 -9.83976,8.90196 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path117"" d=""m 806.74604,230.6473 4.91982,0 0,-8.90194 9.83982,0 0,8.90194 4.91988,0 -9.83976,8.90196 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path119"" d=""m 505.93425,646.74851 231.38046,0 0,245.36649 -231.38046,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path121"" d=""m 505.93425,646.74851 231.38046,0 0,245.36649 -231.38046,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path123"" d=""m 525.6257,676.26627 231.38054,0 0,245.36651 -231.38054,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path125"" d=""m 525.6257,676.26627 231.38054,0 0,245.36651 -231.38054,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path127"" d=""m 545.31721,705.78408 231.38045,0 0,245.36647 -231.38045,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path129"" d=""m 545.31721,705.78408 231.38045,0 0,245.36647 -231.38045,0 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path131"" d=""m 568.41682,892.10766 188.59566,0 0,56.64504 -188.59566,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path133"" d=""m 580.56623,927.08965 0,-17.66478 11.39003,0 0,2.07106 -9.3109,0 0,5.42127 8.7143,0 0,2.07106 -8.7143,0 0,6.01005 9.67251,0 0,2.09134 -11.75164,0 z m 14.07286,0 0,-17.66478 1.93449,0 0,17.66478 -1.93449,0 z m 12.28072,-1.58367 q -1.08477,1.03553 -2.07914,1.46191 -0.99436,0.4061 -2.13337,0.4061 -1.86217,0 -2.87462,-1.01525 -1.01244,-1.03553 -1.01244,-2.63957 0,-0.95433 0.37963,-1.72588 0.37969,-0.77156 0.99442,-1.23858 0.61468,-0.46703 1.39208,-0.71064 0.57857,-0.18277 1.71758,-0.3249 2.35034,-0.32481 3.45313,-0.75119 0,-0.44674 0,-0.56859 0,-1.31978 -0.54235,-1.86801 -0.74125,-0.73092 -2.2057,-0.73092 -1.35597,0 -2.00681,0.52795 -0.65084,0.52787 -0.95821,1.90857 l -1.89833,-0.30453 q 0.27115,-1.36043 0.84972,-2.19291 0.5966,-0.83248 1.69945,-1.27914 1.12093,-0.46702 2.60347,-0.46702 1.4644,0 2.36841,0.38573 0.90397,0.38582 1.33784,0.97461 0.43393,0.58887 0.59666,1.48228 0.10837,0.54822 0.10837,1.98977 l 0,2.90354 q 0,3.02539 0.10843,3.83751 0.12656,0.79192 0.50625,1.52283 l -2.02489,0 q -0.30737,-0.66999 -0.37969,-1.58367 z m -0.16273,-4.83248 q -1.0486,0.46703 -3.1639,0.8122 -1.1932,0.18269 -1.68136,0.42638 -0.48812,0.24361 -0.75933,0.71064 -0.2712,0.46702 -0.2712,1.03553 0,0.87312 0.57852,1.46191 0.59665,0.56851 1.71758,0.56851 1.12093,0 1.98873,-0.54823 0.8678,-0.56851 1.28365,-1.50247 0.30731,-0.75128 0.30731,-2.17263 l 0,-0.79184 z m 3.94221,2.59901 1.91641,-0.34526 q 0.16273,1.2995 0.88589,1.98986 0.74124,0.67007 2.06105,0.67007 1.33789,0 1.97065,-0.60915 0.65089,-0.60915 0.65089,-1.42127 0,-0.73099 -0.56049,-1.15737 -0.39771,-0.28426 -1.97065,-0.731 -2.13337,-0.60907 -2.96502,-1.03545 -0.81356,-0.44674 -1.24749,-1.2183 -0.41584,-0.79192 -0.41584,-1.72588 0,-0.85276 0.34352,-1.58376 0.36161,-0.73092 0.95821,-1.21822 0.45201,-0.36554 1.22941,-0.62943 0.7774,-0.26397 1.66334,-0.26397 1.35592,0 2.36836,0.44666 1.01245,0.42638 1.48254,1.17765 0.48811,0.731 0.66892,1.96958 l -1.88025,0.28426 q -0.12656,-0.97461 -0.75932,-1.52284 -0.61473,-0.56851 -1.73566,-0.56851 -1.33784,0 -1.89833,0.50759 -0.56044,0.4873 -0.56044,1.13701 0,0.42638 0.23499,0.77156 0.23504,0.34518 0.74129,0.56859 0.28929,0.12176 1.69945,0.56851 2.04297,0.60915 2.85659,0.99489 0.81356,0.38581 1.26552,1.13701 0.47009,0.75128 0.47009,1.86801 0,1.07617 -0.56049,2.05078 -0.56044,0.95433 -1.62713,1.48219 -1.06669,0.50767 -2.40458,0.50767 -2.22378,0 -3.39895,-1.03553 -1.15708,-1.03553 -1.48248,-3.06595 z m 15.80143,1.86793 0.2712,1.92893 q -0.81361,0.18277 -1.46445,0.18277 -1.04861,0 -1.62713,-0.36545 -0.57857,-0.38582 -0.81361,-0.97461 -0.23499,-0.60915 -0.23499,-2.57873 l 0,-7.3502 -1.4283,0 0,-1.70552 1.4283,0 0,-3.16752 1.91641,-1.29942 0,4.46694 1.95257,0 0,1.70552 -1.95257,0 0,7.47205 q 0,0.93404 0.0903,1.19794 0.10843,0.26397 0.34352,0.42638 0.23505,0.16249 0.66892,0.16249 0.30737,0 0.84978,-0.10149 z m 1.78499,-13.23841 0,-2.47716 1.9345,0 0,2.47716 -1.9345,0 z m 0,15.18762 0,-12.81202 1.9345,0 0,12.81202 -1.9345,0 z m 12.22659,-4.69026 1.89833,0.28425 q -0.30737,2.19291 -1.59097,3.45177 -1.28365,1.23858 -3.16395,1.23858 -2.33221,0 -3.7605,-1.7056 -1.41021,-1.72589 -1.41021,-4.93396 0,-2.07107 0.59665,-3.61418 0.61468,-1.56348 1.86217,-2.33504 1.26557,-0.79183 2.72997,-0.79183 1.86222,0 3.03739,1.05581 1.17512,1.05581 1.51865,3.00502 l -1.88025,0.3249 q -0.27121,-1.2995 -0.95821,-1.94921 -0.68705,-0.64972 -1.64526,-0.64972 -1.4644,0 -2.38644,1.17766 -0.90402,1.17758 -0.90402,3.71566 0,2.57865 0.88593,3.7563 0.88589,1.15738 2.2961,1.15738 1.13896,0 1.89833,-0.77156 0.75932,-0.79192 0.97629,-2.41623 z m 2.56725,0.87312 1.91646,-0.34526 q 0.16267,1.2995 0.88589,1.98986 0.74124,0.67007 2.06105,0.67007 1.33789,0 1.97065,-0.60915 0.65084,-0.60915 0.65084,-1.42127 0,-0.73099 -0.56044,-1.15737 -0.39776,-0.28426 -1.97065,-0.731 -2.13337,-0.60907 -2.96507,-1.03545 -0.81356,-0.44674 -1.24744,-1.2183 -0.41585,-0.79192 -0.41585,-1.72588 0,-0.85276 0.34353,-1.58376 0.36156,-0.73092 0.95821,-1.21822 0.45195,-0.36554 1.22941,-0.62943 0.7774,-0.26397 1.66328,-0.26397 1.35598,0 2.36842,0.44666 1.01245,0.42638 1.48254,1.17765 0.48811,0.731 0.66892,1.96958 l -1.88025,0.28426 q -0.12656,-0.97461 -0.75938,-1.52284 -0.61468,-0.56851 -1.7356,-0.56851 -1.3379,0 -1.89833,0.50759 -0.5605,0.4873 -0.5605,1.13701 0,0.42638 0.23505,0.77156 0.23504,0.34518 0.74124,0.56859 0.28929,0.12176 1.6995,0.56851 2.04297,0.60915 2.85654,0.99489 0.81356,0.38581 1.26557,1.13701 0.47003,0.75128 0.47003,1.86801 0,1.07617 -0.56043,2.05078 -0.5605,0.95433 -1.62713,1.48219 -1.06674,0.50767 -2.40458,0.50767 -2.22378,0 -3.39895,-1.03553 -1.15709,-1.03553 -1.48253,-3.06595 z m 19.38118,-0.30462 1.98873,0.28426 q -0.47004,1.94921 -1.75369,3.04567 -1.26557,1.07617 -3.2543,1.07617 -2.49499,0 -3.95939,-1.72588 -1.46445,-1.72589 -1.46445,-4.85276 0,-3.22844 1.46445,-5.01517 1.48248,-1.7868 3.8509,-1.7868 2.2961,0 3.74248,1.74616 1.44632,1.74617 1.44632,4.93396 0,0.18277 -0.0181,0.56851 l -8.49733,0 q 0.10843,2.1117 1.06668,3.22844 0.95821,1.11673 2.3865,1.11673 1.04861,0 1.78985,-0.60915 0.75932,-0.62943 1.21133,-2.01014 z m -6.34589,-3.51261 6.36397,0 q -0.12657,-1.60412 -0.72317,-2.41623 -0.92204,-1.25887 -2.40458,-1.25887 -1.31981,0 -2.24185,1.01517 -0.90397,0.99497 -0.99437,2.65993 z m 17.9899,6.0507 q -1.08477,1.03553 -2.07914,1.46191 -0.99436,0.4061 -2.13337,0.4061 -1.86217,0 -2.87462,-1.01525 -1.01244,-1.03553 -1.01244,-2.63957 0,-0.95433 0.37963,-1.72588 0.37969,-0.77156 0.99437,-1.23858 0.61473,-0.46703 1.39213,-0.71064 0.57857,-0.18277 1.71753,-0.3249 2.35034,-0.32481 3.45318,-0.75119 0,-0.44674 0,-0.56859 0,-1.31978 -0.54235,-1.86801 -0.7413,-0.73092 -2.2057,-0.73092 -1.35597,0 -2.00681,0.52795 -0.65089,0.52787 -0.95821,1.90857 l -1.89838,-0.30453 q 0.27121,-1.36043 0.84978,-2.19291 0.5966,-0.83248 1.69944,-1.27914 1.12093,-0.46702 2.60347,-0.46702 1.4644,0 2.36836,0.38573 0.90397,0.38582 1.3379,0.97461 0.43392,0.58887 0.59665,1.48228 0.10837,0.54822 0.10837,1.98977 l 0,2.90354 q 0,3.02539 0.10843,3.83751 0.12656,0.79192 0.50625,1.52283 l -2.02489,0 q -0.30737,-0.66999 -0.37969,-1.58367 z m -0.16273,-4.83248 q -1.0486,0.46703 -3.1639,0.8122 -1.19325,0.18269 -1.68136,0.42638 -0.48817,0.24361 -0.75932,0.71064 -0.27121,0.46702 -0.27121,1.03553 0,0.87312 0.57852,1.46191 0.59665,0.56851 1.71758,0.56851 1.12093,0 1.98873,-0.54823 0.8678,-0.56851 1.2836,-1.50247 0.30736,-0.75128 0.30736,-2.17263 l 0,-0.79184 z m 4.70154,6.41615 0,-12.81202 1.7356,0 0,1.94922 q 0.66892,-1.36043 1.22941,-1.78681 0.56044,-0.44666 1.24749,-0.44666 0.97629,0 1.98874,0.71063 l -0.66892,2.01014 q -0.70514,-0.46702 -1.4283,-0.46702 -0.63281,0 -1.13901,0.42638 -0.48817,0.42646 -0.70508,1.17765 -0.32544,1.15738 -0.32544,2.53809 l 0,6.7004 -1.93449,0 z m 14.65537,-4.69026 1.89833,0.28425 q -0.30736,2.19291 -1.59101,3.45177 -1.28365,1.23858 -3.1639,1.23858 -2.33221,0 -3.7605,-1.7056 -1.41022,-1.72589 -1.41022,-4.93396 0,-2.07107 0.59665,-3.61418 0.61468,-1.56348 1.86217,-2.33504 1.26557,-0.79183 2.72998,-0.79183 1.86217,0 3.03733,1.05581 1.17517,1.05581 1.5187,3.00502 l -1.88025,0.3249 q -0.2712,-1.2995 -0.9582,-1.94921 -0.68706,-0.64972 -1.64526,-0.64972 -1.4644,0 -2.3865,1.17766 -0.90397,1.17758 -0.90397,3.71566 0,2.57865 0.88589,3.7563 0.88593,1.15738 2.2961,1.15738 1.139,0 1.89833,-0.77156 0.75937,-0.79192 0.97633,-2.41623 z m 3.34471,4.69026 0,-17.66478 1.93449,0 0,6.33495 q 1.35592,-1.76644 3.41703,-1.76644 1.26551,0 2.18756,0.5685 0.94012,0.54823 1.33789,1.54312 0.41585,0.99497 0.41585,2.86298 l 0,8.12167 -1.93449,0 0,-8.12167 q 0,-1.6244 -0.63281,-2.35532 -0.63276,-0.75127 -1.77177,-0.75127 -0.8678,0 -1.62718,0.50758 -0.74124,0.48731 -1.06669,1.36043 -0.32539,0.85276 -0.32539,2.35531 l 0,7.00494 -1.93449,0 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path135"" d=""m 577.65225,721.23555 150.992,0 0,193.50102 -150.992,0 z"" /> <g id=""g137"" transform=""matrix(0.57851343,0,0,0.8234084,577.65225,721.23559)""> <clipPath id=""p.1""> <path inkscape:connector-curvature=""0"" id=""path140"" clip-rule=""nonzero"" d=""m 0,0 261,0 0,235 -261,0 z"" /> </clipPath> <image style=""fill:#000000"" id=""image142"" xlink:href=""data:image/png;base64,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"" preserveAspectRatio=""none"" y=""0"" x=""0"" height=""235"" width=""261"" clip-path=""url(#p.1)"" /> </g> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path144"" d=""M 196.37908,290.13709 653.16332,721.23716"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path146"" d=""M 196.37908,290.13709 647.84833,716.22102"" /> <path style=""fill:#000000;fill-rule:evenodd;stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt"" inkscape:connector-curvature=""0"" id=""path148"" d=""m 646.61876,717.86426 5.24955,2.15067 -2.7904,-5.43712 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path150"" d=""M 503.00663,290.13495 653.15425,721.23503"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path152"" d=""M 503.00663,290.13495 650.62535,713.97383"" /> <path style=""fill:#000000;fill-rule:evenodd;stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt"" inkscape:connector-curvature=""0"" id=""path154"" d=""m 648.84547,714.75568 3.69266,4.71014 -0.13291,-6.2739 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path156"" d=""M 816.57673,290.13495 653.16353,721.23503"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path158"" d=""M 816.57673,290.13495 655.88284,714.06115"" /> <path style=""fill:#000000;fill-rule:evenodd;stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt"" inkscape:connector-curvature=""0"" id=""path160"" d=""m 654.1244,713.22043 -0.2983,6.26668 3.81528,-4.58521 z"" /> <path style=""fill:#ffffff;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path162"" d=""m 708.9875,464.83362 74.05338,0 0,56.64507 -74.05338,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path164"" d=""m 708.9875,464.83362 74.05338,0 0,56.64507 -74.05338,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path166"" d=""m 721.01029,502.14856 0,-17.6648 2.07913,0 0,15.57345 7.7561,0 0,2.09135 -9.83523,0 z m 11.11974,-6.39588 q 0,-3.55326 1.77176,-5.27914 1.46446,-1.4213 3.57975,-1.4213 2.35034,0 3.83282,1.74617 1.50062,1.72588 1.50062,4.77154 0,2.47713 -0.66892,3.89844 -0.65089,1.40099 -1.91646,2.19287 -1.24749,0.77157 -2.74806,0.77157 -2.3865,0 -3.86898,-1.72588 -1.48253,-1.72587 -1.48253,-4.95427 z m 1.98873,0 q 0,2.45684 0.9582,3.6751 0.95821,1.21826 2.40458,1.21826 1.44638,0 2.3865,-1.21826 0.95821,-1.23858 0.95821,-3.75632 0,-2.3756 -0.95821,-3.59387 -0.9582,-1.21826 -2.3865,-1.21826 -1.44637,0 -2.40458,1.21826 -0.9582,1.21827 -0.9582,3.67509 z m 10.39652,7.45171 1.86217,0.32487 q 0.12656,0.97462 0.66897,1.42131 0.70508,0.58882 1.95257,0.58882 1.35598,0 2.07914,-0.60913 0.72316,-0.58882 0.99436,-1.66496 0.14465,-0.67003 0.12657,-2.802 -1.26558,1.68526 -3.14583,1.68526 -2.35033,0 -3.65207,-1.9086 -1.28365,-1.90861 -1.28365,-4.5685 0,-1.82739 0.59665,-3.37052 0.5966,-1.56344 1.71753,-2.39592 1.12093,-0.85278 2.62154,-0.85278 2.0249,0 3.32663,1.82739 l 0,-1.54313 1.78985,0 0,11.06589 q 0,3.00505 -0.54236,4.24361 -0.54241,1.25887 -1.71758,1.96953 -1.17517,0.73096 -2.8927,0.73096 -2.04297,0 -3.30854,-1.03553 -1.24749,-1.03551 -1.19325,-3.10657 z m 1.59102,-7.69537 q 0,2.53806 0.88588,3.69541 0.90396,1.15735 2.24186,1.15735 1.31976,0 2.22377,-1.15735 0.90397,-1.15735 0.90397,-3.61419 0,-2.3553 -0.94013,-3.53296 -0.92204,-1.19795 -2.22377,-1.19795 -1.28365,0 -2.18762,1.17765 -0.90396,1.15735 -0.90396,3.47204 z m 9.98067,2.82233 1.91641,-0.34519 q 0.16272,1.29948 0.88594,1.98983 0.74124,0.67005 2.06105,0.67005 1.33784,0 1.97065,-0.60913 0.65084,-0.60913 0.65084,-1.4213 0,-0.73097 -0.56043,-1.15736 -0.39777,-0.28426 -1.97066,-0.73096 -2.13337,-0.60913 -2.96507,-1.03551 -0.81356,-0.4467 -1.24749,-1.21827 -0.41579,-0.79188 -0.41579,-1.72588 0,-0.85278 0.34352,-1.58374 0.36156,-0.73095 0.95821,-1.21827 0.45195,-0.36547 1.22941,-0.62942 0.7774,-0.26396 1.66329,-0.26396 1.35597,0 2.36841,0.44669 1.01245,0.4264 1.48249,1.17766 0.48817,0.73095 0.66897,1.96953 l -1.88025,0.28426 q -0.12656,-0.97461 -0.75937,-1.52284 -0.61468,-0.56852 -1.73561,-0.56852 -1.33789,0 -1.89833,0.50762 -0.56049,0.4873 -0.56049,1.13705 0,0.42638 0.23504,0.77156 0.23505,0.34517 0.74124,0.56852 0.28929,0.12176 1.6995,0.56852 2.04298,0.60913 2.85654,0.99491 0.81356,0.38579 1.26557,1.13705 0.47003,0.75127 0.47003,1.868 0,1.07614 -0.56043,2.05075 -0.56049,0.9543 -1.62718,1.48221 -1.06669,0.50762 -2.40453,0.50762 -2.22377,0 -3.39894,-1.03553 -1.15709,-1.03552 -1.48254,-3.06595 z"" /> <path style=""fill:#ffffff;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path168"" d=""m 531.65438,464.83525 74.0534,0 0,56.64506 -74.0534,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path170"" d=""m 531.65438,464.83525 74.0534,0 0,56.64506 -74.0534,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path172"" d=""m 543.67723,502.15018 0,-17.66481 2.07913,0 0,15.57345 7.75609,0 0,2.09136 -9.83522,0 z m 11.11971,-6.39589 q 0,-3.55326 1.77179,-5.27914 1.46442,-1.4213 3.57972,-1.4213 2.35033,0 3.83287,1.74618 1.50056,1.72587 1.50056,4.77153 0,2.47713 -0.66892,3.89844 -0.65089,1.401 -1.91641,2.19288 -1.24751,0.77156 -2.7481,0.77156 -2.38648,0 -3.869,-1.72588 -1.48251,-1.72586 -1.48251,-4.95427 z m 1.98874,0 q 0,2.45684 0.95821,3.6751 0.95821,1.21826 2.40456,1.21826 1.44636,0 2.38649,-1.21826 0.95821,-1.23857 0.95821,-3.75632 0,-2.3756 -0.95821,-3.59386 -0.95821,-1.21827 -2.38649,-1.21827 -1.44635,0 -2.40456,1.21827 -0.95821,1.21826 -0.95821,3.67508 z m 10.39645,7.45172 1.86217,0.32487 q 0.12656,0.97461 0.66897,1.4213 0.70508,0.58882 1.95257,0.58882 1.35597,0 2.07913,-0.60912 0.72317,-0.58882 0.99437,-1.66497 0.14464,-0.67004 0.12656,-2.802 -1.26557,1.68527 -3.14582,1.68527 -2.35034,0 -3.65207,-1.90861 -1.28365,-1.90862 -1.28365,-4.5685 0,-1.82739 0.59665,-3.37052 0.5966,-1.56343 1.71753,-2.39592 1.12093,-0.85278 2.62154,-0.85278 2.02489,0 3.32663,1.82739 l 0,-1.54313 1.78984,0 0,11.06589 q 0,3.00505 -0.54241,4.24361 -0.54235,1.25887 -1.71752,1.96953 -1.17517,0.73096 -2.8927,0.73096 -2.04297,0 -3.30854,-1.03553 -1.24749,-1.03552 -1.19325,-3.10656 z m 1.59096,-7.69537 q 0,2.53805 0.88594,3.6954 0.90396,1.15736 2.24186,1.15736 1.31975,0 2.22372,-1.15736 0.90402,-1.15735 0.90402,-3.61418 0,-2.35531 -0.94013,-3.53296 -0.9221,-1.19796 -2.22378,-1.19796 -1.28365,0 -2.18761,1.17766 -0.90402,1.15734 -0.90402,3.47204 z m 9.98073,2.82231 1.91641,-0.34517 q 0.16272,1.29948 0.88588,1.98982 0.7413,0.67005 2.06111,0.67005 1.33784,0 1.97065,-0.60912 0.65084,-0.60914 0.65084,-1.42131 0,-0.73096 -0.56044,-1.15736 -0.39776,-0.28426 -1.9707,-0.73096 -2.13338,-0.60913 -2.96502,-1.03551 -0.81356,-0.4467 -1.24749,-1.21826 -0.41579,-0.79188 -0.41579,-1.72589 0,-0.85278 0.34347,-1.58374 0.36161,-0.73096 0.9582,-1.21826 0.45201,-0.36548 1.22941,-0.62943 0.77746,-0.26396 1.66334,-0.26396 1.35598,0 2.36842,0.4467 1.01245,0.42639 1.48248,1.17765 0.48817,0.73095 0.66892,1.96952 l -1.88025,0.28427 q -0.12656,-0.97461 -0.75932,-1.52284 -0.61468,-0.56852 -1.7356,-0.56852 -1.3379,0 -1.89839,0.50762 -0.56044,0.48731 -0.56044,1.13704 0,0.42639 0.23505,0.77157 0.23499,0.34517 0.74124,0.56852 0.28929,0.12177 1.69945,0.56853 2.04302,0.60913 2.85659,0.9949 0.81356,0.3858 1.26557,1.13705 0.47003,0.75127 0.47003,1.868 0,1.07614 -0.56043,2.05075 -0.5605,0.9543 -1.62718,1.48222 -1.06669,0.50761 -2.40458,0.50761 -2.22373,0 -3.3989,-1.03553 -1.15708,-1.03551 -1.48253,-3.06596 z"" /> <path style=""fill:#ffffff;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path174"" d=""m 365.91786,461.96011 74.05342,0 0,56.64507 -74.05342,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path176"" d=""m 365.91786,461.96011 74.05342,0 0,56.64507 -74.05342,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path178"" d=""m 377.94071,499.27506 0,-17.66482 2.07914,0 0,15.57346 7.75608,0 0,2.09136 -9.83522,0 z m 11.11967,-6.39589 q 0,-3.55326 1.77179,-5.27914 1.46443,-1.42131 3.57973,-1.42131 2.35033,0 3.83284,1.74617 1.50059,1.72589 1.50059,4.77154 0,2.47714 -0.66893,3.89845 -0.65086,1.40099 -1.91642,2.19286 -1.24749,0.77158 -2.74808,0.77158 -2.38649,0 -3.869,-1.72589 -1.48252,-1.72586 -1.48252,-4.95426 z m 1.98875,0 q 0,2.45683 0.9582,3.6751 0.95822,1.21826 2.40457,1.21826 1.44635,0 2.38649,-1.21826 0.95821,-1.23858 0.95821,-3.75632 0,-2.37561 -0.95821,-3.59387 -0.95822,-1.21826 -2.38649,-1.21826 -1.44635,0 -2.40457,1.21826 -0.9582,1.21826 -0.9582,3.67509 z m 10.39651,7.45171 1.86219,0.32487 q 0.12656,0.97461 0.66894,1.42131 0.7051,0.58882 1.95258,0.58882 1.35596,0 2.07914,-0.60914 0.72318,-0.58882 0.99436,-1.66495 0.14464,-0.67004 0.12656,-2.80201 -1.26556,1.68528 -3.14582,1.68528 -2.35033,0 -3.65205,-1.90862 -1.28364,-1.90861 -1.28364,-4.56849 0,-1.8274 0.59663,-3.37053 0.59661,-1.56343 1.71753,-2.39591 1.12093,-0.85279 2.62153,-0.85279 2.0249,0 3.32662,1.82739 l 0,-1.54313 1.78986,0 0,11.06589 q 0,3.00505 -0.54238,4.24361 -0.54239,1.25888 -1.71755,1.96954 -1.17517,0.73095 -2.89271,0.73095 -2.04298,0 -3.30854,-1.03553 -1.24748,-1.03551 -1.19325,-3.10656 z m 1.59099,-7.69536 q 0,2.53805 0.8859,3.69539 0.90398,1.15735 2.24186,1.15735 1.31979,0 2.22376,-1.15735 0.90398,-1.15734 0.90398,-3.61418 0,-2.35531 -0.94013,-3.53296 -0.92205,-1.19795 -2.22377,-1.19795 -1.28365,0 -2.18762,1.17765 -0.90398,1.15734 -0.90398,3.47205 z m 9.98068,2.82231 1.91642,-0.34519 q 0.16271,1.29949 0.88589,1.98984 0.74127,0.67005 2.06106,0.67005 1.33788,0 1.97066,-0.60913 0.65087,-0.60913 0.65087,-1.42131 0,-0.73095 -0.56047,-1.15736 -0.39775,-0.28425 -1.97066,-0.73096 -2.13338,-0.60912 -2.96503,-1.03551 -0.81358,-0.44669 -1.24749,-1.21827 -0.41582,-0.79187 -0.41582,-1.72587 0,-0.85279 0.34351,-1.58374 0.36158,-0.73096 0.95821,-1.21826 0.45198,-0.36549 1.2294,-0.62943 0.77742,-0.26397 1.66331,-0.26397 1.35596,0 2.36841,0.44669 1.01245,0.42641 1.48251,1.17766 0.48815,0.73096 0.66895,1.96953 l -1.88026,0.28426 q -0.12657,-0.97461 -0.75934,-1.52283 -0.6147,-0.56853 -1.73563,-0.56853 -1.33788,0 -1.89835,0.50762 -0.56046,0.4873 -0.56046,1.13705 0,0.42639 0.23503,0.77156 0.23504,0.34517 0.74127,0.56853 0.28926,0.12176 1.69946,0.56852 2.04298,0.60913 2.85655,0.99491 0.81358,0.38579 1.26556,1.13704 0.47007,0.75127 0.47007,1.86801 0,1.07614 -0.56047,2.05074 -0.56045,0.95431 -1.62715,1.48222 -1.06668,0.50762 -2.40456,0.50762 -2.22377,0 -3.39893,-1.03553 -1.15709,-1.03553 -1.48252,-3.06596 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path180"" d=""m 971.31638,64.679308 231.38032,0 0,245.366452 -231.38032,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path182"" d=""m 971.31638,64.679308 231.38032,0 0,245.366452 -231.38032,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path184"" d=""m 991.00786,94.197087 231.38044,0 0,245.366423 -231.38044,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path186"" d=""m 991.00786,94.197087 231.38044,0 0,245.366423 -231.38044,0 z"" /> <path style=""fill:#cfe2f3;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path188"" d=""m 1010.6993,123.71488 231.3804,0 0,245.36647 -231.3804,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path190"" d=""m 1010.6993,123.71488 231.3804,0 0,245.36647 -231.3804,0 z"" /> <path style=""fill:#ffd966;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path192"" d=""m 1033.7985,148.879 188.5958,0 0,182.17282 -188.5958,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path194"" d=""m 1033.7985,148.879 188.5958,0 0,182.17282 -188.5958,0 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path196"" d=""m 1047.684,251.25285 160.8256,0 0,38.88209 -160.8256,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path198"" d=""m 1047.684,251.25285 160.8256,0 0,38.88209 -160.8256,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path200"" d=""m 1101.834,279.6863 0,-17.66481 2.0973,0 0,7.24866 8.1719,0 0,-7.24866 2.0791,0 0,17.66481 -2.0791,0 0,-8.32479 -8.1719,0 0,8.32479 -2.0973,0 z m 23.0923,-4.1218 1.9888,0.28427 q -0.4701,1.94922 -1.7537,3.04566 -1.2655,1.07613 -3.2542,1.07613 -2.4951,0 -3.9595,-1.72588 -1.4644,-1.72586 -1.4644,-4.85274 0,-3.2284 1.4644,-5.01519 1.4825,-1.78678 3.8509,-1.78678 2.2961,0 3.7425,1.74617 1.4463,1.74619 1.4463,4.93397 0,0.18274 -0.019,0.56853 l -8.4974,0 q 0.1087,2.11165 1.0667,3.22839 0.9582,1.11675 2.3865,1.11675 1.0485,0 1.7899,-0.60914 0.7592,-0.62944 1.2112,-2.01014 z m -6.3457,-3.51265 6.3639,0 q -0.1266,-1.60405 -0.7232,-2.41623 -0.922,-1.25887 -2.4046,-1.25887 -1.3198,0 -2.2419,1.01522 -0.9039,0.99492 -0.9942,2.65988 z m 10.5591,7.63445 0,-17.66481 1.9346,0 0,10.07097 4.574,-5.21823 2.4949,0 -4.3571,4.75123 4.7911,8.06084 -2.3865,0 -3.7605,-6.53801 -1.3559,1.46191 0,5.0761 -1.9346,0 z m 18.2241,-1.58374 q -1.0847,1.03552 -2.0792,1.46192 -0.9943,0.40608 -2.1333,0.40608 -1.8621,0 -2.8746,-1.01522 -1.0125,-1.03553 -1.0125,-2.63957 0,-0.95431 0.3797,-1.72587 0.3796,-0.77157 0.9944,-1.23857 0.6146,-0.467 1.392,-0.71066 0.5786,-0.18273 1.7176,-0.32487 2.3503,-0.32487 3.4533,-0.75125 0,-0.44669 0,-0.56852 0,-1.3198 -0.5425,-1.86801 -0.7412,-0.73095 -2.2056,-0.73095 -1.356,0 -2.0069,0.52791 -0.6509,0.52792 -0.9582,1.90861 l -1.8984,-0.30457 q 0.2712,-1.36039 0.8498,-2.19288 0.5966,-0.83247 1.6995,-1.27916 1.1208,-0.46701 2.6034,-0.46701 1.4644,0 2.3684,0.38579 0.904,0.38578 1.3379,0.97461 0.4339,0.58882 0.5966,1.48221 0.1087,0.54823 0.1087,1.98984 l 0,2.90352 q 0,3.02535 0.1088,3.83752 0.1266,0.79188 0.5062,1.52284 l -2.0248,0 q -0.3074,-0.67005 -0.3797,-1.58374 z m -0.1626,-4.83245 q -1.0488,0.467 -3.164,0.81218 -1.1933,0.18274 -1.6814,0.42639 -0.4881,0.24365 -0.7593,0.71066 -0.2713,0.467 -0.2713,1.03551 0,0.8731 0.5786,1.46192 0.5967,0.56852 1.7176,0.56852 1.1209,0 1.9887,-0.54821 0.8678,-0.56852 1.2836,-1.50253 0.3075,-0.75127 0.3075,-2.17257 l 0,-0.79187 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path202"" d=""m 1082.9614,167.92801 90.2709,0 0,38.88209 -90.2709,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path204"" d=""m 1082.9614,167.92801 90.2709,0 0,38.88209 -90.2709,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path206"" d=""m 1106.9793,196.36147 0,-17.6648 2.0791,0 0,15.57345 7.7561,0 0,2.09135 -9.8352,0 z m 11.1195,-6.39588 q 0,-3.55326 1.7719,-5.27914 1.4644,-1.4213 3.5797,-1.4213 2.3503,0 3.8328,1.74617 1.5006,1.72588 1.5006,4.77154 0,2.47713 -0.6689,3.89843 -0.6509,1.401 -1.9165,2.19288 -1.2474,0.77157 -2.748,0.77157 -2.3865,0 -3.869,-1.72588 -1.4826,-1.72587 -1.4826,-4.95427 z m 1.9888,0 q 0,2.45684 0.9582,3.6751 0.9582,1.21826 2.4046,1.21826 1.4463,0 2.3865,-1.21826 0.9583,-1.23858 0.9583,-3.75632 0,-2.3756 -0.9583,-3.59387 -0.9583,-1.21826 -2.3865,-1.21826 -1.4464,0 -2.4046,1.21826 -0.9582,1.21827 -0.9582,3.67509 z m 10.3965,7.45171 1.8623,0.32487 q 0.1265,0.97461 0.6689,1.42131 0.7051,0.58882 1.9526,0.58882 1.3559,0 2.0791,-0.60913 0.7232,-0.58882 0.9944,-1.66496 0.1447,-0.67003 0.1265,-2.802 -1.2655,1.68526 -3.1458,1.68526 -2.3503,0 -3.6521,-1.90861 -1.2835,-1.9086 -1.2835,-4.56849 0,-1.82739 0.5966,-3.37052 0.5966,-1.56344 1.7176,-2.39592 1.1208,-0.85278 2.6214,-0.85278 2.0249,0 3.3266,1.82739 l 0,-1.54313 1.7899,0 0,11.06589 q 0,3.00505 -0.5424,4.24361 -0.5423,1.25887 -1.7176,1.96953 -1.1751,0.73096 -2.8927,0.73096 -2.0429,0 -3.3085,-1.03553 -1.2475,-1.03552 -1.1933,-3.10657 z m 1.5911,-7.69537 q 0,2.53806 0.8858,3.69541 0.9041,1.15735 2.2418,1.15735 1.32,0 2.2239,-1.15735 0.904,-1.15735 0.904,-3.61419 0,-2.3553 -0.9401,-3.53296 -0.9221,-1.19795 -2.2239,-1.19795 -1.2836,0 -2.1875,1.17765 -0.904,1.15735 -0.904,3.47204 z m 9.9806,2.82233 1.9164,-0.34519 q 0.1627,1.29948 0.8858,1.98983 0.7414,0.67005 2.0611,0.67005 1.3379,0 1.9707,-0.60913 0.6508,-0.60913 0.6508,-1.4213 0,-0.73097 -0.5605,-1.15736 -0.3976,-0.28427 -1.9706,-0.73096 -2.1333,-0.60913 -2.965,-1.03551 -0.8136,-0.44671 -1.2475,-1.21827 -0.4158,-0.79188 -0.4158,-1.72588 0,-0.85278 0.3435,-1.58374 0.3616,-0.73095 0.9582,-1.21827 0.452,-0.36547 1.2294,-0.62942 0.7775,-0.26396 1.6633,-0.26396 1.356,0 2.3685,0.44669 1.0124,0.4264 1.4824,1.17766 0.4882,0.73095 0.669,1.96953 l -1.8802,0.28426 q -0.1266,-0.97461 -0.7594,-1.52284 -0.6147,-0.56852 -1.7357,-0.56852 -1.3378,0 -1.8983,0.50762 -0.5605,0.4873 -0.5605,1.13704 0,0.42638 0.2351,0.77157 0.2351,0.34517 0.7413,0.56852 0.2892,0.12176 1.6994,0.56852 2.0429,0.60913 2.8566,0.99491 0.8136,0.38579 1.2655,1.13705 0.4702,0.75127 0.4702,1.868 0,1.07613 -0.5605,2.05075 -0.5605,0.95429 -1.6273,1.48221 -1.0665,0.50762 -2.4045,0.50762 -2.2238,0 -3.3989,-1.03554 -1.1571,-1.03551 -1.4825,-3.06594 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path208"" d=""m 1002.5577,10.100597 188.5956,0 0,56.645065 -188.5956,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path210"" d=""m 1025.8983,38.88977 2.0791,0.588828 q -0.6508,2.883221 -2.3503,4.406047 -1.6995,1.50253 -4.1582,1.50253 -2.5493,0 -4.1403,-1.157353 -1.591,-1.177658 -2.4226,-3.370524 -0.8317,-2.21318 -0.8317,-4.751232 0,-2.761391 0.9221,-4.812139 0.9401,-2.05074 2.6757,-3.106567 1.7356,-1.076132 3.8148,-1.076132 2.3684,0 3.9775,1.360394 1.609,1.340089 2.2419,3.776616 l -2.043,0.548219 q -0.5424,-1.928919 -1.591,-2.802009 -1.0486,-0.893387 -2.6216,-0.893387 -1.8079,0 -3.0374,0.974607 -1.2112,0.974607 -1.7175,2.639569 -0.4882,1.644656 -0.4882,3.390829 0,2.25379 0.5786,3.939056 0.5966,1.664953 1.826,2.497434 1.2475,0.83248 2.6758,0.83248 1.7537,0 2.9651,-1.116742 1.2113,-1.137039 1.6452,-3.370524 z m 3.3856,-0.203042 q 0,-3.55327 1.7719,-5.279138 1.4644,-1.421309 3.5797,-1.421309 2.3503,0 3.8328,1.746173 1.5006,1.725876 1.5006,4.771529 0,2.477137 -0.6689,3.898446 -0.6509,1.400996 -1.9164,2.192875 -1.2475,0.771566 -2.7481,0.771566 -2.3865,0 -3.869,-1.725877 -1.4826,-1.725868 -1.4826,-4.954265 z m 1.9888,0 q 0,2.456824 0.9582,3.675091 0.9582,1.218259 2.4046,1.218259 1.4463,0 2.3865,-1.218259 0.9582,-1.238564 0.9582,-3.756311 0,-2.375612 -0.9582,-3.593871 -0.9583,-1.218268 -2.3865,-1.218268 -1.4464,0 -2.4046,1.218268 -0.9582,1.218259 -0.9582,3.675091 z m 10.74,6.39588 0,-12.812065 1.7357,0 0,1.807088 q 0.5243,-0.933997 1.4101,-1.502521 0.904,-0.588829 2.043,-0.588829 1.2656,0 2.0791,0.588829 0.8136,0.58882 1.1391,1.664953 1.3559,-2.253782 3.5255,-2.253782 1.6994,0 2.6034,1.055827 0.9221,1.055828 0.9221,3.248703 l 0,8.791797 -1.9346,0 0,-8.060841 q 0,-1.29948 -0.1807,-1.868004 -0.1808,-0.588828 -0.6871,-0.934005 -0.4881,-0.345169 -1.1571,-0.345169 -1.1932,0 -1.9887,0.893388 -0.7955,0.893395 -0.7955,2.883228 l 0,7.431403 -1.9345,0 0,-8.324798 q 0,-1.441615 -0.4701,-2.152265 -0.47,-0.730956 -1.5548,-0.730956 -0.8136,0 -1.5187,0.487304 -0.687,0.466999 -0.9943,1.401004 -0.3074,0.933998 -0.3074,2.680179 l 0,6.639532 -1.9345,0 z m 17.9821,4.913656 0,-17.725721 1.7717,0 0,1.664961 q 0.6148,-0.974616 1.3922,-1.461919 0.7955,-0.487304 1.8983,-0.487304 1.4645,0 2.5854,0.852786 1.1209,0.83248 1.6814,2.375611 0.5785,1.543132 0.5785,3.370525 0,1.969528 -0.6328,3.553269 -0.6327,1.563436 -1.826,2.395917 -1.1932,0.832481 -2.5131,0.832481 -0.9762,0 -1.7536,-0.446702 -0.7594,-0.466999 -1.2475,-1.157345 l 0,6.233441 -1.9345,0 z m 1.7537,-11.248629 q 0,2.477137 0.8859,3.654794 0.904,1.177649 2.1695,1.177649 1.2836,0 2.1876,-1.218259 0.9221,-1.218267 0.9221,-3.796921 0,-2.436527 -0.904,-3.654786 -0.8859,-1.218268 -2.1333,-1.218268 -1.2295,0 -2.1877,1.299488 -0.9401,1.299479 -0.9401,3.756303 z m 17.7187,6.334973 0,-1.888308 q -1.3199,2.17257 -3.616,2.17257 -0.9943,0 -1.8802,-0.426397 -0.8678,-0.446694 -1.3017,-1.096438 -0.4159,-0.649735 -0.5967,-1.604046 -0.1084,-0.649735 -0.1084,-2.030435 l 0,-7.939011 1.9345,0 0,7.10653 q 0,1.705572 0.1085,2.294401 0.1807,0.852777 0.7774,1.34008 0.5966,0.487312 1.4644,0.487312 0.8678,0 1.6271,-0.487312 0.7594,-0.507608 1.0667,-1.360385 0.3255,-0.873091 0.3255,-2.517747 l 0,-6.862879 1.9345,0 0,12.812065 -1.7356,0 z m 8.7693,-1.949223 0.2712,1.928918 q -0.8136,0.182737 -1.4645,0.182737 -1.0486,0 -1.6271,-0.365482 -0.5786,-0.385779 -0.8135,-0.974608 -0.2351,-0.609134 -0.2351,-2.578653 l 0,-7.350191 -1.4283,0 0,-1.705563 1.4283,0 0,-3.167482 1.9164,-1.29948 0,4.466962 1.9526,0 0,1.705563 -1.9526,0 0,7.472012 q 0,0.934006 0.09,1.197963 0.1084,0.263957 0.3435,0.426388 0.235,0.162441 0.6689,0.162441 0.3074,0 0.8497,-0.101534 z m 9.5772,-2.17257 1.9888,0.284262 q -0.4701,1.949223 -1.7537,3.04566 -1.2656,1.076133 -3.2543,1.076133 -2.495,0 -3.9594,-1.725877 -1.4645,-1.725868 -1.4645,-4.852748 0,-3.228398 1.4645,-5.015181 1.4825,-1.786783 3.8509,-1.786783 2.2961,0 3.7424,1.746173 1.4464,1.746181 1.4464,4.933969 0,0.182737 -0.018,0.568524 l -8.4974,0 q 0.1085,2.111655 1.0667,3.228397 0.9582,1.116734 2.3865,1.116734 1.0486,0 1.7899,-0.609125 0.7593,-0.629439 1.2113,-2.010138 z m -6.3458,-3.51266 6.3639,0 q -0.1265,-1.604046 -0.7232,-2.416222 -0.922,-1.258869 -2.4045,-1.258869 -1.3198,0 -2.2419,1.015218 -0.9039,0.99492 -0.9943,2.659873 z m 16.5386,7.634453 0,-12.812065 1.7356,0 0,1.827393 q 1.2656,-2.111655 3.634,-2.111655 1.0306,0 1.8984,0.426389 0.8678,0.406092 1.2836,1.096437 0.4339,0.670049 0.6147,1.583741 0.1088,0.609134 0.1088,2.111655 l 0,7.878105 -1.9344,0 0,-7.796885 q 0,-1.319784 -0.2351,-1.969528 -0.217,-0.67004 -0.7955,-1.055827 -0.5786,-0.385779 -1.3559,-0.385779 -1.2295,0 -2.1334,0.873091 -0.886,0.873082 -0.886,3.350219 l 0,6.984709 -1.9344,0 z m 11.2824,-6.39588 q 0,-3.55327 1.7719,-5.279138 1.4644,-1.421309 3.5796,-1.421309 2.3504,0 3.8329,1.746173 1.5006,1.725876 1.5006,4.771529 0,2.477137 -0.6689,3.898446 -0.6509,1.400996 -1.9165,2.192875 -1.2475,0.771566 -2.7481,0.771566 -2.3865,0 -3.8689,-1.725877 -1.4826,-1.725868 -1.4826,-4.954265 z m 1.9888,0 q 0,2.456824 0.9582,3.675091 0.9582,1.218259 2.4045,1.218259 1.4464,0 2.3865,-1.218259 0.9583,-1.238564 0.9583,-3.756311 0,-2.375612 -0.9583,-3.593871 -0.9582,-1.218268 -2.3865,-1.218268 -1.4463,0 -2.4045,1.218268 -0.9582,1.218259 -0.9582,3.675091 z m 18.1345,6.39588 0,-1.624352 q -1.0848,1.908614 -3.182,1.908614 -1.3559,0 -2.513,-0.832481 -1.139,-0.852786 -1.7717,-2.355307 -0.6148,-1.522834 -0.6148,-3.492354 0,-1.908613 0.5605,-3.47205 0.5785,-1.563436 1.6994,-2.395916 1.139,-0.832481 2.5493,-0.832481 1.0305,0 1.826,0.487304 0.8135,0.487303 1.3197,1.279174 l 0,-6.334965 1.9164,0 0,17.664814 -1.7898,0 z m -6.1109,-6.39588 q 0,2.456824 0.9221,3.675091 0.9401,1.218259 2.1876,1.218259 1.2656,0 2.1514,-1.157344 0.8859,-1.157352 0.8859,-3.553269 0,-2.619264 -0.9039,-3.837532 -0.904,-1.238564 -2.2238,-1.238564 -1.2837,0 -2.1515,1.177658 -0.8678,1.177649 -0.8678,3.715701 z m 18.5322,2.274087 1.9888,0.284262 q -0.4701,1.949223 -1.7536,3.04566 -1.2657,1.076133 -3.2543,1.076133 -2.4951,0 -3.9595,-1.725877 -1.4644,-1.725868 -1.4644,-4.852748 0,-3.228398 1.4644,-5.015181 1.4825,-1.786783 3.8509,-1.786783 2.2961,0 3.7425,1.746173 1.4463,1.746181 1.4463,4.933969 0,0.182737 -0.019,0.568524 l -8.4974,0 q 0.1087,2.111655 1.0667,3.228397 0.9582,1.116734 2.3865,1.116734 1.0485,0 1.7899,-0.609125 0.7593,-0.629439 1.2112,-2.010138 z m -6.3458,-3.51266 6.364,0 q -0.1266,-1.604046 -0.7232,-2.416222 -0.9221,-1.258869 -2.4046,-1.258869 -1.3198,0 -2.2419,1.015218 -0.9039,0.99492 -0.9943,2.659873 z m 9.7637,3.817227 1.9164,-0.345177 q 0.1628,1.299479 0.886,1.989833 0.7412,0.67004 2.061,0.67004 1.3379,0 1.9706,-0.609125 0.6509,-0.609134 0.6509,-1.421309 0,-0.730956 -0.5604,-1.157353 -0.3978,-0.284262 -1.9708,-0.730956 -2.1333,-0.609133 -2.965,-1.035522 -0.8135,-0.446694 -1.2474,-1.218259 -0.4159,-0.791879 -0.4159,-1.725877 0,-0.852785 0.3436,-1.583741 0.3615,-0.730956 0.9581,-1.218259 0.4521,-0.365482 1.2294,-0.629439 0.7775,-0.263957 1.6633,-0.263957 1.356,0 2.3685,0.446694 1.0124,0.426397 1.4825,1.177657 0.4881,0.730956 0.6689,1.96952 l -1.8802,0.284262 q -0.1266,-0.974607 -0.7594,-1.522826 -0.6147,-0.568524 -1.7356,-0.568524 -1.3378,0 -1.8983,0.507609 -0.5605,0.487304 -0.5605,1.137047 0,0.426389 0.2351,0.771566 0.235,0.345177 0.7412,0.568524 0.2893,0.12183 1.6994,0.568523 2.0431,0.609134 2.8566,0.994913 0.8136,0.385787 1.2655,1.137047 0.4702,0.751261 0.4702,1.868004 0,1.076132 -0.5605,2.050739 -0.5605,0.954311 -1.6271,1.482225 -1.0667,0.507609 -2.4047,0.507609 -2.2236,0 -3.3989,-1.035523 -1.1571,-1.035531 -1.4825,-3.065965 z"" /> <path style=""fill:#f6b26b;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path212"" d=""m 1118.2661,230.6473 4.92,0 0,-8.90194 9.8397,0 0,8.90194 4.9199,0 -9.8398,8.90196 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path214"" d=""m 1118.2661,230.6473 4.92,0 0,-8.90194 9.8397,0 0,8.90194 4.9199,0 -9.8398,8.90196 z"" /> <path style=""fill:#000000;fill-opacity:0;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path216"" d=""M 1128.0967,290.13495 653.16364,721.23503"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path218"" d=""M 1128.0967,290.13495 658.56305,716.33397"" /> <path style=""fill:#000000;fill-rule:evenodd;stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt"" inkscape:connector-curvature=""0"" id=""path220"" d=""m 657.36169,714.66462 -2.88245,5.37622 5.28522,-2.03758 z"" /> <path style=""fill:#ffffff;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path222"" d=""m 861.71052,469.91217 74.05338,0 0,56.64507 -74.05338,0 z"" /> <path style=""stroke:#000000;stroke-width:1.22621727;stroke-linecap:butt;stroke-linejoin:round"" inkscape:connector-curvature=""0"" id=""path224"" d=""m 861.71052,469.91217 74.05338,0 0,56.64507 -74.05338,0 z"" /> <path style=""fill:#000000;fill-rule:nonzero"" inkscape:connector-curvature=""0"" id=""path226"" d=""m 873.73331,507.22711 0,-17.66482 2.07913,0 0,15.57347 7.7561,0 0,2.09135 -9.83523,0 z m 11.11968,-6.39588 q 0,-3.55327 1.77177,-5.27914 1.4644,-1.4213 3.57975,-1.4213 2.35029,0 3.83282,1.74617 1.50062,1.72587 1.50062,4.77152 0,2.47714 -0.66898,3.89845 -0.65084,1.401 -1.91641,2.19287 -1.24749,0.77157 -2.74805,0.77157 -2.3865,0 -3.86904,-1.72587 -1.48248,-1.72587 -1.48248,-4.95427 z m 1.98873,0 q 0,2.45682 0.95821,3.67509 0.95821,1.21826 2.40458,1.21826 1.44632,0 2.38645,-1.21826 0.9582,-1.23856 0.9582,-3.7563 0,-2.37562 -0.9582,-3.59389 -0.95821,-1.21826 -2.38645,-1.21826 -1.44637,0 -2.40458,1.21826 -0.95821,1.21827 -0.95821,3.6751 z m 10.39653,7.45171 1.86217,0.32486 q 0.12656,0.97462 0.66892,1.42131 0.70513,0.58884 1.95262,0.58884 1.35592,0 2.07913,-0.60914 0.72316,-0.58883 0.99437,-1.66496 0.14464,-0.67005 0.12656,-2.802 -1.26557,1.68526 -3.14582,1.68526 -2.35034,0 -3.65207,-1.90861 -1.28365,-1.90862 -1.28365,-4.56848 0,-1.8274 0.59665,-3.37054 0.5966,-1.56344 1.71753,-2.39591 1.12093,-0.85278 2.62154,-0.85278 2.02489,0 3.32657,1.82739 l 0,-1.54313 1.7899,0 0,11.06588 q 0,3.00505 -0.54241,4.24362 -0.54235,1.25887 -1.71752,1.96952 -1.17517,0.73096 -2.8927,0.73096 -2.04303,0 -3.30854,-1.03552 -1.24749,-1.03553 -1.19325,-3.10657 z m 1.59096,-7.69536 q 0,2.53804 0.88594,3.69539 0.90396,1.15735 2.2418,1.15735 1.31981,0 2.22378,-1.15735 0.90396,-1.15735 0.90396,-3.61417 0,-2.35531 -0.94012,-3.53297 -0.92205,-1.19796 -2.22378,-1.19796 -1.2836,0 -2.18761,1.17766 -0.90397,1.15735 -0.90397,3.47205 z m 9.98073,2.8223 1.91641,-0.34517 q 0.16272,1.29948 0.88588,1.98984 0.74124,0.67003 2.06106,0.67003 1.33789,0 1.97065,-0.60913 0.65089,-0.60913 0.65089,-1.42131 0,-0.73095 -0.56049,-1.15734 -0.39772,-0.28426 -1.97065,-0.73096 -2.13338,-0.60913 -2.96502,-1.03553 -0.81356,-0.44669 -1.24749,-1.21826 -0.41585,-0.79187 -0.41585,-1.72586 0,-0.85279 0.34353,-1.58375 0.3616,-0.73096 0.9582,-1.21826 0.45201,-0.36548 1.22941,-0.62944 0.77741,-0.26395 1.66334,-0.26395 1.35592,0 2.36837,0.44669 1.01244,0.42639 1.48253,1.17765 0.48812,0.73097 0.66892,1.96952 l -1.88025,0.28426 q -0.12656,-0.9746 -0.75932,-1.52281 -0.61473,-0.56853 -1.73566,-0.56853 -1.33784,0 -1.89833,0.5076 -0.56044,0.48731 -0.56044,1.13705 0,0.4264 0.23505,0.77157 0.23499,0.34518 0.74124,0.56852 0.28923,0.12176 1.69945,0.56852 2.04297,0.60913 2.85653,0.99492 0.81362,0.38578 1.26557,1.13705 0.47009,0.75125 0.47009,1.86801 0,1.07612 -0.56049,2.05073 -0.56044,0.95431 -1.62712,1.48222 -1.06669,0.50761 -2.40458,0.50761 -2.22378,0 -3.39895,-1.03552 -1.15709,-1.03553 -1.48248,-3.06597 z"" /> </svg> ",1,943
openstack%2Ftripleo-quickstart~master~I5ca23e9061c6e48768ba99766f83f2652e1e84af,openstack/tripleo-quickstart,master,I5ca23e9061c6e48768ba99766f83f2652e1e84af,Adds a Bashate target to tox.ini.,MERGED,2017-02-06 13:35:13.000000000,2017-02-28 15:51:02.000000000,2017-02-28 15:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 11491}, {'_account_id': 11589}, {'_account_id': 12715}, {'_account_id': 18846}]","[{'number': 1, 'created': '2017-02-06 13:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3d39c3fb4912f63c19c1418bc194f03ec829e5db', 'message': 'Adds a Bashate target to tox.ini.\n\nThis will now run bashate on all shell scripts. We could ignore the\nfollowing list of bashate errors:\n\n- E006: Line longer than 79 columns (as many scripts use jinja\n        templating, this is very difficult)\n- E040: Syntax error determined using `bash -n` (as many scripts\n        use jinja templating, this will often fail and the syntax\n        error will be discovered in execution anyway)\n\nChange-Id: I5ca23e9061c6e48768ba99766f83f2652e1e84af\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2017-02-09 09:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/dd4049871aa813c4008ac5fecddea61864fbc164', 'message': 'Adds a Bashate target to tox.ini.\n\nThis will now run bashate on all shell scripts. We could ignore the\nfollowing list of bashate errors:\n\n- E006: Line longer than 79 columns (as many scripts use jinja\n        templating, this is very difficult)\n- E040: Syntax error determined using `bash -n` (as many scripts\n        use jinja templating, this will often fail and the syntax\n        error will be discovered in execution anyway)\n\nChange-Id: I5ca23e9061c6e48768ba99766f83f2652e1e84af\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 3, 'created': '2017-02-20 13:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2280ad54f62d018537c55d3ce61837dcddbac557', 'message': 'Adds a Bashate target to tox.ini.\n\nThis will now run bashate on all shell scripts. We could ignore the\nfollowing list of bashate errors:\n\n- E006: Line longer than 79 columns (as many scripts use jinja\n        templating, this is very difficult)\n- E040: Syntax error determined using `bash -n` (as many scripts\n        use jinja templating, this will often fail and the syntax\n        error will be discovered in execution anyway)\n\nChange-Id: I5ca23e9061c6e48768ba99766f83f2652e1e84af\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 4, 'created': '2017-02-23 17:01:06.000000000', 'files': ['ci-scripts/ooo-usbkey.sh', 'ci-scripts/releasenotes_tox.sh', 'test-requirements.txt', 'ci-scripts/collect-logs.sh', 'ci-scripts/get-node.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/19b29880b6aa751ca6b9299f6e60df5e767990ef', 'message': 'Adds a Bashate target to tox.ini.\n\nThis will now run bashate on all shell scripts. We could ignore the\nfollowing list of bashate errors:\n\n- E006: Line longer than 79 columns (as many scripts use jinja\n        templating, this is very difficult)\n- E040: Syntax error determined using `bash -n` (as many scripts\n        use jinja templating, this will often fail and the syntax\n        error will be discovered in execution anyway)\n\nChange-Id: I5ca23e9061c6e48768ba99766f83f2652e1e84af\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}]",0,429703,19b29880b6aa751ca6b9299f6e60df5e767990ef,36,9,4,11491,,,0,"Adds a Bashate target to tox.ini.

This will now run bashate on all shell scripts. We could ignore the
following list of bashate errors:

- E006: Line longer than 79 columns (as many scripts use jinja
        templating, this is very difficult)
- E040: Syntax error determined using `bash -n` (as many scripts
        use jinja templating, this will often fail and the syntax
        error will be discovered in execution anyway)

Change-Id: I5ca23e9061c6e48768ba99766f83f2652e1e84af
Signed-off-by: Gael Chamoulaud <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/03/429703/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci-scripts/ooo-usbkey.sh', 'ci-scripts/releasenotes_tox.sh', 'test-requirements.txt', 'ci-scripts/get-node.sh', 'tox.ini']",5,3d39c3fb4912f63c19c1418bc194f03ec829e5db,fix_flake8_testing,"[testenv:bashate] commands = # Run bashate check for all bash scripts # Ignores the following rules: # E006: Line longer than 79 columns (as many scripts use jinja # templating, this is very difficult) # E040: Syntax error determined using `bash -n` (as many scripts # use jinja templating, this will often fail and the syntax # error will be discovered in execution anyway) bash -c ""grep --recursive --binary-files=without-match \ --files-with-match '^.!.*\(ba\)\?sh$' \ --exclude-dir .tox \ --exclude-dir .git \ {toxinidir} | xargs bashate --error . --verbose --ignore=E006,E040"" {[testenv:bashate]commands}",,37,20
openstack%2Fironic-ui~stable%2Focata~I6f698ca46e466e1dc84c570f6a2917c7c2cb8c99,openstack/ironic-ui,stable/ocata,I6f698ca46e466e1dc84c570f6a2917c7c2cb8c99,Imported Translations from Zanata,MERGED,2017-02-21 09:29:18.000000000,2017-02-28 15:50:16.000000000,2017-02-28 15:50:16.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-21 09:29:18.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'ironic_ui/locale/id/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'ironic_ui/locale/zh_CN/LC_MESSAGES/djangojs.po', 'ironic_ui/locale/ja/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'ironic_ui/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/0d7fbcdfc14310655f74f4de4f6435d3c1e22f24', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I6f698ca46e466e1dc84c570f6a2917c7c2cb8c99\n'}]",0,436382,0d7fbcdfc14310655f74f4de4f6435d3c1e22f24,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I6f698ca46e466e1dc84c570f6a2917c7c2cb8c99
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/82/436382/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'ironic_ui/locale/id/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'ironic_ui/locale/zh_CN/LC_MESSAGES/djangojs.po', 'ironic_ui/locale/ja/LC_MESSAGES/djangojs.po', 'ironic_ui/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po']",11,0d7fbcdfc14310655f74f4de4f6435d3c1e22f24,zanata/translations,,"# sunanchen <KF.sunanchen@h3c.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: ironic-ui 2.0.0\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2016-08-19 12:56+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-08-23 03:16+0000\n"" ""Last-Translator: sunanchen <KF.sunanchen@h3c.com>\n"" ""Language-Team: Chinese (China)\n"" ""Language: zh-CN\n"" ""X-Generator: Zanata 3.7.3\n"" ""Plural-Forms: nplurals=1; plural=0\n"" msgid ""2.0.0"" msgstr ""2.0.0"" msgid ""Add and delete nodes"" msgstr """" msgid ""Add and delete ports"" msgstr """" msgid ""Breadcrumbs have been added"" msgstr """" msgid ""Current Series Release Notes"" msgstr """" msgid """" ""Currently it is not possible to edit a node via the UI once it has been "" ""enrolled. Therefore, the enrollment must be done accurately to ensure the "" ""node is enrolled accurately and can then be made available. At present, any "" ""errors made during enrollment can only be corrected by deleting the node and "" ""enrolling it again."" msgstr """" ""UI"" """" """" msgid ""Ironic UI Release Notes"" msgstr ""Ironic UI"" msgid ""Known Issues"" msgstr """" msgid ""New Features"" msgstr """" msgid ""Newton Series Release Notes"" msgstr ""Newton"" msgid ""Panel hidden if baremetal service or admin rights are not present"" msgstr ""baremetal serviceadmin"" msgid """" ""This release adds support for adding and deleting nodes. Support has also "" ""been added for adding and deleting ports. The panel will now be hidden if "" ""the baremetal service is not present in the scenario where the collection of "" ""running services differs between multiple keystone regions."" msgstr """" ""keystone "" ""regionsbaremetal service"" msgid ""UX improvements across the interface"" msgstr ""UX "" ",310,692
openstack%2Ftrove~stable%2Fmitaka~Id6a5135c61e65884b3fb56410053e2ebc108da13,openstack/trove,stable/mitaka,Id6a5135c61e65884b3fb56410053e2ebc108da13,"test review, stable/mitaka",ABANDONED,2017-01-25 20:47:31.000000000,2017-02-28 15:49:47.000000000,,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 12208}]","[{'number': 1, 'created': '2017-01-25 20:47:31.000000000', 'files': ['brian-was-here'], 'web_link': 'https://opendev.org/openstack/trove/commit/37a6eeec5cb6acc449b04e85ff4cb961b332a4f7', 'message': 'test review, stable/mitaka\n\nDO NOT MERGE\nThis is simply to see the current state of how stable/mitaka is tested.\n\nChange-Id: Id6a5135c61e65884b3fb56410053e2ebc108da13\n'}]",0,425405,37a6eeec5cb6acc449b04e85ff4cb961b332a4f7,5,3,1,12208,,,0,"test review, stable/mitaka

DO NOT MERGE
This is simply to see the current state of how stable/mitaka is tested.

Change-Id: Id6a5135c61e65884b3fb56410053e2ebc108da13
",git fetch https://review.opendev.org/openstack/trove refs/changes/05/425405/1 && git format-patch -1 --stdout FETCH_HEAD,['brian-was-here'],1,37a6eeec5cb6acc449b04e85ff4cb961b332a4f7,,,,0,0
openstack%2Fdesignate~master~Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b,openstack/designate,master,Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b,Updated from global requirements,MERGED,2017-02-27 01:09:40.000000000,2017-02-28 15:48:53.000000000,2017-02-28 15:48:53.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 25033}]","[{'number': 1, 'created': '2017-02-27 01:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e60b46f42218d9ac120764687cae33253f5f7d30', 'message': 'Updated from global requirements\n\nChange-Id: Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b\n'}, {'number': 2, 'created': '2017-02-28 05:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/9dbdf32702c2ad2102efb9118c19fffc968bd2f0', 'message': 'Updated from global requirements\n\nChange-Id: Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b\n'}, {'number': 3, 'created': '2017-02-28 13:56:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/e34cb197dde325c9c0fccdc31f9008c43f34e50f', 'message': 'Updated from global requirements\n\nChange-Id: Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b\n'}]",0,438305,e34cb197dde325c9c0fccdc31f9008c43f34e50f,13,3,3,11131,,,0,"Updated from global requirements

Change-Id: Iecc6a6cddd1a37bdccf31fccb5bf1e2d9af2c06b
",git fetch https://review.opendev.org/openstack/designate refs/changes/05/438305/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e60b46f42218d9ac120764687cae33253f5f7d30,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fkolla~stable%2Fnewton~Ia1f198cd14254571adb4a93e521fdfd2ade2947f,openstack/kolla,stable/newton,Ia1f198cd14254571adb4a93e521fdfd2ade2947f,Bump nova release to 14.0.4 tag,MERGED,2017-02-28 10:44:19.000000000,2017-02-28 15:41:59.000000000,2017-02-28 15:41:59.000000000,"[{'_account_id': 3}, {'_account_id': 16620}, {'_account_id': 19316}, {'_account_id': 23717}]","[{'number': 1, 'created': '2017-02-28 10:44:19.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/193aca9854219838d32df09983c3133e529e3c69', 'message': 'Bump nova release to 14.0.4 tag\n\nChange-Id: Ia1f198cd14254571adb4a93e521fdfd2ade2947f\n'}]",0,438903,193aca9854219838d32df09983c3133e529e3c69,8,4,1,7488,,,0,"Bump nova release to 14.0.4 tag

Change-Id: Ia1f198cd14254571adb4a93e521fdfd2ade2947f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/03/438903/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,193aca9854219838d32df09983c3133e529e3c69,," 'nova-14.0.4.tar.gz')},"," 'nova-14.0.3.tar.gz')},",1,1
openstack%2Ftempest~master~I11aa85f70e55b34bded4ac7452afbe0bf464d4c4,openstack/tempest,master,I11aa85f70e55b34bded4ac7452afbe0bf464d4c4,Verify root/swap/ephemeral disk sizes,ABANDONED,2016-07-06 17:18:02.000000000,2017-02-28 15:40:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5196}, {'_account_id': 6873}, {'_account_id': 7350}, {'_account_id': 9732}, {'_account_id': 10224}, {'_account_id': 10385}, {'_account_id': 16907}]","[{'number': 1, 'created': '2016-07-06 17:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/94a6c53ab57123735907e3771248919ff1d56ed6', 'message': 'WIP - verify root/swap/ephemeral disk sizes\n\nChange-Id: I11aa85f70e55b34bded4ac7452afbe0bf464d4c4\n'}, {'number': 2, 'created': '2016-07-06 19:59:24.000000000', 'files': ['tempest/scenario/test_server_disks.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f5dfd4acbb51da9d31df43035b0ef7f547a007fd', 'message': ""Verify root/swap/ephemeral disk sizes\n\nAdd a tempest test scenario that verifies the swap, root, and ephemeral\ndisk sizes before and after resizing an instance.\n\nThis test also demonstrates that ephemeral disk resizing is currently\nbroken. The ephemeral disk should have been 2GB after the resize, but\nit's still 1GB post-resize.\n\nChange-Id: I11aa85f70e55b34bded4ac7452afbe0bf464d4c4\n""}]",0,338411,f5dfd4acbb51da9d31df43035b0ef7f547a007fd,23,9,2,16907,,,0,"Verify root/swap/ephemeral disk sizes

Add a tempest test scenario that verifies the swap, root, and ephemeral
disk sizes before and after resizing an instance.

This test also demonstrates that ephemeral disk resizing is currently
broken. The ephemeral disk should have been 2GB after the resize, but
it's still 1GB post-resize.

Change-Id: I11aa85f70e55b34bded4ac7452afbe0bf464d4c4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/338411/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_server_disks.py'],1,94a6c53ab57123735907e3771248919ff1d56ed6,,"# Copyright 2016 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from oslo_utils import units import testtools from tempest.common.utils import data_utils from tempest.common import waiters from tempest import config from tempest.scenario import manager from tempest import test CONF = config.CONF LOG = logging.getLogger(__name__) class TestServerDisks(manager.ScenarioTest): """"""This test case attempts to reproduce the following steps: * Create two flavors: flavor-1 & flavor-2 * Launch an instance with flavor-1 * Verify disk sizes (before resize) * Resize instance to flavor-2 * Confirm instance resize * Verify disk sizes (after resize) * Terminate the instance * Delete the new flavors """""" credentials = ['primary', 'admin'] def _assert_disk_sizes(self, ssh_client, expected, when): for device in expected: disk_type, disk_size = expected[device] cmd = 'cat /sys/block/%s/size' % device size = int(ssh_client.exec_command(cmd).strip()) msg = '%s disk %s resize (512-byte blocks)' % (disk_type, when) self.assertEqual(size, disk_size / 512, msg) def _create_flavor(self, name, root, swap, ephemeral): flavor = self.admin_manager.flavors_client.create_flavor( name=data_utils.rand_name(name), vcpus=1, ram=64, disk=root, swap=swap, ephemeral=ephemeral, )['flavor'] self.addCleanup(self._cleanup_flavor, flavor['id']) return flavor def _cleanup_flavor(self, flavor_id): self.admin_manager.flavors_client.delete_flavor(flavor_id) self.admin_manager.flavors_client.wait_for_resource_deletion(flavor_id) def _wait_for_status(self, instance_id, state): waiters.wait_for_server_status(self.servers_client, instance_id, state) @test.idempotent_id('363ee4ba-2e75-433d-9051-72de64c3386b') @testtools.skipUnless(CONF.compute_feature_enabled.resize, 'Resize is not available.') @test.services('compute', 'image') def test_disk_sizes_before_and_after_resize(self): keypair = self.create_keypair() security_group = self._create_security_group() security_groups = [{'name': security_group['name']}] # create flavor-1 # - root disk: 1GB # - swap disk: 111MB # - ephemeral disk: 1GB flavor_1 = self._create_flavor('flavor-1', 1, 111, 1) # create flavor-2 # - root disk: 2GB # - swap disk: 222MB # - ephemeral disk: 2GB flavor_2 = self._create_flavor('flavor-2', 2, 222, 2) # create instance with flavor-1 instance = self.create_server( wait_until='ACTIVE', flavor=flavor_1['id'], key_name=keypair['name'], security_groups=security_groups, ) instance_id = instance['id'] # ssh to instance private_key = keypair['private_key'] instance_ip = self.get_server_ip(instance) ssh = self.get_remote_client(instance_ip, private_key=private_key) # verify disk sizes (before resize) expected_disk_sizes = { 'vda': ('root', 1 * units.Gi), 'vdb': ('ephemeral', 1 * units.Gi), 'vdc': ('swap', 111 * units.Mi), } self._assert_disk_sizes(ssh, expected_disk_sizes, 'before') # resize instance to flavor-2 self.servers_client.resize_server(instance_id, flavor_2['id']) self._wait_for_status(instance_id, 'VERIFY_RESIZE') # confirm resize self.servers_client.confirm_resize_server(instance_id) self._wait_for_status(instance_id, 'ACTIVE') # verify disk sizes (after resize) expected_disk_sizes = { 'vda': ('root', 2 * units.Gi), 'vdb': ('ephemeral', 1 * units.Gi), # bug, should be: 2 * units.Gi 'vdc': ('swap', 222 * units.Mi), } self._assert_disk_sizes(ssh, expected_disk_sizes, 'after') ",,131,0
openstack%2Fnetworking-calico~master~I0de314897c80244a32899be0fea16c776b9a18ac,openstack/networking-calico,master,I0de314897c80244a32899be0fea16c776b9a18ac,Handle recent FloatingIP move,MERGED,2017-02-28 11:09:05.000000000,2017-02-28 15:40:14.000000000,2017-02-28 15:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 13734}, {'_account_id': 19461}]","[{'number': 1, 'created': '2017-02-28 11:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/338671049ec834313923afd34fb5abf7596a37e6', 'message': 'Handle recent FloatingIP move\n\nFloatingIP was recently moved from neutron.db.l3_db to\nneutron.db.models.l3.\n\nChange-Id: I0de314897c80244a32899be0fea16c776b9a18ac\n'}, {'number': 2, 'created': '2017-02-28 11:47:16.000000000', 'files': ['networking_calico/plugins/ml2/drivers/calico/mech_calico.py', 'networking_calico/plugins/ml2/drivers/calico/test/lib.py'], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/f8ef5fb4288596fc18859608f681e5e1248cada5', 'message': 'Handle recent FloatingIP move\n\nFloatingIP was recently moved from neutron.db.l3_db to\nneutron.db.models.l3.\n\nChange-Id: I0de314897c80244a32899be0fea16c776b9a18ac\n'}]",0,438920,f8ef5fb4288596fc18859608f681e5e1248cada5,8,3,2,13734,,,0,"Handle recent FloatingIP move

FloatingIP was recently moved from neutron.db.l3_db to
neutron.db.models.l3.

Change-Id: I0de314897c80244a32899be0fea16c776b9a18ac
",git fetch https://review.opendev.org/openstack/networking-calico refs/changes/20/438920/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_calico/plugins/ml2/drivers/calico/mech_calico.py'],1,338671049ec834313923afd34fb5abf7596a37e6,,try: from neutron.db.models.l3 import FloatingIP except ImportError: # Ocata and earlier. from neutron.db.l3_db import FloatingIP FloatingIP,from neutron.db import l3_db l3_db.FloatingIP,6,2
openstack%2Fmasakari~stable%2Focata~I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0,openstack/masakari,stable/ocata,I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0,Prevent 404 error when adding reserved_host to aggregate,MERGED,2017-02-28 06:17:05.000000000,2017-02-28 15:40:07.000000000,2017-02-28 15:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 8716}, {'_account_id': 12950}]","[{'number': 1, 'created': '2017-02-28 06:17:05.000000000', 'files': ['masakari/tests/unit/fakes.py', 'masakari/engine/drivers/taskflow/host_failure.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py', 'masakari/tests/unit/compute/test_nova.py', 'masakari/compute/nova.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/6947cb0d2324f2cfc5eadefd9fa0ad7f17229fca', 'message': 'Prevent 404 error when adding reserved_host to aggregate\n\nWhen host-failure occurs, masakari-engine adds reserve_host\nto aggregate.\nHowever, when masakari-engine adds reserved_host,\nmasakari-engine passes an aggregate_name to novaclient.\nThis patch is modified so that masakari-engine passes\naggregate_id instead of aggregate_name to novaclient.\n\nChange-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0\nCloses-Bug: #1667246\n(cherry picked from commit 7415951c46e21297a1f8a3c878595cd399669831)\n'}]",0,438815,6947cb0d2324f2cfc5eadefd9fa0ad7f17229fca,7,3,1,20191,,,0,"Prevent 404 error when adding reserved_host to aggregate

When host-failure occurs, masakari-engine adds reserve_host
to aggregate.
However, when masakari-engine adds reserved_host,
masakari-engine passes an aggregate_name to novaclient.
This patch is modified so that masakari-engine passes
aggregate_id instead of aggregate_name to novaclient.

Change-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0
Closes-Bug: #1667246
(cherry picked from commit 7415951c46e21297a1f8a3c878595cd399669831)
",git fetch https://review.opendev.org/openstack/masakari refs/changes/15/438815/1 && git format-patch -1 --stdout FETCH_HEAD,"['masakari/engine/drivers/taskflow/host_failure.py', 'masakari/tests/unit/fakes.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py', 'masakari/tests/unit/compute/test_nova.py', 'masakari/compute/nova.py']",5,6947cb0d2324f2cfc5eadefd9fa0ad7f17229fca,bug/1667246," LOG.info(msg, {'host_name': host, 'aggregate_name': aggregate.name}) return nova.aggregates.add_host(aggregate.id, host)"," LOG.info(msg, {'host_name': host, 'aggregate_name': aggregate}) return nova.aggregates.add_host(aggregate, host)",10,10
openstack%2Fnova~master~Id6a9c4ec9ba3420190647dfb72b314ae9008eae7,openstack/nova,master,Id6a9c4ec9ba3420190647dfb72b314ae9008eae7,Remove paramiko dependency,ABANDONED,2016-09-08 14:00:02.000000000,2017-02-28 15:39:59.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 7764}, {'_account_id': 8119}, {'_account_id': 8213}, {'_account_id': 8864}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16907}, {'_account_id': 20040}, {'_account_id': 23304}]","[{'number': 1, 'created': '2016-09-08 14:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8e2de3c2f4fd07ae72f960713b5dcbbfbac9203', 'message': ""Remove paramiko dependency\n\nIn Liberty, key pair creation (previously done via ssh-keygen) was\nreplaced with paramiko library calls. While paramiko was listed as a\ndependency in Liberty, it wasn't actually used until that commit.\n\n  Replace ssh exec calls with paramiko lib\n  https://review.openstack.org/#/c/157931/\n\nThe above commit was unintentionally backwards incompatible.\nSpecifically, it changed the SSH key ASN.1 encoding from DER to BER.\nApparently golang doesn't support BER, meaning tools like Terraform no\nlonger work with OpenStack.\n\n  ssh-keygen-to-Paramiko change breaks third-party tools\n  https://bugs.launchpad.net/nova/+bug/1483132\n\nThis has since been fixed in paramiko 2.0, but that major version bump\ndoesn't make it into Nova until Newton, making these third-party tools\nunusable for Liberty & Mitaka in the mean time.\n\n   stable/liberty: paramiko>=1.13.0\n   upper-constraints: paramiko===1.16.0\n\n   stable/mitaka: paramiko>=1.16.0\n   upper-constraints: paramiko===1.16.0\n\n   master (newton): paramiko>=2.0\n   upper-constraints: paramiko===2.0.2\n\nThe bump to paramiko 2.0 was a big change, complete with a huge red\nwarning in the changelog (which I suspect makes a backport that bumps\nthe paramiko version to 2.0+ unrealistic for Liberty & Mitaka).\n\n  http://www.paramiko.org/changelog.html\n  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/\n\nThe switch to paramiko also introduced a number of Nova regressions\nalong the way.\n\n  Tolerate installation of pycryptodome\n  https://review.openstack.org/#/c/279909/\n\n  crypto: Add support for Paramiko 2.x\n  https://review.openstack.org/#/c/314592/\n\n  Drop paramiko < 2 compat code\n  https://review.openstack.org/#/c/314639/\n\nAll this, coupled with the known security implications of using the\nolder paramiko versions, makes me think that perhaps we should just go\nback to using ssh-keygen.\n\nIdeally, I'd like to backport this change all the way down to\nstable/liberty.\n\nChange-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7\n""}, {'number': 2, 'created': '2016-09-08 15:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46e8375b9911a1eaf9713cbf69b6b7a4926a894a', 'message': ""Remove paramiko dependency\n\nIn Liberty, key pair creation (previously done via ssh-keygen) was\nreplaced with paramiko library calls. While paramiko was listed as a\ndependency in Liberty, it wasn't actually used until that commit.\n\n  Replace ssh exec calls with paramiko lib\n  https://review.openstack.org/#/c/157931/\n\nThe above commit was unintentionally backwards incompatible.\nSpecifically, it changed the SSH key ASN.1 encoding from DER to BER.\nApparently golang doesn't support BER, meaning tools like Terraform no\nlonger work with OpenStack.\n\n  ssh-keygen-to-Paramiko change breaks third-party tools\n  https://bugs.launchpad.net/nova/+bug/1483132\n\nThis has since been fixed in paramiko 2.0, but that major version bump\ndoesn't make it into Nova until Newton, meaning these third-party tools\nare unusable for Liberty & Mitaka in the mean time.\n\n   stable/liberty: paramiko>=1.13.0\n   upper-constraints: paramiko===1.16.0\n\n   stable/mitaka: paramiko>=1.16.0\n   upper-constraints: paramiko===1.16.0\n\n   master (newton): paramiko>=2.0\n   upper-constraints: paramiko===2.0.2\n\nThe bump to paramiko 2.0 was a big change, complete with a huge red\nwarning in the changelog (which I suspect makes a backport that bumps\nthe paramiko version to 2.0+ unrealistic for Liberty & Mitaka).\n\n  http://www.paramiko.org/changelog.html\n  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/\n\nThe switch to paramiko also introduced a number of Nova regressions\nalong the way.\n\n  Tolerate installation of pycryptodome\n  https://review.openstack.org/#/c/279909/\n\n  crypto: Add support for Paramiko 2.x\n  https://review.openstack.org/#/c/314592/\n\n  Drop paramiko < 2 compat code\n  https://review.openstack.org/#/c/314639/\n\nAll this, coupled with the known security implications of using the\nolder paramiko versions, makes me think that perhaps we should just go\nback to using ssh-keygen.\n\nIdeally, I'd like to backport this change all the way down to\nstable/liberty.\n\nChange-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7\n""}, {'number': 3, 'created': '2016-09-08 15:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d7f948781823dd4f7782c66549c86fe29512037', 'message': ""Remove paramiko dependency\n\nIn Liberty, key pair creation (previously done via ssh-keygen) was\nreplaced with paramiko library calls. While paramiko was listed as a\ndependency in Liberty, it wasn't actually used until that commit.\n\n  Replace ssh exec calls with paramiko lib\n  https://review.openstack.org/#/c/157931/\n\nThe above commit was unintentionally backwards incompatible.\nSpecifically, it changed the SSH key ASN.1 encoding from DER to BER.\nApparently golang doesn't support BER, meaning tools like Terraform no\nlonger work with OpenStack.\n\n  ssh-keygen-to-Paramiko change breaks third-party tools\n  https://bugs.launchpad.net/nova/+bug/1483132\n\nThis has since been fixed in paramiko 2.0, but that major version bump\ndoesn't make it into Nova until Newton, meaning these third-party tools\nare unusable for Liberty & Mitaka in the mean time.\n\n   stable/liberty: paramiko>=1.13.0\n   upper-constraints: paramiko===1.16.0\n\n   stable/mitaka: paramiko>=1.16.0\n   upper-constraints: paramiko===1.16.0\n\n   master (newton): paramiko>=2.0\n   upper-constraints: paramiko===2.0.2\n\nThe bump to paramiko 2.0 was a big change, complete with a huge red\nwarning in the changelog (which I suspect makes a backport that bumps\nthe paramiko version to 2.0+ unrealistic for Liberty & Mitaka).\n\n  http://www.paramiko.org/changelog.html\n  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/\n\nThe switch to paramiko also introduced a number of Nova regressions\nalong the way.\n\n  Tolerate installation of pycryptodome\n  https://review.openstack.org/#/c/279909/\n\n  crypto: Add support for Paramiko 2.x\n  https://review.openstack.org/#/c/314592/\n\n  Drop paramiko < 2 compat code\n  https://review.openstack.org/#/c/314639/\n\nAll this, coupled with the known security implications of using the\nolder paramiko versions, makes me think that perhaps we should just go\nback to using ssh-keygen.\n\nIdeally, I'd like to backport this change all the way down to\nstable/liberty.\n\nCloses-Bug #1621536\nChange-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7\n""}, {'number': 4, 'created': '2016-09-13 01:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d6fc3931326fbfaeaf150a5815ea8911c335b7b', 'message': ""Remove paramiko dependency\n\nIn Liberty, key pair creation (previously done via ssh-keygen) was\nreplaced with paramiko library calls. While paramiko was listed as a\nNova dependency in Liberty, it wasn't actually used until that commit.\n\n  Replace ssh exec calls with paramiko lib\n  https://review.openstack.org/#/c/157931/\n\nThe above commit was unintentionally backwards incompatible.\nSpecifically, it changed the SSH key ASN.1 encoding from DER to BER.\nApparently golang doesn't support BER, meaning tools like Terraform no\nlonger work with OpenStack.\n\n  ssh-keygen-to-Paramiko change breaks third-party tools\n  https://bugs.launchpad.net/nova/+bug/1483132\n\nThis has since been fixed in paramiko 2.0, but that major version bump\ndoesn't make it into Nova until Newton, meaning these third-party tools\nare unusable for Liberty & Mitaka in the mean time.\n\n   stable/liberty: paramiko>=1.13.0\n   upper-constraints: paramiko===1.16.0\n\n   stable/mitaka: paramiko>=1.16.0\n   upper-constraints: paramiko===1.16.0\n\n   master (newton): paramiko>=2.0\n   upper-constraints: paramiko===2.0.2\n\nThe bump to paramiko 2.0 was a big change, complete with a huge red\nwarning in the changelog (which I suspect makes a backport that bumps\nthe paramiko version to 2.0+ unrealistic for Liberty & Mitaka).\n\n  http://www.paramiko.org/changelog.html\n  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/\n\nThe switch to paramiko also introduced a number of other Nova\nregressions along the way.\n\n  nova should accept pre-pended comments in public keys\n  https://bugs.launchpad.net/nova/+bug/1613199\n\n  Tolerate installation of pycryptodome\n  https://review.openstack.org/#/c/279909/\n\n  crypto: Add support for Paramiko 2.x\n  https://review.openstack.org/#/c/314592/\n\n  Drop paramiko < 2 compat code\n  https://review.openstack.org/#/c/314639/\n\nAll this, coupled with the known security implications of using the\nolder paramiko versions, makes me think that perhaps we should just go\nback to using ssh-keygen.\n\nIdeally, I'd like to backport this change all the way down to\nstable/liberty.\n\nCloses-Bug #1621536\nChange-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7\n""}, {'number': 5, 'created': '2016-10-11 16:46:08.000000000', 'files': ['requirements.txt', 'nova/crypto.py', 'nova/tests/unit/test_crypto.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f418e3600fb33fdb4cf53f3c513f346594b17400', 'message': ""Remove paramiko dependency\n\nIn Liberty, key pair creation (previously done via ssh-keygen) was\nreplaced with paramiko library calls. While paramiko was listed as a\nNova dependency in Liberty, it wasn't actually used until that commit.\n\n  Replace ssh exec calls with paramiko lib\n  https://review.openstack.org/#/c/157931/\n\nThe above commit was unintentionally backwards incompatible.\nSpecifically, it changed the SSH key ASN.1 encoding from DER to BER.\nApparently golang doesn't support BER, meaning tools like Terraform no\nlonger work with OpenStack.\n\n  ssh-keygen-to-Paramiko change breaks third-party tools\n  https://bugs.launchpad.net/nova/+bug/1483132\n\nThis has since been fixed in paramiko 2.0, but that major version bump\ndoesn't make it into Nova until Newton, meaning these third-party tools\nare unusable for Liberty & Mitaka in the mean time.\n\n   stable/liberty: paramiko>=1.13.0\n   upper-constraints: paramiko===1.16.0\n\n   stable/mitaka: paramiko>=1.16.0\n   upper-constraints: paramiko===1.16.0\n\n   master (newton): paramiko>=2.0\n   upper-constraints: paramiko===2.0.2\n\nThe bump to paramiko 2.0 was a big change, complete with a huge red\nwarning in the changelog (which I suspect makes a backport that bumps\nthe paramiko version to 2.0+ unrealistic for Liberty & Mitaka).\n\n  http://www.paramiko.org/changelog.html\n  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/\n\nThe switch to paramiko also introduced a number of other Nova\nregressions along the way.\n\n  nova should accept pre-pended comments in public keys\n  https://bugs.launchpad.net/nova/+bug/1613199\n\n  Tolerate installation of pycryptodome\n  https://review.openstack.org/#/c/279909/\n\n  crypto: Add support for Paramiko 2.x\n  https://review.openstack.org/#/c/314592/\n\n  Drop paramiko < 2 compat code\n  https://review.openstack.org/#/c/314639/\n\nAll this, coupled with the known security implications of using the\nolder paramiko versions, makes me think that perhaps we should just go\nback to using ssh-keygen.\n\nCloses-Bug #1621536\nChange-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7\n""}]",9,367395,f418e3600fb33fdb4cf53f3c513f346594b17400,85,27,5,16907,,,0,"Remove paramiko dependency

In Liberty, key pair creation (previously done via ssh-keygen) was
replaced with paramiko library calls. While paramiko was listed as a
Nova dependency in Liberty, it wasn't actually used until that commit.

  Replace ssh exec calls with paramiko lib
  https://review.openstack.org/#/c/157931/

The above commit was unintentionally backwards incompatible.
Specifically, it changed the SSH key ASN.1 encoding from DER to BER.
Apparently golang doesn't support BER, meaning tools like Terraform no
longer work with OpenStack.

  ssh-keygen-to-Paramiko change breaks third-party tools
  https://bugs.launchpad.net/nova/+bug/1483132

This has since been fixed in paramiko 2.0, but that major version bump
doesn't make it into Nova until Newton, meaning these third-party tools
are unusable for Liberty & Mitaka in the mean time.

   stable/liberty: paramiko>=1.13.0
   upper-constraints: paramiko===1.16.0

   stable/mitaka: paramiko>=1.16.0
   upper-constraints: paramiko===1.16.0

   master (newton): paramiko>=2.0
   upper-constraints: paramiko===2.0.2

The bump to paramiko 2.0 was a big change, complete with a huge red
warning in the changelog (which I suspect makes a backport that bumps
the paramiko version to 2.0+ unrealistic for Liberty & Mitaka).

  http://www.paramiko.org/changelog.html
  http://bitprophet.org/blog/2016/04/23/paramiko-2.0-is-coming/

The switch to paramiko also introduced a number of other Nova
regressions along the way.

  nova should accept pre-pended comments in public keys
  https://bugs.launchpad.net/nova/+bug/1613199

  Tolerate installation of pycryptodome
  https://review.openstack.org/#/c/279909/

  crypto: Add support for Paramiko 2.x
  https://review.openstack.org/#/c/314592/

  Drop paramiko < 2 compat code
  https://review.openstack.org/#/c/314639/

All this, coupled with the known security implications of using the
older paramiko versions, makes me think that perhaps we should just go
back to using ssh-keygen.

Closes-Bug #1621536
Change-Id: Id6a9c4ec9ba3420190647dfb72b314ae9008eae7
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/367395/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'nova/crypto.py', 'nova/tests/unit/test_crypto.py']",3,b8e2de3c2f4fd07ae72f960713b5dcbbfbac9203,bug/1621536,,"import paramiko def test_generate_key_pair_mocked_private_key(self): keyin = six.StringIO() keyin.write(self.rsa_prv) keyin.seek(0) key = paramiko.RSAKey.from_private_key(keyin) with mock.patch.object(paramiko.RSAKey, 'generate') as mock_generate: mock_generate.return_value = key (private_key, public_key, fingerprint) = crypto.generate_key_pair() self.assertEqual(self.rsa_pub, public_key) self.assertEqual(self.rsa_fp, fingerprint)",20,22
openstack%2Fnova~master~I92359dbd557f46e6c254e65cf54852127b66cc64,openstack/nova,master,I92359dbd557f46e6c254e65cf54852127b66cc64,Always validate availability_zone on 'nova boot',ABANDONED,2016-10-21 20:43:16.000000000,2017-02-28 15:39:45.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16907}, {'_account_id': 17292}]","[{'number': 1, 'created': '2016-10-21 20:43:16.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d76cb21449b48988c5c51a524002ce938ca1bdc', 'message': 'Always validate availability_zone on \'nova boot\'\n\nCurrently `availability_zone` is only validated against the known\navailability zones if it doesn\'t also include a `forced_host`` (example:\n""ZONE""). If it does include a forced host delimited by a colon (example:\n""ZONE:HOST""), then availability zone validation is skipped.\n\nThat is, this would fail: ""INVALID-ZONE"", but this would not fail:\n""INVALID-ZONE:HOST"".\n\nInstead, always validate `availability_zone` if one is provided,\nregardless of the presence or absence of a `forced_host`.\n\nChange-Id: I92359dbd557f46e6c254e65cf54852127b66cc64\nCloses-Bug: #1431194\n'}]",1,389845,6d76cb21449b48988c5c51a524002ce938ca1bdc,20,15,1,16907,,,0,"Always validate availability_zone on 'nova boot'

Currently `availability_zone` is only validated against the known
availability zones if it doesn't also include a `forced_host`` (example:
""ZONE""). If it does include a forced host delimited by a colon (example:
""ZONE:HOST""), then availability zone validation is skipped.

That is, this would fail: ""INVALID-ZONE"", but this would not fail:
""INVALID-ZONE:HOST"".

Instead, always validate `availability_zone` if one is provided,
regardless of the presence or absence of a `forced_host`.

Change-Id: I92359dbd557f46e6c254e65cf54852127b66cc64
Closes-Bug: #1431194
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/389845/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/compute/api.py']",2,6d76cb21449b48988c5c51a524002ce938ca1bdc,bug/1431194, if availability_zone not in available_zones:, if forced_host is None and availability_zone not in \ available_zones:,39,2
openstack%2Fpython-openstackclient~master~If08a68fddd5aacc488a93ad18751eb793e7edf3d,openstack/python-openstackclient,master,If08a68fddd5aacc488a93ad18751eb793e7edf3d,WIP - Add nova microversion 2.40 support,ABANDONED,2017-01-11 19:29:17.000000000,2017-02-28 15:39:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-01-11 19:29:17.000000000', 'files': ['openstackclient/compute/v2/usage.py', 'openstackclient/tests/unit/compute/v2/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ae8479b76479a8c8e13bfa57d3b6e3e5227f3302', 'message': ""WIP - Add nova microversion 2.40 support\n\nMicroversion 2.40 added pagination (and next links) to the usage\nstatistics via optional limit and marker query parameters. If limit\nisnt provided, the configurable max_limit will be used which currently\ndefaults to 1000. Older microversions will not accept these new paging\nquery parameters, but they will start to silently limit by max_limit.\n\nIf microversion 2.40 isn't specified, the usage results may be truncated\nand inaccurate.\n\nChange-Id: If08a68fddd5aacc488a93ad18751eb793e7edf3d\n""}]",0,419108,ae8479b76479a8c8e13bfa57d3b6e3e5227f3302,3,2,1,16907,,,0,"WIP - Add nova microversion 2.40 support

Microversion 2.40 added pagination (and next links) to the usage
statistics via optional limit and marker query parameters. If limit
isnt provided, the configurable max_limit will be used which currently
defaults to 1000. Older microversions will not accept these new paging
query parameters, but they will start to silently limit by max_limit.

If microversion 2.40 isn't specified, the usage results may be truncated
and inaccurate.

Change-Id: If08a68fddd5aacc488a93ad18751eb793e7edf3d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/419108/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/compute/v2/usage.py', 'openstackclient/tests/unit/compute/v2/fakes.py']",2,ae8479b76479a8c8e13bfa57d3b6e3e5227f3302,stu,from novaclient import api_versions self.api_version = api_versions.APIVersion('2.1') ,,77,2
openstack%2Fnova~master~I386f7e6e887aea0e0ff00974eb7c41dd403aedb7,openstack/nova,master,I386f7e6e887aea0e0ff00974eb7c41dd403aedb7,Query parameter validation for hypervisors API,ABANDONED,2017-01-06 20:48:29.000000000,2017-02-28 15:39:14.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6062}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16907}, {'_account_id': 18339}, {'_account_id': 20040}, {'_account_id': 23676}]","[{'number': 1, 'created': '2017-01-06 20:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22a3b8331c969bc80a2788b49f719c6a666071ec', 'message': 'Query parameter validation for hypervisors API\n\nThis patch adds JSON Schema query parameter validation for the\nhypervisors index & detail API endpoints.\n\nImplementation blueprint consistent-query-parameters-validation\n\nChange-Id: I386f7e6e887aea0e0ff00974eb7c41dd403aedb7\n'}, {'number': 2, 'created': '2017-01-06 21:10:30.000000000', 'files': ['nova/api/openstack/compute/hypervisors.py', 'nova/tests/unit/api/openstack/compute/test_hypervisors.py', 'nova/api/openstack/compute/schemas/hypervisors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/442d4d0d14ac838b953c9fc14c1791130c9b2c4a', 'message': 'Query parameter validation for hypervisors API\n\nThis patch adds JSON Schema query parameter validation for the\nhypervisors index & detail API endpoints.\n\nImplementation blueprint consistent-query-parameters-validation\n\nChange-Id: I386f7e6e887aea0e0ff00974eb7c41dd403aedb7\n'}]",10,417507,442d4d0d14ac838b953c9fc14c1791130c9b2c4a,25,18,2,16907,,,0,"Query parameter validation for hypervisors API

This patch adds JSON Schema query parameter validation for the
hypervisors index & detail API endpoints.

Implementation blueprint consistent-query-parameters-validation

Change-Id: I386f7e6e887aea0e0ff00974eb7c41dd403aedb7
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/417507/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/hypervisors.py', 'nova/api/openstack/compute/schemas/hypervisors.py']",2,22a3b8331c969bc80a2788b49f719c6a666071ec,bp/consistent-query-parameters-validation,"# Copyright 2017 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy from nova.api.validation import parameter_types index_query_schema_v20 = { 'type': 'object', 'properties': {}, 'additionalProperties': True } index_query_schema_v233 = copy.deepcopy(index_query_schema_v20) index_query_schema_v233['properties'].update( parameter_types.pagination_parameters) detail_query_schema_v20 = { 'type': 'object', 'properties': {}, 'additionalProperties': True } detail_query_schema_v233 = copy.deepcopy(detail_query_schema_v20) detail_query_schema_v233['properties'].update( parameter_types.pagination_parameters) ",,45,0
openstack%2Fnova~master~I15147711620bcbfd7770dab085846c76994a0734,openstack/nova,master,I15147711620bcbfd7770dab085846c76994a0734,Query parameter validation for usages API,ABANDONED,2017-01-06 20:32:49.000000000,2017-02-28 15:39:07.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6062}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16907}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-01-06 20:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4606d07c232828fc5ebe25b4191fc27f28ee47f2', 'message': 'Query parameter validation for usages API\n\nThis patch adds JSON Schema query parameter validation for the simple\ntenant usage API endpoints.\n\nImplementation blueprint consistent-query-parameters-\n\nChange-Id: I15147711620bcbfd7770dab085846c76994a0734\n'}, {'number': 2, 'created': '2017-01-06 20:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3323c366e47b7c485feb171be20bcef8535c92d', 'message': 'Query parameter validation for usages API\n\nThis patch adds JSON Schema query parameter validation for the simple\ntenant usage API endpoints.\n\nImplementation blueprint consistent-query-parameters-validation\n\nChange-Id: I15147711620bcbfd7770dab085846c76994a0734\n'}, {'number': 3, 'created': '2017-01-06 21:36:37.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_simple_tenant_usage.py', 'nova/api/openstack/compute/schemas/usages.py', 'nova/api/openstack/compute/simple_tenant_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ccb3683c5d1e10f7ef67fa33f5c14d144a0e157c', 'message': 'Query parameter validation for usages API\n\nThis patch adds JSON Schema query parameter validation for the simple\ntenant usage API endpoints.\n\nImplementation blueprint consistent-query-parameters-validation\n\nChange-Id: I15147711620bcbfd7770dab085846c76994a0734\n'}]",16,417500,ccb3683c5d1e10f7ef67fa33f5c14d144a0e157c,28,16,3,16907,,,0,"Query parameter validation for usages API

This patch adds JSON Schema query parameter validation for the simple
tenant usage API endpoints.

Implementation blueprint consistent-query-parameters-validation

Change-Id: I15147711620bcbfd7770dab085846c76994a0734
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/417500/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/schemas/usages.py', 'nova/api/openstack/compute/simple_tenant_usage.py']",2,4606d07c232828fc5ebe25b4191fc27f28ee47f2,bp/consistent-query-parameters-validation,from nova.api.openstack.compute.schemas import usagesfrom nova.api import validation @validation.query_schema(usages.index_query_schema_v240) @validation.query_schema(usages.index_query_schema_v20) @validation.query_schema(usages.show_query_schema_v240) @validation.query_schema(usages.show_query_schema_v20),,61,0
openstack%2Fnova~master~I7bdf83aa0c880279a8db9799c3d80977082d72bf,openstack/nova,master,I7bdf83aa0c880279a8db9799c3d80977082d72bf,DNM: check experimental queue,ABANDONED,2017-01-13 21:34:01.000000000,2017-02-28 15:38:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16907}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-01-13 21:34:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/c4bec76c7d66dc8560b2efcd0f1c2be0e8f79279', 'message': 'DNM: check experimental queue\n\nChange-Id: I7bdf83aa0c880279a8db9799c3d80977082d72bf\n'}]",0,420186,c4bec76c7d66dc8560b2efcd0f1c2be0e8f79279,16,9,1,16907,,,0,"DNM: check experimental queue

Change-Id: I7bdf83aa0c880279a8db9799c3d80977082d72bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/420186/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c4bec76c7d66dc8560b2efcd0f1c2be0e8f79279,exp,# TEST,,1,0
openstack%2Fdevstack-tools~master~Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848,openstack/devstack-tools,master,Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848,Insert the right content at end of files,MERGED,2017-02-28 14:54:31.000000000,2017-02-28 15:37:29.000000000,2017-02-28 15:37:29.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}]","[{'number': 1, 'created': '2017-02-28 14:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-tools/commit/084af1ec84fd019c6715ee92770d82fd0a82e680', 'message': ""Insert the right content at end of files\n\nPreviously the logic around hitting the end of the file without having\nfound the insertion point didn't account for the fact that you might\nbe in roughly the right area, and would not need to duplicate the meta\nsection or section headers.\n\nThis takes that into account during the else phase. It will help with\nthe neutron functional jobs that merge a lot of snippets together.\n\nChange-Id: Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848\n""}, {'number': 2, 'created': '2017-02-28 15:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-tools/commit/9b3d2ed1be626400838a68e23aa22c7a372f9a9a', 'message': ""Insert the right content at end of files\n\nPreviously the logic around hitting the end of the file without having\nfound the insertion point didn't account for the fact that you might\nbe in roughly the right area, and would not need to duplicate the meta\nsection or section headers.\n\nThis takes that into account during the else phase. It will help with\nthe neutron functional jobs that merge a lot of snippets together.\n\nChange-Id: Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848\n""}, {'number': 3, 'created': '2017-02-28 15:28:06.000000000', 'files': ['devstack/dsconf.py', 'devstack/tests/test_localconf_merge.py'], 'web_link': 'https://opendev.org/openstack/devstack-tools/commit/8a9057a4e2a854f77f8bee2ea3ed1e006fb0a45a', 'message': ""Insert the right content at end of files\n\nPreviously the logic around hitting the end of the file without having\nfound the insertion point didn't account for the fact that you might\nbe in roughly the right area, and would not need to duplicate the meta\nsection or section headers.\n\nThis takes that into account during the else phase. It will help with\nthe neutron functional jobs that merge a lot of snippets together.\n\nChange-Id: Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848\n""}]",1,438989,8a9057a4e2a854f77f8bee2ea3ed1e006fb0a45a,12,3,3,2750,,,0,"Insert the right content at end of files

Previously the logic around hitting the end of the file without having
found the insertion point didn't account for the fact that you might
be in roughly the right area, and would not need to duplicate the meta
section or section headers.

This takes that into account during the else phase. It will help with
the neutron functional jobs that merge a lot of snippets together.

Change-Id: Ifaa1176e9fdfbc4fdb43192ed2f85e7306823848
",git fetch https://review.opendev.org/openstack/devstack-tools refs/changes/89/438989/3 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/dsconf.py', 'devstack/tests/test_localconf_merge.py']",2,084af1ec84fd019c6715ee92770d82fd0a82e680,,"BASIC2 = """""" [[local|localrc]] a=b c=d f=1 [[post-config|$NEUTRON_CONF]] [quotas] quota_network = 100 """""" LC3 = """""" [[post-config|$NEUTRON_CONF]] [quotas] quota_port = 500 """""" """""" RESULT3 = """""" [[local|localrc]] a=b c=d f=1 [[post-config|$NEUTRON_CONF]] [quotas] quota_network = 100 quota_port = 500 class TestLcMergePost(testtools.TestCase): def setUp(self): super(TestLcMergePost, self).setUp() self._path = self.useFixture(fixtures.TempDir()).path self._path += ""/local.conf"" with open(self._path, ""w"") as f: f.write(BASIC2) def test_merge_lc3(self): """"""Test merging with 2 post-config sections that should overlap."""""" dirname = self.useFixture(fixtures.TempDir()).path lc = os.path.join(dirname, ""local.conf"") with open(lc, ""w+"") as f: f.write(LC3) conf = dsconf.LocalConf(self._path) conf.merge_lc(lc) with open(self._path) as f: content = f.read() self.assertEqual(content, RESULT3)",,57,3
openstack%2Fopenstack-ansible-pip_install~master~Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,openstack/openstack-ansible-pip_install,master,Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b,Use an explicit version of urrlib3,MERGED,2017-02-28 15:24:28.000000000,2017-02-28 15:37:03.000000000,2017-02-28 15:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 15:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/e34ecdb516c86b0f4d9b1d6a054dd1444145c499', 'message': 'Install urllib3\n\nget_url/uri modules need a proper urllib3 on the host it executes.\n\nChange-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b\n'}, {'number': 2, 'created': '2017-02-28 15:30:29.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44', 'message': ""Use an explicit version of urrlib3\n\nIf not forcing to install urllib3, ansible on the target node\nwill reuse the urrlib3 from site-packages, which could be older\nthan the one in global-requirements, because ansible doesn't\nlist it in its dependencies, so we don't explicit force a\ncertain version to be installed.\n\nOn my machine, I had an urllib3 installed with a version of\n1.7.1, and the get_url/uri modules with https had SSL issues.\nMoving to a more recent version urllib3 fixed it.\n\nChange-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b\n""}]",0,439017,3a6cc1a44cf74a83cc06d740ca71e7ea6cc7ac44,11,4,2,17068,,,0,"Use an explicit version of urrlib3

If not forcing to install urllib3, ansible on the target node
will reuse the urrlib3 from site-packages, which could be older
than the one in global-requirements, because ansible doesn't
list it in its dependencies, so we don't explicit force a
certain version to be installed.

On my machine, I had an urllib3 installed with a version of
1.7.1, and the get_url/uri modules with https had SSL issues.
Moving to a more recent version urllib3 fixed it.

Change-Id: Id249d8f3aa9adab3d3b86a95bcd518c927d6a45b
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/17/439017/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'vars/suse.yml']",3,e34ecdb516c86b0f4d9b1d6a054dd1444145c499,urllib3, - urllib3 # SSL SNI support,,6,0
openstack%2Ffuel-astute~master~I17db392ac4c73a3c08505fcbaf17dbcce96ebd91,openstack/fuel-astute,master,I17db392ac4c73a3c08505fcbaf17dbcce96ebd91,Fail tolerance behavior for upload file tasks,MERGED,2017-02-28 01:54:53.000000000,2017-02-28 15:32:31.000000000,2017-02-28 15:31:06.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 10959}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2017-02-28 01:54:53.000000000', 'files': ['lib/astute/task_node.rb', 'lib/astute/mclients/upload_file_mclient.rb', 'lib/astute/mclients/shell_mclient.rb', 'lib/astute/puppet_job.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/48ee1f746752e47b8d1735bbf25ba5ab3b0f1d4d', 'message': 'Fail tolerance behavior for upload file tasks\n\nAdditional changes:\n\n- decrease number of ""reset undefined retries"" messages;\n- rewriting log messages for better understanding.\n\nChange-Id: I17db392ac4c73a3c08505fcbaf17dbcce96ebd91\nBlueprint: graph-concept-extension\n'}]",0,438764,48ee1f746752e47b8d1735bbf25ba5ab3b0f1d4d,20,7,1,8776,,,0,"Fail tolerance behavior for upload file tasks

Additional changes:

- decrease number of ""reset undefined retries"" messages;
- rewriting log messages for better understanding.

Change-Id: I17db392ac4c73a3c08505fcbaf17dbcce96ebd91
Blueprint: graph-concept-extension
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/64/438764/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/task_node.rb', 'lib/astute/mclients/upload_file_mclient.rb', 'lib/astute/mclients/shell_mclient.rb', 'lib/astute/puppet_job.rb']",4,48ee1f746752e47b8d1735bbf25ba5ab3b0f1d4d,bp/graph-concept-extension, return if @undefined_retries == @original_undefined_retries ,,30,11
openstack%2Ffuel-qa~stable%2Focata~I99959cb72caeec33a91358af4b58fa858b9c22c8,openstack/fuel-qa,stable/ocata,I99959cb72caeec33a91358af4b58fa858b9c22c8,Redirect update-master-node.sh stdout and stderr,MERGED,2017-02-28 11:01:14.000000000,2017-02-28 15:26:47.000000000,2017-02-28 15:26:47.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 19119}]","[{'number': 1, 'created': '2017-02-28 11:01:14.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/cb4a6873534c8103a43d17209e19b475809d55e4', 'message': ""Redirect update-master-node.sh stdout and stderr\n\nSSHD stops reading of update-master-node.sh stdout\nduring puppet run, this causes puppet hanging on\nkeystone tasks. In order to avoid this we need to\nredirect script's output to /dev/null.\n\nChange-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8\nCloses-Bug: #1664635\n(cherry picked from commit ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a)\n""}]",0,438914,cb4a6873534c8103a43d17209e19b475809d55e4,10,4,1,18795,,,0,"Redirect update-master-node.sh stdout and stderr

SSHD stops reading of update-master-node.sh stdout
during puppet run, this causes puppet hanging on
keystone tasks. In order to avoid this we need to
redirect script's output to /dev/null.

Change-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8
Closes-Bug: #1664635
(cherry picked from commit ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/14/438914/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,cb4a6873534c8103a43d17209e19b475809d55e4,bug/1664635, # LP #1664635 - we need to redirect stdout to /dev/null to avoid # ssh connection hanging on massive output from puppet run. cmd = '/usr/share/fuel-utils/update-master-node.sh > /dev/null 2>&1', cmd = '/usr/share/fuel-utils/update-master-node.sh',3,1
openstack%2Ffuel-qa~stable%2Fnewton~I99959cb72caeec33a91358af4b58fa858b9c22c8,openstack/fuel-qa,stable/newton,I99959cb72caeec33a91358af4b58fa858b9c22c8,Redirect update-master-node.sh stdout and stderr,MERGED,2017-02-28 11:01:36.000000000,2017-02-28 15:25:45.000000000,2017-02-28 15:25:45.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 19119}]","[{'number': 1, 'created': '2017-02-28 11:01:36.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/b431c985530508ec590d618e4381d5d8dd886dbf', 'message': ""Redirect update-master-node.sh stdout and stderr\n\nSSHD stops reading of update-master-node.sh stdout\nduring puppet run, this causes puppet hanging on\nkeystone tasks. In order to avoid this we need to\nredirect script's output to /dev/null.\n\nChange-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8\nCloses-Bug: #1664635\n(cherry picked from commit ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a)\n""}]",0,438915,b431c985530508ec590d618e4381d5d8dd886dbf,14,4,1,18795,,,0,"Redirect update-master-node.sh stdout and stderr

SSHD stops reading of update-master-node.sh stdout
during puppet run, this causes puppet hanging on
keystone tasks. In order to avoid this we need to
redirect script's output to /dev/null.

Change-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8
Closes-Bug: #1664635
(cherry picked from commit ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/15/438915/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,b431c985530508ec590d618e4381d5d8dd886dbf,bug/1664635, # LP #1664635 - we need to redirect stdout to /dev/null to avoid # ssh connection hanging on massive output from puppet run. cmd = '/usr/share/fuel-utils/update-master-node.sh > /dev/null 2>&1', cmd = '/usr/share/fuel-utils/update-master-node.sh',3,1
openstack%2Fironic-ui~master~I890a676ecccdbea01ba78991d7ef5ac834d2d99a,openstack/ironic-ui,master,I890a676ecccdbea01ba78991d7ef5ac834d2d99a,Source code documentation updates,MERGED,2017-02-06 22:53:11.000000000,2017-02-28 15:23:42.000000000,2017-02-28 15:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 11655}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-02-06 22:53:11.000000000', 'files': ['ironic_ui/api/ironic.py', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/8e94b781c3fa99c7e99ed3474065751a624c14f1', 'message': 'Source code documentation updates\n\n- Replace obsolete urls with up to date versions\n- Add missing urls to be consistent with the existing pattern\n\nChange-Id: I890a676ecccdbea01ba78991d7ef5ac834d2d99a\n'}]",0,429916,8e94b781c3fa99c7e99ed3474065751a624c14f1,7,3,1,19380,,,0,"Source code documentation updates

- Replace obsolete urls with up to date versions
- Add missing urls to be consistent with the existing pattern

Change-Id: I890a676ecccdbea01ba78991d7ef5ac834d2d99a
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/16/429916/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_ui/api/ironic.py', 'ironic_ui/static/dashboard/admin/ironic/ironic.service.js']",2,8e94b781c3fa99c7e99ed3474065751a624c14f1,code-comment-updates," * http://developer.openstack.org/api-ref/baremetal/? * expanded=create-node-detail#list-nodes-detailed * http://developer.openstack.org/api-ref/baremetal/? * expanded=create-node-detail#list-nodes-detailed * http://developer.openstack.org/api-ref/baremetal/#list-detailed-ports * http://developer.openstack.org/api-ref/baremetal/#set-maintenance-flag * http://developer.openstack.org/api-ref/baremetal/#clear-maintenance-flag * http://developer.openstack.org/api-ref/baremetal/#change-node-power-state * http://developer.openstack.org/api-ref/baremetal/#change-node-power-state * http://developer.openstack.org/api-ref/baremetal/#change-node-provision-state * http://developer.openstack.org/api-ref/baremetal/#create-node * http://developer.openstack.org/api-ref/baremetal/#delete-node * http://developer.openstack.org/api-ref/baremetal/#update-node * http://developer.openstack.org/api-ref/baremetal/#validate-node * @return {promise} Promise. success: list of interface validation * records, error: failure response * http://developer.openstack.org/api-ref/baremetal/#list-drivers * http://developer.openstack.org/api-ref/baremetal/#show-driver-properties * http://developer.openstack.org/api-ref/baremetal/#create-port * * http://developer.openstack.org/api-ref/baremetal/#delete-port *", * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-nodes * http://docs.openstack.org/developer/ironic/webapi/v1.html#NodeCollection * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1- * nodes-(node_ident) * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-ports * http://docs.openstack.org/developer/ironic/webapi/v1.html# * put--v1-nodes-(node_ident)-maintenance * http://docs.openstack.org/developer/ironic/webapi/v1.html# * delete--v1-nodes-(node_ident)-maintenance * http://docs.openstack.org/developer/ironic/webapi/v1.html# * put--v1-nodes-(node_ident)-states-power * http://docs.openstack.org/developer/ironic/webapi/v1.html# * put--v1-nodes-(node_ident)-states-power * http://docs.openstack.org/developer/ironic/webapi/v1.html# * put--v1-nodes-(node_ident)-states-provision * http://docs.openstack.org/developer/ironic/webapi/v1.html#post--v1-nodes * http://docs.openstack.org/developer/ironic/webapi/v1.html# * delete--v1-nodes * http://docs.openstack.org/developer/ironic/webapi/v1.html# * patch--v1-nodes-(node_ident) * http://docs.openstack.org/developer/ironic/webapi/v1.html# * validate--v1-nodes * @return {promise} Promise * http://docs.openstack.org/developer/ironic/webapi/v1.html#get--v1-drivers * http://docs.openstack.org/developer/ironic/webapi/v1.html#DriverList * http://docs.openstack.org/developer/ironic/webapi/v1.html# * get--v1-drivers-properties,30,27
openstack%2Fopenstack-ansible~stable%2Focata~I0e5677bbab614b3e1dd34d86059d8fdcf38c6c07,openstack/openstack-ansible,stable/ocata,I0e5677bbab614b3e1dd34d86059d8fdcf38c6c07,Final SHA bump before 15.0.0 release,MERGED,2017-02-28 11:50:27.000000000,2017-02-28 15:22:39.000000000,2017-02-28 15:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-28 11:50:27.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/capping_nova_workers-349f0f4d3fd50b37.yaml', 'releasenotes/notes/capping_repo_nginx_workers-ddbc355855f8fe43.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/cap-workers-fc70b4f8586ba1a5.yaml', 'releasenotes/notes/capping_neutron_workers-d97a5d50ca996af5.yaml', 'releasenotes/notes/capping_heat_workers-13791c456e59277d.yaml', 'releasenotes/notes/capping_glance_workers-54afc20c20baa14e.yaml', 'releasenotes/notes/capping_horizon_workers-29ecc4893bcc3a4b.yaml', 'ansible-role-requirements.yml', 'releasenotes/notes/capping_keystone_workers-e284a47fc4dcea38.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1515c99e48834058bb0855447d1fab8b71f85a65', 'message': 'Final SHA bump before 15.0.0 release\n\nPending any last minute issues, this should be the final SHA bump before\nrelease.\n\nChange-Id: I0e5677bbab614b3e1dd34d86059d8fdcf38c6c07\n'}]",0,438934,1515c99e48834058bb0855447d1fab8b71f85a65,8,3,1,2799,,,0,"Final SHA bump before 15.0.0 release

Pending any last minute issues, this should be the final SHA bump before
release.

Change-Id: I0e5677bbab614b3e1dd34d86059d8fdcf38c6c07
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/438934/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/capping_nova_workers-349f0f4d3fd50b37.yaml', 'releasenotes/notes/capping_repo_nginx_workers-ddbc355855f8fe43.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/cap-workers-fc70b4f8586ba1a5.yaml', 'releasenotes/notes/capping_neutron_workers-d97a5d50ca996af5.yaml', 'releasenotes/notes/capping_heat_workers-13791c456e59277d.yaml', 'releasenotes/notes/capping_glance_workers-54afc20c20baa14e.yaml', 'releasenotes/notes/capping_horizon_workers-29ecc4893bcc3a4b.yaml', 'ansible-role-requirements.yml', 'releasenotes/notes/capping_keystone_workers-e284a47fc4dcea38.yaml']",11,1515c99e48834058bb0855447d1fab8b71f85a65,,--- features: - Capping the default value for the variable ``keystone_wsgi_processes`` to 16 when the user doesn't configure this variable. Default value is half the number of vCPUs available on the machine with a capping value of 16. ,,94,46
openstack%2Fkeystone~master~I3431381abfe4d9fd15512c5c7beb6ab0028dc38e,openstack/keystone,master,I3431381abfe4d9fd15512c5c7beb6ab0028dc38e,Ensure migration file names are unique to avoid caching errors,MERGED,2017-02-06 22:45:55.000000000,2017-02-28 15:17:59.000000000,2017-02-28 15:17:59.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 17846}, {'_account_id': 18338}]","[{'number': 1, 'created': '2017-02-06 22:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/be12a82f2dc2afc84a47279abecba0fba05aeed5', 'message': 'WIP - Ensure migration file names are unique\n\nChange-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e\n'}, {'number': 2, 'created': '2017-02-06 22:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1773894590dd1d3d5b06b1a6861fa9dd06617708', 'message': 'WIP - Ensure migration file names are unique by requiring a prefix\n\nCloses-Bug: #1658116\nChange-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e\n'}, {'number': 3, 'created': '2017-02-07 15:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23b375a06a38d4be708fb12c09a82bdb6ac5ce8a', 'message': 'WIP - Ensure migration file names are unique by requiring a prefix\n\nCloses-Bug: #1658116\nChange-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e\n'}, {'number': 4, 'created': '2017-02-07 15:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/10d6df2c8f9fd8392c6883813ccaecb7b343e360', 'message': 'Ensure migration file names are unique to avoid caching errors\n\nThis patch requires migration files to include a prefix (expand,\nmigrate, contract) in order to keep them unique and prevent a bug\nrelated to caching. Here is the standard format:\n[version]_[prefix]_[description]\n\nFor example:\n* 001_expand_new_fk_constraint.py\n* 001_migrate_new_fk_constraint.py\n* 001_contract_new_fk_constraint.py\n\nCloses-Bug: #1658116\nChange-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e\n'}, {'number': 5, 'created': '2017-02-08 17:12:33.000000000', 'files': ['keystone/tests/unit/test_sql_upgrade.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/eb1c186f10a4d0cfdcc53fbcf49c005cd9c4349d', 'message': 'Ensure migration file names are unique to avoid caching errors\n\nThis patch requires migration files to include a prefix (expand,\nmigrate, contract) in order to keep them unique and prevent a bug\nrelated to caching. Here is the standard format:\n[version]_[prefix]_[description]\n\nFor example:\n* 001_expand_new_fk_constraint.py\n* 001_migrate_new_fk_constraint.py\n* 001_contract_new_fk_constraint.py\n\nCloses-Bug: #1658116\nChange-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e\n'}]",13,429912,eb1c186f10a4d0cfdcc53fbcf49c005cd9c4349d,23,6,5,18338,,,0,"Ensure migration file names are unique to avoid caching errors

This patch requires migration files to include a prefix (expand,
migrate, contract) in order to keep them unique and prevent a bug
related to caching. Here is the standard format:
[version]_[prefix]_[description]

For example:
* 001_expand_new_fk_constraint.py
* 001_migrate_new_fk_constraint.py
* 001_contract_new_fk_constraint.py

Closes-Bug: #1658116
Change-Id: I3431381abfe4d9fd15512c5c7beb6ab0028dc38e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/12/429912/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_sql_upgrade.py'],1,be12a82f2dc2afc84a47279abecba0fba05aeed5,bug/1658116,"import os def test_migrate_repos_file_names_have_prefix(self): versions_path = '/versions' # test expand expand_list = os.listdir( self.repos[EXPAND_REPO].repo_path + versions_path) self.assertRepoFileNamePrefix(expand_list, 'expand') # test migrate migrate_list = os.listdir( self.repos[DATA_MIGRATION_REPO].repo_path + versions_path) self.assertRepoFileNamePrefix(migrate_list, 'migrate') # test contract contract_list = os.listdir( self.repos[CONTRACT_REPO].repo_path + versions_path) self.assertRepoFileNamePrefix(contract_list, 'contract') def assertRepoFileNamePrefix(self, repo_list, prefix): if(len(repo_list) > 1): file_name = sorted(repo_list)[-2] pattern = '^[0-9]{3,}_PREFIX_|^[0-9]{3,}_placeholder.py' pattern = pattern.replace('PREFIX', prefix) self.assertRegexpMatches(file_name, pattern) ",,23,0
openstack%2Fopenstack-manuals~master~I5cb5ac0f00948c1185b00d16df4758c2ea6239fa,openstack/openstack-manuals,master,I5cb5ac0f00948c1185b00d16df4758c2ea6239fa,"Use 'openstack' command to replace ""neutron""",ABANDONED,2017-02-28 08:37:27.000000000,2017-02-28 15:17:50.000000000,,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14151}, {'_account_id': 14643}]","[{'number': 1, 'created': '2017-02-28 08:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/89f415182844b07dee8964119304061a29b23853', 'message': ""Use 'openstack' command to replace the neutron commands\n\nChange-Id: I5cb5ac0f00948c1185b00d16df4758c2ea6239fa\nImplements: blueprint use-openstack-command\n""}, {'number': 2, 'created': '2017-02-28 08:56:13.000000000', 'files': ['doc/ops-guide/source/ops-maintenance-compute.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b93422cc8d32bf9e14b4b4eb09b47a74be82cc3d', 'message': 'Use \'openstack\' command to replace ""neutron""\n\nChange-Id: I5cb5ac0f00948c1185b00d16df4758c2ea6239fa\nImplements: blueprint use-openstack-command\n'}]",0,438848,b93422cc8d32bf9e14b4b4eb09b47a74be82cc3d,8,4,2,22165,,,0,"Use 'openstack' command to replace ""neutron""

Change-Id: I5cb5ac0f00948c1185b00d16df4758c2ea6239fa
Implements: blueprint use-openstack-command
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/438848/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops-maintenance-compute.rst'],1,89f415182844b07dee8964119304061a29b23853,bp/use-openstack-command," $ openstack port create --network Public_AGILE PORT_NAME +-----------------------+-----------------------------------------------------------------------------+ | Field | Value | +-----------------------+-----------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | | | binding_host_id | | | binding_profile | | | binding_vif_details | | | binding_vif_type | unbound | | binding_vnic_type | normal | | created_at | 2017-02-28T08:18:07Z | | description | | | device_id | | | device_owner | | | extra_dhcp_opts | | | fixed_ips | ip_address='96.118.182.4', subnet_id='e21e9a6c-6958-4a4f-a578-11cfb7229f47' | | headers | | | id | 787ceaf8-b0da-4404-a57b-4ec21f4ac473 | | mac_address | fa:16:3e:8b:d6:8c | | name | PORT_NAME | | network_id | fb94202c-2765-439a-b329-524478fcb498 | | project_id | 8cec6038784543ceb0996f366d5b5eae | | project_id | 8cec6038784543ceb0996f366d5b5eae | | revision_number | 4 | | security_groups | 1c4b41a4-88fe-4c77-87d5-ac42d6afc543 | | status | DOWN | | updated_at | 2017-02-28T08:18:07Z | +-----------------------+-----------------------------------------------------------------------------+ $ openstack port create --network Public_AGILE \ +-----------------------+------------------------------------------------------------------------------+ | Field | Value | +-----------------------+------------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | | | binding_host_id | | | binding_profile | | | binding_vif_details | | | binding_vif_type | unbound | | binding_vnic_type | normal | | created_at | 2017-02-28T08:23:31Z | | description | | | device_id | | | device_owner | | | extra_dhcp_opts | | | fixed_ips | ip_address='96.118.182.14', subnet_id='e21e9a6c-6958-4a4f-a578-11cfb7229f47' | | headers | | | id | b9d4dba6-8680-488e-bf6b-192e4b35bb43 | | mac_address | fa:16:3e:ec:09:f5 | | name | example-fqdn-01.sys.example.com | | network_id | fb94202c-2765-439a-b329-524478fcb498 | | project_id | 8cec6038784543ceb0996f366d5b5eae | | project_id | 8cec6038784543ceb0996f366d5b5eae | | revision_number | 4 | | security_groups | 1c4b41a4-88fe-4c77-87d5-ac42d6afc543 | | status | DOWN | | updated_at | 2017-02-28T08:23:31Z | +-----------------------+------------------------------------------------------------------------------+ $ openstack port list | grep -B1 96.118.182.107 $ for i in {0..10}; do openstack port create --network Public_AGILE \ $ openstack port set 731c3b28-3753-4e63-bae3-b58a52d6ccca \ $ for port in $(openstack port list | grep -i ip-recovery | \ awk '{print $2}'); do openstack port delete $port; done"," $ neutron port-create Public_AGILE +-----------------------+-------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------+ | admin_state_up | True | | allowed_address_pairs | | | binding:host_id | | | binding:profile | {} | | binding:vif_details | {} | | binding:vif_type | unbound | | binding:vnic_type | normal | | device_id | | | device_owner | | | fixed_ips | {""subnet_id"": ""11d8087b-6288-4129-95ff... | | | ""ip_address"": ""2001:558:fc0b:100:f816:... | | | {""subnet_id"": ""4279c70a-7218-4c7e-94e5... | | | ""ip_address"": ""96.118.182.106""} | | id | 3871bf29-e963-4701-a7dd-8888dbaab375 | | mac_address | fa:16:3e:e2:09:e0 | | name | | | network_id | f41bd921-3a59-49c4-aa95-c2e4496a4b56 | | security_groups | 20d96891-0055-428a-8fa6-d5aed25f0dc6 | | status | DOWN | | tenant_id | 52f0574689f14c8a99e7ca22c4eb572 | +-----------------------+-------------------------------------------+ $ neutron port-create Public_AGILE --name \ +-----------------------+--------------------------------------------+ | Field | Value | +-----------------------+--------------------------------------------+ | admin_state_up | True | | allowed_address_pairs | | | binding:host_id | | | binding:profile | {} | | binding:vif_details | {} | | binding:vif_type | unbound | | binding:vnic_type | normal | | device_id | | | device_owner | | | fixed_ips | {""subnet_id"": ""11d8087b-6288-4129-95ff... | | | ""ip_address"": ""2001:558:fc0b:100:f816:... | | | {""subnet_id"": ""4279c70a-7218-4c7e-94e5... | | | ""ip_address"": ""96.118.182.107""} | | id | 731c3b28-3753-4e63-bae3-b58a52d6ccca | | mac_address | fa:16:3e:fb:65:fc | | name | example-fqdn-01.sys.example.com | | network_id | f41bd921-3a59-49c4-aa95-c2e4496a4b56 | | security_groups | 20d96891-0055-428a-8fa6-d5aed25f0dc6 | | status | DOWN | | tenant_id | 52f0574689f14c8a99e7ca22c4eb5720 | +-----------------------+--------------------------------------------+ $ neutron port-list | grep -B1 96.118.182.107 $ for i in {0..10}; do neutron port-create Public_AGILE --name \ $ neutron port-update 731c3b28-3753-4e63-bae3-b58a52d6ccca \ $ for port in $(neutron port-list | grep -i ip-recovery | \ awk '{print $2}'); do neutron port-delete $port; done",63,56
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Focata~Ibd3796cc78060016d4099ccb4ed176f6666f73f8,openstack/openstack-ansible-lxc_hosts,stable/ocata,Ibd3796cc78060016d4099ccb4ed176f6666f73f8,Support user shell commands during cache prep,MERGED,2017-02-28 14:49:15.000000000,2017-02-28 15:16:53.000000000,2017-02-28 15:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-28 14:49:15.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/20286090e2bf611023d0d3b4c12b17db5734e11f', 'message': 'Support user shell commands during cache prep\n\nSupport running user shell comamnds before/after the LXC cache build\nprocess without requiring a complete override of the cache map dict.\n\nChange-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8\n(cherry picked from commit ba800949ed712b5245e7471ba9834384a5cd9a5d)\n'}]",0,438983,20286090e2bf611023d0d3b4c12b17db5734e11f,8,3,1,17799,,,0,"Support user shell commands during cache prep

Support running user shell comamnds before/after the LXC cache build
process without requiring a complete override of the cache map dict.

Change-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8
(cherry picked from commit ba800949ed712b5245e7471ba9834384a5cd9a5d)
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/83/438983/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml']",3,20286090e2bf611023d0d3b4c12b17db5734e11f,cache-prep-user-cmd,# Custom shell commands to run before/after the LXC cache prep process has taken # place. lxc_cache_prep_pre_commands: '## pre command skipped ##' lxc_cache_prep_post_commands: '## post command skipped ##' ,,9,0
openstack%2Fopenstack-manuals~master~Ic22b70ba55d15755457056426fb61c1bd446a477,openstack/openstack-manuals,master,Ic22b70ba55d15755457056426fb61c1bd446a477,[arch-design-draft] Compute - Overcommit Section,MERGED,2017-02-27 17:47:45.000000000,2017-02-28 15:16:18.000000000,2017-02-28 15:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14947}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-02-27 17:47:45.000000000', 'files': ['doc/arch-design-draft/source/design-compute/design-compute-overcommit.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/91c5ed9718f3e07c7f8918d10f64ceedced3aab6', 'message': '[arch-design-draft] Compute - Overcommit Section\n\n- Removed networking and logging section - redundant\n\nChange-Id: Ic22b70ba55d15755457056426fb61c1bd446a477\nImplements: blueprint arch-guide-pike\n'}]",0,438643,91c5ed9718f3e07c7f8918d10f64ceedced3aab6,8,4,1,14870,,,0,"[arch-design-draft] Compute - Overcommit Section

- Removed networking and logging section - redundant

Change-Id: Ic22b70ba55d15755457056426fb61c1bd446a477
Implements: blueprint arch-guide-pike
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/438643/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design-draft/source/design-compute/design-compute-overcommit.rst'],1,91c5ed9718f3e07c7f8918d10f64ceedced3aab6,bp/arch-guide-pike,," Logging ~~~~~~~ Logging is described in more detail in `Logging and Monitoring <https://docs.openstack.org/ops-guide/ops-logging-monitoring.html>`_. However, it is an important design consideration to take into account before commencing operations of your cloud. OpenStack produces a great deal of useful logging information, however, for the information to be useful for operations purposes, you should consider having a central logging server to send logs to, and a log parsing/analysis system (such as logstash). Networking ~~~~~~~~~~ Networking in OpenStack is a complex, multifaceted challenge. See :doc:`../design-networking/design-networking-concepts`.",0,19
openstack%2Fsahara-image-elements~master~I1e29cce101e44fc82e27b5e7986101847be0da8d,openstack/sahara-image-elements,master,I1e29cce101e44fc82e27b5e7986101847be0da8d,Fix: DIB_RELEASE is not defined on CentOS,MERGED,2017-02-27 10:22:57.000000000,2017-02-28 15:16:13.000000000,2017-02-28 15:16:13.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8932}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2017-02-27 10:22:57.000000000', 'files': ['elements/hadoop-mapr/install.d/41-scala'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/591bfed8f045b88b29c4c627e1c8106080dabd3a', 'message': 'Fix: DIB_RELEASE is not defined on CentOS\n\nOtherwise an ""unbound variable"" error is thrown.\n\nChange-Id: I1e29cce101e44fc82e27b5e7986101847be0da8d\n'}]",0,438413,591bfed8f045b88b29c4c627e1c8106080dabd3a,8,5,1,10459,,,0,"Fix: DIB_RELEASE is not defined on CentOS

Otherwise an ""unbound variable"" error is thrown.

Change-Id: I1e29cce101e44fc82e27b5e7986101847be0da8d
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/13/438413/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/hadoop-mapr/install.d/41-scala'],1,591bfed8f045b88b29c4c627e1c8106080dabd3a,,"if [ ""trusty"" == ""${DIB_RELEASE:-}"" ]; then","if [ ""trusty"" == ""${DIB_RELEASE}"" ]; then",1,1
openstack%2Fbifrost~master~Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06,openstack/bifrost,master,Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06,Workaround for network start race condition,MERGED,2017-02-24 20:58:02.000000000,2017-02-28 15:15:16.000000000,2017-02-28 15:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6133}, {'_account_id': 9542}, {'_account_id': 11655}, {'_account_id': 14826}, {'_account_id': 22474}, {'_account_id': 23330}]","[{'number': 1, 'created': '2017-02-24 20:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/bcaf47d9a41155e9d749e9462762a56ac61b584e', 'message': 'Workaround for network start race condition\n\nAdd some debug and a possible workaround for the libvirt network\nstart race condition bug\n(https://bugs.launchpad.net/bifrost/+bug/1660953)\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\n'}, {'number': 2, 'created': '2017-02-24 21:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/cb6ddad8142f5dc346c3dfccf25cfb1d5ac1b0e8', 'message': 'Workaround for network start race condition\n\nAdd some debug and a possible workaround for the libvirt network\nstart race condition bug\n(https://bugs.launchpad.net/bifrost/+bug/1660953)\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\n'}, {'number': 3, 'created': '2017-02-24 23:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/593fa7b199728ae9de0acab897d267edb1fc1d3a', 'message': 'Workaround for network start race condition\n\nAdd some debug and a possible workaround for the libvirt network\nstart race condition bug\n(https://bugs.launchpad.net/bifrost/+bug/1660953)\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\n'}, {'number': 4, 'created': '2017-02-25 13:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/78d2a1b1f30378ee364e3b41c916b4acec2b444b', 'message': 'Workaround for network start race condition\n\nAdd some debug and a possible workaround for the libvirt network\nstart race condition bug\n(https://bugs.launchpad.net/bifrost/+bug/1660953)\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\n'}, {'number': 5, 'created': '2017-02-25 18:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0737a5869360eb8e691d4561aa067b51d7efef18', 'message': 'Workaround for network start race condition\n\nAdd some debug and a possible workaround for the libvirt network\nstart race condition bug\n(https://bugs.launchpad.net/bifrost/+bug/1660953)\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\n'}, {'number': 6, 'created': '2017-02-27 15:03:53.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9c18eeac6d0072522e2537f3848b577ddb3a690d', 'message': 'Workaround for network start race condition\n\nAdd a workaround for the libvirt network start race condition bug. In\nsome cases the libvirt default network starts in an inactive state\nwith the bridge interface down. Trying to start the network via libvirt\nfails because the network interface already exists. This condition is\nchecked for and ignored but causes the Bifrost deployment test to fail\nlater when templating ironic.conf as the configured network interface\nhas no IP address.\n\nThis change checks for the condition where the libvirt default network\nis inactive and attempts to delete the associated bridge interface\nbefore starting the libvirt network. This has been run through the CI\njob and appears to resolve the issue.\n\nChange-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06\nCloses-Bug: #1660953\nRelated-Bug: #1650025\n'}]",0,438076,9c18eeac6d0072522e2537f3848b577ddb3a690d,43,8,6,14826,,,0,"Workaround for network start race condition

Add a workaround for the libvirt network start race condition bug. In
some cases the libvirt default network starts in an inactive state
with the bridge interface down. Trying to start the network via libvirt
fails because the network interface already exists. This condition is
checked for and ignored but causes the Bifrost deployment test to fail
later when templating ironic.conf as the configured network interface
has no IP address.

This change checks for the condition where the libvirt default network
is inactive and attempts to delete the associated bridge interface
before starting the libvirt network. This has been run through the CI
job and appears to resolve the issue.

Change-Id: Icb2baf0975ca3feb6041b2f2da9702ad6cc9fa06
Closes-Bug: #1660953
Related-Bug: #1650025
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/76/438076/5 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml']",2,bcaf47d9a41155e9d749e9462762a56ac61b584e,bug/1660953,"- name: ""Fail if the network interface does not exist"" fail: msg: > The configured network interface {{ network_interface }} does not exist when: ""{{ 'ansible_' ~ ans_network_interface not in hostvars[inventory_hostname] }}"" - name: ""Fail if the network interface has no IP address assigned"" fail: msg: > The configured network interface {{ network_interface }} does not have an IP address assigned when: ""{{ not hostvars['ansible_' ~ ans_network_interface].get('ipv4', {}).get('address') }}""",,45,1
openstack%2Fopenstack-ansible-os_keystone~master~I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31,openstack/openstack-ansible-os_keystone,master,I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31,Conditionally run appropriate db_sync commands,MERGED,2017-02-10 06:31:57.000000000,2017-02-28 15:12:45.000000000,2017-02-28 15:12:45.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-10 06:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/56381418fceb50f55686f3a63479b4eda7e75d4f', 'message': ""Conditionally run appropriate db_sync commands\n\nTake advantage of the return code given by keystone_manage db_sync's\n'check' option to conditionally run the appropriate database migration\ncommands.\n\n0 - currently up to date\n1 - error requiring operator intervention\n2 - expand required\n3 - migrate required\n4 - contract required\n\nRelated-Bug: 1642212\nChange-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31\n""}, {'number': 2, 'created': '2017-02-10 07:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3d45fae73e3eb410c311b7caf160c79b313b4215', 'message': ""Conditionally run appropriate db_sync commands\n\nTake advantage of the return code given by keystone_manage db_sync's\n'check' option to conditionally run the appropriate database migration\ncommands.\n\n0 - currently up to date\n1 - error requiring operator intervention\n2 - expand required\n3 - migrate required\n4 - contract required\n\nRelated-Bug: 1642212\nChange-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31\n""}, {'number': 3, 'created': '2017-02-24 18:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/da86f64ae3626e0fb7347e7252c03e837993631e', 'message': ""Conditionally run appropriate db_sync commands\n\nTake advantage of the return code given by keystone_manage db_sync's\n'check' option to conditionally run the appropriate database migration\ncommands.\n\n0 - currently up to date\n1 - error requiring operator intervention\n2 - expand required\n3 - migrate required\n4 - contract required\n\nRelated-Bug: 1642212\nChange-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31\n""}, {'number': 4, 'created': '2017-02-28 00:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/ce2ef9881027f9d255cf1cf9c2c13460996bab6d', 'message': ""Conditionally run appropriate db_sync commands\n\nTake advantage of the return code given by keystone_manage db_sync's\n'check' option to conditionally run the appropriate database migration\ncommands.\n\n0 - currently up to date\n1 - error requiring operator intervention\n2 - expand required\n3 - migrate required\n4 - contract required\n\nRelated-Bug: 1642212\nChange-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31\n""}, {'number': 5, 'created': '2017-02-28 00:47:39.000000000', 'files': ['tasks/keystone_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/d2e00019b49e6a07adb89b84536921a06c19ff0e', 'message': ""Conditionally run appropriate db_sync commands\n\nTake advantage of the return code given by keystone_manage db_sync's\n'check' option to conditionally run the appropriate database migration\ncommands.\n\n0 - currently up to date\n1 - error requiring operator intervention\n2 - expand required\n3 - migrate required\n4 - contract required\n\nRelated-Bug: 1642212\nChange-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31\n""}]",9,432134,d2e00019b49e6a07adb89b84536921a06c19ff0e,22,4,5,14805,,,0,"Conditionally run appropriate db_sync commands

Take advantage of the return code given by keystone_manage db_sync's
'check' option to conditionally run the appropriate database migration
commands.

0 - currently up to date
1 - error requiring operator intervention
2 - expand required
3 - migrate required
4 - contract required

Related-Bug: 1642212
Change-Id: I129590ff6ac4e45bfd9b3ea21ad6615f66d37d31
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/34/432134/5 && git format-patch -1 --stdout FETCH_HEAD,['tasks/keystone_db_setup.yml'],1,56381418fceb50f55686f3a63479b4eda7e75d4f,bug/1642212,"- name: Check current state of Keystone DB command: ""{{ keystone_bin }}/keystone-manage db_sync --check"" register: keystone_db_sync_check failed_when: keystone_db_sync_check.rc == 1 changed_when: keystone_db_sync_check.rc == 4 notify: - Perform a Keystone DB sync contract register: keystone_db_sync_expand when: keystone_db_sync_check.rc == 2 when: (keystone_db_sync_check.rc == 3) or (keystone_db_sync_expand.changed)", changed_when: true changed_when: true,11,2
openstack%2Fkolla-ansible~stable%2Focata~I350ee69b0eca7a1763bb7eab34f874d7e22c1340,openstack/kolla-ansible,stable/ocata,I350ee69b0eca7a1763bb7eab34f874d7e22c1340,Add until in restart nova libvirt task,MERGED,2017-02-28 06:42:44.000000000,2017-02-28 15:11:20.000000000,2017-02-28 15:11:20.000000000,"[{'_account_id': 3}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22582}]","[{'number': 1, 'created': '2017-02-28 06:42:44.000000000', 'files': ['ansible/roles/nova/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/203fd79d59bc309b641e6f06d0bc26b673966527', 'message': 'Add until in restart nova libvirt task\n\nretries only works with until.\n\nChange-Id: I350ee69b0eca7a1763bb7eab34f874d7e22c1340\nCloses-bug: #1668023\n(cherry picked from commit 242c559a044ede8c20134ba40f6643719498c6a2)\n'}]",0,438817,203fd79d59bc309b641e6f06d0bc26b673966527,9,5,1,7488,,,0,"Add until in restart nova libvirt task

retries only works with until.

Change-Id: I350ee69b0eca7a1763bb7eab34f874d7e22c1340
Closes-bug: #1668023
(cherry picked from commit 242c559a044ede8c20134ba40f6643719498c6a2)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/17/438817/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/handlers/main.yml'],1,203fd79d59bc309b641e6f06d0bc26b673966527,bug/1668023, register: restart_nova_libvirt until: restart_nova_libvirt | success,,2,0
openstack%2Ftripleo-quickstart-extras~master~Ifcca245b67077a903fca5dac8f1cb73b6423cf6c,openstack/tripleo-quickstart-extras,master,Ifcca245b67077a903fca5dac8f1cb73b6423cf6c,Add disk root device hints,MERGED,2017-02-14 15:06:41.000000000,2017-02-28 15:10:52.000000000,2017-02-28 15:10:52.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-02-14 15:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/61fee3469ce52f103a7cf1d606512ee5ce22114f', 'message': 'WIP: Add disk root device hints to OOOQ\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}, {'number': 2, 'created': '2017-02-14 16:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d77670f5acdef42e9f8990fbb5b25e848076e3b2', 'message': 'WIP: Add disk root device hints to OOOQ\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}, {'number': 3, 'created': '2017-02-14 17:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c21e6ff386f0745f3e6b31285652b3ba6c763399', 'message': 'Add disk root device hints\n\nIt currently just supported disk hints by size. Add the\npossibility to give root device hints by any or the ironic\nsupported properties.\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}, {'number': 4, 'created': '2017-02-14 17:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8050d2be9481102d1a6d0f76c78e6c8286b6fb44', 'message': 'Add disk root device hints\n\nIt currently just supported disk hints by size. Add the\npossibility to give root device hints by any or the ironic\nsupported properties.\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}, {'number': 5, 'created': '2017-02-15 10:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/86c9f3dde332d588a978502025f86e640d1ee68b', 'message': 'Add disk root device hints\n\nIt currently just supported disk hints by size. Add the\npossibility to give root device hints by any or the ironic\nsupported properties.\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}, {'number': 6, 'created': '2017-02-15 15:40:09.000000000', 'files': ['roles/overcloud-prep-images/README.md', 'releasenotes/notes/root-device-hints-a8a6e41ec851ec12.yaml', 'roles/collect-logs/docs/static/baremetal-overcloud/env-specific-pre-deploy-steps.rst', 'roles/overcloud-prep-images/templates/overcloud-prep-images.sh.j2', 'roles/overcloud-prep-images/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/75f5b56ad4232b68f57d7a802e5df9817e28be94', 'message': 'Add disk root device hints\n\nIt currently just supported disk hints by size. Add the\npossibility to give root device hints by any or the ironic\nsupported properties.\n\nChange-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c\n'}]",6,433691,75f5b56ad4232b68f57d7a802e5df9817e28be94,33,7,6,6133,,,0,"Add disk root device hints

It currently just supported disk hints by size. Add the
possibility to give root device hints by any or the ironic
supported properties.

Change-Id: Ifcca245b67077a903fca5dac8f1cb73b6423cf6c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/91/433691/2 && git format-patch -1 --stdout FETCH_HEAD,"['roles/overcloud-prep-images/README.md', 'releasenotes/notes/root-device-hints-a8a6e41ec851ec12.yaml', 'roles/collect-logs/docs/static/baremetal-overcloud/env-specific-pre-deploy-steps.rst']",3,61fee3469ce52f103a7cf1d606512ee5ce22114f,,- Adding disk hints,- Adding disk size hints,40,1
openstack%2Fnetworking-ovn~master~Iba0d5b8b3d91a7caeef00d2576ca271f3b0a6bc2,openstack/networking-ovn,master,Iba0d5b8b3d91a7caeef00d2576ca271f3b0a6bc2,Improve OVN DB sync dsvm-functional test for external gateway,MERGED,2017-02-27 12:29:21.000000000,2017-02-28 15:09:01.000000000,2017-02-28 15:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-27 12:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6a9397c0162d8a831019b3d9203877ef613bc187', 'message': 'Improve OVN DB sync functional test for external gateway\n\nThis patch improves OVN DB sync dsvm-functional test for external gateway,\ngateway default route, gateway sNATs and floating ips.\n\nChange-Id: Iba0d5b8b3d91a7caeef00d2576ca271f3b0a6bc2\nDepends-on: Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1\nDepends-on: I4161f870e819e55963867a33d09580d4b81ad4ad\nCloses-Bug: #1665388\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 2, 'created': '2017-02-28 02:31:24.000000000', 'files': ['networking_ovn/tests/functional/test_ovn_db_sync.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/76c481f2a3044a0acc882405f9a919ca51446efa', 'message': 'Improve OVN DB sync dsvm-functional test for external gateway\n\nThis patch improves OVN DB sync dsvm-functional test for external gateway,\ngateway default route, gateway sNATs and floating ips.\n\nChange-Id: Iba0d5b8b3d91a7caeef00d2576ca271f3b0a6bc2\nCloses-Bug: #1665388\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,438470,76c481f2a3044a0acc882405f9a919ca51446efa,9,3,2,23458,,,0,"Improve OVN DB sync dsvm-functional test for external gateway

This patch improves OVN DB sync dsvm-functional test for external gateway,
gateway default route, gateway sNATs and floating ips.

Change-Id: Iba0d5b8b3d91a7caeef00d2576ca271f3b0a6bc2
Closes-Bug: #1665388
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/70/438470/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/tests/functional/test_ovn_db_sync.py'],1,6a9397c0162d8a831019b3d9203877ef613bc187,bug/1665388,"from neutron_lib.api.definitions import l3 self.create_lrouter_nats = [] self.delete_lrouter_nats = [] self.lport_dhcp_ignored = [] n1_port_dict = {} n1_port_dict[p] = port['port']['id'] # External network and subnet e1 = self._make_network(self.fmt, 'e1', True, arg_list=('router:external', ), **{'router:external': True}) self.assertEqual(True, e1['network']['router:external']) res = self._create_subnet(self.fmt, e1['network']['id'], '100.0.0.0/24', gateway_ip='100.0.0.1', enable_dhcp=False) e1_s1 = self.deserialize(self.fmt, res) {'router': { 'name': 'r1', 'admin_state_up': True, 'tenant_id': self._tenant_id, 'external_gateway_info': { 'enable_snat': True, 'network_id': e1['network']['id'], 'external_fixed_ips': [ {'ip_address': '100.0.0.2', 'subnet_id': e1_s1['subnet']['id']}]}}}) self.delete_lrouter_ports.append(('lrp-' + r1['gw_port_id'], 'neutron-' + r1['id'])) r1_f1 = self.l3_plugin.create_floatingip( self.context, {'floatingip': { 'tenant_id': self._tenant_id, 'floating_network_id': e1['network']['id'], 'floating_ip_address': '100.0.0.20', 'port_id': n1_port_dict['p1']}}) r1_f2 = self.l3_plugin.create_floatingip( self.context, {'floatingip': { 'tenant_id': self._tenant_id, 'floating_network_id': e1['network']['id'], 'floating_ip_address': '100.0.0.21'}}) self.l3_plugin.update_floatingip( self.context, r1_f2['id'], {'floatingip': { 'port_id': n1_port_dict['p2']}}) # Static routes # Gateway default route self.delete_lrouter_routes.append(('neutron-' + r1['id'], '0.0.0.0/0', '100.0.0.1')) # Gateway sNATs self.create_lrouter_nats.append(('neutron-' + r1['id'], '100.0.0.100', '200.0.0.0/24', 'snat')) self.delete_lrouter_nats.append(('neutron-' + r1['id'], '100.0.0.2', '10.0.0.0/24', 'snat')) # Floating IPs self.create_lrouter_nats.append(('neutron-' + r1['id'], '100.0.0.200', '200.0.0.200', 'dnat_and_snat')) self.delete_lrouter_nats.append(('neutron-' + r1['id'], r1_f1['floating_ip_address'], r1_f1['fixed_ip_address'], 'dnat_and_snat')) n4 = self._make_network(self.fmt, 'n4', True) res = self._create_subnet(self.fmt, n4['network']['id'], '40.0.0.0/24', enable_dhcp=False) n4_s1 = self.deserialize(self.fmt, res) n4_port_dict = {} for p in ['p1', 'p2']: port = self._make_port(self.fmt, n4['network']['id'], name='n4-' + p, device_owner='compute:None') n4_port_dict[p] = port['port']['id'] self.lport_dhcp_ignored.append(port['port']['id']) self.l3_plugin.add_router_interface( self.context, r2['id'], {'subnet_id': n4_s1['subnet']['id']}) 'nexthop': '10.0.0.20'}], 'external_gateway_info': { 'enable_snat': False, 'network_id': e1['network']['id'], 'external_fixed_ips': [ {'ip_address': '100.0.0.3', 'subnet_id': e1_s1['subnet']['id']}]}}}) self.l3_plugin.create_floatingip( self.context, {'floatingip': { 'tenant_id': self._tenant_id, 'floating_network_id': e1['network']['id'], 'floating_ip_address': '100.0.0.30', 'port_id': n4_port_dict['p1']}}) self.l3_plugin.create_floatingip( self.context, {'floatingip': { 'tenant_id': self._tenant_id, 'floating_network_id': e1['network']['id'], 'floating_ip_address': '100.0.0.31', 'port_id': n4_port_dict['p2']}}) for lrouter_name, external_ip, logical_ip, nat_type in( self.create_lrouter_nats): txn.add(cmd.AddNATRuleInLRouterCommand( fake_api, lrouter_name, external_ip=external_ip, logical_ip=logical_ip, type=nat_type)) for lrouter_name, external_ip, logical_ip, nat_type in( self.delete_lrouter_nats): txn.add(cmd.DeleteNATRuleInLRouterCommand( fake_api, lrouter_name, external_ip=external_ip, logical_ip=logical_ip, type=nat_type, if_exists=True)) db_port_ids = [port['id'] for port in db_ports['ports'] if port['device_owner'] != constants.DEVICE_OWNER_FLOATINGIP] constants.DEVICE_OWNER_PREFIXES) and port['id'] not in self.lport_dhcp_ignored) db_nats = {} db_nats[db_router['id']] = [] if db_router.get(l3.EXTERNAL_GW_INFO): r_ip, gw_ip = self.l3_plugin.\ get_external_router_and_gateway_ip(self.context, db_router) # Add gateway default route and snats if gw_ip: db_routes[db_router['id']].append('0.0.0.0/0' + gw_ip) if r_ip and utils.is_snat_enabled(db_router): networks = self.l3_plugin.\ _get_v4_network_of_all_router_ports(self.context, db_router['id']) db_nats[db_router['id']].extend([r_ip + network + 'snat' for network in networks]) fips = self._list('floatingips') for fip in fips['floatingips']: db_nats[fip['router_id']].append(fip['floating_ip_address'] + fip['fixed_ip_address'] + 'dnat_and_snat') r_nats = db_nats[router_id] nats = getattr(lrouter, 'nat', []) plugin_nats = [nat.external_ip + nat.logical_ip + nat.type for nat in nats] plugin_nats = [] nats = getattr(lrouter, 'nat', []) monitor_nats = [nat.external_ip + nat.logical_ip + nat.type for nat in nats] monitor_nats = [] self.assertItemsEqual(r_nats, plugin_nats) self.assertItemsEqual(r_nats, monitor_nats) self.assertRaises( AssertionError, self.assertItemsEqual, r_nats, plugin_nats) self.assertRaises( AssertionError, self.assertItemsEqual, r_nats, monitor_nats) "," {'router': {'name': 'r1', 'admin_state_up': True, 'tenant_id': self._tenant_id}}) 'nexthop': '10.0.0.20'}]}}) db_port_ids = [port['id'] for port in db_ports['ports']] constants.DEVICE_OWNER_PREFIXES))",151,5
openstack%2Fopenstack-ansible-os_gnocchi~stable%2Focata~Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc,openstack/openstack-ansible-os_gnocchi,stable/ocata,Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc,Fix gnocchi endpoint variable names,MERGED,2017-02-27 18:13:07.000000000,2017-02-28 15:08:14.000000000,2017-02-28 15:08:14.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 11268}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-27 18:13:07.000000000', 'files': ['releasenotes/notes/var-rename-gnocchi-endpoints-87626018773f77e0.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_gnocchi/commit/7d9bcbeff77a2d6055e9140629bf7d71d4887db4', 'message': 'Fix gnocchi endpoint variable names\n\nFixed the gnocchi endpoint variable names to be consistent with other roles.\n\nChange-Id: Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc\n(cherry picked from commit 236c943d4ce8942a9c773cca52a9c9567eef9843)\n'}]",0,438662,7d9bcbeff77a2d6055e9140629bf7d71d4887db4,8,4,1,25128,,,0,"Fix gnocchi endpoint variable names

Fixed the gnocchi endpoint variable names to be consistent with other roles.

Change-Id: Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc
(cherry picked from commit 236c943d4ce8942a9c773cca52a9c9567eef9843)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_gnocchi refs/changes/62/438662/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/var-rename-gnocchi-endpoints-87626018773f77e0.yaml', 'defaults/main.yml']",2,7d9bcbeff77a2d6055e9140629bf7d71d4887db4,,"gnocchi_service_publicuri: ""{{ gnocchi_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_publicurl: ""{{ gnocchi_service_publicuri }}"" gnocchi_service_internaluri: ""{{ gnocchi_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_internalurl: ""{{ gnocchi_service_internaluri }}"" gnocchi_service_adminuri: ""{{ gnocchi_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_adminurl: ""{{ gnocchi_service_adminuri }}""","gnocchi_service_publicurl: ""{{ gnocchi_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_internalurl: ""{{ gnocchi_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_adminurl: ""{{ gnocchi_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}""",11,3
openstack%2Fdesignate~master~Iee2c117b2dff6a5d9fcf486d201da32773055dec,openstack/designate,master,Iee2c117b2dff6a5d9fcf486d201da32773055dec,[doc] Update Ubuntu dev environment doc,MERGED,2017-02-23 21:43:13.000000000,2017-02-28 15:05:45.000000000,2017-02-28 15:05:45.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-23 21:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/869fcecaedee2a46499975dddf2083db3aabd55d', 'message': '[doc] Update Ubuntu dev environment doc\n\nGet the dev doc up to date, and delete some old ones that are\noutdated.\n\nChange-Id: Iee2c117b2dff6a5d9fcf486d201da32773055dec\n'}, {'number': 2, 'created': '2017-02-27 20:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/32295fb2bb5209e681a7bdc7b142877b16798b30', 'message': '[doc] Update Ubuntu dev environment doc\n\nGet the dev doc up to date, and delete some old ones that are\noutdated.\n\nChange-Id: Iee2c117b2dff6a5d9fcf486d201da32773055dec\n'}, {'number': 3, 'created': '2017-02-28 14:29:22.000000000', 'files': ['doc/source/ubuntu-dev.rst', 'doc/source/index.rst', 'doc/source/examples/basic-config-sample.conf', 'doc/source/examples/basic-config-sample-kilo.conf', 'doc/source/examples/basic-config-sample-juno.conf'], 'web_link': 'https://opendev.org/openstack/designate/commit/9d39448ab20f13d7f2b324a9d65e256a85d44463', 'message': '[doc] Update Ubuntu dev environment doc\n\nGet the dev doc up to date, and delete some old ones that are\noutdated.\n\nChange-Id: Iee2c117b2dff6a5d9fcf486d201da32773055dec\n'}]",0,437689,9d39448ab20f13d7f2b324a9d65e256a85d44463,16,3,3,8174,,,0,"[doc] Update Ubuntu dev environment doc

Get the dev doc up to date, and delete some old ones that are
outdated.

Change-Id: Iee2c117b2dff6a5d9fcf486d201da32773055dec
",git fetch https://review.opendev.org/openstack/designate refs/changes/89/437689/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ubuntu-dev.rst', 'doc/source/index.rst', 'doc/source/examples/basic-config-sample.conf', 'doc/source/examples/basic-config-sample-kilo.conf', 'doc/source/examples/basic-config-sample-juno.conf', 'doc/source/install/ubuntu-kilo.rst', 'doc/source/install/ubuntu-liberty.rst']",7,869fcecaedee2a46499975dddf2083db3aabd55d,docs-clean-remove,,"**************************** Installing Liberty on Ubuntu **************************** This section describes how to install Designate on Ubuntu 14.04. To install other OpenStack services, see `OpenStack Installation Guide <http://docs.openstack.org/#install-guides>`_. This section assumes the Identity service runs on the host ``controller``. Install and configure Basic Environment ======================================= Enable OpenStack repository --------------------------- #. Enable the OpenStack Liberty repository: .. code-block:: console $ sudo apt-get update $ sudo apt-get install software-properties-common $ sudo add-apt-repository cloud-archive:liberty #. Upgrade the packages on your host: .. code-block:: console $ sudo apt-get update $ sudo apt-get dist-upgrade Install and configure SQL database ---------------------------------- #. Install the MariaDB packages: .. code-block:: console $ sudo apt-get install mariadb-server python-pymysql Choose a suitable password for the database root account. Install and configure message queue ----------------------------------- #. Install the RabbitMQ packages: .. code-block:: console $ sudo apt-get install rabbitmq-server #. Add the ``openstack`` user: .. code-block:: console $ sudo rabbitmqctl add_user openstack RABBIT_PASS Creating user ""openstack"" ... Replace ``RABBIT_PASS`` with a suitable password. #. Permit configuration, write, and read access for the ``openstack`` user: .. code-block:: console $ sudo rabbitmqctl set_permissions openstack "".*"" "".*"" "".*"" Setting permissions for user ""openstack"" in vhost ""/"" ... Install DNS server ================== #. Install the BIND9 packages: .. code-block:: console $ sudo apt-get install bind9 #. Add the following options in the ``/etc/bind/named.conf.options`` file: .. code-block:: none options { ... allow-new-zones yes; request-ixfr no; recursion no; }; #. Restart the DNS service: .. code-block:: console $ sudo service bind9 restart Install Designate ================= #. Install the ``designate`` package: .. code-block:: console $ sudo apt-get install designate #. In the ``Configuring designate-common`` prompt, complete the following actions: * select ``Yes`` for the question ``Set up a database for Designate?``. * enter ``localhost`` for the ``IP address of your RabbitMQ host``. * enter the ``openstack`` as ``Username for connection to the RabbitMQ server``. * enter the ``password for connection to the RabbitMQ server`` that you chose for the RabbitMQ server at the previous step. * press the ``enter`` key at the prompt ``Authentication server hostname``. * press the ``enter`` key at the prompt ``Authentication server password``. * select ``No`` for the question ``Register Designate in the Keystone endpoint catalog?``. * select ``Yes`` for the question ``Configure database for designate-common with dbconfig-common``. * select ``mysql`` for ``database type to be used by designate-common``. * enter the ``password of the database's administrative user`` that is chosen for the root account at the previous step. * enter the ``MySQL application password for designate-common``. * enter the same password as ``password confirmation``. .. note:: the ``designate-common`` package offers automatic creation of the database tables for Designate during the installation process. Configure Designate =================== #. Source the admin credentials to gain access to admin-only CLI commands. #. Create the ``designate`` user: .. code-block:: console $ openstack user create --domain default --password-prompt designate User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | default | | enabled | True | | id | b7dd483c69654442b09a7458f7daf8d3 | | name | designate | +-----------+----------------------------------+ #. Add the admin role to the ``designate`` user and ``service`` project: .. code-block:: console $ openstack role add --project service --user designate admin #. Create the ``designate`` service entity: .. code-block:: console $ openstack service create --name designate \ --description ""OpenStack DNS service"" dns +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack DNS service | | enabled | True | | id | 6f634693062946579f678c32c006e097 | | name | designate | | type | dns | +-------------+----------------------------------+ #. Create the DNS service API endpoints: .. code-block:: console $ openstack endpoint create --region RegionOne \ dns public http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 05bf0535afad4e0897fcbc4686bf1ab9 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ dns internal http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | b8f56bf8a8ed4e88b1655655a3327ae6 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ dns admin http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | f081aef76b06472cb791aa04d920f195 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ #. Edit the ``/etc/designate/designate.conf`` file and complete the following actions: * In the ``[service:api]`` section, configure ``auth_strategy``: .. code-block:: ini [service:api] api_host = 0.0.0.0 api_port = 9001 auth_strategy = keystone enable_api_v1 = True enabled_extensions_v1 = diagnostics, quotas, reports, sync, touch enable_api_v2 = True enabled_extensions_v2 = quotas, reports * In the ``[keystone_authtoken]`` section, configure the following options: .. code-block:: ini [keystone_authtoken] auth_host = controller auth_port = 35357 auth_protocol = http admin_tenant_name = service admin_user = designate admin_password = DESIGNATE_PASS Replace DESIGNATE_PASS with the password you chose for the ``designate`` user in the Identity service. * In the ``[service:pool_manager]`` section, configure ``pool_id``: .. code-block:: ini [service:pool_manager] pool_id = 794ccc2c-d751-44fe-b57f-8894c9f5c842 * Configure the pool: .. code-block:: ini [pool:794ccc2c-d751-44fe-b57f-8894c9f5c842] nameservers = 0f66b842-96c2-4189-93fc-1dc95a08b012 targets = f26e0b32-736f-4f0a-831b-039a415c481e [pool_nameserver:0f66b842-96c2-4189-93fc-1dc95a08b012] port = 53 host = 127.0.0.1 [pool_target:f26e0b32-736f-4f0a-831b-039a415c481e] options = port: 53, host: 127.0.0.1 masters = 127.0.0.1:5354 type = bind9 * In the ``[storage:sqlalchemy]`` section, configure database access: .. code-block:: ini [storage:sqlalchemy] connection = mysql+pymysql://designate-common:DESIGNATE_DBPASS@localhost/designatedb ``DESIGNATE_DBPASS`` is automatically set to the password you chose for the Designate database. * In the ``[pool_manager_cache:sqlalchemy]`` section, configure database access: .. code-block:: ini [pool_manager_cache:sqlalchemy] connection = mysql+pymysql://designate-common:DESIGNATE_DBPASS@localhost/designate_pool_manager Replace ``DESIGNATE_DBPASS`` with a suitable password. #. Restart the Designate central and API services: .. code-block:: console $ sudo service designate-central restart $ sudo service designate-api restart Install Designate pool manager and mdns ======================================= #. Create the ``designate_pool_manager`` database and grant proper access: .. code-block:: console $ mysql -u root -p Enter password: <enter your root password here> mysql> CREATE DATABASE `designate_pool_manager` CHARACTER SET utf8 COLLATE utf8_general_ci; mysql> GRANT ALL PRIVILEGES ON designate_pool_manager.* TO 'designate-common'@'localhost' IDENTIFIED BY 'DESIGNATE_DBPASS'; mysql> exit; #. Install the ``designate-pool-manager`` and ``designate-mdns`` package: .. code-block:: console $ sudo apt-get install designate-pool-manager designate-mdns #. Sync the Pool Manager cache: .. code-block:: console $ sudo su -s /bin/sh -c ""designate-manage pool-manager-cache sync"" designate #. Restart the Designate pool manager and mDNS services: .. code-block:: console $ sudo service designate-pool-manager restart $ sudo service designate-mdns restart Verify operation ================ .. note:: If you have a firewall enabled, make sure to open port 53, as well as Designate's default port (9001). Using a web browser, curl statement, or a REST client, calls can be made to the Designate API using the following format where ""api_version"" is either v1 or v2 and ""command"" is any of the commands listed under the corresponding version at :ref:`rest`. :: http://controller:9001/api_version/command You can find the IP Address of your server by running: :: curl -s checkip.dyndns.org | sed -e 's/.*Current IP Address: //' -e 's/<.*$//' .. note:: Before Domains are created, you must create a server (/v1/servers). ",109,1098
openstack%2Fdesignate-tempest-plugin~master~I0064553874e621da17fcc742868b4373c233bb7b,openstack/designate-tempest-plugin,master,I0064553874e621da17fcc742868b4373c233bb7b,Add Docs for plugin,MERGED,2017-02-23 21:06:48.000000000,2017-02-28 15:05:40.000000000,2017-02-28 15:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-23 21:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/b6a37f58283e18c0acd4cbcd82ae4451b675c8dd', 'message': 'Add Docs for plugin\n\nChange-Id: I0064553874e621da17fcc742868b4373c233bb7b\n'}, {'number': 2, 'created': '2017-02-27 21:22:00.000000000', 'files': ['doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/c392cf94fd30c188c560b688bc2ad18a7a784274', 'message': 'Add Docs for plugin\n\nChange-Id: I0064553874e621da17fcc742868b4373c233bb7b\n'}]",0,437662,c392cf94fd30c188c560b688bc2ad18a7a784274,12,3,2,8099,,,0,"Add Docs for plugin

Change-Id: I0064553874e621da17fcc742868b4373c233bb7b
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/62/437662/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'tox.ini']",4,b6a37f58283e18c0acd4cbcd82ae4451b675c8dd,add-docs-plugin, [testenv:docs] commands = rm -rf doc/build sphinx-build -E -W -b html doc/source doc/build/html ,,537,0
openstack%2Fopenstack-ansible-os_horizon~stable%2Focata~Ib3fa401e6ecf4053ef0a4a5bb9d18ae18ae7f07a,openstack/openstack-ansible-os_horizon,stable/ocata,Ib3fa401e6ecf4053ef0a4a5bb9d18ae18ae7f07a,ensure OPENSTACK_KEYSTONE_URL is always configured,MERGED,2017-02-24 16:39:21.000000000,2017-02-28 15:02:20.000000000,2017-02-28 15:02:20.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-24 16:39:21.000000000', 'files': ['templates/horizon_local_settings.py.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/dcb6e3e6b228cf9996a72cca3b43f409a5d520a5', 'message': 'ensure OPENSTACK_KEYSTONE_URL is always configured\n\nThis is being moved in the template file such that it will ensure the\nvariable is always rendered. This change is needed for multi-region\nclouds.\n\nChange-Id: Ib3fa401e6ecf4053ef0a4a5bb9d18ae18ae7f07a\nCloses-Bug: #1660344\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit fbd1492f1ff298565f823c1f8ea7ad71bdcb8e6c)\n'}]",0,437983,dcb6e3e6b228cf9996a72cca3b43f409a5d520a5,7,4,1,6816,,,0,"ensure OPENSTACK_KEYSTONE_URL is always configured

This is being moved in the template file such that it will ensure the
variable is always rendered. This change is needed for multi-region
clouds.

Change-Id: Ib3fa401e6ecf4053ef0a4a5bb9d18ae18ae7f07a
Closes-Bug: #1660344
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit fbd1492f1ff298565f823c1f8ea7ad71bdcb8e6c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/83/437983/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/horizon_local_settings.py.j2'],1,dcb6e3e6b228cf9996a72cca3b43f409a5d520a5,bug/1660344,"OPENSTACK_KEYSTONE_URL = ""{{ horizon_keystone_endpoint }}"" ","OPENSTACK_KEYSTONE_URL = ""{{ horizon_keystone_endpoint }}""",2,1
openstack%2Fdesignate~stable%2Fnewton~I1e8334884068116ff0e184c7a38fe70562be8cac,openstack/designate,stable/newton,I1e8334884068116ff0e184c7a38fe70562be8cac,Updated from global requirements,MERGED,2017-02-27 14:46:10.000000000,2017-02-28 14:58:06.000000000,2017-02-28 14:58:06.000000000,"[{'_account_id': 3}, {'_account_id': 8099}]","[{'number': 1, 'created': '2017-02-27 14:46:10.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/3707f7aa15c9cf726480c60db00899d5790c25b4', 'message': 'Updated from global requirements\n\nChange-Id: I1e8334884068116ff0e184c7a38fe70562be8cac\n'}]",0,438520,3707f7aa15c9cf726480c60db00899d5790c25b4,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I1e8334884068116ff0e184c7a38fe70562be8cac
",git fetch https://review.opendev.org/openstack/designate refs/changes/20/438520/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3707f7aa15c9cf726480c60db00899d5790c25b4,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fdesignate~stable%2Focata~Ib8ad3aa6db77750e53a342da52b04390dc9cd17e,openstack/designate,stable/ocata,Ib8ad3aa6db77750e53a342da52b04390dc9cd17e,Updated from global requirements,MERGED,2017-02-20 22:25:58.000000000,2017-02-28 14:58:01.000000000,2017-02-28 14:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 8099}]","[{'number': 1, 'created': '2017-02-20 22:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/20b247c500c22fde0b773d825adf92282604e721', 'message': 'Updated from global requirements\n\nChange-Id: Ib8ad3aa6db77750e53a342da52b04390dc9cd17e\n'}, {'number': 2, 'created': '2017-02-27 15:12:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/ecd7f13210dddb4e91d7069052d1f0d2f6ac910a', 'message': 'Updated from global requirements\n\nChange-Id: Ib8ad3aa6db77750e53a342da52b04390dc9cd17e\n'}]",0,436231,ecd7f13210dddb4e91d7069052d1f0d2f6ac910a,9,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ib8ad3aa6db77750e53a342da52b04390dc9cd17e
",git fetch https://review.opendev.org/openstack/designate refs/changes/31/436231/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,20b247c500c22fde0b773d825adf92282604e721,openstack/requirements,openstackdocstheme>=1.5.0 # Apache-2.0,openstackdocstheme>=1.5.0 # Apache-2.0,1,1
openstack%2Fnova~master~I32eb55f12a379d1e40725db999330744c5a29baf,openstack/nova,master,I32eb55f12a379d1e40725db999330744c5a29baf,placement: rename can_host to shared,ABANDONED,2017-02-14 23:21:52.000000000,2017-02-28 14:56:49.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-14 23:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47e2b6abac993f4eb6adfadd6ecbe42b0e3bb93e', 'message': 'placement: rename can_host to shared\n\nIn upcoming patches, we will be using a field on the resource_providers table\nto mark a provider as one which contains shared resources. We already had a\nfield called ""can_host"" in the resource_providers table, but to date had not\nbeen using it for anything. This patch renames that field to ""shared"" for two\nreasons:\n\na) ""shared"" is more generic (for non-Nova cases) than ""can_host""\nb) the default value for can_host is 0 and that\'s what we\'ve been setting\n   compute host providers to. However, compute hosts don\'t share resources, so\n   0 is appropriate for ""shared"", not ""can_host"".\n\nChange-Id: I32eb55f12a379d1e40725db999330744c5a29baf\nblueprint: shared-resources-pike\n'}, {'number': 2, 'created': '2017-02-16 18:18:26.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/objects/resource_provider.py', 'nova/db/sqlalchemy/api_migrations/migrate_repo/versions/041_rename_can_host.py', 'nova/tests/functional/db/test_resource_provider.py', 'nova/db/sqlalchemy/api_models.py', 'nova/tests/unit/objects/test_resource_provider.py', 'nova/tests/functional/db/api/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/db4ac99bdeb7478b7291ffedb6d02039e1fe271e', 'message': 'placement: rename can_host to shared\n\nIn upcoming patches, we will be using a field on the resource_providers table\nto mark a provider as one which contains shared resources. We already had a\nfield called ""can_host"" in the resource_providers table, but to date had not\nbeen using it for anything. This patch renames that field to ""shared"" for two\nreasons:\n\na) ""shared"" is more generic (for non-Nova cases) than ""can_host""\nb) the default value for can_host is 0 and that\'s what we\'ve been setting\n   compute host providers to. However, compute hosts don\'t share resources, so\n   0 is appropriate for ""shared"", not ""can_host"".\n\nChange-Id: I32eb55f12a379d1e40725db999330744c5a29baf\nblueprint: shared-resources-pike\n'}]",0,433977,db4ac99bdeb7478b7291ffedb6d02039e1fe271e,25,11,2,7,,,0,"placement: rename can_host to shared

In upcoming patches, we will be using a field on the resource_providers table
to mark a provider as one which contains shared resources. We already had a
field called ""can_host"" in the resource_providers table, but to date had not
been using it for anything. This patch renames that field to ""shared"" for two
reasons:

a) ""shared"" is more generic (for non-Nova cases) than ""can_host""
b) the default value for can_host is 0 and that's what we've been setting
   compute host providers to. However, compute hosts don't share resources, so
   0 is appropriate for ""shared"", not ""can_host"".

Change-Id: I32eb55f12a379d1e40725db999330744c5a29baf
blueprint: shared-resources-pike
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/433977/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/objects/resource_provider.py', 'nova/db/sqlalchemy/api_migrations/migrate_repo/versions/041_rename_can_host.py', 'nova/tests/functional/db/test_resource_provider.py', 'nova/db/sqlalchemy/api_models.py', 'nova/tests/unit/objects/test_resource_provider.py', 'nova/tests/functional/db/api/test_migrations.py']",7,47e2b6abac993f4eb6adfadd6ecbe42b0e3bb93e,bp/shared-resources-pike," def _check_041(self, engine, data): self.assertColumnExists(engine, 'resource_providers', 'shared') ",,45,8
openstack%2Fnova~master~I23c2cd34c02e0c009cf8a5f959c011f76be1fe27,openstack/nova,master,I23c2cd34c02e0c009cf8a5f959c011f76be1fe27,placement: get inventory shared with provider,ABANDONED,2017-02-14 23:21:52.000000000,2017-02-28 14:56:33.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-14 23:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10e6547cf6cc544f59faf5d58ab6e702e2f372b1', 'message': 'placement: get inventory shared with provider\n\nAdds InventoryList.get_all_shared_with_provider() method to return all\nInventory records for any provider that is marked as a shared provider and is\nassociated with an aggregate with which the supplied provider is also\nassociated.\n\nChange-Id: I23c2cd34c02e0c009cf8a5f959c011f76be1fe27\nblueprint: shared-resources-pike\n'}, {'number': 2, 'created': '2017-02-16 18:18:26.000000000', 'files': ['nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py', 'nova/tests/unit/objects/test_resource_provider.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b5c4154f6478d51223ff0e514e972dfaf9e1a667', 'message': 'placement: get inventory shared with provider\n\nAdds InventoryList.get_all_shared_with_provider() method to return all\nInventory records for any provider that is marked as a shared provider and is\nassociated with an aggregate with which the supplied provider is also\nassociated.\n\nChange-Id: I23c2cd34c02e0c009cf8a5f959c011f76be1fe27\nblueprint: shared-resources-pike\n'}]",0,433978,b5c4154f6478d51223ff0e514e972dfaf9e1a667,26,12,2,7,,,0,"placement: get inventory shared with provider

Adds InventoryList.get_all_shared_with_provider() method to return all
Inventory records for any provider that is marked as a shared provider and is
associated with an aggregate with which the supplied provider is also
associated.

Change-Id: I23c2cd34c02e0c009cf8a5f959c011f76be1fe27
blueprint: shared-resources-pike
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/433978/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py']",2,10e6547cf6cc544f59faf5d58ab6e702e2f372b1,bp/shared-resources-pike,"class SharedResourcesTestCase(ResourceProviderBaseCase): def test_inventory_list_get_all_shared_with_provider(self): """"""We set up two compute nodes as resource providers and one aggregate associated with both compute nodes. Neither compute node will have any local disk. We set up a resource provider for shared storage and also associate that with the same aggregate as the compute nodes. We then verify that InventoryList.get_all_shared_with_provider() returns the shared storage provider's DISK_GB inventory only. """""" memory_inv = objects.Inventory( resource_class=fields.ResourceClass.MEMORY_MB, total=1024, reserved=0, min_unit=64, max_unit=1024, step_size=64, allocation_ratio=1.0, ) vcpu_inv = objects.Inventory( resource_class=fields.ResourceClass.VCPU, total=12, reserved=0, min_unit=1, max_unit=12, step_size=1, allocation_ratio=16.0, ) cn1 = objects.ResourceProvider( context=self.context, uuid=uuidsentinel.cn1, name='cn1', ) cn1.create() cn2 = objects.ResourceProvider( context=self.context, uuid=uuidsentinel.cn2, name='cn2', ) cn2.create() agg_uuid = uuidsentinel.agg agg_uuids = [agg_uuid] for cn in (cn1, cn2): memory_inv.resource_provider = cn inv_list = objects.InventoryList(objects=[memory_inv, vcpu_inv]) cn.set_inventory(inv_list) cn.set_aggregates(agg_uuids) storage_rp = objects.ResourceProvider( context=self.context, uuid=uuidsentinel.storage, name='shared storage', shared=True, ) storage_rp.create() disk_inv = objects.Inventory( resource_provider=storage_rp, resource_class=fields.ResourceClass.DISK_GB, total=10000, reserved=10, min_unit=10, max_unit=500, step_size=10, allocation_ratio=1.0, ) inv_list = objects.InventoryList(objects=[disk_inv]) storage_rp.set_inventory(inv_list) storage_rp.set_aggregates(agg_uuids) # Get the inventory shared with the first compute node got_inv = objects.InventoryList.get_all_shared_with_provider( self.context, uuidsentinel.cn1, ) self.assertEqual(1, len(got_inv)) found_inv = got_inv.find(fields.ResourceClass.DISK_GB) self.assertIsNotNone(found_inv) self.assertEqual(10000, found_inv.total) # Inventory shared with the second compute node should be identical got_inv = objects.InventoryList.get_all_shared_with_provider( self.context, uuidsentinel.cn2, ) self.assertEqual(1, len(got_inv)) found_inv = got_inv.find(fields.ResourceClass.DISK_GB) self.assertIsNotNone(found_inv) self.assertEqual(10000, found_inv.total) ",,161,2
openstack%2Fnova~master~I9ae81c23de6eb4eb720552571267a372365b95d9,openstack/nova,master,I9ae81c23de6eb4eb720552571267a372365b95d9,Fix typos detected by toolkit misspellings.,MERGED,2017-02-26 06:10:51.000000000,2017-02-28 14:55:19.000000000,2017-02-28 14:55:19.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 20223}, {'_account_id': 23006}]","[{'number': 1, 'created': '2017-02-26 06:10:51.000000000', 'files': ['doc/source/upgrade.rst', 'nova/conf/libvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/90b6a3984a4b07232d8426e7e3cb7076ef42c31e', 'message': 'Fix typos detected by toolkit misspellings.\n\n* pip install misspellings\n* git ls-files | grep -v locale | misspellings -f -\n\ndoc/source/upgrade.rst:177: incidentially -> ""incidentally""\nnova/conf/libvirt.py:286: dependant -> ""dependent""\n\nChange-Id: I9ae81c23de6eb4eb720552571267a372365b95d9\n'}]",0,438232,90b6a3984a4b07232d8426e7e3cb7076ef42c31e,31,7,1,25050,,,0,"Fix typos detected by toolkit misspellings.

* pip install misspellings
* git ls-files | grep -v locale | misspellings -f -

doc/source/upgrade.rst:177: incidentially -> ""incidentally""
nova/conf/libvirt.py:286: dependant -> ""dependent""

Change-Id: I9ae81c23de6eb4eb720552571267a372365b95d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/438232/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/upgrade.rst', 'nova/conf/libvirt.py']",2,90b6a3984a4b07232d8426e7e3cb7076ef42c31e,typo,Override the default libvirt live migration scheme (which is dependent on,Override the default libvirt live migration scheme (which is dependant on,2,2
openstack%2Fironic~master~I010c03c3796322dd66d3d9fb6fef6d3725ddf44c,openstack/ironic,master,I010c03c3796322dd66d3d9fb6fef6d3725ddf44c,"When user executes ""ironic node-show-states <node-name/node-uuid >"", now it also displays information like  name, uuid , maintenance and maintenance reason of the node.",ABANDONED,2017-02-10 12:14:02.000000000,2017-02-28 14:54:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10118}, {'_account_id': 10206}, {'_account_id': 11878}, {'_account_id': 12356}, {'_account_id': 14629}, {'_account_id': 17814}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 20401}]","[{'number': 1, 'created': '2017-02-10 12:14:02.000000000', 'files': ['ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3896ed51f151e3fa8a476123e0621b2d51cc0b7b', 'message': 'When user executes ""ironic node-show-states <node-name/node-uuid >"",\nnow it also displays information like  name, uuid , maintenance and\nmaintenance reason of the node.\n\nChange-Id: I010c03c3796322dd66d3d9fb6fef6d3725ddf44c\nCloses-Bug: #1663129\n'}]",12,432277,3896ed51f151e3fa8a476123e0621b2d51cc0b7b,15,12,1,20401,,,0,"When user executes ""ironic node-show-states <node-name/node-uuid >"",
now it also displays information like  name, uuid , maintenance and
maintenance reason of the node.

Change-Id: I010c03c3796322dd66d3d9fb6fef6d3725ddf44c
Closes-Bug: #1663129
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/432277/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/controllers/v1/node.py']",2,3896ed51f151e3fa8a476123e0621b2d51cc0b7b,bug/1663129," maintenance = types.boolean """"""Represent the maintenance mode of the node."""""" maintenance_reason = wtypes.text """"""Represents the reason for the node going into maintenance mode."""""" uuid = wtypes.text """"""Represents the uuid of the node."""""" name = wtypes.text """"""Represents the name of the node."""""" 'provision_state', 'target_power_state', 'name', 'maintenance', 'maintenance_reason', 'uuid', not uuidutils.is_uuid_like(node)):"," 'provision_state', 'target_power_state', not uuidutils.is_uuid_like(node)):",20,2
openstack%2Fopenstack-ansible-rsyslog_client~stable%2Fnewton~Iea783d443af96d9996fd25ea9355f2930d82fb20,openstack/openstack-ansible-rsyslog_client,stable/newton,Iea783d443af96d9996fd25ea9355f2930d82fb20,rsyslog client tasks overwriting rsyslog server config,MERGED,2017-02-28 08:24:35.000000000,2017-02-28 14:54:33.000000000,2017-02-28 14:54:33.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 25128}]","[{'number': 1, 'created': '2017-02-28 08:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/3e5621920bb034d0173a1cceb5ea6cf861a88661', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)\n'}, {'number': 2, 'created': '2017-02-28 13:03:21.000000000', 'files': ['tasks/rsyslog_client_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/4910d69766580a16edee812cf823b81acce9c409', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nCombined backport of:\nhttps://review.openstack.org/438205\nhttps://review.openstack.org/438927\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)\n'}]",0,438846,4910d69766580a16edee812cf823b81acce9c409,13,5,2,6816,,,0,"rsyslog client tasks overwriting rsyslog server config

when rsyslog client role is invoked as part of monitoring agent
installation across all hosts its breaking the rsyslog server.
Added conditions not overwrite the rsyslog configs on rsyslog servers.

Combined backport of:
https://review.openstack.org/438205
https://review.openstack.org/438927

Change-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20
(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/46/438846/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rsyslog_client_post_install.yml'],1,3e5621920bb034d0173a1cceb5ea6cf861a88661,, when: inventory_hostname not in groups['rsyslog_all'] when: inventory_hostname not in groups['rsyslog_all'],,2,0
openstack%2Fneutron-dynamic-routing~master~I58972e3465ed9e3b7d8cdd24abc463d55ce1b7d5,openstack/neutron-dynamic-routing,master,I58972e3465ed9e3b7d8cdd24abc463d55ce1b7d5,Fix relocated DB models,MERGED,2017-02-27 23:40:53.000000000,2017-02-28 14:54:11.000000000,2017-02-28 14:54:11.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 9656}]","[{'number': 1, 'created': '2017-02-27 23:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/4fd7fa4d096bb4a0e461f9600468115b300238ae', 'message': 'Fix relocated DB models\n\nSome DB models were relocated and their deprecated import paths were\ncleaned up[1].\n\n[1] Iadbf44d52ee8e30712807384152a29ce1a8b8f72\n\nChange-Id: I58972e3465ed9e3b7d8cdd24abc463d55ce1b7d5\n'}, {'number': 2, 'created': '2017-02-27 23:54:54.000000000', 'files': ['neutron_dynamic_routing/db/bgp_db.py', 'neutron_dynamic_routing/db/bgp_dragentscheduler_db.py', 'neutron_dynamic_routing/services/bgp/scheduler/bgp_dragent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/f7a4b32137674a6f1532c6f6ba09774c658a1d74', 'message': 'Fix relocated DB models\n\nSome DB models were relocated and their deprecated import paths were\ncleaned up[1].\n\n[1] Iadbf44d52ee8e30712807384152a29ce1a8b8f72\n\nChange-Id: I58972e3465ed9e3b7d8cdd24abc463d55ce1b7d5\n'}]",0,438739,f7a4b32137674a6f1532c6f6ba09774c658a1d74,8,3,2,8344,,,0,"Fix relocated DB models

Some DB models were relocated and their deprecated import paths were
cleaned up[1].

[1] Iadbf44d52ee8e30712807384152a29ce1a8b8f72

Change-Id: I58972e3465ed9e3b7d8cdd24abc463d55ce1b7d5
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/39/438739/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_dynamic_routing/db/bgp_db.py', 'neutron_dynamic_routing/db/bgp_dragentscheduler_db.py', 'neutron_dynamic_routing/services/bgp/scheduler/bgp_dragent_scheduler.py']",3,4fd7fa4d096bb4a0e461f9600468115b300238ae,fix-db-models,from neutron.db.models import agent as agent_model query = context.session.query(agent_model.Agent), query = context.session.query(agents_db.Agent),6,5
openstack%2Fopenstack-ansible-os_gnocchi~stable%2Fnewton~Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc,openstack/openstack-ansible-os_gnocchi,stable/newton,Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc,Fix gnocchi endpoint variable names,MERGED,2017-02-27 18:12:45.000000000,2017-02-28 14:53:42.000000000,2017-02-28 14:53:42.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-27 18:12:45.000000000', 'files': ['releasenotes/notes/var-rename-gnocchi-endpoints-87626018773f77e0.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_gnocchi/commit/c4036b9594d6bc3641ffa08e8d42d45e94292cd6', 'message': 'Fix gnocchi endpoint variable names\n\nFixed the gnocchi endpoint variable names to be consistent with other roles.\n\nChange-Id: Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc\n(cherry picked from commit 236c943d4ce8942a9c773cca52a9c9567eef9843)\n'}]",0,438661,c4036b9594d6bc3641ffa08e8d42d45e94292cd6,8,3,1,25128,,,0,"Fix gnocchi endpoint variable names

Fixed the gnocchi endpoint variable names to be consistent with other roles.

Change-Id: Ib98fbb7362d6f24db523432cbaca421d8ecaf5bc
(cherry picked from commit 236c943d4ce8942a9c773cca52a9c9567eef9843)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_gnocchi refs/changes/61/438661/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/var-rename-gnocchi-endpoints-87626018773f77e0.yaml', 'defaults/main.yml']",2,c4036b9594d6bc3641ffa08e8d42d45e94292cd6,,"gnocchi_service_publicuri: ""{{ gnocchi_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_publicurl: ""{{ gnocchi_service_publicuri }}"" gnocchi_service_internaluri: ""{{ gnocchi_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_internalurl: ""{{ gnocchi_service_internaluri }}"" gnocchi_service_adminuri: ""{{ gnocchi_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_adminurl: ""{{ gnocchi_service_adminuri }}""","gnocchi_service_publicurl: ""{{ gnocchi_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_internalurl: ""{{ gnocchi_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"" gnocchi_service_adminurl: ""{{ gnocchi_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}""",11,3
openstack%2Fopenstack-ansible-rsyslog_client~stable%2Focata~Iea783d443af96d9996fd25ea9355f2930d82fb20,openstack/openstack-ansible-rsyslog_client,stable/ocata,Iea783d443af96d9996fd25ea9355f2930d82fb20,rsyslog client tasks overwriting rsyslog server config,MERGED,2017-02-28 08:24:26.000000000,2017-02-28 14:53:05.000000000,2017-02-28 14:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 25128}]","[{'number': 1, 'created': '2017-02-28 08:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/964fd84ca0cf0f1b7100f2695e9280ce8bae9501', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)\n'}, {'number': 2, 'created': '2017-02-28 13:01:26.000000000', 'files': ['tasks/rsyslog_client_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/d61d3fb2dc61f76673b6297c17c213a3def9d745', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nCombined backport of:\nhttps://review.openstack.org/438205\nhttps://review.openstack.org/438927\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)\n'}]",0,438845,d61d3fb2dc61f76673b6297c17c213a3def9d745,11,5,2,6816,,,0,"rsyslog client tasks overwriting rsyslog server config

when rsyslog client role is invoked as part of monitoring agent
installation across all hosts its breaking the rsyslog server.
Added conditions not overwrite the rsyslog configs on rsyslog servers.

Combined backport of:
https://review.openstack.org/438205
https://review.openstack.org/438927

Change-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20
(cherry picked from commit 931b04ed00917dfee250ced5fe55ff462b0d9c2b)
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/45/438845/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rsyslog_client_post_install.yml'],1,964fd84ca0cf0f1b7100f2695e9280ce8bae9501,438845, when: inventory_hostname not in groups['rsyslog_all'] when: inventory_hostname not in groups['rsyslog_all'],,2,0
openstack%2Fgnocchi~master~Ic88d40461989a0c96f9c3dc03746c48b89bd3357,openstack/gnocchi,master,Ic88d40461989a0c96f9c3dc03746c48b89bd3357,tests: Hide useless tests output,MERGED,2017-02-28 09:11:49.000000000,2017-02-28 14:49:36.000000000,2017-02-28 14:49:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-28 09:11:49.000000000', 'files': ['gnocchi/tests/base.py', 'gnocchi/tests/functional/fixtures.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/47b7de0e2bb1157524b7b5988b8c715bec1dcd39', 'message': 'tests: Hide useless tests output\n\nCurrently the tests output flow is corrupted by data logged\nduring setUpClass() and gabbi fixtures, this change uses a oslotest fixture\nto hide them.\n\nChange-Id: Ic88d40461989a0c96f9c3dc03746c48b89bd3357\n'}]",0,438868,47b7de0e2bb1157524b7b5988b8c715bec1dcd39,7,3,1,2813,,,0,"tests: Hide useless tests output

Currently the tests output flow is corrupted by data logged
during setUpClass() and gabbi fixtures, this change uses a oslotest fixture
to hide them.

Change-Id: Ic88d40461989a0c96f9c3dc03746c48b89bd3357
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/68/438868/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/base.py', 'gnocchi/tests/functional/fixtures.py']",2,47b7de0e2bb1157524b7b5988b8c715bec1dcd39,sileht/redis,from oslotest import log from oslotest import output self.output = output.CaptureOutput() self.output.setUp() self.log = log.ConfigureLogging() self.log.setUp() self.output.cleanUp() self.log.cleanUp(),,19,0
openstack%2Fnova~master~I7ce745c93bc62379729a66477472cde3a21d5604,openstack/nova,master,I7ce745c93bc62379729a66477472cde3a21d5604,adding more stuffs in the first-file,ABANDONED,2017-02-27 05:18:46.000000000,2017-02-28 14:49:35.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17292}, {'_account_id': 18602}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-27 05:18:46.000000000', 'files': ['first-file'], 'web_link': 'https://opendev.org/openstack/nova/commit/196d2e409b0507206ba299d4337af98c7cad6339', 'message': 'adding more stuffs in the first-file\n\nChange-Id: I7ce745c93bc62379729a66477472cde3a21d5604\n'}]",0,438331,196d2e409b0507206ba299d4337af98c7cad6339,18,14,1,15527,,,0,"adding more stuffs in the first-file

Change-Id: I7ce745c93bc62379729a66477472cde3a21d5604
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/438331/1 && git format-patch -1 --stdout FETCH_HEAD,['first-file'],1,196d2e409b0507206ba299d4337af98c7cad6339,nova-branch,This is my first changes for OpenStack. ,,1,0
openstack%2Fopenstack-ansible-lxc_hosts~master~Ibd3796cc78060016d4099ccb4ed176f6666f73f8,openstack/openstack-ansible-lxc_hosts,master,Ibd3796cc78060016d4099ccb4ed176f6666f73f8,Support user shell commands during cache prep,MERGED,2017-02-27 17:24:46.000000000,2017-02-28 14:49:16.000000000,2017-02-28 14:41:54.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-27 17:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/2f26cd694570d31398cff936089cabc778df7907', 'message': 'Support user shell commands during cache prep\n\nSupport running user shell comamnds before/after the LXC cache build\nprocess without requiring a complete override of the cache map dict.\n\nChange-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8\n'}, {'number': 2, 'created': '2017-02-27 18:12:17.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ba800949ed712b5245e7471ba9834384a5cd9a5d', 'message': 'Support user shell commands during cache prep\n\nSupport running user shell comamnds before/after the LXC cache build\nprocess without requiring a complete override of the cache map dict.\n\nChange-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8\n'}]",6,438634,ba800949ed712b5245e7471ba9834384a5cd9a5d,16,5,2,17799,,,0,"Support user shell commands during cache prep

Support running user shell comamnds before/after the LXC cache build
process without requiring a complete override of the cache map dict.

Change-Id: Ibd3796cc78060016d4099ccb4ed176f6666f73f8
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/34/438634/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml']",3,2f26cd694570d31398cff936089cabc778df7907,cache-prep-user-cmd,# Custom shell commands to run before/after the LXC cache prep process has taken # place. lxc_cache_prep_pre_commands: '' lxc_cache_prep_post_commands: '' ,,9,0
openstack%2Fopenstack-ansible-rsyslog_client~stable%2Focata~I0cc9dd512fba6a1d583bf861a645097ae7c1d852,openstack/openstack-ansible-rsyslog_client,stable/ocata,I0cc9dd512fba6a1d583bf861a645097ae7c1d852,Ensure rsyslog restarts after configuration file changes,MERGED,2017-02-27 17:28:44.000000000,2017-02-28 14:45:33.000000000,2017-02-28 14:45:33.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-27 17:28:44.000000000', 'files': ['tasks/rsyslog_client_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/459404a83cd5c5674b29e7051b77257fe4029936', 'message': 'Ensure rsyslog restarts after configuration file changes\n\nAdded rsyslog restart handlers to each rsyslog_client_post_install task.\nThere was an issue when rsyslog_client_post_install would stop its service,\nit would automatically get restarted and the service would not listen\nfor incoming logs. This now ensures that the rsyslog service will\nbe restarted after configuration files are changed.\n\nChange-Id: I0cc9dd512fba6a1d583bf861a645097ae7c1d852\nPartial-Bug: 1636017\n'}]",0,438637,459404a83cd5c5674b29e7051b77257fe4029936,7,3,1,25278,,,0,"Ensure rsyslog restarts after configuration file changes

Added rsyslog restart handlers to each rsyslog_client_post_install task.
There was an issue when rsyslog_client_post_install would stop its service,
it would automatically get restarted and the service would not listen
for incoming logs. This now ensures that the rsyslog service will
be restarted after configuration files are changed.

Change-Id: I0cc9dd512fba6a1d583bf861a645097ae7c1d852
Partial-Bug: 1636017
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/37/438637/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/rsyslog_client_post_install.yml', 'handlers/main.yml']",2,459404a83cd5c5674b29e7051b77257fe4029936,bug/1636017,--- - name: restart rsyslog service: name: rsyslog state: restarted ,,13,15
openstack%2Fopenstack-ansible-rsyslog_client~stable%2Fnewton~I0cc9dd512fba6a1d583bf861a645097ae7c1d852,openstack/openstack-ansible-rsyslog_client,stable/newton,I0cc9dd512fba6a1d583bf861a645097ae7c1d852,Ensure rsyslog restarts after configuration file changes,MERGED,2017-02-27 17:25:58.000000000,2017-02-28 14:44:43.000000000,2017-02-28 14:44:43.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-27 17:25:58.000000000', 'files': ['tasks/rsyslog_client_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/57c956cbfcb3fea6e7e75514823acc49494d1f66', 'message': 'Ensure rsyslog restarts after configuration file changes\n\nAdded rsyslog restart handlers to each rsyslog_client_post_install task.\nThere was an issue when rsyslog_client_post_install would stop its service,\nit would automatically get restarted and the service would not listen\nfor incoming logs. This now ensures that the rsyslog service will\nbe restarted after configuration files are changed.\n\nChange-Id: I0cc9dd512fba6a1d583bf861a645097ae7c1d852\nPartial-Bug: 1636017\n'}]",0,438635,57c956cbfcb3fea6e7e75514823acc49494d1f66,7,3,1,25278,,,0,"Ensure rsyslog restarts after configuration file changes

Added rsyslog restart handlers to each rsyslog_client_post_install task.
There was an issue when rsyslog_client_post_install would stop its service,
it would automatically get restarted and the service would not listen
for incoming logs. This now ensures that the rsyslog service will
be restarted after configuration files are changed.

Change-Id: I0cc9dd512fba6a1d583bf861a645097ae7c1d852
Partial-Bug: 1636017
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/35/438635/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/rsyslog_client_post_install.yml', 'handlers/main.yml']",2,57c956cbfcb3fea6e7e75514823acc49494d1f66,bug/1636017,--- - name: restart rsyslog service: name: rsyslog state: restarted ,,13,15
openstack%2Ffreezer~stable%2Focata~Ic7266d46f2f30f6d519db6acdb01d6470382243d,openstack/freezer,stable/ocata,Ic7266d46f2f30f6d519db6acdb01d6470382243d,Fix max_segment_size parameter,MERGED,2017-02-28 12:21:02.000000000,2017-02-28 14:36:09.000000000,2017-02-28 14:36:09.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14340}, {'_account_id': 16768}, {'_account_id': 22405}]","[{'number': 1, 'created': '2017-02-28 12:21:02.000000000', 'files': ['freezer/openstack/osclients.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/66eaa164964f313e6057ea3c47b6af030fc82d60', 'message': 'Fix max_segment_size parameter\n\nChange-Id: Ic7266d46f2f30f6d519db6acdb01d6470382243d\n'}]",0,438944,66eaa164964f313e6057ea3c47b6af030fc82d60,9,5,1,13940,,,0,"Fix max_segment_size parameter

Change-Id: Ic7266d46f2f30f6d519db6acdb01d6470382243d
",git fetch https://review.opendev.org/openstack/freezer refs/changes/44/438944/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/openstack/osclients.py'],1,66eaa164964f313e6057ea3c47b6af030fc82d60,," return utils.ReSizeStream(stream, image.size, CONF.get('max_segment_size'))"," return utils.ReSizeStream(stream, image.size, 1000000)",2,1
openstack%2Fgnocchi~master~Ic374a760ba8d3f658011705b401b29c05b39c47b,openstack/gnocchi,master,Ic374a760ba8d3f658011705b401b29c05b39c47b,indexer: fix typo,MERGED,2017-02-28 07:28:21.000000000,2017-02-28 14:34:55.000000000,2017-02-28 14:34:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-28 07:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/50acafd67008055dfb0a3010477e87afdd3627dd', 'message': 'indexer: fix typo\n\nWe looks at exception.inner_exception instead of exc.inner_exception.\n\nThis change fixes that.\n\nChange-Id: Ic374a760ba8d3f658011705b401b29c05b39c47b\n'}, {'number': 2, 'created': '2017-02-28 09:11:49.000000000', 'files': ['gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4e82338b016b3006c567864b9c678b7f722bb1e5', 'message': 'indexer: fix typo\n\nWe looks at exception.inner_exception instead of exc.inner_exception.\n\nThis change fixes that.\n\nChange-Id: Ic374a760ba8d3f658011705b401b29c05b39c47b\n'}]",0,438826,4e82338b016b3006c567864b9c678b7f722bb1e5,13,3,2,2813,,,0,"indexer: fix typo

We looks at exception.inner_exception instead of exc.inner_exception.

This change fixes that.

Change-Id: Ic374a760ba8d3f658011705b401b29c05b39c47b
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/26/438826/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/sqlalchemy.py'],1,50acafd67008055dfb0a3010477e87afdd3627dd,sileht/redis, inn_e = exc.inner_exception, inn_e = exception.inner_exception,1,1
openstack%2Ftripleo-ci~master~I0ac0dac42286994241700f803159764fa3a6aee6,openstack/tripleo-ci,master,I0ac0dac42286994241700f803159764fa3a6aee6,Export UPGRADE_ENV for scenario-upgrades,MERGED,2017-02-27 15:46:47.000000000,2017-02-28 14:33:17.000000000,2017-02-28 14:33:17.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8449}]","[{'number': 1, 'created': '2017-02-27 15:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a5ccbfa24fb88450fb6162a39019d68136794d7d', 'message': ""Export UPGRADE_ENV for scenario-upgrades\n\nIt's required when upgrading scenarios in CI, so we can add the new\nservices during the upgrade process and pingtest won't fail to find new\nresources.\n\nChange-Id: I0ac0dac42286994241700f803159764fa3a6aee6\n""}, {'number': 2, 'created': '2017-02-27 15:51:36.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3c3e78a29f187d524ad2329f73cadff6cdc57fc9', 'message': ""Export UPGRADE_ENV for scenario-upgrades\n\nIt's required when upgrading scenarios in CI, so we can add the new\nservices during the upgrade process and pingtest won't fail to find new\nresources.\n\nChange-Id: I0ac0dac42286994241700f803159764fa3a6aee6\n""}]",0,438567,3c3e78a29f187d524ad2329f73cadff6cdc57fc9,10,4,2,3153,,,0,"Export UPGRADE_ENV for scenario-upgrades

It's required when upgrading scenarios in CI, so we can add the new
services during the upgrade process and pingtest won't fail to find new
resources.

Change-Id: I0ac0dac42286994241700f803159764fa3a6aee6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/67/438567/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,a5ccbfa24fb88450fb6162a39019d68136794d7d,update_env, export UPGRADE_ENV=/usr/share/openstack-tripleo-heat-templates/ci/environments/multinode_major_upgrade.yaml else export UPGRADE_ENV=/usr/share/openstack-tripleo-heat-templates/ci/environments/$MULTINODE_ENV_NAME.yaml, export UPGRADE_ENV=/usr/share/openstack-tripleo-heat-templates/ci/environments/multinode_major_upgrade.yaml,3,1
openstack%2Fopenstacksdk~master~Ica327f27b26e5dd4b6744566eb09ea81a6e9583e,openstack/openstacksdk,master,Ica327f27b26e5dd4b6744566eb09ea81a6e9583e,Implement metric docs,MERGED,2017-02-16 20:59:32.000000000,2017-02-28 14:28:50.000000000,2017-02-28 14:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-16 20:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a65dcf4aa7c7464faf79b9f258271d9ec4a80fc8', 'message': 'Implement metric docs\n\nThis change introduces metric docs. There is only one method in the\nproxy as of right now, so that was easy.\n\nChange-Id: Ica327f27b26e5dd4b6744566eb09ea81a6e9583e\n'}, {'number': 2, 'created': '2017-02-17 17:52:06.000000000', 'files': ['doc/source/users/index.rst', 'doc/source/users/proxies/metric.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6e7840842a9fd314554ae9353ded1869c19787ad', 'message': 'Implement metric docs\n\nThis change introduces metric docs. There is only one method in the\nproxy as of right now, so that was easy.\n\nChange-Id: Ica327f27b26e5dd4b6744566eb09ea81a6e9583e\n'}]",2,435110,6e7840842a9fd314554ae9353ded1869c19787ad,11,3,2,8257,,,0,"Implement metric docs

This change introduces metric docs. There is only one method in the
proxy as of right now, so that was easy.

Change-Id: Ica327f27b26e5dd4b6744566eb09ea81a6e9583e
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/10/435110/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/index.rst', 'doc/source/users/proxies/metric.rst']",2,a65dcf4aa7c7464faf79b9f258271d9ec4a80fc8,reorganize_metric_proxy_docs,Metric API ========== .. automodule:: openstack.metric.v1._proxy The Metric Class ---------------- The metric high-level interface is available through the ``metric`` member of a :class:`~openstack.connection.Connection` object. The ``metric`` member will only be added if the service is detected. Database Operations ^^^^^^^^^^^^^^^^^^^ .. autoclass:: openstack.metric.v1._proxy.Proxy .. automethod:: openstack.metric.v1._proxy.Proxy.capabilities ,,19,0
openstack%2Fopenstacksdk~master~I4733161959ab282915f1cc2956245a377417fced,openstack/openstacksdk,master,I4733161959ab282915f1cc2956245a377417fced,"Deprecate ""wait_for"" methods on ProxyBase",MERGED,2017-02-15 16:38:01.000000000,2017-02-28 14:28:34.000000000,2017-02-28 14:28:34.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-15 16:38:01.000000000', 'files': ['openstack/proxy2.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9260f8404ca0cfa7260638bceede0839fff94bcf', 'message': 'Deprecate ""wait_for"" methods on ProxyBase\n\nThe wait_for_status and wait_for_delete methods on ProxyBase end up\nattached to every service-specific proxy, though they\'re not generally\napplicable. The proxy methods as they are just simply expose what\'s\navailable on the resource base class, so any direct users in a proxy\nsubclass should instead implement this on their own when it\'s needed.\n\nCurrently, only compute uses this kind of functionality, and it rightly\nimplements it itself by going to the resource2 module and calling the\nmodule-level functions. Internally, we do have a few uses of the\nwait_for methods attached to proxies, though they\'re all in functional\ntests (for block_store, compute, and orchestration). We should consider\nexposing those methods directly on those proxies rather than exposing\nthe methods through the base class to dozens of services that don\'t have\nthose needs.\n\nThese should be removed for 1.0. They\'re also currently generating\nwarnings on every service\'s documentation via the enforcer tool for not\nbeing documented (which was how this was originally found).\n\nChange-Id: I4733161959ab282915f1cc2956245a377417fced\n'}]",2,434381,9260f8404ca0cfa7260638bceede0839fff94bcf,10,4,1,8257,,,0,"Deprecate ""wait_for"" methods on ProxyBase

The wait_for_status and wait_for_delete methods on ProxyBase end up
attached to every service-specific proxy, though they're not generally
applicable. The proxy methods as they are just simply expose what's
available on the resource base class, so any direct users in a proxy
subclass should instead implement this on their own when it's needed.

Currently, only compute uses this kind of functionality, and it rightly
implements it itself by going to the resource2 module and calling the
module-level functions. Internally, we do have a few uses of the
wait_for methods attached to proxies, though they're all in functional
tests (for block_store, compute, and orchestration). We should consider
exposing those methods directly on those proxies rather than exposing
the methods through the base class to dozens of services that don't have
those needs.

These should be removed for 1.0. They're also currently generating
warnings on every service's documentation via the enforcer tool for not
being documented (which was how this was originally found).

Change-Id: I4733161959ab282915f1cc2956245a377417fced
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/81/434381/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/proxy2.py'],1,9260f8404ca0cfa7260638bceede0839fff94bcf,deprecate_wait_for_methods,"from openstack import utils @utils.deprecated(deprecated_in=""0.9.14"", removed_in=""1.0"", details=(""This is no longer a part of the proxy base, "" ""service-specific subclasses should expose "" ""this as needed. See resource2.wait_for_status "" ""for this behavior"")) @utils.deprecated(deprecated_in=""0.9.14"", removed_in=""1.0"", details=(""This is no longer a part of the proxy base, "" ""service-specific subclasses should expose "" ""this as needed. See resource2.wait_for_delete "" ""for this behavior""))",,11,0
openstack%2Fopenstack-manuals~master~I07b924666ecbd27fa5aff93a80fb91acef2e7f98,openstack/openstack-manuals,master,I07b924666ecbd27fa5aff93a80fb91acef2e7f98,Config guide missing new settings for Ocata,ABANDONED,2017-02-28 08:48:41.000000000,2017-02-28 14:27:29.000000000,,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14643}]","[{'number': 1, 'created': '2017-02-28 08:48:41.000000000', 'files': ['doc/config-reference/source/tables/conf-changes/keystone.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2368e4a13a52988c4cd6fafdfa38df7c1047e7c5', 'message': 'Config guide missing new settings for Ocata\n\nThe config reference[1] only mentions part of the new configs,\nsome features are missing according to release notes[2].\n[1]https://docs.openstack.org/ocata/config-reference/tables/conf-changes/keystone.html\n[2]https://docs.openstack.org/releasenotes/keystone/ocata.html\n\nChange-Id: I07b924666ecbd27fa5aff93a80fb91acef2e7f98\nCloses-Bug:#1668202\n'}]",0,438856,2368e4a13a52988c4cd6fafdfa38df7c1047e7c5,6,3,1,17645,,,0,"Config guide missing new settings for Ocata

The config reference[1] only mentions part of the new configs,
some features are missing according to release notes[2].
[1]https://docs.openstack.org/ocata/config-reference/tables/conf-changes/keystone.html
[2]https://docs.openstack.org/releasenotes/keystone/ocata.html

Change-Id: I07b924666ecbd27fa5aff93a80fb91acef2e7f98
Closes-Bug:#1668202
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/438856/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/tables/conf-changes/keystone.rst'],1,2368e4a13a52988c4cd6fafdfa38df7c1047e7c5,bug/1668202, * - ``[ldap] group_ad_nesting`` - ``None`` - ``false`` * - ``[ldap] connection_timeout`` - ``None`` - ``-1`` * - ``[security_compliance] change_password_upon_first_use`` - ``None`` - ``false`` * - ``[token] allow_expired_window`` - ``None`` - ``172800`` * - ``[token] cache_on_issue`` - ``false`` - ``true`` * - ``[token] provider`` - ``uuid`` - ``fernet`` * - ``[kvs] backends`` - ``None`` * - ``[kvs] config_prefix`` - ``None`` * - ``[kvs] enable_key_mangler`` - ``None`` * - ``[kvs] default_lock_timeout`` - ``None`` * - ``[security_compliance] password_expires_ignore_user_ids`` - ``None`` * - ``[memcache] servers`` - ``None``,,30,0
openstack%2Finstack-undercloud~master~I177a574a6481962638f727831ff12bf30f14b0b0,openstack/instack-undercloud,master,I177a574a6481962638f727831ff12bf30f14b0b0,Add UEFI specific entries into the dnsmasq-ironic config file,ABANDONED,2017-02-23 17:20:03.000000000,2017-02-28 14:24:20.000000000,,"[{'_account_id': 3}, {'_account_id': 7229}, {'_account_id': 9191}, {'_account_id': 10239}, {'_account_id': 18893}]","[{'number': 1, 'created': '2017-02-23 17:20:03.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/71203e4cc182b5f0082f3576b4b44988f85b693c', 'message': ""Add UEFI specific entries into the dnsmasq-ironic config file\n\nThis patch adds in UEFI specific configuration options for the\ndnsmasq process that's used for Ironic or TripleO node deployment.\nWithout these options, UEFI hardware fails to boot, as it's\ntypically unable to download the ipxe.efi file.\n\nThere's another patch that suggests we should remove this\nconfiguration file entirely (see #354068) in favour of using\nthe dhcp.py cmdline options set by Neutron itself. The problem\nhere is that we need to set specific entries for OUR Ironic use\ncase for UEFI systems, which is not applicable for all uses of\nNeutron's DHCP agent. The first line we can likely remove, but\nthe others are required for UEFI booting.\n\nNote that inspection is not affected by this change, this has\na different configuration file and works with UEFI already.\n\nChange-Id: I177a574a6481962638f727831ff12bf30f14b0b0\n""}]",3,437534,71203e4cc182b5f0082f3576b4b44988f85b693c,8,5,1,9191,,,0,"Add UEFI specific entries into the dnsmasq-ironic config file

This patch adds in UEFI specific configuration options for the
dnsmasq process that's used for Ironic or TripleO node deployment.
Without these options, UEFI hardware fails to boot, as it's
typically unable to download the ipxe.efi file.

There's another patch that suggests we should remove this
configuration file entirely (see #354068) in favour of using
the dhcp.py cmdline options set by Neutron itself. The problem
here is that we need to set specific entries for OUR Ironic use
case for UEFI systems, which is not applicable for all uses of
Neutron's DHCP agent. The first line we can likely remove, but
the others are required for UEFI booting.

Note that inspection is not affected by this change, this has
a different configuration file and works with UEFI already.

Change-Id: I177a574a6481962638f727831ff12bf30f14b0b0
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/34/437534/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,71203e4cc182b5f0082f3576b4b44988f85b693c,rdo/uefi-dnsmasq," content => 'dhcp-match=ipxe,175 dhcp-match=set:efi,option:client-arch,7 dhcp-boot=tag:efi,ipxe.efi enable-tftp tftp-root=/tftpboot';"," content => 'dhcp-match=ipxe,175';",6,1
openstack%2Ffreezer~master~Ic7266d46f2f30f6d519db6acdb01d6470382243d,openstack/freezer,master,Ic7266d46f2f30f6d519db6acdb01d6470382243d,Fix max_segment_size parameter,MERGED,2017-02-28 12:19:36.000000000,2017-02-28 14:22:12.000000000,2017-02-28 14:22:12.000000000,"[{'_account_id': 3}, {'_account_id': 14340}, {'_account_id': 16768}]","[{'number': 1, 'created': '2017-02-28 12:19:36.000000000', 'files': ['freezer/openstack/osclients.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/6ef45bf6580feb2cec155f95bed4920ba541651f', 'message': 'Fix max_segment_size parameter\n\nChange-Id: Ic7266d46f2f30f6d519db6acdb01d6470382243d\n'}]",0,438943,6ef45bf6580feb2cec155f95bed4920ba541651f,8,3,1,13940,,,0,"Fix max_segment_size parameter

Change-Id: Ic7266d46f2f30f6d519db6acdb01d6470382243d
",git fetch https://review.opendev.org/openstack/freezer refs/changes/43/438943/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/openstack/osclients.py'],1,6ef45bf6580feb2cec155f95bed4920ba541651f,fix-volume-backup," return utils.ReSizeStream(stream, image.size, CONF.get('max_segment_size'))"," return utils.ReSizeStream(stream, image.size, 1000000)",2,1
openstack%2Ffreezer~master~Ia2fd5d2a9ec2ab93fe710384704f009e29339596,openstack/freezer,master,Ia2fd5d2a9ec2ab93fe710384704f009e29339596,Added PrettyPrint for action: Info,MERGED,2017-02-27 10:56:46.000000000,2017-02-28 14:20:47.000000000,2017-02-28 14:20:47.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 14340}]","[{'number': 1, 'created': '2017-02-27 10:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/b79886f5bc805f0b2ddd35f8af27764093fb4547', 'message': 'Added PrettyPrint for action: Info\n\nChange-Id: Ia2fd5d2a9ec2ab93fe710384704f009e29339596\n'}, {'number': 2, 'created': '2017-02-27 10:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/3f08025797476312cebaad624561ca3366caa612', 'message': 'Added PrettyPrint for action: Info\n\nChange-Id: Ia2fd5d2a9ec2ab93fe710384704f009e29339596\n'}, {'number': 3, 'created': '2017-02-28 10:53:30.000000000', 'files': ['freezer/storage/swift.py', 'freezer/job.py', 'freezer/main.py', 'freezer/tests/unit/test_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/baa7942549e4573b78886f863b47b622a1c72f76', 'message': 'Added PrettyPrint for action: Info\n\nChange-Id: Ia2fd5d2a9ec2ab93fe710384704f009e29339596\n'}]",0,438433,baa7942549e4573b78886f863b47b622a1c72f76,10,3,3,13940,,,0,"Added PrettyPrint for action: Info

Change-Id: Ia2fd5d2a9ec2ab93fe710384704f009e29339596
",git fetch https://review.opendev.org/openstack/freezer refs/changes/33/438433/3 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/job.py', 'freezer/storage/swift.py', 'freezer/main.py']",3,b79886f5bc805f0b2ddd35f8af27764093fb4547,prettyprint-info," elif response and isinstance(response, dict): elif response and isinstance(response, list): pp = prettytable.PrettyTable() pp.field_names = response[0] for i in response[1]: pp.add_row(i) print (pp)", elif response:,31,12
openstack%2Ftripleo-quickstart~master~If3ad22a2db0cb9420264745620aa57841da5f1dd,openstack/tripleo-quickstart,master,If3ad22a2db0cb9420264745620aa57841da5f1dd,Set network isolation type to single-nic by default,MERGED,2017-02-24 07:12:04.000000000,2017-02-28 14:15:31.000000000,2017-02-28 14:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 11491}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 21513}]","[{'number': 1, 'created': '2017-02-24 07:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/79f734ef03529ecf8f86fba9e1911ce5f4399dc8', 'message': 'Set network isolation type to single-nic by default\n\nSet centos.ci network isolation type by default to single-nic.\n\nChange-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd\n'}, {'number': 2, 'created': '2017-02-24 07:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/443af1c096813bf6ca1c393e9a90d438db0b44d1', 'message': 'Set network isolation type to single-nic by default\n\nSet centos.ci network isolation type by default to single-nic.\n\nChange-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd\n'}, {'number': 3, 'created': '2017-02-26 05:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/98b3dfa6f720af0bdbe90305916b4b7eb830b234', 'message': 'Set network isolation type to single-nic by default\n\nSet centos.ci network isolation type by default to single-nic.\n\nChange-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd\n'}, {'number': 4, 'created': '2017-02-28 07:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/28be0e97f078c40d97772f14e3f9fe33f40a1f9a', 'message': 'Set network isolation type to single-nic by default\n\nSet centos.ci network isolation type by default to single-nic.\n\nChange-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd\n'}, {'number': 5, 'created': '2017-02-28 10:32:58.000000000', 'files': ['config/general_config/ceph.yml', 'config/general_config/minimal_pacemaker.yml', 'config/general_config/minimal.yml', 'roles/common/defaults/main.yml', 'config/general_config/ha_ipv6.yml', 'config/general_config/ha_big.yml', 'config/general_config/ha.yml', 'config/general_config/ha_ipa.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/56097910a5d1c742b6b80685b8f6355015e9901d', 'message': ""Set network isolation type to single-nic by default\n\nWe introduced a few network isolation types support in\npatch https://review.openstack.org/#/c/437437.\nNow it's required to set type of network isolation.\nSet centos.ci network isolation type by default to single nic\nwith vlans which was used always by quickstart before.\n\nChange-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd\n""}]",1,437816,56097910a5d1c742b6b80685b8f6355015e9901d,38,10,5,10969,,,0,"Set network isolation type to single-nic by default

We introduced a few network isolation types support in
patch https://review.openstack.org/#/c/437437.
Now it's required to set type of network isolation.
Set centos.ci network isolation type by default to single nic
with vlans which was used always by quickstart before.

Change-Id: If3ad22a2db0cb9420264745620aa57841da5f1dd
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/16/437816/2 && git format-patch -1 --stdout FETCH_HEAD,"['config/general_config/ceph.yml', 'config/general_config/minimal_pacemaker.yml', 'config/general_config/minimal.yml', 'roles/common/defaults/main.yml', 'config/general_config/ha_ipv6.yml', 'config/general_config/minimal_no_netiso.yml', 'config/general_config/ha_big.yml', 'config/general_config/ha.yml', 'config/general_config/ha_ipa.yml']",9,79f734ef03529ecf8f86fba9e1911ce5f4399dc8,multi,network_isolation_type: 'single-nic',,9,1
openstack%2Frally~master~Id81771d3600f28a7195cab61015970c31bf0a312,openstack/rally,master,Id81771d3600f28a7195cab61015970c31bf0a312,[Verify] Fix issue with verifier versions,MERGED,2017-02-07 16:51:12.000000000,2017-02-28 14:14:35.000000000,2017-02-28 14:14:35.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-02-07 16:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/911e4e639130737ca8e3eb8f6d48734548546ae8', 'message': '[Verify] Fix issue with verifier versions\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n'}, {'number': 2, 'created': '2017-02-16 13:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b2505baa6cc4283b44812a50b125c414691278d8', 'message': '[Verify] Fix issue with verifier versions\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n'}, {'number': 3, 'created': '2017-02-17 14:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/764ba5b06077503815765b93914c4db34ed74fb7', 'message': '[Verify] Fix issue with verifier versions\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n'}, {'number': 4, 'created': '2017-02-23 22:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c54542026c9cafa2ba46adebd6bd583fc6655b4d', 'message': '[Verify] Fix issue with verifier versions\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n'}, {'number': 5, 'created': '2017-02-23 22:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4a39bd4981e566e490ad2b1e9dfbfdd13805e0c9', 'message': '[Verify] Fix issue with verifier versions\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n'}, {'number': 6, 'created': '2017-02-25 09:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fb5e263b402a7a4f32742968dea9aa727aaf90ff', 'message': ""[Verify] Fix issue with verifier versions\n\nWhen we are trying to install a verifier from a local repo, the verifier\nversion will be always shown as 'master' even though the verifier repo is\nswitched to some other version (branch, tag or commit ID).  This patch is\nintended to resolve the issue.\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n""}, {'number': 7, 'created': '2017-02-27 09:56:26.000000000', 'files': ['tests/unit/verification/test_manager.py', 'rally/verification/manager.py', 'rally/cli/commands/verify.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/0fec65ad9ef709ff06b35c9c2d659751d725916f', 'message': ""[Verify] Fix issue with verifier versions\n\nWhen we are trying to install a verifier from a local repo, the verifier\nversion will be always shown as 'master' even though the verifier repo is\nswitched to some other version (branch, tag or commit ID).  This patch is\nintended to resolve the issue.\n\nChange-Id: Id81771d3600f28a7195cab61015970c31bf0a312\n""}]",3,430360,0fec65ad9ef709ff06b35c9c2d659751d725916f,27,4,7,7428,,,0,"[Verify] Fix issue with verifier versions

When we are trying to install a verifier from a local repo, the verifier
version will be always shown as 'master' even though the verifier repo is
switched to some other version (branch, tag or commit ID).  This patch is
intended to resolve the issue.

Change-Id: Id81771d3600f28a7195cab61015970c31bf0a312
",git fetch https://review.opendev.org/openstack/rally refs/changes/60/430360/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/verification/test_manager.py', 'rally/verification/manager.py', 'rally/cli/commands/verify.py']",3,911e4e639130737ca8e3eb8f6d48734548546ae8,(HEAD," source=None, version=None, system_wide=False,"," source=None, version=""master"", system_wide=False,",58,35
openstack%2Ftrove~stable%2Fnewton~I3463e75057d0d4544f6a0212da888759ab5e171b,openstack/trove,stable/newton,I3463e75057d0d4544f6a0212da888759ab5e171b,Prepare for using standard python tests,MERGED,2017-02-01 20:20:51.000000000,2017-02-28 14:14:15.000000000,2017-02-28 14:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 9664}]","[{'number': 1, 'created': '2017-02-01 20:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/020eb91686520fa4ef900dd2e664d3c2b589780a', 'message': 'Prepare for using standard python tests\n\nAdd simple script to setup mysql and postgresql databases, this script\ncan be run by users during testing and will be run by CI systems for\nspecific setup before running unit tests.\n\nThis allows to change in project-config the python-db jobs to\npython-jobs since python-jobs will call this script initially.\n\nUpdate CONTRIBUTING for this.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-November/107784.html\n\nChange-Id: I3463e75057d0d4544f6a0212da888759ab5e171b\nNeeded-By: I92e6e6502c2c516babf2bf66f3514875f77c460e\n(cherry picked from commit 6bd5974610cd3b77d966dd8ce68117ddbf3a371b)\n'}, {'number': 2, 'created': '2017-02-02 08:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6a0d4651afa06717870d2301393c969796d54e91', 'message': 'Prepare for using standard python tests\n\nAdd simple script to setup mysql and postgresql databases, this script\ncan be run by users during testing and will be run by CI systems for\nspecific setup before running unit tests.\n\nThis allows to change in project-config the python-db jobs to\npython-jobs since python-jobs will call this script initially.\n\nUpdate CONTRIBUTING for this.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-November/107784.html\n\nChange-Id: I3463e75057d0d4544f6a0212da888759ab5e171b\nNeeded-By: I92e6e6502c2c516babf2bf66f3514875f77c460e\n(cherry picked from commit 6bd5974610cd3b77d966dd8ce68117ddbf3a371b)\n'}, {'number': 3, 'created': '2017-02-02 12:14:30.000000000', 'files': ['CONTRIBUTING.rst', 'tools/test-setup.sh'], 'web_link': 'https://opendev.org/openstack/trove/commit/6a7d1aaf63ca8a156373ecb19126f5d21f4c34d5', 'message': 'Prepare for using standard python tests\n\nAdd simple script to setup mysql and postgresql databases, this script\ncan be run by users during testing and will be run by CI systems for\nspecific setup before running unit tests.\n\nThis allows to change in project-config the python-db jobs to\npython-jobs since python-jobs will call this script initially.\n\nUpdate CONTRIBUTING for this.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-November/107784.html\n\nChange-Id: I3463e75057d0d4544f6a0212da888759ab5e171b\nNeeded-By: I92e6e6502c2c516babf2bf66f3514875f77c460e\n(cherry picked from commit 6bd5974610cd3b77d966dd8ce68117ddbf3a371b)\n'}]",0,427897,6a7d1aaf63ca8a156373ecb19126f5d21f4c34d5,17,2,3,6547,,,0,"Prepare for using standard python tests

Add simple script to setup mysql and postgresql databases, this script
can be run by users during testing and will be run by CI systems for
specific setup before running unit tests.

This allows to change in project-config the python-db jobs to
python-jobs since python-jobs will call this script initially.

Update CONTRIBUTING for this.

See also
http://lists.openstack.org/pipermail/openstack-dev/2016-November/107784.html

Change-Id: I3463e75057d0d4544f6a0212da888759ab5e171b
Needed-By: I92e6e6502c2c516babf2bf66f3514875f77c460e
(cherry picked from commit 6bd5974610cd3b77d966dd8ce68117ddbf3a371b)
",git fetch https://review.opendev.org/openstack/trove refs/changes/97/427897/2 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'tools/test-setup.sh']",2,020eb91686520fa4ef900dd2e664d3c2b589780a,test-setup,"#!/bin/bash -xe # This script will be run by OpenStack CI before unit tests are run, # it sets up the test system as needed. # Developers should setup their test systems in a similar way. # This setup needs to be run as a user that can run sudo. # The root password for the MySQL database; pass it in via # MYSQL_ROOT_PW. DB_ROOT_PW=${MYSQL_ROOT_PW:-insecure_slave} # This user and its password are used by the tests, if you change it, # your tests might fail. DB_USER=openstack_citest DB_PW=openstack_citest sudo -H mysqladmin -u root password $DB_ROOT_PW # It's best practice to remove anonymous users from the database. If # a anonymous user exists, then it matches first for connections and # other connections from that host will not work. sudo -H mysql -u root -p$DB_ROOT_PW -h localhost -e "" DELETE FROM mysql.user WHERE User=''; FLUSH PRIVILEGES; GRANT ALL PRIVILEGES ON *.* TO '$DB_USER'@'%' identified by '$DB_PW' WITH GRANT OPTION;"" # Now create our database. mysql -u $DB_USER -p$DB_PW -h 127.0.0.1 -e "" SET default_storage_engine=MYISAM; DROP DATABASE IF EXISTS openstack_citest; CREATE DATABASE openstack_citest CHARACTER SET utf8;"" # Same for PostgreSQL # The root password for the PostgreSQL database; pass it in via # POSTGRES_ROOT_PW. DB_ROOT_PW=${POSTGRES_ROOT_PW:-insecure_slave} # Setup user root_roles=$(sudo -H -u postgres psql -t -c "" SELECT 'HERE' from pg_roles where rolname='$DB_USER'"") if [[ ${root_roles} == *HERE ]];then sudo -H -u postgres psql -c ""ALTER ROLE $DB_USER WITH SUPERUSER LOGIN PASSWORD '$DB_PW'"" else sudo -H -u postgres psql -c ""CREATE ROLE $DB_USER WITH SUPERUSER LOGIN PASSWORD '$DB_PW'"" fi # Store password for tests cat << EOF > $HOME/.pgpass *:*:*:$DB_USER:$DB_PW EOF chmod 0600 $HOME/.pgpass # Now create our database psql -h 127.0.0.1 -U $DB_USER -d template1 -c ""DROP DATABASE IF EXISTS {db_name}"" createdb -h 127.0.0.1 -U $DB_USER -l C -T template0 -E utf8 {db_name} ",,61,0
openstack%2Ffuel-library~master~I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352,openstack/fuel-library,master,I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352,Shift nova user config to enable_compute task,MERGED,2017-02-13 13:16:11.000000000,2017-02-28 14:12:49.000000000,2017-02-28 13:54:51.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 16771}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-13 13:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a05331e36d70adabd93cc2f2fabd449a7db855d7', 'message': 'Shift nova user config to enable_compute task\n\nMake nova user configuration before ceilometer/compute task since\nceilometer-common package reset shell of nova user to /bin/false back.\n\nChange-Id: I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352\nCloses-Bug: #1660981\n'}, {'number': 2, 'created': '2017-02-13 13:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d6651bdca202ba6be8fb29e35bace89d04f1d12d', 'message': 'Shift nova user config to enable_compute task\n\nMake nova user configuration before ceilometer/compute task since\nceilometer-common package reset shell of nova user to /bin/false back.\n\nChange-Id: I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352\nCloses-Bug: #1660981\n'}, {'number': 3, 'created': '2017-02-15 07:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bbdfe4dbc55433b2500c8d9d891a0f75e6b3f4fd', 'message': 'Shift nova user config to enable_compute task\n\nMake nova user configuration before ceilometer/compute task since\nceilometer-common package reset shell of nova user to /bin/false back.\n\nChange-Id: I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352\nCloses-Bug: #1660981\n'}, {'number': 4, 'created': '2017-02-17 10:27:54.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/roles/compute.pp', 'deployment/puppet/openstack_tasks/examples/roles/tasks.yaml', 'tests/noop/spec/hosts/roles/enable_compute_spec.rb', 'tests/noop/spec/hosts/roles/compute_spec.rb', 'deployment/puppet/openstack_tasks/manifests/roles/enable_compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2c381ff80b52191af5b4085c1fb27a79c220bf1e', 'message': 'Shift nova user config to enable_compute task\n\nMake nova user configuration before ceilometer/compute task since\nceilometer-common package reset shell of nova user to /bin/false back.\n\nChange-Id: I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352\nCloses-Bug: #1660981\n'}]",0,433047,2c381ff80b52191af5b4085c1fb27a79c220bf1e,111,13,4,16771,,,0,"Shift nova user config to enable_compute task

Make nova user configuration before ceilometer/compute task since
ceilometer-common package reset shell of nova user to /bin/false back.

Change-Id: I92be4cb23ad4ffe2cbd52562b40e336a1ad1e352
Closes-Bug: #1660981
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/47/433047/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/manifests/roles/compute.pp', 'deployment/puppet/openstack_tasks/examples/roles/tasks.yaml', 'deployment/puppet/openstack_tasks/manifests/roles/enable_compute.pp']",3,a05331e36d70adabd93cc2f2fabd449a7db855d7,nova_cold_migration," # Configure ssh key authentication between compute nodes # (required for non-live/cold migration) $ssh_key_path = '/var/lib/astute/nova' install_ssh_keys { 'nova_ssh_key_for_migration': ensure => present, user => 'nova', private_key_path => ""${ssh_key_path}/nova"", public_key_path => ""${ssh_key_path}/nova.pub"", } -> file { '/var/lib/nova/.ssh/config': ensure => present, owner => 'nova', group => 'nova', mode => '0600', content => ""Host *\n StrictHostKeyChecking no\n"", } user { 'nova': ensure => present, shell => '/bin/rbash', } ",,24,25
openstack%2Fmolteniron~master~I97c4a82a2467297223b929a29b73e6a8d41f019d,openstack/molteniron,master,I97c4a82a2467297223b929a29b73e6a8d41f019d,Return complete reservation id,MERGED,2017-02-24 18:36:41.000000000,2017-02-28 14:01:33.000000000,2017-02-28 14:01:33.000000000,"[{'_account_id': 3}, {'_account_id': 7979}, {'_account_id': 11929}, {'_account_id': 18242}]","[{'number': 1, 'created': '2017-02-24 18:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/molteniron/commit/fea417b2a9391b4dfed916f30188944d1bc6620f', 'message': 'Return complete reservation id\n\nChanged the length of the provisioned field for the\nmolteniron status command.  Also added the missing\nipmi_ip field for the blob_status aggregate.\n\nChange-Id: I97c4a82a2467297223b929a29b73e6a8d41f019d\nCloses-Bug: 1650332\n'}, {'number': 2, 'created': '2017-02-25 02:20:02.000000000', 'files': ['molteniron/moltenirond.py'], 'web_link': 'https://opendev.org/openstack/molteniron/commit/f9f122da4a25a450e68a035c50e4e54109cc70f1', 'message': 'Return complete reservation id\n\nChanged the length of the provisioned field for the\nmolteniron status command.  Also added the missing\nipmi_ip field for the blob_status aggregate.\n\nChange-Id: I97c4a82a2467297223b929a29b73e6a8d41f019d\nCloses-Bug: 1650332\n'}]",1,438039,f9f122da4a25a450e68a035c50e4e54109cc70f1,15,4,2,18242,,,0,"Return complete reservation id

Changed the length of the provisioned field for the
molteniron status command.  Also added the missing
ipmi_ip field for the blob_status aggregate.

Change-Id: I97c4a82a2467297223b929a29b73e6a8d41f019d
Closes-Bug: 1650332
",git fetch https://review.opendev.org/openstack/molteniron refs/changes/39/438039/1 && git format-patch -1 --stdout FETCH_HEAD,['molteniron/moltenirond.py'],1,fea417b2a9391b4dfed916f30188944d1bc6620f,bug/1650332," (""ipmi_ip"", 16, str, False), (""provisioned"", 40, str, False), (""provisioned"", 40, str, False), import pdb pdb.set_trace()"," (""provisioned"", 13, str, False), (""provisioned"", 13, str, False),",5,2
openstack%2Fsushy~master~Iff300172853e23628da56213081f24c70f0d0959,openstack/sushy,master,Iff300172853e23628da56213081f24c70f0d0959,Libvirt-Mockup: Add support for getting the boot source target,MERGED,2017-02-28 13:44:53.000000000,2017-02-28 13:54:59.000000000,2017-02-28 13:54:59.000000000,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-02-28 13:44:53.000000000', 'files': ['tools/mockup_server_libvirt/templates/system.json', 'tools/mockup_server_libvirt/mockup_server_libvirt.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/37fcd7ef8fac7092c7649c1a2d2f11d5f8f88a86', 'message': 'Libvirt-Mockup: Add support for getting the boot source target\n\nPrior to this patch the BootSourceOverrideTarget element of the Redfish\ntemplate was hardcoded to ""Pxe"".\n\nChange-Id: Iff300172853e23628da56213081f24c70f0d0959\n'}]",0,438966,37fcd7ef8fac7092c7649c1a2d2f11d5f8f88a86,6,2,1,6773,,,0,"Libvirt-Mockup: Add support for getting the boot source target

Prior to this patch the BootSourceOverrideTarget element of the Redfish
template was hardcoded to ""Pxe"".

Change-Id: Iff300172853e23628da56213081f24c70f0d0959
",git fetch https://review.opendev.org/openstack/sushy refs/changes/66/438966/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/mockup_server_libvirt/templates/system.json', 'tools/mockup_server_libvirt/mockup_server_libvirt.py']",2,37fcd7ef8fac7092c7649c1a2d2f11d5f8f88a86,libvirt-mockup-get-boot-source-target,"BOOT_DEVICE_MAP = {BOOT_DEVICE_MAP_REV = {v: k for k, v in BOOT_DEVICE_MAP.items()} # Get the current boot device boot_source_target = None tree = ET.fromstring(domain.XMLDesc()) boot_element = tree.find('.//boot') if boot_element is not None: boot_source_target = ( BOOT_DEVICE_MAP_REV.get(boot_element.get('dev'))) total_cpus=total_cpus, boot_source_target=boot_source_target) target = BOOT_DEVICE_MAP.get(boot.get('BootSourceOverrideTarget'))",SET_BOOT_DEVICES_MAP = { total_cpus=total_cpus) target = SET_BOOT_DEVICES_MAP.get(boot.get('BootSourceOverrideTarget')),15,5
openstack%2Frequirements~master~I2e56501d59055688a40fa276217e576601064f80,openstack/requirements,master,I2e56501d59055688a40fa276217e576601064f80,Updated from generate-constraints,MERGED,2017-02-28 09:02:55.000000000,2017-02-28 13:54:11.000000000,2017-02-28 13:54:11.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6593}, {'_account_id': 13404}]","[{'number': 1, 'created': '2017-02-28 09:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/17cdaae22fc5c0143c6c795a95bc4ddcbbd2cd99', 'message': 'Updated from generate-constraints\n\nChange-Id: I2e56501d59055688a40fa276217e576601064f80\n'}, {'number': 2, 'created': '2017-02-28 10:07:36.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4e03d7ab197000d250919cc5701a1af31d3dbad7', 'message': 'Updated from generate-constraints\n\nChange-Id: I2e56501d59055688a40fa276217e576601064f80\n'}]",0,438864,4e03d7ab197000d250919cc5701a1af31d3dbad7,8,4,2,11131,,,0,"Updated from generate-constraints

Change-Id: I2e56501d59055688a40fa276217e576601064f80
",git fetch https://review.opendev.org/openstack/requirements refs/changes/64/438864/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,17cdaae22fc5c0143c6c795a95bc4ddcbbd2cd99,openstack/requirements/constraints,WebOb===1.7.1eventlet===0.20.1oslo.messaging===5.17.1amqp===2.1.4oslo.log===3.20.1docutils===0.13.1keyring===10.3idna===2.3Sphinx===1.5.3botocore===1.5.19kombu===4.0.2,WebOb===1.6.3eventlet===0.19.0oslo.messaging===5.17.0amqp===1.4.9oslo.log===3.20.0docutils===0.12keyring===10.2idna===2.2Sphinx===1.3.6botocore===1.5.18kombu===3.0.37,11,11
openstack%2Fdevstack~master~I2dc8ea416f5eb3fcc9d2e959533497e464220ff5,openstack/devstack,master,I2dc8ea416f5eb3fcc9d2e959533497e464220ff5,Added support for fake drivers as Cinder backend,MERGED,2016-07-28 15:43:44.000000000,2017-02-28 13:53:27.000000000,2017-02-28 13:53:27.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5997}, {'_account_id': 6172}, {'_account_id': 6491}, {'_account_id': 7350}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 14305}, {'_account_id': 14510}, {'_account_id': 16376}, {'_account_id': 16803}, {'_account_id': 23117}]","[{'number': 1, 'created': '2016-07-28 15:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4208d0f6a30e8916783c93cbd21996cc985a0804', 'message': ""Added support for FakeDriver as Cinder backend\n\nFakeDriver will be used for functional Cinder tests to prevent\ndependencies on any storage and opportunity to tests such features\nlike CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}, {'number': 2, 'created': '2016-08-18 13:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0c7860bb8510c75f6c613d38e48dc0df67a24de8', 'message': ""Added support for FakeLoggingVolumeDriver and FakeGateDriver as Cinder backend\n\nFakeLoggingVolumeDriver  will be used for functional Cinder tests to prevent\ndependencies on any storage.\n\nFakeGateDriver is based on LVM and will be used to run Tempest tests for such\nfeatures like CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}, {'number': 3, 'created': '2016-08-18 20:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d4b15ff154ecc58ac1866c073da6e716fd061c3d', 'message': ""Added support for fake drivers as Cinder backend\n\nFakeLoggingVolumeDriver  will be used for functional Cinder tests to\nprevent dependencies on any storage.\n\nFakeGateDriver is based on LVM and will be used to run Tempest tests for\nsuch features like CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}, {'number': 4, 'created': '2016-09-19 09:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f07cc349f39e18f58761176a5df2cfe34342fdd1', 'message': ""Added support for fake drivers as Cinder backend\n\nFakeLoggingVolumeDriver  will be used for functional Cinder tests to\nprevent dependencies on any storage.\n\nFakeGateDriver is based on LVM and will be used to run Tempest tests for\nsuch features like CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}, {'number': 5, 'created': '2017-01-25 16:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4c37a0335562876d876f3153683d1217fadedd00', 'message': ""Added support for fake drivers as Cinder backend\n\nFakeLoggingVolumeDriver  will be used for functional Cinder tests to\nprevent dependencies on any storage.\n\nFakeGateDriver is based on LVM and will be used to run Tempest tests for\nsuch features like CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}, {'number': 6, 'created': '2017-02-22 14:15:37.000000000', 'files': ['lib/cinder_backends/fake_gate', 'lib/cinder_backends/fake'], 'web_link': 'https://opendev.org/openstack/devstack/commit/447f141d4f0e1b7be7f186714f18236c069b486e', 'message': ""Added support for fake drivers as Cinder backend\n\nFakeLoggingVolumeDriver  will be used for functional Cinder tests to\nprevent dependencies on any storage.\n\nFakeGateDriver is based on LVM and will be used to run Tempest tests for\nsuch features like CG's, replication, etc.\n\nDepends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854\nChange-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5\n""}]",4,348449,447f141d4f0e1b7be7f186714f18236c069b486e,71,18,6,1736,,,0,"Added support for fake drivers as Cinder backend

FakeLoggingVolumeDriver  will be used for functional Cinder tests to
prevent dependencies on any storage.

FakeGateDriver is based on LVM and will be used to run Tempest tests for
such features like CG's, replication, etc.

Depends-On: I383bcdb531c7d52c0fdbb6875de73f1274a92854
Change-Id: I2dc8ea416f5eb3fcc9d2e959533497e464220ff5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/49/348449/6 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder_backends/fake'],1,4208d0f6a30e8916783c93cbd21996cc985a0804,fake-cinder-backend,"#!/bin/bash # # lib/cinder_backends/fake # Configure the Fake backend # Enable with: # # CINDER_ENABLED_BACKENDS+=,fake:fake # Dependencies: # # - ``functions`` file # - ``cinder`` configurations # CINDER_CONF # clean_cinder_backend_fake - called from clean_cinder() # configure_cinder_backend_fake - called from configure_cinder() # init_cinder_backend_fake - called from init_cinder() # Save trace setting _XTRACE_CINDER_FAKE=$(set +o | grep xtrace) set +o xtrace function cleanup_cinder_backend_fake { local be_name=$1 } function configure_cinder_backend_fake { local be_name=$1 iniset $CINDER_CONF $be_name volume_backend_name $be_name iniset $CINDER_CONF $be_name volume_driver ""cinder.tests.fake_driver.FakeDriver"" } function init_cinder_backend_fake { local be_name=$1 } # Restore xtrace $_XTRACE_CINDER_FAKE # mode: shell-script # End: ",,47,0
openstack%2Fnova~stable%2Focata~Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,openstack/nova,stable/ocata,Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,Ignore deleted services in minimum version calculation,MERGED,2017-02-27 17:10:17.000000000,2017-02-28 13:50:28.000000000,2017-02-28 13:50:28.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 6062}, {'_account_id': 10118}]","[{'number': 1, 'created': '2017-02-27 17:10:17.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a1dd547d3ba7d9cf5b73da1ce9668e412501ace1', 'message': 'Ignore deleted services in minimum version calculation\n\nWhen we go to detect the minimum version for a given service, we\nshould ignore any deleted services. Without this, we will return\nthe minimum version of all records, including those that have been\ndeleted with ""nova service-delete"". This patch filters deleted\nservices from the query.\n\nCloses-Bug: #1668310\nChange-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b\n(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)\n'}]",0,438628,a1dd547d3ba7d9cf5b73da1ce9668e412501ace1,26,5,1,6873,,,0,"Ignore deleted services in minimum version calculation

When we go to detect the minimum version for a given service, we
should ignore any deleted services. Without this, we will return
the minimum version of all records, including those that have been
deleted with ""nova service-delete"". This patch filters deleted
services from the query.

Closes-Bug: #1668310
Change-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b
(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/438628/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,a1dd547d3ba7d9cf5b73da1ce9668e412501ace1,bug/1668310, filter(models.Service.deleted == 0).\,,5,0
openstack%2Fdesignate~master~I5750547486c2b69241c034a48940d8f28a7a3e56,openstack/designate,master,I5750547486c2b69241c034a48940d8f28a7a3e56,Update Architecture Doc,MERGED,2017-02-22 19:27:17.000000000,2017-02-28 13:49:14.000000000,2017-02-28 13:49:14.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-22 19:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/46ef598835b447bd1e4295f66b5c6d5657fecbbe', 'message': 'Update Architecture Doc\n\nAdd new services and update descriptions, add a high-level\ndescription of what Designate is.\n\nNew picture: http://i.imgur.com/UlDJi3t.png\n\nChange-Id: I5750547486c2b69241c034a48940d8f28a7a3e56\n'}, {'number': 2, 'created': '2017-02-22 19:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/3bd2433412d33894fba9a1568141cd060b587a12', 'message': 'Update Architecture Doc\n\nAdd new services and update descriptions, add a high-level\ndescription of what Designate is.\n\nNew picture: http://i.imgur.com/UlDJi3t.png\n\nChange-Id: I5750547486c2b69241c034a48940d8f28a7a3e56\n'}, {'number': 3, 'created': '2017-02-27 20:10:38.000000000', 'files': ['doc/source/images/Designate-Arch.png', 'doc/source/architecture.rst', 'doc/source/install/ubuntu-dev.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/d67a33e0175dfc8a064724d3ef5896d0e75f7ed4', 'message': 'Update Architecture Doc\n\nAdd new services and update descriptions, add a high-level\ndescription of what Designate is.\n\nNew picture: http://i.imgur.com/UlDJi3t.png\n\nChange-Id: I5750547486c2b69241c034a48940d8f28a7a3e56\n'}]",1,437085,d67a33e0175dfc8a064724d3ef5896d0e75f7ed4,20,3,3,8174,,,0,"Update Architecture Doc

Add new services and update descriptions, add a high-level
description of what Designate is.

New picture: http://i.imgur.com/UlDJi3t.png

Change-Id: I5750547486c2b69241c034a48940d8f28a7a3e56
",git fetch https://review.opendev.org/openstack/designate refs/changes/85/437085/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/images/Designate-Arch.png', 'doc/source/production-architecture.rst', 'doc/source/architecture.rst', 'doc/source/install/ubuntu-dev.rst']",4,46ef598835b447bd1e4295f66b5c6d5657fecbbe,docs-clean-remove,"designate-mdns, and designate-pool-manager, supported by a few",":ref:`designate-mdns`, and :ref:`designate-pool-manager`, supported by a few",12,19
openstack%2Ftripleo-heat-templates~master~Ifd1a06e0749a05a65f6314255843f572d2209067,openstack/tripleo-heat-templates,master,Ifd1a06e0749a05a65f6314255843f572d2209067,Configure SSL connection for MySQL client via client config file,MERGED,2017-02-23 13:04:54.000000000,2017-02-28 13:47:56.000000000,2017-02-28 13:47:56.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-23 13:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a405929b63956dedaca5bbfb3a7a692e25a069b', 'message': 'Configure SSL connection for MySQL client via client config file\n\nThis uses the mysql client configuration file to configure if SSL should\nbe used for the connection if SSL in the internal network is enabled.\n\nChange-Id: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 2, 'created': '2017-02-24 09:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2f0098424d7fc0a01a52de09a96c89874ec7313c', 'message': 'Configure SSL connection for MySQL client via client config file\n\nThis uses the mysql client configuration file to configure if SSL should\nbe used for the connection if SSL in the internal network is enabled.\n\nChange-Id: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}, {'number': 3, 'created': '2017-02-28 05:49:19.000000000', 'files': ['puppet/services/database/mysql-client.yaml', 'ci/environments/multinode-3nodes.yaml', 'roles_data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a4b972737825c5402d7d2b1ca7b3b4fb7f2c6e5', 'message': 'Configure SSL connection for MySQL client via client config file\n\nThis uses the mysql client configuration file to configure if SSL should\nbe used for the connection if SSL in the internal network is enabled.\n\nChange-Id: Ifd1a06e0749a05a65f6314255843f572d2209067\n'}]",3,437364,9a4b972737825c5402d7d2b1ca7b3b4fb7f2c6e5,25,9,3,10873,,,0,"Configure SSL connection for MySQL client via client config file

This uses the mysql client configuration file to configure if SSL should
be used for the connection if SSL in the internal network is enabled.

Change-Id: Ifd1a06e0749a05a65f6314255843f572d2209067
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/437364/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/database/mysql-client.yaml', 'ci/environments/multinode-3nodes.yaml', 'roles_data.yaml']",3,6a405929b63956dedaca5bbfb3a7a692e25a069b,mysql-ssl, - OS::TripleO::Services::MySQLClient - OS::TripleO::Services::MySQLClient - OS::TripleO::Services::MySQLClient - OS::TripleO::Services::MySQLClient,,9,0
openstack%2Fopenstack-manuals~master~I281052002498706a5b3499c4fe5fddc2d781a510,openstack/openstack-manuals,master,I281052002498706a5b3499c4fe5fddc2d781a510,"[user-guide] Replace ""tenant"" with ""project""",ABANDONED,2017-02-25 09:21:42.000000000,2017-02-28 13:47:31.000000000,,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14962}, {'_account_id': 18464}]","[{'number': 1, 'created': '2017-02-25 09:21:42.000000000', 'files': ['doc/user-guide/source/cli-launch-instances.rst', 'doc/user-guide/source/dashboard-log-in.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a8daa5e1722c63c805b5e53c18b708770a2664b', 'message': '[user-guide] Replace ""tenant"" with ""project""\n\nChange-Id: I281052002498706a5b3499c4fe5fddc2d781a510\nPartial-Bug: #1475005\n'}]",2,438162,0a8daa5e1722c63c805b5e53c18b708770a2664b,7,4,1,14151,,,0,"[user-guide] Replace ""tenant"" with ""project""

Change-Id: I281052002498706a5b3499c4fe5fddc2d781a510
Partial-Bug: #1475005
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/438162/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/source/cli-launch-instances.rst', 'doc/user-guide/source/dashboard-log-in.rst']",2,0a8daa5e1722c63c805b5e53c18b708770a2664b,bug/1475005,projects or accounts. Each user is a member of one or more projects.,tenants or accounts. Each user is a member of one or more projects.,2,2
openstack%2Ftripleo-quickstart-extras~master~Ie36073a0e7cda2c24d51305860049f2d8dcbb17e,openstack/tripleo-quickstart-extras,master,Ie36073a0e7cda2c24d51305860049f2d8dcbb17e,collect-logs: use rsync to gather logs,MERGED,2017-02-24 11:49:24.000000000,2017-02-28 13:39:46.000000000,2017-02-28 13:34:33.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 11491}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-02-24 11:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ffe8150484c9702e781e8e7a259dd7de83b2741d', 'message': 'collect-logs: use rsync to gather logs\n\nThis allows us to support excluding files during the copy step, avoiding\ntime consuming copy operations.\n\nChange-Id: Ie36073a0e7cda2c24d51305860049f2d8dcbb17e\n'}, {'number': 2, 'created': '2017-02-24 17:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4d3651b4d57b0b902425c3a24224a40bb7a06914', 'message': 'collect-logs: use rsync to gather logs\n\n* Support excluding files during the copy step, avoiding\n  time consuming copy operations.\n\n* Empty directories are no longer collected. This results in a cleaner\n  directory tree while browsing the collected files.\n\n* The extra exclude items are just there to speed up rsync pattern\n  matching as there are a lot of subdirs in /dev, /proc, /run, /sys and\n  we generally do not want to collect files from there. It is possible\n  to override it if needed.\n\n* Directory definitions now need to end with / or with * to get\n  collected.\n\nChange-Id: Ie36073a0e7cda2c24d51305860049f2d8dcbb17e\n'}, {'number': 3, 'created': '2017-02-27 15:56:41.000000000', 'files': ['roles/collect-logs/README.md', 'roles/collect-logs/tasks/collect.yml', 'roles/collect-logs/defaults/main.yml', 'roles/collect-logs/templates/rsync-filter.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8aac167c21640a73c8bc088ff573d3a138ec592f', 'message': 'collect-logs: use rsync to gather logs\n\n* Support excluding files during the copy step, avoiding\n  time consuming copy operations.\n\n* Empty directories are no longer collected. This results in a cleaner\n  directory tree while browsing the collected files.\n\n* The extra exclude items are just there to speed up rsync pattern\n  matching as there are a lot of subdirs in /dev, /proc, /run, /sys and\n  we generally do not want to collect files from there. It is possible\n  to override it if needed.\n\n* Directory definitions now need to end with / or with * to get\n  collected.\n\nChange-Id: Ie36073a0e7cda2c24d51305860049f2d8dcbb17e\n'}]",5,437878,8aac167c21640a73c8bc088ff573d3a138ec592f,46,8,3,8652,,,0,"collect-logs: use rsync to gather logs

* Support excluding files during the copy step, avoiding
  time consuming copy operations.

* Empty directories are no longer collected. This results in a cleaner
  directory tree while browsing the collected files.

* The extra exclude items are just there to speed up rsync pattern
  matching as there are a lot of subdirs in /dev, /proc, /run, /sys and
  we generally do not want to collect files from there. It is possible
  to override it if needed.

* Directory definitions now need to end with / or with * to get
  collected.

Change-Id: Ie36073a0e7cda2c24d51305860049f2d8dcbb17e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/78/437878/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/collect-logs/tasks/collect.yml'],1,ffe8150484c9702e781e8e7a259dd7de83b2741d,collect-logs,"- name: Create temp directory before gathering logs file: dest: ""/tmp/{{ inventory_hostname }}"" state: directory rsync --delete {{ collect_list }} {% for exclude_path in artcl_exclude_list|default([]) %} --exclude {{ exclude_path }} {% endfor %} /tmp/{{ inventory_hostname }};"," mkdir -p /tmp/{{ inventory_hostname }}; for F in $(ls -d1 /var/log/rpm.list /var/log/extra {{ collect_list }}); do cp -rL --parents $F /tmp/{{ inventory_hostname }}; done; find /tmp/{{ inventory_hostname }} -not -type f -not -type d -delete; for D in {{ artcl_exclude_list | default([]) | join(' ') }}; do rm -rf ""/tmp/{{ inventory_hostname }}/$D""; done;",10,8
openstack%2Fbarbican-tempest-plugin~master~I18f5c726513b68083d8a5793b8eb391b421b8514,openstack/barbican-tempest-plugin,master,I18f5c726513b68083d8a5793b8eb391b421b8514,Remove tempest-lib from requirements.txt,MERGED,2017-02-24 14:51:22.000000000,2017-02-28 13:37:48.000000000,2017-02-28 13:37:48.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 6783}, {'_account_id': 7012}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11561}, {'_account_id': 16046}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-24 14:51:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/c5ad78f1ba89e4907a783f86531ebf01344328b5', 'message': 'Remove tempest-lib from requirements.txt\n\nIt is not used and also deprecated in favor of tempest.lib (from tempest\nitself).\n\nChange-Id: I18f5c726513b68083d8a5793b8eb391b421b8514\n'}]",0,437930,c5ad78f1ba89e4907a783f86531ebf01344328b5,10,13,1,7102,,,0,"Remove tempest-lib from requirements.txt

It is not used and also deprecated in favor of tempest.lib (from tempest
itself).

Change-Id: I18f5c726513b68083d8a5793b8eb391b421b8514
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/30/437930/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c5ad78f1ba89e4907a783f86531ebf01344328b5,,,tempest-lib>=0.14.0 # Apache-2.0,0,1
openstack%2Fneutron~master~I586da8491aebf99907b2f7da34b483bbde045d04,openstack/neutron,master,I586da8491aebf99907b2f7da34b483bbde045d04,DNM: testing disallow update provder-net attrs,ABANDONED,2017-02-10 18:35:18.000000000,2017-02-28 13:37:38.000000000,,"[{'_account_id': 3}, {'_account_id': 5367}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-10 18:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/07be165b1ecc771e44157e3a63cfbdab0f21fba9', 'message': 'DNM: testing disallow update provder-net attrs\n\nDO NOT MERGE THIS PATCH\n\nFor testing with neutron-lib patch [1].\n\n[1] https://review.openstack.org/#/c/421961/\n\nChange-Id: I586da8491aebf99907b2f7da34b483bbde045d04\n'}, {'number': 2, 'created': '2017-02-10 20:37:02.000000000', 'files': ['neutron/tests/unit/extensions/test_providernet.py', 'neutron/db/l3_hamode_db.py', 'neutron/tests/functional/scheduler/test_dhcp_agent_scheduler.py', 'neutron/extensions/multiprovidernet.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/extensions/providernet.py', 'neutron/tests/unit/plugins/ml2/extensions/test_dns_integration.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/managers.py', 'neutron/tests/unit/db/test_l3_hamode_db.py', 'neutron/extensions/segment.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb14f2e87e2cbbbbfec44e2e8678afbed6784466', 'message': 'DNM: testing disallow update provder-net attrs\n\nDO NOT MERGE THIS PATCH\n\nFor testing with neutron-lib patch [1].\n\n[1] https://review.openstack.org/#/c/421961/\n\nChange-Id: I586da8491aebf99907b2f7da34b483bbde045d04\n'}]",0,432418,eb14f2e87e2cbbbbfec44e2e8678afbed6784466,18,8,2,5367,,,0,"DNM: testing disallow update provder-net attrs

DO NOT MERGE THIS PATCH

For testing with neutron-lib patch [1].

[1] https://review.openstack.org/#/c/421961/

Change-Id: I586da8491aebf99907b2f7da34b483bbde045d04
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/432418/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/extensions/providernet.py', 'neutron/plugins/ml2/plugin.py']",2,07be165b1ecc771e44157e3a63cfbdab0f21fba9,bug/1428062,, provider._raise_if_updates_provider_attributes(net_data),0,17
openstack%2Fnova-specs~master~I4d87fd0cc8148aa90a1968064378b11a0d7b65c1,openstack/nova-specs,master,I4d87fd0cc8148aa90a1968064378b11a0d7b65c1,Add prep-for-network-aware-scheduling-pike spec,MERGED,2017-02-10 23:01:08.000000000,2017-02-28 13:34:46.000000000,2017-02-28 13:34:46.000000000,"[{'_account_id': 3}, {'_account_id': 782}]","[{'number': 1, 'created': '2017-02-10 23:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/59a3971b79aed7391a82e73fbdbc58c61b2712c3', 'message': 'Add prep-for-network-aware-scheduling-pike spec\n\nChange how we talk to neutron to allow us in the future to implement\nnetwork aware scheduling.\n\nThis is continuation of the work started during newton.\n\nThis is a priority, because this blocks routed networks, which is\nblocking the removal of cells v1.\n\nblueprint prep-for-network-aware-scheduling-pike\n\nChange-Id: I4d87fd0cc8148aa90a1968064378b11a0d7b65c1\n'}, {'number': 2, 'created': '2017-02-28 13:26:21.000000000', 'files': ['specs/pike/approved/prep-for-network-aware-scheduling-pike.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/04f25414c2a788e24190c10ed92e686a3542c2ca', 'message': 'Add prep-for-network-aware-scheduling-pike spec\n\nChange how we talk to neutron to allow us in the future to implement\nnetwork aware scheduling.\n\nThis is continuation of the work started during newton.\n\nThis is a important, because this blocks routed networks, which is\nblocking the removal of cells v1.\n\nblueprint prep-for-network-aware-scheduling-pike\nPreviously-Approved: Ocata\n\nChange-Id: I4d87fd0cc8148aa90a1968064378b11a0d7b65c1\n'}]",2,432489,04f25414c2a788e24190c10ed92e686a3542c2ca,10,2,2,18339,,,0,"Add prep-for-network-aware-scheduling-pike spec

Change how we talk to neutron to allow us in the future to implement
network aware scheduling.

This is continuation of the work started during newton.

This is a important, because this blocks routed networks, which is
blocking the removal of cells v1.

blueprint prep-for-network-aware-scheduling-pike
Previously-Approved: Ocata

Change-Id: I4d87fd0cc8148aa90a1968064378b11a0d7b65c1
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/89/432489/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/prep-for-network-aware-scheduling-pike.rst'],1,59a3971b79aed7391a82e73fbdbc58c61b2712c3,bp/prep-for-network-aware-scheduling-pike,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Prep work for Network aware scheduling (Pike) ============================================== https://blueprints.launchpad.net/nova/+spec/prep-for-network-aware-scheduling-pike Change how we talk to neutron to allow us in the future to implement network aware scheduling. This continues on from the work started in Newton: http://specs.openstack.org/openstack/nova-specs/specs/newton/implemented/prep-for-network-aware-scheduling.html Problem description =================== Some IP subnets can be restricted to a subset of hosts, due to an operators network configuration. In this environment, it means you could build somewhere that has no public IPs available. The ability to manage IP addresses in this way is being added into Neutron by the Routed Networks feature: * http://specs.openstack.org/openstack/neutron-specs/specs/newton/routed-networks.html * https://specs.openstack.org/openstack/nova-specs/specs/newton/implemented/neutron-routed-networks.html To make this possible, we need to know the details of all the user's requested ports, and what resources are required, before asking the scheduler for a host. In addition, after picking a location, we should check that there is an IP available before continuing with the rest of the build process. As an aside, the allocate_for_instance call currently contains both parts of that operation and has proved very difficult to maintain and evolve. In newton, we changed the code to separate the update and create operations, so we are now able to look at moving where those operations happen. Use Cases --------- This is largely a code refactor. Proposed change =============== In newton we have changed the code inside allocate_for_instance into clear get/create and update phase. We need to complete the split, by ensuring the network info cache contains all the info required to be shared between the two phases of the operation (get/create ports and update ports). Should a build request fail, and the build is retried on a different host, the ports that Nova creates should be re-used for the new build attempt, just like the ports that are passed into Nova. This bug fix requires the data to be correctly passed in a very similar way, so will be the initial focus of this effort. Second, we want to move the get/create ports before the scheduler is called. In terms of upgrades, we need to ensure old compute nodes don't re-create ports that the conductor has already created. Similarly, when deleting an instance, the old node should still correctly know which ports were created by Nova and can be deleted when the instance is deleted, in the usual way. For nova-network users, the get/create ports can be a noop. To avoid problems across upgrades, the early creating of ports is not allowed until all nova-compute nodes are upgraded to the version that understands if a port has been created or not. Once all are upgraded, and credentials are available on the nova-conductor node, ports will be created before calling the scheduler. The third step is to move the port update into the conductor, right after the scheduler has picked an appropriate host. We will not be able to run this code until all compute nodes have been upgraded to the newest version. Until all nodes have been upgraded, the new nodes will still have to run this code on the Compute node. While annoying, this move is only to help with faster retries, and as such, should not block any progress. Note this port update step includes setting the host on the port, and in the future will be the point an IP is assigned, if the port does not yet have an IP. It is useful to update the port bindings in the conductor, so any failure in the port binding for a specific host can quickly trigger a retry. This is particularly a problem when you have routed networks, and segments can run out of IP addresses independently. For nova-network, we can run the existing allocate-for-instance logic in the conductor, after the scheduler is called. For cells v1 users, this should correctly be in the child cell conductor, because each cells v1 cell has its own separate nova-network instance with a different set of IP addresses. (For cells v2 users, the networking is global to the nova deployment, so its doesn't matter where that happens.) Alternatives ------------ We could attempt to add more complexity into the existing allocate_for_instance code. But history has shown that is likely to create many regressions. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- Eventually it could mean we don't need any neutron related credentials on any of the compute nodes. This work will not achieve that goal, but it is a step in the right direction. Notifications impact -------------------- Notifications may now have a different host and service, but they should be otherwise identical. Other end user impact --------------------- None Performance Impact ------------------ Currently the neutron port binding is done in parallel with other long running tasks that the compute node performs during the boot process. This moves the port creation and binding into the critical path of the boot process. When Nova is creating ports for users, instead of just calling port create with all the parameters, will now first create the port and later update the port. This will slightly increase the load on the Neutron API during the boot process. However this should be minimal, as we are not duplicating any of the expensive parts of the process, such as port binding and IP allocation. This also generally moves more load into the nova-conductor nodes, but on the upside this reduces the load on the nova-compute nodes. Other deployer impact --------------------- We will need the neutron credentials on nova-conductor, which may not currently have been happening. To maintain our upgrade promise, we will fall back to the old behaviour for one cycle to give deployers a warning about the missing credentials. The following cycle will require the credentials to be present on nova-conductor. Developer impact ---------------- Improved ability to understand allocate_for_instance, and its replacements. Implementation ============== Assignee(s) ----------- Primary assignee: John Garbutt (IRC: johnthetubaguy) Work Items ---------- * Split allocate_for_instance into two functions * Move create/get port call into the conductor, before calling the scheduler, such that allocate_for_instance no longer creates ports, no op for nova-net. This is likely to be achieved by adding a new method into the network API for both neutron and nova-net. * Move the remainder of allocate_for_instance call into conductor, for both nova-net and neutron Dependencies ============ None (however, several things depend on this work) Testing ======= Grenade + neutron should ensure the pre-upgrade flow is covered, the regular gate tests should ensure the post-upgrade flow is covered. We should add functional tests to test the re-schedule flow. We might also need functional tests to check the transition between the pre and post upgrade flows. Documentation Impact ==================== Need to describe the transition in the release notes, and release specific upgrade documentation, at a minimum. References ========== * Previous work: http://specs.openstack.org/openstack/nova-specs/specs/newton/implemented/prep-for-network-aware-scheduling.html * Neutron Routed network spec: http://specs.openstack.org/openstack/neutron-specs/specs/newton/routed-networks.html * Nova Routed network spec: https://specs.openstack.org/openstack/nova-specs/specs/newton/implemented/neutron-routed-networks.html History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Newton - Introduced * - Ocata - Continued ",,218,0
openstack%2Ftripleo-heat-templates~master~I003ad5449bd99c01376781ec0ce9074eca3e2704,openstack/tripleo-heat-templates,master,I003ad5449bd99c01376781ec0ce9074eca3e2704,Adds http proxy support for registering RHEL overcloud nodes,MERGED,2017-02-23 04:51:22.000000000,2017-02-28 13:28:15.000000000,2017-02-28 07:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}]","[{'number': 1, 'created': '2017-02-23 04:51:22.000000000', 'files': ['extraconfig/pre_deploy/rhel-registration/environment-rhel-registration.yaml', 'extraconfig/pre_deploy/rhel-registration/scripts/rhel-registration', 'extraconfig/pre_deploy/rhel-registration/rhel-registration.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3002edc90a631f3adb8ae0ee696062347f94ea52', 'message': 'Adds http proxy support for registering RHEL overcloud nodes\n\nIt is quite common in large entreprises that direct HTTP/HTTPS to the outside\nworld is denied from nodes/systems but reaching out through a proxy is allowed.\n\nThis change adds support for an HTTP proxy when RHEL overcloud nodes reach\nout to either the RHSM portal or to a satellite server. This allows the\novercloud nodes to download updates even in locked-down environments.\n\nThe following variables are settable through templates:\n  rhel_reg_http_proxy_host:\n  rhel_reg_http_proxy_port:\n  rhel_reg_http_proxy_username:\n  rhel_reg_http_proxy_password:\n\nNote the following restrictions:\n  - If setting rhel_reg_http_proxy_host,\n    then rhel_reg_http_proxy_port cannot be empty.\n  - If setting rhel_reg_http_proxy_port,\n    then rhel_reg_http_proxy_host cannot be empty.\n  - If setting rhel_reg_http_proxy_username,\n    then rhel_reg_http_proxy_password cannot be empty.\n  - If setting rhel_reg_http_proxy_password,\n    then rhel_reg_http_proxy_username cannot be empty.\n  - If setting either rhel_reg_http_proxy_username or\n    rhel_reg_http_proxy_password, then rhel_reg_http_proxy_host\n    AND rhel_reg_http_proxy_port cannot be empty\n\nChange-Id: I003ad5449bd99c01376781ec0ce9074eca3e2704\n'}]",0,437247,3002edc90a631f3adb8ae0ee696062347f94ea52,12,3,1,19743,,,0,"Adds http proxy support for registering RHEL overcloud nodes

It is quite common in large entreprises that direct HTTP/HTTPS to the outside
world is denied from nodes/systems but reaching out through a proxy is allowed.

This change adds support for an HTTP proxy when RHEL overcloud nodes reach
out to either the RHSM portal or to a satellite server. This allows the
overcloud nodes to download updates even in locked-down environments.

The following variables are settable through templates:
  rhel_reg_http_proxy_host:
  rhel_reg_http_proxy_port:
  rhel_reg_http_proxy_username:
  rhel_reg_http_proxy_password:

Note the following restrictions:
  - If setting rhel_reg_http_proxy_host,
    then rhel_reg_http_proxy_port cannot be empty.
  - If setting rhel_reg_http_proxy_port,
    then rhel_reg_http_proxy_host cannot be empty.
  - If setting rhel_reg_http_proxy_username,
    then rhel_reg_http_proxy_password cannot be empty.
  - If setting rhel_reg_http_proxy_password,
    then rhel_reg_http_proxy_username cannot be empty.
  - If setting either rhel_reg_http_proxy_username or
    rhel_reg_http_proxy_password, then rhel_reg_http_proxy_host
    AND rhel_reg_http_proxy_port cannot be empty

Change-Id: I003ad5449bd99c01376781ec0ce9074eca3e2704
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/437247/1 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/pre_deploy/rhel-registration/environment-rhel-registration.yaml', 'extraconfig/pre_deploy/rhel-registration/scripts/rhel-registration', 'extraconfig/pre_deploy/rhel-registration/rhel-registration.yaml']",3,3002edc90a631f3adb8ae0ee696062347f94ea52,rhel_reg_proxy_support, rhel_reg_http_proxy_host: type: string rhel_reg_http_proxy_port: type: string rhel_reg_http_proxy_username: type: string rhel_reg_http_proxy_password: type: string - name: REG_HTTP_PROXY_HOST - name: REG_HTTP_PROXY_PORT - name: REG_HTTP_PROXY_USERNAME - name: REG_HTTP_PROXY_PASSWORD REG_HTTP_PROXY_HOST: {get_param: rhel_reg_http_proxy_host} REG_HTTP_PROXY_PORT: {get_param: rhel_reg_http_proxy_port} REG_HTTP_PROXY_USERNAME: {get_param: rhel_reg_http_proxy_username} REG_HTTP_PROXY_PASSWORD: {get_param: rhel_reg_http_proxy_password},,100,0
openstack%2Fneutron~master~I78f3d4fcd4327492d9906cf11c1b5b3e544ac7f7,openstack/neutron,master,I78f3d4fcd4327492d9906cf11c1b5b3e544ac7f7,DNM: test lib extension descriptor,ABANDONED,2017-02-14 21:16:03.000000000,2017-02-28 13:18:55.000000000,,"[{'_account_id': 3}, {'_account_id': 5367}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10385}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-14 21:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b85edde4096152e74e0b4bccf0c75dae435f3f78', 'message': 'DNM: test lib extension descriptor\n\nDO NOT MERGE THIS PATCH\n\nFor testing with neutron-lib patch [1].\n\n[1] https://review.openstack.org/#/c/430334/\n\nChange-Id: I78f3d4fcd4327492d9906cf11c1b5b3e544ac7f7\n'}, {'number': 2, 'created': '2017-02-27 17:56:41.000000000', 'files': ['neutron/tests/unit/extensions/test_providernet.py', 'neutron/db/l3_hamode_db.py', 'neutron/tests/functional/scheduler/test_dhcp_agent_scheduler.py', 'neutron/extensions/multiprovidernet.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/extensions/providernet.py', 'neutron/tests/unit/plugins/ml2/extensions/test_dns_integration.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/managers.py', 'neutron/tests/unit/db/test_l3_hamode_db.py', 'neutron/extensions/segment.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7860f78cd086b562a688f8fa4fe265bc0a91afa', 'message': 'DNM: test lib extension descriptor\n\nDO NOT MERGE THIS PATCH\n\nFor testing with neutron-lib patch [1].\n\n[1] https://review.openstack.org/#/c/430334/\n\nChange-Id: I78f3d4fcd4327492d9906cf11c1b5b3e544ac7f7\n'}]",0,433929,a7860f78cd086b562a688f8fa4fe265bc0a91afa,21,11,2,5367,,,0,"DNM: test lib extension descriptor

DO NOT MERGE THIS PATCH

For testing with neutron-lib patch [1].

[1] https://review.openstack.org/#/c/430334/

Change-Id: I78f3d4fcd4327492d9906cf11c1b5b3e544ac7f7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/433929/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_providernet.py', 'neutron/db/l3_hamode_db.py', 'neutron/tests/functional/scheduler/test_dhcp_agent_scheduler.py', 'neutron/extensions/multiprovidernet.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/extensions/providernet.py', 'neutron/tests/unit/plugins/ml2/extensions/test_dns_integration.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/managers.py', 'neutron/tests/unit/db/test_l3_hamode_db.py', 'neutron/extensions/segment.py']",12,b85edde4096152e74e0b4bccf0c75dae435f3f78,boilerplate-ext-descriptor,from neutron_lib.api.definitions import provider_net as providernet,from neutron.extensions import providernet,22,89
openstack%2Fproject-config~master~I6500815e19119f0c1544eaaa39e1651cd5b30202,openstack/project-config,master,I6500815e19119f0c1544eaaa39e1651cd5b30202,Updates to Chef OpenStack project,MERGED,2017-02-27 14:11:55.000000000,2017-02-28 13:11:12.000000000,2017-02-28 13:11:11.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 11915}, {'_account_id': 14790}]","[{'number': 1, 'created': '2017-02-27 14:11:55.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2926fb9605c50aa4348c406cf5da2de3573faab3', 'message': 'Updates to Chef OpenStack project\n\n- Add new branches to gerritbot and clean up old branches.\n- Remove jobs running on Ubuntu Trusty.\n\nChange-Id: I6500815e19119f0c1544eaaa39e1651cd5b30202\n'}]",2,438501,2926fb9605c50aa4348c406cf5da2de3573faab3,18,5,1,13252,,,0,"Updates to Chef OpenStack project

- Add new branches to gerritbot and clean up old branches.
- Remove jobs running on Ubuntu Trusty.

Change-Id: I6500815e19119f0c1544eaaa39e1651cd5b30202
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/438501/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",4,2926fb9605c50aa4348c406cf5da2de3573faab3,update-chef,, - 'gate-{name}-chef-rake-integration-ubuntu-trusty-nv' - periodic-openstack-chef-repo-chef-rake-integration-ubuntu-trusty,2,7
openstack%2Fopenstack-manuals~master~Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547,openstack/openstack-manuals,master,Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547,telemetry: reorg and cleanup data collection,MERGED,2017-02-22 15:07:15.000000000,2017-02-28 12:59:10.000000000,2017-02-28 12:59:10.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-02-22 15:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/90ff5b0fc5172cc82f75320ca25ade7c87fe55d3', 'message': ""telemetry: reorg and cleanup data collection\n\n- ha notes are redundant to ha-guide. move stuff there and just\nreference it\n- move meter definition section under notifications as that's what\nit relates to\n- move the configuration of standard meters to install guide.\n\nChange-Id: Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547\n""}, {'number': 2, 'created': '2017-02-22 17:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4fef7ee977f9f0b1510eff712726e169ca77f29a', 'message': ""telemetry: reorg and cleanup data collection\n\n- ha notes are redundant to ha-guide\n- move meter definition section under notifications as that's what\nit relates to\n- move the configuration of standard meters to install guide.\n\nChange-Id: Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547\n""}, {'number': 3, 'created': '2017-02-22 18:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fb4f118fda66c74d2e6a61e5d6444eb75c719cd3', 'message': ""telemetry: reorg and cleanup data collection\n\n- ha notes are redundant to ha-guide\n- move meter definition section under notifications as that's what\nit relates to\n- move the configuration of standard meters to install guide.\n\nChange-Id: Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547\n""}, {'number': 4, 'created': '2017-02-28 12:07:56.000000000', 'files': ['doc/admin-guide/source/telemetry-alarms.rst', 'doc/admin-guide/source/telemetry-best-practices.rst', 'doc/admin-guide/source/telemetry-data-collection.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b6946421d0402f1c8dd49e3023a2e5eb5e4b9d37', 'message': ""telemetry: reorg and cleanup data collection\n\n- ha notes are redundant to ha-guide\n- move meter definition section under notifications as that's what\nit relates to\n- move the configuration of standard meters to install guide.\n\nChange-Id: Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547\n""}]",2,436970,b6946421d0402f1c8dd49e3023a2e5eb5e4b9d37,15,5,4,6537,,,0,"telemetry: reorg and cleanup data collection

- ha notes are redundant to ha-guide
- move meter definition section under notifications as that's what
it relates to
- move the configuration of standard meters to install guide.

Change-Id: Ib09dea06c609e3611a8a9d20d5f3a1c8f757a547
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/436970/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide/source/telemetry-data-collection.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst']",2,90ff5b0fc5172cc82f75320ca25ade7c87fe55d3,docs,========================== Highly available Telemetry ==========================Telemetry polling agentThe Telemetry polling agent can be configured to partition its polling,============================== Highly available Telemetry API ==============================Telemetry central agentThe Telemetry central agent can be configured to partition its polling,135,238
openstack%2Fopenstack-manuals~master~I81d0ce68473efd2e327518d805bb20f3916f2e65,openstack/openstack-manuals,master,I81d0ce68473efd2e327518d805bb20f3916f2e65,Imported Translations from Zanata,MERGED,2017-02-28 10:15:23.000000000,2017-02-28 12:58:44.000000000,2017-02-28 12:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-02-28 10:15:23.000000000', 'files': ['doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/common/source/locale/zh_CN/LC_MESSAGES/common.po', 'doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/common/source/locale/ja/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/40a411b3869fec18ddb660f6245549a4670b4a30', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I81d0ce68473efd2e327518d805bb20f3916f2e65\n'}]",0,438893,40a411b3869fec18ddb660f6245549a4670b4a30,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I81d0ce68473efd2e327518d805bb20f3916f2e65
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/438893/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/common/source/locale/zh_CN/LC_MESSAGES/common.po', 'doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/common/source/locale/ja/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po']",11,40a411b3869fec18ddb660f6245549a4670b4a30,zanata/translations,"""POT-Creation-Date: 2017-02-28 05:57+0000\n""""PO-Revision-Date: 2017-02-27 10:31+0000\n""""In addition to ``rhel-7-server-rpms``, you also need to have the ``rhel-7-"" ""server-optional-rpms``, ``rhel-7-server-extras-rpms``, and ``rhel-7-server-"" ""rh-common-rpms`` repositories enabled:"" msgstr """" ""``rhel-7-server-rpms`` ``rhel-7-server-optional-rpms````rhel-7-"" ""server-extras-rpms````rhel-7-server-rh-common-rpms`` "" """" msgid """"msgid """" ""Starting with the Newton release, SUSE OpenStack packages are shipping with "" ""the upstream default configuration files. For example ``/etc/glance/glance-"" ""api.conf`` or ``/etc/glance/glance-registry.conf``, with customizations in "" ""``/etc/glance/glance-api.conf.d/`` or ``/etc/glance/glance-registry.conf.d/"" ""``. While the following instructions modify the default configuration files, "" ""adding new files in ``/etc/glance/glance-api.conf.d`` or ``/etc/glance/"" ""glance-registry.conf.d`` achieves the same result."" msgstr """" ""Newton SUSE OpenStack "" ""``/etc/glance/glance-api.conf``  "" ""``/etc/glance/glance-registry.conf``  ``/etc/glance/"" ""glance-api.conf.d/``  ``/etc/glance/glance-registry.conf.d/`` "" ""``/etc/glance/glance-api."" ""conf.d/``  ``/etc/glance/glance-registry.conf.d/`` "" """" msgid """" ""Starting with the Newton release, SUSE OpenStack packages are shipping with "" ""the upstream default configuration files. For example ``/etc/keystone/"" ""keystone.conf``, with customizations in ``/etc/keystone/keystone.conf.d/010-"" ""keystone.conf``. While the following instructions modify the default "" ""configuration file, adding a new file in ``/etc/keystone/keystone.conf.d`` "" ""achieves the same result."" msgstr """" ""Newton SUSE OpenStack "" ""``/etc/keystone/keystone.conf`` "" "" ``/etc/keystone/keystone.conf.d/010-keystone.conf`` "" ""``/etc/keystone/"" ""keystone.conf.d`` "" """" msgid """" ""When using RHEL, it is assumed that you have registered your system using "" ""Red Hat Subscription Management and that you have the ``rhel-7-server-rpms`` "" ""repository enabled by default."" msgstr """" ""RHEL  Red Hat Subscription Management "" "" ``rhel-7-server-rpms``"" """" ","""POT-Creation-Date: 2017-02-27 00:08+0000\n""""PO-Revision-Date: 2017-02-22 04:53+0000\n""",439,428
openstack%2Ffuel-web~master~I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247,openstack/fuel-web,master,I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247,Remove Ceilometer and MongoDB code,ABANDONED,2017-02-22 07:58:04.000000000,2017-02-28 12:57:56.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2017-02-22 07:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4ad0a598de616c7271867dc36fbe6dd74f729af2', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}, {'number': 2, 'created': '2017-02-22 14:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ebe1f2c0b6bdb5e3140c1dd1f8a3ae1dc4ae67b0', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}, {'number': 3, 'created': '2017-02-27 10:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fe5f8672d4fb5f190bcf69e67db40a94623826a9', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}, {'number': 4, 'created': '2017-02-27 10:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ac749de6975cef8daad381b6cf181da5ac6c0764', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}, {'number': 5, 'created': '2017-02-27 13:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/839d8e97ac610d499ef9a67d3a97e669cd08ccc1', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}, {'number': 6, 'created': '2017-02-27 14:13:05.000000000', 'files': ['nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/objects/release.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer_70.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ef76030ef1ff897c568867b351c06ec242e3c38e', 'message': 'Remove Ceilometer and MongoDB code\n\nChange-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247\n'}]",0,436809,ef76030ef1ff897c568867b351c06ec242e3c38e,108,4,6,8766,,,0,"Remove Ceilometer and MongoDB code

Change-Id: I62125a90c8cb87c9b8b9d22f3ee3c66ce508a247
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/09/436809/6 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/fixtures/openstack.yaml'],1,4ad0a598de616c7271867dc36fbe6dd74f729af2,remove-ceilometer,," mongo: name: ""Telemetry - MongoDB"" description: ""A feature-complete and recommended database for storage of metering data from OpenStack Telemetry (Ceilometer)."" weight: 60 group: ""other"" conflicts: - compute - ceph-osd limits: min: 1 overrides: - condition: ""cluster:mode != 'ha_compact'"" max: 1 message: ""At most 1 MongoDB node can be added for non-HA deployment"" - condition: ""cluster:mode == 'ha_compact'"" recommended: 3 message: ""At least 3 MongoDB nodes are recommended for HA deployment."" restrictions: - condition: ""settings:additional_components.ceilometer.value == false"" message: ""Ceilometer should be enabled in the environment settings."" - condition: ""settings:additional_components.mongo.value == true"" message: ""You are already using external MongoDB."" tags: - mongo external_mongo: metadata: label: ""External MongoDB"" weight: 30 group: ""openstack_services"" restrictions: - condition: ""settings:additional_components.mongo.value == false"" message: ""Ceilometer and MongoDB are not enabled on the Additional Components section"" action: ""hide"" hosts_ip: value: """" label: ""MongoDB hosts IP"" description: ""IP Addresses of MongoDB. Use comma to split IPs"" weight: 30 type: ""text"" regex: source: '^(((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?),)*((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$' error: ""Invalid hosts ip sequence"" mongo_user: value: ""ceilometer"" label: ""Username"" description: ""Mongo database username"" weight: 30 type: ""text"" regex: source: '^\w+$' error: ""Empty username"" mongo_password: value: ""ceilometer"" label: ""Password"" description: ""Mongo database password"" weight: 30 type: ""password"" regex: source: '^\S*$' error: ""Password contains spaces"" mongo_db_name: value: ""ceilometer"" label: ""Database name"" description: ""Mongo database name"" weight: 30 type: ""text"" regex: source: '^\w+$' error: ""Invalid database name"" mongo_replset: value: """" label: ""Replset"" description: ""Name for Mongo replication set"" weight: 30 type: ""text"" ceilometer: value: false label: ""Install Ceilometer and Aodh"" description: ""If selected, Ceilometer and Aodh components will be installed"" weight: 60 type: ""checkbox"" mongo: value: false label: ""Use external Mongo DB"" description: ""If selected, You can use external Mongo DB as ceilometer backend"" weight: 70 type: ""checkbox"" restrictions: - ""settings:additional_components.ceilometer.value == false"": ""External Mongo aims to be an external backend for Ceilometer. Without Ceilometer enabled, External Mongo is useless and should not be installed."" - name: additional_service:ceilometer - name: additional_service:ceilometer - name: additional_service:ironic - name: additional_service:ceilometer bind: - ""settings:additional_components.ceilometer.value"" weight: 30 label: ""dialog.create_cluster_wizard.additional.install_ceilometer"" description: ""dialog.create_cluster_wizard.additional.install_ceilometer_description"" compatible: - name: hypervisor:qemu - name: network:neutron:core:ml2 - name: network:neutron:ml2:vlan - name: network:neutron:ml2:tun - name: storage:block:lvm - name: storage:block:ceph - name: storage:object:ceph - name: storage:ephemeral:ceph - name: storage:image:ceph - name: additional_service:sahara - name: additional_service:murano - name: additional_service:ceilometer",0,111
openstack%2Ftripleo-heat-templates~master~I483992f7349d7900f594115a13420e6a100ee6cf,openstack/tripleo-heat-templates,master,I483992f7349d7900f594115a13420e6a100ee6cf,DNM - test a revert to fix scenario004,ABANDONED,2017-02-28 04:47:37.000000000,2017-02-28 12:57:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-28 04:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/36b2be37c7a1cb20ea960fe6fe5213fefb21cc90', 'message': 'DNM - temprevert swift testing\n\nChange-Id: I483992f7349d7900f594115a13420e6a100ee6cf\nDepends-On: I22dec0bdf2c78eea54474b6628b46ebb73def94a\n'}, {'number': 2, 'created': '2017-02-28 05:07:23.000000000', 'files': ['ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9b9f1ffcbe780ece1c7e45f937486bf536fa5325', 'message': 'DNM - test a revert to fix scenario004\n\nChange-Id: I483992f7349d7900f594115a13420e6a100ee6cf\nDepends-On: I3f79c881d8aeda361a59f9952948355986a7c835\n'}]",0,438798,9b9f1ffcbe780ece1c7e45f937486bf536fa5325,5,1,2,3153,,,0,"DNM - test a revert to fix scenario004

Change-Id: I483992f7349d7900f594115a13420e6a100ee6cf
Depends-On: I3f79c881d8aeda361a59f9952948355986a7c835
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/438798/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml']",4,36b2be37c7a1cb20ea960fe6fe5213fefb21cc90,scenario004/test, #,,4,3
openstack%2Fopenstack-ansible-rsyslog_client~master~Ica4e2e5ab2cf7e433e2d8bff05c4bca70031a65d,openstack/openstack-ansible-rsyslog_client,master,Ica4e2e5ab2cf7e433e2d8bff05c4bca70031a65d,Test for rsyslog_all group before conditional,MERGED,2017-02-28 11:26:24.000000000,2017-02-28 12:51:32.000000000,2017-02-28 12:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-28 11:26:24.000000000', 'files': ['tasks/rsyslog_client_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/8e6b89c230019e57d51a19be80110a1c0ceaf956', 'message': ""Test for rsyslog_all group before conditional\n\nRoles that depend on the rsyslog_client role may not have rsyslog_all\nservers setup - this will then fail as the group does not exist in the\ninventory.\n\nWe should test whether the group exists, and skip if the group doesn't\nexist or if the host is not in the group.\n\nChange-Id: Ica4e2e5ab2cf7e433e2d8bff05c4bca70031a65d\n""}]",0,438927,8e6b89c230019e57d51a19be80110a1c0ceaf956,8,3,1,2799,,,0,"Test for rsyslog_all group before conditional

Roles that depend on the rsyslog_client role may not have rsyslog_all
servers setup - this will then fail as the group does not exist in the
inventory.

We should test whether the group exists, and skip if the group doesn't
exist or if the host is not in the group.

Change-Id: Ica4e2e5ab2cf7e433e2d8bff05c4bca70031a65d
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/27/438927/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rsyslog_client_post_install.yml'],1,8e6b89c230019e57d51a19be80110a1c0ceaf956,, when: (groups['rsyslog_all'] is not defined) or (inventory_hostname not in groups['rsyslog_all']) when: (groups['rsyslog_all'] is not defined) or (inventory_hostname not in groups['rsyslog_all']), when: inventory_hostname not in groups['rsyslog_all'] when: inventory_hostname not in groups['rsyslog_all'],2,2
openstack%2Fopenstack-manuals~master~I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a,openstack/openstack-manuals,master,I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a,Adds Hyper-V NUMA topology documentation,MERGED,2017-01-23 13:10:24.000000000,2017-02-28 12:50:33.000000000,2017-02-28 12:50:32.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-01-23 13:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8360a6053c908ef0630ce3e729693edcd3701087', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}, {'number': 2, 'created': '2017-01-23 14:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1bdebc2bc74c1c0be207a02ca8bacc7d18df2db3', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}, {'number': 3, 'created': '2017-01-24 16:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/819141e931aefde394bf8ed69629c1565fbdcf11', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}, {'number': 4, 'created': '2017-01-24 16:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/75833acc165f49057e70eb422001260ed44fedb2', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}, {'number': 5, 'created': '2017-01-25 11:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/53aaf9935d3fa32fb83520d75f97028970012a2c', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}, {'number': 6, 'created': '2017-02-10 15:42:17.000000000', 'files': ['doc/admin-guide/source/compute-cpu-topologies.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3c884a59d87887246cce0d0c7a6d73cfa72e897a', 'message': 'Adds Hyper-V NUMA topology documentation\n\nThe commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced\nthe ability to spawn NUMA-aware instances on Hyper-V compute nodes.\n\nUpdates the compute-cpu-topologies to include information about\nHyper-V compute nodes configuration and instance creation restrictions.\n\nCloses-bug: 1655892\nChange-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a\n'}]",18,424102,3c884a59d87887246cce0d0c7a6d73cfa72e897a,29,6,6,8213,,,0,"Adds Hyper-V NUMA topology documentation

The commit Iba2110e95e80b9511698cb7df2963fd218264c8e introduced
the ability to spawn NUMA-aware instances on Hyper-V compute nodes.

Updates the compute-cpu-topologies to include information about
Hyper-V compute nodes configuration and instance creation restrictions.

Closes-bug: 1655892
Change-Id: I9427ff28daf46da1aa9ed0b3b0d6a33b14d2b49a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/424102/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/compute-cpu-topologies.rst'],1,8360a6053c908ef0630ce3e729693edcd3701087,,"Configuring compute nodes for instances with NUMA placement policies ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Hyper-V is configured by default to allow instances to span multiple NUMA nodes, irregardless if the instances have been configured to only span N NUMA nodes. This behaviour allows Hyper-V instances to have up to 64 vCPUs and 1 TB of memory. In order to disable this behaviour, the host will have to be configured to disable NUMA spanning. This can be done by executing the following powershell commands: .. code-block:: console Set-VMHost -NumaSpanningEnabled $false Restart-Service vmms In order to restore this behaviour, the following powershell commands can be executed: .. code-block:: console Set-VMHost -NumaSpanningEnabled $true Restart-Service vmms The ``vmms`` service (Virtual Machine Management Service) is responsible for managing the Hyper-V VMs. The VMs will still run while the service is down or restarting, but they won't be manageable by the nova-compute service. In order for the effects of the Host NUMA spanning configuration to take effect, the VMs will have to be restarted. Hyper-V does not allow instances having a NUMA topology to have dynamic memory allocation turned on. Thus, the Hyper-V driver will ignore the configured ``dynamic_memory_ratio`` from the given ``nova.conf`` file when spawning instances with a NUMA topology. libvirt/KVM and Hyper-V driver.Keep in mind that Hyper-V does not support asymmetric NUMA topologies, and the Hyper-V driver will not spawn them. libvirt/KVM driver. Hyper-V does not support CPU pinning.", libvirt/KVM driver. libvirt/KVM driver.,41,2
openstack%2Fopenstack-manuals~master~I33a0d8ebe7d18cff30cfc14bca6189e3be8612c4,openstack/openstack-manuals,master,I33a0d8ebe7d18cff30cfc14bca6189e3be8612c4,Modify the hyperlink to the correct one,MERGED,2017-02-27 15:06:41.000000000,2017-02-28 12:45:57.000000000,2017-02-28 12:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-27 15:06:41.000000000', 'files': ['doc/admin-guide/source/dashboard-manage-volumes.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/051dc6435f9c157f2a1b148a0f997bf40ec5cb3e', 'message': 'Modify the hyperlink to the correct one\n\nThe previous link is moved, and now is available\nat: http://dx.doi.org/10.6028/NIST.SP.800-38E, so this\npatch fix it.\n\nChange-Id: I33a0d8ebe7d18cff30cfc14bca6189e3be8612c4\n'}]",0,438539,051dc6435f9c157f2a1b148a0f997bf40ec5cb3e,7,3,1,14151,,,0,"Modify the hyperlink to the correct one

The previous link is moved, and now is available
at: http://dx.doi.org/10.6028/NIST.SP.800-38E, so this
patch fix it.

Change-Id: I33a0d8ebe7d18cff30cfc14bca6189e3be8612c4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/438539/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/dashboard-manage-volumes.rst'],1,051dc6435f9c157f2a1b148a0f997bf40ec5cb3e,,`*` Source `NIST SP 800-38E <http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38e.pdf>`_,`*` Source `NIST SP 800-38E <http://csrc.nist.gov/publications/nistpubs/800-38E/nist-sp-800-38E.pdf>`_,1,1
openstack%2Fhorizon~master~I51a8edf02129b0a7190c40f20f090cd9a8dd1815,openstack/horizon,master,I51a8edf02129b0a7190c40f20f090cd9a8dd1815,Horizon does not display ID of Security Group,MERGED,2017-02-08 08:34:29.000000000,2017-02-28 12:22:09.000000000,2017-02-28 12:22:09.000000000,"[{'_account_id': 3}, {'_account_id': 6732}, {'_account_id': 8648}, {'_account_id': 9155}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 15209}, {'_account_id': 16628}, {'_account_id': 17642}, {'_account_id': 17654}, {'_account_id': 22037}]","[{'number': 1, 'created': '2017-02-08 08:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8f41a9d017578b02177627bb7db9669bac474ac1', 'message': 'Horizon does not display ID of Security Group\n\n   This patch set is to add ID column in the security group table.\nThis is useful when there are multiple security group that has the\nsame name.\n\nChange-Id: I51a8edf02129b0a7190c40f20f090cd9a8dd1815\nCloses-Bug: #1429866\n'}, {'number': 2, 'created': '2017-02-09 04:51:31.000000000', 'files': ['openstack_dashboard/dashboards/project/security_groups/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/dc920515ecd965795971b1587cd5d2fa0f132d1d', 'message': 'Horizon does not display ID of Security Group\n\n   This patch set is to add ID column in the security group table.\nThis is useful when there are multiple security group that has the\nsame name.\n\nChange-Id: I51a8edf02129b0a7190c40f20f090cd9a8dd1815\nCloses-Bug: #1429866\n'}]",1,430643,dc920515ecd965795971b1587cd5d2fa0f132d1d,21,11,2,24288,,,0,"Horizon does not display ID of Security Group

   This patch set is to add ID column in the security group table.
This is useful when there are multiple security group that has the
same name.

Change-Id: I51a8edf02129b0a7190c40f20f090cd9a8dd1815
Closes-Bug: #1429866
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/430643/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/security_groups/tables.py'],1,8f41a9d017578b02177627bb7db9669bac474ac1,bug/1429866," security_group_id = tables.Column(""id"", verbose_name=_(""Id""))",,1,0
openstack%2Frally~master~Ide55d0c4048e4584e76cf067a34b7793caf70c02,openstack/rally,master,Ide55d0c4048e4584e76cf067a34b7793caf70c02,Remove Endpoint from Rally common objects,MERGED,2017-02-26 16:28:43.000000000,2017-02-28 12:20:29.000000000,2017-02-28 12:20:29.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-02-26 16:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e78086cd98505b5f3da29a8fc296f270ff507513', 'message': 'Remove objects.endpoint\n\nI think we should remove endpoint.py now :)\n\nChange-Id: Ide55d0c4048e4584e76cf067a34b7793caf70c02\n'}, {'number': 2, 'created': '2017-02-27 00:47:00.000000000', 'files': ['rally/common/objects/__init__.py', 'rally/common/objects/endpoint.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8d18582cbec93f77a841892048a2d3b956014534', 'message': 'Remove Endpoint from Rally common objects\n\nNow is 0.8 release so its far enough to remove this deprication\n\nChange-Id: Ide55d0c4048e4584e76cf067a34b7793caf70c02\n'}]",4,438275,8d18582cbec93f77a841892048a2d3b956014534,16,5,2,22960,,,0,"Remove Endpoint from Rally common objects

Now is 0.8 release so its far enough to remove this deprication

Change-Id: Ide55d0c4048e4584e76cf067a34b7793caf70c02
",git fetch https://review.opendev.org/openstack/rally refs/changes/75/438275/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/common/objects/__init__.py', 'rally/common/objects/endpoint.py']",2,e78086cd98505b5f3da29a8fc296f270ff507513,remove_redudant_code,,"# Copyright 2014: Mirantis Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from rally.common import logging from rally.common.objects import credential LOG = logging.getLogger(__name__) class Endpoint(credential.Credential): def __init__(self, *args, **kwargs): super(Endpoint, self).__init__(*args, **kwargs) LOG.warning(""Endpoint is deprecated since Rally 0.1.2. "" ""Please use rally.common.objects.credentials instead"") ",0,27
openstack%2Fsenlin~master~I9dca2c7194f48cbf0c26ba46dc1b094d3f6a7bb3,openstack/senlin,master,I9dca2c7194f48cbf0c26ba46dc1b094d3f6a7bb3,Fix tags update when join/leave a stack,MERGED,2017-02-22 03:48:10.000000000,2017-02-28 12:07:59.000000000,2017-02-28 12:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-22 03:48:10.000000000', 'files': ['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1c947de6b40286e0b75fd5729ed2920595f0dcde', 'message': 'Fix tags update when join/leave a stack\n\nWe update stack tags to indicate that a stack is a member of a senlin\ncluster. This has to be done not only when stack is created, but also\nwhen we join an existing stack to a cluster or remove a stack from a\ncluster.\n\nChange-Id: I9dca2c7194f48cbf0c26ba46dc1b094d3f6a7bb3\n'}]",0,436745,1c947de6b40286e0b75fd5729ed2920595f0dcde,7,3,1,8246,,,0,"Fix tags update when join/leave a stack

We update stack tags to indicate that a stack is a member of a senlin
cluster. This has to be done not only when stack is created, but also
when we join an existing stack to a cluster or remove a stack from a
cluster.

Change-Id: I9dca2c7194f48cbf0c26ba46dc1b094d3f6a7bb3
",git fetch https://review.opendev.org/openstack/senlin refs/changes/45/436745/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py']",2,1c947de6b40286e0b75fd5729ed2920595f0dcde,fix-stack-join-leave," def test__refresh_tags_empty_no_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock() res = profile._refresh_tags([], node, False) self.assertEqual(([], False), res) def test__refresh_tags_with_contents_no_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock() res = profile._refresh_tags(['foo'], node, False) self.assertEqual((['foo'], False), res) def test__refresh_tags_deleted_no_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock() res = profile._refresh_tags( ['cluster_id=FOO', 'bar'], node, False) self.assertEqual((['bar'], True), res) def test__refresh_tags_empty_and_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) res = profile._refresh_tags([], node, True) expected = [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] self.assertEqual((expected, True), res) def test__refresh_tags_with_contents_and_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) res = profile._refresh_tags(['foo'], node, True) expected = [ 'foo', 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123', ] self.assertEqual((expected, True), res) def test__refresh_tags_deleted_and_add(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) res = profile._refresh_tags( ['cluster_id=FOO', 'bar'], node, True) expected = [ 'bar', 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123', ] self.assertEqual((expected, True), res) def test_do_join(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['bar'], True)) res = profile.do_join(node, 'CLUSTER_ID') self.assertTrue(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, True) oc.stack_update.assert_called_once_with('STACK_ID', {'tags': ['bar']}) def test_do_join_no_physical_id(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock(physical_id=None) res = profile.do_join(node, 'CLUSTER_ID') self.assertFalse(res) def test_do_join_failed_get_stack(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc err = exc.InternalError(code=400, message='Boom') oc.stack_get.side_effect = err node = mock.Mock(physical_id='STACK_ID') res = profile.do_join(node, 'CLUSTER_ID') self.assertFalse(res) oc.stack_get.assert_called_once_with('STACK_ID') def test_do_join_no_update(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['foo'], False)) res = profile.do_join(node, 'CLUSTER_ID') self.assertTrue(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, True) self.assertEqual(0, oc.stack_update.call_count) def test_do_join_failed_update(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack err = exc.InternalError(code=400, message='Boom') oc.stack_update.side_effect = err node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['bar'], True)) res = profile.do_join(node, 'CLUSTER_ID') self.assertFalse(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, True) oc.stack_update.assert_called_once_with('STACK_ID', {'tags': ['bar']}) def test_do_leave(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['bar'], True)) res = profile.do_leave(node) self.assertTrue(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, False) oc.stack_update.assert_called_once_with('STACK_ID', {'tags': ['bar']}) def test_do_leave_no_physical_id(self): profile = stack.StackProfile('t', self.spec) node = mock.Mock(physical_id=None) res = profile.do_leave(node) self.assertFalse(res) def test_do_leave_failed_get_stack(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc err = exc.InternalError(code=400, message='Boom') oc.stack_get.side_effect = err node = mock.Mock(physical_id='STACK_ID') res = profile.do_leave(node) self.assertFalse(res) oc.stack_get.assert_called_once_with('STACK_ID') def test_do_leave_no_update(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['foo'], False)) res = profile.do_leave(node) self.assertTrue(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, False) self.assertEqual(0, oc.stack_update.call_count) def test_do_leave_failed_update(self): profile = stack.StackProfile('t', self.spec) oc = mock.Mock() profile._orchestrationclient = oc x_stack = mock.Mock(tags=['foo']) oc.stack_get.return_value = x_stack err = exc.InternalError(code=400, message='Boom') oc.stack_update.side_effect = err node = mock.Mock(physical_id='STACK_ID') mock_tags = self.patchobject(profile, '_refresh_tags', return_value=(['bar'], True)) res = profile.do_leave(node) self.assertFalse(res) oc.stack_get.assert_called_once_with('STACK_ID') mock_tags.assert_called_once_with(['foo'], node, False) oc.stack_update.assert_called_once_with('STACK_ID', {'tags': ['bar']})",,274,0
openstack%2Fcinder~master~I63cb785d27fa9e43da16a27da6d7b92052badf06,openstack/cinder,master,I63cb785d27fa9e43da16a27da6d7b92052badf06,Change volume_type dict to ovo,MERGED,2017-02-17 16:12:16.000000000,2017-02-28 12:06:37.000000000,2017-02-28 12:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10628}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 14208}, {'_account_id': 14969}, {'_account_id': 16708}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 19852}, {'_account_id': 21990}, {'_account_id': 23083}, {'_account_id': 23100}, {'_account_id': 23602}, {'_account_id': 24502}, {'_account_id': 24578}]","[{'number': 1, 'created': '2017-02-17 16:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9667de44b1d3826e72a2eb1eceeb6a49cd3b7aa9', 'message': 'Change volume_type dict to ovo\n\nThe volume type in the create method in volume API\nwas changed from dict to ovo by the following patch:\n  https://review.openstack.org/#/c/406780/\nHowever, this is not changed in create group from src\nAPI which calls volume create and therefore introduced\nthis bug. It throws an exception when calling volume_type.id\nbecause volume_type is still a dict.\n\nThis patch fixed this problem.\n\nChange-Id: I63cb785d27fa9e43da16a27da6d7b92052badf06\nCloses-Bug: #1665549\n'}, {'number': 2, 'created': '2017-02-17 20:14:22.000000000', 'files': ['cinder/tests/unit/group/test_groups_api.py', 'cinder/consistencygroup/api.py', 'cinder/group/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/71aa2a27e3016fb9e62c15bf6fe497b60ca94027', 'message': 'Change volume_type dict to ovo\n\nThe volume type in the create method in volume API\nwas changed from dict to ovo by the following patch:\n  https://review.openstack.org/#/c/406780/\nHowever, this is not changed in create group from src\nAPI which calls volume create and therefore introduced\nthis bug. It throws an exception when calling volume_type.id\nbecause volume_type is still a dict.\n\nThis patch fixed this problem.\n\nChange-Id: I63cb785d27fa9e43da16a27da6d7b92052badf06\nCloses-Bug: #1665549\n'}]",0,435511,71aa2a27e3016fb9e62c15bf6fe497b60ca94027,64,22,2,6491,,,0,"Change volume_type dict to ovo

The volume type in the create method in volume API
was changed from dict to ovo by the following patch:
  https://review.openstack.org/#/c/406780/
However, this is not changed in create group from src
API which calls volume create and therefore introduced
this bug. It throws an exception when calling volume_type.id
because volume_type is still a dict.

This patch fixed this problem.

Change-Id: I63cb785d27fa9e43da16a27da6d7b92052badf06
Closes-Bug: #1665549
",git fetch https://review.opendev.org/openstack/cinder refs/changes/11/435511/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/group/test_groups_api.py', 'cinder/consistencygroup/api.py', 'cinder/group/api.py']",3,9667de44b1d3826e72a2eb1eceeb6a49cd3b7aa9,bug/1665549," kwargs['volume_type'] = ( objects.VolumeType.get_by_name_or_id( context, volume_type_id)) kwargs['volume_type'] = ( objects.VolumeType.get_by_name_or_id( context, volume_type_id))"," kwargs['volume_type'] = volume_types.get_volume_type( context, volume_type_id) kwargs['volume_type'] = volume_types.get_volume_type( context, volume_type_id)",23,16
openstack%2Fopenstack-manuals~stable%2Fnewton~I15abb241af8a41edc3dd3850b08be4ab7a31c9c5,openstack/openstack-manuals,stable/newton,I15abb241af8a41edc3dd3850b08be4ab7a31c9c5,release notes and config guide new settings,MERGED,2017-02-28 08:58:23.000000000,2017-02-28 11:59:54.000000000,2017-02-28 11:59:54.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 14643}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-28 08:58:23.000000000', 'files': ['doc/config-reference/source/tables/conf-changes/keystone.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bf6edca4e50aed66a0bb5a538c3906eb1510eebc', 'message': 'release notes and config guide new settings\n\nOpenStack operators and folks who automate openstack deployments with\ntools like puppet rely on the release notes and config guides to\nhighlight new, changed, deleted, and deprecated config options.\n\nChange-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5\nCloses-bug:#1640504\n(cherry picked from commit 260a31067d58d045477908de62bcc2e6798e1bae)\n'}]",0,438863,bf6edca4e50aed66a0bb5a538c3906eb1510eebc,8,4,1,17645,,,0,"release notes and config guide new settings

OpenStack operators and folks who automate openstack deployments with
tools like puppet rely on the release notes and config guides to
highlight new, changed, deleted, and deprecated config options.

Change-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5
Closes-bug:#1640504
(cherry picked from commit 260a31067d58d045477908de62bcc2e6798e1bae)
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/438863/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/tables/conf-changes/keystone.rst'],1,bf6edca4e50aed66a0bb5a538c3906eb1510eebc,bug/1640504,".. list-table:: New options :header-rows: 1 :class: config-ref-table * - Option = default value - (Type) Help string * - ``[security_compliance] disable_user_account_days_inactive =`` - (IntOpt) The maximum number of days a user can go without authenticating before being considered ""inactive"" and automatically disabled (locked). * - ``[security_compliance] lockout_failure_attempts =`` - (IntOpt) The maximum number of times that a user can fail to authenticate before the user account is locked. * - ``[security_compliance] lockout_duration = 1800`` - (IntOpt) The number of seconds a user account will be locked when the maximum number of failed authentication attempts is exceeded. * - ``[security_compliance] password_expires_days = <None>`` - (IntOpt) The number of days for which a password will be considered valid before requiring it to be changed. * - ``[security_compliance] password_expires_ignore_user_ids =`` - (StrOpt) User IDs to be ignored when checking if a password is expired. * - ``[security_compliance] unique_last_password_count = 1`` - (IntOpt) Controls the number of previous user password iterations to keep in history, in order to enforce that newly created passwords are unique. * - ``[security_compliance] minimum_password_age = 0`` - (IntOptThe number of days that a password must be used before the user can change it. * - ``[security_compliance] password_regex = <None>`` - (StrOpt) Validate password strength requirements. * - ``[security_compliance] password_regex_description = <None>`` - (StrOpt) Humans language to describe password regular expression. * - ``[token] cache_on_issue = false`` - (BoolOpt) Enable storing issued token data to token validation cache so that first token validation doesn't actually cause full validation cycle. * - ``[endpoint_policy] enabled`` - ``None`` * - ``[token] hash_algorithm`` - ``None`` * - ``[os_inherit]`` - ``None``",,33,0
openstack%2Fsushy~master~I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d,openstack/sushy,master,I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d,Rework exceptions,MERGED,2017-02-27 23:21:38.000000000,2017-02-28 11:57:23.000000000,2017-02-28 11:57:23.000000000,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-02-27 23:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/be8741e706b10603328b9f7b93737b889e4f2ad1', 'message': 'Rework exceptions\n\nThis patch is reworking the exceptions that can be raised from Sushy,\nbefore this patch many errors such as HTTP 4XX or 5XX were failing\nsilently.\n\nThis patch add custom exceptions for cases such as ConnectionError and\nHTTPError that can be raised from requests.\n\nChange-Id: I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d\n'}, {'number': 2, 'created': '2017-02-27 23:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/d279c060192e677d886a394dd2994700c44f4271', 'message': 'Rework exceptions\n\nThis patch is reworking the exceptions that can be raised from Sushy,\nbefore this patch many errors such as HTTP 4XX or 5XX were failing\nsilently.\n\nThis patch add custom exceptions for cases such as ConnectionError and\nHTTPError that can be raised from requests.\n\nChange-Id: I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d\n'}, {'number': 3, 'created': '2017-02-27 23:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/35e4f4dee6db55ae630a7e22a9a17d923777d6b8', 'message': 'Rework exceptions\n\nThis patch is reworking the exceptions that can be raised from Sushy,\nbefore this patch many errors such as HTTP 4XX or 5XX were failing\nsilently.\n\nThis patch add custom exceptions for cases such as ConnectionError and\nHTTPError that can be raised from requests.\n\nChange-Id: I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d\n'}, {'number': 4, 'created': '2017-02-28 11:08:15.000000000', 'files': ['sushy/tests/unit/resources/test_base.py', 'sushy/connector.py', 'sushy/exceptions.py', 'sushy/resources/base.py', 'sushy/tests/unit/test_connector.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/56af7a561675d30a07835f9ed6bea5db039853fc', 'message': 'Rework exceptions\n\nThis patch is reworking the exceptions that can be raised from Sushy,\nbefore this patch many errors such as HTTP 4XX or 5XX were failing\nsilently.\n\nThis patch add custom exceptions for cases such as ConnectionError and\nHTTPError that can be raised from requests.\n\nChange-Id: I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d\n'}]",0,438732,56af7a561675d30a07835f9ed6bea5db039853fc,11,2,4,6773,,,0,"Rework exceptions

This patch is reworking the exceptions that can be raised from Sushy,
before this patch many errors such as HTTP 4XX or 5XX were failing
silently.

This patch add custom exceptions for cases such as ConnectionError and
HTTPError that can be raised from requests.

Change-Id: I57ff8dffdfe0ab763bd0194e1916db8ae7a7861d
",git fetch https://review.opendev.org/openstack/sushy refs/changes/32/438732/4 && git format-patch -1 --stdout FETCH_HEAD,"['sushy/tests/unit/resources/test_base.py', 'sushy/connector.py', 'sushy/exceptions.py', 'sushy/resources/base.py', 'sushy/tests/unit/test_connector.py']",5,be8741e706b10603328b9f7b93737b889e4f2ad1,requests-raise,"import requestsfrom sushy import exceptions @mock.patch.object(requests, 'Session', autospec=True) @mock.patch.object(requests, 'Session', autospec=True) def test__op_connection_error(self, mock_session): fake_session = mock.Mock() mock_session.return_value.__enter__.return_value = fake_session fake_session.request.side_effect = requests.exceptions.ConnectionError self.assertRaises(exceptions.ConnectionError, self.conn._op, 'GET') @mock.patch.object(requests, 'Session', autospec=True) def test__op_http_error(self, mock_session): fake_session = mock.Mock() mock_session.return_value.__enter__.return_value = fake_session fake_response = fake_session.request.return_value fake_response.status_code = 400 fake_response.raise_for_status.side_effect = ( requests.exceptions.HTTPError(response=fake_response)) self.assertRaises(exceptions.HTTPError, self.conn._op, 'GET')"," @mock.patch('sushy.connector.requests.Session', autospec=True)",120,13
openstack%2Frally~master~I27070f6282d82de2431e7150be2fdcd46f300376,openstack/rally,master,I27070f6282d82de2431e7150be2fdcd46f300376,Update core members,MERGED,2017-02-28 10:53:44.000000000,2017-02-28 11:52:21.000000000,2017-02-28 11:26:57.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2017-02-28 10:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7b6e797ef28863689cacd28243c534a9912068d9', 'message': 'Update core members\n\nChange-Id: I27070f6282d82de2431e7150be2fdcd46f300376\n'}, {'number': 2, 'created': '2017-02-28 10:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6cc13f39b071391302f3b60d57924c642a7aa0cc', 'message': 'Update core members\n\nChange-Id: I27070f6282d82de2431e7150be2fdcd46f300376\n'}, {'number': 3, 'created': '2017-02-28 10:57:24.000000000', 'files': ['doc/source/project_info/index.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/e91af1d337a26a96c3bfd24419e091213b513180', 'message': 'Update core members\n\nChange-Id: I27070f6282d82de2431e7150be2fdcd46f300376\n'}]",0,438906,e91af1d337a26a96c3bfd24419e091213b513180,11,3,3,9545,,,0,"Update core members

Change-Id: I27070f6282d82de2431e7150be2fdcd46f300376
",git fetch https://review.opendev.org/openstack/rally refs/changes/06/438906/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/project_info/index.rst'],1,7b6e797ef28863689cacd28243c534a9912068d9,core_members,| | andreykurilin (gitter) | * Release management || | Anton Studenov | * Rally Deployment | | | tohin (irc) | * Task Hooks | | | astudenov@mirantis.com | | +------------------------------+------------------------------------------------+| | pomeo92@gmail.com | || | Yaroslav Lobankov | * Rally Verification | | | ylobankov (irc) | | | | ylobankov@mirantis.com | | +------------------------------+------------------------------------------------+| | Spyros Trigazis | * Magnum plugins | | | strigazi (irc) | | | | strigazi@gmail.com | | +------------------------------+------------------------------------------------+ | | Nikita Konovalov | * Sahara plugins | | | NikitaKonovalov (irc) | | | | nkonovalov@mirantis.com | |,| | rvasilets@mirantis.com | || | Nikita Konovalov | * Sahara plugins | | | NikitaKonovalov (irc) | | | | nkonovalov@mirantis.com | | +------------------------------+------------------------------------------------+| | Yaroslav Lobankov | * Rally Verification | | | ylobankov (irc) | | | | ylobankov@mirantis.com | |,17,8
openstack%2Fpuppet-tripleo~master~I9a0a027d339963264987676604f21d77e6b977ad,openstack/puppet-tripleo,master,I9a0a027d339963264987676604f21d77e6b977ad,Enable TLS in the internal network for heat,ABANDONED,2016-06-08 12:43:53.000000000,2017-02-28 11:48:39.000000000,,"[{'_account_id': 3}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-06-08 12:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/fe38bca45c79afae50be6fc1d1f1eaf3b55ab088', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 2, 'created': '2016-06-08 14:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d552241eec2bef9c82fd428b2eefd977f7221596', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 3, 'created': '2016-06-09 05:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6aa0863d7da096e3a0326c153a0795c350dc000a', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 4, 'created': '2016-06-10 06:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ea33885403dd92bcc45870fec79745382f4a0037', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 5, 'created': '2016-06-13 06:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/95c63dfd7d6d790da46249351d8fc4cf49264eba', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 6, 'created': '2016-06-13 07:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e51a9e3d42f93fb559fbe9e4fe92bd6f1083152b', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 7, 'created': '2016-06-13 09:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/34546e4e7823c2dad477597fa7c3705335e885d4', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 8, 'created': '2016-06-15 07:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/51cac8efb4a0fc69bb01476763fc0cf424861593', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 9, 'created': '2016-06-15 07:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7491b08d943583f039beadfdce43976e55849e52', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 10, 'created': '2016-06-15 09:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2065295d459d40ab8d3e92b559ae016d2b118a7f', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 11, 'created': '2016-06-16 07:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8a86992ce7e11124c9346c5a903ddc5fd24361a6', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 12, 'created': '2016-06-16 11:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a84a0e5003cae76093ce0466f22da6e34265192e', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 13, 'created': '2016-06-20 11:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6527c7f97905e4c34936e91aec09efbd7b954609', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 14, 'created': '2016-07-01 07:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/634af030c3c9da125264ab2566ebcf24f4067094', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 15, 'created': '2016-07-07 09:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f2a486fd536a8017f4bd1775d7c89e96b44bc37a', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 16, 'created': '2016-07-13 09:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/17a0674033236a24983c87b0abe86dd992789c0b', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 17, 'created': '2016-08-10 11:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/03660bf2fce573212ef31b97d951c07669fbe67d', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}, {'number': 18, 'created': '2016-08-30 10:03:06.000000000', 'files': ['manifests/profile/base/heat/api_cloudwatch.pp', 'manifests/profile/base/heat/api.pp', 'manifests/profile/base/heat/api_cfn.pp', 'manifests/haproxy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/94895c0c383d79bb566e74ac2ebf98a6dad704fc', 'message': ""Enable TLS in the internal network for heat\n\nThis optionally enables TLS for heat's different services  in the\ninternal network. If internal TLS is enabled, each node that is\nserving the keystone service will use certmonger to request its\ncertificate.\n\nbp tls-via-certmonger\nChange-Id: I9a0a027d339963264987676604f21d77e6b977ad\n""}]",3,327069,94895c0c383d79bb566e74ac2ebf98a6dad704fc,74,4,18,10873,,,0,"Enable TLS in the internal network for heat

This optionally enables TLS for heat's different services  in the
internal network. If internal TLS is enabled, each node that is
serving the keystone service will use certmonger to request its
certificate.

bp tls-via-certmonger
Change-Id: I9a0a027d339963264987676604f21d77e6b977ad
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/69/327069/16 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/heat/api_cloudwatch.pp', 'manifests/profile/base/heat/api.pp', 'manifests/profile/base/heat/api_cfn.pp']",3,fe38bca45c79afae50be6fc1d1f1eaf3b55ab088,bp/tls-via-certmonger,"# [*tls_certfile*] # (Optional) The path to the certificate that will be used for TLS in this # service. # Defaults to '/etc/pki/tls/certs/heat-api-cfn.crt' # # [*tls_keyfile*] # (Optional) The path to the key that will be used for TLS in this service. # Defaults to '/etc/pki/tls/private/heat-api-cfn.key' # # [*service_principal*] # (Optional) The kerberos service principal that will be used to request the # certificate. (Might not be needed depending on the CA). # Defaults to ""heat-api-cfn/${::fqdn}"" # # [*tls_cert_refresh_command*] # (Optional) The command that will be issued after certmonger issues a # resubmit for the certificate. That is, when the certificate expires and a # new one needs to be requested. This typically needs to be a command that # can refresh the service so it can start using the new certificate. # Defaults to (TBD) # $step = hiera('step'), $tls_certfile = '/etc/pki/tls/certs/heat-api-cfn.crt', $tls_keyfile = '/etc/pki/tls/private/heat-api-cfn.key', $service_principal = ""heat-api/${::fqdn}"", $tls_cert_refresh_command = '/bin/true', include ::tripleo::internal_tls if $::tripleo::internal_tls::enable_internal_tls { certmonger_certificate { 'heat-api-cfn-cert': certfile => $tls_certfile, keyfile => $tls_keyfile, hostname => $::fqdn, principal => $service_principal, postsave_cmd => $tls_cert_refresh_command, notify => Class['::heat::api_cfn'], } } class { '::heat::api_cfn': use_ssl => $::tripleo::internal_tls::enable_internal_tls, cert_file => $tls_certfile, key_file => $tls_keyfile, }"," $step = hiera('step'), include ::heat::api_cfn",134,6
openstack%2Ftripleo-ci~master~I8cc2bfd34846001100be4ea5b32751cd6562d0ec,openstack/tripleo-ci,master,I8cc2bfd34846001100be4ea5b32751cd6562d0ec,DO NOT MERGE - testing TLS everywhere job (MySQL client),ABANDONED,2017-01-30 17:50:56.000000000,2017-02-28 11:47:29.000000000,,"[{'_account_id': 3}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-01-30 17:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ebfcdff7390a06726d8205fa843ce3cebacc8054', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 2, 'created': '2017-02-08 17:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/08ff2cee23e8d834dd7e50e8fefe5c6261a1605c', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 3, 'created': '2017-02-13 06:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0287710ada06e8164964c718b1d9b0ae7c150e5f', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 4, 'created': '2017-02-14 06:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1830668335c41c8a2d4699cc10448d35e76e8879', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 5, 'created': '2017-02-15 05:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/654a294805cc9b8f833aa1407dde79484c555d14', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nDepends-On: I195321354df167c09cfc87c5b9f86c6dc5026d75\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 6, 'created': '2017-02-15 08:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f177f03750917fa807c669b58f7df7d48af6afc', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nDepends-On: I195321354df167c09cfc87c5b9f86c6dc5026d75\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 7, 'created': '2017-02-16 05:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9370ffe88d517b5bb715bdbdb8823a2d0a25505f', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 8, 'created': '2017-02-16 05:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/134128e4edde260d1b222cd272c32130bafad69a', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 9, 'created': '2017-02-17 01:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/27ed6353a75363df57ff38ba04e46e290528e896', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 10, 'created': '2017-02-20 06:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5ddedbbd50bc5a106d8b1bba9a0195a120dab61e', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 11, 'created': '2017-02-23 13:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/58bc92474ece32ffd29829b268b8038739568549', 'message': 'DO NOT MERGE - testing TLS everywhere job\n\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}, {'number': 12, 'created': '2017-02-23 13:09:24.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ee9acf5ebe859aee2a6c9868eaf9e922f33e3814', 'message': 'DO NOT MERGE - testing TLS everywhere job (MySQL client)\n\nDepends-On: I24e4c195a31109835739e78a6b53d36f661f9fd0\nChange-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec\n'}]",0,426863,ee9acf5ebe859aee2a6c9868eaf9e922f33e3814,49,2,12,10873,,,0,"DO NOT MERGE - testing TLS everywhere job (MySQL client)

Depends-On: I24e4c195a31109835739e78a6b53d36f661f9fd0
Change-Id: I8cc2bfd34846001100be4ea5b32751cd6562d0ec
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/63/426863/5 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,ebfcdff7390a06726d8205fa843ce3cebacc8054,test-mysql-tls,"if [[ $TOCI_JOBTYPE =~ ovb-ha ]]; then if [[ ""${STABLE_RELEASE}"" =~ ^(ocata|newton|mitaka)$ ]] ; then exit 0 fi export TOCI_JOBTYPE=gate-tripleo-ci-centos-7-ovb-fakeha-caserver else exit 0 fi ",,9,0
openstack%2Fpython-cinderclient~master~If3ba44b2b188607542bdadfeb58f8e4b363837b7,openstack/python-cinderclient,master,If3ba44b2b188607542bdadfeb58f8e4b363837b7,Group show command should be in V3,MERGED,2017-02-10 07:46:19.000000000,2017-02-28 11:46:01.000000000,2017-02-28 11:46:01.000000000,"[{'_account_id': 3}, {'_account_id': 7173}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 15054}, {'_account_id': 23602}]","[{'number': 1, 'created': '2017-02-10 07:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/da25af70171dc127b674ba4ea86dc77e35569012', 'message': 'Group show command should be in V3\n\nGroup feature was introduced in Cinder V3, So the command should\nbe there as well. But the ""group show"" command is in V2 which is\nwrong.\n\nChange-Id: If3ba44b2b188607542bdadfeb58f8e4b363837b7\nCloses-bug: #1663496\n'}, {'number': 2, 'created': '2017-02-12 06:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a20ab15e5a3136714aefbaa901e197f571ae93e6', 'message': 'Group show command should be in V3\n\nGroup feature was introduced in Cinder V3, So the command should\nbe there as well. But the ""group show"" command is in V2 which is\nwrong.\n\nChange-Id: If3ba44b2b188607542bdadfeb58f8e4b363837b7\nCloses-bug: #1663496\n'}, {'number': 3, 'created': '2017-02-20 15:07:44.000000000', 'files': ['cinderclient/v3/shell.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/8fee629fd0554ba609c6a72195020013c7f21d9d', 'message': 'Group show command should be in V3\n\nGroup feature was introduced in Cinder V3, So the command should\nbe there as well. But the ""group show"" command is in V2 which is\nwrong.\n\nChange-Id: If3ba44b2b188607542bdadfeb58f8e4b363837b7\nCloses-bug: #1663496\n'}]",2,432159,8fee629fd0554ba609c6a72195020013c7f21d9d,18,6,3,15054,,,0,"Group show command should be in V3

Group feature was introduced in Cinder V3, So the command should
be there as well. But the ""group show"" command is in V2 which is
wrong.

Change-Id: If3ba44b2b188607542bdadfeb58f8e4b363837b7
Closes-bug: #1663496
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/59/432159/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v3/shell.py', 'cinderclient/v2/shell.py']",2,da25af70171dc127b674ba4ea86dc77e35569012,bug/1663496,,"@utils.arg('group', metavar='<group>', help='Name or ID of a group.') def do_group_show(cs, args): """"""Shows details of a group."""""" info = dict() group = shell_utils.find_group(cs, args.group) info.update(group._info) info.pop('links', None) utils.print_dict(info) ",13,13
openstack%2Fopenstack-ansible~master~I116928a1db96e242ed87177578581fe7bf16a001,openstack/openstack-ansible,master,I116928a1db96e242ed87177578581fe7bf16a001,Remove ceilometer from the gate,MERGED,2017-02-27 21:32:11.000000000,2017-02-28 11:41:43.000000000,2017-02-28 11:40:59.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 11268}]","[{'number': 1, 'created': '2017-02-27 21:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e0760645c8d3f3f68cb9b4c8caa356075e6d4802', 'message': ""Remove ceilometer from the gate\n\nThis change removes ceilometer from the integrated gate. Sadly the\nceilomteter roles and playbooks have been a little neglected which has\nresulted in a slow and sometimes unstable system. To improve gate times\nceilometer has been pulled out of the integrated gate. Once we're able\nto get the ceilometer roles and playbooks  updated to the latest\nrelease and we're able to resolve all of the deprecations we should\nput these rolse back in rotation for the integrated gate.\n\nChange-Id: I116928a1db96e242ed87177578581fe7bf16a001\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2017-02-27 21:43:40.000000000', 'files': ['tests/bootstrap-aio.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5094011164a7a670a5c083269e50d82699eb9790', 'message': ""Remove ceilometer from the gate\n\nThis change removes ceilometer from the integrated gate. Sadly the\nceilomteter roles and playbooks have been a little neglected which has\nresulted in a slow and sometimes unstable system. To improve gate times\nceilometer has been pulled out of the integrated gate. Once we're able\nto get the ceilometer roles and playbooks  updated to the latest\nrelease and we're able to resolve all of the deprecations we should\nput these rolse back in rotation for the integrated gate.\n\nChange-Id: I116928a1db96e242ed87177578581fe7bf16a001\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,438708,5094011164a7a670a5c083269e50d82699eb9790,14,4,2,7353,,,0,"Remove ceilometer from the gate

This change removes ceilometer from the integrated gate. Sadly the
ceilomteter roles and playbooks have been a little neglected which has
resulted in a slow and sometimes unstable system. To improve gate times
ceilometer has been pulled out of the integrated gate. Once we're able
to get the ceilometer roles and playbooks  updated to the latest
release and we're able to resolve all of the deprecations we should
put these rolse back in rotation for the integrated gate.

Change-Id: I116928a1db96e242ed87177578581fe7bf16a001
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/08/438708/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/openstack_deploy/conf.d/gnocchi.yml.aio', 'etc/openstack_deploy/conf.d/aodh.yml.aio', 'etc/openstack_deploy/conf.d/ceilometer.yml.aio']",3,e0760645c8d3f3f68cb9b4c8caa356075e6d4802,faster-run-time,# metering-compute_hosts: # aio1: # ip: 172.29.236.100# metering-infra_hosts: # aio1: # ip: 172.29.236.100,metering-compute_hosts: aio1: ip: 172.29.236.100metering-infra_hosts: aio1: ip: 172.29.236.100,12,13
openstack%2Fheat~master~I5b05d64d3dc9365aea24cd2e94894872ce6e4f94,openstack/heat,master,I5b05d64d3dc9365aea24cd2e94894872ce6e4f94,Switch image mirror,MERGED,2017-02-28 09:42:03.000000000,2017-02-28 11:37:05.000000000,2017-02-28 11:37:05.000000000,"[{'_account_id': 3}, {'_account_id': 6577}]","[{'number': 1, 'created': '2017-02-28 09:42:03.000000000', 'files': ['heat_integrationtests/prepare_test_env.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/18ae017d161f2da3476b8cbfa2a3e3582043baa0', 'message': ""Switch image mirror\n\nThe current mirror doesn't work anymore.\n\nChange-Id: I5b05d64d3dc9365aea24cd2e94894872ce6e4f94\n""}]",0,438879,18ae017d161f2da3476b8cbfa2a3e3582043baa0,7,2,1,7385,,,0,"Switch image mirror

The current mirror doesn't work anymore.

Change-Id: I5b05d64d3dc9365aea24cd2e94894872ce6e4f94
",git fetch https://review.opendev.org/openstack/heat refs/changes/79/438879/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/prepare_test_env.sh'],1,18ae017d161f2da3476b8cbfa2a3e3582043baa0,image-mirror,curl http://fedora.bhs.mirrors.ovh.net/linux/releases/24/CloudImages/x86_64/images/Fedora-Cloud-Base-24-1.2.x86_64.qcow2 | openstack image create fedora-heat-test-image --disk-format qcow2 --container-format bare --public,curl http://mirror.liquidtelecom.com/fedora/fedora/linux/releases/24/CloudImages/x86_64/images/Fedora-Cloud-Base-24-1.2.x86_64.qcow2 | openstack image create fedora-heat-test-image --disk-format qcow2 --container-format bare --public,1,1
openstack%2Fpython-freezerclient~master~I711aa2f9ef2d4b2b8629ae2b3b3688412027ccbe,openstack/python-freezerclient,master,I711aa2f9ef2d4b2b8629ae2b3b3688412027ccbe,Drop MANIFEST.in,MERGED,2017-02-21 12:20:22.000000000,2017-02-28 11:22:34.000000000,2017-02-28 11:22:34.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 12512}, {'_account_id': 13940}, {'_account_id': 14101}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 16768}, {'_account_id': 17001}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-21 12:20:22.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/d82b5f3f5c1a0e60c0f8a4d53ee04ddae52a473c', 'message': 'Drop MANIFEST.in\n\nPbr generates a sensible manifest from git files\nand some standard files. So MANIFEST.in is not needed\nby pbr.\n\nChange-Id: I711aa2f9ef2d4b2b8629ae2b3b3688412027ccbe\n'}]",0,436431,d82b5f3f5c1a0e60c0f8a4d53ee04ddae52a473c,8,10,1,22056,,,0,"Drop MANIFEST.in

Pbr generates a sensible manifest from git files
and some standard files. So MANIFEST.in is not needed
by pbr.

Change-Id: I711aa2f9ef2d4b2b8629ae2b3b3688412027ccbe
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/31/436431/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,d82b5f3f5c1a0e60c0f8a4d53ee04ddae52a473c,remove_MANIFEST,,include AUTHORS include ChangeLog exclude .gitignore exclude .gitreview global-exclude *.pyc ,0,6
openstack%2Fdragonflow~master~I46299dc37f19f633cf7fbd3742873cb4dadf6dc1,openstack/dragonflow,master,I46299dc37f19f633cf7fbd3742873cb4dadf6dc1,fix a mismatch directory of dragonflow.ini,MERGED,2017-02-28 02:50:40.000000000,2017-02-28 11:19:41.000000000,2017-02-28 11:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-28 02:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cc9ae8e006f5f99175394e87b58d26e626dbc11d', 'message': 'fix a mismatch directory of dragonflow.ini\n\nChange-Id: I46299dc37f19f633cf7fbd3742873cb4dadf6dc1\n'}, {'number': 2, 'created': '2017-02-28 03:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c88fc954ab79c4ce96e28904d99cd8d120c5cc50', 'message': 'fix a mismatch directory of dragonflow.ini\n\nChange-Id: I46299dc37f19f633cf7fbd3742873cb4dadf6dc1\n'}, {'number': 3, 'created': '2017-02-28 07:47:39.000000000', 'files': ['doc/source/manual_deployment.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a8383a565e99da4b14702579a8a8693ffcf67858', 'message': 'fix a mismatch directory of dragonflow.ini\n\nChange-Id: I46299dc37f19f633cf7fbd3742873cb4dadf6dc1\n'}]",1,438773,a8383a565e99da4b14702579a8a8693ffcf67858,13,5,3,13108,,,0,"fix a mismatch directory of dragonflow.ini

Change-Id: I46299dc37f19f633cf7fbd3742873cb4dadf6dc1
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/73/438773/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/manual_deployment.rst'],1,cc9ae8e006f5f99175394e87b58d26e626dbc11d,,/etc/neutron/dragonflow.ini:,/etc/neutron/plugins/dragonflow.ini:,1,1
openstack%2Fpython-tripleoclient~master~I1502a81576e28a9232657ecf5f7bb269732be477,openstack/python-tripleoclient,master,I1502a81576e28a9232657ecf5f7bb269732be477,Updated from global requirements,MERGED,2017-02-28 05:48:23.000000000,2017-02-28 11:16:57.000000000,2017-02-28 11:16:57.000000000,"[{'_account_id': 3}, {'_account_id': 4978}]","[{'number': 1, 'created': '2017-02-28 05:48:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f90b59d0d592b2c5bbe801664198c8ed9b26089f', 'message': 'Updated from global requirements\n\nChange-Id: I1502a81576e28a9232657ecf5f7bb269732be477\n'}]",0,438809,f90b59d0d592b2c5bbe801664198c8ed9b26089f,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I1502a81576e28a9232657ecf5f7bb269732be477
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/09/438809/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f90b59d0d592b2c5bbe801664198c8ed9b26089f,openstack/requirements,tripleo-common>=5.7.0 # Apache-2.0,tripleo-common>=5.0.0 # Apache-2.0,1,1
openstack%2Fpython-novaclient~master~Ia62c8e37f240f0dfc00950f6ef6e1ecc4d5b9453,openstack/python-novaclient,master,Ia62c8e37f240f0dfc00950f6ef6e1ecc4d5b9453,Grammar typo in the comments for function set_meta.,MERGED,2017-02-27 17:16:58.000000000,2017-02-28 11:14:36.000000000,2017-02-28 11:14:36.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 9545}, {'_account_id': 19590}]","[{'number': 1, 'created': '2017-02-27 17:16:58.000000000', 'files': ['novaclient/v2/servers.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0a88bd439f138f3edeea589160cf7f9ce51aa752', 'message': 'Grammar typo in the comments for function set_meta.\n\nChange-Id: Ia62c8e37f240f0dfc00950f6ef6e1ecc4d5b9453\nCloses-Bug: #1668336\n'}]",0,438631,0a88bd439f138f3edeea589160cf7f9ce51aa752,8,4,1,19910,,,0,"Grammar typo in the comments for function set_meta.

Change-Id: Ia62c8e37f240f0dfc00950f6ef6e1ecc4d5b9453
Closes-Bug: #1668336
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/31/438631/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v2/servers.py'],1,0a88bd439f138f3edeea589160cf7f9ce51aa752,fix-bug/1668336, Set a server's metadata :param metadata: A dict of metadata to be added to the server, Set a servers metadata :param metadata: A dict of metadata to add to the server,2,2
openstack%2Fneutron~master~I75e41b5801ff9dc7ea7edebfa7affa92fdcc9bd4,openstack/neutron,master,I75e41b5801ff9dc7ea7edebfa7affa92fdcc9bd4,Use registry decorator in ML2 plugin,MERGED,2017-02-27 13:19:57.000000000,2017-02-28 11:04:17.000000000,2017-02-28 10:43:29.000000000,"[{'_account_id': 3}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8726}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-27 13:19:57.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb3931a9924bb7a19bada78944344ed1e678f9a3', 'message': 'Use registry decorator in ML2 plugin\n\nUse the new registry decorator for subscribing to callbacks in ML2 so\nits easy to see when each function will be called.\n\nTrivialFix\n\nChange-Id: I75e41b5801ff9dc7ea7edebfa7affa92fdcc9bd4\n'}]",0,438489,bb3931a9924bb7a19bada78944344ed1e678f9a3,22,6,1,7787,,,0,"Use registry decorator in ML2 plugin

Use the new registry decorator for subscribing to callbacks in ML2 so
its easy to see when each function will be called.

TrivialFix

Change-Id: I75e41b5801ff9dc7ea7edebfa7affa92fdcc9bd4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/438489/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,bb3931a9924bb7a19bada78944344ed1e678f9a3,,"@registry.has_registry_receivers @registry.receives(resources.PORT, [provisioning_blocks.PROVISIONING_COMPLETE]) @registry.receives(resources.SEGMENT, (events.PRECOMMIT_CREATE, events.PRECOMMIT_DELETE, events.AFTER_CREATE, events.AFTER_DELETE))"," registry.subscribe(self._port_provisioned, resources.PORT, provisioning_blocks.PROVISIONING_COMPLETE) registry.subscribe(self._handle_segment_change, resources.SEGMENT, events.PRECOMMIT_CREATE) registry.subscribe(self._handle_segment_change, resources.SEGMENT, events.PRECOMMIT_DELETE) registry.subscribe(self._handle_segment_change, resources.SEGMENT, events.AFTER_CREATE) registry.subscribe(self._handle_segment_change, resources.SEGMENT, events.AFTER_DELETE)",7,10
openstack%2Fpython-watcherclient~master~Ib9600297b6b65a44a72090cfb0c7d8f80dcfd34a,openstack/python-watcherclient,master,Ib9600297b6b65a44a72090cfb0c7d8f80dcfd34a,Remove RST files located in doc/source/api.,MERGED,2017-02-14 17:06:52.000000000,2017-02-28 11:04:09.000000000,2017-02-28 11:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 18971}]","[{'number': 1, 'created': '2017-02-14 17:06:52.000000000', 'files': ['doc/source/api/watcherclient.v1.audit_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_shell.rst', 'doc/source/api/watcherclient.common.utils.rst', 'doc/source/api/watcherclient.tests.v1.test_action_plan.rst', 'doc/source/api/watcherclient.v1.action_plan.rst', 'doc/source/api/watcherclient.v1.audit.rst', 'doc/source/api/watcherclient.common.apiclient.base.rst', 'doc/source/api/watcherclient.common.apiclient.exceptions.rst', 'doc/source/api/watcherclient.tests.v1.test_action.rst', 'doc/source/api/watcherclient.v1.client.rst', 'doc/source/api/watcherclient.v1.metric_collector_shell.rst', 'doc/source/api/watcherclient.common.apiclient.auth.rst', 'doc/source/api/watcherclient.v1.goal.rst', 'doc/source/api/watcherclient.common.base.rst', 'doc/source/api/watcherclient.exceptions.rst', 'doc/source/api/watcherclient.tests.v1.test_metric_collector_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_action_shell.rst', 'doc/source/api/watcherclient.shell.rst', 'doc/source/api/watcherclient.tests.test_shell.rst', 'doc/source/api/watcherclient.tests.keystone_client_fixtures.rst', 'doc/source/api/watcherclient.v1.shell.rst', 'doc/source/api/watcherclient.tests.test_http.rst', 'doc/source/api/watcherclient.common.apiclient.client.rst', 'doc/source/api/watcherclient.tests.utils.rst', 'doc/source/api/watcherclient.v1.resource_fields.rst', 'doc/source/api/watcherclient.client.rst', 'doc/source/api/watcherclient.tests.v1.test_audit.rst', 'doc/source/api/watcherclient.version.rst', 'doc/source/api/watcherclient.tests.test_import.rst', 'doc/source/api/watcherclient.tests.test_utils.rst', 'doc/source/api/watcherclient.v1.audit_template_shell.rst', 'doc/source/api/watcherclient.common.i18n.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_template.rst', 'doc/source/api/watcherclient.common.cliutils.rst', 'doc/source/api/watcherclient.tests.test_client.rst', 'doc/source/api/watcherclient.v1.goal_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_action_plan_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_goal_shell.rst', 'doc/source/api/watcherclient.v1.action.rst', 'doc/source/api/watcherclient.common.apiclient.utils.rst', 'doc/source/api/watcherclient.tests.v1.test_metric_collector.rst', 'doc/source/api/watcherclient.v1.audit_template.rst', 'doc/source/api/watcherclient.v1.action_plan_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_goal.rst', 'doc/source/api/watcherclient.v1.action_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_template_shell.rst', 'doc/source/api/watcherclient.common.http.rst', 'doc/source/api/watcherclient.v1.metric_collector.rst'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/cd267c9fa42bcb64859084e008de74b9fb959aa6', 'message': 'Remove RST files located in doc/source/api.\n\nChange-Id: Ib9600297b6b65a44a72090cfb0c7d8f80dcfd34a\nCloses-Bug: 1640811\n'}]",0,433795,cd267c9fa42bcb64859084e008de74b9fb959aa6,7,2,1,21361,,,0,"Remove RST files located in doc/source/api.

Change-Id: Ib9600297b6b65a44a72090cfb0c7d8f80dcfd34a
Closes-Bug: 1640811
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/95/433795/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/api/watcherclient.v1.audit_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_shell.rst', 'doc/source/api/watcherclient.common.utils.rst', 'doc/source/api/watcherclient.tests.v1.test_action_plan.rst', 'doc/source/api/watcherclient.v1.action_plan.rst', 'doc/source/api/watcherclient.v1.audit.rst', 'doc/source/api/watcherclient.common.apiclient.base.rst', 'doc/source/api/watcherclient.common.apiclient.exceptions.rst', 'doc/source/api/watcherclient.tests.v1.test_action.rst', 'doc/source/api/watcherclient.v1.client.rst', 'doc/source/api/watcherclient.v1.metric_collector_shell.rst', 'doc/source/api/watcherclient.common.apiclient.auth.rst', 'doc/source/api/watcherclient.v1.goal.rst', 'doc/source/api/watcherclient.common.base.rst', 'doc/source/api/watcherclient.exceptions.rst', 'doc/source/api/watcherclient.tests.v1.test_metric_collector_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_action_shell.rst', 'doc/source/api/watcherclient.shell.rst', 'doc/source/api/watcherclient.tests.test_shell.rst', 'doc/source/api/watcherclient.tests.keystone_client_fixtures.rst', 'doc/source/api/watcherclient.v1.shell.rst', 'doc/source/api/watcherclient.tests.test_http.rst', 'doc/source/api/watcherclient.common.apiclient.client.rst', 'doc/source/api/watcherclient.tests.utils.rst', 'doc/source/api/watcherclient.v1.resource_fields.rst', 'doc/source/api/watcherclient.client.rst', 'doc/source/api/watcherclient.tests.v1.test_audit.rst', 'doc/source/api/watcherclient.version.rst', 'doc/source/api/watcherclient.tests.test_import.rst', 'doc/source/api/watcherclient.tests.test_utils.rst', 'doc/source/api/watcherclient.v1.audit_template_shell.rst', 'doc/source/api/watcherclient.common.i18n.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_template.rst', 'doc/source/api/watcherclient.common.cliutils.rst', 'doc/source/api/watcherclient.tests.test_client.rst', 'doc/source/api/watcherclient.v1.goal_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_action_plan_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_goal_shell.rst', 'doc/source/api/watcherclient.v1.action.rst', 'doc/source/api/watcherclient.common.apiclient.utils.rst', 'doc/source/api/watcherclient.tests.v1.test_metric_collector.rst', 'doc/source/api/watcherclient.v1.audit_template.rst', 'doc/source/api/watcherclient.v1.action_plan_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_goal.rst', 'doc/source/api/watcherclient.v1.action_shell.rst', 'doc/source/api/watcherclient.tests.v1.test_audit_template_shell.rst', 'doc/source/api/watcherclient.common.http.rst', 'doc/source/api/watcherclient.v1.metric_collector.rst']",48,cd267c9fa42bcb64859084e008de74b9fb959aa6,bug/1640811,,The :mod:`watcherclient.v1.metric_collector` Module =================================================== .. automodule:: watcherclient.v1.metric_collector :members: :undoc-members: :show-inheritance: ,0,336
openstack%2Ffuel-qa~master~I99959cb72caeec33a91358af4b58fa858b9c22c8,openstack/fuel-qa,master,I99959cb72caeec33a91358af4b58fa858b9c22c8,Redirect update-master-node.sh stdout and stderr,MERGED,2017-02-23 13:29:23.000000000,2017-02-28 11:01:36.000000000,2017-02-23 15:39:09.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11081}, {'_account_id': 15984}]","[{'number': 1, 'created': '2017-02-23 13:29:23.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a', 'message': ""Redirect update-master-node.sh stdout and stderr\n\nSSHD stops reading of update-master-node.sh stdout\nduring puppet run, this causes puppet hanging on\nkeystone tasks. In order to avoid this we need to\nredirect script's output to /dev/null.\n\nChange-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8\nCloses-Bug: #1664635\n""}]",0,437373,ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a,13,5,1,18795,,,0,"Redirect update-master-node.sh stdout and stderr

SSHD stops reading of update-master-node.sh stdout
during puppet run, this causes puppet hanging on
keystone tasks. In order to avoid this we need to
redirect script's output to /dev/null.

Change-Id: I99959cb72caeec33a91358af4b58fa858b9c22c8
Closes-Bug: #1664635
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/73/437373/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,ee0bf1cfa424aca4c2eb65a5d8506661b8e3346a,bug/1664635, # LP #1664635 - we need to redirect stdout to /dev/null to avoid # ssh connection hanging on massive output from puppet run. cmd = '/usr/share/fuel-utils/update-master-node.sh > /dev/null 2>&1', cmd = '/usr/share/fuel-utils/update-master-node.sh',3,1
openstack%2Fopenstack-manuals~master~I48a24bc88cef38bc0b04913dccb86030371de8b0,openstack/openstack-manuals,master,I48a24bc88cef38bc0b04913dccb86030371de8b0,"Has been revised, please review, thank you.",ABANDONED,2017-02-28 09:25:11.000000000,2017-02-28 10:58:48.000000000,,"[{'_account_id': 3}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-28 09:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b8b38257cc4e587caf1ae9a92f450a99598527e', 'message': 'Has been revised, please review, thank you.\n\nChange-Id: I48a24bc88cef38bc0b04913dccb86030371de8b0\n'}]",0,438872,9b8b38257cc4e587caf1ae9a92f450a99598527e,4,2,1,23975,,,0,"Has been revised, please review, thank you.

Change-Id: I48a24bc88cef38bc0b04913dccb86030371de8b0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/438872/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,9b8b38257cc4e587caf1ae9a92f450a99598527e,,,,0,0
openstack%2Ftripleo-heat-templates~master~I36d66b42d1ac5030db8841820d4fc512a71d1285,openstack/tripleo-heat-templates,master,I36d66b42d1ac5030db8841820d4fc512a71d1285,Write out a json file containing container startup info and create tool to use it.,MERGED,2017-02-09 21:27:02.000000000,2017-02-28 10:58:17.000000000,2017-02-28 10:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6159}]","[{'number': 1, 'created': '2017-02-09 21:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/042e5e2d73ec99f12482dee3d204a8a1019686fd', 'message': ""Write out a json file containing container startup info and create tool to start it.\n\nThis adds a bit to the post.yaml for docker to write out a json file\ncontaining all the information on how we are start docker containers\n(thanks Dan!).  I've then written a script that parses this and can\nbe used to execute docker run commands in various ways for debugging\npurposes.\n\nChange-Id: I36d66b42d1ac5030db8841820d4fc512a71d1285\nCo-Authored-by: Dan Prince <dprince@redhat.com>\n""}, {'number': 2, 'created': '2017-02-09 21:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23150846ccf89e567b2c48df038e618739833734', 'message': ""Write out a json file containing container startup info and create tool to use it.\n\nThis adds a bit to the post.yaml for docker to write out a json file\ncontaining all the information on how we are start docker containers\n(thanks Dan!).  I've then written a script that parses this that can\nbe used to execute docker run commands in various ways for debugging\npurposes.\n\nChange-Id: I36d66b42d1ac5030db8841820d4fc512a71d1285\nCo-Authored-by: Dan Prince <dprince@redhat.com>\n""}, {'number': 3, 'created': '2017-02-22 18:29:51.000000000', 'files': ['docker/docker-toool', 'docker/post.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27b61887798fbfb88f293b4778633f969829d3ac', 'message': ""Write out a json file containing container startup info and create tool to use it.\n\nThis adds a bit to the post.yaml for docker to write out a json file\ncontaining all the information on how we are start docker containers\n(thanks Dan!).  I've then written a script that parses this that can\nbe used to execute docker run commands in various ways for debugging\npurposes.\n\nChange-Id: I36d66b42d1ac5030db8841820d4fc512a71d1285\nCo-Authored-by: Dan Prince <dprince@redhat.com>\n""}]",0,431746,27b61887798fbfb88f293b4778633f969829d3ac,18,3,3,2011,,,0,"Write out a json file containing container startup info and create tool to use it.

This adds a bit to the post.yaml for docker to write out a json file
containing all the information on how we are start docker containers
(thanks Dan!).  I've then written a script that parses this that can
be used to execute docker run commands in various ways for debugging
purposes.

Change-Id: I36d66b42d1ac5030db8841820d4fc512a71d1285
Co-Authored-by: Dan Prince <dprince@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/431746/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/docker-toool', 'docker/post.j2.yaml']",2,042e5e2d73ec99f12482dee3d204a8a1019686fd,docker_glance," # Here we are dumping all the docker container startup configuration data # so that we can have access to how they are started outside of heat # and docker-cmd. This lets us create command line tools to start and # test these containers. {{role.name}}DockerConfigJsonStartupData: type: OS::Heat::StructuredConfig properties: group: json-file config: /var/lib/docker-container-startup-configs.json: {get_attr: [{{role.name}}DockerConfig, value]} {{role.name}}DockerConfigJsonStartupDataDeployment: type: OS::Heat::SoftwareDeploymentGroup properties: config: {get_resource: {{role.name}}DockerConfigJsonStartupData} servers: {get_param: [servers, {{role.name}}]} ",,210,0
openstack%2Fmistral~master~I1d54c6a98a8c98a24736a8605d417c2db900c414,openstack/mistral,master,I1d54c6a98a8c98a24736a8605d417c2db900c414,Make the workflow definition optional,ABANDONED,2017-02-28 10:57:03.000000000,2017-02-28 10:58:08.000000000,,[],"[{'number': 1, 'created': '2017-02-28 10:57:03.000000000', 'files': ['mistral/engine/workflows.py', 'mistral/engine/workflow_handler.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/4468ea16905457488a711ed48aeb6594d9dbb1d7', 'message': 'Make the workflow definition optional\n\nChange-Id: I1d54c6a98a8c98a24736a8605d417c2db900c414\n'}]",0,438908,4468ea16905457488a711ed48aeb6594d9dbb1d7,2,0,1,9712,,,0,"Make the workflow definition optional

Change-Id: I1d54c6a98a8c98a24736a8605d417c2db900c414
",git fetch https://review.opendev.org/openstack/mistral refs/changes/08/438908/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/workflows.py', 'mistral/engine/workflow_handler.py']",2,4468ea16905457488a711ed48aeb6594d9dbb1d7,, wf = workflows.Workflow(wf_ex=wf_ex)," wf = workflows.Workflow( db_api.get_workflow_definition(wf_ex.workflow_id), wf_ex=wf_ex )",2,5
openstack%2Fcongress~master~I25ff6fb917c6255781ac8188e7f7ed81f17aa011,openstack/congress,master,I25ff6fb917c6255781ac8188e7f7ed81f17aa011,Fix some tiny errors in doc,MERGED,2017-02-23 07:32:53.000000000,2017-02-28 10:48:59.000000000,2017-02-28 10:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 18591}]","[{'number': 1, 'created': '2017-02-23 07:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0a6fb1ff13ce18ea7d61c776d7a262ec2a2ec2d2', 'message': 'Use ""OpenStack"" instead of ""Openstack""\n\nChange-Id: I25ff6fb917c6255781ac8188e7f7ed81f17aa011\n'}, {'number': 2, 'created': '2017-02-23 07:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cd61ebf2cd30a68b38609f1e47773b69c041cd97', 'message': 'Fix some tiny errors in doc\n\nChange-Id: I25ff6fb917c6255781ac8188e7f7ed81f17aa011\n'}, {'number': 3, 'created': '2017-02-28 02:07:33.000000000', 'files': ['doc/source/architecture.rst', 'doc/source/cloudservices.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/8abedfeb27775421aa875ec2e3c1986d8a7418cb', 'message': 'Fix some tiny errors in doc\n\nChange-Id: I25ff6fb917c6255781ac8188e7f7ed81f17aa011\n'}]",0,437269,8abedfeb27775421aa875ec2e3c1986d8a7418cb,13,2,3,21797,,,0,"Fix some tiny errors in doc

Change-Id: I25ff6fb917c6255781ac8188e7f7ed81f17aa011
",git fetch https://review.opendev.org/openstack/congress refs/changes/69/437269/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/cloudservices.rst'],1,0a6fb1ff13ce18ea7d61c776d7a262ec2a2ec2d2,fix, - OpenStack Aodh, - Openstack Aodh,1,1
openstack%2Ftripleo-ui~stable%2Focata~I00fa6768a71dc960427994a2b0c56c384d0eb9d3,openstack/tripleo-ui,stable/ocata,I00fa6768a71dc960427994a2b0c56c384d0eb9d3,Imported Translations from Zanata,MERGED,2017-02-28 08:48:39.000000000,2017-02-28 10:46:27.000000000,2017-02-28 10:46:27.000000000,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-02-28 08:48:39.000000000', 'files': ['i18n/locales/zh-CN.json', 'i18n/locales/es.json', 'i18n/locales/ja.json'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/18811fb6f76b252d90ea439dbb14ba3c09a0392c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I00fa6768a71dc960427994a2b0c56c384d0eb9d3\n'}]",0,438855,18811fb6f76b252d90ea439dbb14ba3c09a0392c,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I00fa6768a71dc960427994a2b0c56c384d0eb9d3
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/55/438855/1 && git format-patch -1 --stdout FETCH_HEAD,"['i18n/locales/es.json', 'i18n/locales/zh-CN.json', 'i18n/locales/ja.json']",3,18811fb6f76b252d90ea439dbb14ba3c09a0392c,zanata/translations," ""NodesTable.loadingNodes"": ""\u30ce\u30fc\u30c9\u3092\u8aad\u307f\u8fbc\u307f\u4e2d..."", ""NodesTable.noNodes"": ""\u5229\u7528\u3067\u304d\u308b\u30ce\u30fc\u30c9\u304c\u3042\u308a\u307e\u305b\u3093\u3002"", ""NodesTables.cpuArch"": ""CPU \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30fc"", ""NodesTables.cpuCores"": ""CPU (\u30b3\u30a2)"", ""NodesTables.diskGb"": ""\u30c7\u30a3\u30b9\u30af (GB)"", ""NodesTables.macAddresses"": ""MAC \u30a2\u30c9\u30ec\u30b9"", ""NodesTables.memoryMb"": ""\u30e1\u30e2\u30ea\u30fc (MB)"", ""NodesTables.name"": ""\u540d\u524d"", ""NodesTables.powerState"": ""\u96fb\u6e90\u72b6\u614b"", ""NodesTables.profile"": ""\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb"", ""NodesTables.provisionState"": ""\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u72b6\u614b"",",,19,0
openstack%2Finstack-undercloud~master~I8b961fa542af4cf40c82d92192184ab5eb571e6d,openstack/instack-undercloud,master,I8b961fa542af4cf40c82d92192184ab5eb571e6d,Use Swift as a Zaqar backend.,MERGED,2017-02-16 08:27:19.000000000,2017-02-28 10:46:17.000000000,2017-02-28 10:46:17.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7385}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-16 08:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/58f5eb74d7842f84639be7377b6a4e78cc7ef2f7', 'message': 'Use Swift as a Zaqar backend.\n\nUse the new Swift storage backend for Zaqar. This removes mongo from the\nundercloud.\n\nChange-Id: I8b961fa542af4cf40c82d92192184ab5eb571e6d\n'}, {'number': 2, 'created': '2017-02-22 21:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/025acd9401ac820e60c16276ed7e1c1a7aecd733', 'message': 'Use Swift as a Zaqar backend.\n\nUse the new Swift storage backend for Zaqar. This removes mongo from the\nundercloud.\n\nChange-Id: I8b961fa542af4cf40c82d92192184ab5eb571e6d\n'}, {'number': 3, 'created': '2017-02-27 08:31:25.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp', 'releasenotes/notes/swift_zaqar-d476d1a8eb946776.yaml', 'elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/95de498d0f8dbd10c6f66d32c3d4ea7e25c8f148', 'message': 'Use Swift as a Zaqar backend.\n\nUse the new Swift storage backend for Zaqar. This removes mongo from the\nundercloud.\n\nChange-Id: I8b961fa542af4cf40c82d92192184ab5eb571e6d\n'}]",4,434727,95de498d0f8dbd10c6f66d32c3d4ea7e25c8f148,22,4,3,7385,,,0,"Use Swift as a Zaqar backend.

Use the new Swift storage backend for Zaqar. This removes mongo from the
undercloud.

Change-Id: I8b961fa542af4cf40c82d92192184ab5eb571e6d
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/27/434727/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-stack-config/puppet-stack-config.pp', 'elements/puppet-stack-config/puppet-stack-config.yaml.template']",2,58f5eb74d7842f84639be7377b6a4e78cc7ef2f7,zaqar-swift,"zaqar::message_store: swift zaqar::management_store: sqlalchemy zaqar::management::sqlalchemy::uri: mysql+pymysql://zaqar:{{UNDERCLOUD_ZAQAR_PASSWORD}}@{{LOCAL_IP}}/zaqar zaqar::messaging::swift::uri: swift://zaqar:{{UNDERCLOUD_ZAQAR_PASSWORD}}@/service zaqar::messaging::swift::auth_url: ""%{hiera('keystone_auth_uri')}""",zaqar::management::mongodb::uri: mongodb://127.0.0.1:27017 zaqar::messaging::mongodb::uri: mongodb://127.0.0.1:27017 '101 mongodb_config': dport: 27019 '102 mongodb_sharding': dport: 27018 '103 mongod': dport: 27017,7,14
openstack%2Fceilometermiddleware~master~Iffea59754960ea13e7ae6b8f9d63001b243fa4f6,openstack/ceilometermiddleware,master,Iffea59754960ea13e7ae6b8f9d63001b243fa4f6,Read swift-proxy configuration file from middleware,ABANDONED,2017-02-27 09:04:08.000000000,2017-02-28 10:45:19.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-27 09:04:08.000000000', 'files': ['ceilometermiddleware/swift.py'], 'web_link': 'https://opendev.org/openstack/ceilometermiddleware/commit/8f9a7d907aa92157370324e656bd14a0cf80d628', 'message': ""Read swift-proxy configuration file from middleware\n\nThis enables us to add the driver-specific configurations for the\nnotification driver used. This is necessary since currently we are\nnot able to configure SSL or the HA-specific parameters of the driver,\nsince one has to do this in a separate section of the configuration, and\nthe current implementation can't read that.\n\nChange-Id: Iffea59754960ea13e7ae6b8f9d63001b243fa4f6\n""}]",2,438377,8f9a7d907aa92157370324e656bd14a0cf80d628,6,3,1,10873,,,0,"Read swift-proxy configuration file from middleware

This enables us to add the driver-specific configurations for the
notification driver used. This is necessary since currently we are
not able to configure SSL or the HA-specific parameters of the driver,
since one has to do this in a separate section of the configuration, and
the current implementation can't read that.

Change-Id: Iffea59754960ea13e7ae6b8f9d63001b243fa4f6
",git fetch https://review.opendev.org/openstack/ceilometermiddleware refs/changes/77/438377/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometermiddleware/swift.py'],1,8f9a7d907aa92157370324e656bd14a0cf80d628,read-config," self.conf = cfg.ConfigOpts() oslo_messaging.get_transport(self.conf, url=conf.get('url')), self.conf(['--config-file', conf['__file__']])"," oslo_messaging.get_transport(cfg.CONF, url=conf.get('url')),",3,1
openstack%2Fcinder~master~Ice3b2819b65c55cb189a0c16c0d7ef2795bd20dd,openstack/cinder,master,Ice3b2819b65c55cb189a0c16c0d7ef2795bd20dd,Reuse identical API v2 code for v1,MERGED,2017-02-26 04:29:19.000000000,2017-02-28 10:43:55.000000000,2017-02-28 10:43:55.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 11600}]","[{'number': 1, 'created': '2017-02-26 04:29:19.000000000', 'files': ['cinder/api/v1/snapshot_metadata.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/api/v1/router.py', 'cinder/api/v1/limits.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c50e4b2e6a40217097220f03109080e4a0982213', 'message': 'Reuse identical API v2 code for v1\n\nThere are a couple modules that are virtually identical between\nAPI v1 and v2. This cleans up some of the v1 API code to just\nuse the v2 API code.\n\nMore clean up can be done for other API modules, but there are\nsubtle differences (returning 200 vs 202) between the two. The\ncode can still be reused, but some v1 specific handling will\nneed to be put in place to make that optimization.\n\nChange-Id: Ice3b2819b65c55cb189a0c16c0d7ef2795bd20dd\nPartial-bug: #1627921\n'}]",0,438230,c50e4b2e6a40217097220f03109080e4a0982213,59,4,1,11904,,,0,"Reuse identical API v2 code for v1

There are a couple modules that are virtually identical between
API v1 and v2. This cleans up some of the v1 API code to just
use the v2 API code.

More clean up can be done for other API modules, but there are
subtle differences (returning 200 vs 202) between the two. The
code can still be reused, but some v1 specific handling will
need to be put in place to make that optimization.

Change-Id: Ice3b2819b65c55cb189a0c16c0d7ef2795bd20dd
Partial-bug: #1627921
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/438230/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v1/snapshot_metadata.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/api/v1/router.py', 'cinder/api/v1/limits.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py']",5,c50e4b2e6a40217097220f03109080e4a0982213,bug/1627921,,"# Copyright 2011 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from oslo_serialization import jsonutils import webob from cinder.api import extensions from cinder.api.v1 import snapshot_metadata from cinder.api.v1 import snapshots from cinder import context import cinder.db from cinder import exception as exc from cinder.objects import fields from cinder import test from cinder.tests.unit.api import fakes from cinder.tests.unit import fake_constants as fake from cinder.tests.unit import fake_snapshot from cinder.tests.unit import fake_volume from cinder import volume def return_create_snapshot_metadata(context, snapshot_id, metadata, delete): return stub_snapshot_metadata(snapshot_id) def return_create_snapshot_metadata_insensitive(context, snapshot_id, metadata, delete): return stub_snapshot_metadata_insensitive(snapshot_id) def return_new_snapshot_metadata(context, snapshot_id, metadata, delete): return stub_new_snapshot_metadata(snapshot_id) def return_empty_container_metadata(context, snapshot_id, metadata, delete): if snapshot_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.SnapshotNotFound(snapshot_id) return {} def stub_snapshot_metadata(snapshot_id): if snapshot_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.SnapshotNotFound(snapshot_id) metadata = { ""key1"": ""value1"", ""key2"": ""value2"", ""key3"": ""value3"", } return metadata def stub_snapshot_metadata_insensitive(snapshot_id): if snapshot_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.SnapshotNotFound(snapshot_id) metadata = { ""key1"": ""value1"", ""key2"": ""value2"", ""key3"": ""value3"", ""KEY4"": ""value4"", } return metadata def stub_new_snapshot_metadata(snapshot_id): if snapshot_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.SnapshotNotFound(snapshot_id) metadata = { 'key10': 'value10', 'key99': 'value99', 'KEY20': 'value20', } return metadata def return_snapshot(context, snapshot_id): if snapshot_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.SnapshotNotFound(snapshot_id) return {'id': '0cc3346e-9fef-4445-abe6-5d2b2690ec64', 'name': 'fake', 'status': 'available', 'metadata': {}} def stub_get(self, context, volume_id, *args, **kwargs): if volume_id == fake.WILL_NOT_BE_FOUND_ID: raise exc.VolumeNotFound(volume_id) vol = {'id': volume_id, 'size': 100, 'name': 'fake', 'host': 'fake-host', 'status': 'available', 'encryption_key_id': None, 'volume_type_id': None, 'migration_status': None, 'availability_zone': 'zone1:host1', 'attach_status': fields.VolumeAttachStatus.DETACHED} return fake_volume.fake_volume_obj(context, **vol) def fake_update_snapshot_metadata(self, context, snapshot, diff): pass class SnapshotMetaDataTest(test.TestCase): def setUp(self): super(SnapshotMetaDataTest, self).setUp() self.volume_api = cinder.volume.api.API() self.stubs.Set(volume.api.API, 'get', stub_get) self.stubs.Set(cinder.db, 'snapshot_get', return_snapshot) self.stubs.Set(self.volume_api, 'update_snapshot_metadata', fake_update_snapshot_metadata) self.ext_mgr = extensions.ExtensionManager() self.ext_mgr.extensions = {} self.snapshot_controller = snapshots.SnapshotsController(self.ext_mgr) self.controller = snapshot_metadata.Controller() self.url = '/v1/%s/snapshots/%s/metadata' % ( fake.PROJECT_ID, fake.SNAPSHOT_ID) snap = {""volume_size"": 100, ""volume_id"": fake.VOLUME_ID, ""display_name"": ""Snapshot Test Name"", ""display_description"": ""Snapshot Test Desc"", ""availability_zone"": ""zone1:host1"", ""host"": ""fake-host"", ""metadata"": {}} body = {""snapshot"": snap} req = fakes.HTTPRequest.blank('/v1/snapshots') self.snapshot_controller.create(req, body) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_index(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_obj['metadata'] = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'} snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url) res_dict = self.controller.index(req, fake.SNAPSHOT_ID) expected = { 'metadata': { 'key1': 'value1', 'key2': 'value2', 'key3': 'value3', }, } self.assertEqual(expected, res_dict) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_index_nonexistent_snapshot(self, snapshot_get_by_id): snapshot_get_by_id.side_effect = \ exc.SnapshotNotFound(snapshot_id=fake.WILL_NOT_BE_FOUND_ID) req = fakes.HTTPRequest.blank(self.url) self.assertRaises(exc.SnapshotNotFound, self.controller.index, req, self.url) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_index_no_data(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url) res_dict = self.controller.index(req, fake.SNAPSHOT_ID) expected = {'metadata': {}} self.assertEqual(expected, res_dict) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_show(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_obj['metadata'] = {'key2': 'value2'} snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url + '/key2') res_dict = self.controller.show(req, fake.SNAPSHOT_ID, 'key2') expected = {'meta': {'key2': 'value2'}} self.assertEqual(expected, res_dict) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_show_nonexistent_snapshot(self, snapshot_get_by_id): snapshot_get_by_id.side_effect = \ exc.SnapshotNotFound(snapshot_id=fake.WILL_NOT_BE_FOUND_ID) req = fakes.HTTPRequest.blank(self.url + '/key2') self.assertRaises(exc.SnapshotNotFound, self.controller.show, req, fake.SNAPSHOT_ID, 'key2') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_show_meta_not_found(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url + '/key6') self.assertRaises(exc.SnapshotMetadataNotFound, self.controller.show, req, fake.SNAPSHOT_ID, 'key6') @mock.patch('cinder.db.snapshot_metadata_delete') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_delete(self, snapshot_get_by_id, snapshot_metadata_delete): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_obj['metadata'] = {'key2': 'value2'} snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url + '/key2') req.method = 'DELETE' res = self.controller.delete(req, fake.SNAPSHOT_ID, 'key2') self.assertEqual(200, res.status_int) def test_delete_nonexistent_snapshot(self): req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'DELETE' self.assertRaises(exc.SnapshotNotFound, self.controller.delete, req, fake.WILL_NOT_BE_FOUND_ID, 'key1') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_delete_meta_not_found(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url + '/key6') req.method = 'DELETE' self.assertRaises(exc.SnapshotMetadataNotFound, self.controller.delete, req, fake.SNAPSHOT_ID, 'key6') @mock.patch('cinder.db.snapshot_update') @mock.patch('cinder.objects.Volume.get_by_id') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_create(self, snapshot_get_by_id, volume_get_by_id, snapshot_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) fake_volume_obj = fake_volume.fake_volume_obj(ctx) snapshot_get_by_id.return_value = snapshot_obj volume_get_by_id.return_value = fake_volume_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank('/v1/snapshot_metadata') req.method = 'POST' req.content_type = ""application/json"" body = {""metadata"": {""key1"": ""value1"", ""key2"": ""value2"", ""key3"": ""value3""}} req.body = jsonutils.dump_as_bytes(body) res_dict = self.controller.create(req, fake.SNAPSHOT_ID, body) self.assertEqual(body, res_dict) @mock.patch('cinder.db.snapshot_update') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_create_with_keys_in_uppercase_and_lowercase( self, snapshot_get_by_id, snapshot_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj # if the keys in uppercase_and_lowercase, should return the one # which server added self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata_insensitive) req = fakes.HTTPRequest.blank('/v1/snapshot_metadata') req.method = 'POST' req.content_type = ""application/json"" body = {""metadata"": {""key1"": ""value1"", ""KEY1"": ""value1"", ""key2"": ""value2"", ""KEY2"": ""value2"", ""key3"": ""value3"", ""KEY4"": ""value4""}} expected = {""metadata"": {""key1"": ""value1"", ""key2"": ""value2"", ""key3"": ""value3"", ""KEY4"": ""value4""}} req.body = jsonutils.dump_as_bytes(body) res_dict = self.controller.create(req, fake.SNAPSHOT_ID, body) self.assertEqual(expected, res_dict) def test_create_empty_body(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'POST' req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, req, fake.SNAPSHOT_ID, None) def test_create_item_empty_key(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {"""": ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, req, fake.SNAPSHOT_ID, body) def test_create_item_key_too_long(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {(""a"" * 260): ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, req, fake.SNAPSHOT_ID, body) def test_create_nonexistent_snapshot(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank('/v1/snapshot_metadata') req.method = 'POST' req.content_type = ""application/json"" body = {""metadata"": {""key9"": ""value9""}} req.body = jsonutils.dump_as_bytes(body) self.assertRaises(exc.SnapshotNotFound, self.controller.create, req, fake.WILL_NOT_BE_FOUND_ID, body) @mock.patch('cinder.db.snapshot_update') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_all(self, snapshot_get_by_id, snapshot_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': [] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_new_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" expected = { 'metadata': { 'key10': 'value10', 'key99': 'value99', 'KEY20': 'value20', }, } req.body = jsonutils.dump_as_bytes(expected) res_dict = self.controller.update_all(req, fake.SNAPSHOT_ID, expected) self.assertEqual(expected, res_dict) @mock.patch('cinder.db.snapshot_update', return_value={'key10': 'value10', 'key99': 'value99', 'KEY20': 'value20'}) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_all_with_keys_in_uppercase_and_lowercase( self, snapshot_get_by_id, snapshot_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_new_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" body = { 'metadata': { 'key10': 'value10', 'KEY10': 'value10', 'key99': 'value99', 'KEY20': 'value20', }, } expected = { 'metadata': { 'key10': 'value10', 'key99': 'value99', 'KEY20': 'value20', }, } req.body = jsonutils.dump_as_bytes(expected) res_dict = self.controller.update_all(req, fake.SNAPSHOT_ID, body) self.assertEqual(expected, res_dict) @mock.patch('cinder.db.snapshot_update') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_all_empty_container(self, snapshot_get_by_id, snapshot_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': [] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_empty_container_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" expected = {'metadata': {}} req.body = jsonutils.dump_as_bytes(expected) res_dict = self.controller.update_all(req, fake.SNAPSHOT_ID, expected) self.assertEqual(expected, res_dict) def test_update_all_malformed_container(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" expected = {'meta': {}} req.body = jsonutils.dump_as_bytes(expected) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update_all, req, fake.SNAPSHOT_ID, expected) @mock.patch('cinder.db.sqlalchemy.api._snapshot_get') @mock.patch('cinder.db.snapshot_metadata_update', autospec=True) def test_update_all_malformed_data(self, metadata_update, snapshot_get): snapshot_get.return_value = stub_get req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" expected = {'metadata': ['asdf']} req.body = jsonutils.dump_as_bytes(expected) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update_all, req, fake.SNAPSHOT_ID, expected) def test_update_all_nonexistent_snapshot(self): req = fakes.HTTPRequest.blank(self.url) req.method = 'PUT' req.content_type = ""application/json"" body = {'metadata': {'key10': 'value10'}} req.body = jsonutils.dump_as_bytes(body) self.assertRaises(exc.SnapshotNotFound, self.controller.update_all, req, fake.WILL_NOT_BE_FOUND_ID, body) @mock.patch('cinder.db.snapshot_metadata_update', return_value=dict()) @mock.patch('cinder.db.snapshot_update') @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_item(self, snapshot_get_by_id, snapshot_update, snapshot_metadata_update): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {""key1"": ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" res_dict = self.controller.update(req, fake.SNAPSHOT_ID, 'key1', body) expected = {'meta': {'key1': 'value1'}} self.assertEqual(expected, res_dict) def test_update_item_nonexistent_snapshot(self): req = fakes.HTTPRequest.blank( '/v1.1/fake/snapshots/asdf/metadata/key1') req.method = 'PUT' body = {""meta"": {""key1"": ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(exc.SnapshotNotFound, self.controller.update, req, fake.WILL_NOT_BE_FOUND_ID, 'key1', body) def test_update_item_empty_body(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, fake.SNAPSHOT_ID, 'key1', None) @mock.patch('cinder.db.sqlalchemy.api._snapshot_get') @mock.patch('cinder.db.snapshot_metadata_update', autospec=True) def test_update_item_empty_key(self, metadata_update, snapshot_get): snapshot_get.return_value = stub_get req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {"""": ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, fake.SNAPSHOT_ID, '', body) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_item_key_too_long(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {(""a"" * 260): ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, self.controller.update, req, fake.SNAPSHOT_ID, (""a"" * 260), body) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_update_item_value_too_long(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {""key1"": (""a"" * 260)}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, self.controller.update, req, fake.SNAPSHOT_ID, ""key1"", body) def test_update_item_too_many_keys(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/key1') req.method = 'PUT' body = {""meta"": {""key1"": ""value1"", ""key2"": ""value2""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, fake.SNAPSHOT_ID, 'key1', body) def test_update_item_body_uri_mismatch(self): self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url + '/bad') req.method = 'PUT' body = {""meta"": {""key1"": ""value1""}} req.body = jsonutils.dump_as_bytes(body) req.headers[""content-type""] = ""application/json"" self.assertRaises(webob.exc.HTTPBadRequest, self.controller.update, req, fake.SNAPSHOT_ID, 'bad', body) @mock.patch('cinder.objects.Snapshot.get_by_id') def test_invalid_metadata_items_on_create(self, snapshot_get_by_id): snapshot = { 'id': fake.SNAPSHOT_ID, 'expected_attrs': ['metadata'] } ctx = context.RequestContext(fake.USER_ID, fake.PROJECT_ID, True) snapshot_obj = fake_snapshot.fake_snapshot_obj(ctx, **snapshot) snapshot_get_by_id.return_value = snapshot_obj self.stubs.Set(cinder.db, 'snapshot_metadata_update', return_create_snapshot_metadata) req = fakes.HTTPRequest.blank(self.url) req.method = 'POST' req.headers[""content-type""] = ""application/json"" # test for long key data = {""metadata"": {""a"" * 260: ""value1""}} req.body = jsonutils.dump_as_bytes(data) self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, self.controller.create, req, fake.SNAPSHOT_ID, data) # test for long value data = {""metadata"": {""key"": ""v"" * 260}} req.body = jsonutils.dump_as_bytes(data) self.assertRaises(webob.exc.HTTPRequestEntityTooLarge, self.controller.create, req, fake.SNAPSHOT_ID, data) # test for empty key. data = {""metadata"": {"""": ""value1""}} req.body = jsonutils.dump_as_bytes(data) self.assertRaises(webob.exc.HTTPBadRequest, self.controller.create, req, fake.SNAPSHOT_ID, data) ",2,2062
openstack%2Fpuppet-designate~stable%2Fmitaka~I0af3c1e6afe1c0ca4da00dc80c2d0e5b1fdfd4dd,openstack/puppet-designate,stable/mitaka,I0af3c1e6afe1c0ca4da00dc80c2d0e5b1fdfd4dd,Change the value of common_package_name,ABANDONED,2017-02-28 09:42:54.000000000,2017-02-28 10:39:30.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}]","[{'number': 1, 'created': '2017-02-28 09:42:54.000000000', 'files': ['manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/c830a85d7a267f6850c9ae9dfef7ba35c6778803', 'message': 'Change the value of common_package_name\n\nChange-Id: I0af3c1e6afe1c0ca4da00dc80c2d0e5b1fdfd4dd\n'}]",0,438880,c830a85d7a267f6850c9ae9dfef7ba35c6778803,4,2,1,24579,,,0,"Change the value of common_package_name

Change-Id: I0af3c1e6afe1c0ca4da00dc80c2d0e5b1fdfd4dd
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/80/438880/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,c830a85d7a267f6850c9ae9dfef7ba35c6778803,, $common_package_name = 'openstack-designate-common', $common_package_name = 'openstack-designate',1,1
openstack%2Fdragonflow~master~I8c9aa74e9d393816612a45306f9c6f4d43b943ca,openstack/dragonflow,master,I8c9aa74e9d393816612a45306f9c6f4d43b943ca,Propose a pub/sub refactor,MERGED,2017-01-26 10:31:39.000000000,2017-02-28 10:36:56.000000000,2017-02-28 10:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}, {'_account_id': 23235}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-01-26 10:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f87eaf9c696d56faca8dd31b4fc785d050bf40cb', 'message': ""Propose a pub/sub refactor\n\nThis blueprint is in its draft stage. The workitems listed in the spec\nmay not cover all the aspects. Some words may not be suitable.\n\nI'd like first bring it up to discuss the problems.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: bp/pub-sub-v2\n""}, {'number': 2, 'created': '2017-02-04 04:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d1c98034ff868bece54d682ea42f135d7ce63b5c', 'message': ""Propose a pub/sub refactor\n\nThis blueprint is in its draft stage. The workitems listed in the spec\nmay not cover all the aspects. Some words may not be suitable.\n\nI'd like first bring it up to discuss the problems.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: bp/pub-sub-v2\n""}, {'number': 3, 'created': '2017-02-04 06:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2ccead8eb39d45c55eb6ed8e4e5be3d1eeca29c9', 'message': ""Propose a pub/sub refactor\n\nThis blueprint is in its draft stage. The workitems listed in the spec\nmay not cover all the aspects. Some words may not be suitable.\n\nI'd like first bring it up to discuss the problems.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nPartially-Implements: bp/pub-sub-v2\n""}, {'number': 4, 'created': '2017-02-09 05:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6fbe036035efa5f6e6f250fd00c9f434dc252a9b', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nPartially-Implements: bp/pub-sub-v2\n'}, {'number': 5, 'created': '2017-02-13 05:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d72cc11ce39447a364f31118b37a4255318b13a0', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nPartially-Implements: bp/pub-sub-v2\n'}, {'number': 6, 'created': '2017-02-15 01:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5ab88a0aaff6c4fea0e07eaf56fbbc55f17b64bd', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nPartially-Implements: bp/pub-sub-v2\n'}, {'number': 7, 'created': '2017-02-15 10:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a75a160bb08411d7a780c783d31e23928c19e5d6', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 8, 'created': '2017-02-16 03:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/aef0112b949890348b3df5420c5806d139deb68d', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 9, 'created': '2017-02-16 03:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/52360c4a121552a6845100f6a8b526e33c8c960b', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 10, 'created': '2017-02-16 03:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/74e75ae1fcf6a62a63f6b6cb41b347cc80191944', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 11, 'created': '2017-02-20 12:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5a2ca27b2ce2499cc3b94c87026bea9dd18eb0d0', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 12, 'created': '2017-02-24 16:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0fdbc7aae3538f503ae903f83d7225de11042f44', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}, {'number': 13, 'created': '2017-02-24 16:21:47.000000000', 'files': ['doc/source/specs/index.rst', 'doc/source/specs/publish_subscribe_v2.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/45dbb6a741632a71073a3e53d9739a8edd86d384', 'message': 'Propose a pub/sub refactor\n\nThis blueprint implements publisher for df-local-controller\nand also brings some refactor work for application usage.\n\nChange-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca\nImplements: blueprint pub-sub-v2\n'}]",18,425619,45dbb6a741632a71073a3e53d9739a8edd86d384,62,7,13,7805,,,0,"Propose a pub/sub refactor

This blueprint implements publisher for df-local-controller
and also brings some refactor work for application usage.

Change-Id: I8c9aa74e9d393816612a45306f9c6f4d43b943ca
Implements: blueprint pub-sub-v2
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/19/425619/11 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specs/publish_subscribe_v2.rst'],1,f87eaf9c696d56faca8dd31b4fc785d050bf40cb,bp/pub-sub-v2,"================================ Publisher Subscriber Refactor v2 ================================ https://blueprints.launchpad.net/dragonflow/+spec/pub-sub-v2 This spec is to refactor the pub-sub mechanism to implement publisher in df-local-controller. Problem Description =================== Currently pub/sub mechanism doesn't work in the following scenario: When enabling port-status driver or automatic port detection for allow-address-pair, the zeromq pub/sub driver doesn't work. Because these two applications require the df-local-controller run publishers. It brings socket bind conflicts when running two publishers on the same host (one is df-local-controller, the other is df-publisher-service). If you deploy with redis driver, everything will be well. Because redis-based pub/sub mechansim doesn't require socket binding. This bug is dedicated to zeromq based driver and was reported earlier [1]. Moreover this superficial problem will lead to the rest of the mess. * The port-status driver's name is redis-based, but the implementation doesn't have anything to do with redis nb db driver. This driver is possible to be the generic one. The gap is that it requires df-local-controller run publisher and neutron-server run subscriber. * The auto-port-detection app also requires df-local-controller run publisher. But I cannot find any codes that implement the corresponding subscriber. I doult its functionality. [FIXME] * We set up publisher port in the common [df] section in the configuration. When we run both df-local-controller and df-publisher-service, they read the same option to initialize and we don't have the chance to specify different port for these services. * The publisher run on the df-local-controller doesn't register itself to nb db. Because the registration is implemented in df-publisher-service, not in publisher driver. As a result, the corresponding subscriber cannot connect to it via dynamic registration. Instead it only connects publishers set up in the configuration, aka publisher_ips. By default, publisher_ips contains the local host ip address. So, when you deploy in multi-node, the subscriber will not be able to connect to other publishers. * We implement dynamic registration for df-publisher-service and we also keep the old publisher_ips in configuration which leads double registration. * We initialize publisher and subscriber in api_nb module and determine multiproc by is_neutron_server flag. This is not flexible as we need to modify the internal states of api_nb to decide which publisher or subscriber to use. The fix of this bug is simple, but it is also a good chance to revisit pub/sub mechanism. Proposed Change =============== One of the solution for this bug is to try to enable multiproc publisher in df-local-controller when it runs with df-publisher-service. As a result, both neutron-server and df-local-controller will publish events via ipc to df-publisher-service and let it distribute event to where the subscriber locates. It is the fast path but it still hides the potential problems. The other solution for this bug is to try to refactor the pub/sub to fix all the issues discussed above one by one. Configuration Impact -------------------- [neutron] publisher_port = 8898 publisher_binding_address = * multiproc_publisher = True/False multiproc_subscriber = True/False [df_local_controller] publisher_port = 8899 publisher_binding_address = * multiproc_publisher = True/False multiproc_subscriber = True/False API_NB Impact ------------- * Add constants for role definition, ROLE_NEUTRON_SERVER and ROLE_DF_LOCAL_CONTROLLER. * Pass one of the role constant when initializing api_nb and remove the is_neutron_server_flag. * Check each role and apply different options according to the above section:: if role == ROLE_NEUTRON_SERVER: read pub/sub options from [neutron-server] section else role == ROLE_DF_LOCAL_CONTROLLER: read pub/sub options from [df_local_controller] section Publisher Subscriber Impact --------------------------- * Remove publisher_ips option and logic. * Move publisher registration codes from df-publisher-service to driver. When initializing publisher, it will auto-register itself to nb db, along with its role definition. * When subscriber read nb db, it will filter the role in order to register to the right publishers. Other Impact ------------ * Make port-status driver work for all the db drivers. * Make auto port detection work for all the db drivers. Implementation ============== Assignee(s) ----------- Primary assignee: `nick-ma-z <https://launchpad.net/~nick-ma-z>`_ References ========== [1] https://bugs.launchpad.net/dragonflow/+bug/1651643 ",,135,0
openstack%2Fneutron~master~I38e0a5f4c361435ae4af6c16a407191b1e722e37,openstack/neutron,master,I38e0a5f4c361435ae4af6c16a407191b1e722e37,Prevent double-subscribes with registry decorator,MERGED,2017-02-27 13:19:57.000000000,2017-02-28 10:34:29.000000000,2017-02-28 10:34:28.000000000,"[{'_account_id': 3}, {'_account_id': 5948}, {'_account_id': 6854}]","[{'number': 1, 'created': '2017-02-27 13:19:57.000000000', 'files': ['neutron/callbacks/registry.py', 'neutron/tests/unit/callbacks/test_registry.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/92116a0cc935160ad6006c60c549b8a257142397', 'message': ""Prevent double-subscribes with registry decorator\n\nThis adds a simple flag to object instances to avoid multiple calls\nto 'subscribe' for a class with multiple children that use the\n'has_registry_receivers' decorator.\n\nThe registry manager protects from multiple subscriptions of the\nsame function by storing callbacks based on IDs, but this is necessary\nto eliminate the duplicate debug logging statements.\n\nChange-Id: I38e0a5f4c361435ae4af6c16a407191b1e722e37\n""}]",0,438488,92116a0cc935160ad6006c60c549b8a257142397,20,3,1,7787,,,0,"Prevent double-subscribes with registry decorator

This adds a simple flag to object instances to avoid multiple calls
to 'subscribe' for a class with multiple children that use the
'has_registry_receivers' decorator.

The registry manager protects from multiple subscriptions of the
same function by storing callbacks based on IDs, but this is necessary
to eliminate the duplicate debug logging statements.

Change-Id: I38e0a5f4c361435ae4af6c16a407191b1e722e37
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/438488/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/callbacks/registry.py', 'neutron/tests/unit/callbacks/test_registry.py']",2,92116a0cc935160ad6006c60c549b8a257142397,,"import mock @registry.has_registry_receivers class AnotherObjectWithDecoratedCallback(ObjectWithDecoratedCallback): def __init__(self): super(AnotherObjectWithDecoratedCallback, self).__init__() self.counter2 = 0 @registry.receives(resources.NETWORK, [events.AFTER_DELETE]) def callback2(self, *args, **kwargs): self.counter2 += 1 def test_object_inheriting_others_no_double_subscribe(self): with mock.patch.object(registry, 'subscribe') as sub: AnotherObjectWithDecoratedCallback() # there are 3 methods (2 in parent and one in child) and 1 # subscribes to 2 events, so we expect 4 subscribes self.assertEqual(4, len(sub.mock_calls))",,27,0
openstack%2Ftempest~master~Ic3676973b52630cca2c7edd396bcba828f21d08f,openstack/tempest,master,Ic3676973b52630cca2c7edd396bcba828f21d08f,Domain specific roles API tests,MERGED,2017-01-27 14:30:53.000000000,2017-02-28 10:34:22.000000000,2017-02-28 10:34:22.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 11022}, {'_account_id': 12017}]","[{'number': 1, 'created': '2017-01-27 14:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c49f18e0abee3eb90364acb59f097ed1fd920c8', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 2, 'created': '2017-01-27 14:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/811cbae44c9f23a87ddb247ac2fc1bda78a7ca5f', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 3, 'created': '2017-01-30 12:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e17b510a49dd8bdfd5d40b2ddccc1b9f650f28cc', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 4, 'created': '2017-01-30 18:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e71446d87bfbc7c6b965b2086d35a9045ea1a9e', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 5, 'created': '2017-01-31 10:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff8bb6402071f6d403081b136eba80bb43bb09d9', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 6, 'created': '2017-01-31 18:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c8d79c8f7ad54a9acf02f91b4708de7b9ebcfcad', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 7, 'created': '2017-02-02 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e1fd63e219f071f0a227bfc071a75d7f1330416e', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 8, 'created': '2017-02-03 13:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/142e641180bb2560fd8f784c886c1ef00ee570e5', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 9, 'created': '2017-02-03 23:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d7fdd212d0b326fa8574304305c8d7f218e3b02a', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 10, 'created': '2017-02-03 23:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/29c50c7adc0d59f12c6a290463cc489cb54b6ffd', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 11, 'created': '2017-02-04 15:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fe870a4c33f7b80f55e7094bb449b6a5c46c6e07', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 12, 'created': '2017-02-07 13:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f417c1b7d8f3efaae42e08c4fcd4c05377924331', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 13, 'created': '2017-02-10 21:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a77069872169307f2218ff923492b8dc94521457', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}, {'number': 14, 'created': '2017-02-11 12:45:23.000000000', 'files': ['tempest/api/identity/admin/v3/test_roles.py', 'tempest/api/identity/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/34a6512b77d2264dc8c911fb0af6060c605eb91f', 'message': 'Domain specific roles API tests\n\nThis patch adds the API tests for the domain specific roles feature.\n\nThis feature provides the power to have more granularity in defining the\nroles (and implied roles rules) within the same cloud provider, this is\naccomplished by allowing the roles to be handled (scoped) in the domain\nlevel. For the ""implied roles"" use case, a domain specific role can be\nused in the same way as a ""global"" role - the difference is that we\ncan\'t have a global role implying a domain specific one.\n\nAnother limitation is that domain specific roles can\'t be used to scope\na token - they don\'t have an effective power when used in an assignment.\n\nChange-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f\n'}]",9,426249,34a6512b77d2264dc8c911fb0af6060c605eb91f,72,8,14,11022,,,0,"Domain specific roles API tests

This patch adds the API tests for the domain specific roles feature.

This feature provides the power to have more granularity in defining the
roles (and implied roles rules) within the same cloud provider, this is
accomplished by allowing the roles to be handled (scoped) in the domain
level. For the ""implied roles"" use case, a domain specific role can be
used in the same way as a ""global"" role - the difference is that we
can't have a global role implying a domain specific one.

Another limitation is that domain specific roles can't be used to scope
a token - they don't have an effective power when used in an assignment.

Change-Id: Ic3676973b52630cca2c7edd396bcba828f21d08f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/426249/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_roles.py'],1,6c49f18e0abee3eb90364acb59f097ed1fd920c8,implied_roles," @test.idempotent_id('d92a41d2-5501-497a-84bb-6e294330e8f8') def test_domain_roles_create_delete(self): domain_role = self.roles_client.create_role( name=data_utils.rand_name('domain_role'), domain_id=self.domain['id'])['role'] domain_roles = self.roles_client.list_roles( domain_id=self.domain['id'])['roles'] self.assertEqual(1, len(domain_roles)) self.assertIn(domain_role, domain_roles) self.roles_client.delete_role(domain_role['id']) domain_roles = self.roles_client.list_roles( domain_id=self.domain['id'])['roles'] self.assertEqual(0, len(domain_roles)) @test.idempotent_id('eb1e1c24-1bc4-4d47-9748-e127a1852c82') def test_implied_domain_roles(self): # Create two roles in the same domain domain_role1 = self.roles_client.create_role( name=data_utils.rand_name('domain_role'), domain_id=self.domain['id'])['role'] self.addCleanup(self.roles_client.delete_role, domain_role1['id']) domain_role2 = self.roles_client.create_role( name=data_utils.rand_name('domain_role'), domain_id=self.domain['id'])['role'] self.addCleanup(self.roles_client.delete_role, domain_role2['id']) # Check if we can create an inference rule from roles in the same # domain self.roles_client.create_role_inference_rule( domain_role1['id'], domain_role2['id']) self.addCleanup(self.roles_client.delete_role_inference_rule, domain_role1['id'], domain_role2['id']) # Create another role in a different domain domain2 = self.domains_client.create_domain( name=data_utils.rand_name('domain'))['domain'] self.addCleanup(self.domains_client.delete_domain, domain2['id']) self.addCleanup(self.domains_client.update_domain, domain2['id'], enabled=False) domain_role3 = self.roles_client.create_role( name=data_utils.rand_name('domain_role'), domain_id=domain2['id'])['role'] self.addCleanup(self.roles_client.delete_role, domain_role3['id']) # Check if we can create cross domain implied roles self.roles_client.create_role_inference_rule( domain_role1['id'], domain_role3['id']) self.addCleanup(self.roles_client.delete_role_inference_rule, domain_role1['id'], domain_role3['id']) # Finally, we also should be able to create an implied from a # domain role to a global one self.roles_client.create_role_inference_rule( domain_role1['id'], self.role['id']) self.addCleanup(self.roles_client.delete_role_inference_rule, domain_role1['id'], self.role['id']) # The contrary is not true: we can't create an inference rule # from a global role to a domain role self.assertRaises( lib_exc.Forbidden, self.roles_client.create_role_inference_rule, self.role['id'], domain_role1['id']) @test.idempotent_id('3859df7e-5b78-4e4d-b10e-214c8953842a') def test_assignments_for_domain_roles(self): domain_role = self.roles_client.create_role( name=data_utils.rand_name('domain_role'), domain_id=self.domain['id'])['role'] self.addCleanup(self.roles_client.delete_role, domain_role['id']) # Create a grant using ""roles[0]"" self.roles_client.create_user_role_on_project( self.project['id'], self.user_body['id'], domain_role['id']) self.addCleanup( self.roles_client.delete_role_from_user_on_project, self.project['id'], self.user_body['id'], domain_role['id']) # In the effective list of role assignments we should not see # the assignment with the domain role params = {'scope.project.id': self.project['id'], 'user.id': self.user_body['id']} role_assignments = self.role_assignments.list_role_assignments( effective=True, **params)['role_assignments'] self.assertEqual(0, len(role_assignments))",,91,0
openstack%2Ftempest~master~I42e528b3b9954aa28f6dfab3967c485f18638d4a,openstack/tempest,master,I42e528b3b9954aa28f6dfab3967c485f18638d4a,Use base.create_flavor in test_flavors_access,MERGED,2017-02-13 08:32:21.000000000,2017-02-28 10:31:42.000000000,2017-02-28 10:31:42.000000000,"[{'_account_id': 3}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 20190}, {'_account_id': 23184}]","[{'number': 1, 'created': '2017-02-13 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/12fbd1a32edfc7dc77b765492485e65921e4be87', 'message': 'Use base.create_flavor in test_flavors_access\n\nThe multi-lines of create_flavor can be replaced\nby one call to base.create_flavor, so that the code\nlooks simpler.\n\nChange-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a\n'}, {'number': 2, 'created': '2017-02-15 01:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/44d83c7369bb8d99dd9fe3714fb3e8b370348699', 'message': 'Use base.create_flavor in test_flavors_access\n\nThe multi-lines of create_flavor can be replaced\nby one call to base.create_flavor, so that the code\nlooks simpler.\n\nChange-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a\n'}, {'number': 3, 'created': '2017-02-15 01:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf68ace5bc949e7ef2143cdaa80a3113188afb3f', 'message': 'Use base.create_flavor in test_flavors_access\n\nThe multi-lines of create_flavor can be replaced\nby one call to base.create_flavor, so that the code\nlooks simpler.\n\nChange-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a\n'}, {'number': 4, 'created': '2017-02-23 03:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a139c37571f05130f4362cdc0c86c364e3cb0303', 'message': 'Use base.create_flavor in test_flavors_access\n\nThe multi-lines of create_flavor can be replaced\nby one call to base.create_flavor, so that the code\nlooks simpler.\n\nChange-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a\n'}, {'number': 5, 'created': '2017-02-24 02:55:48.000000000', 'files': ['tempest/api/compute/admin/test_flavors_access_negative.py', 'tempest/api/compute/admin/test_flavors_access.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1157b4bfce4d6a5450d4a73eff55639c87d16713', 'message': 'Use base.create_flavor in test_flavors_access\n\nThe multi-lines of create_flavor can be replaced\nby one call to base.create_flavor, so that the code\nlooks simpler.\n\nChange-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a\n'}]",0,432914,1157b4bfce4d6a5450d4a73eff55639c87d16713,39,7,5,20190,,,0,"Use base.create_flavor in test_flavors_access

The multi-lines of create_flavor can be replaced
by one call to base.create_flavor, so that the code
looks simpler.

Change-Id: I42e528b3b9954aa28f6dfab3967c485f18638d4a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/14/432914/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/admin/test_flavors_access_negative.py', 'tempest/api/compute/admin/test_flavors_access.py']",2,12fbd1a32edfc7dc77b765492485e65921e4be87,use_create_flavor," flavor = self.create_flavor(ram=self.ram, vcpus=self.vcpus, disk=self.disk, is_public='False') flavor_access = (self.client.list_flavor_access(flavor['id']) flavor = self.create_flavor(ram=self.ram, vcpus=self.vcpus, disk=self.disk, is_public='False') ""flavor_id"": str(flavor['id']), } add_body = (self.client.add_flavor_access(flavor['id'], self.assertIn(flavor['id'], map(lambda x: x['id'], flavors)) remove_body = (self.client.remove_flavor_access(flavor['id'], self.assertNotIn(flavor['id'], map(lambda x: x['id'], flavors))","from tempest.common.utils import data_utils flavor_name = data_utils.rand_name(self.flavor_name_prefix) new_flavor_id = data_utils.rand_int_id(start=1000) new_flavor = self.client.create_flavor(name=flavor_name, ram=self.ram, vcpus=self.vcpus, disk=self.disk, id=new_flavor_id, is_public='False')['flavor'] self.addCleanup(self.client.delete_flavor, new_flavor['id']) flavor_access = (self.client.list_flavor_access(new_flavor_id) flavor_name = data_utils.rand_name(self.flavor_name_prefix) new_flavor_id = data_utils.rand_int_id(start=1000) new_flavor = self.client.create_flavor(name=flavor_name, ram=self.ram, vcpus=self.vcpus, disk=self.disk, id=new_flavor_id, is_public='False')['flavor'] self.addCleanup(self.client.delete_flavor, new_flavor['id']) ""flavor_id"": str(new_flavor['id']), } add_body = (self.client.add_flavor_access(new_flavor['id'], self.assertIn(new_flavor['id'], map(lambda x: x['id'], flavors)) remove_body = (self.client.remove_flavor_access(new_flavor['id'], self.assertNotIn(new_flavor['id'], map(lambda x: x['id'], flavors))",32,72
openstack%2Ffuel-qa~master~I5996520ded3419fd2ce2cb1e76056eed157bfffb,openstack/fuel-qa,master,I5996520ded3419fd2ce2cb1e76056eed157bfffb,remove vmware,MERGED,2017-02-14 14:53:33.000000000,2017-02-28 10:29:49.000000000,2017-02-28 10:21:24.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 12199}, {'_account_id': 14057}, {'_account_id': 15921}, {'_account_id': 15984}, {'_account_id': 16044}, {'_account_id': 16106}, {'_account_id': 19119}, {'_account_id': 20120}]","[{'number': 1, 'created': '2017-02-14 14:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/684152565877fb76c24c2c81159c3b8fb8f6de63', 'message': 'remove vmware\n\nVMware not supported since Fuel 10. So we should stop test it.\n\nChange-Id: I5996520ded3419fd2ce2cb1e76056eed157bfffb\nImplements: blueprint remove-vmware\n'}, {'number': 2, 'created': '2017-02-14 15:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/85a5ad24ea0ffb37d0e6caa3f929ac793a6f9fbb', 'message': 'remove vmware\n\nVMware not supported since Fuel 10. So we should stop test it.\n\nChange-Id: I5996520ded3419fd2ce2cb1e76056eed157bfffb\nImplements: blueprint remove-vmware\n'}, {'number': 3, 'created': '2017-02-15 08:04:07.000000000', 'files': ['fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/cluster_settings.yaml', 'doc/base_tests.rst', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/idempotency/controller.yaml', 'system_test/actions/base.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_cinder_and_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cluster_to_ctrl.yaml', 'fuelweb_test/settings.py', 'packages_tests/rpm/packages.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceilometer.yaml', 'system_test/tests/vcenter/test_vcenter_dvs.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend.yaml', 'packages_tests/deb/packages.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_smoke.yaml', 'system_test/tests/vcenter/test_vcenter_failover.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_ctrl_to_compute.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_vmware_roles.yaml', 'fuelweb_test/helpers/utils.py', 'system_test/tests/vcenter/test_vcenter_cluster_actions.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceph_and_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cluster_settings.yaml', 'doc/system_tests.rst', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_shutdown_cvm.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vmware_roles_local_ds.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs/dvs_1cluster.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/idempotency/primary-controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vmware_roles_pub_ip.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_cindervmdk_and_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/idempotency/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/idempotency/controller.yaml', 'gates_tests/helpers/fuel_library_modules_mapping.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/ensurability/controller.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_computevmware_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/idempotency/controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_ifaces.yaml', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/cluster_settings.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_compute_to_compute.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceilometer_and_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_vmware_roles.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_controller.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs/dvs_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_computevmware.yaml', 'fuelweb_test/tests/test_vcenter.py', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/primary-controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_failover.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_compute_to_ctrl.yaml', 'fuelweb_test/tests/tests_lcm/test_task_coverage.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_ceilometer.yaml', 'system_test/actions/vcenter_actions.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_cinder.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_bvt.yaml', 'system_test/tests/vcenter/__init__.py', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/cluster_settings.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_ctrl.yaml', 'system_test/actions/__init__.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_multiple_clusters.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_glance.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_ceph.yaml', 'fuelweb_test/models/nailgun_client.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_reboot_cvm.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/idempotency/controller.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a0838e91a9dc9a996b03ba293396d93e4f2ee788', 'message': 'remove vmware\n\nVMware not supported since Fuel 10. So we should stop test it.\n\nChange-Id: I5996520ded3419fd2ce2cb1e76056eed157bfffb\nImplements: blueprint remove-vmware\n'}]",2,433686,a0838e91a9dc9a996b03ba293396d93e4f2ee788,23,11,3,12199,,,0,"remove vmware

VMware not supported since Fuel 10. So we should stop test it.

Change-Id: I5996520ded3419fd2ce2cb1e76056eed157bfffb
Implements: blueprint remove-vmware
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/86/433686/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/cluster_settings.yaml', 'doc/base_tests.rst', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/idempotency/controller.yaml', 'system_test/actions/base.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_cinder_and_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cluster_to_ctrl.yaml', 'fuelweb_test/settings.py', 'packages_tests/rpm/packages.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceilometer.yaml', 'system_test/tests/vcenter/test_vcenter_dvs.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend.yaml', 'packages_tests/deb/packages.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_smoke.yaml', 'system_test/tests/vcenter/test_vcenter_failover.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_ctrl_to_compute.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_vmware_roles.yaml', 'fuelweb_test/helpers/utils.py', 'system_test/tests/vcenter/test_vcenter_cluster_actions.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceph_and_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/cluster_settings.yaml', 'doc/system_tests.rst', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_shutdown_cvm.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vmware_roles_local_ds.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs/dvs_1cluster.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/idempotency/primary-controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vmware_roles_pub_ip.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_3_ceph/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_cindervmdk_and_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/idempotency/controller.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/idempotency/controller.yaml', 'gates_tests/helpers/fuel_library_modules_mapping.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/ensurability/controller.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_computevmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_cinder/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_computevmware_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/idempotency/controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_ifaces.yaml', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/cluster_settings.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_compute_to_compute.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceilometer_and_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_vmware_roles.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_controller.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs/dvs_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_computevmware.yaml', 'fuelweb_test/tests/test_vcenter.py', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_delete_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/primary-controller_mongo.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_failover.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_mv_cluster_compute_to_ctrl.yaml', 'fuelweb_test/tests/tests_lcm/test_task_coverage.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_ceilometer.yaml', 'system_test/actions/vcenter_actions.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_cinder.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_bvt.yaml', 'system_test/tests/vcenter/__init__.py', 'fuelweb_test/tests/tests_lcm/fixtures/3_ctrl_3_cmp_ceph_sahara/ensurability/cluster_settings.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_ctrl.yaml', 'system_test/actions/__init__.py', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/ensurability/cluster_settings.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_mongo/ensurability/controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_multiple_clusters.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_glance.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_ceph.yaml', 'fuelweb_test/models/nailgun_client.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_reboot_cvm.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cindervmware.yaml', 'fuelweb_test/tests/tests_lcm/fixtures/1_ctrl_1_cmp_1_ironic/idempotency/controller.yaml']",78,684152565877fb76c24c2c81159c3b8fb8f6de63,bp/remove-vmware,, - vmware-vcenter: no_puppet_run: true - vcenter_compute_zones_create: type: shell,5,5718
openstack%2Fironic~master~Icd61bbbdc0f0633a93adef89652d54a87d835534,openstack/ironic,master,Icd61bbbdc0f0633a93adef89652d54a87d835534,Fix BaseBaremetalTest._assertExpected docstring,MERGED,2017-02-27 15:49:18.000000000,2017-02-28 10:28:11.000000000,2017-02-28 10:28:11.000000000,"[{'_account_id': 3}, {'_account_id': 14525}, {'_account_id': 14760}]","[{'number': 1, 'created': '2017-02-27 15:49:18.000000000', 'files': ['ironic_tempest_plugin/tests/api/admin/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c10a7dfd10f3a37dd9e218e480291024df3fe1a3', 'message': ""Fix BaseBaremetalTest._assertExpected docstring\n\nThis updates the docstring for tempest plugin's\nBaseBaremetalTest._assertExpected() so that it clarifies\nwhat it is doing and what the parameters are.\n\nChange-Id: Icd61bbbdc0f0633a93adef89652d54a87d835534\n""}]",0,438569,c10a7dfd10f3a37dd9e218e480291024df3fe1a3,11,3,1,6618,,,0,"Fix BaseBaremetalTest._assertExpected docstring

This updates the docstring for tempest plugin's
BaseBaremetalTest._assertExpected() so that it clarifies
what it is doing and what the parameters are.

Change-Id: Icd61bbbdc0f0633a93adef89652d54a87d835534
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/438569/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/tests/api/admin/base.py'],1,c10a7dfd10f3a37dd9e218e480291024df3fe1a3,assertExpected," """"""Check if expected keys/values exist in actual response body. Check if the expected keys and values are in the actual response body. It will not check the keys 'created_at' and 'updated_at', since they will always have different values. Asserts if any expected key (or corresponding value) is not in the actual response. Note: this method has an underscore even though it is used outside of this class, in order to distinguish this method from the more standard assertXYZ methods. :param expected: dict of key-value pairs that are expected to be in 'actual' dict. :param actual: dict of key-value pairs. """""""," """"""Check if not expected keys/values exist in actual response body.""""""",16,1
openstack%2Fos-win~stable%2Focata~Iec9b501880098e69be652bf6c2a90a9864e52a9c,openstack/os-win,stable/ocata,Iec9b501880098e69be652bf6c2a90a9864e52a9c,vmutils: Adds vnuma_enabled argument to update_vm,MERGED,2017-02-27 08:40:10.000000000,2017-02-28 10:16:56.000000000,2017-02-28 10:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-02-27 08:40:10.000000000', 'files': ['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/d1803fa4ceb92deb794fff55180ba7f486486c73', 'message': 'vmutils: Adds vnuma_enabled argument to update_vm\n\nA VM can have its virtual NUMA spanning turned on and off.\n\nPartial-Bug: #1663238\n\nChange-Id: Iec9b501880098e69be652bf6c2a90a9864e52a9c\n(cherry picked from commit d440793e0b074084c7a9604996ee0ee3b07a300b)\n'}]",0,438371,d1803fa4ceb92deb794fff55180ba7f486486c73,11,2,1,8213,,,0,"vmutils: Adds vnuma_enabled argument to update_vm

A VM can have its virtual NUMA spanning turned on and off.

Partial-Bug: #1663238

Change-Id: Iec9b501880098e69be652bf6c2a90a9864e52a9c
(cherry picked from commit d440793e0b074084c7a9604996ee0ee3b07a300b)
",git fetch https://review.opendev.org/openstack/os-win refs/changes/71/438371/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py']",2,d1803fa4ceb92deb794fff55180ba7f486486c73,bug/1663238," host_shutdown_action=None, vnuma_enabled=None, if vnuma_enabled is not None: vmsetting.VirtualNumaEnabled = vnuma_enabled update_needed = (configuration_root_dir or host_shutdown_action or vnuma_enabled is not None) "," host_shutdown_action=None, update_needed = configuration_root_dir or host_shutdown_action",14,5
openstack%2Fos-win~stable%2Focata~Ib83bbc5c7fd07b55888f58d3407e1dd1a50e9b7e,openstack/os-win,stable/ocata,Ib83bbc5c7fd07b55888f58d3407e1dd1a50e9b7e,vmutils: Allows updating and disabling instance RemoteFX,MERGED,2017-02-27 08:40:10.000000000,2017-02-28 10:16:51.000000000,2017-02-28 10:16:51.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-02-27 08:40:10.000000000', 'files': ['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/tests/unit/utils/compute/test_vmutils10.py', 'os_win/utils/compute/vmutils10.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/3c7d3b732dc282e92383834ce534802c9da33965', 'message': ""vmutils: Allows updating and disabling instance RemoteFX\n\nWhen resizing an instance, if it was imported, its resources\nneeds to be updated according to the new flavor. If a flavor\nhas different RemoteFX requirements, os_win should allow updates\nto the instance's RemoteFX configuration.\n\nChange-Id: Ib83bbc5c7fd07b55888f58d3407e1dd1a50e9b7e\nPartial-Bug: #1663238\n(cherry picked from commit ac07fcd78b39b9aa1bda1734c774d2a6dc8e2691)\n""}]",0,438370,3c7d3b732dc282e92383834ce534802c9da33965,11,2,1,8213,,,0,"vmutils: Allows updating and disabling instance RemoteFX

When resizing an instance, if it was imported, its resources
needs to be updated according to the new flavor. If a flavor
has different RemoteFX requirements, os_win should allow updates
to the instance's RemoteFX configuration.

Change-Id: Ib83bbc5c7fd07b55888f58d3407e1dd1a50e9b7e
Partial-Bug: #1663238
(cherry picked from commit ac07fcd78b39b9aa1bda1734c774d2a6dc8e2691)
",git fetch https://review.opendev.org/openstack/os-win refs/changes/70/438370/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/tests/unit/utils/compute/test_vmutils10.py', 'os_win/utils/compute/vmutils.py', 'os_win/utils/compute/vmutils10.py']",4,3c7d3b732dc282e92383834ce534802c9da33965,bug/1663238,"import six if vram_bytes and vram_bytes not in self._remotefx_vram_vals: def _set_remotefx_vram(self, remotefx_disp_ctrl_res, vram_bytes): if vram_bytes: remotefx_disp_ctrl_res.VRAMSizeBytes = six.text_type(vram_bytes)"," if vram_bytes not in self._remotefx_vram_vals: def _add_3d_display_controller(self, vm, monitor_count, max_resolution, vram_bytes=None): synth_3d_disp_ctrl_res = self._get_new_resource_setting_data( self._SYNTH_3D_DISP_CTRL_RES_SUB_TYPE, self._SYNTH_3D_DISP_ALLOCATION_SETTING_DATA_CLASS) synth_3d_disp_ctrl_res.MaximumMonitors = monitor_count synth_3d_disp_ctrl_res.MaximumScreenResolution = max_resolution if vram_bytes: synth_3d_disp_ctrl_res.VRAMSizeBytes = unicode(vram_bytes) self._jobutils.add_virt_resource(synth_3d_disp_ctrl_res, vm)",166,49
openstack%2Fos-win~stable%2Focata~Ia7fbb2a9bc8f5d21bf5ec4a865fc7b1368ecf136,openstack/os-win,stable/ocata,Ia7fbb2a9bc8f5d21bf5ec4a865fc7b1368ecf136,vmutils: Adds remove_all_pci_devices method,MERGED,2017-02-27 08:40:10.000000000,2017-02-28 10:16:45.000000000,2017-02-28 10:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-02-27 08:40:10.000000000', 'files': ['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/tests/unit/utils/compute/test_vmutils10.py', 'os_win/utils/compute/vmutils10.py', 'os_win/utils/jobutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/e0e92d00995e68a3844ce9e1c71f37f0e7f3b656', 'message': ""vmutils: Adds remove_all_pci_devices method\n\nWhen resizing an imported VM, nova does not specify which\nPCI devices needs to be attached and which needs to be detached.\nThus, all the VM's PCI devices needs to be detached, and reattached\naccording to the new PCI request.\n\nChange-Id: Ia7fbb2a9bc8f5d21bf5ec4a865fc7b1368ecf136\nPartial-Bug: #1663238\n(cherry picked from commit a1bc0e3aec4c11fe72804c1b718928cf6a65ef34)\n""}]",0,438369,e0e92d00995e68a3844ce9e1c71f37f0e7f3b656,11,2,1,8213,,,0,"vmutils: Adds remove_all_pci_devices method

When resizing an imported VM, nova does not specify which
PCI devices needs to be attached and which needs to be detached.
Thus, all the VM's PCI devices needs to be detached, and reattached
according to the new PCI request.

Change-Id: Ia7fbb2a9bc8f5d21bf5ec4a865fc7b1368ecf136
Partial-Bug: #1663238
(cherry picked from commit a1bc0e3aec4c11fe72804c1b718928cf6a65ef34)
",git fetch https://review.opendev.org/openstack/os-win refs/changes/69/438369/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/tests/unit/utils/compute/test_vmutils10.py', 'os_win/utils/compute/vmutils.py', 'os_win/utils/compute/vmutils10.py', 'os_win/utils/jobutils.py']",5,e0e92d00995e68a3844ce9e1c71f37f0e7f3b656,bug/1663238," def remove_virt_resource(self, virt_resource): self.remove_multiple_virt_resources([virt_resource]) @_utils.retry_decorator(exceptions=exceptions.HyperVException) def remove_multiple_virt_resources(self, virt_resources): ResourceSettings=[r.path_() for r in virt_resources])"," @_utils.retry_decorator(exceptions=exceptions.HyperVException) def remove_virt_resource(self, virt_resource): ResourceSettings=[virt_resource.path_()])",48,2
openstack%2Fos-win~stable%2Focata~Ic153dcfd621a1e6235dd3a75241274ee7d7c868b,openstack/os-win,stable/ocata,Ic153dcfd621a1e6235dd3a75241274ee7d7c868b,removes the VirtualSystemType kwarg when fetching VMs,MERGED,2017-02-27 08:40:10.000000000,2017-02-28 10:15:58.000000000,2017-02-28 10:15:58.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-02-27 08:40:10.000000000', 'files': ['os_win/utils/metrics/metricsutils.py', 'os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/tests/unit/utils/metrics/test_metricsutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/21cb88cfc03626d36678714ebd26ea449f1e7fe1', 'message': 'removes the VirtualSystemType kwarg when fetching VMs\n\nA VM can be either ""Realized"" or ""Planned"", but not both. Thus,\nusing the VirtualSystemType as a filter is not useful.\n\nBecause of this, the ""is_planned_vm"" argument from vmutils\nmethods will no longer be unused, and will be removed once it is\nno longer used.\n\nThis will make vmutils easier to use for Planned VMs, which will\nbe used for cold migration in the future. Plus, not all vmutils\nmethods have the ""is_planned_vm"" argument, which would have been\nnecessary in order to update the Planned VM (e.g.: get_vm_config_dir method).\n\nPartial-Bug: #1663238\n\nChange-Id: Ic153dcfd621a1e6235dd3a75241274ee7d7c868b\n(cherry picked from commit 6c5d895ba4984464e1e11a4fcd6e83d82a3d6893)\n'}]",0,438368,21cb88cfc03626d36678714ebd26ea449f1e7fe1,11,2,1,8213,,,0,"removes the VirtualSystemType kwarg when fetching VMs

A VM can be either ""Realized"" or ""Planned"", but not both. Thus,
using the VirtualSystemType as a filter is not useful.

Because of this, the ""is_planned_vm"" argument from vmutils
methods will no longer be unused, and will be removed once it is
no longer used.

This will make vmutils easier to use for Planned VMs, which will
be used for cold migration in the future. Plus, not all vmutils
methods have the ""is_planned_vm"" argument, which would have been
necessary in order to update the Planned VM (e.g.: get_vm_config_dir method).

Partial-Bug: #1663238

Change-Id: Ic153dcfd621a1e6235dd3a75241274ee7d7c868b
(cherry picked from commit 6c5d895ba4984464e1e11a4fcd6e83d82a3d6893)
",git fetch https://review.opendev.org/openstack/os-win refs/changes/68/438368/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/utils/metrics/metricsutils.py', 'os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/tests/unit/utils/metrics/test_metricsutils.py']",4,21cb88cfc03626d36678714ebd26ea449f1e7fe1,bug/1663238, conn_class.assert_called_once_with(ElementName=mock.sentinel.vm_name)," conn_class.assert_called_once_with( ElementName=mock.sentinel.vm_name, VirtualSystemType=self.utils._VIRTUAL_SYSTEM_TYPE_REALIZED)",37,84
openstack%2Fpuppet-neutron~stable%2Focata~Ie4f2e75ec05af39c8b9db4aea98ba5127bcf4277,openstack/puppet-neutron,stable/ocata,Ie4f2e75ec05af39c8b9db4aea98ba5127bcf4277,Added user_domain_name and project_domain_name for nova notifications,MERGED,2017-02-27 11:23:03.000000000,2017-02-28 10:13:13.000000000,2017-02-28 09:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 7745}, {'_account_id': 11583}, {'_account_id': 15519}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-27 11:23:03.000000000', 'files': ['spec/classes/neutron_server_notifications_spec.rb', 'manifests/server/notifications.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8a88e47ba6264a38a32f851f08b86286e4debb5a', 'message': 'Added user_domain_name and project_domain_name for nova notifications\n\nA few parameters missed in neutron::server::notifications and\nthere were configured with default params.\n\nChange-Id: Ie4f2e75ec05af39c8b9db4aea98ba5127bcf4277\n(cherry picked from commit I642fec707a669a724961dd0dd900d28522b8f869)\n'}]",0,438446,8a88e47ba6264a38a32f851f08b86286e4debb5a,15,7,1,20676,,,0,"Added user_domain_name and project_domain_name for nova notifications

A few parameters missed in neutron::server::notifications and
there were configured with default params.

Change-Id: Ie4f2e75ec05af39c8b9db4aea98ba5127bcf4277
(cherry picked from commit I642fec707a669a724961dd0dd900d28522b8f869)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/46/438446/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_notifications_spec.rb', 'manifests/server/notifications.pp']",2,8a88e47ba6264a38a32f851f08b86286e4debb5a,project_domain_name,"# [*project_domain_name*] # (Optional) Name of domain for $project_name # Defaults to 'Default' ## [*user_domain_name*] # (Optional) Name of domain for $username # Defaults to 'Default' # $project_domain_name = 'Default', $user_domain_name = 'Default', 'nova/auth_url': value => $auth_url; 'nova/username': value => $username; 'nova/password': value => $password, secret => true; 'nova/project_domain_id': value => $project_domain_id; 'nova/project_domain_name': value => $project_domain_name; 'nova/project_name': value => $project_name; 'nova/user_domain_id': value => $user_domain_id; 'nova/user_domain_name': value => $user_domain_name; 'nova/region_name': value => $region_name;"," 'nova/auth_url': value => $auth_url; 'nova/username': value => $username; 'nova/password': value => $password, secret => true; 'nova/project_domain_id': value => $project_domain_id; 'nova/project_name': value => $project_name; 'nova/user_domain_id': value => $user_domain_id; 'nova/region_name': value => $region_name;",34,8
openstack%2Fneutron~master~I55feb42e6ed864ce49e5161c82e50c7df6b739be,openstack/neutron,master,I55feb42e6ed864ce49e5161c82e50c7df6b739be,Adding icmp ingress allow rule to the Security Group,ABANDONED,2017-02-07 13:11:40.000000000,2017-02-28 10:10:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 4727}, {'_account_id': 8655}, {'_account_id': 9732}, {'_account_id': 12444}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 18746}, {'_account_id': 19118}, {'_account_id': 20330}, {'_account_id': 21302}]","[{'number': 1, 'created': '2017-02-07 13:11:40.000000000', 'files': ['neutron/tests/tempest/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/51dc756282cb1c2ad10d387ac9d7d678757b854e', 'message': 'Adding icmp ingress allow rule to the Security Group\n\nChange-Id: I55feb42e6ed864ce49e5161c82e50c7df6b739be\n'}]",1,430242,51dc756282cb1c2ad10d387ac9d7d678757b854e,14,13,1,18746,,,0,"Adding icmp ingress allow rule to the Security Group

Change-Id: I55feb42e6ed864ce49e5161c82e50c7df6b739be
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/430242/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/scenario/base.py'],1,51dc756282cb1c2ad10d387ac9d7d678757b854e,icmp_rule_for_secgroup," 'remote_ip_prefix': '0.0.0.0/0'}, {'protocol': 'icmp', 'direction': 'ingress',}]", 'remote_ip_prefix': '0.0.0.0/0'}],3,1
openstack%2Fopenstack-manuals~master~I2b2c2021a346062e4525bbb53bff4b8e528211c2,openstack/openstack-manuals,master,I2b2c2021a346062e4525bbb53bff4b8e528211c2,telemetry: cleanup pipline docs,MERGED,2017-02-21 20:05:40.000000000,2017-02-28 10:01:38.000000000,2017-02-28 10:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 9162}, {'_account_id': 10897}, {'_account_id': 14643}]","[{'number': 1, 'created': '2017-02-21 20:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3212740b4e36fdad6e400a33581fdd340bdbc8b2', 'message': ""telemetry: cleanup pipline docs\n\n- publishers are currently shown on collection and retrieval pages\nbut is really related to pipeline. move it all to pipeline page and\nremove from other places.\n- pipeline doesn't do collection so drop the polling stuff because that's\nnot part of pipeline.\n- fix headings to make each transformers and publisher under general\n'Transformer' and 'Publisher' section\n- put rate of change transformer under it's own section similar to others\n- put deprecated publishers in own section for easier removal and to make\ndeprecation more obvious.\n\nChange-Id: I2b2c2021a346062e4525bbb53bff4b8e528211c2\n""}, {'number': 2, 'created': '2017-02-21 20:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b0c95813cbf6e2497f5479f5ad127e3cf56cd9ee', 'message': ""telemetry: cleanup pipline docs\n\n- publishers are currently shown on collection and retrieval pages\nbut is really related to pipeline. move it all to pipeline page and\nremove from other places.\n- pipeline doesn't do collection so drop the polling stuff because that's\nnot part of pipeline.\n- fix headings to make each transformers and publisher under general\n'Transformer' and 'Publisher' section\n- put rate of change transformer under it's own section similar to others\n- put deprecated publishers in own section for easier removal and to make\ndeprecation more obvious.\n\nChange-Id: I2b2c2021a346062e4525bbb53bff4b8e528211c2\n""}, {'number': 3, 'created': '2017-02-22 15:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/011bc0925eace064bd151e6555b85e4fbc9d0575', 'message': ""telemetry: cleanup pipline docs\n\n- publishers are currently shown on collection and retrieval pages\nbut is really related to pipeline. move it all to pipeline page and\nremove from other places.\n- pipeline doesn't do collection so drop the polling stuff because that's\nnot part of pipeline.\n- fix headings to make each transformers and publisher under general\n'Transformer' and 'Publisher' section\n- put rate of change transformer under it's own section similar to others\n- put deprecated publishers in own section for easier removal and to make\ndeprecation more obvious.\n\nChange-Id: I2b2c2021a346062e4525bbb53bff4b8e528211c2\n""}, {'number': 4, 'created': '2017-02-22 18:01:19.000000000', 'files': ['doc/admin-guide/source/telemetry-data-retrieval.rst', 'doc/admin-guide/source/telemetry-best-practices.rst', 'doc/admin-guide/source/telemetry-data-collection.rst', 'doc/admin-guide/source/telemetry-data-pipelines.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a98a1740929576009c03364e22b9d092e4bdd536', 'message': ""telemetry: cleanup pipline docs\n\n- publishers are currently shown on collection and retrieval pages\nbut is really related to pipeline. move it all to pipeline page and\nremove from other places.\n- pipeline doesn't do collection so drop the polling stuff because that's\nnot part of pipeline.\n- fix headings to make each transformers and publisher under general\n'Transformer' and 'Publisher' section\n- put rate of change transformer under it's own section similar to others\n- put deprecated publishers in own section for easier removal and to make\ndeprecation more obvious.\n\nChange-Id: I2b2c2021a346062e4525bbb53bff4b8e528211c2\n""}]",81,436637,a98a1740929576009c03364e22b9d092e4bdd536,19,5,4,6537,,,0,"telemetry: cleanup pipline docs

- publishers are currently shown on collection and retrieval pages
but is really related to pipeline. move it all to pipeline page and
remove from other places.
- pipeline doesn't do collection so drop the polling stuff because that's
not part of pipeline.
- fix headings to make each transformers and publisher under general
'Transformer' and 'Publisher' section
- put rate of change transformer under it's own section similar to others
- put deprecated publishers in own section for easier removal and to make
deprecation more obvious.

Change-Id: I2b2c2021a346062e4525bbb53bff4b8e528211c2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/436637/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide/source/telemetry-data-retrieval.rst', 'doc/admin-guide/source/telemetry-best-practices.rst', 'doc/admin-guide/source/telemetry-data-collection.rst', 'doc/admin-guide/source/telemetry-data-pipelines.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst']",5,3212740b4e36fdad6e400a33581fdd340bdbc8b2,docs, For more information about pipelines see the `Data processing and pipelines <https://docs.openstack.org/admin-guide/telemetry-data-pipelines.html>`_, For more information about pipelines see the `Data collection and processing <https://docs.openstack.org/admin-guide/telemetry-data-collection.html#data-collection-and-processing>`_,286,323
openstack%2Fhorizon~master~Iaf086fca94aa53d0d110ab4b1f8dbd67fb31a617,openstack/horizon,master,Iaf086fca94aa53d0d110ab4b1f8dbd67fb31a617,Imported Translations from Zanata,MERGED,2017-02-28 08:37:54.000000000,2017-02-28 09:57:24.000000000,2017-02-28 09:57:24.000000000,"[{'_account_id': 3}, {'_account_id': 12826}]","[{'number': 1, 'created': '2017-02-28 08:37:54.000000000', 'files': ['horizon/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/09f40dc0c5000c2c5ce276232346290f8b5dfe20', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Iaf086fca94aa53d0d110ab4b1f8dbd67fb31a617\n'}]",0,438849,09f40dc0c5000c2c5ce276232346290f8b5dfe20,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Iaf086fca94aa53d0d110ab4b1f8dbd67fb31a617
",git fetch https://review.opendev.org/openstack/horizon refs/changes/49/438849/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po']",4,09f40dc0c5000c2c5ce276232346290f8b5dfe20,zanata/translations,"""POT-Creation-Date: 2017-02-27 15:00+0000\n""""PO-Revision-Date: 2017-02-27 11:15+0000\n"" ""Last-Translator: Robert Simai <robert.simai@suse.com>\n""msgid ""11.0.0"" msgstr ""11.0.0"" ","""POT-Creation-Date: 2017-02-07 01:20+0000\n""""PO-Revision-Date: 2017-02-06 04:14+0000\n"" ""Last-Translator: Frank Kloeker <eumel@arcor.de>\n""",126,13
openstack%2Fopenstack-manuals~master~Ie209332ecfc31fc986b0424af62d2d910abde132,openstack/openstack-manuals,master,Ie209332ecfc31fc986b0424af62d2d910abde132,[arch-guide] Rephrase sentence,MERGED,2017-02-28 02:24:05.000000000,2017-02-28 09:55:10.000000000,2017-02-28 09:55:10.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 14643}, {'_account_id': 14870}, {'_account_id': 19779}]","[{'number': 1, 'created': '2017-02-28 02:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ddb08a1b3df6dd3af573c9908cab992f1e4591b7', 'message': '[arch-guide] Rephrase sentence\n\nMinor edit to sentence\n\nChange-Id: Ie209332ecfc31fc986b0424af62d2d910abde132\nCloses-Bug: #1645337\nBackport: ocata, newton\n'}, {'number': 2, 'created': '2017-02-28 03:04:16.000000000', 'files': ['doc/arch-design/source/generalpurpose-technical-considerations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/21bf7296749225dfda00137d519397dfd52bca6c', 'message': '[arch-guide] Rephrase sentence\n\nMinor edit to sentence\n\nChange-Id: Ie209332ecfc31fc986b0424af62d2d910abde132\nCloses-Bug: #1645337\n'}]",0,438768,21bf7296749225dfda00137d519397dfd52bca6c,13,5,2,10705,,,0,"[arch-guide] Rephrase sentence

Minor edit to sentence

Change-Id: Ie209332ecfc31fc986b0424af62d2d910abde132
Closes-Bug: #1645337
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/438768/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/source/generalpurpose-technical-considerations.rst'],1,ddb08a1b3df6dd3af573c9908cab992f1e4591b7,bug/1645337,"However, a cloud architect who selects Windows Server is limited to Hyper-V. Similarly, a cloud architect who selects XenServer is limited to the CentOS-based dom0 operating system provided with XenServer.","However, a cloud architect who selects Hyper-V is limited to Windows Servers. Similarly, a cloud architect who selects XenServer is limited to the CentOS-based dom0 operating system provided with XenServer.",3,3
openstack%2Fgnocchi~master~I94ae031a72414262f091860a8611dbf171ad2737,openstack/gnocchi,master,I94ae031a72414262f091860a8611dbf171ad2737,devstack: do not create legacy resource type if Ceilometer is enabled,MERGED,2017-02-03 13:50:49.000000000,2017-02-28 09:49:40.000000000,2017-02-28 09:49:40.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 11564}]","[{'number': 1, 'created': '2017-02-03 13:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/edac22569870a993b51860a40e6c61b7d7a95cef', 'message': 'devstack: do not create legacy resource type if Ceilometer is enabled\n\nCeilometer knows how to create its own resource types.\n\nChange-Id: I94ae031a72414262f091860a8611dbf171ad2737\n'}, {'number': 2, 'created': '2017-02-11 21:33:13.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/dd7507426057eb3af99d9077880be021ae048330', 'message': 'devstack: do not create legacy resource type if Ceilometer is enabled\n\nCeilometer knows how to create its own resource types.\n\nChange-Id: I94ae031a72414262f091860a8611dbf171ad2737\n'}]",0,428734,dd7507426057eb3af99d9077880be021ae048330,26,5,2,1669,,,0,"devstack: do not create legacy resource type if Ceilometer is enabled

Ceilometer knows how to create its own resource types.

Change-Id: I94ae031a72414262f091860a8611dbf171ad2737
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/34/428734/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,edac22569870a993b51860a40e6c61b7d7a95cef,jd/remove-ceilometer-legacy-resources, $GNOCCHI_BIN_DIR/gnocchi-upgrade, if is_service_enabled ceilometer; then $GNOCCHI_BIN_DIR/gnocchi-upgrade --create-legacy-resource-types else $GNOCCHI_BIN_DIR/gnocchi-upgrade fi,1,5
openstack%2Fneutron-lbaas~master~I83b6100bfcce26b1d02f42c016cc38e4e11eeab4,openstack/neutron-lbaas,master,I83b6100bfcce26b1d02f42c016cc38e4e11eeab4,Add missing classmethod decorator in l7 extension,MERGED,2017-02-20 10:51:23.000000000,2017-02-28 09:46:24.000000000,2017-02-28 09:46:24.000000000,"[{'_account_id': 3}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 14591}]","[{'number': 1, 'created': '2017-02-20 10:51:23.000000000', 'files': ['neutron_lbaas/extensions/l7.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/8929e9373089a1ca6e0c5bc2258031c4915cb61f', 'message': 'Add missing classmethod decorator in l7 extension\n\nChange-Id: I83b6100bfcce26b1d02f42c016cc38e4e11eeab4\n'}]",2,435932,8929e9373089a1ca6e0c5bc2258031c4915cb61f,15,6,1,8157,,,0,"Add missing classmethod decorator in l7 extension

Change-Id: I83b6100bfcce26b1d02f42c016cc38e4e11eeab4
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/32/435932/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/extensions/l7.py'],1,8929e9373089a1ca6e0c5bc2258031c4915cb61f,, @classmethod,,1,0
openstack%2Fblazar-nova~master~I3e2184fd1183c59bae6c25eb9839a47168972530,openstack/blazar-nova,master,I3e2184fd1183c59bae6c25eb9839a47168972530,Define ClimateFilter class,MERGED,2017-02-28 04:40:38.000000000,2017-02-28 09:35:12.000000000,2017-02-28 09:35:12.000000000,"[{'_account_id': 3}, {'_account_id': 8878}, {'_account_id': 15197}]","[{'number': 1, 'created': '2017-02-28 04:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/8a608145bac3f0520631c1ec0c8fba7867e6084f', 'message': 'Define ClimateFilter class\n\nA SchedulerHostFilterNotFound error occurs when the ClimateFilter is\nlisted in the scheduler_default_filters of nova.conf.\nThis patch define ClimateFilter class for backword compatibility.\n\nChange-Id: I3e2184fd1183c59bae6c25eb9839a47168972530\n'}, {'number': 2, 'created': '2017-02-28 04:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/d3fd0f17ae585c65f5b19ea45fc07f2ab645a371', 'message': 'Define ClimateFilter class\n\nA SchedulerHostFilterNotFound error occurs when the ClimateFilter is\nlisted in the scheduler_default_filters of nova.conf.\nThis patch define ClimateFilter class for backword compatibility.\n\nChange-Id: I3e2184fd1183c59bae6c25eb9839a47168972530\nCloses-Bug: #1668418\n'}, {'number': 3, 'created': '2017-02-28 05:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/1d7936c688f58494517af6315495c17a95d6e6d3', 'message': 'Define ClimateFilter class\n\nA SchedulerHostFilterNotFound error occurs when the ClimateFilter is\nlisted in the scheduler_default_filters of nova.conf.\nThis patch define ClimateFilter class for backword compatibility.\n\nChange-Id: I3e2184fd1183c59bae6c25eb9839a47168972530\nCloses-Bug: #1668418\n'}, {'number': 4, 'created': '2017-02-28 09:22:52.000000000', 'files': ['blazarnova/scheduler/filters/blazar_filter.py'], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/ca73d4502c896910fa5edc9facf17081ca77a880', 'message': 'Define ClimateFilter class\n\nA SchedulerHostFilterNotFound error occurs when ClimateFilter is listed\nin scheduler_default_filters in nova.conf. This patch defines a\nClimateFilter class for backward compatibility.\n\nChange-Id: I3e2184fd1183c59bae6c25eb9839a47168972530\nCloses-Bug: #1668418\n'}]",0,438796,ca73d4502c896910fa5edc9facf17081ca77a880,13,3,4,23840,,,0,"Define ClimateFilter class

A SchedulerHostFilterNotFound error occurs when ClimateFilter is listed
in scheduler_default_filters in nova.conf. This patch defines a
ClimateFilter class for backward compatibility.

Change-Id: I3e2184fd1183c59bae6c25eb9839a47168972530
Closes-Bug: #1668418
",git fetch https://review.opendev.org/openstack/blazar-nova refs/changes/96/438796/4 && git format-patch -1 --stdout FETCH_HEAD,['blazarnova/scheduler/filters/blazar_filter.py'],1,8a608145bac3f0520631c1ec0c8fba7867e6084f,,class ClimateFilter(BlazarFilter): pass,ClimateFilter = BlazarFilter,2,1
openstack%2Fceilometer~master~Ib08736b2a16214185b4577f671d69aa599f285ed,openstack/ceilometer,master,Ib08736b2a16214185b4577f671d69aa599f285ed,gnocchi: remove archive policy setting for identity,MERGED,2017-02-27 12:20:29.000000000,2017-02-28 09:31:38.000000000,2017-02-28 09:31:38.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 19055}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-27 12:20:29.000000000', 'files': ['ceilometer/dispatcher/data/gnocchi_resources.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8d3f291bb0fa39be23c008f56f882bc1bbe25ac9', 'message': ""gnocchi: remove archive policy setting for identity\n\nThere's no reason for this one to be forced there.\n\nChange-Id: Ib08736b2a16214185b4577f671d69aa599f285ed\n""}]",0,438469,8d3f291bb0fa39be23c008f56f882bc1bbe25ac9,26,5,1,1669,,,0,"gnocchi: remove archive policy setting for identity

There's no reason for this one to be forced there.

Change-Id: Ib08736b2a16214185b4577f671d69aa599f285ed
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/69/438469/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/dispatcher/data/gnocchi_resources.yaml'],1,8d3f291bb0fa39be23c008f56f882bc1bbe25ac9,jd/remove-archive-policy,, archive_policy: low,0,1
openstack%2Fkolla-ansible~master~I703945766135c432d8bcfc436489f34d6aab6eaf,openstack/kolla-ansible,master,I703945766135c432d8bcfc436489f34d6aab6eaf,Fix 'is' to 'are',ABANDONED,2017-02-28 07:48:18.000000000,2017-02-28 09:31:02.000000000,,"[{'_account_id': 3}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 23913}]","[{'number': 1, 'created': '2017-02-28 07:48:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/77e87eb2dbfc36b78614ce631717a54efe915c1f', 'message': ""Fix 'is' to 'are'\n\nChange-Id: I703945766135c432d8bcfc436489f34d6aab6eaf\n""}]",0,438832,77e87eb2dbfc36b78614ce631717a54efe915c1f,6,4,1,25254,,,0,"Fix 'is' to 'are'

Change-Id: I703945766135c432d8bcfc436489f34d6aab6eaf
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/438832/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,77e87eb2dbfc36b78614ce631717a54efe915c1f,b/01,"# The order of packages are significant, because pip processes them in the order","# The order of packages is significant, because pip processes them in the order",1,1
openstack%2Fdragonflow~stable%2Focata~I2d588a7db246bce4bef8e4f32a4fdd0dfb14384d,openstack/dragonflow,stable/ocata,I2d588a7db246bce4bef8e4f32a4fdd0dfb14384d,Add rate limiter to icmp handler(L3 proactive app),MERGED,2017-02-25 00:33:47.000000000,2017-02-28 09:30:06.000000000,2017-02-28 09:30:06.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-25 00:33:47.000000000', 'files': ['dragonflow/tests/fullstack/test_apps.py', 'dragonflow/controller/l3_proactive_app.py', 'releasenotes/notes/traceroute-support-18e959fd88f15da7.yaml'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5703e44f392991e839e9f6836ad09b3cf2f8c5fd', 'message': ""Add rate limiter to icmp handler(L3 proactive app)\n\nTo support traceroute or its backend network functionality, some icmp\nmessages are generated or re-processed at local controller. This\nprovides the possiblity of DDoS attack.\n\nTo prevent that, several global rate limters are added. So that the\ncontroller won't be overwhelmed. Global rate limters should be enough,\nas icmp works as control message.\n\nChange-Id: I2d588a7db246bce4bef8e4f32a4fdd0dfb14384d\nImplements: blueprint traceroute-support\n(cherry picked from commit d1762b7aa5e1f6720491fdd20529828eae1e2356)\n""}]",0,438127,5703e44f392991e839e9f6836ad09b3cf2f8c5fd,7,3,1,11159,,,0,"Add rate limiter to icmp handler(L3 proactive app)

To support traceroute or its backend network functionality, some icmp
messages are generated or re-processed at local controller. This
provides the possiblity of DDoS attack.

To prevent that, several global rate limters are added. So that the
controller won't be overwhelmed. Global rate limters should be enough,
as icmp works as control message.

Change-Id: I2d588a7db246bce4bef8e4f32a4fdd0dfb14384d
Implements: blueprint traceroute-support
(cherry picked from commit d1762b7aa5e1f6720491fdd20529828eae1e2356)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/27/438127/1 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/tests/fullstack/test_apps.py', 'dragonflow/controller/l3_proactive_app.py', 'releasenotes/notes/traceroute-support-18e959fd88f15da7.yaml']",3,5703e44f392991e839e9f6836ad09b3cf2f8c5fd,bp/traceroute-support,"--- prelude: > Traceroute support. features: - As a Openflow based SDN, traceroute and its back-end network functionalities are not naturally supported. Dragonflow supports traceroute base on RFC792, RFC4884, RFC1812 and RFC5508. Traceroute in Dragonflow cluster works for virtual router and NAT device. security: - To prevent DDoS, the rate of responding ICMP error message is controlled by several configuration options. They are 'dnat_ttl_invalid_max_rate', 'dnat_icmp_error_max_rate', 'router_ttl_invalid_max_rate' and 'router_port_unreach_max_rate'. ",,127,18
openstack%2Ftooz~master~Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db,openstack/tooz,master,Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db,Adds authentication support for zookeeperDriver,MERGED,2017-02-18 15:12:58.000000000,2017-02-28 09:24:45.000000000,2017-02-28 09:24:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 10068}, {'_account_id': 25237}]","[{'number': 1, 'created': '2017-02-18 15:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/48cd07fc6db9b2f6659cf7f31d29f1fd9a67a75f', 'message': 'Adds authentication support for zookeeperDriver\n\n1. Current zookeeperDriver is not support authentication\n2. just add authentication support for zookeeperDriver\n\nChange-Id: Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db\nCloses-Bug: 1665358\n'}, {'number': 2, 'created': '2017-02-19 00:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/5e3d73bad7170e5cdc2f8b786e557b3c99db06be', 'message': 'Adds authentication support for zookeeperDriver\n\n1. Current zookeeperDriver does not support authentication\n2. just add authentication support for zookeeperDriver\n\nChange-Id: Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db\nCloses-Bug: 1665358\n'}, {'number': 3, 'created': '2017-02-24 15:11:53.000000000', 'files': ['tooz/drivers/zookeeper.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/0c4000f24fc74a858ed3d2ca80811cdd1892eaf5', 'message': 'Adds authentication support for zookeeperDriver\n\n1. Current zookeeperDriver does not support authentication\n2. just add authentication support for zookeeperDriver\n\nChange-Id: Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db\nCloses-Bug: 1665358\n'}]",2,435708,0c4000f24fc74a858ed3d2ca80811cdd1892eaf5,26,6,3,25237,,,0,"Adds authentication support for zookeeperDriver

1. Current zookeeperDriver does not support authentication
2. just add authentication support for zookeeperDriver

Change-Id: Iebd43cbc34351fe5b9db8103f1d04c4fecbd40db
Closes-Bug: 1665358
",git fetch https://review.opendev.org/openstack/tooz refs/changes/08/435708/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/zookeeper.py'],1,48cd07fc6db9b2f6659cf7f31d29f1fd9a67a75f,bug/1665358," 'auth_data': options.get('auth_data'), 'default_acl': options.get('default_acl'),",,2,0
openstack%2Fpuppet-tripleo~master~Icabdb30369c8ca15e77d169dc441bee8cfd3631f,openstack/puppet-tripleo,master,Icabdb30369c8ca15e77d169dc441bee8cfd3631f,Add a noop_resource function,MERGED,2017-01-21 01:15:00.000000000,2017-02-28 09:13:19.000000000,2017-01-23 11:13:14.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6159}, {'_account_id': 6926}, {'_account_id': 8042}]","[{'number': 1, 'created': '2017-01-21 01:15:00.000000000', 'files': ['lib/puppet/parser/functions/noop_resource.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a3de7c09427e7ff97a85a5665ac98d43d46a4fb4', 'message': ""Add a noop_resource function\n\nA function to create noop providers (set as the default) for the named\nresource. This works alongside of 'puppet apply --tags' to disable\nsome custom resource types that still attempt to run commands during\nprefetch, etc.\n\nChange-Id: Icabdb30369c8ca15e77d169dc441bee8cfd3631f\n""}]",0,423571,a3de7c09427e7ff97a85a5665ac98d43d46a4fb4,9,5,1,360,,,0,"Add a noop_resource function

A function to create noop providers (set as the default) for the named
resource. This works alongside of 'puppet apply --tags' to disable
some custom resource types that still attempt to run commands during
prefetch, etc.

Change-Id: Icabdb30369c8ca15e77d169dc441bee8cfd3631f
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/71/423571/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/parser/functions/noop_resource.rb'],1,a3de7c09427e7ff97a85a5665ac98d43d46a4fb4,noop_resource,"# Copyright 2017 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Author: Dan Prince <dprince@redhat.com> # # A function to create noop providers (set as the default) for the named # resource. This works alongside of 'puppet apply --tags' to disable # some custom resource types that still attempt to run commands during # prefetch, etc. class Puppet::Provider::Noop < Puppet::Provider def create true end def destroy true end def exists? false end # some puppet-keystone resources require this def self.resource_to_name(domain, name, check_for_default = true) return name end end module Puppet::Parser::Functions newfunction(:noop_resource, :type => :rvalue, :doc => ""Create a default noop provider for the specified resource."") do |arg| if arg[0].class == String Puppet::Type.type(arg[0].downcase.to_sym).provide(:noop, :parent => Puppet::Provider::Noop) do defaultfor :osfamily => :redhat end else end return true end end ",,53,0
openstack%2Ffuel-library~stable%2Fnewton~I52e49ab9d866891a81d3c08b82c50c8addd34786,openstack/fuel-library,stable/newton,I52e49ab9d866891a81d3c08b82c50c8addd34786,Enable proxy headers parsing,MERGED,2017-02-27 12:56:08.000000000,2017-02-28 09:13:13.000000000,2017-02-28 09:07:23.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 14510}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-27 12:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4d47831667501ee3b11dbf376f40891980d43773', 'message': 'Enable proxy headers parsing\n\nAs heat is placed behind the proxy we need to enable\nproxy headers parsing, so heat is aware about about\nprotocol used to connect to endpoint.\n\nChange-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786\nCloses-Bug: #1668227\n'}, {'number': 2, 'created': '2017-02-27 13:14:53.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a151347a3f20bbd9200ff184d06846aeeeeb0ada', 'message': 'Enable proxy headers parsing\n\nAs heat is placed behind the proxy we need to enable\nproxy headers parsing, so heat is aware about\nprotocol used to connect to endpoint.\n\nChange-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786\nCloses-Bug: #1668227\n'}]",1,438481,a151347a3f20bbd9200ff184d06846aeeeeb0ada,49,7,2,14510,,,0,"Enable proxy headers parsing

As heat is placed behind the proxy we need to enable
proxy headers parsing, so heat is aware about
protocol used to connect to endpoint.

Change-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786
Closes-Bug: #1668227
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/81/438481/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb']",2,4d47831667501ee3b11dbf376f40891980d43773,bug/1668227," it 'should configure heat class' do should contain_class('heat').with( 'enable_proxy_headers_parsing' => true, ) end ",,8,1
openstack%2Fopenstack-ansible~master~I29115b048cc7c65f55217fbe2abf7f4e954a0e5e,openstack/openstack-ansible,master,I29115b048cc7c65f55217fbe2abf7f4e954a0e5e,update galera cluster database bind mount dirs,MERGED,2017-02-26 04:27:46.000000000,2017-02-28 09:11:22.000000000,2017-02-28 09:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 25128}]","[{'number': 1, 'created': '2017-02-26 04:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7577a554076af7e1701d8a1121ec373961151c47', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 2, 'created': '2017-02-26 15:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d0abae130531d3e0658ec40a8f0583519b9a875e', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 3, 'created': '2017-02-26 15:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/862e235b049ba2ecfb480db9ba12f906e7ed39aa', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 4, 'created': '2017-02-26 17:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/66f75360c7d3d0097e0e39af38e9231f4982301b', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 5, 'created': '2017-02-27 15:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bb2d79ce237998d55d02a62bbbbdaabb5fa8d380', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 6, 'created': '2017-02-27 16:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c6ea0598917017c818865561d1a48d0c2c6f5e12', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}, {'number': 7, 'created': '2017-02-28 02:50:35.000000000', 'files': ['playbooks/galera-install.yml', 'playbooks/inventory/group_vars/galera_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca2fecc87689f1c4bdf80415a59dc1c1a0473864', 'message': 'update galera cluster database bind mount dirs\n\nWith the current play we cannot over-ride the\n```/openstack/{{ inventory_hostname }}``` host directory for bind\nmounting database directory. Updated it so that user can specify\na particular host direcotry of his choice.\n\nChange-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e\n'}]",8,438229,ca2fecc87689f1c4bdf80415a59dc1c1a0473864,28,4,7,25128,,,0,"update galera cluster database bind mount dirs

With the current play we cannot over-ride the
```/openstack/{{ inventory_hostname }}``` host directory for bind
mounting database directory. Updated it so that user can specify
a particular host direcotry of his choice.

Change-Id: I29115b048cc7c65f55217fbe2abf7f4e954a0e5e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/29/438229/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/galera-install.yml', 'etc/openstack_deploy/user_variables.yml']",2,7577a554076af7e1701d8a1121ec373961151c47,galera_flex," # Defines galera cluster database bind mount directory # galera_list_of_bind_mounts: # - bind_dir_path: ""/var/lib/mysql"" # mount_path: ""/opt/db""",,6,3
openstack%2Fopenstack-ansible~master~Icf2c1abf661302b54d870028df98c06e89a32dde,openstack/openstack-ansible,master,Icf2c1abf661302b54d870028df98c06e89a32dde,Place gnocchi database bind mount dirs to be in group_vars,MERGED,2017-02-27 03:11:35.000000000,2017-02-28 09:10:44.000000000,2017-02-28 09:10:44.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 11268}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-27 03:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/43f048c19991b6277d96be66e8c0d24ed3f65834', 'message': 'Updated gnocchi database bind mount dir to be defined by user\n\nChange-Id: Icf2c1abf661302b54d870028df98c06e89a32dde\n'}, {'number': 2, 'created': '2017-02-27 17:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/91e3744d39815d1525a198d332416395763f78f2', 'message': 'Place gnocchi database bind mount dirs to be in group_vars\n\nRemoved hardcoded gnocchi database bind mount dirs in play and\nadded to group_vars so users can over-ride if needed.\nChange-Id: Icf2c1abf661302b54d870028df98c06e89a32dde\n'}, {'number': 3, 'created': '2017-02-28 02:45:11.000000000', 'files': ['playbooks/inventory/group_vars/gnocchi_all.yml', 'playbooks/os-gnocchi-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/67f2db5b22d71b009945f02581c9fc1c9fe488ea', 'message': 'Place gnocchi database bind mount dirs to be in group_vars\n\nRemoved hardcoded gnocchi database bind mount dirs in play and\nadded to group_vars so users can over-ride if needed.\nChange-Id: Icf2c1abf661302b54d870028df98c06e89a32dde\n'}]",1,438320,67f2db5b22d71b009945f02581c9fc1c9fe488ea,16,4,3,25128,,,0,"Place gnocchi database bind mount dirs to be in group_vars

Removed hardcoded gnocchi database bind mount dirs in play and
added to group_vars so users can over-ride if needed.
Change-Id: Icf2c1abf661302b54d870028df98c06e89a32dde
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/20/438320/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/os-gnocchi-install.yml', 'etc/openstack_deploy/user_variables.yml']",2,43f048c19991b6277d96be66e8c0d24ed3f65834,," # Defines gnocchi database bind mount directory # gnocchi_list_of_bind_mounts: # - bind_dir_path: ""/var/lib/gnocchi"" # mount_path: ""/opt/gnocchi""",,6,3
openstack%2Fdevstack-gate~master~I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670,openstack/devstack-gate,master,I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670,Add MULTI_REGION flag and new role,ABANDONED,2016-12-20 06:42:43.000000000,2017-02-28 09:05:05.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 11819}, {'_account_id': 12076}]","[{'number': 1, 'created': '2016-12-20 06:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/799b6478c568d65305cd64ddc4dc39f8adf4ef36', 'message': 'Add MULTI_REGION flag and new role\n\nCurrently ""multinode"" topology is supported in devstack gate,\nbut unfortunately only single OpenStack region is applicable.\n\nThis patch is to add new role ""subnode_multi_region"" in feature\nmatrix to enable OpenStack services in subnode(s). To make OpenStack\nmulti-region gate/check job can work ASAP, only two nodes(one primary\nnode as RegionOne, one subnode as RegionTwo) will be supported\nat first stage.\n\nEnvironment variable MULTI_REGION is added to make it possible to\nsetup the multi-region parameters in localrc for RegionOne and\nRegionTwo.\n\nChange-Id: I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670\nSigned-off-by: joehuang <joehuang@huawei.com>\n'}, {'number': 2, 'created': '2016-12-29 00:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/cd7fa59806c54e2d0524107df83c51900b36a300', 'message': 'Add MULTI_REGION flag and new role\n\nCurrently ""multinode"" topology is supported in devstack gate,\nbut unfortunately only single OpenStack region is applicable.\n\nThis patch is to add new role ""subnode_multi_region"" in feature\nmatrix to enable OpenStack services in subnode(s). To make OpenStack\nmulti-region gate/check job can work ASAP, only two nodes(one primary\nnode as RegionOne, one subnode as RegionTwo) will be supported\nat first stage.\n\nEnvironment variable MULTI_REGION is added to make it possible to\nsetup the multi-region parameters in localrc for RegionOne and\nRegionTwo.\n\nChange-Id: I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670\nSigned-off-by: joehuang <joehuang@huawei.com>\n'}, {'number': 3, 'created': '2017-02-24 09:31:32.000000000', 'files': ['features.yaml', 'devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/000c50ff0e1cb2d6168ba8cd8a79ebfb9fa8e6da', 'message': 'Add MULTI_REGION flag and new role\n\nCurrently ""multinode"" topology is supported in devstack gate,\nbut unfortunately only single OpenStack region is applicable.\n\nThis patch is to add new role ""subnode_multi_region"" in feature\nmatrix to enable OpenStack services in subnode(s). To make OpenStack\nmulti-region gate/check job can work ASAP, only two nodes(one primary\nnode as RegionOne, one subnode as RegionTwo) will be supported\nat first stage.\n\nEnvironment variable MULTI_REGION is added to make it possible to\nsetup the multi-region parameters in localrc for RegionOne and\nRegionTwo.\n\nChange-Id: I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670\nSigned-off-by: joehuang <joehuang@huawei.com>\n'}]",0,412777,000c50ff0e1cb2d6168ba8cd8a79ebfb9fa8e6da,14,5,3,11819,,,0,"Add MULTI_REGION flag and new role

Currently ""multinode"" topology is supported in devstack gate,
but unfortunately only single OpenStack region is applicable.

This patch is to add new role ""subnode_multi_region"" in feature
matrix to enable OpenStack services in subnode(s). To make OpenStack
multi-region gate/check job can work ASAP, only two nodes(one primary
node as RegionOne, one subnode as RegionTwo) will be supported
at first stage.

Environment variable MULTI_REGION is added to make it possible to
setup the multi-region parameters in localrc for RegionOne and
RegionTwo.

Change-Id: I63ccd78ada0551c5b33d55f7fa91ff7eef8c7670
Signed-off-by: joehuang <joehuang@huawei.com>
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/77/412777/3 && git format-patch -1 --stdout FETCH_HEAD,"['features.yaml', 'devstack-vm-gate.sh']",2,799b6478c568d65305cd64ddc4dc39f8adf4ef36,multi-region," if [[ ""$MULTI_REGION"" -eq ""1"" ]]; then test_matrix_role='subnode_multi_region' fi if [[ ""$MULTI_REGION"" -eq ""1"" ]]; then # set the second region to use primary region's keystone if [[ ""$role"" = sub ]]; then # currently only two region supported, so it's ok to do so. # enhance here to support more than one sub-nodes local sub_node=`cat /etc/nodepool/sub_nodes_private` echo ""HOST_IP=$sub_node"" >>""$localrc_file"" echo ""SERVICE_HOST=$HOST_IP"" >>""$localrc_file"" echo ""REGION_NAME=RegionTwo"" >>""$localrc_file"" echo ""KEYSTONE_REGION_NAME=RegionOne"" >>""$localrc_file"" echo ""KEYSTONE_SERVICE_HOST=$primary_node"" >>""$localrc_file"" echo ""KEYSTONE_AUTH_HOST=$primary_node"" >>""$localrc_file"" echo ""HOST_IP=$primary_node"" >>""$localrc_file"" echo ""REGION_NAME=RegionOne"" >>""$localrc_file"" else # non-multi-region mode if [[ ""$role"" = sub ]]; then if [[ $original_enabled_services =~ ""qpid"" ]]; then echo ""QPID_HOST=$primary_node"" >>""$localrc_file"" fi if [[ $original_enabled_services =~ ""rabbit"" ]]; then echo ""RABBIT_HOST=$primary_node"" >>""$localrc_file"" fi echo ""DATABASE_HOST=$primary_node"" >>""$localrc_file"" if [[ $original_enabled_services =~ ""mysql"" ]]; then echo ""DATABASE_TYPE=mysql"" >>""$localrc_file"" else echo ""DATABASE_TYPE=postgresql"" >>""$localrc_file"" fi echo ""GLANCE_HOSTPORT=$primary_node:9292"" >>""$localrc_file"" echo ""Q_HOST=$primary_node"" >>""$localrc_file"" # Set HOST_IP in subnodes before copying localrc to each node else echo ""HOST_IP=$primary_node"" >>""$localrc_file"" fi"," if [[ ""$role"" = sub ]]; then if [[ $original_enabled_services =~ ""qpid"" ]]; then echo ""QPID_HOST=$primary_node"" >>""$localrc_file"" fi if [[ $original_enabled_services =~ ""rabbit"" ]]; then echo ""RABBIT_HOST=$primary_node"" >>""$localrc_file"" fi echo ""DATABASE_HOST=$primary_node"" >>""$localrc_file"" if [[ $original_enabled_services =~ ""mysql"" ]]; then echo ""DATABASE_TYPE=mysql"" >>""$localrc_file"" echo ""DATABASE_TYPE=postgresql"" >>""$localrc_file"" echo ""GLANCE_HOSTPORT=$primary_node:9292"" >>""$localrc_file"" echo ""Q_HOST=$primary_node"" >>""$localrc_file"" # Set HOST_IP in subnodes before copying localrc to each node else echo ""HOST_IP=$primary_node"" >>""$localrc_file""",109,16
openstack%2Fswift~master~Idd155401982a2c48110c30b480966a863f6bd305,openstack/swift,master,Idd155401982a2c48110c30b480966a863f6bd305,EC Fragment Duplication - Foundational Global EC Cluster Support,MERGED,2015-09-01 07:38:16.000000000,2017-02-28 09:01:43.000000000,2017-02-26 06:26:08.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 7847}, {'_account_id': 11866}, {'_account_id': 12261}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 17361}, {'_account_id': 20508}]","[{'number': 1, 'created': '2015-09-01 07:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8675788ce4c29d95efd9c28559348b53bf6f5fad', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 2, 'created': '2015-09-01 07:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cf2bf005f96d9c365f44b37ee9f0f716c926a49f', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 3, 'created': '2015-09-01 11:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d6c40a99bdcea60422c25ceecb263b72ef88e27a', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 4, 'created': '2015-09-02 00:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/700409a30cedfd1d7316d1e3d36ebe88688e446d', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 5, 'created': '2015-09-08 11:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c2a03d63284159f5ef6b5e09acaf29427744945d', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 6, 'created': '2015-09-30 01:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6ad09d6be51568514a9cf0f69d9f55d2fe49a4df', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 7, 'created': '2015-10-21 04:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5a804c337c1e7da2e431fac228d2a222c510b544', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 8, 'created': '2015-10-21 05:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d3dd3ee1bc9d57832d1cba3bd73536637039454c', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 9, 'created': '2015-10-21 08:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/99b854a47729924cbfb16ec030d681b752504778', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 10, 'created': '2015-12-10 02:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f842700eea7087932047563396d3767c9196bd95', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 11, 'created': '2015-12-10 04:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0bcb41bba927dc733d5647b061d60799f1ce6692', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 12, 'created': '2015-12-25 15:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0c2e85483ea04d8d4865bdee60bd383ab457673e', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 13, 'created': '2016-01-26 10:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8733a504f1ae9eacd951deb098bcca5c60b570b7', 'message': 'WIP: PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\n1: https://review.openstack.org/#/c/209447/\n\nDoc-Impact\n\nTODO: More tests\nTODO: Feedback (Making sure actual benefits using this, like performance\n      comparison for PUT/GET)\nTODO: Assertion for GET path (prevent doubled nodes for decode)\nTODO: Apply sorting method on reconstructor as well as GET\nTODO: Writing docs\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 14, 'created': '2016-02-18 06:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6a786d4ddbc21efaac281656d1e6ffc4bc6dfcec', 'message': 'PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nTODO: Apply sorting method on reconstructor as well as GET\n      (in later patch)\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 15, 'created': '2016-02-19 13:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/91117d50f3d94394de59c99bbe96283493c8b5b9', 'message': 'PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nTODO: Apply sorting method on reconstructor as well as GET\n      (in later patch)\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 16, 'created': '2016-04-27 18:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/45c90c59a519e23cb1ab767e168b1da523b985f2', 'message': 'PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nTODO: Apply sorting method on reconstructor as well as GET\n      (in later patch)\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 17, 'created': '2016-07-07 11:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/585af2b0a6a88b63f0073b700afdf7250918f520', 'message': 'PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nTODO: Apply sorting method on reconstructor as well as GET\n      (in later patch)\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 18, 'created': '2016-07-07 12:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbee76058833156f834e75484c5d4675de7ffd8e', 'message': 'PUT/GET path for global ec cluster\n\nInitial patch for global ec cluster efficiency[1].\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy\n- Change PUT Path to map encoded chunk to backend nodes by doubling\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nTODO: Apply sorting method on reconstructor as well as GET\n      (in later patch)\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 19, 'created': '2016-07-08 12:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8d9f84a7a967920b1bcb322d0b973f31afc8391a', 'message': 'Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, erasure coding has a weakness, we should have any ec_k fragments\nof ec_k + ec_m (e.g. 6 of 9 in the case above). And then, if we stored the\nec object into a swift cluster on 2 geographically distributed data\ncenter which has same volume of disks, probably the fragments will be\nstored evenly (about 4 and 5) so we still need to access a faraway data\ncenter to decode the original object. In addition, if one of the data\ncenter has gone with disaster, the stored objects will be lost forever,\nwe have to cry a lot. To eunsure highly durable storage, you would think\nof making more parity fragments (e.g. ec_k=6, ec_m=10), unfortunately it\ncauses significant performance degradation due to the cost of\nmathmatical caluculation for erasure coding encode/decode.\n\nHow this resolves the problem:\nBasically depending on the idea to add more parity fragments as well as\ndescribed above. The difference is making copies of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects. So this works most likely\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- And then making duplicated copies of the encoded fragments\n- Storing them as Swift erasure code fragments\n\nThe reason this can work is because Swift handles the actual fragments\nto decode according to X-Object-Sysmeta-Frag-Index. Hence, if we keep\nthe actual fragment index encoded by PyECLib, anytime we can decode the\noriginal objects if we can look at the ec_k fragments which has unique\nX-Object-Sysmeta-Frag-Index each other.\n\nThis patch inclues following changes:\n- Add ec_duplication_factor to storage policy, which means how many times\n  the fragments set will be duplicated\n- Change PUT Path to map encoded chunk to backend nodes by\n  ""ec_duplication_factor"" x.\n- Change GET Path to sort primary nodes grouping as subsets, each subset\n  includes unique fragments.\n- Change Reconstructor to be able to ec_duplication_factor\n\nFor example, with this change, swift fragments layout will be\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring should have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 20, 'created': '2016-07-15 15:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/71909ffcb1bcf0f14dff8d80003d2bf7f842098b', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers were lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times dupplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 21, 'created': '2016-07-21 04:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d851d1364e80f85f4904a2b68778aef5fa41331c', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 22, 'created': '2016-07-21 08:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a498b00429133111d63c434b0ed7fee5787b8bb2', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 23, 'created': '2016-07-21 09:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d00153d4682f0201f13e623d75a370a66a20c253', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 24, 'created': '2016-07-22 02:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dc21c314faae68143b688c85c76dff334cf5d8e0', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 25, 'created': '2016-07-25 02:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3360609cca332f8f6a4a6e7b8d6ecd7ea594feb7', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 26, 'created': '2016-08-26 09:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5fa23c6053cb035ceb2c5a047439a793e2df411a', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 27, 'created': '2016-08-31 11:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4927d1ee3d163db81c6f2d86f64f55b50dd53b1e', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 28, 'created': '2016-09-01 03:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/106e1a0e905c1936cec6aad7b5448e8311554089', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 29, 'created': '2016-09-14 12:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0d6745089985a39c1cc6c5d3fe15d3f4a357cef8', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 30, 'created': '2016-09-14 13:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4d9d64401bb32eea7516c5f61c54e09f6dfadef1', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 31, 'created': '2016-09-14 13:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c988908fc2931b63ab994ae1fe777d2fc0b316fc', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 32, 'created': '2016-09-14 21:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9f7c4f043e8cbe15294a55b23078757fc0ced023', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 33, 'created': '2016-09-14 23:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e500f84eba255d13c790e22dd4ef4fe2b22eb60f', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 34, 'created': '2016-09-16 11:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a99ce1b9e929a97fed650064263517624ce22194', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 35, 'created': '2016-09-17 11:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/05fbb0d4a9a612e4b73abefa4d6d629c0029add9', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 36, 'created': '2016-09-23 02:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/46389c3a678d597bf280075905aa1d0cab828f74', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 37, 'created': '2016-10-04 04:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/734cc6be5096cab21b3639eb6742c7aa016968d0', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 38, 'created': '2016-10-04 07:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/49339cb642e59af06f251ed980aff4c4991982e4', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 39, 'created': '2016-10-27 07:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c14f9f43bf4949eac70486749481401a57aad0a6', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 40, 'created': '2016-11-01 02:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d91f9d3a8e17f7f85f271fca54c70755d6acd6cb', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 41, 'created': '2016-11-02 04:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/15d68f761e2b3f633fa1979443eb15c515dcd9bd', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 42, 'created': '2016-12-15 04:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b54b8235a5a3121c8c0ac6bf0ec31916cba7dc91', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 43, 'created': '2017-01-10 02:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2db05dd07de5a909b1b60396fef2e7a26d71bda8', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 44, 'created': '2017-01-13 14:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2d37559753262ef9bb5d2abd2f77c4494d8ff164', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 45, 'created': '2017-01-17 10:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6f67f06282edee83f5042d96c5ab2bd4d967611a', 'message': 'EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decodeing objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Add ec_duplication_factor option to storage policy, to configure\n  how many times duplicates of each fragment set will be created\n- Change PUT Path to map encoded chunk to each backend node by\n  ""ec_duplication_factor""\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_n_data_fragments = 2\nec_n_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n'}, {'number': 46, 'created': '2017-01-30 06:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6c87c04011d6c006a66bcde7528dfc652c2d256a', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 47, 'created': '2017-02-01 01:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/647c96a163eb54fa1df6817e452a8c5536d95069', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 48, 'created': '2017-02-06 00:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ce6807ab6fd33d30d7844546c6261951772eb822', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 49, 'created': '2017-02-06 06:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b4ca7ea682488ee57ac113b4ae62cd00e41bdfe1', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 50, 'created': '2017-02-06 08:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68205d242fc0c26ab6ee45926ff3986af70386f5', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 51, 'created': '2017-02-06 12:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/17052ab746a151a5b5e728a6cfb80cb0fe85abc2', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 52, 'created': '2017-02-06 16:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c1c1dd5313fad03e93d19ad42a2ba26e93bc698b', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 53, 'created': '2017-02-07 05:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/33fe68248a51b829cbccae58a5d0f28be243f7b9', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 54, 'created': '2017-02-09 09:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/faa02cdacd7d4ad8e205fec8200877e00186e78c', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 55, 'created': '2017-02-09 13:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e2e67b7f00017f327c4cb28777c899ed050870f', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 56, 'created': '2017-02-12 08:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/661256a5167da13b956acd5628bc2380f4bcc0dd', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Frag-Index.  In this change, the\nX-Object-Sysmeta-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 57, 'created': '2017-02-14 01:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/df3ac8596aa7c6d8a884848bebb3a48e9ec5c332', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Ec-Frag-Index.  In this change, the\nX-Object-Sysmeta-Ec-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Ec-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Ec-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Ec-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 58, 'created': '2017-02-15 06:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4bb5ce1c17b1fa8f3c30081075d3ce074051415d', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To eunsure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmatical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Ec-Frag-Index.  In this change, the\nX-Object-Sysmeta-Ec-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Ec-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Ec-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Ec-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 59, 'created': '2017-02-22 16:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e23833f5b9baa45c43b667e34dac26e497ccb9aa', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To ensure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmetical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution to add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Ec-Frag-Index.  In this change, the\nX-Object-Sysmeta-Ec-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Ec-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Ec-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Ec-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}, {'number': 60, 'created': '2017-02-22 18:56:24.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'swift/obj/reconstructor.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/helpers.py', 'swift/proxy/controllers/obj.py', 'doc/source/overview_erasure_code.rst', 'test/unit/obj/test_reconstructor.py', 'swift/common/utils.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/40ba7f6172465c2f9bc63fb6f4d24f8bb5f96ef9', 'message': ""EC Fragment Duplication - Foundational Global EC Cluster Support\n\nThis patch enables efficent PUT/GET for global distributed cluster[1].\n\nProblem:\nErasure coding has the capability to decrease the amout of actual stored\ndata less then replicated model. For example, ec_k=6, ec_m=3 parameter\ncan be 1.5x of the original data which is smaller than 3x replicated.\nHowever, unlike replication, erasure coding requires availability of at\nleast some ec_k fragments of the total ec_k + ec_m fragments to service\nread (e.g. 6 of 9 in the case above). As such, if we stored the\nEC object into a swift cluster on 2 geographically distributed data\ncenters which have the same volume of disks, it is likely the fragments\nwill be stored evenly (about 4 and 5) so we still need to access a\nfaraway data center to decode the original object. In addition, if one\nof the data centers was lost in a disaster, the stored objects will be\nlost forever, and we have to cry a lot. To ensure highly durable\nstorage, you would think of making *more* parity fragments (e.g.\nec_k=6, ec_m=10), unfortunately this causes *significant* performance\ndegradation due to the cost of mathmetical caluculation for erasure\ncoding encode/decode.\n\nHow this resolves the problem:\nEC Fragment Duplication extends on the initial solution to add *more*\nfragments from which to rebuild an object similar to the solution\ndescribed above. The difference is making *copies* of encoded fragments.\nWith experimental results[1][2], employing small ec_k and ec_m shows\nenough performance to store/retrieve objects.\n\nOn PUT:\n\n- Encode incomming object with small ec_k and ec_m  <- faster!\n- Make duplicated copies of the encoded fragments. The # of copies\n  are determined by 'ec_duplication_factor' in swift.conf\n- Store all fragments in Swift Global EC Cluster\n\nThe duplicated fragments increase pressure on existing requirements\nwhen decoding objects in service to a read request.  All fragments are\nstored with their X-Object-Sysmeta-Ec-Frag-Index.  In this change, the\nX-Object-Sysmeta-Ec-Frag-Index represents the actual fragment index\nencoded by PyECLib, there *will* be duplicates.  Anytime we must decode\nthe original object data, we must only consider the ec_k fragments as\nunique according to their X-Object-Sysmeta-Ec-Frag-Index.  On decode no\nduplicate X-Object-Sysmeta-Ec-Frag-Index may be used when decoding an\nobject, duplicate X-Object-Sysmeta-Ec-Frag-Index should be expected and\navoided if possible.\n\nOn GET:\n\nThis patch inclues following changes:\n- Change GET Path to sort primary nodes grouping as subsets, so that\n  each subset will includes unique fragments\n- Change Reconstructor to be more aware of possibly duplicate fragments\n\nFor example, with this change, a policy could be configured such that\n\nswift.conf:\nec_num_data_fragments = 2\nec_num_parity_fragments = 1\nec_duplication_factor = 2\n(object ring must have 6 replicas)\n\nAt Object-Server:\nnode index (from object ring):  0 1 2 3 4 5 <- keep node index for\n                                               reconstruct decision\nX-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual\n                                               fragment index for\n                                               backend (PyEClib)\n\nAdditional improvements to Global EC Cluster Support will require\nfeatures such as Composite Rings, and more efficient fragment\nrebalance/reconstruction.\n\n1: http://goo.gl/IYiNPk (Swift Design Spec Repository)\n2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)\n\nDoc-Impact\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: Idd155401982a2c48110c30b480966a863f6bd305\n""}]",389,219165,40ba7f6172465c2f9bc63fb6f4d24f8bb5f96ef9,262,11,60,4608,,,0,"EC Fragment Duplication - Foundational Global EC Cluster Support

This patch enables efficent PUT/GET for global distributed cluster[1].

Problem:
Erasure coding has the capability to decrease the amout of actual stored
data less then replicated model. For example, ec_k=6, ec_m=3 parameter
can be 1.5x of the original data which is smaller than 3x replicated.
However, unlike replication, erasure coding requires availability of at
least some ec_k fragments of the total ec_k + ec_m fragments to service
read (e.g. 6 of 9 in the case above). As such, if we stored the
EC object into a swift cluster on 2 geographically distributed data
centers which have the same volume of disks, it is likely the fragments
will be stored evenly (about 4 and 5) so we still need to access a
faraway data center to decode the original object. In addition, if one
of the data centers was lost in a disaster, the stored objects will be
lost forever, and we have to cry a lot. To ensure highly durable
storage, you would think of making *more* parity fragments (e.g.
ec_k=6, ec_m=10), unfortunately this causes *significant* performance
degradation due to the cost of mathmetical caluculation for erasure
coding encode/decode.

How this resolves the problem:
EC Fragment Duplication extends on the initial solution to add *more*
fragments from which to rebuild an object similar to the solution
described above. The difference is making *copies* of encoded fragments.
With experimental results[1][2], employing small ec_k and ec_m shows
enough performance to store/retrieve objects.

On PUT:

- Encode incomming object with small ec_k and ec_m  <- faster!
- Make duplicated copies of the encoded fragments. The # of copies
  are determined by 'ec_duplication_factor' in swift.conf
- Store all fragments in Swift Global EC Cluster

The duplicated fragments increase pressure on existing requirements
when decoding objects in service to a read request.  All fragments are
stored with their X-Object-Sysmeta-Ec-Frag-Index.  In this change, the
X-Object-Sysmeta-Ec-Frag-Index represents the actual fragment index
encoded by PyECLib, there *will* be duplicates.  Anytime we must decode
the original object data, we must only consider the ec_k fragments as
unique according to their X-Object-Sysmeta-Ec-Frag-Index.  On decode no
duplicate X-Object-Sysmeta-Ec-Frag-Index may be used when decoding an
object, duplicate X-Object-Sysmeta-Ec-Frag-Index should be expected and
avoided if possible.

On GET:

This patch inclues following changes:
- Change GET Path to sort primary nodes grouping as subsets, so that
  each subset will includes unique fragments
- Change Reconstructor to be more aware of possibly duplicate fragments

For example, with this change, a policy could be configured such that

swift.conf:
ec_num_data_fragments = 2
ec_num_parity_fragments = 1
ec_duplication_factor = 2
(object ring must have 6 replicas)

At Object-Server:
node index (from object ring):  0 1 2 3 4 5 <- keep node index for
                                               reconstruct decision
X-Object-Sysmeta-Ec-Frag-Index: 0 1 2 0 1 2 <- each object keeps actual
                                               fragment index for
                                               backend (PyEClib)

Additional improvements to Global EC Cluster Support will require
features such as Composite Rings, and more efficient fragment
rebalance/reconstruction.

1: http://goo.gl/IYiNPk (Swift Design Spec Repository)
2: http://goo.gl/frgj6w (Slide Share for OpenStack Summit Tokyo)

Doc-Impact

Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
Change-Id: Idd155401982a2c48110c30b480966a863f6bd305
",git fetch https://review.opendev.org/openstack/swift refs/changes/65/219165/29 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_storage_policy.py', 'swift/common/utils.py', 'test/unit/proxy/controllers/test_obj.py', 'swift/common/storage_policy.py', 'swift/proxy/controllers/obj.py', 'test/unit/common/test_utils.py']",6,8675788ce4c29d95efd9c28559348b53bf6f5fad,global-ec-cluster," def test_config_nutural_number_value(self): expectations = { # value : expected, '1': 1, 1: 1, 'asdf': ValueError, None: ValueError, 0: ValueError, -1: ValueError, } for value, expected in expectations.items(): try: rv = utils.config_natural_number_value(value) except Exception as e: if e.__class__ is not expected: raise else: self.assertEquals(expected, rv) ",,206,13
openstack%2Fopenstack-manuals~master~I15abb241af8a41edc3dd3850b08be4ab7a31c9c5,openstack/openstack-manuals,master,I15abb241af8a41edc3dd3850b08be4ab7a31c9c5,release notes and config guide new settings,MERGED,2016-12-02 01:49:11.000000000,2017-02-28 08:58:23.000000000,2016-12-06 01:04:12.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14962}, {'_account_id': 19779}]","[{'number': 1, 'created': '2016-12-02 01:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8b381d12efaabae527c210c96755350054a14dfa', 'message': 'release notes and config guide new settings\n\nOpenStack operators and folks who automate openstack deployments with\ntools like puppet rely on the release notes and config guides to\nhighlight new, changed, deleted, and deprecated config options.\n\nChange-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5\n'}, {'number': 2, 'created': '2016-12-02 01:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1765393109c1c1654a09348cea3db039a55f67ef', 'message': 'release notes and config guide new settings\n\nOpenStack operators and folks who automate openstack deployments with\ntools like puppet rely on the release notes and config guides to\nhighlight new, changed, deleted, and deprecated config options.\n\nChange-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5\nCloses-bug:#1640504\n'}, {'number': 3, 'created': '2016-12-02 02:14:40.000000000', 'files': ['doc/config-reference/source/tables/conf-changes/keystone.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/260a31067d58d045477908de62bcc2e6798e1bae', 'message': 'release notes and config guide new settings\n\nOpenStack operators and folks who automate openstack deployments with\ntools like puppet rely on the release notes and config guides to\nhighlight new, changed, deleted, and deprecated config options.\n\nChange-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5\nCloses-bug:#1640504\n'}]",0,405711,260a31067d58d045477908de62bcc2e6798e1bae,14,6,3,17645,,,0,"release notes and config guide new settings

OpenStack operators and folks who automate openstack deployments with
tools like puppet rely on the release notes and config guides to
highlight new, changed, deleted, and deprecated config options.

Change-Id: I15abb241af8a41edc3dd3850b08be4ab7a31c9c5
Closes-bug:#1640504
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/405711/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/tables/conf-changes/keystone.rst'],1,8b381d12efaabae527c210c96755350054a14dfa,bug/1640504,".. list-table:: New options :header-rows: 1 :class: config-ref-table * - Option = default value - (Type) Help string * - ``[security_compliance] disable_user_account_days_inactive =`` - (IntOpt) The maximum number of days a user can go without authenticating before being considered ""inactive"" and automatically disabled (locked). * - ``[security_compliance] lockout_failure_attempts =`` - (IntOpt) The maximum number of times that a user can fail to authenticate before the user account is locked. * - ``[security_compliance] lockout_duration = 1800`` - (IntOpt) The number of seconds a user account will be locked when the maximum number of failed authentication attempts is exceeded. * - ``[security_compliance] password_expires_days = <None>`` - (IntOpt) The number of days for which a password will be considered valid before requiring it to be changed. * - ``[security_compliance] password_expires_ignore_user_ids =`` - (StrOpt) User IDs to be ignored when checking if a password is expired. * - ``[security_compliance] unique_last_password_count = 1`` - (IntOpt) Controls the number of previous user password iterations to keep in history, in order to enforce that newly created passwords are unique. * - ``[security_compliance] minimum_password_age = 0`` - (IntOptThe number of days that a password must be used before the user can change it. * - ``[security_compliance] password_regex = <None>`` - (StrOpt) Validate password strength requirements. * - ``[security_compliance] password_regex_description = <None>`` - (StrOpt) Humans language to describe password regular expression. * - ``[token] cache_on_issue = false`` - (BoolOpt) Enable storing issued token data to token validation cache so that first token validation doesn't actually cause full validation cycle. * - ``[endpoint_policy] enabled`` - ``None`` * - ``[token] hash_algorithm`` - ``None`` * - ``[os_inherit]``", * - ``[DEFAULT] use_syslog``,32,1
openstack%2Fnetworking-bgpvpn~master~I9599163db0817b03b433b22f5834af09557d4ff9,openstack/networking-bgpvpn,master,I9599163db0817b03b433b22f5834af09557d4ff9,Updated from global requirements,MERGED,2017-02-27 16:45:09.000000000,2017-02-28 08:57:12.000000000,2017-02-28 08:57:12.000000000,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-02-27 16:45:09.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/e5c7c51ec2402e51d58c699dc28502a05689aa75', 'message': 'Updated from global requirements\n\nChange-Id: I9599163db0817b03b433b22f5834af09557d4ff9\n'}]",0,438606,e5c7c51ec2402e51d58c699dc28502a05689aa75,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I9599163db0817b03b433b22f5834af09557d4ff9
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/06/438606/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e5c7c51ec2402e51d58c699dc28502a05689aa75,openstack/requirements,neutron-lib>=1.2.0 # Apache-2.0,neutron-lib>=1.1.0 # Apache-2.0,1,1
openstack%2Fdragonflow~master~I82972e1b7d57154e0d0f02cff80295d8aa711ecd,openstack/dragonflow,master,I82972e1b7d57154e0d0f02cff80295d8aa711ecd,Updated from global requirements,MERGED,2017-02-27 16:41:57.000000000,2017-02-28 08:56:12.000000000,2017-02-28 08:56:12.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-27 16:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ce65a3a4200aeec1120d032935ed64cfcec53377', 'message': 'Updated from global requirements\n\nChange-Id: I82972e1b7d57154e0d0f02cff80295d8aa711ecd\n'}, {'number': 2, 'created': '2017-02-28 05:38:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/834f05db41a783674f578234aa3c00b2acbdc4d1', 'message': 'Updated from global requirements\n\nChange-Id: I82972e1b7d57154e0d0f02cff80295d8aa711ecd\n'}]",0,438601,834f05db41a783674f578234aa3c00b2acbdc4d1,10,4,2,11131,,,0,"Updated from global requirements

Change-Id: I82972e1b7d57154e0d0f02cff80295d8aa711ecd
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/01/438601/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ce65a3a4200aeec1120d032935ed64cfcec53377,openstack/requirements,neutron-lib>=1.2.0 # Apache-2.0,neutron-lib>=1.1.0 # Apache-2.0,1,1
openstack%2Fkolla-ansible~master~Ide3a90a4882197bf361c794dccccbc195b89e5bb,openstack/kolla-ansible,master,Ide3a90a4882197bf361c794dccccbc195b89e5bb,Update the panko location of site.yml,MERGED,2017-02-27 09:07:22.000000000,2017-02-28 08:54:33.000000000,2017-02-28 03:45:48.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-02-27 09:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3c828b031402ca3cabb6395bc47ee6f1274a5823', 'message': 'Change the panko location\n\nThe panko database type can be mongodb, so the panko container should\nboot after mongodb\n\nChange-Id: Ide3a90a4882197bf361c794dccccbc195b89e5bb\n'}, {'number': 2, 'created': '2017-02-27 09:41:53.000000000', 'files': ['ansible/site.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/37e173d708a15ec0d8f248447733dbd71fa3c04d', 'message': 'Update the panko location of site.yml\n\nThe panko database type can be mongodb, so the panko container should\nboot after mongodb\n\nChange-Id: Ide3a90a4882197bf361c794dccccbc195b89e5bb\nCloses-Bug: #1668206\n'}]",0,438380,37e173d708a15ec0d8f248447733dbd71fa3c04d,9,3,2,22165,,,0,"Update the panko location of site.yml

The panko database type can be mongodb, so the panko container should
boot after mongodb

Change-Id: Ide3a90a4882197bf361c794dccccbc195b89e5bb
Closes-Bug: #1668206
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/80/438380/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/site.yml'],1,3c828b031402ca3cabb6395bc47ee6f1274a5823,,"- name: Apply role panko hosts: panko-api serial: '{{ serial|default(""0"") }}' roles: - { role: panko, tags: panko, when: enable_panko | bool } ","- name: Apply role panko hosts: panko-api serial: '{{ serial|default(""0"") }}' roles: - { role: panko, tags: panko, when: enable_panko | bool } ",8,8
openstack%2Fproject-config~master~I0082c483b849deeffe872a5489c7123c2b2c706c,openstack/project-config,master,I0082c483b849deeffe872a5489c7123c2b2c706c,Remove trove tempest plugin job,MERGED,2017-02-22 16:30:42.000000000,2017-02-28 08:48:42.000000000,2017-02-28 08:48:42.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 9664}]","[{'number': 1, 'created': '2017-02-22 16:30:42.000000000', 'files': ['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c2ffe36eb69d05d37aef7188f5b94fe11e8e672d', 'message': ""Remove trove tempest plugin job\n\nThe tempest trove plugin only has limited testing that has\nduplicated coverage with other testing in trove. There isn't much value\nin continuing to use test resources for this. The plugin is also going\nto be removed from trove also, so removing the job is the first step for\nthis.\n\nNeeded-By: Iccc9e62bcd46c7aa8b67a454a9882f41f743f332\nChange-Id: I0082c483b849deeffe872a5489c7123c2b2c706c\n""}]",0,437019,c2ffe36eb69d05d37aef7188f5b94fe11e8e672d,8,4,1,5196,,,0,"Remove trove tempest plugin job

The tempest trove plugin only has limited testing that has
duplicated coverage with other testing in trove. There isn't much value
in continuing to use test resources for this. The plugin is also going
to be removed from trove also, so removing the job is the first step for
this.

Needed-By: Iccc9e62bcd46c7aa8b67a454a9882f41f743f332
Change-Id: I0082c483b849deeffe872a5489c7123c2b2c706c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/19/437019/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,c2ffe36eb69d05d37aef7188f5b94fe11e8e672d,,," name: '{pipeline}-tempest-dsvm-trove-{node}{suffix}' node: '{node}' wrappers: - build-timeout: timeout: 180 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_REGEX=""database"" export DEVSTACK_LOCAL_CONFIG=""enable_plugin trove git://git.openstack.org/openstack/trove"" # use tempest plugin (copied from ironic.yaml) if [[ ""$ZUUL_BRANCH"" != ""master"" ]] ; then # if this isn't a patch against master, then # fetch master to install the plugin export DEVSTACK_LOCAL_CONFIG+=$'\n'""TEMPEST_PLUGINS=git+git://git.openstack.org/openstack/trove"" else # on master, use the local change, so we can pick up any changes to the plugin export DEVSTACK_LOCAL_CONFIG+=$'\n'""TEMPEST_PLUGINS=/opt/stack/new/trove"" fi export PROJECTS=""openstack/trove-dashboard $PROJECTS"" export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: - '{pipeline}-tempest-dsvm-trove-{node}{suffix}' - '{pipeline}-tempest-dsvm-trove-{node}{suffix}'",0,52
openstack%2Ffuel-library~master~I52e49ab9d866891a81d3c08b82c50c8addd34786,openstack/fuel-library,master,I52e49ab9d866891a81d3c08b82c50c8addd34786,Enable proxy headers parsing,MERGED,2017-02-27 11:34:39.000000000,2017-02-28 08:47:31.000000000,2017-02-28 08:44:08.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 16771}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-27 11:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8355d7cfe40e2e09d89990c0f39a70a2d193b6a7', 'message': 'Enable proxy headers parsing\n\nAs heat is placed behind the proxy we need to enable\nproxy headers parsing, so heat is aware about about\nprotocol used to connect to endpoint.\n\nChange-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786\nCloses-Bug: #1668227\n'}, {'number': 2, 'created': '2017-02-27 13:17:34.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5035fd35578326918beb5d01655d7beb90c20fa5', 'message': 'Enable proxy headers parsing\n\nAs heat is placed behind the proxy we need to enable\nproxy headers parsing, so heat is aware about\nprotocol used to connect to endpoint.\n\nChange-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786\nCloses-Bug: #1668227\n'}]",0,438450,5035fd35578326918beb5d01655d7beb90c20fa5,54,13,2,14510,,,0,"Enable proxy headers parsing

As heat is placed behind the proxy we need to enable
proxy headers parsing, so heat is aware about
protocol used to connect to endpoint.

Change-Id: I52e49ab9d866891a81d3c08b82c50c8addd34786
Closes-Bug: #1668227
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/50/438450/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb']",2,8355d7cfe40e2e09d89990c0f39a70a2d193b6a7,bug/1668227," 'sync_db' => primary_controller, 'heat_clients_url' => ""#{public_heat_protocol}://#{public_vip}:8004/v1/%(tenant_id)s"", 'enable_proxy_headers_parsing' => true,"," 'sync_db' => primary_controller, 'heat_clients_url' => ""#{public_heat_protocol}://#{public_vip}:8004/v1/%(tenant_id)s"",",4,2
openstack%2Fproject-config~master~I55d1aa38b2bfeb298bbc926a255374e6f0157fb7,openstack/project-config,master,I55d1aa38b2bfeb298bbc926a255374e6f0157fb7,tripleo/layout: run scenarios on haproxy manifests,MERGED,2017-02-28 05:12:06.000000000,2017-02-28 08:39:46.000000000,2017-02-28 08:39:46.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-28 05:12:06.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a35aa937650442f39989bd709487ff20fe01ca79', 'message': ""tripleo/layout: run scenarios on haproxy manifests\n\nRun TripleO scenarios on haproxy manifests changes, so we don't break\nscenarios if we miss something in the haproxy manifests.\n\nIt will prevent situations like:\nhttps://bugs.launchpad.net/tripleo/+bug/1668493\n\nChange-Id: I55d1aa38b2bfeb298bbc926a255374e6f0157fb7\n""}]",0,438803,a35aa937650442f39989bd709487ff20fe01ca79,8,4,1,3153,,,0,"tripleo/layout: run scenarios on haproxy manifests

Run TripleO scenarios on haproxy manifests changes, so we don't break
scenarios if we miss something in the haproxy manifests.

It will prevent situations like:
https://bugs.launchpad.net/tripleo/+bug/1668493

Change-Id: I55d1aa38b2bfeb298bbc926a255374e6f0157fb7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/438803/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,a35aa937650442f39989bd709487ff20fe01ca79,haproxy/tripleo, - ^manifests/haproxy.*$ - ^manifests/haproxy.*$ - ^manifests/haproxy.*$ - ^manifests/haproxy.*$ - ^manifests/haproxy.*$,,5,0
openstack%2Fproject-config~master~I76abb096426e24683fe8316c2f8e2d7a796dd96e,openstack/project-config,master,I76abb096426e24683fe8316c2f8e2d7a796dd96e,Detect misaligned ':' in zuul/layout.yaml,MERGED,2017-02-27 23:28:11.000000000,2017-02-28 08:34:57.000000000,2017-02-28 08:34:57.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-27 23:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cdba4eb68b764cb4b6599115848cb2d14787273a', 'message': ""Detect misaligned ':' in zuul/layout.yaml\n\nThis came up in I79ced2532d03701f50afc9d2a6e4a6e533e8228a.  I don't\nthink it's actually a problem as the value is stripped.  Certainly the\nzuul config-parser doesn't trip up on it.  So it's just for\nconsistency.\n\nThis found the entries fixed up in in zuul/layout.yaml\n\nChange-Id: I76abb096426e24683fe8316c2f8e2d7a796dd96e\n""}, {'number': 2, 'created': '2017-02-27 23:33:51.000000000', 'files': ['tools/layout-checks.py', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1418d48f82469cc55588864f732865f06cda46ed', 'message': ""Detect misaligned ':' in zuul/layout.yaml\n\nThis came up in I79ced2532d03701f50afc9d2a6e4a6e533e8228a.  I don't\nthink it's actually a problem as the value is stripped.  Certainly the\nzuul config-parser doesn't trip up on it.  So it's just for\nconsistency.\n\nThis found the entries fixed up in in zuul/layout.yaml\n\nChange-Id: I76abb096426e24683fe8316c2f8e2d7a796dd96e\n""}]",0,438735,1418d48f82469cc55588864f732865f06cda46ed,8,3,2,7118,,,0,"Detect misaligned ':' in zuul/layout.yaml

This came up in I79ced2532d03701f50afc9d2a6e4a6e533e8228a.  I don't
think it's actually a problem as the value is stripped.  Certainly the
zuul config-parser doesn't trip up on it.  So it's just for
consistency.

This found the entries fixed up in in zuul/layout.yaml

Change-Id: I76abb096426e24683fe8316c2f8e2d7a796dd96e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/438735/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/layout-checks.py', 'zuul/layout.yaml']",2,cdba4eb68b764cb4b6599115848cb2d14787273a,layout-name-key, - name: ^gate-tripleo-ci-centos-7-scenario.*-multinode-puppet.*$ - name: ^gate-tripleo-ci-centos-7.*-upgrades.*$ - name: ^gate-tripleo-ci-centos-7-scenario001-multinode.*$ - name: ^gate-tripleo-ci-centos-7-scenario002-multinode.*$ - name: ^gate-tripleo-ci-centos-7-scenario003-multinode.*$ - name: ^gate-tripleo-ci-centos-7-scenario004-multinode.*$ - name: ^gate-tripleo-ci-centos-7-scenario005-multinode.*$, - name : ^gate-tripleo-ci-centos-7-scenario.*-multinode-puppet.*$ - name : ^gate-tripleo-ci-centos-7.*-upgrades.*$ - name : ^gate-tripleo-ci-centos-7-scenario001-multinode.*$ - name : ^gate-tripleo-ci-centos-7-scenario002-multinode.*$ - name : ^gate-tripleo-ci-centos-7-scenario003-multinode.*$ - name : ^gate-tripleo-ci-centos-7-scenario004-multinode.*$ - name : ^gate-tripleo-ci-centos-7-scenario005-multinode.*$,16,9
openstack%2Fopenstack-ansible-rsyslog_client~master~Iea783d443af96d9996fd25ea9355f2930d82fb20,openstack/openstack-ansible-rsyslog_client,master,Iea783d443af96d9996fd25ea9355f2930d82fb20,rsyslog client tasks overwriting rsyslog server config,MERGED,2017-02-25 20:29:15.000000000,2017-02-28 08:24:35.000000000,2017-02-28 03:49:21.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 17799}, {'_account_id': 19814}, {'_account_id': 25128}]","[{'number': 1, 'created': '2017-02-25 20:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/7754585c40a5b9a9be9ee92483bdf917032b4963', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n'}, {'number': 2, 'created': '2017-02-25 23:04:36.000000000', 'files': ['tasks/rsyslog_client_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/931b04ed00917dfee250ced5fe55ff462b0d9c2b', 'message': 'rsyslog client tasks overwriting rsyslog server config\n\nwhen rsyslog client role is invoked as part of monitoring agent\ninstallation across all hosts its breaking the rsyslog server.\nAdded conditions not overwrite the rsyslog configs on rsyslog servers.\n\nChange-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20\n'}]",0,438205,931b04ed00917dfee250ced5fe55ff462b0d9c2b,19,5,2,25128,,,0,"rsyslog client tasks overwriting rsyslog server config

when rsyslog client role is invoked as part of monitoring agent
installation across all hosts its breaking the rsyslog server.
Added conditions not overwrite the rsyslog configs on rsyslog servers.

Change-Id: Iea783d443af96d9996fd25ea9355f2930d82fb20
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/05/438205/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rsyslog_client_post_install.yml'],1,7754585c40a5b9a9be9ee92483bdf917032b4963,, when: inventory_hostname not in groups['rsyslog_container'] when: inventory_hostname not in groups['rsyslog_container'],,2,0
openstack%2Fproject-config~master~I3b61f7af032af4c0d5e7490539a95f305bd7e16f,openstack/project-config,master,I3b61f7af032af4c0d5e7490539a95f305bd7e16f,Install python-barbicanclient from git for castellan gate,MERGED,2017-02-27 21:43:44.000000000,2017-02-28 08:09:52.000000000,2017-02-28 08:09:52.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 21:43:44.000000000', 'files': ['jenkins/jobs/castellan.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc43c66e8972f4cca7480245739a6412ee3ee2b6', 'message': 'Install python-barbicanclient from git for castellan gate\n\nPython-barbicanclient is a dependency for castellan, and it\nwould be useful to test the latest features from git, instead\nof waiting for releases.\n\nChange-Id: I3b61f7af032af4c0d5e7490539a95f305bd7e16f\n'}]",0,438712,cc43c66e8972f4cca7480245739a6412ee3ee2b6,7,3,1,8623,,,0,"Install python-barbicanclient from git for castellan gate

Python-barbicanclient is a dependency for castellan, and it
would be useful to test the latest features from git, instead
of waiting for releases.

Change-Id: I3b61f7af032af4c0d5e7490539a95f305bd7e16f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/12/438712/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/castellan.yaml'],1,cc43c66e8972f4cca7480245739a6412ee3ee2b6,castellan," export DEVSTACK_LOCAL_CONFIG+=$'\n'""LIBS_FROM_GIT=python-barbicanclient""",,1,0
openstack%2Fproject-config~master~Ifddbb45e8d83bc20922437ca340e33ae7b514356,openstack/project-config,master,Ifddbb45e8d83bc20922437ca340e33ae7b514356,switch redis legacy tests to non-voting,MERGED,2017-02-27 21:29:49.000000000,2017-02-28 08:05:18.000000000,2017-02-28 08:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 21:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b72cc829dde290035d99a5d37ebb4f5562173cb7', 'message': 'switch redis legacy tests to non-voting\n\nIn trove stable branches, switch the redis job to non-voting.\n\nChange-Id: Ifddbb45e8d83bc20922437ca340e33ae7b514356\n'}, {'number': 2, 'created': '2017-02-27 21:40:09.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1cbaaff18bd7316bfa980b4363286e71a346aa9a', 'message': 'switch redis legacy tests to non-voting\n\nIn trove stable branches, switch the redis job to non-voting.\n\nChange-Id: Ifddbb45e8d83bc20922437ca340e33ae7b514356\n'}]",0,438706,1cbaaff18bd7316bfa980b4363286e71a346aa9a,9,3,2,9664,,,0,"switch redis legacy tests to non-voting

In trove stable branches, switch the redis job to non-voting.

Change-Id: Ifddbb45e8d83bc20922437ca340e33ae7b514356
",git fetch https://review.opendev.org/openstack/project-config refs/changes/06/438706/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b72cc829dde290035d99a5d37ebb4f5562173cb7,, - gate-trove-legacy-scenario-dsvm-redis-nv, - gate-trove-legacy-scenario-dsvm-redis - gate-trove-legacy-scenario-dsvm-redis,1,2
openstack%2Fproject-config~master~Ief3f2b373c6a9b8c6ed2e33a71523ba767dbcd63,openstack/project-config,master,Ief3f2b373c6a9b8c6ed2e33a71523ba767dbcd63,Run containers-oooq jobs on every patch,MERGED,2017-02-24 15:15:33.000000000,2017-02-28 08:01:14.000000000,2017-02-28 08:01:14.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 9592}]","[{'number': 1, 'created': '2017-02-24 15:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/89df732cf261ec0799a3ca6602a5169a7c285244', 'message': 'Run containers-oooq jobs on every patch\n\nChange-Id: Ief3f2b373c6a9b8c6ed2e33a71523ba767dbcd63\n'}, {'number': 2, 'created': '2017-02-27 10:31:43.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/121ca16df45695f95aff059032db28ec8c6fa4d9', 'message': 'Run containers-oooq jobs on every patch\n\nChange-Id: Ief3f2b373c6a9b8c6ed2e33a71523ba767dbcd63\n'}]",1,437944,121ca16df45695f95aff059032db28ec8c6fa4d9,12,5,2,6159,,,0,"Run containers-oooq jobs on every patch

Change-Id: Ief3f2b373c6a9b8c6ed2e33a71523ba767dbcd63
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/437944/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,89df732cf261ec0799a3ca6602a5169a7c285244,,, files: - ^docker/.*$ - ^environments/docker.*$,0,3
openstack%2Fpuppet-keystone~stable%2Focata~Id578980cae370ad46187ea2ced0ae8dada1ef3ee,openstack/puppet-keystone,stable/ocata,Id578980cae370ad46187ea2ced0ae8dada1ef3ee,Fix shibboleth tests,MERGED,2017-02-28 05:17:58.000000000,2017-02-28 07:59:32.000000000,2017-02-28 07:59:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-28 05:17:58.000000000', 'files': ['spec/classes/keystone_federation_shibboleth_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/6d0f1879129eda4c65b626889bc70a373fc9f8de', 'message': 'Fix shibboleth tests\n\nThis patch basically rewrites the shibboleth unit tests. The previous\nversion was not properly running the invalid parameters cases and the\ncases for installing under Red Hat were not properly being exercised.\n\nChange-Id: Id578980cae370ad46187ea2ced0ae8dada1ef3ee\nCloses-Bug: #1667866\n(cherry picked from commit d369e3ab0fdc6d8a69b8a6428deaa89fc9066368)\n'}]",0,438804,6d0f1879129eda4c65b626889bc70a373fc9f8de,6,3,1,3153,,,0,"Fix shibboleth tests

This patch basically rewrites the shibboleth unit tests. The previous
version was not properly running the invalid parameters cases and the
cases for installing under Red Hat were not properly being exercised.

Change-Id: Id578980cae370ad46187ea2ced0ae8dada1ef3ee
Closes-Bug: #1667866
(cherry picked from commit d369e3ab0fdc6d8a69b8a6428deaa89fc9066368)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/04/438804/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/keystone_federation_shibboleth_spec.rb'],1,6d0f1879129eda4c65b626889bc70a373fc9f8de,bug/1667866," let :default_params do { :methods => 'password, token, saml2', :template_order => 331, } shared_examples 'keystone::federation::shibboleth with invalid parameters' do context 'external method' do let (:params) { default_params.merge(:methods => ['external']) } it_raises 'a Puppet::Error', /The external method/ context 'method missing saml2' do let (:params) { default_params.merge(:methods => ['password', 'token', 'oauth1']) } context 'wrong plugin' do let (:params) { default_params.merge(:methods => ['password', 'token', 'oauth1', 'saml2'], :module_plugin => 'keystone.auth.plugins') } it_raises 'a Puppet::Error', /The plugin for saml and shibboleth should be keystone.auth.plugins.mapped.Mapped/ context 'no ports' do let (:params) { default_params.merge(:admin_port => false, :main_port => false) } it_raises 'a Puppet::Error', /No VirtualHost port to configure, please choose at least one./ context 'template port too low' do let(:params) { default_params.merge(:template_order => 330) } it_raises 'a Puppet::Error', /The template order should be greater than 330 and less than 999./ context 'template port too high' do let(:params) { default_params.merge(:template_order => 999) } it_raises 'a Puppet::Error', /The template order should be greater than 330 and less than 999./ shared_examples 'keystone::federation::shibboleth' do let(:pre_condition) do <<-EOS include apache class { 'keystone::wsgi::apache': } EOS end let (:params) { default_params } let (:params) { default_params.merge({ :methods => ['password', 'token', 'saml2', 'somethingelse'], }) } is_expected.to contain_keystone_config('auth/methods').with_value('password,token,saml2,somethingelse') end end end shared_examples 'keystone::federation::shibboleth on RedHat' do context 'with shibboleth package' do let(:pre_condition) do <<-EOS include apache package { 'shibboleth': ensure => present } class { 'keystone::wsgi::apache': } EOS context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it {is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], }) } end end context 'with shibboleth repo' do let(:pre_condition) do <<-EOS include apache yumrepo { 'shibboleth': ensure => present } class { 'keystone::wsgi::apache': } EOS end context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it { is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], }) } end end context 'without repo or package' do context 'with defaults' do let (:params) { default_params } it { is_expected.to_not contain_apache__mod('shib2') } it { is_expected.to_not contain_concat__fragment('configure_shibboleth_on_port_5000') } end context 'with overrides' do let (:params) { default_params.merge({ :admin_port => true, :template_order => 332 }) } it { is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') } it { is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') } it { is_expected.to_not contain_concat__fragment('configure_shibboleth_on_port_35357') } end end end shared_examples 'keystone::federation::shibboleth on Debian' do context 'with defaults' do let (:params) { default_params } it { is_expected.to contain_apache__mod('shib2') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} context ""on #{os}"" do let (:facts) do facts.merge(OSDefaults.get_facts({ :concat_basedir => '/var/lib/puppet/concat' })) end it_behaves_like 'keystone::federation::shibboleth' it_behaves_like 'keystone::federation::shibboleth with invalid parameters' it_behaves_like ""keystone::federation::shibboleth on #{facts[:osfamily]}"" end"," let :params do { :methods => 'password, token, saml2', :template_order => 331 } describe 'with invalid params' do before do params.merge!(:methods => 'external, password, token, oauth1') it_raises 'a Puppet::Error', /The external method should be dropped to avoid any interference with some Apache + Shibboleth SP setups, where a REMOTE_USER env variable is always set, even as an empty value./ before do params.merge!(:methods => 'password, token, oauth1') before do params.merge!(:methods => 'password, token, oauth1, saml2', :module_plugin => 'keystone.auth.plugins') it_raises 'a Puppet:Error', /The plugin for saml and shibboleth should be keystone.auth.plugins.mapped.Mapped/ before do params.merge!(:admin_port => false, :main_port => false) it_raises 'a Puppet:Error', /No VirtualHost port to configure, please choose at least one./ before do params.merge!(:template_port => 330) it_raises 'a Puppet:Error', /The template order should be greater than 330 and less than 999./ before do params.merge!(:template_port => 999) it_raises 'a Puppet:Error', /The template order should be greater than 330 and less than 999./ shared_examples 'Federation Shibboleth' do it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} before do params.merge!({ :admin_port => true }) end is_expected.to contain_keystone_config('auth/methods').with_value('password, token, saml2') is_expected.to contain_keystone_config('auth/saml2').with_value('keystone.auth.plugins.mapped.Mapped') it { is_expected.to contain_class('apache::mod::shib') } it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_5000').with({ :target => ""10-keystone_wsgi_main.conf"", :order => params[:template_order], })} it { is_expected.to contain_concat__fragment('configure_shibboleth_on_port_35357').with({ :target => ""10-keystone_wsgi_admin.conf"", :order => params[:template_order], })} let (:facts) do facts.merge!(OSDefaults.get_facts({})) end it_behaves_like 'Federation Shibboleth'",155,50
openstack%2Fsecurity-doc~master~Ib73396ee7d720de9c68d15ad7b3e7307fd2753a0,openstack/security-doc,master,Ib73396ee7d720de9c68d15ad7b3e7307fd2753a0,Updated from openstack-manuals,MERGED,2017-02-28 06:00:09.000000000,2017-02-28 07:39:57.000000000,2017-02-28 07:39:57.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-28 06:00:09.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/aaae6c34d33e16257c27a07fe9addfb89b68c3d3', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ib73396ee7d720de9c68d15ad7b3e7307fd2753a0\n'}]",0,438811,aaae6c34d33e16257c27a07fe9addfb89b68c3d3,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ib73396ee7d720de9c68d15ad7b3e7307fd2753a0
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/11/438811/1 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,aaae6c34d33e16257c27a07fe9addfb89b68c3d3,openstack/openstack-manuals," discovery, distributed multi-project authorization, and auditing. optimization service for multi-project OpenStack-based clouds. The OpenStack service that provides a multi-project, highly scalable, projects to gain operational insight and visibility, ensuring availability management of shared file systems in a multi-project cloud"," discovery, distributed multi-tenant authorization, and auditing. optimization service for multi-tenant OpenStack-based clouds. The OpenStack service that provides a multi-tenant, highly scalable, tenants to gain operational insight and visibility, ensuring availability management of shared file systems in a multi-tenant cloud",5,5
openstack%2Fos-win~stable%2Focata~Ic9248f44de6ff097b8080a80fd3212eeef6712f6,openstack/os-win,stable/ocata,Ic9248f44de6ff097b8080a80fd3212eeef6712f6,vmutils: set all *DataRoot paths to the same value,MERGED,2017-02-27 08:35:24.000000000,2017-02-28 07:34:21.000000000,2017-02-28 07:34:21.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-02-27 08:35:24.000000000', 'files': ['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/0795dc8818c21903697137e61796c3eae5c2fcb4', 'message': 'vmutils: set all *DataRoot paths to the same value\n\nIn order to maintain consistency with create_vm, update_vm\nshould also set the *DataRoot paths to the same given value.\n\nFurthermore, this will be required for planned VMs, in order to\nprevent having instances running on different compute nodes and\ndifferent storages to have some of the *DataRoot paths pointing to\nthe old compute node.\n\nPartial-Bug: #1663238\n\nChange-Id: Ic9248f44de6ff097b8080a80fd3212eeef6712f6\n(cherry picked from commit 133271f250aeff69792e9fba078a99034a1daf4b)\n'}]",0,438366,0795dc8818c21903697137e61796c3eae5c2fcb4,11,2,1,8213,,,0,"vmutils: set all *DataRoot paths to the same value

In order to maintain consistency with create_vm, update_vm
should also set the *DataRoot paths to the same given value.

Furthermore, this will be required for planned VMs, in order to
prevent having instances running on different compute nodes and
different storages to have some of the *DataRoot paths pointing to
the old compute node.

Partial-Bug: #1663238

Change-Id: Ic9248f44de6ff097b8080a80fd3212eeef6712f6
(cherry picked from commit 133271f250aeff69792e9fba078a99034a1daf4b)
",git fetch https://review.opendev.org/openstack/os-win refs/changes/66/438366/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py']",2,0795dc8818c21903697137e61796c3eae5c2fcb4,bug/1663238, # Created VMs must have their *DataRoot paths in the same location # as the VM's path. vmsetting.LogDataRoot = configuration_root_dir vmsetting.SnapshotDataRoot = configuration_root_dir vmsetting.SuspendDataRoot = configuration_root_dir vmsetting.SwapFileDataRoot = configuration_root_dir update_needed = configuration_root_dir or host_shutdown_action, if snapshot_dir: vmsetting.SnapshotDataRoot = snapshot_dir update_needed = (configuration_root_dir or snapshot_dir or host_shutdown_action),25,8
openstack%2Ftripleo-common~stable%2Focata~I198a33c8608648c7abcafc2cfb1aefb0fb8417e6,openstack/tripleo-common,stable/ocata,I198a33c8608648c7abcafc2cfb1aefb0fb8417e6,Fix wrong args to update manager,MERGED,2017-02-27 22:33:54.000000000,2017-02-28 07:26:07.000000000,2017-02-28 07:03:17.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}]","[{'number': 1, 'created': '2017-02-27 22:33:54.000000000', 'files': ['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/944c16214ffb8259b7a1cd6551169e736a129dfb', 'message': 'Fix wrong args to update manager\n\nThe abort update and clear breakpoints actions were using the wrong\nnumber of arguments to the update manager. This fixes that, and adds\nto the unit tests to detect the problem.\n\nChange-Id: I198a33c8608648c7abcafc2cfb1aefb0fb8417e6\nCloses-Bug: #1668269\n(cherry picked from commit d2ee6d070e755cb77ec8fcddeec56bc97df10b3d)\n'}]",0,438725,944c16214ffb8259b7a1cd6551169e736a129dfb,11,3,1,7065,,,0,"Fix wrong args to update manager

The abort update and clear breakpoints actions were using the wrong
number of arguments to the update manager. This fixes that, and adds
to the unit tests to detect the problem.

Change-Id: I198a33c8608648c7abcafc2cfb1aefb0fb8417e6
Closes-Bug: #1668269
(cherry picked from commit d2ee6d070e755cb77ec8fcddeec56bc97df10b3d)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/25/438725/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py']",2,944c16214ffb8259b7a1cd6551169e736a129dfb,bug/1668269," mock_update_manager.assert_called_once_with( mock_orchestration_client(), mock_compute_client(), self.stack_id, stack_fields={}) mock_update_manager.assert_called_once_with( mock_orchestration_client(), mock_compute_client(), self.stack_id, stack_fields={})",,14,2
openstack%2Fnova~master~If2efd874bb41faf366e4a5ac6075615fe1ad4ed9,openstack/nova,master,If2efd874bb41faf366e4a5ac6075615fe1ad4ed9,Updated from global requirements,MERGED,2017-02-27 01:15:54.000000000,2017-02-28 07:18:17.000000000,2017-02-27 22:58:44.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17292}, {'_account_id': 20040}, {'_account_id': 22056}, {'_account_id': 23871}]","[{'number': 1, 'created': '2017-02-27 01:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ec4cdafb7bbb6f8fd4620786aa041fff25b9a62', 'message': 'Updated from global requirements\n\nChange-Id: If2efd874bb41faf366e4a5ac6075615fe1ad4ed9\n'}, {'number': 2, 'created': '2017-02-27 11:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf1489413fc9a4db76b3da4571d1830da941e26f', 'message': 'Updated from global requirements\n\nChange-Id: If2efd874bb41faf366e4a5ac6075615fe1ad4ed9\n'}, {'number': 3, 'created': '2017-02-27 14:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2aa65d64807be66e5fb190f19791a83aeb6f527', 'message': 'Updated from global requirements\n\nChange-Id: If2efd874bb41faf366e4a5ac6075615fe1ad4ed9\n'}, {'number': 4, 'created': '2017-02-27 18:14:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/63bd4d12573cb1de2a86bc9c51a55454456895d5', 'message': 'Updated from global requirements\n\nChange-Id: If2efd874bb41faf366e4a5ac6075615fe1ad4ed9\n'}]",0,438309,63bd4d12573cb1de2a86bc9c51a55454456895d5,54,15,4,11131,,,0,"Updated from global requirements

Change-Id: If2efd874bb41faf366e4a5ac6075615fe1ad4ed9
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/438309/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1ec4cdafb7bbb6f8fd4620786aa041fff25b9a62,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fnetworking-generic-switch~master~Ic3f5e9182dda51cf91cb38141b659828f3d69959,openstack/networking-generic-switch,master,Ic3f5e9182dda51cf91cb38141b659828f3d69959,Updated from global requirements,MERGED,2017-02-27 16:45:13.000000000,2017-02-28 07:16:56.000000000,2017-02-28 07:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-02-27 16:45:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/4de410da447d937870a55154d0251f5f24cd19ec', 'message': 'Updated from global requirements\n\nChange-Id: Ic3f5e9182dda51cf91cb38141b659828f3d69959\n'}]",0,438607,4de410da447d937870a55154d0251f5f24cd19ec,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ic3f5e9182dda51cf91cb38141b659828f3d69959
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/07/438607/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4de410da447d937870a55154d0251f5f24cd19ec,openstack/requirements,neutron-lib>=1.2.0 # Apache-2.0,neutron-lib>=1.1.0 # Apache-2.0,1,1
openstack%2Fzun~master~If18d3adf39bafd03f22d701edb283c153f9a0aa4,openstack/zun,master,If18d3adf39bafd03f22d701edb283c153f9a0aa4,Add test to enforce object version,MERGED,2017-02-27 13:52:44.000000000,2017-02-28 07:09:13.000000000,2017-02-28 07:09:13.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12175}]","[{'number': 1, 'created': '2017-02-27 13:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/62fac7f2dddb9f8f4562f080df4a177fe61b9b55', 'message': 'Add test to enforce object version\n\nAdd both the testcases and the document\n\nChange-Id: If18d3adf39bafd03f22d701edb283c153f9a0aa4\nCloses-Bug: #1654424\n'}, {'number': 2, 'created': '2017-02-27 14:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2bc56401bbf2601553bd61520cc492c0f0e08548', 'message': 'Add test to enforce object version\n\nAdd both the testcases and the document\n\nChange-Id: If18d3adf39bafd03f22d701edb283c153f9a0aa4\nCloses-Bug: #1654424\n'}, {'number': 3, 'created': '2017-02-28 01:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/68bad80e2847d96d0edfd8fd94263e20c57b4e84', 'message': 'Add test to enforce object version\n\nAdd both the testcases and the document\n\nChange-Id: If18d3adf39bafd03f22d701edb283c153f9a0aa4\nCloses-Bug: #1654424\n'}, {'number': 4, 'created': '2017-02-28 01:39:55.000000000', 'files': ['doc/source/objects.rst', 'zun/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/3a84375531440dcf268c9ab2253d25498ef60ccb', 'message': 'Add test to enforce object version\n\nAdd both the testcases and the document\n\nChange-Id: If18d3adf39bafd03f22d701edb283c153f9a0aa4\nCloses-Bug: #1654424\n'}]",2,438496,3a84375531440dcf268c9ab2253d25498ef60ccb,12,3,4,12297,,,0,"Add test to enforce object version

Add both the testcases and the document

Change-Id: If18d3adf39bafd03f22d701edb283c153f9a0aa4
Closes-Bug: #1654424
",git fetch https://review.opendev.org/openstack/zun refs/changes/96/438496/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/objects.rst', 'zun/tests/unit/objects/test_objects.py']",2,62fac7f2dddb9f8f4562f080df4a177fe61b9b55,bug/1654424,"# Copyright 2015 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import gettext import mock from oslo_versionedobjects import exception as object_exception from oslo_versionedobjects import fields from oslo_versionedobjects import fixture from zun.common import context as zun_context from zun.objects import base from zun.tests import base as test_base gettext.install('zun') @base.ZunObjectRegistry.register class MyObj(base.ZunPersistentObject, base.ZunObject): VERSION = '1.0' fields = {'foo': fields.IntegerField(), 'bar': fields.StringField(), 'missing': fields.StringField(), } def obj_load_attr(self, attrname): setattr(self, attrname, 'loaded!') @base.remotable_classmethod def query(cls, context): obj = cls(context) obj.foo = 1 obj.bar = 'bar' obj.obj_reset_changes() return obj @base.remotable def marco(self, context): return 'polo' @base.remotable def update_test(self, context): if context.project_id == 'alternate': self.bar = 'alternate-context' else: self.bar = 'updated' @base.remotable def save(self, context): self.obj_reset_changes() @base.remotable def refresh(self, context): self.foo = 321 self.bar = 'refreshed' self.obj_reset_changes() @base.remotable def modify_save_modify(self, context): self.bar = 'meow' self.save(context) self.foo = 42 class MyObj2(object): @classmethod def obj_name(cls): return 'MyObj' @base.remotable_classmethod def get(cls, *args, **kwargs): pass @base.ZunObjectRegistry.register_if(False) class TestSubclassedObject(MyObj): fields = {'new_field': fields.StringField()} class _TestObject(object): def test_hydration_type_error(self): primitive = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'zun', 'versioned_object.version': '1.0', 'versioned_object.data': {'foo': 'a'}} self.assertRaises(ValueError, MyObj.obj_from_primitive, primitive) def test_hydration(self): primitive = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'zun', 'versioned_object.version': '1.0', 'versioned_object.data': {'foo': 1}} obj = MyObj.obj_from_primitive(primitive) self.assertEqual(1, obj.foo) def test_hydration_bad_ns(self): primitive = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'foo', 'versioned_object.version': '1.0', 'versioned_object.data': {'foo': 1}} self.assertRaises(object_exception.UnsupportedObjectError, MyObj.obj_from_primitive, primitive) def test_dehydration(self): expected = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'zun', 'versioned_object.version': '1.0', 'versioned_object.data': {'foo': 1}} obj = MyObj(self.context) obj.foo = 1 obj.obj_reset_changes() self.assertEqual(expected, obj.obj_to_primitive()) def test_get_updates(self): obj = MyObj(self.context) self.assertEqual({}, obj.obj_get_changes()) obj.foo = 123 self.assertEqual({'foo': 123}, obj.obj_get_changes()) obj.bar = 'test' self.assertEqual({'foo': 123, 'bar': 'test'}, obj.obj_get_changes()) obj.obj_reset_changes() self.assertEqual({}, obj.obj_get_changes()) def test_object_property(self): obj = MyObj(self.context, foo=1) self.assertEqual(1, obj.foo) def test_object_property_type_error(self): obj = MyObj(self.context) def fail(): obj.foo = 'a' self.assertRaises(ValueError, fail) def test_load(self): obj = MyObj(self.context) self.assertEqual('loaded!', obj.bar) def test_load_in_base(self): @base.ZunObjectRegistry.register_if(False) class Foo(base.ZunPersistentObject, base.ZunObject): fields = {'foobar': fields.IntegerField()} obj = Foo(self.context) # NOTE(danms): Can't use assertRaisesRegexp() because of py26 raised = False ex = None try: obj.foobar except NotImplementedError as e: raised = True ex = e self.assertTrue(raised) self.assertIn('foobar', str(ex)) def test_loaded_in_primitive(self): obj = MyObj(self.context) obj.foo = 1 obj.obj_reset_changes() self.assertEqual('loaded!', obj.bar) expected = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'zun', 'versioned_object.version': '1.0', 'versioned_object.changes': ['bar'], 'versioned_object.data': {'foo': 1, 'bar': 'loaded!'}} self.assertEqual(expected, obj.obj_to_primitive()) def test_changes_in_primitive(self): obj = MyObj(self.context) obj.foo = 123 self.assertEqual(set(['foo']), obj.obj_what_changed()) primitive = obj.obj_to_primitive() self.assertIn('versioned_object.changes', primitive) obj2 = MyObj.obj_from_primitive(primitive) self.assertEqual(set(['foo']), obj2.obj_what_changed()) obj2.obj_reset_changes() self.assertEqual(set(), obj2.obj_what_changed()) def test_unknown_objtype(self): self.assertRaises(object_exception.UnsupportedObjectError, base.ZunObject.obj_class_from_name, 'foo', '1.0') def test_with_alternate_context(self): context1 = zun_context.RequestContext('foo', 'foo') context2 = zun_context.RequestContext('bar', project_id='alternate') obj = MyObj.query(context1) obj.update_test(context2) self.assertEqual('alternate-context', obj.bar) def test_orphaned_object(self): obj = MyObj.query(self.context) obj._context = None self.assertRaises(object_exception.OrphanedObjectError, obj.update_test) def test_changed_1(self): obj = MyObj.query(self.context) obj.foo = 123 self.assertEqual(set(['foo']), obj.obj_what_changed()) obj.update_test(self.context) self.assertEqual(set(['foo', 'bar']), obj.obj_what_changed()) self.assertEqual(123, obj.foo) def test_changed_2(self): obj = MyObj.query(self.context) obj.foo = 123 self.assertEqual(set(['foo']), obj.obj_what_changed()) obj.save(self.context) self.assertEqual(set([]), obj.obj_what_changed()) self.assertEqual(123, obj.foo) def test_changed_3(self): obj = MyObj.query(self.context) obj.foo = 123 self.assertEqual(set(['foo']), obj.obj_what_changed()) obj.refresh(self.context) self.assertEqual(set([]), obj.obj_what_changed()) self.assertEqual(321, obj.foo) self.assertEqual('refreshed', obj.bar) def test_changed_4(self): obj = MyObj.query(self.context) obj.bar = 'something' self.assertEqual(set(['bar']), obj.obj_what_changed()) obj.modify_save_modify(self.context) self.assertEqual(set(['foo']), obj.obj_what_changed()) self.assertEqual(42, obj.foo) self.assertEqual('meow', obj.bar) def test_static_result(self): obj = MyObj.query(self.context) self.assertEqual('bar', obj.bar) result = obj.marco(self.context) self.assertEqual('polo', result) def test_updates(self): obj = MyObj.query(self.context) self.assertEqual(1, obj.foo) obj.update_test(self.context) self.assertEqual('updated', obj.bar) def test_base_attributes(self): dt = datetime.datetime(1955, 11, 5) datatime = fields.DateTimeField() obj = MyObj(self.context) obj.created_at = dt obj.updated_at = dt expected = {'versioned_object.name': 'MyObj', 'versioned_object.namespace': 'zun', 'versioned_object.version': '1.0', 'versioned_object.changes': ['created_at', 'updated_at'], 'versioned_object.data': {'created_at': datatime.stringify(dt), 'updated_at': datatime.stringify(dt)} } actual = obj.obj_to_primitive() # versioned_object.changes is built from a set and order is undefined self.assertEqual(sorted(expected['versioned_object.changes']), sorted(actual['versioned_object.changes'])) del expected['versioned_object.changes'], actual['versioned_object.changes'] self.assertEqual(expected, actual) def test_contains(self): obj = MyObj(self.context) self.assertNotIn('foo', obj) obj.foo = 1 self.assertIn('foo', obj) self.assertNotIn('does_not_exist', obj) def test_obj_attr_is_set(self): obj = MyObj(self.context, foo=1) self.assertTrue(obj.obj_attr_is_set('foo')) self.assertFalse(obj.obj_attr_is_set('bar')) self.assertRaises(AttributeError, obj.obj_attr_is_set, 'bang') def test_get(self): obj = MyObj(self.context, foo=1) # Foo has value, should not get the default self.assertEqual(1, getattr(obj, 'foo', 2)) # Foo has value, should return the value without error self.assertEqual(1, getattr(obj, 'foo')) # Bar without a default should lazy-load self.assertEqual('loaded!', getattr(obj, 'bar')) # Bar now has a default, but loaded value should be returned self.assertEqual('loaded!', getattr(obj, 'bar', 'not-loaded')) # Invalid attribute should raise AttributeError self.assertFalse(hasattr(obj, 'nothing')) def test_object_inheritance(self): base_fields = list(base.ZunPersistentObject.fields.keys()) myobj_fields = ['foo', 'bar', 'missing'] + base_fields myobj3_fields = ['new_field'] self.assertTrue(issubclass(TestSubclassedObject, MyObj)) self.assertEqual(len(MyObj.fields), len(myobj_fields)) self.assertEqual(set(MyObj.fields.keys()), set(myobj_fields)) self.assertEqual(len(TestSubclassedObject.fields), len(myobj_fields) + len(myobj3_fields)) self.assertEqual(set(TestSubclassedObject.fields.keys()), set(myobj_fields) | set(myobj3_fields)) def test_get_changes(self): obj = MyObj(self.context) self.assertEqual({}, obj.obj_get_changes()) obj.foo = 123 self.assertEqual({'foo': 123}, obj.obj_get_changes()) obj.bar = 'test' self.assertEqual({'foo': 123, 'bar': 'test'}, obj.obj_get_changes()) obj.obj_reset_changes() self.assertEqual({}, obj.obj_get_changes()) def test_obj_fields(self): @base.ZunObjectRegistry.register_if(False) class TestObj(base.ZunPersistentObject, base.ZunObject): fields = {'foo': fields.IntegerField()} obj_extra_fields = ['bar'] @property def bar(self): return 'this is bar' obj = TestObj(self.context) self.assertEqual(set(['created_at', 'updated_at', 'foo', 'bar']), set(obj.obj_fields)) def test_obj_constructor(self): obj = MyObj(self.context, foo=123, bar='abc') self.assertEqual(123, obj.foo) self.assertEqual('abc', obj.bar) self.assertEqual(set(['foo', 'bar']), obj.obj_what_changed()) class TestObject(test_base.TestCase, _TestObject): pass # This is a static dictionary that holds all fingerprints of the versioned # objects registered with the ZunRegistry. Each fingerprint contains # the version of the object and an md5 hash of RPC-critical parts of the # object (fields and remotable methods). If either the version or hash # change, the static tree needs to be updated. # For more information on object version testing, read # http://docs.openstack.org/developer/zun/objects.html object_data = { 'ResourceProvider': '1.0-92b427359d5a4cf9ec6c72cbe630ee24', 'Image': '1.0-0b976be24f4f6ee0d526e5c981ce0633', 'MyObj': '1.0-34c4b1aadefd177b13f9a2f894cc23cd', 'NUMANode':'1.0-cba878b70b2f8b52f1e031b41ac13b4e', 'NUMATopology':'1.0-b54086eda7e4b2e6145ecb6ee2c925ab', 'ZunService':'1.0-2a19ab9987a746621b2ada02d8aadf22', 'ResourceClass':'1.0-2c41abea55d0f7cb47a97bdb345b37fd', 'Container':'1.11-ddffeb42cb5472decab6d73534fe103f', } class TestObjectVersions(test_base.TestCase): def test_versions(self): # Test the versions of current objects with the static tree above. # This ensures that any incompatible object changes require a version # bump. classes = base.ZunObjectRegistry.obj_classes() checker = fixture.ObjectVersionChecker(obj_classes=classes) expected, actual = checker.test_hashes(object_data) self.assertEqual(expected, actual, ""Fields or remotable methods in some objects have "" ""changed. Make sure the versions of the objects has "" ""been bumped, and update the hashes in the static "" ""fingerprints tree (object_data). For more "" ""information, read http://docs.openstack.org/"" ""developer/zun/objects.html."") class TestObjectSerializer(test_base.TestCase): def test_object_serialization(self): ser = base.ZunObjectSerializer() obj = MyObj(self.context) primitive = ser.serialize_entity(self.context, obj) self.assertIn('versioned_object.name', primitive) obj2 = ser.deserialize_entity(self.context, primitive) self.assertIsInstance(obj2, MyObj) self.assertEqual(self.context, obj2._context) def test_object_serialization_iterables(self): ser = base.ZunObjectSerializer() obj = MyObj(self.context) for iterable in (list, tuple, set): thing = iterable([obj]) primitive = ser.serialize_entity(self.context, thing) self.assertEqual(1, len(primitive)) for item in primitive: self.assertFalse(isinstance(item, base.ZunObject)) thing2 = ser.deserialize_entity(self.context, primitive) self.assertEqual(1, len(thing2)) for item in thing2: self.assertIsInstance(item, MyObj) @mock.patch('zun.objects.base.ZunObject.indirection_api') def _test_deserialize_entity_newer(self, obj_version, backported_to, mock_indirection_api, my_version='1.6'): ser = base.ZunObjectSerializer() mock_indirection_api.object_backport_versions.side_effect \ = NotImplementedError() mock_indirection_api.object_backport.return_value = 'backported' @base.ZunObjectRegistry.register class MyTestObj(MyObj): VERSION = my_version obj = MyTestObj() obj.VERSION = obj_version primitive = obj.obj_to_primitive() result = ser.deserialize_entity(self.context, primitive) if backported_to is None: self.assertFalse(mock_indirection_api.object_backport.called) else: self.assertEqual('backported', result) mock_indirection_api.object_backport.assert_called_with( self.context, primitive, backported_to) def test_deserialize_entity_newer_version_backports_level1(self): ""Test object with unsupported (newer) version"" self._test_deserialize_entity_newer('11.5', '1.6') def test_deserialize_entity_newer_version_backports_level2(self): ""Test object with unsupported (newer) version"" self._test_deserialize_entity_newer('1.25', '1.6') def test_deserialize_entity_same_revision_does_not_backport(self): ""Test object with supported revision"" self._test_deserialize_entity_newer('1.6', None) def test_deserialize_entity_newer_revision_does_not_backport_zero(self): ""Test object with supported revision"" self._test_deserialize_entity_newer('1.6.0', None) def test_deserialize_entity_newer_revision_does_not_backport(self): ""Test object with supported (newer) revision"" self._test_deserialize_entity_newer('1.6.1', None) def test_deserialize_entity_newer_version_passes_revision(self): ""Test object with unsupported (newer) version and revision"" self._test_deserialize_entity_newer('1.7', '1.6.1', my_version='1.6.1') ",,578,0
openstack%2Ftripleo-common~stable%2Focata~Ie8acc73c391469b48f3fb04b013562357a70d25f,openstack/tripleo-common,stable/ocata,Ie8acc73c391469b48f3fb04b013562357a70d25f,Just set the breakpoints on args passed to heat update,MERGED,2017-02-21 16:23:51.000000000,2017-02-28 07:03:31.000000000,2017-02-28 07:03:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7065}]","[{'number': 1, 'created': '2017-02-21 16:23:51.000000000', 'files': ['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c01a1436b63cf150a3e0841904dfff3861c08b8f', 'message': 'Just set the breakpoints on args passed to heat update\n\nRather than update the plan with the breakpoints, just add the\nbreakpoints to the environment passed to the heat update.\n\nChange-Id: Ie8acc73c391469b48f3fb04b013562357a70d25f\nCloses-Bug: #1663635\n(cherry picked from commit 999ceebf56ac8e55d89cfdcec8b105a3cdc8c3ce)\n'}]",0,436536,c01a1436b63cf150a3e0841904dfff3861c08b8f,8,3,1,11166,,,0,"Just set the breakpoints on args passed to heat update

Rather than update the plan with the breakpoints, just add the
breakpoints to the environment passed to the heat update.

Change-Id: Ie8acc73c391469b48f3fb04b013562357a70d25f
Closes-Bug: #1663635
(cherry picked from commit 999ceebf56ac8e55d89cfdcec8b105a3cdc8c3ce)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/36/436536/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py']",2,c01a1436b63cf150a3e0841904dfff3861c08b8f,bug/1663635," timeout_mins=1, environment={ 'resource_registry': { 'resources': { '*': { '*': {'UpdateDeployment': {'hooks': 'pre-update'}} } } } })", timeout_mins=1 ),26,14
openstack%2Finstack-undercloud~master~I91edc20ae9ffc9451de53403d6b76be1cd542658,openstack/instack-undercloud,master,I91edc20ae9ffc9451de53403d6b76be1cd542658,Purge /var/lib/os-collect-config,MERGED,2017-02-13 03:35:31.000000000,2017-02-28 07:03:08.000000000,2017-02-28 07:03:08.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-13 03:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/a7b7988af71824f5250756c92cee4ea64ab35972', 'message': 'Purge /var/lib/os-collect-config\n\nIf os-collect-config is run manually on the undercloud node stale\ndata can collect in /var/lib/os-collect-config/ which could override\nand prevent configuration changes during future undercloud updates\nor upgrades.\n\nos-apply-config called during an instack-undercloud run will reference\nthe data in /var/lib/os-collect-config/ if available; however, this\ndata is not refreshed by instack-undercloud and can be stale.\n\nChange-Id: I91edc20ae9ffc9451de53403d6b76be1cd542658\n'}, {'number': 2, 'created': '2017-02-13 05:07:03.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/7490384c5b5a674b2e2d1dab9f749d6f3f4da083', 'message': 'Purge /var/lib/os-collect-config\n\nIf os-collect-config is run manually on the undercloud node stale\ndata can collect in /var/lib/os-collect-config/ which could override\nand prevent configuration changes during future undercloud updates\nor upgrades.\n\nos-apply-config called during an instack-undercloud run will reference\nthe data in /var/lib/os-collect-config/ if available; however, this\ndata is not refreshed by instack-undercloud and can be stale.\n\nCloses-Bug: 1664111\nChange-Id: I91edc20ae9ffc9451de53403d6b76be1cd542658\n'}]",0,432830,7490384c5b5a674b2e2d1dab9f749d6f3f4da083,21,4,2,19736,,,0,"Purge /var/lib/os-collect-config

If os-collect-config is run manually on the undercloud node stale
data can collect in /var/lib/os-collect-config/ which could override
and prevent configuration changes during future undercloud updates
or upgrades.

os-apply-config called during an instack-undercloud run will reference
the data in /var/lib/os-collect-config/ if available; however, this
data is not refreshed by instack-undercloud and can be stale.

Closes-Bug: 1664111
Change-Id: I91edc20ae9ffc9451de53403d6b76be1cd542658
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/30/432830/2 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,a7b7988af71824f5250756c92cee4ea64ab35972,bug/1664111,"def _clean_os_collect_config(): occ_dir = '/var/lib/os-collect-config' args = ['sudo', 'rm', '-fr', occ_dir] _run_command(args, name='Clean os-collect-config') _clean_os_collect_config()",,7,0
openstack%2Frequirements~stable%2Fnewton~I5b11a7a4ac3bded7a675b7731d3971b40102d716,openstack/requirements,stable/newton,I5b11a7a4ac3bded7a675b7731d3971b40102d716,update constraint for yaql to new release 1.1.2,MERGED,2017-02-03 14:56:38.000000000,2017-02-28 07:01:55.000000000,2017-02-28 07:01:55.000000000,"[{'_account_id': 3}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-03 14:56:38.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ed4d9e5cb5cbaebbc8ddeb6cb1cca831e1ab25e8', 'message': 'update constraint for yaql to new release 1.1.2\n\nChange-Id: I5b11a7a4ac3bded7a675b7731d3971b40102d716\nmeta:version: 1.1.2\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\n'}]",0,428768,ed4d9e5cb5cbaebbc8ddeb6cb1cca831e1ab25e8,10,5,1,11131,,,0,"update constraint for yaql to new release 1.1.2

Change-Id: I5b11a7a4ac3bded7a675b7731d3971b40102d716
meta:version: 1.1.2
meta:series: newton
meta:release-type: release
meta:announce: openstack-announce@lists.openstack.org
meta:pypi: yes
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/428768/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ed4d9e5cb5cbaebbc8ddeb6cb1cca831e1ab25e8,new-release,yaql===1.1.2,yaql===1.1.1,1,1
openstack%2Ftempest~master~Ibafa745097fa12f5e6d061640009bc5b935ae52a,openstack/tempest,master,Ibafa745097fa12f5e6d061640009bc5b935ae52a,Remove unnecessary wait_for_server_status,MERGED,2017-02-24 07:43:23.000000000,2017-02-28 07:01:50.000000000,2017-02-28 07:01:49.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7350}]","[{'number': 1, 'created': '2017-02-24 07:43:23.000000000', 'files': ['tempest/api/compute/servers/test_server_rescue.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3b9e42e1092cd93477ef52185b67da1975e2cac7', 'message': ""Remove unnecessary wait_for_server_status\n\nIn ServerRescueTestJSON's resource_setup, wait_for_server_status\nis not needed, instead, create_test_server(wait_until='ACTIVE')\nshould be used.\nThis is left over in I9487ddf6db8fda5b5fe6aa3f8787b56b8c865cf5\n\nChange-Id: Ibafa745097fa12f5e6d061640009bc5b935ae52a\n""}]",0,437823,3b9e42e1092cd93477ef52185b67da1975e2cac7,22,3,1,20190,,,0,"Remove unnecessary wait_for_server_status

In ServerRescueTestJSON's resource_setup, wait_for_server_status
is not needed, instead, create_test_server(wait_until='ACTIVE')
should be used.
This is left over in I9487ddf6db8fda5b5fe6aa3f8787b56b8c865cf5

Change-Id: Ibafa745097fa12f5e6d061640009bc5b935ae52a
",git fetch https://review.opendev.org/openstack/tempest refs/changes/23/437823/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_rescue.py'],1,3b9e42e1092cd93477ef52185b67da1975e2cac7,wait_for_server, wait_until='ACTIVE')," wait_until='BUILD') waiters.wait_for_server_status(cls.servers_client, cls.server_id, 'ACTIVE')",1,3
openstack%2Frequirements~stable%2Focata~Id1d29828e7016b7dc86db050e4e21448b8387671,openstack/requirements,stable/ocata,Id1d29828e7016b7dc86db050e4e21448b8387671,update constraint for monasca-common to new release 1.5.0,MERGED,2017-02-16 13:07:03.000000000,2017-02-28 07:01:44.000000000,2017-02-28 07:01:44.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-16 13:07:03.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a56100d1819b36880a1288beef9425345af59a65', 'message': 'update constraint for monasca-common to new release 1.5.0\n\nChange-Id: Id1d29828e7016b7dc86db050e4e21448b8387671\nmeta:version: 1.5.0\nmeta:diff-start: -\nmeta:series: ocata\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Witold Bedyk <witold.bedyk@est.fujitsu.com>\nmeta:release:Commit: Witold Bedyk <witold.bedyk@est.fujitsu.com>\nmeta:release:Change-Id: Ieef7f0d1ba4b3278b3c5f364698c95085d373053\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,434893,a56100d1819b36880a1288beef9425345af59a65,12,6,1,11131,,,0,"update constraint for monasca-common to new release 1.5.0

Change-Id: Id1d29828e7016b7dc86db050e4e21448b8387671
meta:version: 1.5.0
meta:diff-start: -
meta:series: ocata
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Witold Bedyk <witold.bedyk@est.fujitsu.com>
meta:release:Commit: Witold Bedyk <witold.bedyk@est.fujitsu.com>
meta:release:Change-Id: Ieef7f0d1ba4b3278b3c5f364698c95085d373053
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/434893/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a56100d1819b36880a1288beef9425345af59a65,new-release,monasca-common===1.5.0,monasca-common===1.4.0,1,1
openstack%2Fdiskimage-builder~feature%2Fv2~Ic1fdcd74edcb638d91eb96385152dfb82b290c80,openstack/diskimage-builder,feature/v2,Ic1fdcd74edcb638d91eb96385152dfb82b290c80,Fixes fix for #1641157: '-p' might be specified multiple times,ABANDONED,2017-02-24 17:14:35.000000000,2017-02-28 06:56:07.000000000,,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 21741}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-02-24 17:14:35.000000000', 'files': ['diskimage_builder/lib/disk-image-create'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7ce52ac243b99f2a070233e3815cce882e8dcb14', 'message': ""Fixes fix for #1641157: '-p' might be specified multiple times\n\nChange Iabe43982e1606c7ca963a1dd3b23ba47d148ae38 introduces a bug:\nonly the first package specified with '-p' is picked up.\nThis patch fixes this: '-p' can now be specified many times\nwith package lists separated by comma.\n\nChange-Id: Ic1fdcd74edcb638d91eb96385152dfb82b290c80\nSigned-off-by: Andreas Florath <andreas@florath.net>\nCloses-Bug: #1641157\n""}]",0,438010,7ce52ac243b99f2a070233e3815cce882e8dcb14,7,4,1,21741,,,0,"Fixes fix for #1641157: '-p' might be specified multiple times

Change Iabe43982e1606c7ca963a1dd3b23ba47d148ae38 introduces a bug:
only the first package specified with '-p' is picked up.
This patch fixes this: '-p' can now be specified many times
with package lists separated by comma.

Change-Id: Ic1fdcd74edcb638d91eb96385152dfb82b290c80
Signed-off-by: Andreas Florath <andreas@florath.net>
Closes-Bug: #1641157
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/10/438010/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/lib/disk-image-create'],1,7ce52ac243b99f2a070233e3815cce882e8dcb14,bug/1641157," -p) export INSTALL_PACKAGES+="" $(tr "","" "" "" <<< ""$2"")"" ; shift 2 ;;"," -p) IFS="","" read -a _INSTALL_PACKAGES <<< ""$2""; export INSTALL_PACKAGES=( ${INSTALL_PACKAGES[@]} ${_INSTALL_PACKAGES[@]} ) ; shift 2 ;;",1,1
openstack%2Fpython-tripleoclient~stable%2Focata~I74a21d73da95e81c5270f7264c25eaee923ba9ba,openstack/python-tripleoclient,stable/ocata,I74a21d73da95e81c5270f7264c25eaee923ba9ba,Make overcloud image upload honor --image-path,MERGED,2017-02-16 15:33:17.000000000,2017-02-28 06:53:17.000000000,2017-02-28 06:53:17.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 9317}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-16 15:33:17.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a4cb75e80e61ca8b55a1275e91ed4bede65d653a', 'message': 'Make overcloud image upload honor --image-path\n\nThe openstack overcloud image upload command supports --image-path argument\nbut the code assumes that the command is run from ~/images directory and fails\notherwise with errors such a ""The given file overcloud-full.vmlinuz is not a\nregular file"".\n\nWhen the code checks if the image file exists we do not see this error as\n""self._check_file_exists(os.path.join(parsed_args.image_path,\nimage))"" uses the image_path from user passed arguments. However, when\nbuilding the file name for uploading the image, the --image-path is\nneglected.\n\nThis commit adds code to make the image upload command work from\nany directory as long as --image-path option is passed.\n\nCloses-Bug: #1647519\n\nChange-Id: I74a21d73da95e81c5270f7264c25eaee923ba9ba\nCo-Authored-By: Ben Nemec <bnemec@redhat.com>\n(cherry picked from commit 17b5d6cd4299cdc14e43039e8fa906ccb36497fb)\n'}]",0,434975,a4cb75e80e61ca8b55a1275e91ed4bede65d653a,20,5,1,6928,,,0,"Make overcloud image upload honor --image-path

The openstack overcloud image upload command supports --image-path argument
but the code assumes that the command is run from ~/images directory and fails
otherwise with errors such a ""The given file overcloud-full.vmlinuz is not a
regular file"".

When the code checks if the image file exists we do not see this error as
""self._check_file_exists(os.path.join(parsed_args.image_path,
image))"" uses the image_path from user passed arguments. However, when
building the file name for uploading the image, the --image-path is
neglected.

This commit adds code to make the image upload command work from
any directory as long as --image-path option is passed.

Closes-Bug: #1647519

Change-Id: I74a21d73da95e81c5270f7264c25eaee923ba9ba
Co-Authored-By: Ben Nemec <bnemec@redhat.com>
(cherry picked from commit 17b5d6cd4299cdc14e43039e8fa906ccb36497fb)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/75/434975/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,a4cb75e80e61ca8b55a1275e91ed4bede65d653a,image-path," @mock.patch('os.path.isfile') @mock.patch('subprocess.check_call', autospec=True) def test_overcloud_create_images_image_path(self, mock_subprocess_call, mock_isfile): parsed_args = self.check_parser(self.cmd, ['--image-path', '/foo'], []) self.cmd._image_try_update = mock.Mock() mock_isfile.return_value = False self.cmd.take_action(parsed_args) expected = [ mock.call('overcloud-full-vmlinuz', '/foo/overcloud-full.vmlinuz', mock.ANY), mock.call('overcloud-full-initrd', '/foo/overcloud-full.initrd', mock.ANY), mock.call('overcloud-full', '/foo/overcloud-full.qcow2', mock.ANY), mock.call('bm-deploy-kernel', '/foo/ironic-python-agent.kernel', mock.ANY), mock.call('bm-deploy-ramdisk', '/foo/ironic-python-agent.initramfs', mock.ANY), ] self.assertEqual(expected, self.cmd._image_try_update.mock_calls) ",,51,6
openstack%2Fpuppet-tripleo~master~I5533e42c5ba9f72cc70d80489a07e30ee2341198,openstack/puppet-tripleo,master,I5533e42c5ba9f72cc70d80489a07e30ee2341198,Default neutron dhcp_agents_per_network to number of agents,MERGED,2017-02-27 15:17:05.000000000,2017-02-28 06:53:13.000000000,2017-02-28 06:53:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6681}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-27 15:17:05.000000000', 'files': ['releasenotes/notes/calculate-dhcp-agents-per-network-3089c5e7b15f8b7b.yaml', 'manifests/profile/base/neutron.pp', 'spec/classes/tripleo_profile_base_neutron_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/52a68ffc8f060e1961458a524e5861cea02d1c1c', 'message': ""Default neutron dhcp_agents_per_network to number of agents\n\nThis patch will set neutron's dhcp_agents_per_network equal to the\nnumber of deployed neutron DHCP agents unless otherwise explicitly set.\n\nPartial-bug: #1632721\nChange-Id: I5533e42c5ba9f72cc70d80489a07e30ee2341198\n""}]",0,438545,52a68ffc8f060e1961458a524e5861cea02d1c1c,10,5,1,6681,,,0,"Default neutron dhcp_agents_per_network to number of agents

This patch will set neutron's dhcp_agents_per_network equal to the
number of deployed neutron DHCP agents unless otherwise explicitly set.

Partial-bug: #1632721
Change-Id: I5533e42c5ba9f72cc70d80489a07e30ee2341198
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/45/438545/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/calculate-dhcp-agents-per-network-3089c5e7b15f8b7b.yaml', 'manifests/profile/base/neutron.pp', 'spec/classes/tripleo_profile_base_neutron_spec.rb']",3,52a68ffc8f060e1961458a524e5861cea02d1c1c,bug/1632721,"# # Copyright (C) 2016 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # require 'spec_helper' describe 'tripleo::profile::base::neutron' do let :params do { :step => 5, :oslomsg_notify_password => 'foobar', :oslomsg_rpc_password => 'foobar' } end shared_examples_for 'tripleo::profile::base::neutron' do before :each do facts.merge!({ :step => params[:step] }) end context 'when no dhcp agents per network set' do before do params.merge!({ :dhcp_nodes => ['netcont1.localdomain', 'netcont2.localdomain', 'netcont3.localdomain'] }) end it 'should equal the number of dhcp agents' do is_expected.to contain_class('neutron').with(:dhcp_agents_per_network => 3) end end context 'when dhcp agents per network is set' do before do params.merge!({ :dhcp_agents_per_network => 2 }) end it 'should set the the value' do is_expected.to contain_class('neutron').with(:dhcp_agents_per_network => 2) end end context 'when dhcp agents per network is greater than number of agents' do before do params.merge!({ :dhcp_nodes => ['netcont1.localdomain', 'netcont2.localdomain'], :dhcp_agents_per_network => 5 }) end it 'should set value and complain about not enough agents' do is_expected.to contain_class('neutron').with(:dhcp_agents_per_network => 5) end end end on_supported_os.each do |os, facts| context ""on #{os}"" do let(:facts) do facts.merge({ :hostname => 'node.example.com' }) end it_behaves_like 'tripleo::profile::base::neutron' end end end ",,109,0
openstack%2Fpuppet-tripleo~master~I4a71a95efb87a10528df0600277768969a32117b,openstack/puppet-tripleo,master,I4a71a95efb87a10528df0600277768969a32117b,Ironic inspector support,MERGED,2017-02-20 18:54:39.000000000,2017-02-28 06:52:48.000000000,2017-02-28 06:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6159}, {'_account_id': 10239}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-20 18:54:39.000000000', 'files': ['manifests/profile/base/ironic_inspector.pp', 'manifests/profile/base/keystone.pp', 'manifests/profile/base/database/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5fbe3853fbd1e4f22204f452156c2e78f73a5c1c', 'message': 'Ironic inspector support\n\nThis includes a new ironic-inspector profile, and updates\nto the mysql and keystone profiles so that a database\nand endpoints are also created when the inspector\nis enabled.\n\nChange-Id: I4a71a95efb87a10528df0600277768969a32117b\n'}]",0,436143,5fbe3853fbd1e4f22204f452156c2e78f73a5c1c,9,5,1,360,,,0,"Ironic inspector support

This includes a new ironic-inspector profile, and updates
to the mysql and keystone profiles so that a database
and endpoints are also created when the inspector
is enabled.

Change-Id: I4a71a95efb87a10528df0600277768969a32117b
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/43/436143/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/ironic_inspector.pp', 'manifests/profile/base/keystone.pp', 'manifests/profile/base/database/mysql.pp']",3,5fbe3853fbd1e4f22204f452156c2e78f73a5c1c,ironic-inspector," if hiera('ironic_inspector_enabled', false) { include ::ironic::inspector::db::mysql }",,52,0
openstack%2Fnova~stable%2Fnewton~I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f,openstack/nova,stable/newton,I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f,Imported Translations from Zanata,MERGED,2017-02-17 08:45:11.000000000,2017-02-28 06:52:26.000000000,2017-02-28 04:02:56.000000000,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 12898}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-17 08:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca48a0656efba6d521db8f461efcd3b0af07133f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f\n'}, {'number': 2, 'created': '2017-02-18 08:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb53175e4363b7b64557f65a2fd1a017f6cbd394', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f\n'}, {'number': 3, 'created': '2017-02-21 09:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22d99063e8c19f285dedcf4cbf8ccabd2d8a3cf4', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f\n'}, {'number': 4, 'created': '2017-02-27 08:55:50.000000000', 'files': ['nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po'], 'web_link': 'https://opendev.org/openstack/nova/commit/feea820d474c80281f497e13904ac1042bd9b972', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f\n'}]",0,435311,feea820d474c80281f497e13904ac1042bd9b972,40,9,4,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I5951f07f6e00e3fb73b2a783d137c48e8fb3c71f
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/435311/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po']",12,ca48a0656efba6d521db8f461efcd3b0af07133f,zanata/translations,"""Project-Id-Version: nova 14.0.4.dev58\n""""POT-Creation-Date: 2017-02-16 09:51+0000\n""","""Project-Id-Version: nova 14.0.2.dev16\n""""POT-Creation-Date: 2016-10-23 09:20+0000\n""msgid ""libvirt error while requesting blockjob info."" msgstr ""libvirt-Fehler beim Anfordern der blockjob-Informationen."" ",31,62
openstack%2Frequirements~stable%2Fmitaka~Ia4957fb13549c4092cb70714487f618aeaa9c6d0,openstack/requirements,stable/mitaka,Ia4957fb13549c4092cb70714487f618aeaa9c6d0,update constraint for python-openstackclient to new release 2.3.1,MERGED,2017-02-22 05:09:34.000000000,2017-02-28 06:38:34.000000000,2017-02-28 06:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-22 05:09:34.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/808355f7ddd29f834531bfa6ead7ad01fbe37fb6', 'message': 'update constraint for python-openstackclient to new release 2.3.1\n\nChange-Id: Ia4957fb13549c4092cb70714487f618aeaa9c6d0\nmeta:version: 2.3.1\nmeta:diff-start: -\nmeta:series: mitaka\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Dean Troyer <dtroyer@gmail.com>\nmeta:release:Commit: Dean Troyer <dtroyer@gmail.com>\nmeta:release:Change-Id: I26eb9f5fe9bcb1e2eb2d176fedce7ae9e5159164\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Code-Review+1: Alfredo Moralejo <amoralej@redhat.com>\nmeta:release:Code-Review+2: Alan Pevec <alan.pevec@redhat.com>\nmeta:release:Workflow+1: Alan Pevec <alan.pevec@redhat.com>\n'}]",0,436762,808355f7ddd29f834531bfa6ead7ad01fbe37fb6,7,3,1,11131,,,0,"update constraint for python-openstackclient to new release 2.3.1

Change-Id: Ia4957fb13549c4092cb70714487f618aeaa9c6d0
meta:version: 2.3.1
meta:diff-start: -
meta:series: mitaka
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Dean Troyer <dtroyer@gmail.com>
meta:release:Commit: Dean Troyer <dtroyer@gmail.com>
meta:release:Change-Id: I26eb9f5fe9bcb1e2eb2d176fedce7ae9e5159164
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Code-Review+1: Alfredo Moralejo <amoralej@redhat.com>
meta:release:Code-Review+2: Alan Pevec <alan.pevec@redhat.com>
meta:release:Workflow+1: Alan Pevec <alan.pevec@redhat.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/62/436762/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,808355f7ddd29f834531bfa6ead7ad01fbe37fb6,new-release,python-openstackclient===2.3.1,python-openstackclient===2.3.0,1,1
openstack%2Frequirements~stable%2Focata~Ic0439c3a4d43ba2c7a9767667df2143874c20942,openstack/requirements,stable/ocata,Ic0439c3a4d43ba2c7a9767667df2143874c20942,update constraint for mistral to new release 4.0.0,MERGED,2017-02-22 13:47:05.000000000,2017-02-28 06:38:29.000000000,2017-02-28 06:38:29.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-22 13:47:05.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6f433339a50c53a0f8dbdf2ab9e8562c128572dc', 'message': 'update constraint for mistral to new release 4.0.0\n\nChange-Id: Ic0439c3a4d43ba2c7a9767667df2143874c20942\nmeta:version: 4.0.0\nmeta:diff-start: 3.0.0.0rc1\nmeta:series: ocata\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: I4aad8807dc7f0d8b4988432dad952c588a2445d2\nmeta:release:Code-Review+1: Dave McCowan <dmccowan@cisco.com>\nmeta:release:Code-Review+1: Michael Johnson <johnsomor@gmail.com>\nmeta:release:Code-Review+1: Dariusz Smigiel <smigiel.dariusz@gmail.com>\nmeta:release:Code-Review+1: Sylvain Bauza <sbauza@redhat.com>\nmeta:release:Code-Review+1: Richard Jones <r1chardj0n3s@gmail.com>\nmeta:release:Code-Review+1: Kevin Benton <kevin@benton.pub>\nmeta:release:Code-Review+1: Brian Rosmaita <brian.rosmaita@rackspace.com>\nmeta:release:Code-Review+1: Matt Riedemann <mriedem@us.ibm.com>\nmeta:release:Code-Review+1: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+1: Pierre Mathieu <pierre-arthur.mathieu@hpe.com>\nmeta:release:Code-Review+1: Graham Hayes <graham.hayes@hpe.com>\nmeta:release:Code-Review+1: Feilong Wang <flwang@catalyst.net.nz>\nmeta:release:Code-Review+1: Rabi Mishra <ramishra@redhat.com>\nmeta:release:Code-Review+2: Davanum Srinivas (dims) <davanum@gmail.com>\nmeta:release:Code-Review+1: Telles Mota Vidal Nbrega <tenobreg@redhat.com>\nmeta:release:Code-Review+1: Rico Lin <rico.lin.guanyu@gmail.com>\nmeta:release:Code-Review+1: Eric K <ekcs.openstack@gmail.com>\nmeta:release:Code-Review+1: amrith <amrith.kumar@gmail.com>\nmeta:release:Code-Review+1: Ian Cordasco <sigmavirus24@gmail.com>\nmeta:release:Code-Review+1: Vitaly Gridnev <vgridnev@mirantis.com>\nmeta:release:Code-Review+1: Steve McLellan <steven.j.mclellan@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta:release:Workflow+1: Thierry Carrez <thierry@openstack.org>\n'}]",0,436928,6f433339a50c53a0f8dbdf2ab9e8562c128572dc,8,3,1,11131,,,0,"update constraint for mistral to new release 4.0.0

Change-Id: Ic0439c3a4d43ba2c7a9767667df2143874c20942
meta:version: 4.0.0
meta:diff-start: 3.0.0.0rc1
meta:series: ocata
meta:release-type: release
meta:pypi: yes
meta:first: yes
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: I4aad8807dc7f0d8b4988432dad952c588a2445d2
meta:release:Code-Review+1: Dave McCowan <dmccowan@cisco.com>
meta:release:Code-Review+1: Michael Johnson <johnsomor@gmail.com>
meta:release:Code-Review+1: Dariusz Smigiel <smigiel.dariusz@gmail.com>
meta:release:Code-Review+1: Sylvain Bauza <sbauza@redhat.com>
meta:release:Code-Review+1: Richard Jones <r1chardj0n3s@gmail.com>
meta:release:Code-Review+1: Kevin Benton <kevin@benton.pub>
meta:release:Code-Review+1: Brian Rosmaita <brian.rosmaita@rackspace.com>
meta:release:Code-Review+1: Matt Riedemann <mriedem@us.ibm.com>
meta:release:Code-Review+1: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+1: Pierre Mathieu <pierre-arthur.mathieu@hpe.com>
meta:release:Code-Review+1: Graham Hayes <graham.hayes@hpe.com>
meta:release:Code-Review+1: Feilong Wang <flwang@catalyst.net.nz>
meta:release:Code-Review+1: Rabi Mishra <ramishra@redhat.com>
meta:release:Code-Review+2: Davanum Srinivas (dims) <davanum@gmail.com>
meta:release:Code-Review+1: Telles Mota Vidal Nbrega <tenobreg@redhat.com>
meta:release:Code-Review+1: Rico Lin <rico.lin.guanyu@gmail.com>
meta:release:Code-Review+1: Eric K <ekcs.openstack@gmail.com>
meta:release:Code-Review+1: amrith <amrith.kumar@gmail.com>
meta:release:Code-Review+1: Ian Cordasco <sigmavirus24@gmail.com>
meta:release:Code-Review+1: Vitaly Gridnev <vgridnev@mirantis.com>
meta:release:Code-Review+1: Steve McLellan <steven.j.mclellan@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta:release:Workflow+1: Thierry Carrez <thierry@openstack.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/436928/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,6f433339a50c53a0f8dbdf2ab9e8562c128572dc,new-release,mistral===4.0.0,mistral===3.0.2,1,1
openstack%2Ftempest~master~I1be3c16e499ac0131b24b889f17361d4a1835f02,openstack/tempest,master,I1be3c16e499ac0131b24b889f17361d4a1835f02,Remove testing of bdm v1 in boot from volume tests,MERGED,2017-02-27 17:28:58.000000000,2017-02-28 06:36:05.000000000,2017-02-27 20:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 7350}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-27 17:28:58.000000000', 'files': ['tempest/scenario/test_volume_boot_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d571e03b5b67a401e7774988a84df3bef16273ad', 'message': ""Remove testing of bdm v1 in boot from volume tests\n\nThe BDM v1 payload in Nova is really really old, and we don't even\ndocument it anywhere anymore (it's actually unclear if this was ever\ndocumented).\n\nJust use the BDM v2 payload, don't run all these tests twice.\n\nChange-Id: I1be3c16e499ac0131b24b889f17361d4a1835f02\n""}]",0,438638,d571e03b5b67a401e7774988a84df3bef16273ad,9,4,1,2750,,,0,"Remove testing of bdm v1 in boot from volume tests

The BDM v1 payload in Nova is really really old, and we don't even
document it anywhere anymore (it's actually unclear if this was ever
documented).

Just use the BDM v2 payload, don't run all these tests twice.

Change-Id: I1be3c16e499ac0131b24b889f17361d4a1835f02
",git fetch https://review.opendev.org/openstack/tempest refs/changes/38/438638/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_volume_boot_pattern.py'],1,d571e03b5b67a401e7774988a84df3bef16273ad,bdm_v1_rm," bd_map_v2 = [{ 'uuid': source_id, 'source_type': source_type, 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': delete_on_termination}] return {'block_device_mapping_v2': bd_map_v2}"," # NOTE(gfidente): the syntax for block_device_mapping is # dev_name=id:type:size:delete_on_terminate # where type needs to be ""snap"" if the server is booted # from a snapshot, size instead can be safely left empty bd_map = [{ 'device_name': 'vda', '{}_id'.format(source_type): source_id, 'delete_on_termination': str(int(delete_on_termination))}] return {'block_device_mapping': bd_map} class TestVolumeBootPatternV2(TestVolumeBootPattern): def _get_bdm(self, source_id, source_type, delete_on_termination=False): bd_map_v2 = [{ 'uuid': source_id, 'source_type': source_type, 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': delete_on_termination}] return {'block_device_mapping_v2': bd_map_v2}",7,21
openstack%2Fnova~master~Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,openstack/nova,master,Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,Ignore deleted services in minimum version calculation,MERGED,2017-02-27 16:17:10.000000000,2017-02-28 06:31:19.000000000,2017-02-27 19:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-27 16:17:10.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c79770e615799cd4457ac603dcad4fb3452fe2bc', 'message': 'Ignore deleted services in minimum version calculation\n\nWhen we go to detect the minimum version for a given service, we\nshould ignore any deleted services. Without this, we will return\nthe minimum version of all records, including those that have been\ndeleted with ""nova service-delete"". This patch filters deleted\nservices from the query.\n\nCloses-Bug: #1668310\nChange-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b\n'}]",0,438578,c79770e615799cd4457ac603dcad4fb3452fe2bc,18,5,1,4393,,,0,"Ignore deleted services in minimum version calculation

When we go to detect the minimum version for a given service, we
should ignore any deleted services. Without this, we will return
the minimum version of all records, including those that have been
deleted with ""nova service-delete"". This patch filters deleted
services from the query.

Closes-Bug: #1668310
Change-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/438578/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,c79770e615799cd4457ac603dcad4fb3452fe2bc,bug/1668310, filter(models.Service.deleted == 0).\,,5,0
openstack%2Fkolla-ansible~master~I350ee69b0eca7a1763bb7eab34f874d7e22c1340,openstack/kolla-ansible,master,I350ee69b0eca7a1763bb7eab34f874d7e22c1340,Add until in restart nova libvirt task,MERGED,2017-02-26 08:59:32.000000000,2017-02-28 06:26:21.000000000,2017-02-28 06:26:21.000000000,"[{'_account_id': 3}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-26 08:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9e12cb40bad635e84b0238360cbe2a5fbc03631f', 'message': 'Add until in restart nova libvirt task\n\nretries only works with until.\n\nChange-Id: I350ee69b0eca7a1763bb7eab34f874d7e22c1340\nCloses-bug: #1668023\n'}, {'number': 2, 'created': '2017-02-26 09:36:55.000000000', 'files': ['ansible/roles/nova/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/242c559a044ede8c20134ba40f6643719498c6a2', 'message': 'Add until in restart nova libvirt task\n\nretries only works with until.\n\nChange-Id: I350ee69b0eca7a1763bb7eab34f874d7e22c1340\nCloses-bug: #1668023\n'}]",0,438237,242c559a044ede8c20134ba40f6643719498c6a2,10,4,2,7488,,,0,"Add until in restart nova libvirt task

retries only works with until.

Change-Id: I350ee69b0eca7a1763bb7eab34f874d7e22c1340
Closes-bug: #1668023
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/37/438237/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/handlers/main.yml'],1,9e12cb40bad635e84b0238360cbe2a5fbc03631f,bug/1668023, retister: restart_nova_libvirt until: restart_nova_libvirt | success,,2,0
openstack%2Fpuppet-oslo~master~I7ccd995ef01c2d54427684718adba054260fdd52,openstack/puppet-oslo,master,I7ccd995ef01c2d54427684718adba054260fdd52,Remove rpc_backend due to duplicate declaration when dual backends,MERGED,2017-02-16 20:50:27.000000000,2017-02-28 06:23:59.000000000,2017-02-28 06:23:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 18795}, {'_account_id': 20523}]","[{'number': 1, 'created': '2017-02-16 20:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-oslo/commit/be2b041f6c74c0a823efc33e85c776f534fbabea', 'message': 'Remove rpc_backend due to duplicate declaration when dual backends\n\nChange-Id: I7ccd995ef01c2d54427684718adba054260fdd52\n'}, {'number': 2, 'created': '2017-02-27 19:51:02.000000000', 'files': ['spec/defines/oslo_messaging_amqp_spec.rb', 'manifests/messaging/amqp.pp'], 'web_link': 'https://opendev.org/openstack/puppet-oslo/commit/12d80eb63e133337db14f7bef0a870902e0733ab', 'message': 'Remove rpc_backend due to duplicate declaration when dual backends\n\nThis patch:\n* Removes the [DEFAULT] rpc_backend as it lead to a duplicate\n  declaration when dual oslo.messaging backends were used\n* Removes the conversion of pre_settled as it was incorrect\n  for the multiple line MultStrOpt value\n\nChange-Id: I7ccd995ef01c2d54427684718adba054260fdd52\n'}]",1,435105,12d80eb63e133337db14f7bef0a870902e0733ab,28,6,2,20523,,,0,"Remove rpc_backend due to duplicate declaration when dual backends

This patch:
* Removes the [DEFAULT] rpc_backend as it lead to a duplicate
  declaration when dual oslo.messaging backends were used
* Removes the conversion of pre_settled as it was incorrect
  for the multiple line MultStrOpt value

Change-Id: I7ccd995ef01c2d54427684718adba054260fdd52
",git fetch https://review.opendev.org/openstack/puppet-oslo refs/changes/05/435105/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/oslo_messaging_amqp_spec.rb', 'manifests/messaging/amqp.pp']",2,be2b041f6c74c0a823efc33e85c776f534fbabea,amqp-opts," 'oslo_messaging_amqp/pre_settled' => { value => any2array($pre_settled) },"," 'oslo_messaging_amqp/pre_settled' => { value => join(any2array($pre_settled),',') }, 'DEFAULT/rpc_backend' => { value => 'amqp' },",4,4
openstack%2Fmasakari~master~I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0,openstack/masakari,master,I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0,Prevent 404 error when adding reserved_host to aggregate,MERGED,2017-02-23 10:05:26.000000000,2017-02-28 06:17:06.000000000,2017-02-27 10:15:28.000000000,"[{'_account_id': 3}, {'_account_id': 8988}, {'_account_id': 12950}, {'_account_id': 23226}]","[{'number': 1, 'created': '2017-02-23 10:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/bdc0229963db2464cb0a32368eaed1069566c41d', 'message': 'Prevent 404 error when adding reserved_host to aggregate\n\nWhen host-failure occurs, masakari-engine adds reserve_host\nto aggregate.\nHowever, when masakari-engine adds reserved_host,\nmasakari-engine passes an aggregate_name to novaclient.\nThis patch is modified so that masakari-engine passes\naggregate_id instead of aggregate_name to novaclient.\n\nChange-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0\nCloses-Bug: #1667246\n'}, {'number': 2, 'created': '2017-02-24 04:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/82ecbfb21b2481cd88a0f9f11695f414302f7e70', 'message': 'Prevent 404 error when adding reserved_host to aggregate\n\nWhen host-failure occurs, masakari-engine adds reserve_host\nto aggregate.\nHowever, when masakari-engine adds reserved_host,\nmasakari-engine passes an aggregate_name to novaclient.\nThis patch is modified so that masakari-engine passes\naggregate_id instead of aggregate_name to novaclient.\n\nChange-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0\nCloses-Bug: #1667246\n'}, {'number': 3, 'created': '2017-02-27 08:00:43.000000000', 'files': ['masakari/tests/unit/fakes.py', 'masakari/engine/drivers/taskflow/host_failure.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py', 'masakari/tests/unit/compute/test_nova.py', 'masakari/compute/nova.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/7415951c46e21297a1f8a3c878595cd399669831', 'message': 'Prevent 404 error when adding reserved_host to aggregate\n\nWhen host-failure occurs, masakari-engine adds reserve_host\nto aggregate.\nHowever, when masakari-engine adds reserved_host,\nmasakari-engine passes an aggregate_name to novaclient.\nThis patch is modified so that masakari-engine passes\naggregate_id instead of aggregate_name to novaclient.\n\nChange-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0\nCloses-Bug: #1667246\n'}]",2,437312,7415951c46e21297a1f8a3c878595cd399669831,19,4,3,23226,,,0,"Prevent 404 error when adding reserved_host to aggregate

When host-failure occurs, masakari-engine adds reserve_host
to aggregate.
However, when masakari-engine adds reserved_host,
masakari-engine passes an aggregate_name to novaclient.
This patch is modified so that masakari-engine passes
aggregate_id instead of aggregate_name to novaclient.

Change-Id: I669b19dea04c8ebb3a27a8ae746ae4c3f88d66f0
Closes-Bug: #1667246
",git fetch https://review.opendev.org/openstack/masakari refs/changes/12/437312/3 && git format-patch -1 --stdout FETCH_HEAD,['masakari/engine/drivers/taskflow/host_failure.py'],1,bdc0229963db2464cb0a32368eaed1069566c41d,bug/1667246," context, reserved_host.name, aggregate.id)"," context, reserved_host.name, aggregate.name)",1,1
openstack%2Fglance_store~master~I53fba2317b4621488cb602c7f9f7b231f2dd80d7,openstack/glance_store,master,I53fba2317b4621488cb602c7f9f7b231f2dd80d7,Fix SafeConfigParser DeprecationWarning in Python 3.2+,MERGED,2016-09-11 08:57:28.000000000,2017-02-28 06:13:48.000000000,2017-02-28 06:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6484}, {'_account_id': 12807}, {'_account_id': 21722}, {'_account_id': 22255}, {'_account_id': 22448}, {'_account_id': 22752}, {'_account_id': 22834}]","[{'number': 1, 'created': '2016-09-11 08:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/c2b238d2a63af671d781215876ffcde7234952c9', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 2, 'created': '2016-09-11 09:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/a41e795912afa6b66461bb4ae1646912df89c909', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 3, 'created': '2016-09-11 11:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/6ed4a5ac8bce0691269ee63a84243019649a4a06', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 4, 'created': '2016-09-21 06:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/e0187bf3ee092c097dde294ac40ffcd251fc2812', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 5, 'created': '2016-10-12 06:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/10211016e4ed13a6cb6d9fd9a1202bf18def7961', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 6, 'created': '2016-10-12 12:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/fe803adf9eaadc8c66287932d8a48442d9bd96a2', 'message': 'Change SafeConfigParser into ConfigParser\n\nSafeConfigParser supports interpolation on top of ConfigParser\nin Python 2, and SafeConfigParser is deprecated in Python 3.2.\nUse ConfigParser directly instead.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 7, 'created': '2017-01-06 05:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/32a91756bdad7ef6cae44a4d670d6d9993aad92c', 'message': 'Fix SafeConfigParser DeprecationWarning in Python 3.2+\n\nSafeConfigParser is deprecated in Python 3.2 and log warning\nlike "" DeprecationWarning: The SafeConfigParser class has\nbeen renamed to ConfigParser in Python 3.2. This alias will be\nremoved in future versions. Use ConfigParser directly instead.""\nSo use ConfigParser in Python 3.2+.\n\nWe don\'t support Python 2.6 now, so don\'t need set dict_type manually.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}, {'number': 8, 'created': '2017-01-19 06:10:09.000000000', 'files': ['glance_store/_drivers/swift/utils.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/93f5570bde937b771e0eac5d056889204770f223', 'message': 'Fix SafeConfigParser DeprecationWarning in Python 3.2+\n\nSafeConfigParser is deprecated in Python 3.2 and log warning\nlike "" DeprecationWarning: The SafeConfigParser class has\nbeen renamed to ConfigParser in Python 3.2. This alias will be\nremoved in future versions. Use ConfigParser directly instead.""\nSo use ConfigParser in Python 3.2+.\n\nWe don\'t support Python 2.6 now, so don\'t need set dict_type manually.\n\nCloses-Bug: #1618666\nChange-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7\n'}]",3,368409,93f5570bde937b771e0eac5d056889204770f223,40,9,8,22834,,,0,"Fix SafeConfigParser DeprecationWarning in Python 3.2+

SafeConfigParser is deprecated in Python 3.2 and log warning
like "" DeprecationWarning: The SafeConfigParser class has
been renamed to ConfigParser in Python 3.2. This alias will be
removed in future versions. Use ConfigParser directly instead.""
So use ConfigParser in Python 3.2+.

We don't support Python 2.6 now, so don't need set dict_type manually.

Closes-Bug: #1618666
Change-Id: I53fba2317b4621488cb602c7f9f7b231f2dd80d7
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/09/368409/8 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/_drivers/swift/utils.py'],1,c2b238d2a63af671d781215876ffcde7234952c9,bug/1618666,"CONFIG = configparser.ConfigParser(defaults=_config_defaults,","CONFIG = configparser.SafeConfigParser(defaults=_config_defaults,",1,1
openstack%2Ftempest~master~I1a614942e25af26fedc720e5ebf8f800e0c54138,openstack/tempest,master,I1a614942e25af26fedc720e5ebf8f800e0c54138,Fix subunit describe calls for py3,MERGED,2017-02-27 16:07:31.000000000,2017-02-28 06:09:22.000000000,2017-02-27 19:30:11.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 7350}, {'_account_id': 10385}, {'_account_id': 12024}]","[{'number': 1, 'created': '2017-02-27 16:07:31.000000000', 'files': ['tempest/cmd/subunit_describe_calls.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6a375e6e65f08ca88d903e156205fe6f934a0f0', 'message': ""Fix subunit describe calls for py3\n\niteritems does not exists in python3, and it's\nactually enough to iterate over keys.\n\nChange-Id: I1a614942e25af26fedc720e5ebf8f800e0c54138\n""}]",0,438575,e6a375e6e65f08ca88d903e156205fe6f934a0f0,10,5,1,1921,,,0,"Fix subunit describe calls for py3

iteritems does not exists in python3, and it's
actually enough to iterate over keys.

Change-Id: I1a614942e25af26fedc720e5ebf8f800e0c54138
",git fetch https://review.opendev.org/openstack/tempest refs/changes/75/438575/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/subunit_describe_calls.py'],1,e6a375e6e65f08ca88d903e156205fe6f934a0f0,subunit_describe_calls_py3, for test_name in url_parser.test_logs: items = url_parser.test_logs[test_name]," for test_name, items in url_parser.test_logs.iteritems():",2,1
openstack%2Ftripleo-quickstart-extras~master~I2a01afdbde6324bf2555cdf76ad2b277828c55e2,openstack/tripleo-quickstart-extras,master,I2a01afdbde6324bf2555cdf76ad2b277828c55e2,Stop building heat-agents image,MERGED,2017-02-23 17:59:52.000000000,2017-02-28 06:08:25.000000000,2017-02-28 06:08:25.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18846}, {'_account_id': 23317}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-02-23 17:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fd7dc6effee03ae983510b4224e0c19dc7fd833a', 'message': 'Stop building heat-agents image\n\nRemoves the step to rebuild heat-agents container image since it is\nfailing due to rpm dependency issue and is not needed anymore after\nIbcff99f03e6751fbf3197adefd5d344178b71fc2 landed.\n\nChange-Id: I2a01afdbde6324bf2555cdf76ad2b277828c55e2\n'}, {'number': 2, 'created': '2017-02-23 19:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4180601b8508ae89939ce3f18a93ee1ff2ba68e2', 'message': 'Stop building heat-agents image\n\nRemoves the step to rebuild heat-agents container image since it is\nfailing due to rpm dependency issue and is not needed anymore after\nIbcff99f03e6751fbf3197adefd5d344178b71fc2 landed.\n\nChange-Id: I2a01afdbde6324bf2555cdf76ad2b277828c55e2\n'}, {'number': 3, 'created': '2017-02-24 14:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1ed4354e07995d85ecbff193b354f8e171c3cc90', 'message': 'Stop building heat-agents image\n\nRemoves the step to rebuild heat-agents container image since it is\nfailing due to rpm dependency issue and is not needed anymore after\nIbcff99f03e6751fbf3197adefd5d344178b71fc2 landed.\n\nChange-Id: I2a01afdbde6324bf2555cdf76ad2b277828c55e2\nDepends-On: I93553f8248f969bb8d5e212c2e92acbd18623afc\n'}, {'number': 4, 'created': '2017-02-25 22:08:19.000000000', 'files': ['roles/overcloud-prep-containers/templates/overcloud-prep-containers.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/234b4f7c9c11246099c4606c29d3e46984428c66', 'message': 'Stop building heat-agents image\n\nRemoves the step to rebuild heat-agents container image since it is\nfailing due to rpm dependency issue and is not needed anymore after\nIbcff99f03e6751fbf3197adefd5d344178b71fc2 landed.\n\nChange-Id: I2a01afdbde6324bf2555cdf76ad2b277828c55e2\nDepends-On: I93553f8248f969bb8d5e212c2e92acbd18623afc\n'}]",0,437546,234b4f7c9c11246099c4606c29d3e46984428c66,56,8,4,13039,,,0,"Stop building heat-agents image

Removes the step to rebuild heat-agents container image since it is
failing due to rpm dependency issue and is not needed anymore after
Ibcff99f03e6751fbf3197adefd5d344178b71fc2 landed.

Change-Id: I2a01afdbde6324bf2555cdf76ad2b277828c55e2
Depends-On: I93553f8248f969bb8d5e212c2e92acbd18623afc
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/46/437546/4 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-prep-containers/templates/overcloud-prep-containers.sh.j2'],1,fd7dc6effee03ae983510b4224e0c19dc7fd833a,upstream-containers,,"## * Rebuild heat-agents image and push to local registry ## :: sudo docker build -t ""{{ ctl_plane_ip }}:8787/tripleoupstream/heat-docker-agents:newton"" {{ tripleo_common_dir }}/heat_docker_agent/ sudo docker push {{ ctl_plane_ip }}:8787/tripleoupstream/heat-docker-agents:newton ",0,6
openstack%2Fmonasca-api~stable%2Fnewton~If82c0a7dcdce39336471c82a17d5b12d27f922bd,openstack/monasca-api,stable/newton,If82c0a7dcdce39336471c82a17d5b12d27f922bd,Updated from global requirements,MERGED,2017-02-27 14:48:24.000000000,2017-02-28 06:07:52.000000000,2017-02-28 06:07:52.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-02-27 14:48:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0d8c6d86b190fbe60ec8835dd5c6d2458c58ca0d', 'message': 'Updated from global requirements\n\nChange-Id: If82c0a7dcdce39336471c82a17d5b12d27f922bd\n'}]",0,438527,0d8c6d86b190fbe60ec8835dd5c6d2458c58ca0d,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: If82c0a7dcdce39336471c82a17d5b12d27f922bd
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/27/438527/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0d8c6d86b190fbe60ec8835dd5c6d2458c58ca0d,openstack/requirements,"hacking<0.12,>=0.11.0 # Apache-2.0","hacking>=0.11.0,<0.12 # Apache-2.0",1,1
openstack%2Fsenlin~master~I230d2ce37573b250275669823ebe900cae26c1a7,openstack/senlin,master,I230d2ce37573b250275669823ebe900cae26c1a7,"Revert ""Modify network name in examples files""",MERGED,2017-02-24 01:57:01.000000000,2017-02-28 06:07:46.000000000,2017-02-28 06:07:46.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-24 01:57:01.000000000', 'files': ['examples/policies/lb_policy.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3fd069ab4586a2b70978d5200d32317d6148697c', 'message': 'Revert ""Modify network name in examples files""\n\nWhat we need is subnet in lb_policy, just the right name.\n\nThis reverts commit cd33e7c384c1dae5b90146f5149a874d3a939cee.\n\nChange-Id: I230d2ce37573b250275669823ebe900cae26c1a7\n'}]",0,437753,3fd069ab4586a2b70978d5200d32317d6148697c,9,3,1,15917,,,0,"Revert ""Modify network name in examples files""

What we need is subnet in lb_policy, just the right name.

This reverts commit cd33e7c384c1dae5b90146f5149a874d3a939cee.

Change-Id: I230d2ce37573b250275669823ebe900cae26c1a7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/53/437753/1 && git format-patch -1 --stdout FETCH_HEAD,['examples/policies/lb_policy.yaml'],1,3fd069ab4586a2b70978d5200d32317d6148697c,fix/default_value, subnet: private-subnet subnet: public-subnet, subnet: private subnet: public,2,2
openstack%2Fnetworking-ovn~master~Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86,openstack/networking-ovn,master,Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86,Support OVS branch arg to devstackgaterc.,MERGED,2017-02-18 06:50:21.000000000,2017-02-28 06:06:34.000000000,2017-02-28 06:06:34.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 8871}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-18 06:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/147490b48ff02ad75f0060e16f943a40f9d399e9', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 2, 'created': '2017-02-18 08:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/df9c6844e36037a4205d045ef02f3596cf3f201d', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 3, 'created': '2017-02-22 16:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8ced1bf082333d1b4b127a221dd3f208bdfc51ed', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 4, 'created': '2017-02-23 16:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f9007adf928199d0ae06f1f7e24845151be6d045', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 5, 'created': '2017-02-27 20:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fea978a52f50d506c6547c5905c89c6bc13a17fb', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 6, 'created': '2017-02-27 21:53:43.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e9db3d77a60bd475696f0d6ebb63a2355cd42717', 'message': 'Support OVS branch arg to devstackgaterc.\n\nA recent project-config commit started passing in an optional argument\nto devstackgaterc to specify which OVS branch to use.  Make it work.\n\nhttps://review.openstack.org/#/c/394684/\n\nChange-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,435664,e9db3d77a60bd475696f0d6ebb63a2355cd42717,29,4,6,1561,,,0,"Support OVS branch arg to devstackgaterc.

A recent project-config commit started passing in an optional argument
to devstackgaterc to specify which OVS branch to use.  Make it work.

https://review.openstack.org/#/c/394684/

Change-Id: Id7823ddc9d6c4755367525cb43ca16ad4ffa9a86
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/64/435664/5 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,147490b48ff02ad75f0060e16f943a40f9d399e9,ci-jobs,"OVS_BRANCH=$1 if [[ ""${OVS_BRANCH}"" == ""latest-release"" ]] ; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVN_BRANCH=branch-2.7"" elif [[ ""${OVS_BRANCH}"" == ""master"" ]] ; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVN_BRANCH=master"" elif [[ -z ""${OVS_BRANCH}"" ]] # Use the default specified in the devstack plugin else echo ""Unexpected value to ovs branch argument to devstackgaterc: \""${OVS_BRANCH}\"""" exit 1 fi ",,12,0
openstack%2Fnova~master~I9979118fbc2924921ecbcbae3bd1757d0271f771,openstack/nova,master,I9979118fbc2924921ecbcbae3bd1757d0271f771,Transform instance.live_migration_rollback_dest notification,ABANDONED,2017-01-16 10:34:01.000000000,2017-02-28 06:04:23.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12299}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 18602}, {'_account_id': 20040}, {'_account_id': 21797}, {'_account_id': 22056}]","[{'number': 1, 'created': '2017-01-16 10:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bac04c2f0f48208d0486984e7477564f3f0623f8', 'message': 'Transform instance.live_migration_rollback_dest notification\n\nThe instance.live_migration_rollback_dest.start and instance.live_migration_rollback_dest.end notifications\nare transformed to the versioned framework.\n\nChange-Id: I9979118fbc2924921ecbcbae3bd1757d0271f771\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 2, 'created': '2017-01-17 02:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d48fc464403d75017a25800a2ef79814e32b5c04', 'message': 'Transform instance.live_migration_rollback_dest notification\n\nThe instance.live_migration_rollback_dest.start and\ninstance.live_migration_rollback_dest.end notifications\nare transformed to the versioned framework.\n\nChange-Id: I9979118fbc2924921ecbcbae3bd1757d0271f771\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 3, 'created': '2017-01-17 10:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5817d2a391706fcc285d50b0989a5d59f008467', 'message': 'Transform instance.live_migration_rollback_dest notification\n\nThe instance.live_migration_rollback_dest.start and\ninstance.live_migration_rollback_dest.end notifications\nare transformed to the versioned framework.\n\nChange-Id: I9979118fbc2924921ecbcbae3bd1757d0271f771\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 4, 'created': '2017-01-17 10:30:10.000000000', 'files': ['doc/notification_samples/instance-live_migration_rollback_dest-end.json', 'nova/notifications/objects/instance.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'doc/notification_samples/instance-live_migration_rollback_dest-start.json', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e3b03c4e6d6a269f0f000197fdca84dc9da0f423', 'message': 'Transform instance.live_migration_rollback_dest notification\n\nThe instance.live_migration_rollback_dest.start and\ninstance.live_migration_rollback_dest.end notifications\nare transformed to the versioned framework.\n\nChange-Id: I9979118fbc2924921ecbcbae3bd1757d0271f771\nImplements: bp versioned-notification-transformation-ocata\n'}]",3,420629,e3b03c4e6d6a269f0f000197fdca84dc9da0f423,52,16,4,22056,,,0,"Transform instance.live_migration_rollback_dest notification

The instance.live_migration_rollback_dest.start and
instance.live_migration_rollback_dest.end notifications
are transformed to the versioned framework.

Change-Id: I9979118fbc2924921ecbcbae3bd1757d0271f771
Implements: bp versioned-notification-transformation-ocata
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/420629/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/notification_samples/instance-live_migration_rollback_dest-end.json', 'nova/notifications/objects/instance.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'doc/notification_samples/instance-live_migration_rollback_dest-start.json', 'nova/compute/manager.py']",6,bac04c2f0f48208d0486984e7477564f3f0623f8,bp/versioned-notification-transformation-ocata," compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST, phase=fields.NotificationPhase.START) compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST, phase=fields.NotificationPhase.END)",,180,4
openstack%2Fnova-powervm~master~I8ae0eeb209caa07341c00a7b29a0ae2542871b6e,openstack/nova-powervm,master,I8ae0eeb209caa07341c00a7b29a0ae2542871b6e,Refine oslo config help description and code format,ABANDONED,2016-12-14 12:55:24.000000000,2017-02-28 05:54:34.000000000,,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}, {'_account_id': 16710}]","[{'number': 1, 'created': '2016-12-14 12:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/9cd6ae10c8949f5c397b8c663bd11b61bc2815ae', 'message': ""Refine oslo config help description and code format\n\nRefine config options' help format and polish code format.\n\nChange-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e\n""}, {'number': 2, 'created': '2016-12-14 14:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/c73e169e394a6485b0c1b5ab3141b6fc248b36f8', 'message': ""Refine oslo config help description and code format\n\nRefine config options' help format and polish code format.\n\nChange-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e\n""}, {'number': 3, 'created': '2016-12-14 14:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/24490d660e96c184fe0396baffd330b4598ef75a', 'message': ""Refine oslo config help description and code format\n\nRefine config options' help format and polish code format.\n\nChange-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e\n""}, {'number': 4, 'created': '2017-01-20 06:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/95a6cd0ae64cda127359bf368f01481e1ae73f39', 'message': ""Refine oslo config help description and code format\n\nRefine config options' help format and polish code format.\n\nChange-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e\n""}, {'number': 5, 'created': '2017-02-09 01:49:01.000000000', 'files': ['nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/tasks/vm.py', 'nova_powervm/virt/powervm/host.py', 'nova_powervm/conf/powervm.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0c2ece10c21d39328428c392b045bc2e53b7c3e0', 'message': ""Refine oslo config help description and code format\n\nRefine config options' help format and polish code format.\n\nChange-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e\n""}]",0,410734,0c2ece10c21d39328428c392b045bc2e53b7c3e0,14,6,5,10347,,,0,"Refine oslo config help description and code format

Refine config options' help format and polish code format.

Change-Id: I8ae0eeb209caa07341c00a7b29a0ae2542871b6e
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/34/410734/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/tasks/vm.py', 'nova_powervm/virt/powervm/host.py', 'nova_powervm/conf/powervm.py']",4,9cd6ae10c8949f5c397b8c663bd11b61bc2815ae,sync-format," title='PowerVM Options', help="""""" PowerVM options allow cloud administrators to configure how OpenStack will deploy against the PowerVM hypervisor. """""") help="""""" Factor used to calculate the processor units per vcpu. Possible values: 0.05 - 1.0 Related options: None """"""), help="""""" The processor weight to assign to newly created VMs. Represents how aggressively LPARs grab CPU when unused cycles are available. Possible values: 1 - 255 Related options: None """"""), help="""""" The volume group is set on the system. The volume group on the system that should be used to store the config drive metadata that will be attached to VMs. If not specified and no media repository exists, rootvg will be used. This option is ignored if a media repository already exists. Possible values: rootvg Related options: None """"""), help="""""" The size of the media repository (in GB) for the metadata for config drive. Only used if the media repository needs to be created. Possible values: The minimum vaule is 1 Related options: None """"""), help="""""" The location where the config drive ISO files should be built. Possible values: /tmp/cfgdrv/ Related options: None """"""), help="""""" The disk driver to use for PowerVM disks. Possible values: localdisk, ssp Related options: None """"""), help="""""" The volume adapter to use for PowerVM volumes. Possible values: fibre_channel, iscsi Related options: None """"""), help="""""" Name of the PowerVM virtual switch to be used when mapping Linux based network ports to PowerVM virtual Ethernet devices. Possible values: NovaLinkVEABridge Related options: None """"""), help="""""" If enabled, tells the PowerVM Driver to create an RMC network interface on the deploy of a VM. This is an adapter that can only talk to the NovaLink partition and enables DLPAR actions. Possible values: True Related options: None """"""), help="""""" Set the RMC with IPv6 local address. If set, the system will configure the RMC network interface with an IPv6 link local address. This is generally set to True, but users may wish to turn this off if their operating system has compatibility issues. Possible values: True Related options: Only used if use_rmc_mgmt_vif is True and config drive is being used. """"""), help="""""" Default time in seconds to wait for Virtual I/O Server to be up and running. Possible values: 300 Related options: None """""") help="""""" Volume Group to use for block device operations. Must not be rootvg. If disk_driver is localdisk, and more than one non-rootvg volume group exists across the Virtual I/O Servers, then this attribute must be specified. """"""), help="""""" (Optional) The name of the Virtual I/O Server hosting the volume group. If this is not specified, the system will query through the Virtual I/O Servers looking for one that matches the volume_group_vios_name. This is only needed if the system has multiple Virtual I/O Servers with a non-rootvg volume group whose name is duplicated. """""") help="""""" Cluster hosting the Shared Storage Pool to use for storage operations. If none specified, the host is queried; if a single Cluster is found, it is used. Not used unless disk_driver option is set to ssp. """""") help="""""" The Fibre Channel Volume Strategy defines how FC Cinder volumes should be attached to the Virtual Machine. Possible values: npiv or vscsi Related options: If npiv is selected then the ports_per_fabric and fabrics option should be specified and at least one fabric_X_port_wwpns option (where X corresponds to the fabric name) must be specified. """"""), help="""""" The iSCSI Volume Strategy defines how iSCSI Cinder ' volumes should be attached to the Virtual Machine. Possible values: iscsi Related options: None """"""), help="""""" Volume Adapter API to connect FC volumes using NPIV connection mechanism. """"""), help="""""" Volume Adapter API to connect FC volumes through Virtual I/O Server using PowerVM vSCSI connection mechanism. """"""), help="""""" Indicates a minimum number of Virtual I/O Servers that are required to support a Cinder volume attach with the vSCSI volume connector. Possible values: 1 Related options: None """""") help="""""" The number of physical ports that should be connected directly to the Virtual Machine, per fabric. Example: 2 fabrics and ports_per_fabric set to 2 will result in 4 NPIV ports being created, two per fabric. If multiple Virtual I/O Servers are available, will attempt to span ports across I/O Servers. Possible values: 1 Related options: None """"""), help="""""" Unique identifier for each physical FC fabric that is available. Possible values: This is a comma separated list. If there are two fabrics for multi-pathing, then this could be set to A,B. The fabric identifiers are used for the '\'fabric_<identifier>_port_wwpns\' key. Related options: None """""") help="""""" The NVRAM store to use to hold the PowerVM NVRAM for virtual machines. """"""), help="""""" The Swift container to store the PowerVM NVRAM in. This must be configured the same value for all compute hosts. """"""), help="""""" The Swift user name to use for operations that use the Swift store. """"""), help="""""" The Swift domain the user is a member of. """"""), help="""""" The password for the Swift user. """"""), help="""""" The Swift project. """"""), help="""""" The Swift project domain. """"""), cfg.StrOpt('swift_auth_version', default='3', help="""""" The Keystone API version. """"""), cfg.StrOpt('swift_auth_url', help="""""" The Keystone authorization url. Possible values: http://keystone-hostname:5000/v3 Related options: None """"""), cfg.StrOpt('swift_cacert', required=False, help="""""" Path to CA certificate file. Possible values: /etc/swiftclient/myca.pem Related options: None """""") help="""""" If enabled, uses X509 Authentication for the VNC sessions started for each VM. """"""), cfg.StrOpt('vnc_ca_certs', help="""""" Path to CA certificate to use for verifying VNC X509 Authentication. """"""), cfg.StrOpt('vnc_server_cert', help="""""" Path to Server certificate to use for verifying VNC X509 Authentication. """"""), cfg.StrOpt('vnc_server_key', help="""""" Path to Server private key to use for verifying VNC X509 Authentication. """""")"," title='PowerVM Options') help='Factor used to calculate the processor units per vcpu. ' 'Valid values are: 0.05 - 1.0'), help='The processor weight to assign to newly created VMs. ' 'Value should be between 1 and 255. Represents how ' 'aggressively LPARs grab CPU when unused cycles are ' 'available.'), help='The volume group on the system that should be used ' 'to store the config drive metadata that will be attached ' 'to VMs. If not specified and no media repository ' 'exists, rootvg will be used. This option is ignored if ' 'a media repository already exists.'), help='The size of the media repository (in GB) for the ' 'metadata for config drive. Only used if the media ' 'repository needs to be created.'), help='The location where the config drive ISO files should be ' 'built.'), help='The disk driver to use for PowerVM disks. ' 'Valid options are: localdisk, ssp'), help='The volume adapter to use for PowerVM volumes. ' 'Valid options are: fibre_channel, iscsi'), help=""Name of the PowerVM virtual switch to be used when "" ""mapping Linux based network ports to PowerVM virtual "" ""Ethernet devices""), help=""If enabled, tells the PowerVM Driver to create an RMC "" ""network interface on the deploy of a VM. This is an "" ""adapter that can only talk to the NovaLink partition "" ""and enables DLPAR actions.""), help=""Only used if use_rmc_mgmt_vif is True and config drive "" ""is being used. If set, the system will configure the "" ""RMC network interface with an IPv6 link local address. "" ""This is generally set to True, but users may wish to "" ""turn this off if their operating system has "" ""compatibility issues.""), help=""Default time in seconds to wait for Virtual I/O Server "" ""to be up and running."") help='Volume Group to use for block device operations. Must ' 'not be rootvg. If disk_driver is localdisk, and more ' 'than one non-rootvg volume group exists across the ' 'Virtual I/O Servers, then this attribute must be ' 'specified.'), help='(Optional) The name of the Virtual I/O Server hosting ' 'the volume group. If this is not specified, the system ' 'will query through the Virtual I/O Servers looking for ' 'one that matches the volume_group_vios_name. This is ' 'only needed if the system has multiple Virtual I/O ' 'Servers with a non-rootvg volume group whose name is ' 'duplicated.') help='Cluster hosting the Shared Storage Pool to use for ' 'storage operations. If none specified, the host is ' 'queried; if a single Cluster is found, it is used. ' 'Not used unless disk_driver option is set to ssp.') help='The Fibre Channel Volume Strategy defines how FC Cinder ' 'volumes should be attached to the Virtual Machine. The ' 'options are: npiv or vscsi. If npiv is selected then ' 'the ports_per_fabric and fabrics option should be ' 'specified and at least one fabric_X_port_wwpns option ' '(where X corresponds to the fabric name) must be ' 'specified.'), help='The iSCSI Volume Strategy defines how iSCSI Cinder ' 'volumes should be attached to the Virtual Machine. The ' 'option is: iscsi.'), help='Volume Adapter API to connect FC volumes using NPIV' 'connection mechanism.'), help='Volume Adapter API to connect FC volumes through Virtual ' 'I/O Server using PowerVM vSCSI connection mechanism.'), help='Indicates a minimum number of Virtual I/O Servers that ' 'are required to support a Cinder volume attach with the ' 'vSCSI volume connector.') help='The number of physical ports that should be connected ' 'directly to the Virtual Machine, per fabric. ' 'Example: 2 fabrics and ports_per_fabric set to 2 will ' 'result in 4 NPIV ports being created, two per fabric. ' 'If multiple Virtual I/O Servers are available, will ' 'attempt to span ports across I/O Servers.'), help='Unique identifier for each physical FC fabric that is ' 'available. This is a comma separated list. If there ' 'are two fabrics for multi-pathing, then this could be ' 'set to A,B.' 'The fabric identifiers are used for the ' '\'fabric_<identifier>_port_wwpns\' key.') help='The NVRAM store to use to hold the PowerVM NVRAM for ' 'virtual machines.'), help='The Swift container to store the PowerVM NVRAM in. This ' 'must be configured the same value for all compute hosts.'), help='The Swift user name to use for operations that use ' 'the Swift store.'), help='The Swift domain the user is a member of.'), help='The password for the Swift user.'), help='The Swift project.'), help='The Swift project domain.'), cfg.StrOpt('swift_auth_version', default='3', help='The Keystone API ' 'version.'), cfg.StrOpt('swift_auth_url', help='The Keystone authorization url. ' 'Example: ""http://keystone-hostname:5000/v3""'), cfg.StrOpt('swift_cacert', required=False, help='Path to CA certificate ' 'file. Example: /etc/swiftclient/myca.pem') help='If enabled, uses X509 Authentication for the ' 'VNC sessions started for each VM.'), cfg.StrOpt('vnc_ca_certs', help='Path to CA certificate ' 'to use for verifying VNC X509 Authentication.'), cfg.StrOpt('vnc_server_cert', help='Path to Server certificate ' 'to use for verifying VNC X509 Authentication.'), cfg.StrOpt('vnc_server_key', help='Path to Server private key ' 'to use for verifying VNC X509 Authentication.')",321,120
openstack%2Fkeystone~master~I0a65e279911edcb941ca200844bfde6b2ee9d6d0,openstack/keystone,master,I0a65e279911edcb941ca200844bfde6b2ee9d6d0,Replace the RevocationEvent model with a dict,ABANDONED,2016-09-13 01:00:19.000000000,2017-02-28 05:51:20.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-09-13 01:00:19.000000000', 'files': ['keystone/models/revoke_model.py', 'keystone/revoke/controllers.py', 'keystone/tests/unit/test_revoke.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/revoke/backends/sql.py', 'keystone/tests/unit/test_v3_os_revoke.py', 'keystone/revoke/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/af91607fadfc7b820e2eec10764b63f6c5e7d447', 'message': 'Replace the RevocationEvent model with a dict\n\nTo eliminate the need to utilize a custom serializer for msgpack when\nhandling the RevocationEvent model, the model has been converted to a\nprimitive (dict) instead allowing the RevocationEvent to be serialized\nwith the standard msgpack handlers.\n\nThis will help to make edge cases that may occur due to issues with\nthe cache more straightforward to debug as the errors will reflect\nthe re-hydration of the serialized primitive and not possible code\nlevel errors in the custom msgpack handler. This chang will also\nsimplify eliminating some of the revocation fields as they will\nnot be full attributes on an opaque object.\n\nChange-Id: I0a65e279911edcb941ca200844bfde6b2ee9d6d0\n'}]",0,369099,af91607fadfc7b820e2eec10764b63f6c5e7d447,4,4,1,2903,,,0,"Replace the RevocationEvent model with a dict

To eliminate the need to utilize a custom serializer for msgpack when
handling the RevocationEvent model, the model has been converted to a
primitive (dict) instead allowing the RevocationEvent to be serialized
with the standard msgpack handlers.

This will help to make edge cases that may occur due to issues with
the cache more straightforward to debug as the errors will reflect
the re-hydration of the serialized primitive and not possible code
level errors in the custom msgpack handler. This chang will also
simplify eliminating some of the revocation fields as they will
not be full attributes on an opaque object.

Change-Id: I0a65e279911edcb941ca200844bfde6b2ee9d6d0
",git fetch https://review.opendev.org/openstack/keystone refs/changes/99/369099/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/models/revoke_model.py', 'keystone/revoke/controllers.py', 'keystone/tests/unit/test_revoke.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/revoke/backends/sql.py', 'keystone/tests/unit/test_v3_os_revoke.py', 'keystone/revoke/core.py']",7,af91607fadfc7b820e2eec10764b63f6c5e7d447,," self.revoke({'role_id': payload['resource_info']}) self.revoke({'project_id': payload['resource_info']}) self.revoke({'domain_id': payload['resource_info']}) self.revoke({'trust_id': payload['resource_info']}) self.revoke({'consumer_id': payload['resource_info']}) self.revoke({'access_token_id': payload['resource_info']}) return self.revoke({'user_id': user_id}) self.revoke({'audit_id': audit_id}) self.revoke({'audit_chain_id': audit_chain_id, 'domain_id': domain_id, 'project_id': project_id}) self.revoke({ 'user_id': user_id, 'role_id': role_id, 'domain_id': domain_id, 'project_id': project_id}) self.revoke({'project_id': project_id, 'user_id': user_id}) self.revoke({'project_id': project_id, 'role_id': role_id}) self.revoke({'domain_id': domain_id, 'role_id': role_id})"," self.revoke( revoke_model.RevokeEvent(role_id=payload['resource_info'])) self.revoke( revoke_model.RevokeEvent(project_id=payload['resource_info'])) self.revoke( revoke_model.RevokeEvent(domain_id=payload['resource_info'])) self.revoke( revoke_model.RevokeEvent(trust_id=payload['resource_info'])) self.revoke( revoke_model.RevokeEvent(consumer_id=payload['resource_info'])) self.revoke( revoke_model.RevokeEvent(access_token_id=payload['resource_info'])) return self.revoke(revoke_model.RevokeEvent(user_id=user_id)) self.revoke(revoke_model.RevokeEvent(audit_id=audit_id)) self.revoke(revoke_model.RevokeEvent(audit_chain_id=audit_chain_id, domain_id=domain_id, project_id=project_id)) self.revoke( revoke_model.RevokeEvent(user_id=user_id, role_id=role_id, domain_id=domain_id, project_id=project_id)) self.revoke( revoke_model.RevokeEvent(project_id=project_id, user_id=user_id)) self.revoke(revoke_model.RevokeEvent(project_id=project_id, role_id=role_id)) self.revoke(revoke_model.RevokeEvent(domain_id=domain_id, role_id=role_id))",136,201
openstack%2Frequirements~stable%2Fnewton~Ie60570ed61ad21460c38a4ac9267a92b7363cb26,openstack/requirements,stable/newton,Ie60570ed61ad21460c38a4ac9267a92b7363cb26,Updated from global requirements,MERGED,2017-02-27 14:54:41.000000000,2017-02-28 05:50:22.000000000,2017-02-28 05:50:22.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-27 14:54:41.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c5df510da708cf23a8a9a973e17f53ddbf057dc8', 'message': 'Updated from global requirements\n\nChange-Id: Ie60570ed61ad21460c38a4ac9267a92b7363cb26\n'}]",0,438533,c5df510da708cf23a8a9a973e17f53ddbf057dc8,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie60570ed61ad21460c38a4ac9267a92b7363cb26
",git fetch https://review.opendev.org/openstack/requirements refs/changes/33/438533/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c5df510da708cf23a8a9a973e17f53ddbf057dc8,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Frequirements~stable%2Focata~I807d25d3dda115f7f8c607d20aaaaa226c5d02f7,openstack/requirements,stable/ocata,I807d25d3dda115f7f8c607d20aaaaa226c5d02f7,Updated from global requirements,MERGED,2017-02-27 15:21:48.000000000,2017-02-28 05:49:50.000000000,2017-02-28 05:49:50.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-27 15:21:48.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7205c52f4f9de66d3d24957876ec2bcd2a6208bc', 'message': 'Updated from global requirements\n\nChange-Id: I807d25d3dda115f7f8c607d20aaaaa226c5d02f7\n'}]",0,438553,7205c52f4f9de66d3d24957876ec2bcd2a6208bc,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I807d25d3dda115f7f8c607d20aaaaa226c5d02f7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/53/438553/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7205c52f4f9de66d3d24957876ec2bcd2a6208bc,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,!=34.3.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Frequirements~stable%2Focata~If10ae59cfeb7b80c2e28669d262383c402d996fc,openstack/requirements,stable/ocata,If10ae59cfeb7b80c2e28669d262383c402d996fc,update constraint for oslo.messaging to new release 5.17.1,MERGED,2017-02-27 11:37:33.000000000,2017-02-28 05:49:43.000000000,2017-02-28 05:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-27 11:37:33.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/83de51acc43df0e458b34d53a4257f226ca7f91d', 'message': 'update constraint for oslo.messaging to new release 5.17.1\n\nChange-Id: If10ae59cfeb7b80c2e28669d262383c402d996fc\nmeta:version: 5.17.1\nmeta:diff-start: -\nmeta:series: ocata\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Kenneth Giusti <kgiusti@gmail.com>\nmeta:release:Commit: Kenneth Giusti <kgiusti@gmail.com>\nmeta:release:Change-Id: I789a9e293bc174fd9882a589a39e1abbad9c2914\nmeta:release:Code-Review-1: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Code-Review+1: ChangBo Guo(gcb) <glongwave@gmail.com>\nmeta:release:Code-Review+2: Davanum Srinivas (dims) <davanum@gmail.com>\nmeta:release:Workflow+1: Davanum Srinivas (dims) <davanum@gmail.com>\n'}]",0,438451,83de51acc43df0e458b34d53a4257f226ca7f91d,10,4,1,11131,,,0,"update constraint for oslo.messaging to new release 5.17.1

Change-Id: If10ae59cfeb7b80c2e28669d262383c402d996fc
meta:version: 5.17.1
meta:diff-start: -
meta:series: ocata
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Kenneth Giusti <kgiusti@gmail.com>
meta:release:Commit: Kenneth Giusti <kgiusti@gmail.com>
meta:release:Change-Id: I789a9e293bc174fd9882a589a39e1abbad9c2914
meta:release:Code-Review-1: Doug Hellmann <doug@doughellmann.com>
meta:release:Code-Review+1: ChangBo Guo(gcb) <glongwave@gmail.com>
meta:release:Code-Review+2: Davanum Srinivas (dims) <davanum@gmail.com>
meta:release:Workflow+1: Davanum Srinivas (dims) <davanum@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/438451/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,83de51acc43df0e458b34d53a4257f226ca7f91d,new-release,oslo.messaging===5.17.1,oslo.messaging===5.17.0,1,1
openstack%2Frequirements~master~Idf71b207fbd4f8d307dfe2e9455a2bd846fe2d96,openstack/requirements,master,Idf71b207fbd4f8d307dfe2e9455a2bd846fe2d96,update constraint for ironic-lib to new release 2.6.0,MERGED,2017-02-28 02:02:07.000000000,2017-02-28 05:49:38.000000000,2017-02-28 05:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-28 02:02:07.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1c91f864bde2f7443f84a7703b1de513a38e8ff7', 'message': 'update constraint for ironic-lib to new release 2.6.0\n\nChange-Id: Idf71b207fbd4f8d307dfe2e9455a2bd846fe2d96\nmeta:version: 2.6.0\nmeta:diff-start: -\nmeta:series: pike\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: Jim Rollenhagen <jim@jimrollenhagen.com>\nmeta:release:Commit: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Change-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>\n'}]",0,438765,1c91f864bde2f7443f84a7703b1de513a38e8ff7,7,3,1,11131,,,0,"update constraint for ironic-lib to new release 2.6.0

Change-Id: Idf71b207fbd4f8d307dfe2e9455a2bd846fe2d96
meta:version: 2.6.0
meta:diff-start: -
meta:series: pike
meta:release-type: release
meta:pypi: yes
meta:first: yes
meta:release:Author: Jim Rollenhagen <jim@jimrollenhagen.com>
meta:release:Commit: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Change-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Workflow+1: Tony Breeds <tony@bakeyournoodle.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/438765/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,1c91f864bde2f7443f84a7703b1de513a38e8ff7,new-release,ironic-lib===2.6.0,ironic-lib===2.5.2,1,1
openstack%2Fopenstack-manuals~master~I1ece6f69840e9e8abbf94e534ce4808127ef3094,openstack/openstack-manuals,master,I1ece6f69840e9e8abbf94e534ce4808127ef3094,"[common] Replace ""tenant"" with ""project""",MERGED,2017-02-25 09:01:44.000000000,2017-02-28 05:39:16.000000000,2017-02-28 05:39:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 10897}, {'_account_id': 14962}, {'_account_id': 18464}]","[{'number': 1, 'created': '2017-02-25 09:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/efdd32473b7aeaef5cd9a2b00486b5d6079a42ad', 'message': '[common] Replace ""tenant"" with ""project""\n\nChange-Id: I1ece6f69840e9e8abbf94e534ce4808127ef3094\nPartial-Bug: #1475005\n'}, {'number': 2, 'created': '2017-02-25 09:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e3de2609e934eacf312c9baa15fba7a9da014e90', 'message': '[contributor-guide] Replace ""tenant"" with ""project""\n\nChange-Id: I1ece6f69840e9e8abbf94e534ce4808127ef3094\nPartial-Bug: #1475005\n'}, {'number': 3, 'created': '2017-02-27 22:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/29d47d75b09b0260b6ab52e33716cda2ee0588d7', 'message': '[common] Replace ""tenant"" with ""project""\n\nChange-Id: I1ece6f69840e9e8abbf94e534ce4808127ef3094\nPartial-Bug: #1475005\n'}, {'number': 4, 'created': '2017-02-27 22:42:24.000000000', 'files': ['doc/common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7e7ca51298f16c53405efa5ab9460ecb3871e827', 'message': '[common] Replace ""tenant"" with ""project""\n\nChange-Id: I1ece6f69840e9e8abbf94e534ce4808127ef3094\nPartial-Bug: #1475005\n'}]",0,438159,7e7ca51298f16c53405efa5ab9460ecb3871e827,18,7,4,14151,,,0,"[common] Replace ""tenant"" with ""project""

Change-Id: I1ece6f69840e9e8abbf94e534ce4808127ef3094
Partial-Bug: #1475005
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/59/438159/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/glossary.rst', 'doc/common/get-started-object-storage.rst', 'doc/common/get-started-database-service.rst', 'doc/common/nova-show-usage-statistics-for-hosts-instances.rst']",4,efdd32473b7aeaef5cd9a2b00486b5d6079a42ad,bug/1475005,* Get summary statistics for each project:,* Get summary statistics for each tenant:,8,8
openstack%2Fopenstack-manuals~master~I15c889ec3b469c3a8e6b7e2ed11c70472f7125dc,openstack/openstack-manuals,master,I15c889ec3b469c3a8e6b7e2ed11c70472f7125dc,Fix incorrect service name to use official name,MERGED,2017-02-28 00:14:09.000000000,2017-02-28 05:36:58.000000000,2017-02-28 05:36:58.000000000,"[{'_account_id': 3}, {'_account_id': 10705}, {'_account_id': 10897}, {'_account_id': 12686}]","[{'number': 1, 'created': '2017-02-28 00:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/224e53d68e40a87f2a75dce61247e6d6626b5f4a', 'message': 'Fix incorrect service name to use official name\n\nChange-Id: I15c889ec3b469c3a8e6b7e2ed11c70472f7125dc\n'}, {'number': 2, 'created': '2017-02-28 00:14:54.000000000', 'files': ['doc/ops-guide/source/ops-upgrades.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/45e65dff0d150e0772a6bf302d003a93f55a21b6', 'message': 'Fix incorrect service name to use official name\n\nChange-Id: I15c889ec3b469c3a8e6b7e2ed11c70472f7125dc\n'}]",0,438751,45e65dff0d150e0772a6bf302d003a93f55a21b6,9,4,2,10497,,,0,"Fix incorrect service name to use official name

Change-Id: I15c889ec3b469c3a8e6b7e2ed11c70472f7125dc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/438751/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops-upgrades.rst'],1,224e53d68e40a87f2a75dce61247e6d6626b5f4a,,* `Bare Metal service (ironic) upgrades,* `Bare metal service (ironic) upgrades,1,1
openstack%2Frequirements~master~I56864050f1d01c9f9d50a31f1eddabb241d1140e,openstack/requirements,master,I56864050f1d01c9f9d50a31f1eddabb241d1140e,Update tripleo-common requirement for Pike,MERGED,2017-01-26 16:38:49.000000000,2017-02-28 05:36:25.000000000,2017-02-28 05:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 4978}, {'_account_id': 5638}, {'_account_id': 6593}, {'_account_id': 9712}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-01-26 16:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c4be00e0612e0628ff707592d43433f9e7b0ea8a', 'message': 'Update tripleo-common requirement for Ocata\n\nChange-Id: I56864050f1d01c9f9d50a31f1eddabb241d1140e\n'}, {'number': 2, 'created': '2017-02-27 11:10:17.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/214d17958c4fb71e39c5bdf30994f2f5c26a90ee', 'message': ""Update tripleo-common requirement for Pike\n\nThe requirement hasn't been updated for a long time and other\ncomponents are no longer compatible with the older version (mainly, new\nworkflows were added).\n\nChange-Id: I56864050f1d01c9f9d50a31f1eddabb241d1140e\n""}]",0,425778,214d17958c4fb71e39c5bdf30994f2f5c26a90ee,21,7,2,4978,,,0,"Update tripleo-common requirement for Pike

The requirement hasn't been updated for a long time and other
components are no longer compatible with the older version (mainly, new
workflows were added).

Change-Id: I56864050f1d01c9f9d50a31f1eddabb241d1140e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/78/425778/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,c4be00e0612e0628ff707592d43433f9e7b0ea8a,ocata-bump-tripleo-common,tripleo-common>=5.7.0 # Apache-2.0,tripleo-common>=5.0.0 # Apache-2.0,1,1
openstack%2Ftempest~master~I7554cdcd7968bde2ce0924dcbac5f349ae230935,openstack/tempest,master,I7554cdcd7968bde2ce0924dcbac5f349ae230935,"Revert ""Add reno for Tempest v15.0.0""",MERGED,2017-02-27 23:59:32.000000000,2017-02-28 05:31:00.000000000,2017-02-28 04:05:55.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-27 23:59:32.000000000', 'files': ['releasenotes/notes/15.0.0-start-of-pike-support-4925678d477b0745.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e663406e66123b03b89c9ac6ea9b4c48765b3da', 'message': 'Revert ""Add reno for Tempest v15.0.0""\n\nWe cannot add a new reno into the existing tag, so we need to\nrevert the patch.\n\nThis reverts commit 4e9c1dcf8f5c7f743e4ad98ae9f095b1078a691f.\n\nChange-Id: I7554cdcd7968bde2ce0924dcbac5f349ae230935\n'}]",0,438747,5e663406e66123b03b89c9ac6ea9b4c48765b3da,7,4,1,6167,,,0,"Revert ""Add reno for Tempest v15.0.0""

We cannot add a new reno into the existing tag, so we need to
revert the patch.

This reverts commit 4e9c1dcf8f5c7f743e4ad98ae9f095b1078a691f.

Change-Id: I7554cdcd7968bde2ce0924dcbac5f349ae230935
",git fetch https://review.opendev.org/openstack/tempest refs/changes/47/438747/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/15.0.0-start-of-pike-support-4925678d477b0745.yaml'],1,5e663406e66123b03b89c9ac6ea9b4c48765b3da,tag,,"--- prelude: > This release is marking the start of Ocata release support in Tempest other: - | OpenStack releases supported at this time are **Mitaka**, **Newton**, and **Ocata**. The release under current development as of this tag is Pike, meaning that every Tempest commit is also tested against master during the Pike cycle. However, this does not necessarily mean that using Tempest as of this tag will work against a Pike (or future releases) cloud. ",0,13
openstack%2Fcongress~master~If9ee99042f8451c4b8fabc1dce7f18e2f22ae589,openstack/congress,master,If9ee99042f8451c4b8fabc1dce7f18e2f22ae589,Updated from global requirements,MERGED,2017-02-13 15:10:36.000000000,2017-02-28 05:28:37.000000000,2017-02-28 05:28:37.000000000,"[{'_account_id': 3}, {'_account_id': 6469}, {'_account_id': 8215}, {'_account_id': 11278}, {'_account_id': 18591}]","[{'number': 1, 'created': '2017-02-13 15:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9f8c676ae36415fdf88fdacb4404be279d763a9d', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}, {'number': 2, 'created': '2017-02-14 05:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/1c92518de34743efbc4ecb9c15f56a9719633873', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}, {'number': 3, 'created': '2017-02-16 01:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/54fd33ccb70145a4693d130ec7bb9fb60c64e5bd', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}, {'number': 4, 'created': '2017-02-17 20:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/e7310789fe9ee7a388476a01abb3dec34db72c1d', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}, {'number': 5, 'created': '2017-02-22 22:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/36abefdf91d591c82821772ee1ded1d3d17600d3', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}, {'number': 6, 'created': '2017-02-28 02:03:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/29c3ea03d3c1e96741315fd3897d35aea827968b', 'message': 'Updated from global requirements\n\nChange-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589\n'}]",0,433112,29c3ea03d3c1e96741315fd3897d35aea827968b,24,5,6,11131,,,0,"Updated from global requirements

Change-Id: If9ee99042f8451c4b8fabc1dce7f18e2f22ae589
",git fetch https://review.opendev.org/openstack/congress refs/changes/12/433112/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9f8c676ae36415fdf88fdacb4404be279d763a9d,openstack/requirements,python-novaclient>=7.1.0 # Apache-2.0,"python-novaclient!=7.0.0,>=6.0.0 # Apache-2.0",1,1
openstack%2Fmonasca-log-api~stable%2Fnewton~Ibdc966fdbfc1b6a8fddd56ecbfc0a25229734e02,openstack/monasca-log-api,stable/newton,Ibdc966fdbfc1b6a8fddd56ecbfc0a25229734e02,Updated from global requirements,MERGED,2017-02-27 14:48:32.000000000,2017-02-28 05:21:24.000000000,2017-02-28 05:21:23.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-02-27 14:48:32.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/3ca4d5f1a88cc2b6eee044d647a29c69a9a242be', 'message': 'Updated from global requirements\n\nChange-Id: Ibdc966fdbfc1b6a8fddd56ecbfc0a25229734e02\n'}]",0,438528,3ca4d5f1a88cc2b6eee044d647a29c69a9a242be,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ibdc966fdbfc1b6a8fddd56ecbfc0a25229734e02
",git fetch https://review.opendev.org/openstack/monasca-log-api refs/changes/28/438528/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,3ca4d5f1a88cc2b6eee044d647a29c69a9a242be,openstack/requirements,"hacking<0.12,>=0.11.0 # Apache-2.0 bandit>=1.1.0 # Apache-2.0sphinx!=1.3b1,<1.3,>=1.2.1 # BSD oslosphinx!=3.4.0,>=2.5.0 # Apache-2.0os-testr>=0.7.0 # Apache-2.0","hacking>=0.11.0,<0.12 # Apache-2.0 bandit>=1.1.0 # Apache-2.0sphinx>=1.2.1,!=1.3b1,<1.3 # BSD oslosphinx>=2.5.0,!=3.4.0 # Apache-2.0os-testr>=0.7.0 # Apache-2.0",5,5
openstack%2Fceilometer~master~Ic03ee3343f68428775f2dd780a26298ab0434800,openstack/ceilometer,master,Ic03ee3343f68428775f2dd780a26298ab0434800,"Revert ""verify gnocchi connection before processing""",MERGED,2017-02-22 10:24:32.000000000,2017-02-28 05:18:13.000000000,2017-02-28 05:18:13.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 10969}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-22 10:24:32.000000000', 'files': ['ceilometer/opts.py', 'ceilometer/tests/unit/dispatcher/test_gnocchi.py', 'ceilometer/dispatcher/__init__.py', 'ceilometer/dispatcher/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/79859c7dedd4895b395b3dabde454dda772af2ad', 'message': 'Revert ""verify gnocchi connection before processing""\n\nThis reverts commit 152aa1af01769841956da1bc0225bde88b80af08.\n\nThis makes Ceilometer spam Gnocchi at startup for no good reason. Gnocchi being\nstarted or not at the start of Ceilometer should not change anything, as it can\nbecome down at anytime and Ceilometer ought to handle that case anyway.\n\nRelated-Bug: #1666072\nChange-Id: Ic03ee3343f68428775f2dd780a26298ab0434800\n'}]",0,436863,79859c7dedd4895b395b3dabde454dda772af2ad,29,5,1,1669,,,0,"Revert ""verify gnocchi connection before processing""

This reverts commit 152aa1af01769841956da1bc0225bde88b80af08.

This makes Ceilometer spam Gnocchi at startup for no good reason. Gnocchi being
started or not at the start of Ceilometer should not change anything, as it can
become down at anytime and Ceilometer ought to handle that case anyway.

Related-Bug: #1666072
Change-Id: Ic03ee3343f68428775f2dd780a26298ab0434800
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/63/436863/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/opts.py', 'ceilometer/tests/unit/dispatcher/test_gnocchi.py', 'ceilometer/dispatcher/__init__.py', 'ceilometer/dispatcher/gnocchi.py']",4,79859c7dedd4895b395b3dabde454dda772af2ad,bug/1666072,,"import tenacity retries = conf.storage.max_retries @tenacity.retry( wait=tenacity.wait_fixed(conf.storage.retry_interval), stop=(tenacity.stop_after_attempt(retries) if retries >= 0 else tenacity.stop_never), reraise=True) def _get_connection(): self._gnocchi.capabilities.list() try: _get_connection() except Exception: LOG.error(_LE('Failed to connect to Gnocchi.')) raise ",1,34
openstack%2Fopenstack-manuals~master~I5fb61f31e2f9ebd1a5f63141e79f7b765a0777db,openstack/openstack-manuals,master,I5fb61f31e2f9ebd1a5f63141e79f7b765a0777db,[config-reference] Fix the incorrect format,MERGED,2017-02-27 02:41:21.000000000,2017-02-28 05:11:28.000000000,2017-02-28 05:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14962}]","[{'number': 1, 'created': '2017-02-27 02:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/57cacd506f12027add7ffa09904f45203e11b8dc', 'message': '[config-reference] Fix the incorrect format\n\nChange-Id: I5fb61f31e2f9ebd1a5f63141e79f7b765a0777db\n'}, {'number': 2, 'created': '2017-02-28 04:38:59.000000000', 'files': ['doc/config-reference/source/compute/hypervisor-xen-api.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6501171e778cedc4682059da82fb5a6df8c4427d', 'message': '[config-reference] Fix the incorrect format\n\nChange-Id: I5fb61f31e2f9ebd1a5f63141e79f7b765a0777db\n'}]",2,438316,6501171e778cedc4682059da82fb5a6df8c4427d,12,5,2,19779,,,0,"[config-reference] Fix the incorrect format

Change-Id: I5fb61f31e2f9ebd1a5f63141e79f7b765a0777db
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/438316/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/hypervisor-xen-api.rst'],1,57cacd506f12027add7ffa09904f45203e11b8dc,incorrect_format,Image upload in tgz compressed format -------------------------------------,Image upload in ``tgz`` compressed format -----------------------------------------,2,2
openstack%2Ftripleo-ci~master~I22dec0bdf2c78eea54474b6628b46ebb73def94a,openstack/tripleo-ci,master,I22dec0bdf2c78eea54474b6628b46ebb73def94a,temprevert Swift Global EC Cluster Support,ABANDONED,2017-02-28 04:45:58.000000000,2017-02-28 05:07:32.000000000,,[],"[{'number': 1, 'created': '2017-02-28 04:45:58.000000000', 'files': ['toci_instack_osinfra.sh', 'toci_instack_ovb.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/53b57f7c02e3d94353e5073c843dab54b9e4a854', 'message': 'temprevert Swift Global EC Cluster Support\n\nSee https://bugs.launchpad.net/tripleo/+bug/1668493 for all details.\n\nChange-Id: I22dec0bdf2c78eea54474b6628b46ebb73def94a\nRelated-Bug: #1668493\n'}]",0,438797,53b57f7c02e3d94353e5073c843dab54b9e4a854,2,0,1,3153,,,0,"temprevert Swift Global EC Cluster Support

See https://bugs.launchpad.net/tripleo/+bug/1668493 for all details.

Change-Id: I22dec0bdf2c78eea54474b6628b46ebb73def94a
Related-Bug: #1668493
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/97/438797/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci_instack_osinfra.sh', 'toci_instack_ovb.sh']",2,53b57f7c02e3d94353e5073c843dab54b9e4a854,bug/1668493,temprevert swift 1f36b5dd1617eb971327893635402529becd584d 1668493 ,,4,0
openstack%2Fpuppet-tripleo~master~Ie72b96c76d7513f84003bc15b6527c97df7ba92f,openstack/puppet-tripleo,master,Ie72b96c76d7513f84003bc15b6527c97df7ba92f,Add httpchk for http services,MERGED,2016-11-08 00:23:46.000000000,2017-02-28 05:06:23.000000000,2017-02-27 01:13:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 10873}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-11-08 00:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d467fbfae171182cb552844faec36921dec8dd80', 'message': 'Standardize httpchk for http services\n\nThis change adds a default httpchk to the haproxy endpoint\nconfiguration.  The httpchk health check option should help reduce the\nsitutations where haproxy thinks the service is up but the service is\nonly listening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 2, 'created': '2016-11-08 19:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4ebea0861583031fb0e9560489575b5e7e1c7fa5', 'message': 'Standardize httpchk for http services\n\nThis change adds a default httpchk to the haproxy endpoint\nconfiguration.  The httpchk health check option should help reduce the\nsitutations where haproxy thinks the service is up but the service is\nonly listening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 3, 'created': '2016-11-08 19:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a65d9ceab730038e3de56c5d6555d915ed474852', 'message': 'Standardize httpchk for http services\n\nThis change adds a default httpchk to the haproxy endpoint\nconfiguration.  The httpchk health check option should help reduce the\nsitutations where haproxy thinks the service is up but the service is\nonly listening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 4, 'created': '2016-11-23 23:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e2036647238294dd8b70ab2e459fc2901076e356', 'message': 'Standardize httpchk for http services\n\nThis change adds a default httpchk to the haproxy endpoint\nconfiguration.  The httpchk health check option should help reduce the\nsitutations where haproxy thinks the service is up but the service is\nonly listening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 5, 'created': '2016-12-05 17:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/daa3ad1f869e98ffd3cd8f2d5c3f1bfb8327bd63', 'message': 'Standardize httpchk for http services\n\nThis change adds a default httpchk to the haproxy endpoint\nconfiguration.  The httpchk health check option should help reduce the\nsitutations where haproxy thinks the service is up but the service is\nonly listening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 6, 'created': '2016-12-05 23:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e16b72699e6e1c39efc0fbd78e55e24202a4afbc', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 7, 'created': '2016-12-06 14:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4eeaf04b13b55e387ea1ececeaf6697a5d566c2f', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 8, 'created': '2016-12-06 17:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6f4be2b9ace54d66be11f91ad87dca496b8f6f00', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 9, 'created': '2016-12-06 17:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e08f5f653475f17f7c1489b7a7c4ab9cfd867d52', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 10, 'created': '2016-12-07 00:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7e55bfdd565de8f2ff0b946f5ff29d41ffb94576', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 11, 'created': '2016-12-07 19:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/966522f9f35cbefaee3275a3d9a675376de85be7', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 12, 'created': '2016-12-09 15:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/38c32684c186aa9de26eaf861851c824c837d995', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 13, 'created': '2016-12-20 23:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2663f16adc3c81380ec876f0209c5a3d10af9f34', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 14, 'created': '2017-01-03 20:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3047e92f0ab9526b44f39e377518b50cd3bf73ad', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 15, 'created': '2017-01-23 19:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/14a6bf81ffc07322f020847c30a81b0ff8bb2dbb', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 16, 'created': '2017-01-24 17:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/dcc302139a0fe37fbcc71495b9df3ac903dca82c', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 17, 'created': '2017-02-20 20:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/691a6bc4adecb23edc28ad4f6ea69eaeceed44e7', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 18, 'created': '2017-02-20 21:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/53a44cab72eab3fb82a4bbe60ccd583cc5c024d6', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 19, 'created': '2017-02-20 23:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/699ddae00702af7d9b3a8e8f5645cd781fad15b9', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 20, 'created': '2017-02-22 07:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/17d6a2721c8fd89d81b09e14d1f6c76669827aef', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}, {'number': 21, 'created': '2017-02-22 13:13:14.000000000', 'files': ['manifests/haproxy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ebcc470ea8a632e6d5c13561a97e817d5f290aac', 'message': 'Add httpchk for http services\n\nThe httpchk health check option should help reduce the situtations\nwhere haproxy thinks the service is up but the service is only\nlistening and not actively serving http requests.\n\nChange-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f\nCloses-Bug: #1629052\n'}]",6,394686,ebcc470ea8a632e6d5c13561a97e817d5f290aac,127,5,21,14985,,,0,"Add httpchk for http services

The httpchk health check option should help reduce the situtations
where haproxy thinks the service is up but the service is only
listening and not actively serving http requests.

Change-Id: Ie72b96c76d7513f84003bc15b6527c97df7ba92f
Closes-Bug: #1629052
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/86/394686/10 && git format-patch -1 --stdout FETCH_HEAD,['manifests/haproxy.pp'],1,d467fbfae171182cb552844faec36921dec8dd80,bug/1629052," 'option' => ['httpchk', 'forwardfor',], 'option' => ['httpchk', 'forwardfor',], $http_listen_options = { 'option' => [ 'httpchk' ], 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }', ], } listen_options => $http_listen_options, listen_options => merge($http_listen_options, $keystone_public_tls_listen_opts), listen_options => merge($http_listen_options, $swift_proxy_server_listen_options), } else { $heat_ssl_options = {} } $heat_options = merge($http_listen_options, $heat_ssl_options) options => merge($http_listen_options, $horizon_options), # NOTE(jaosorior): Websockets have more overhead in establishing # connections than regular HTTP connections. Also, since it begins # as an HTTP connection and then ""upgrades"" to a TCP connection, some # timeouts get overriden by others at certain times of the connection. # The following values were taken from the following site: # http://blog.haproxy.com/2012/11/07/websockets-load-balancing-with-haproxy/ $zaqar_options = { 'timeout' => ['connect 5s', 'client 25s', 'server 25s', 'tunnel 3600s'], } listen_options => merge($http_listen_options, $zaqar_options),"," 'option' => 'forwardfor', 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], 'option' => 'forwardfor', listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, $keystone_listen_opts = { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], } listen_options => merge($keystone_listen_opts, $keystone_public_tls_listen_opts), listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }'], }, listen_options => $swift_proxy_server_listen_options, $heat_base_options = { 'http-request' => [ 'set-header X-Forwarded-Proto https if { ssl_fc }', 'set-header X-Forwarded-Proto http if !{ ssl_fc }']} $heat_options = merge($heat_base_options, $heat_ssl_options) } else { $heat_options = $heat_base_options } options => $horizon_options, listen_options => { # NOTE(jaosorior): Websockets have more overhead in establishing # connections than regular HTTP connections. Also, since it begins # as an HTTP connection and then ""upgrades"" to a TCP connection, some # timeouts get overriden by others at certain times of the connection. # The following values were taken from the following site: # http://blog.haproxy.com/2012/11/07/websockets-load-balancing-with-haproxy/ 'timeout' => ['connect 5s', 'client 25s', 'server 25s', 'tunnel 3600s'], },",27,53
openstack%2Fneutron~master~I764be99b2edbd0e7b54673c1940e883d7f313bf5,openstack/neutron,master,I764be99b2edbd0e7b54673c1940e883d7f313bf5,Use registry decorator in external_net_db,MERGED,2017-02-21 08:13:56.000000000,2017-02-28 05:00:36.000000000,2017-02-28 02:31:16.000000000,"[{'_account_id': 3}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10385}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-21 08:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa81cf743efb5d017f6364b589e6c93968d62b4e', 'message': 'Use registry decorator in external_net_db\n\nSwitch to the registry decorator in external_net_db.\n\nChange-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5\n'}, {'number': 2, 'created': '2017-02-21 09:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/426a7744dff763781e6327ea8bb1e74a4fe5180d', 'message': 'Use registry decorator in external_net_db\n\nSwitch to the registry decorator in external_net_db.\n\nChange-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5\n'}, {'number': 3, 'created': '2017-02-21 12:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f76bae7715961a6dc344f23739cd0c33a3777230', 'message': 'Use registry decorator in external_net_db\n\nSwitch to the registry decorator in external_net_db.\n\nChange-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5\n'}, {'number': 4, 'created': '2017-02-21 15:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9a021db7ff66f8e161ffb55ee7b5ab89e517d52', 'message': 'Use registry decorator in external_net_db\n\nSwitch to the registry decorator in external_net_db.\n\nChange-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5\n'}, {'number': 5, 'created': '2017-02-27 12:25:27.000000000', 'files': ['neutron/db/external_net_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3028edbf6b3962fb22127a4ca561a7d6adb84fac', 'message': 'Use registry decorator in external_net_db\n\nSwitch to the registry decorator in external_net_db.\n\nChange-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5\n'}]",0,436353,3028edbf6b3962fb22127a4ca561a7d6adb84fac,62,12,5,7787,,,0,"Use registry decorator in external_net_db

Switch to the registry decorator in external_net_db.

Change-Id: I764be99b2edbd0e7b54673c1940e883d7f313bf5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/436353/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/external_net_db.py'],1,aa81cf743efb5d017f6364b589e6c93968d62b4e,," @registry.receives('rbac-policy', [events.BEFORE_CREATE]) @registry.receives('rbac-policy', (events.BEFORE_UPDATE, events.BEFORE_DELETE))"," def _register_external_net_rbac_hooks(self): registry.subscribe(self._process_ext_policy_create, 'rbac-policy', events.BEFORE_CREATE) for e in (events.BEFORE_UPDATE, events.BEFORE_DELETE): registry.subscribe(self._validate_ext_not_in_use_by_tenant, 'rbac-policy', e) def __new__(cls, *args, **kwargs): new = super(External_net_db_mixin, cls).__new__(cls, *args, **kwargs) new._register_external_net_rbac_hooks() return new ",3,12
openstack%2Fcongress~master~I21a00c97ca2ed8c62438d47a80dfa95b09e456ca,openstack/congress,master,I21a00c97ca2ed8c62438d47a80dfa95b09e456ca,Use more specific asserts in tests,MERGED,2017-02-07 08:45:37.000000000,2017-02-28 04:50:19.000000000,2017-02-28 04:50:19.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 11278}, {'_account_id': 18591}, {'_account_id': 18603}]","[{'number': 1, 'created': '2017-02-07 08:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/10ed38eff3f628b3af37f0fcbfafb5742bca64be', 'message': 'Use more specific asserts in tests\n\nInstead of assertTrue and assertFalse use more specific asserts.\nThey are compatible with Python 2.7[1] and 3.4[2]\n\n[1]: https://docs.python.org/2.7/library/unittest.html\n[2]: https://docs.python.org/3.4/library/unittest.html\n\nChange-Id: I21a00c97ca2ed8c62438d47a80dfa95b09e456ca\n'}, {'number': 2, 'created': '2017-02-14 13:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/2164c832db50008c2e851600984187e4b1886391', 'message': 'Use more specific asserts in tests\n\nInstead of assertTrue and assertFalse use more specific asserts.\nThey are compatible with Python 2.7[1] and 3.4[2]\n\n[1]: https://docs.python.org/2.7/library/unittest.html\n[2]: https://docs.python.org/3.4/library/unittest.html\n\nChange-Id: I21a00c97ca2ed8c62438d47a80dfa95b09e456ca\n'}, {'number': 3, 'created': '2017-02-28 03:14:25.000000000', 'files': ['congress/tests/policy_engines/test_agnostic.py', 'congress/tests/datasources/test_keystonev3_driver.py', 'congress/tests/datasources/test_keystone_driver.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/tests/datalog/test_compiler.py', 'congress/tests/datasources/test_murano_driver.py', 'congress/tests/policy_engines/brokentest_agnostic.py', 'congress/tests/datalog/test_unify.py', 'congress/tests/api/test_row_model.py', 'congress/tests/datalog/test_factset.py', 'congress/tests/common/test_policy.py', 'congress/tests/api/test_policy_model.py', 'congress/tests/haht/test_congress_haht.py', 'congress/tests/db/test_db_ds_table_data.py', 'congress/tests/datalog/test_ruleset.py', 'congress/tests/dse2/test_data_service.py', 'congress/tests/datalog/test_builtin.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/05b54c4a23886f18a8de601a6407aba9293cc214', 'message': 'Use more specific asserts in tests\n\nInstead of assertTrue and assertFalse use more specific asserts.\nThey are compatible with Python 2.7[1] and 3.4[2]\n\n[1]: https://docs.python.org/2.7/library/unittest.html\n[2]: https://docs.python.org/3.4/library/unittest.html\n\nChange-Id: I21a00c97ca2ed8c62438d47a80dfa95b09e456ca\n'}]",0,430123,05b54c4a23886f18a8de601a6407aba9293cc214,16,5,3,18603,,,0,"Use more specific asserts in tests

Instead of assertTrue and assertFalse use more specific asserts.
They are compatible with Python 2.7[1] and 3.4[2]

[1]: https://docs.python.org/2.7/library/unittest.html
[2]: https://docs.python.org/3.4/library/unittest.html

Change-Id: I21a00c97ca2ed8c62438d47a80dfa95b09e456ca
",git fetch https://review.opendev.org/openstack/congress refs/changes/23/430123/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy_engines/test_agnostic.py', 'congress/tests/datasources/test_keystonev3_driver.py', 'congress/tests/datasources/test_keystone_driver.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/tests/datalog/test_compiler.py', 'congress/tests/datasources/test_murano_driver.py', 'congress/tests/policy_engines/brokentest_agnostic.py', 'congress/tests/datalog/test_unify.py', 'congress/tests/api/test_row_model.py', 'congress/tests/datalog/test_factset.py', 'congress/tests/api/test_policy_model.py', 'congress/tests/haht/test_congress_haht.py', 'congress/tests/db/test_db_ds_table_data.py', 'congress/tests/datalog/test_ruleset.py']",14,10ed38eff3f628b3af37f0fcbfafb5742bca64be,(detached," self.assertNotIn('p', self.ruleset) self.assertNotIn('p', self.ruleset) self.assertNotIn('p', self.ruleset) self.assertNotIn('p', self.ruleset) self.assertNotIn('p', self.ruleset) self.assertNotIn('p1', self.ruleset) self.assertNotIn('p2', self.ruleset) self.assertNotIn('p', self.ruleset) self.assertNotIn('p', self.ruleset)", self.assertFalse('p' in self.ruleset) self.assertFalse('p' in self.ruleset) self.assertFalse('p' in self.ruleset) self.assertFalse('p' in self.ruleset) self.assertFalse('p' in self.ruleset) self.assertFalse('p1' in self.ruleset) self.assertFalse('p2' in self.ruleset) self.assertFalse('p' in self.ruleset) self.assertFalse('p' in self.ruleset),108,114
openstack%2Frally~master~I63c5bf7da39423a73411d1c3a9ba14e11955f682,openstack/rally,master,I63c5bf7da39423a73411d1c3a9ba14e11955f682,Fix simple typo in file network.py,MERGED,2017-02-24 04:18:48.000000000,2017-02-28 04:49:16.000000000,2017-02-28 04:49:16.000000000,"[{'_account_id': 3}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2017-02-24 04:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7ab59eba604d9bd1fdc682cb962543ded63d6126', 'message': 'Fix simple typo in file network.py\n\nChange-Id: I63c5bf7da39423a73411d1c3a9ba14e11955f682\n'}, {'number': 2, 'created': '2017-02-24 05:34:28.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/neutron/test_network.py', 'rally/plugins/openstack/scenarios/neutron/network.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/841fcbc35631ab766fd1597c1ef43571db58358c', 'message': 'Fix simple typo in file network.py\n\nChange-Id: I63c5bf7da39423a73411d1c3a9ba14e11955f682\n'}]",0,437786,841fcbc35631ab766fd1597c1ef43571db58358c,17,3,2,18404,,,0,"Fix simple typo in file network.py

Change-Id: I63c5bf7da39423a73411d1c3a9ba14e11955f682
",git fetch https://review.opendev.org/openstack/rally refs/changes/86/437786/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/scenarios/neutron/network.py'],1,7ab59eba604d9bd1fdc682cb962543ded63d6126,neutron.simple_typo,class CreateAndListFloatingIps(utils.NeutronScenario):,class CeateAndListFloatingIps(utils.NeutronScenario):,1,1
openstack%2Fnova~master~I023edd20204657a6d6420a1fb84546e8984d32fb,openstack/nova,master,I023edd20204657a6d6420a1fb84546e8984d32fb,Fix typo in config drive support matrix docs,MERGED,2017-02-24 21:30:08.000000000,2017-02-28 04:44:53.000000000,2017-02-25 03:30:56.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 14595}]","[{'number': 1, 'created': '2017-02-24 21:30:08.000000000', 'files': ['doc/source/support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/5a1cb359850b64846a1393c35b4e88a5d1c1d0f7', 'message': ""Fix typo in config drive support matrix docs\n\nThere is no administrator password of keys, but if there\nis, I'd like to meet them.\n\nChange-Id: I023edd20204657a6d6420a1fb84546e8984d32fb\n""}]",1,438084,5a1cb359850b64846a1393c35b4e88a5d1c1d0f7,14,4,1,6873,,,0,"Fix typo in config drive support matrix docs

There is no administrator password of keys, but if there
is, I'd like to meet them.

Change-Id: I023edd20204657a6d6420a1fb84546e8984d32fb
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/438084/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/support-matrix.ini'],1,5a1cb359850b64846a1393c35b4e88a5d1c1d0f7,docs-config-drive-typo, password or keys is required to get login access. Alternatives, password of keys is required to get login access. Alternatives,1,1
openstack%2Fnova~master~I3c139565fc9300449eb25d87dfcc9d4177bc2085,openstack/nova,master,I3c139565fc9300449eb25d87dfcc9d4177bc2085,Correct some spelling errors,MERGED,2017-02-08 08:38:39.000000000,2017-02-28 04:23:35.000000000,2017-02-25 07:02:58.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19590}, {'_account_id': 20040}, {'_account_id': 21511}, {'_account_id': 21784}]","[{'number': 1, 'created': '2017-02-08 08:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3307658e6a36c09c18812fa57f29b7bf6088cba0', 'message': 'Correct some spelling errors\n\nChange-Id: I3c139565fc9300449eb25d87dfcc9d4177bc2085\n'}, {'number': 2, 'created': '2017-02-10 01:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a97422d5ae009b748ece9784301eb0651906c0b', 'message': 'Correct some spelling errors\n\nChange-Id: I3c139565fc9300449eb25d87dfcc9d4177bc2085\n'}, {'number': 3, 'created': '2017-02-25 02:45:30.000000000', 'files': ['nova/weights.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fdd2c1ed981531a11ac45c7fc16fddbd2dd2edf4', 'message': 'Correct some spelling errors\n\nChange-Id: I3c139565fc9300449eb25d87dfcc9d4177bc2085\n'}]",1,430646,fdd2c1ed981531a11ac45c7fc16fddbd2dd2edf4,54,17,3,21511,,,0,"Correct some spelling errors

Change-Id: I3c139565fc9300449eb25d87dfcc9d4177bc2085
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/430646/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/weights.py'],1,3307658e6a36c09c18812fa57f29b7bf6088cba0,nova17," # but none, we assume that the weigher had set them.", # but none we assume that the weigher has set them,1,1
openstack%2Fmagnum-ui~master~Ie84af46470b9c27009f943f66c2c7db24cd0404c,openstack/magnum-ui,master,Ie84af46470b9c27009f943f66c2c7db24cd0404c,Imported Translations from Zanata,MERGED,2017-02-24 06:07:31.000000000,2017-02-28 04:15:57.000000000,2017-02-28 04:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 16352}, {'_account_id': 22781}]","[{'number': 1, 'created': '2017-02-24 06:07:31.000000000', 'files': ['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/bb52750a82306addb82273696ddd1e72f520a2a0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Ie84af46470b9c27009f943f66c2c7db24cd0404c\n'}]",0,437800,bb52750a82306addb82273696ddd1e72f520a2a0,7,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Ie84af46470b9c27009f943f66c2c7db24cd0404c
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/00/437800/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po'],1,bb52750a82306addb82273696ddd1e72f520a2a0,zanata/translations,"""POT-Creation-Date: 2017-02-21 20:19+0000\n""""PO-Revision-Date: 2017-02-24 05:50+0000\n""msgid ""2.2.0"" msgstr ""2.2.0"" msgid ""Ocata Series Release Notes"" msgstr ""Ocata "" ","""POT-Creation-Date: 2017-02-16 10:02+0000\n""""PO-Revision-Date: 2017-02-14 02:07+0000\n""",8,2
openstack%2Fsenlin~master~Ia19d96a1ee55303ec0be7533a4e2c1558067c155,openstack/senlin,master,Ia19d96a1ee55303ec0be7533a4e2c1558067c155,Fix do_recover problem when operation is None,MERGED,2017-02-22 11:38:50.000000000,2017-02-28 04:06:13.000000000,2017-02-28 04:06:13.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-22 11:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/0c5e1135d3fd6c77699ee9955e28f23aa57fc0c9', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}, {'number': 2, 'created': '2017-02-22 11:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/83035d0111b05ca0830cb0b6606d9fb5db9f1f24', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}, {'number': 3, 'created': '2017-02-22 12:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/c3e03c1450a71a5c9d579af6ff13ce0b663845ef', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}, {'number': 4, 'created': '2017-02-22 12:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/fb153b1600f9ec850221695906df42ae1e67ef89', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}, {'number': 5, 'created': '2017-02-22 13:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/0b5d7f0fce04929aa066b81c2f0bcccf6e66490f', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}, {'number': 6, 'created': '2017-02-22 14:15:38.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/05eb8daaff530b5f3659d3ce40e52c5c69a86c3f', 'message': 'Fix do_recover problem when operation is None\n\nThis patch fixes do_recover problem when operation is None.\n\nChange-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155\nCloses-Bug: #1666245\n'}]",4,436888,05eb8daaff530b5f3659d3ce40e52c5c69a86c3f,33,3,6,22998,,,0,"Fix do_recover problem when operation is None

This patch fixes do_recover problem when operation is None.

Change-Id: Ia19d96a1ee55303ec0be7533a4e2c1558067c155
Closes-Bug: #1666245
",git fetch https://review.opendev.org/openstack/senlin refs/changes/88/436888/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py']",2,0c5e1135d3fd6c77699ee9955e28f23aa57fc0c9,bug/1666245," def test_do_recover_operation_is_none(self, mock_rebuild): profile = server.ServerProfile('t', self.spec) node_obj = mock.Mock(id='FAKE_NODE_ID', index=123, cluster_id='FAKE_CLUSTER_ID', data={ 'placement': { 'zone': 'AZ1', 'servergroup': 'SERVER_GROUP_1' } }) node_obj.name = 'TEST_SERVER' cc = mock.Mock() cc.server_delete.return_value = None cc.wait_for_server_delete.return_value = None nc = mock.Mock() profile._computeclient = cc profile._networkclient = nc self._stubout_profile(profile, mock_image=True, mock_flavor=True, mock_keypair=True, mock_net=True) mock_zone_info = self.patchobject(profile, '_update_zone_info') fake_server = mock.Mock(id='FAKE_ID') cc.server_create.return_value = fake_server cc.server_get.return_value = fake_server res = profile.do_recover(node_obj, operation=None) @mock.patch.object(server.ServerProfile, 'handle_rebuild')",,39,9
openstack%2Fcongress~master~Ibd78e62351bfbd07b20db746c8cb0a5ced40e2f9,openstack/congress,master,Ibd78e62351bfbd07b20db746c8cb0a5ced40e2f9,Fix nova.servers_set_meta unit test,MERGED,2017-02-17 10:04:27.000000000,2017-02-28 04:06:07.000000000,2017-02-28 04:06:07.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 11278}, {'_account_id': 18591}]","[{'number': 1, 'created': '2017-02-17 10:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bfada6cfb855cbb57b2e58b654f59b16b25e5660', 'message': 'Fix nova.servers_set_meta unit test\n\nThe unit test for nova_servers_set_meta was not testing the nova\ndatasource method itself but rather testing the\nDataSourceDriver.execute() method.\n\nAlso, align the format of arguments and description of the\nnova.servers_set_meta method with commit\ndaca060c304574d111c8fc1b09713b2b05a875fc.\n\nCloses-Bug: #1665594\nChange-Id: Ibd78e62351bfbd07b20db746c8cb0a5ced40e2f9\n'}, {'number': 2, 'created': '2017-02-28 02:10:17.000000000', 'files': ['congress/tests/datasources/test_nova_driver.py', 'congress/datasources/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d76057271aab5626d28930691856b1d2d5e1b1f9', 'message': 'Fix nova.servers_set_meta unit test\n\nThe unit test for nova_servers_set_meta was not testing the nova\ndatasource method itself but rather testing the\nDataSourceDriver.execute() method.\n\nAlso, align the format of arguments and description of the\nnova.servers_set_meta method with commit\ndaca060c304574d111c8fc1b09713b2b05a875fc.\n\nCloses-Bug: #1665594\nChange-Id: Ibd78e62351bfbd07b20db746c8cb0a5ced40e2f9\n'}]",0,435341,d76057271aab5626d28930691856b1d2d5e1b1f9,9,4,2,6469,,,0,"Fix nova.servers_set_meta unit test

The unit test for nova_servers_set_meta was not testing the nova
datasource method itself but rather testing the
DataSourceDriver.execute() method.

Also, align the format of arguments and description of the
nova.servers_set_meta method with commit
daca060c304574d111c8fc1b09713b2b05a875fc.

Closes-Bug: #1665594
Change-Id: Ibd78e62351bfbd07b20db746c8cb0a5ced40e2f9
",git fetch https://review.opendev.org/openstack/congress refs/changes/41/435341/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/datasources/test_nova_driver.py', 'congress/datasources/nova_driver.py']",2,bfada6cfb855cbb57b2e58b654f59b16b25e5660,bug/1665594," {'name': 'meta-key1', 'description': 'meta key 1'}, {'name': 'meta-value1', 'description': 'value for meta key1'}, {'name': 'meta-keyN', 'description': 'meta key N'}, {'name': 'meta-valueN', 'description': 'value for meta keyN'}],"," {'name': 'meta', 'description': 'metadata pairs, ' + 'e.g. meta1=val1 meta2=val2'}],",16,22
openstack%2Fnova~master~Ifc3fbcde8371b8002f3b17364e6f252e36113702,openstack/nova,master,Ifc3fbcde8371b8002f3b17364e6f252e36113702,doc: Don't put comments inside toctree,MERGED,2017-02-24 14:37:04.000000000,2017-02-28 04:02:49.000000000,2017-02-25 03:31:29.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16907}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-24 14:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14ea78d3f03c23b5507faad51a6a4dc3aafa3a2c', 'message': ""doc: Don't put comments inside toctree\n\nTurns out you can't embed a comment inside a toctree, resulting in the\nfollowing error:\n\n  WARNING: toctree contains reference to nonexisting document u'.. NOTE:\n  keep this list sorted by title'\n\nChange-Id: Ifc3fbcde8371b8002f3b17364e6f252e36113702\n""}, {'number': 2, 'created': '2017-02-24 19:17:02.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/456a80878dbeeb8241ef20a87f90a1a0bf67fe63', 'message': ""doc: Don't put comments inside toctree\n\nTurns out you can't embed a comment inside a toctree, resulting in the\nfollowing error:\n\n  WARNING: toctree contains reference to nonexisting document u'.. NOTE:\n  keep this list sorted by title'\n\nChange-Id: Ifc3fbcde8371b8002f3b17364e6f252e36113702\n""}]",0,437924,456a80878dbeeb8241ef20a87f90a1a0bf67fe63,24,12,2,15334,,,0,"doc: Don't put comments inside toctree

Turns out you can't embed a comment inside a toctree, resulting in the
following error:

  WARNING: toctree contains reference to nonexisting document u'.. NOTE:
  keep this list sorted by title'

Change-Id: Ifc3fbcde8371b8002f3b17364e6f252e36113702
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/437924/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,14ea78d3f03c23b5507faad51a6a4dc3aafa3a2c,feat/doc-fixes,.. NOTE: keep this list sorted by title , .. NOTE: keep this list sorted by title ,2,2
openstack%2Ftempest~master~I29a3a044a3a29394868abd3f2e4823e1b1ce21ab,openstack/tempest,master,I29a3a044a3a29394868abd3f2e4823e1b1ce21ab,Use 'delete_snapshot' method,MERGED,2017-02-14 13:50:02.000000000,2017-02-28 04:02:47.000000000,2017-02-28 04:02:47.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 19262}, {'_account_id': 20190}, {'_account_id': 23003}]","[{'number': 1, 'created': '2017-02-14 13:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/401e7a18dfacf985f07aa204c10cf34accc1889b', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 2, 'created': '2017-02-14 15:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dfab5925fb2a44ee8b452e1ad24cfcb6c518e93d', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 3, 'created': '2017-02-14 17:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/51dfd2ad2e0c91d725f4db8c1d753dac37f7da0b', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 4, 'created': '2017-02-19 08:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1ddf8bc3c2a1555452e4a3a5bcad514c39b585f', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 5, 'created': '2017-02-22 07:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1fd84faa8b5311005797156219a5a2796975e344', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 6, 'created': '2017-02-23 12:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0947fff151540f4a4801ef9fd74509aaf483df8f', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}, {'number': 7, 'created': '2017-02-23 17:57:34.000000000', 'files': ['tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/admin/v2/test_snapshot_manage.py', 'tempest/api/volume/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5b2b3620dca3c113935e69ae5477aba694dd49d5', 'message': ""Use 'delete_snapshot' method\n\nThere is a method for snapshot deletion in 'BaseVolumeTest' class.\n\nChange-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab\n""}]",8,433656,5b2b3620dca3c113935e69ae5477aba694dd49d5,47,9,7,19262,,,0,"Use 'delete_snapshot' method

There is a method for snapshot deletion in 'BaseVolumeTest' class.

Change-Id: I29a3a044a3a29394868abd3f2e4823e1b1ce21ab
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/433656/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/base.py']",2,401e7a18dfacf985f07aa204c10cf34accc1889b,delete_snapshot," def delete_snapshot(self, snapshot_id, snapshot_client=None): if snapshot_client is None: snapshot_client = self.snapshots_client snapshot_client.delete_snapshot(snapshot_id) snapshot_client.wait_for_resource_deletion(snapshot_id)"," @staticmethod def delete_snapshot(client, snapshot_id): client.delete_snapshot(snapshot_id) client.wait_for_resource_deletion(snapshot_id)",13,18
openstack%2Ftempest~master~I0934be118e7a02252f9fc5cfb21d1a0682b281ef,openstack/tempest,master,I0934be118e7a02252f9fc5cfb21d1a0682b281ef,Fix tempest 14.0.0 release notes,MERGED,2017-02-27 18:17:24.000000000,2017-02-28 04:02:39.000000000,2017-02-28 04:02:39.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 8556}]","[{'number': 1, 'created': '2017-02-27 18:17:24.000000000', 'files': ['releasenotes/notes/14.0.0-remo-stress-tests-81052b211ad95d2e.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a2ca059c608226eb4cf880a49061f78630cb0443', 'message': 'Fix tempest 14.0.0 release notes\n\nThis commit fixes the release notes for tempest 14.0.0 so that the\nprelude and other sections explaining the supported releases is actually\nincluded.\n\nChange-Id: I0934be118e7a02252f9fc5cfb21d1a0682b281ef\n'}]",0,438663,a2ca059c608226eb4cf880a49061f78630cb0443,8,3,1,5196,,,0,"Fix tempest 14.0.0 release notes

This commit fixes the release notes for tempest 14.0.0 so that the
prelude and other sections explaining the supported releases is actually
included.

Change-Id: I0934be118e7a02252f9fc5cfb21d1a0682b281ef
",git fetch https://review.opendev.org/openstack/tempest refs/changes/63/438663/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/14.0.0-remo-stress-tests-81052b211ad95d2e.yaml'],1,a2ca059c608226eb4cf880a49061f78630cb0443,436980,"prelude: > This release is marking the end of Liberty release support in Tempestother: - | OpenStack releases supported at this time are **Mitaka** and **Newton**. The release under current development as of this tag is Ocata, meaning that every Tempest commit is also tested against master during the Ocata cycle. However, this does not necessarily mean that using Tempest as of this tag will work against a Ocata (or future releases) cloud.",,9,0
openstack%2Ftempest~master~I689d51fb48a2ee5daad703db90b596d1d6fb7f6d,openstack/tempest,master,I689d51fb48a2ee5daad703db90b596d1d6fb7f6d,Fix tempest 15.0.0 release notes,MERGED,2017-02-22 15:21:50.000000000,2017-02-28 04:01:05.000000000,2017-02-28 04:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12017}]","[{'number': 1, 'created': '2017-02-22 15:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9874b983882f9d3043a30750fff61c1a2d85c086', 'message': 'Fix tempest 15.0.0 release notes\n\nThis commit fixes the release notes for tempest 15.0.0 so that the\nprelude and other sections explaining the supported releases actually\nshow up in the 15.0.0 release notes.\n\nChange-Id: I689d51fb48a2ee5daad703db90b596d1d6fb7f6d\n'}, {'number': 2, 'created': '2017-02-22 15:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aec69f46505b63bf285ffb4bfacfbdbcec74adc4', 'message': 'Fix tempest 15.0.0 release notes\n\nThis commit fixes the release notes for tempest 15.0.0 so that the\nprelude and other sections explaining the supported releases actually\nshow up in the 15.0.0 release notes.\n\nChange-Id: I689d51fb48a2ee5daad703db90b596d1d6fb7f6d\n'}, {'number': 3, 'created': '2017-02-27 17:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/420b294cbcb6e24fab23e3c6b5296646a51b1bad', 'message': 'Fix tempest 15.0.0 release notes\n\nThis commit fixes the release notes for tempest 15.0.0 so that the\nprelude and other sections explaining the supported releases actually\nshow up in the 15.0.0 release notes.\n\nChange-Id: I689d51fb48a2ee5daad703db90b596d1d6fb7f6d\n'}, {'number': 4, 'created': '2017-02-27 17:12:34.000000000', 'files': ['releasenotes/notes/15.0.0-remove-deprecated-compute-validation-config-options-e3d1b89ce074d71c.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b668a53ca74319bfe37cf42dfbf23e769d419a60', 'message': 'Fix tempest 15.0.0 release notes\n\nThis commit fixes the release notes for tempest 15.0.0 so that the\nprelude and other sections explaining the supported releases actually\nshow up in the 15.0.0 release notes.\n\nChange-Id: I689d51fb48a2ee5daad703db90b596d1d6fb7f6d\n'}]",0,436980,b668a53ca74319bfe37cf42dfbf23e769d419a60,25,7,4,5196,,,0,"Fix tempest 15.0.0 release notes

This commit fixes the release notes for tempest 15.0.0 so that the
prelude and other sections explaining the supported releases actually
show up in the 15.0.0 release notes.

Change-Id: I689d51fb48a2ee5daad703db90b596d1d6fb7f6d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/80/436980/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/15.0.0-start-of-pike-support-4925678d477b0745.yaml', 'releasenotes/notes/add-list-security-groups-by-servers-to-servers-client-library-088df48f6d81f4be.yaml']",2,9874b983882f9d3043a30750fff61c1a2d85c086,436980,"prelude: > This release is marking the start of Ocata release support in Tempestother: - | OpenStack releases supported at this time are **Mitaka**, **Newton**, and **Ocata**. The release under current development as of this tag is Pike, meaning that every Tempest commit is also tested against master during the Pike cycle. However, this does not necessarily mean that using Tempest as of this tag will work against a Pike (or future releases) cloud.",,12,13
openstack%2Fneutron~stable%2Fnewton~Ibe640a584add3acc89520a2bbb25b6f4c5818e1b,openstack/neutron,stable/newton,Ibe640a584add3acc89520a2bbb25b6f4c5818e1b,gate-hook: Accomodate devstack-gate local.conf changes,MERGED,2017-02-25 03:24:01.000000000,2017-02-28 04:00:55.000000000,2017-02-28 04:00:55.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 8655}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-25 03:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/678fbf7cca6bf1d1e33a7dc760385ff705587466', 'message': ""gate-hook: Accomodate devstack-gate local.conf changes\n\nWith devstack-gate switching to local.conf we can no longer use bash for\nevaluating settings variables. Also we shouldn't populate local.conf\ndirectly and let devstack-gate do that.\n\nSince now devstack never uses localrc file directly, we set [[localrc]]\nsections for local.conf instead.\n\nAs a nice side effect, it will make the gate hook work with devstack\nthat may not have the Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616 in\n(Newton and below), which may make backports easier later.\n\nConflicts:\n\tneutron/tests/contrib/gate_hook.sh\n\tneutron/tests/contrib/hooks/api_dvrskip_extensions\n\tneutron/tests/contrib/hooks/api_extensions\n\tneutron/tests/contrib/hooks/dstat\n\tneutron/tests/contrib/hooks/stack_base\n\nNewton changes: devstack is not used to start dstat for functional and\nfullstack jobs, so the corresponding code changes are skipped; there\nwere no different api_{flavor}_extensions hooks back in Newton; the list\nof extensions exposed in tempest jobs is different between Newton and\nOcata+.\n\nChange-Id: Ibe640a584add3acc89520a2bbb25b6f4c5818e1b\nCloses-bug: 1667331\n(cherry picked from commit d46636112f45fdf181751285835229b16886ab28)\n(cherry picked from commit 2ea107f2c8b91f3cff17c687907d265e3142e25d)\n""}, {'number': 2, 'created': '2017-02-25 04:42:44.000000000', 'files': ['neutron/tests/contrib/hooks/api_extensions', 'neutron/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/08c6d1297fc0d895c3950edad3a1f68cf7433757', 'message': ""gate-hook: Accomodate devstack-gate local.conf changes\n\nWith devstack-gate switching to local.conf we can no longer use bash for\nevaluating settings variables. Also we shouldn't populate local.conf\ndirectly and let devstack-gate do that.\n\nSince now devstack never uses localrc file directly, we set [[localrc]]\nsections for local.conf instead.\n\nAs a nice side effect, it will make the gate hook work with devstack\nthat may not have the Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616 in\n(Newton and below), which may make backports easier later.\n\nConflicts:\n\tneutron/tests/contrib/gate_hook.sh\n\tneutron/tests/contrib/hooks/api_dvrskip_extensions\n\tneutron/tests/contrib/hooks/api_extensions\n\tneutron/tests/contrib/hooks/dstat\n\tneutron/tests/contrib/hooks/stack_base\n\nNewton changes: devstack is not used to start dstat for functional and\nfullstack jobs, so the corresponding code changes are skipped; there\nwere no different api_{flavor}_extensions hooks back in Newton; the list\nof extensions exposed in tempest jobs is different between Newton and\nOcata+.\n\nDepends-On: Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616\nChange-Id: Ibe640a584add3acc89520a2bbb25b6f4c5818e1b\nCloses-bug: 1667331\n(cherry picked from commit d46636112f45fdf181751285835229b16886ab28)\n(cherry picked from commit 2ea107f2c8b91f3cff17c687907d265e3142e25d)\n""}]",0,438139,08c6d1297fc0d895c3950edad3a1f68cf7433757,26,9,2,9656,,,0,"gate-hook: Accomodate devstack-gate local.conf changes

With devstack-gate switching to local.conf we can no longer use bash for
evaluating settings variables. Also we shouldn't populate local.conf
directly and let devstack-gate do that.

Since now devstack never uses localrc file directly, we set [[localrc]]
sections for local.conf instead.

As a nice side effect, it will make the gate hook work with devstack
that may not have the Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616 in
(Newton and below), which may make backports easier later.

Conflicts:
	neutron/tests/contrib/gate_hook.sh
	neutron/tests/contrib/hooks/api_dvrskip_extensions
	neutron/tests/contrib/hooks/api_extensions
	neutron/tests/contrib/hooks/dstat
	neutron/tests/contrib/hooks/stack_base

Newton changes: devstack is not used to start dstat for functional and
fullstack jobs, so the corresponding code changes are skipped; there
were no different api_{flavor}_extensions hooks back in Newton; the list
of extensions exposed in tempest jobs is different between Newton and
Ocata+.

Depends-On: Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616
Change-Id: Ibe640a584add3acc89520a2bbb25b6f4c5818e1b
Closes-bug: 1667331
(cherry picked from commit d46636112f45fdf181751285835229b16886ab28)
(cherry picked from commit 2ea107f2c8b91f3cff17c687907d265e3142e25d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/438139/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/contrib/hooks/api_extensions', 'neutron/tests/contrib/gate_hook.sh']",2,678fbf7cca6bf1d1e33a7dc760385ff705587466,bug/1667331,"[[local|localrc]] config=$(cat $GATE_HOOKS/$hook) export DEVSTACK_LOCAL_CONFIG+="" # generated from hook '$hook' ${config} """, cat $GATE_HOOKS/$hook >> $LOCAL_CONF,7,44
openstack%2Fdevstack~stable%2Fnewton~Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616,openstack/devstack,stable/newton,Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616,meta-config: Fix consecutive same sections,MERGED,2016-11-29 04:27:05.000000000,2017-02-28 04:00:49.000000000,2017-02-28 04:00:49.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 9656}, {'_account_id': 10118}]","[{'number': 1, 'created': '2016-11-29 04:27:05.000000000', 'files': ['tests/test_meta_config.sh', 'inc/meta-config'], 'web_link': 'https://opendev.org/openstack/devstack/commit/85032db5139189aa15d372678f5169c3b8f4f5cd', 'message': 'meta-config: Fix consecutive same sections\n\nThe current coding fails to process local.conf like\nthe following.  Note: This example is taken from a\nreal use case. [1]\n\n    [[post-config|$NEUTRON_CONF]]\n    [qos]\n    notification_drivers = midonet\n    [[post-config|$NEUTRON_CONF]]\n\n    [quotas]\n    # x10 of default quotas (at the time of writing)\n    quota_network=100\n    quota_subnet=100\n    quota_port=500\n    quota_router=100\n    quota_floatingip=500\n    quota_security_group=100\n    quota_security_group_rule=1000\n\n[1] https://review.openstack.org/#/c/400627/\n\nCloses-Bug: #1583214\nChange-Id: Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616\n(cherry picked from commit 02f3f9a6bbb6c4af989ad6cf504d5c49d7c9b4e2)\n'}]",0,404018,85032db5139189aa15d372678f5169c3b8f4f5cd,17,6,1,6854,,,0,"meta-config: Fix consecutive same sections

The current coding fails to process local.conf like
the following.  Note: This example is taken from a
real use case. [1]

    [[post-config|$NEUTRON_CONF]]
    [qos]
    notification_drivers = midonet
    [[post-config|$NEUTRON_CONF]]

    [quotas]
    # x10 of default quotas (at the time of writing)
    quota_network=100
    quota_subnet=100
    quota_port=500
    quota_router=100
    quota_floatingip=500
    quota_security_group=100
    quota_security_group_rule=1000

[1] https://review.openstack.org/#/c/400627/

Closes-Bug: #1583214
Change-Id: Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616
(cherry picked from commit 02f3f9a6bbb6c4af989ad6cf504d5c49d7c9b4e2)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/18/404018/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_meta_config.sh', 'inc/meta-config']",2,85032db5139189aa15d372678f5169c3b8f4f5cd,bug/1583214," gsub(""[][]"", """", $1); split($1, a, ""|""); if (a[1] == matchgroup && a[2] == configfile) { group=a[1]"," if (group == """") { gsub(""[][]"", """", $1); split($1, a, ""|""); if (a[1] == matchgroup && a[2] == configfile) { group=a[1] }",32,7
openstack%2Fkolla-ansible~master~I68bd84c750f1551b7036aae33b382828de03ef14,openstack/kolla-ansible,master,I68bd84c750f1551b7036aae33b382828de03ef14,Deprecate use_neutron option,ABANDONED,2016-12-21 07:53:33.000000000,2017-02-28 03:57:58.000000000,,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 9414}, {'_account_id': 11869}, {'_account_id': 16233}, {'_account_id': 22165}, {'_account_id': 23717}]","[{'number': 1, 'created': '2016-12-21 07:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f45a5ff0618a6c8a5276a3105e48bb91cd6d0908', 'message': 'Deprecate use_neutron option\n\nOption ""use_neutron"" from group ""DEFAULT"" is deprecated for removal.\nIts value may be silently ignored in the future.\n\nChange-Id: I68bd84c750f1551b7036aae33b382828de03ef14\nCloses-Bug: #1651665\n'}, {'number': 2, 'created': '2017-02-28 03:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4f8f3b4f80ea5a408bc1acde361266e5a7d80a82', 'message': 'Deprecate use_neutron option\n\nOption ""use_neutron"" from group ""DEFAULT"" is deprecated for removal.\nIts value may be silently ignored in the future.\n\nChange-Id: I68bd84c750f1551b7036aae33b382828de03ef14\nCloses-Bug: #1651665\n'}]",1,413471,4f8f3b4f80ea5a408bc1acde361266e5a7d80a82,17,7,2,9414,,,0,"Deprecate use_neutron option

Option ""use_neutron"" from group ""DEFAULT"" is deprecated for removal.
Its value may be silently ignored in the future.

Change-Id: I68bd84c750f1551b7036aae33b382828de03ef14
Closes-Bug: #1651665
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/71/413471/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/templates/nova.conf.j2'],1,f45a5ff0618a6c8a5276a3105e48bb91cd6d0908,bug/1651665,,use_neutron = True,0,1
openstack%2Fopenstack-manuals~master~Ibcdf0744045d307bf7b03dab5e8b1ea958b7cfcd,openstack/openstack-manuals,master,Ibcdf0744045d307bf7b03dab5e8b1ea958b7cfcd,[www] improve h4 style for language index,MERGED,2017-02-22 13:46:01.000000000,2017-02-28 03:47:39.000000000,2017-02-28 03:47:39.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 12686}, {'_account_id': 14482}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-22 13:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f7a71bb2c3cd9f62b37938c9897476977d98c445', 'message': '[www] improve h4 style for language index\n\nTo improve the current non-coodinated style sheets for\nthe h4 elements that is used for the language index pages.\nThis applies the same style as the h3 element to reduce\ndifference about web design.\n\nChange-Id: Ibcdf0744045d307bf7b03dab5e8b1ea958b7cfcd\n'}, {'number': 2, 'created': '2017-02-22 16:10:32.000000000', 'files': ['www/static/common/css/combined.css'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c9981b42a175a846a8dc5a2d0e02a0eb19eece50', 'message': '[www] improve h4 style for language index\n\nTo improve the current non-coodinated style sheets for\nthe h4 elements that is used for the language index pages.\nThis applies the same style as the h3 element to reduce\ndifference about web design.\n\nChange-Id: Ibcdf0744045d307bf7b03dab5e8b1ea958b7cfcd\n'}]",0,436927,c9981b42a175a846a8dc5a2d0e02a0eb19eece50,14,7,2,10497,,,0,"[www] improve h4 style for language index

To improve the current non-coodinated style sheets for
the h4 elements that is used for the language index pages.
This applies the same style as the h3 element to reduce
difference about web design.

Change-Id: Ibcdf0744045d307bf7b03dab5e8b1ea958b7cfcd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/436927/1 && git format-patch -1 --stdout FETCH_HEAD,['www/static/common/css/combined.css'],1,f7a71bb2c3cd9f62b37938c9897476977d98c445,www,"h3, h4 {.docs-toc h3, .docs-toc h4 {",h3 {.docs-toc h3 {,2,2
openstack%2Fopenstack-manuals~master~I823fdf6cc9d71a27492f124ea65878f623ee1584,openstack/openstack-manuals,master,I823fdf6cc9d71a27492f124ea65878f623ee1584,update documentation for ibm_storage driver,MERGED,2017-02-19 15:50:35.000000000,2017-02-28 03:46:16.000000000,2017-02-28 03:46:16.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10213}, {'_account_id': 10607}, {'_account_id': 13047}, {'_account_id': 14962}, {'_account_id': 17947}, {'_account_id': 19779}, {'_account_id': 20310}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-19 15:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5383b50a6c6191bc8262ddac61802e8af0818e74', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 2, 'created': '2017-02-20 10:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/60197957dc2636b0e278cd763f4f200858d9a94c', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 3, 'created': '2017-02-21 18:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e5f7f4d4df7776c3916815093ead736a1713bb7', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 4, 'created': '2017-02-22 15:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/84f8cc0b71cd775eb2adc8cb7c7f17b68be041a5', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 5, 'created': '2017-02-22 17:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/236b95241e4ef6d0fb2ebd6d4e7e8fd48344d094', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 6, 'created': '2017-02-23 16:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9300372175dd33c57ae8e02bf518ccc192195b88', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 7, 'created': '2017-02-26 20:34:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cd88730f37c2b43b435f02d029f1d077cb116afe', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 8, 'created': '2017-02-27 12:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c857a1834836016980a5864d94c7a461280e5a1d', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}, {'number': 9, 'created': '2017-02-27 14:45:40.000000000', 'files': ['doc/config-reference/source/block-storage/drivers/ibm-storage-volume-driver.rst', 'doc/config-reference/source/figures/ibm-storage-nova-concept.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a1c934bd2592b48dca38f7f84b650d4b4e3c5d68', 'message': 'update documentation for ibm_storage driver\n\nUpdate and enhance the documentation for ibm_storage cinder driver.\n\nChange-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584\n'}]",126,435785,a1c934bd2592b48dca38f7f84b650d4b4e3c5d68,40,10,9,10213,,,0,"update documentation for ibm_storage driver

Update and enhance the documentation for ibm_storage cinder driver.

Change-Id: I823fdf6cc9d71a27492f124ea65878f623ee1584
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/435785/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/block-storage/drivers/ibm-storage-volume-driver.rst', 'doc/config-reference/source/figures/ibm-storage-nova-concept.png']",2,5383b50a6c6191bc8262ddac61802e8af0818e74,update_ibm_storage_block_driver_documentation,,,674,27
openstack%2Fopenstack-manuals~master~I69aaa6bde1e3a22be84ab792b9048f9587319bff,openstack/openstack-manuals,master,I69aaa6bde1e3a22be84ab792b9048f9587319bff,Use 'openstack' command to replace 'neutron' command,MERGED,2017-02-26 14:11:30.000000000,2017-02-28 03:44:42.000000000,2017-02-28 03:44:42.000000000,"[{'_account_id': 3}, {'_account_id': 6635}, {'_account_id': 9162}, {'_account_id': 10607}, {'_account_id': 19779}]","[{'number': 1, 'created': '2017-02-26 14:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/01aaa9bb5bd11a79ec12397b837f89c28bf426c7', 'message': ""Use 'openstack' command to replace 'neutron' command\n\nThis patch use 'openstack' command to replace 'neutron' command\nand make the consistent with the example command.\n\nChange-Id: I69aaa6bde1e3a22be84ab792b9048f9587319bff\n""}, {'number': 2, 'created': '2017-02-27 09:07:39.000000000', 'files': ['doc/networking-guide/source/config-dhcp-ha.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f22b37c2ee9aa615c0685a08103086b22ea12cab', 'message': ""Use 'openstack' command to replace 'neutron' command\n\nThis patch use 'openstack' command to replace 'neutron' command\nand make the consistent with the example command.\n\nChange-Id: I69aaa6bde1e3a22be84ab792b9048f9587319bff\n""}]",2,438256,f22b37c2ee9aa615c0685a08103086b22ea12cab,11,5,2,14151,,,0,"Use 'openstack' command to replace 'neutron' command

This patch use 'openstack' command to replace 'neutron' command
and make the consistent with the example command.

Change-Id: I69aaa6bde1e3a22be84ab792b9048f9587319bff
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/438256/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/config-dhcp-ha.rst'],1,01aaa9bb5bd11a79ec12397b837f89c28bf426c7,, The :command:`openstack network agent show` command shows details for a specified, The :command:`neutron agent-show` command shows details for a specified,1,1
openstack%2Fsecurity-doc~master~Ied1542f4dcbc835520093450ac1d9b95abf0f1cc,openstack/security-doc,master,Ied1542f4dcbc835520093450ac1d9b95abf0f1cc,Update bindep.txt,MERGED,2017-02-24 13:28:43.000000000,2017-02-28 03:36:13.000000000,2017-02-28 03:36:13.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-02-24 13:28:43.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/99cc3f27d3733c82d6939b6f934d76b0c12d4049', 'message': ""Update bindep.txt\n\nSince we're not using XML anymore, remove now unused binary package\ndependencies.\n\nAdd python-devel for RPM platforms.\n\nNote that this test is self-testing - the new config will be used\ndirectly in the OpenStack CI system.\n\nChange-Id: Ied1542f4dcbc835520093450ac1d9b95abf0f1cc\n""}]",0,437896,99cc3f27d3733c82d6939b6f934d76b0c12d4049,9,5,1,6547,,,0,"Update bindep.txt

Since we're not using XML anymore, remove now unused binary package
dependencies.

Add python-devel for RPM platforms.

Note that this test is self-testing - the new config will be used
directly in the OpenStack CI system.

Change-Id: Ied1542f4dcbc835520093450ac1d9b95abf0f1cc
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/96/437896/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,99cc3f27d3733c82d6939b6f934d76b0c12d4049,bindep,python-devel [platform:rpm],libxml2-dev [platform:dpkg] libxml2-devel [platform:rpm] libxml2-utils [platform:dpkg] libxslt-devel [platform:rpm] libxslt1-dev [platform:dpkg]python-lxml,1,6
openstack%2Fsenlin~master~I247b7ae6383de3d9b3db6e6e62e11acd4f5a9cff,openstack/senlin,master,I247b7ae6383de3d9b3db6e6e62e11acd4f5a9cff,Trivial fix: set default dict value to {},MERGED,2017-02-23 11:52:14.000000000,2017-02-28 03:34:58.000000000,2017-02-28 03:34:58.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-23 11:52:14.000000000', 'files': ['senlin/api/openstack/v1/clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/f815d487f2d8339294802b40104ed51218b38e3d', 'message': 'Trivial fix: set default dict value to {}\n\nChange-Id: I247b7ae6383de3d9b3db6e6e62e11acd4f5a9cff\n'}]",0,437344,f815d487f2d8339294802b40104ed51218b38e3d,11,3,1,15917,,,0,"Trivial fix: set default dict value to {}

Change-Id: I247b7ae6383de3d9b3db6e6e62e11acd4f5a9cff
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/437344/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/api/openstack/v1/clusters.py'],1,f815d487f2d8339294802b40104ed51218b38e3d,fix/replace_node," nodes = data.get('nodes', {})"," nodes = data.get('nodes', [])",1,1
openstack%2Fproject-config~master~I18adb1c1daa11d4f84518e449662ffe2b4e9dbf7,openstack/project-config,master,I18adb1c1daa11d4f84518e449662ffe2b4e9dbf7,update the mkfs.xfs path,MERGED,2017-02-28 03:04:36.000000000,2017-02-28 03:22:15.000000000,2017-02-28 03:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 6721}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-28 03:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9bdc8b7af1ed71aadee4fc8ff2e109683e9dbe96', 'message': 'update the mkfs.xfs path\n\nChange-Id: I18adb1c1daa11d4f84518e449662ffe2b4e9dbf7\n'}, {'number': 2, 'created': '2017-02-28 03:07:58.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5b9ddf927a176c0601358eef80eb164a9ecba13e', 'message': 'update the mkfs.xfs path\n\nWhile trying to add centos-7 gate job to swift tests\nthis script failed calling mkfs.xfs. Updating to use the full path\nso that it can be used both on centos and ubuntu\n\nChange-Id: I18adb1c1daa11d4f84518e449662ffe2b4e9dbf7\n'}]",0,438776,5b9ddf927a176c0601358eef80eb164a9ecba13e,8,3,2,9625,,,0,"update the mkfs.xfs path

While trying to add centos-7 gate job to swift tests
this script failed calling mkfs.xfs. Updating to use the full path
so that it can be used both on centos and ubuntu

Change-Id: I18adb1c1daa11d4f84518e449662ffe2b4e9dbf7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/438776/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,9bdc8b7af1ed71aadee4fc8ff2e109683e9dbe96,update_xfs_script, /sbin/mkfs.xfs {xfs_file}, mkfs.xfs {xfs_file},1,1
openstack%2Ftacker~master~Ie7481dcf2c9a37baefc5a698890506342fd7d9fe,openstack/tacker,master,Ie7481dcf2c9a37baefc5a698890506342fd7d9fe,Fix broken link in doc,MERGED,2017-02-21 11:38:40.000000000,2017-02-28 03:02:04.000000000,2017-02-28 03:02:04.000000000,"[{'_account_id': 3}, {'_account_id': 12455}, {'_account_id': 13380}, {'_account_id': 19644}]","[{'number': 1, 'created': '2017-02-21 11:38:40.000000000', 'files': ['doc/source/devref/vnffg_usage_guide.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/6b1f0d47254b03c041cda5627b2dfcaf7a35825a', 'message': 'Fix broken link in doc\n\nFix broken link for vnffgd_template_description.rst in\nvnffg_usage_guide.rst file.\n\nChange-Id: Ie7481dcf2c9a37baefc5a698890506342fd7d9fe\n'}]",0,436420,6b1f0d47254b03c041cda5627b2dfcaf7a35825a,13,4,1,18955,,,0,"Fix broken link in doc

Fix broken link for vnffgd_template_description.rst in
vnffg_usage_guide.rst file.

Change-Id: Ie7481dcf2c9a37baefc5a698890506342fd7d9fe
",git fetch https://review.opendev.org/openstack/tacker refs/changes/20/436420/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/vnffg_usage_guide.rst'],1,6b1f0d47254b03c041cda5627b2dfcaf7a35825a,,<https://github.com/openstack/tacker/blob/master/doc/source/devref,<https://github.com/openstack/tacker/tree/doc/source/devref,1,1
openstack%2Fdeb-openstack-pkg-tools~debian%2Focata~Id2b04998ef6579271d0cbe2df9adf9a08e3377ec,openstack/deb-openstack-pkg-tools,debian/ocata,Id2b04998ef6579271d0cbe2df9adf9a08e3377ec,"Update package tools for Ocata release, part 1",MERGED,2017-02-24 01:49:05.000000000,2017-02-28 02:59:39.000000000,2017-02-28 02:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2017-02-24 01:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/398de776c55b352b050044895a436af332f37823', 'message': 'Update package tools for Ocata release\n\nUpdate the Debian package tools module for CI/CD testing of\nthe OpenStack Ocata release.\n\nChange-Id: Id2b04998ef6579271d0cbe2df9adf9a08e3377ec\n'}, {'number': 2, 'created': '2017-02-27 21:33:49.000000000', 'files': ['.gitreview', 'debian/changelog', 'debian/gbp.conf', 'build-tools/pkgos-infra-install-sbuild', 'debian/control'], 'web_link': 'https://opendev.org/openstack/deb-openstack-pkg-tools/commit/8d2766b399192ba6e3cc2c4df1b8c742ad5dad6c', 'message': 'Update package tools for Ocata release, part 1\n\nPartial update to the Debian package tools module for CI/CD\ntesting of the OpenStack Ocata release. The name of the\nauto-backport archives have to be updated in a separate\ncommit.\n\nChange-Id: Id2b04998ef6579271d0cbe2df9adf9a08e3377ec\n'}]",0,437750,8d2766b399192ba6e3cc2c4df1b8c742ad5dad6c,8,2,2,9397,,,0,"Update package tools for Ocata release, part 1

Partial update to the Debian package tools module for CI/CD
testing of the OpenStack Ocata release. The name of the
auto-backport archives have to be updated in a separate
commit.

Change-Id: Id2b04998ef6579271d0cbe2df9adf9a08e3377ec
",git fetch https://review.opendev.org/openstack/deb-openstack-pkg-tools refs/changes/50/437750/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'debian/changelog', 'debian/gbp.conf', 'build-tools/pkgos-infra-install-sbuild', 'debian/control']",5,398de776c55b352b050044895a436af332f37823,ocata-pkg-update,Vcs-Browser: https://git.openstack.org/cgit/openstack/deb-openstack-pkg-tools?h=debian%2Focata Vcs-Git: https://git.openstack.org/openstack/deb-openstack-pkg-tools -b debian/ocata,Vcs-Browser: https://git.openstack.org/cgit/openstack/deb-openstack-pkg-tools?h=debian%2Fnewton Vcs-Git: https://git.openstack.org/openstack/deb-openstack-pkg-tools -b debian/newton,23,17
openstack%2Ftripleo-ci~master~I267e9d7a301ffd87fd2d231fc9214ae8a4fab3c2,openstack/tripleo-ci,master,I267e9d7a301ffd87fd2d231fc9214ae8a4fab3c2,Drop ceph workaround for mitaka,MERGED,2017-01-26 15:32:02.000000000,2017-02-28 02:56:33.000000000,2017-02-28 02:56:33.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 10873}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-01-26 15:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c8b7bae4a867e1403160cb9f45e4c3f37ec01c3c', 'message': ""Drop ceph workaround for mitaka\n\nOnce Ceph works out the version conflict on their side we shouldn't\nneed this anymore.\n\nChange-Id: I267e9d7a301ffd87fd2d231fc9214ae8a4fab3c2\n""}, {'number': 2, 'created': '2017-02-15 00:20:57.000000000', 'files': ['toci_instack_ovb.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a768e499c63f7103a8d1acccd8d39fe9d8738ff', 'message': ""Drop ceph workaround for mitaka\n\nOnce Ceph works out the version conflict on their side we shouldn't\nneed this anymore.\n\nChange-Id: I267e9d7a301ffd87fd2d231fc9214ae8a4fab3c2\n""}]",0,425754,1a768e499c63f7103a8d1acccd8d39fe9d8738ff,16,4,2,6928,,,0,"Drop ceph workaround for mitaka

Once Ceph works out the version conflict on their side we shouldn't
need this anymore.

Change-Id: I267e9d7a301ffd87fd2d231fc9214ae8a4fab3c2
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/54/425754/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_instack_ovb.sh'],1,c8b7bae4a867e1403160cb9f45e4c3f37ec01c3c,drop-mitaka-workarounds,,if [ $STABLE_RELEASE = mitaka ]; then # FIXME(bnemec): Work around https://bugs.launchpad.net/tripleo/+bug/1654611 sudo sed -i -e 's/\(\[centos-ceph-hammer\]\)/\1\npriority=1/' /etc/yum.repos.d/CentOS-Ceph-Hammer.repo fi ,0,5
openstack%2Ftripleo-ci~master~I2c08b798f9ce64a3015ddaf74ac59fb7a13b6bfc,openstack/tripleo-ci,master,I2c08b798f9ce64a3015ddaf74ac59fb7a13b6bfc,Remove rdo-qemu-ev workaround,MERGED,2017-01-26 15:32:02.000000000,2017-02-28 02:55:32.000000000,2017-02-28 02:55:32.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-01-26 15:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e28fd2b15bf5154152e708c4845d52b5f623a290', 'message': ""Remove rdo-qemu-ev workaround\n\nI noticed that we had a warning message about this repo being\npresent twice in a recent job.  I'm guessing this workaround is now\nbeing applied in dlrn, so we don't need to do it.\n\nChange-Id: I2c08b798f9ce64a3015ddaf74ac59fb7a13b6bfc\n""}, {'number': 2, 'created': '2017-02-15 00:20:57.000000000', 'files': ['toci_instack_ovb.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/96358ac05e4573ecf8e8312f0b8c2f2c66b5b674', 'message': ""Remove rdo-qemu-ev workaround\n\nI noticed that we had a warning message about this repo being\npresent twice in a recent job.  I'm guessing this workaround is now\nbeing applied in dlrn, so we don't need to do it.\n\nChange-Id: I2c08b798f9ce64a3015ddaf74ac59fb7a13b6bfc\n""}]",0,425753,96358ac05e4573ecf8e8312f0b8c2f2c66b5b674,27,5,2,6928,,,0,"Remove rdo-qemu-ev workaround

I noticed that we had a warning message about this repo being
present twice in a recent job.  I'm guessing this workaround is now
being applied in dlrn, so we don't need to do it.

Change-Id: I2c08b798f9ce64a3015ddaf74ac59fb7a13b6bfc
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/53/425753/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_instack_ovb.sh'],1,e28fd2b15bf5154152e708c4845d52b5f623a290,drop-mitaka-workarounds, # FIXME(bnemec): Work around https://bugs.launchpad.net/tripleo/+bug/1654611,# FIXME(bnemec): Work around https://bugs.launchpad.net/tripleo/+bug/1654615 cat > /tmp/delorean-ev.repo <<EOF [rdo-qemu-ev] name=RDO CentOS-\$releasever - QEMU EV baseurl=http://mirror.centos.org/centos/7/virt/\$basearch/kvm-common/ gpgcheck=0 enabled=1 EOF sudo mv /tmp/delorean-ev.repo /etc/yum.repos.d # And also https://bugs.launchpad.net/tripleo/+bug/1654611,1,10
openstack%2Fsenlin~master~I15ab697fad8a91f9310281ec7eed65b469dc5adb,openstack/senlin,master,I15ab697fad8a91f9310281ec7eed65b469dc5adb,WIP: Fix tempest test,ABANDONED,2017-02-24 05:45:16.000000000,2017-02-28 02:45:10.000000000,,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-24 05:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/cc6611b838752e439f7092bb43408f551097055c', 'message': ""Fix server spec used for tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}, {'number': 2, 'created': '2017-02-24 07:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b7d266c2e943799cc8047ed6a198d0d335fb14f7', 'message': ""WIP: Fix tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}, {'number': 3, 'created': '2017-02-24 08:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/9b5b7e9fbd1f86e7730f768f941d8ebe3474c18d', 'message': ""WIP: Fix tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}, {'number': 4, 'created': '2017-02-24 09:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/530a260ab276ecd4b9fcf79f9c441a7bc1bbfb57', 'message': ""WIP: Fix tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nDepends-On: I08fe9a699ee0065672afad0af8b070efc3f633da\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}, {'number': 5, 'created': '2017-02-27 12:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/26a78d829aa699ca0bcb18b59a3050e798e88f4b', 'message': ""WIP: Fix tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nDepends-On: I08fe9a699ee0065672afad0af8b070efc3f633da\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}, {'number': 6, 'created': '2017-02-28 01:12:28.000000000', 'files': ['senlin/tests/tempest/pre_test_hook.sh', 'senlin/tests/tempest/common/constants.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7ca06112c20d2a21d216dfe7b9eeb290a9ceea80', 'message': ""WIP: Fix tempest test\n\nWe don't know why keypair has been created at the gate side. This patch\nremoves the assumption that there is a keypair named 'oskey'.\n\nChange-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb\n""}]",0,437798,7ca06112c20d2a21d216dfe7b9eeb290a9ceea80,14,2,6,8246,,,0,"WIP: Fix tempest test

We don't know why keypair has been created at the gate side. This patch
removes the assumption that there is a keypair named 'oskey'.

Change-Id: I15ab697fad8a91f9310281ec7eed65b469dc5adb
",git fetch https://review.opendev.org/openstack/senlin refs/changes/98/437798/5 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/common/constants.py'],1,cc6611b838752e439f7092bb43408f551097055c,fix-tempest,," ""key_name"": ""oskey""",0,1
openstack%2Fsenlin~master~I7f24fad1c281f6cbf2e59273661e4cded13dd2b0,openstack/senlin,master,I7f24fad1c281f6cbf2e59273661e4cded13dd2b0,[DNM]Debug gate job,ABANDONED,2017-02-24 07:42:05.000000000,2017-02-28 02:44:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-24 07:42:05.000000000', 'files': ['senlin/tests/tempest/pre_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c39d5288df7e5a9c73a59384ada1f9ce5c852a47', 'message': ""[DNM]Debug gate job\n\nThis patch is for debugging gate job. Please don't merge it.\n\nChange-Id: I7f24fad1c281f6cbf2e59273661e4cded13dd2b0\n""}]",0,437821,c39d5288df7e5a9c73a59384ada1f9ce5c852a47,3,1,1,11034,,,0,"[DNM]Debug gate job

This patch is for debugging gate job. Please don't merge it.

Change-Id: I7f24fad1c281f6cbf2e59273661e4cded13dd2b0
",git fetch https://review.opendev.org/openstack/senlin refs/changes/21/437821/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/pre_test_hook.sh'],1,c39d5288df7e5a9c73a59384ada1f9ce5c852a47,test-gate-job, # For gate job test cat $localconf,,3,0
openstack%2Fsenlin~master~I43458f2a9c6d709d670b36cbd2ab538a8dbc8a2e,openstack/senlin,master,I43458f2a9c6d709d670b36cbd2ab538a8dbc8a2e,Improve the slow path of lock acquire,MERGED,2017-02-22 01:37:00.000000000,2017-02-28 02:35:55.000000000,2017-02-28 02:35:55.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-22 01:37:00.000000000', 'files': ['senlin/tests/unit/engine/test_senlin_lock.py', 'senlin/engine/senlin_lock.py', 'TODO.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2c3d98ff93898f9e24770c8be670560615974891', 'message': 'Improve the slow path of lock acquire\n\nThe slow path of cluster_lock_acquire was implemented as only marking\nthe related action as a failure when stealing locks from a dead engine.\nThis is problematic. We are not sure if the dead engine has also\nimpacted other objects, e.g. nodes.\n\nThis patch replaces that cleansing call with a more thorough solution.\n\nChange-Id: I43458f2a9c6d709d670b36cbd2ab538a8dbc8a2e\n'}]",3,436721,2c3d98ff93898f9e24770c8be670560615974891,24,3,1,8246,,,0,"Improve the slow path of lock acquire

The slow path of cluster_lock_acquire was implemented as only marking
the related action as a failure when stealing locks from a dead engine.
This is problematic. We are not sure if the dead engine has also
impacted other objects, e.g. nodes.

This patch replaces that cleansing call with a more thorough solution.

Change-Id: I43458f2a9c6d709d670b36cbd2ab538a8dbc8a2e
",git fetch https://review.opendev.org/openstack/senlin refs/changes/21/436721/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/test_senlin_lock.py', 'senlin/engine/senlin_lock.py', 'TODO.rst']",3,2c3d98ff93898f9e24770c8be670560615974891,cleanse-lock-during-lock,, - Try invoke db.sqlalchemy.api.gc_by_engine when attempting stealing during acquire_lock ,10,13
openstack%2Fkeystone~stable%2Focata~I4efe4b1b90c93110509cd599f9dd047c313dade3,openstack/keystone,stable/ocata,I4efe4b1b90c93110509cd599f9dd047c313dade3,Fix MFA rule checks for LDAP auth,MERGED,2017-02-24 17:02:29.000000000,2017-02-28 02:29:48.000000000,2017-02-28 02:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6486}]","[{'number': 1, 'created': '2017-02-24 17:02:29.000000000', 'files': ['keystone/tests/unit/default_fixtures.py', 'keystone/tests/unit/identity/test_backends.py', 'keystone/identity/backends/ldap/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/95160d1812104d90ff096cb2d32390b065bfeaae', 'message': 'Fix MFA rule checks for LDAP auth\n\nLDAP authentication was broken by the addition of MFA rule checking.\nThis patch fixes that.\n\nChange-Id: I4efe4b1b90c93110509cd599f9dd047c313dade3\nCloses-Bug: #1662762\n(cherry picked from commit 4e0029455ab45e3b9a15fe9fc151c14c502b7bdd)\n'}]",0,437998,95160d1812104d90ff096cb2d32390b065bfeaae,8,4,1,10608,,,0,"Fix MFA rule checks for LDAP auth

LDAP authentication was broken by the addition of MFA rule checking.
This patch fixes that.

Change-Id: I4efe4b1b90c93110509cd599f9dd047c313dade3
Closes-Bug: #1662762
(cherry picked from commit 4e0029455ab45e3b9a15fe9fc151c14c502b7bdd)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/98/437998/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/default_fixtures.py', 'keystone/tests/unit/identity/test_backends.py', 'keystone/identity/backends/ldap/core.py']",3,95160d1812104d90ff096cb2d32390b065bfeaae,bug/1662762," if 'options' in values: values.pop('options') # can't specify options values['options'] = {} # options always empty def get(self, user_id, ldap_filter=None): obj = super(UserApi, self).get(user_id, ldap_filter=ldap_filter) obj['options'] = {} # options always empty return obj def get_all(self, ldap_filter=None, hints=None): objs = super(UserApi, self).get_all(ldap_filter=ldap_filter, hints=hints) for obj in objs: obj['options'] = {} # options always empty return objs def update(self, user_id, values, old_obj=None): if old_obj is None: old_obj = self.get(user_id) # don't support updating options if 'options' in old_obj: old_obj.pop('options') if 'options' in values: values.pop('options') values = super(UserApi, self).update(user_id, values, old_obj) values['options'] = {} # options always empty return values ",,37,1
openstack%2Fkeystone~master~Iaff357efdda7b08b0555b7c56d68222f5610ad80,openstack/keystone,master,Iaff357efdda7b08b0555b7c56d68222f5610ad80,Exclusively use restore_padding method in unpacking fernet tokens,MERGED,2017-02-25 20:31:29.000000000,2017-02-28 02:29:07.000000000,2017-02-28 02:29:07.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 13478}]","[{'number': 1, 'created': '2017-02-25 20:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2cc652730dc7ae8c8107cc1d8ee45d127c8539e2', 'message': 'Exclusively use restore_padding method in unpacking fernet tokens\n\nAs of Mitaka we no longer need to validate both padded and unpadded\nfernet tokens.\n\nChange-Id: Iaff357efdda7b08b0555b7c56d68222f5610ad80\n'}, {'number': 2, 'created': '2017-02-26 20:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2ba405990dbe82c2cfda75178e9eb559b0418ab1', 'message': 'Exclusively use restore_padding method in unpacking fernet tokens\n\nAs of Mitaka we no longer need to validate both padded and unpadded\nfernet tokens.\n\nChange-Id: Iaff357efdda7b08b0555b7c56d68222f5610ad80\n'}, {'number': 3, 'created': '2017-02-27 16:25:11.000000000', 'files': ['keystone/token/providers/fernet/token_formatters.py', 'keystone/tests/unit/token/test_fernet_provider.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9b911daf6f39f456126466df3230ddf19980ff3c', 'message': 'Exclusively use restore_padding method in unpacking fernet tokens\n\nAs of Mitaka we no longer need to validate both padded and unpadded\nfernet tokens.\n\nImplements: bp removed-as-of-pike\n\nChange-Id: Iaff357efdda7b08b0555b7c56d68222f5610ad80\n'}]",0,438207,9b911daf6f39f456126466df3230ddf19980ff3c,17,3,3,16465,,,0,"Exclusively use restore_padding method in unpacking fernet tokens

As of Mitaka we no longer need to validate both padded and unpadded
fernet tokens.

Implements: bp removed-as-of-pike

Change-Id: Iaff357efdda7b08b0555b7c56d68222f5610ad80
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/438207/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/token/providers/fernet/token_formatters.py'],1,2cc652730dc7ae8c8107cc1d8ee45d127c8539e2,bp/removed-as-of-pike, token = TokenFormatter.restore_padding(token)," # TODO(lbragstad): Restore padding on token before decoding it. # Initially in Kilo, Fernet tokens were returned to the user with # padding appended to the token. Later in Liberty this padding was # removed and restored in the Fernet provider. The following if # statement ensures that we can validate tokens with and without token # padding, in the event of an upgrade and the tokens that are issued # throughout the upgrade. Remove this if statement when Mitaka opens # for development and exclusively use the restore_padding() class # method. if token.endswith('%3D'): token = urllib.parse.unquote(token) else: token = TokenFormatter.restore_padding(token)",1,13
openstack%2Fnetworking-odl~master~Id70292163fdda15529e04e0e40014cad6c8e005f,openstack/networking-odl,master,Id70292163fdda15529e04e0e40014cad6c8e005f,Fix neutron-odl-ovs-hostconfig failure on compute,MERGED,2017-02-18 05:08:22.000000000,2017-02-28 02:26:28.000000000,2017-02-28 02:26:28.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 20208}, {'_account_id': 22342}]","[{'number': 1, 'created': '2017-02-18 05:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/dce84f2c68beb482ef72d049c5ecaf196b33ccd5', 'message': 'Fix neutron-odl-ovs-hostconfig failure on compute\n\nneutron-odl-ovs-hostconfig failing in devstack on compute\nnodes due to not finding neutron.conf. Removing neutron.conf\nas it is not needed for setting up hostconfig on compute or\ncontroller nodes.\n\nChange-Id: Id70292163fdda15529e04e0e40014cad6c8e005f\n'}, {'number': 2, 'created': '2017-02-22 19:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/4d1016f75d74c121d53f6afae8a8359c4b176990', 'message': 'Fix neutron-odl-ovs-hostconfig failure on compute\n\nneutron-odl-ovs-hostconfig failing in devstack on compute\nnodes due to not finding neutron.conf. Removing neutron.conf\nas it is not needed for setting up hostconfig on compute nodes.\n\nCloses-Bug: #1665844\nChange-Id: Id70292163fdda15529e04e0e40014cad6c8e005f\n'}, {'number': 3, 'created': '2017-02-23 01:30:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/85b74226f964236124d49e9f01837a206396469b', 'message': 'Fix neutron-odl-ovs-hostconfig failure on compute\n\nneutron-odl-ovs-hostconfig failing in devstack on compute\nnodes due to not finding neutron.conf. Removing neutron.conf\nas it is not needed for setting up hostconfig on compute nodes.\n\nCloses-Bug: #1665844\nChange-Id: Id70292163fdda15529e04e0e40014cad6c8e005f\n'}, {'number': 4, 'created': '2017-02-23 19:28:14.000000000', 'files': ['devstack/settings.odl', 'devstack/entry_points'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/b10c04195f32373b0d8892cf5cf1f83e12a19d8e', 'message': 'Fix neutron-odl-ovs-hostconfig failure on compute\n\nneutron-odl-ovs-hostconfig failing in devstack on compute\nnodes due to not finding neutron.conf. Removing neutron.conf\nas it is not needed for setting up hostconfig on compute nodes.\n\nCloses-Bug: #1665844\nChange-Id: Id70292163fdda15529e04e0e40014cad6c8e005f\n'}]",5,435657,b10c04195f32373b0d8892cf5cf1f83e12a19d8e,23,4,4,20208,,,0,"Fix neutron-odl-ovs-hostconfig failure on compute

neutron-odl-ovs-hostconfig failing in devstack on compute
nodes due to not finding neutron.conf. Removing neutron.conf
as it is not needed for setting up hostconfig on compute nodes.

Closes-Bug: #1665844
Change-Id: Id70292163fdda15529e04e0e40014cad6c8e005f
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/57/435657/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/entry_points'],1,dce84f2c68beb482ef72d049c5ecaf196b33ccd5,bug/1665844, sudo neutron-odl-ovs-hostconfig $ODL_OVS_HOSTCONFIGS_OPTIONS, sudo neutron-odl-ovs-hostconfig --config-file=$NEUTRON_CONF $ODL_OVS_HOSTCONFIGS_OPTIONS,1,1
openstack%2Fnetworking-odl~master~I5f33188427c482bbf6661e1602793e368d30aadf,openstack/networking-odl,master,I5f33188427c482bbf6661e1602793e368d30aadf,Updated from global requirements,MERGED,2017-02-27 16:45:36.000000000,2017-02-28 02:26:07.000000000,2017-02-28 02:26:07.000000000,"[{'_account_id': 3}, {'_account_id': 333}]","[{'number': 1, 'created': '2017-02-27 16:45:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/70545576ba4060dbba646ba43650747fe2921a58', 'message': 'Updated from global requirements\n\nChange-Id: I5f33188427c482bbf6661e1602793e368d30aadf\n'}]",0,438611,70545576ba4060dbba646ba43650747fe2921a58,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I5f33188427c482bbf6661e1602793e368d30aadf
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/11/438611/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,70545576ba4060dbba646ba43650747fe2921a58,openstack/requirements,neutron-lib>=1.2.0 # Apache-2.0,neutron-lib>=1.1.0 # Apache-2.0,1,1
openstack%2Fdevstack-gate~master~Ia5bbc3d5dc405af0417624b92816269775809e1a,openstack/devstack-gate,master,Ia5bbc3d5dc405af0417624b92816269775809e1a,Enable peakmem_tracker in gate,MERGED,2017-02-15 20:57:29.000000000,2017-02-28 02:02:09.000000000,2017-02-28 02:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 8655}, {'_account_id': 8726}]","[{'number': 1, 'created': '2017-02-15 20:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2624f675f5b675dff0af77ffc0ff3370b0ea3825', 'message': ""Enable peakmem_tracker in gate\n\nWe experience unexplained behaviour lately in some gate jobs where\noom-killer is triggered while swap is not used. We suspect that it may\nbe because some process mlocked some pages in RAM. This service should\nhopefully help us to understand if that's the case.\n\nChange-Id: Ia5bbc3d5dc405af0417624b92816269775809e1a\n""}, {'number': 2, 'created': '2017-02-22 20:47:14.000000000', 'files': ['features.yaml', 'test-features.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/57b3b8912989496fb11e7ce30d54cddb601f785e', 'message': ""Enable peakmem_tracker in gate\n\nWe experience unexplained behaviour lately in some gate jobs where\noom-killer is triggered while swap is not used. We suspect that it may\nbe because some process mlocked some pages in RAM. This service should\nhopefully help us to understand if that's the case.\n\nChange-Id: Ia5bbc3d5dc405af0417624b92816269775809e1a\n""}]",0,434511,57b3b8912989496fb11e7ce30d54cddb601f785e,12,5,2,9656,,,0,"Enable peakmem_tracker in gate

We experience unexplained behaviour lately in some gate jobs where
oom-killer is triggered while swap is not used. We suspect that it may
be because some process mlocked some pages in RAM. This service should
hopefully help us to understand if that's the case.

Change-Id: Ia5bbc3d5dc405af0417624b92816269775809e1a
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/11/434511/2 && git format-patch -1 --stdout FETCH_HEAD,"['features.yaml', 'test-features.sh']",2,2624f675f5b675dff0af77ffc0ff3370b0ea3825,434511,"TEMPEST_FULL_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,peakmem_tracker,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,n-net,placement-api"" TEMPEST_NEUTRON_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,peakmem_tracker,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,placement-api"" TEMPEST_HEAT_SLOW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,peakmem_tracker,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,placement-api"" GRENADE_NEW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,peakmem_tracker,tempest,n-net,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,placement-api""","TEMPEST_FULL_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,n-net,placement-api"" TEMPEST_NEUTRON_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,placement-api"" TEMPEST_HEAT_SLOW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,horizon,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-metering,placement-api"" GRENADE_NEW_MASTER=""n-api,n-crt,n-obj,n-cpu,n-sch,n-cond,n-novnc,n-cauth,g-api,g-reg,key,c-api,c-vol,c-sch,c-bak,cinder,s-proxy,s-account,s-container,s-object,mysql,rabbit,dstat,tempest,n-net,ceilometer-acompute,ceilometer-acentral,ceilometer-collector,ceilometer-api,ceilometer-alarm-notifier,ceilometer-alarm-evaluator,ceilometer-anotification,placement-api""",6,6
openstack%2Freleases~master~I7235aca168bdbd0700a6c72d1d1a7195f6b6938c,openstack/releases,master,I7235aca168bdbd0700a6c72d1d1a7195f6b6938c,ironic-lib 2.6.0,MERGED,2017-01-20 13:31:45.000000000,2017-02-28 01:58:13.000000000,2017-02-28 01:58:13.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 10343}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-01-20 13:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7860003501bf174765cd8b9a6b11548d4b549b05', 'message': 'ironic-lib 2.6.0\n\nChange-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c\n'}, {'number': 2, 'created': '2017-02-14 13:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0336fed897ebc0020d6a6ad96169fa03cbf915d3', 'message': 'ironic-lib 2.6.0\n\nChange-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c\n'}, {'number': 3, 'created': '2017-02-28 01:35:57.000000000', 'files': ['deliverables/pike/ironic-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/236264a25cec63b71b4a04abb81b336ac0b4223e', 'message': 'ironic-lib 2.6.0\n\nChange-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c\n'}]",0,423263,236264a25cec63b71b4a04abb81b336ac0b4223e,13,4,3,10343,,,0,"ironic-lib 2.6.0

Change-Id: I7235aca168bdbd0700a6c72d1d1a7195f6b6938c
",git fetch https://review.opendev.org/openstack/releases refs/changes/63/423263/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/ironic-lib.yaml'],1,7860003501bf174765cd8b9a6b11548d4b549b05,ironic-lib-bug-1657808,--- launchpad: ironic-lib team: ironic type: library release-model: cycle-with-intermediary send-announcements-to: openstack-dev@lists.openstack.org include-pypi-link: yes releases: - version: 2.6.0 projects: - repo: openstack/ironic-lib hash: 4ae48d0b212c16c8b49d4f1144c073b3a3206597 ,,12,0
openstack%2Fwatcher~master~I2218a98182001bef65fbc17ae305cfadf341930e,openstack/watcher,master,I2218a98182001bef65fbc17ae305cfadf341930e,Fix no endpoints of ceilometer in devstack environment setup.,MERGED,2017-02-24 13:45:08.000000000,2017-02-28 01:55:53.000000000,2017-02-28 01:55:53.000000000,"[{'_account_id': 3}, {'_account_id': 18971}, {'_account_id': 22775}]","[{'number': 1, 'created': '2017-02-24 13:45:08.000000000', 'files': ['devstack/local.conf.controller'], 'web_link': 'https://opendev.org/openstack/watcher/commit/68e4bc4d87fbbe9693a242c717dc0646ae59dd45', 'message': 'Fix no endpoints of ceilometer in devstack environment setup.\n\nThere are not any endpoints for `ceilometer` with devstack/\nlocal.conf.controller. The service `ceilometer-api` should\nbe enabled explicitly.\n\nChange-Id: I2218a98182001bef65fbc17ae305cfadf341930e\nCloses-Bug: #1667678\n'}]",0,437901,68e4bc4d87fbbe9693a242c717dc0646ae59dd45,8,3,1,23950,,,0,"Fix no endpoints of ceilometer in devstack environment setup.

There are not any endpoints for `ceilometer` with devstack/
local.conf.controller. The service `ceilometer-api` should
be enabled explicitly.

Change-Id: I2218a98182001bef65fbc17ae305cfadf341930e
Closes-Bug: #1667678
",git fetch https://review.opendev.org/openstack/watcher refs/changes/01/437901/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/local.conf.controller'],1,68e4bc4d87fbbe9693a242c717dc0646ae59dd45,bug/1667678,# Enable the ceilometer api explicitly(bug:1667678) enable_service ceilometer-api,,2,0
openstack%2Fopenstacksdk~master~I72c0be77d96f3891748cdd69c382211dc20dbf5e,openstack/openstacksdk,master,I72c0be77d96f3891748cdd69c382211dc20dbf5e,Add missing attribute to Subnet resource,MERGED,2017-02-27 11:12:15.000000000,2017-02-28 01:48:22.000000000,2017-02-28 01:48:22.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 13252}, {'_account_id': 17776}]","[{'number': 1, 'created': '2017-02-27 11:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/13a16032e8e5525af7430076382abf4eb1d7b1c5', 'message': 'Add missing attribute to Subnet resource\n\nThe use_default_subnetpool attribute was missing, leading to errors when\ntrying to create a subnet using the default subnet pool.\n\nChange-Id: I72c0be77d96f3891748cdd69c382211dc20dbf5e\nCloses-Bug: 1668223\n'}, {'number': 2, 'created': '2017-02-27 14:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/58f0a922d213b9cdfccf63b7d07456347d1ef08d', 'message': 'Add missing attribute to Subnet resource\n\nThe use_default_subnet_pool attribute was missing, leading to errors when\ntrying to create a subnet using the default subnet pool.\n\nChange-Id: I72c0be77d96f3891748cdd69c382211dc20dbf5e\nPartial-Bug: 1668223\n'}, {'number': 3, 'created': '2017-02-27 15:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d3d91e8bb46d4239932f35c894d4c01841c9fea7', 'message': 'Add missing attribute to Subnet resource\n\nThe use_default_subnet_pool attribute was missing, leading to errors when\ntrying to create a subnet using the default subnet pool.\n\nChange-Id: I72c0be77d96f3891748cdd69c382211dc20dbf5e\nPartial-Bug: 1668223\n'}, {'number': 4, 'created': '2017-02-27 16:49:20.000000000', 'files': ['openstack/network/v2/subnet.py', 'openstack/tests/unit/network/v2/test_subnet.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0d044b2ecd432f82b7551f7e44ff501d2235f3f1', 'message': 'Add missing attribute to Subnet resource\n\nThe use_default_subnet_pool attribute was missing, leading to errors when\ntrying to create a subnet using the default subnet pool.\n\nChange-Id: I72c0be77d96f3891748cdd69c382211dc20dbf5e\nPartial-Bug: 1668223\n'}]",9,438441,0d044b2ecd432f82b7551f7e44ff501d2235f3f1,28,5,4,13252,,,0,"Add missing attribute to Subnet resource

The use_default_subnet_pool attribute was missing, leading to errors when
trying to create a subnet using the default subnet pool.

Change-Id: I72c0be77d96f3891748cdd69c382211dc20dbf5e
Partial-Bug: 1668223
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/41/438441/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/network/v2/subnet.py'],1,13a16032e8e5525af7430076382abf4eb1d7b1c5,bug/1668223, #: Whether to use the default subnet pool to obtain a CIDR. use_default_subnetpool = resource.Body('use_default_subnetpool'),,2,0
openstack%2Fkeystone-specs~master~I229fb693e577335d48766a3c6b470f9cc0dd80eb,openstack/keystone-specs,master,I229fb693e577335d48766a3c6b470f9cc0dd80eb,API keys,ABANDONED,2017-02-27 18:23:25.000000000,2017-02-28 01:37:16.000000000,,"[{'_account_id': 3}, {'_account_id': 18338}]","[{'number': 1, 'created': '2017-02-27 18:23:25.000000000', 'files': ['specs/keystone/backlog/api-keys.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/e8daf20a4038087ff2dfcd44e9b067ad12653d8a', 'message': 'API keys\n\nThis specification targets an API key implementation based on\ndecoupling the authentication method from the user identity work that\nhas been happening since Mitaka.\n\nbp api-keys\n\nChange-Id: I229fb693e577335d48766a3c6b470f9cc0dd80eb\n'}]",0,438667,e8daf20a4038087ff2dfcd44e9b067ad12653d8a,4,2,1,5046,,,0,"API keys

This specification targets an API key implementation based on
decoupling the authentication method from the user identity work that
has been happening since Mitaka.

bp api-keys

Change-Id: I229fb693e577335d48766a3c6b470f9cc0dd80eb
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/67/438667/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/keystone/backlog/api-keys.rst'],1,e8daf20a4038087ff2dfcd44e9b067ad12653d8a,bp/api-keys,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======== API Keys ======== `bp api-keys <https://blueprints.launchpad.net/keystone/+spec/api-keys>`_ Since the initial implementation of `shadow users_`, keystone has been working towards decoupling authentication methods from identities. Discussions on that work continued at the Pike PTG in Atlanta to include authentication via API key. .. _shadow users: http://specs.openstack.org/openstack/keystone-specs/specs/keystone/mitaka/shadow-users.html Problem Description =================== Keystone has never pursued the concept of API keys as a supported authentication method. Instead, keystone has support for OAuth and delegation mechanisms via `trusts`_. With the shadow user work, we have the ability to decouple the way in which a user authenticates from the actual user identity. This ultimately means that regardless of the way a user authenticates with keystone, the token they receive should map back to a consistent user. This specification proposes the ability for users to create API keys that allows specific role delegation to a project. Authentication via API key will be linked to the user that created it. Service accounts are a great example that would benefit from using API keys. Currently, if a service in OpenStack needs to communicate to other services via their APIs, it is required to create a user in keystone that models that service. These accounts are known as service users, or service accounts. Each service is then configured with the user name and password of the account. At run time, the service uses these credentials to talk to other service and perform actions across OpenStack. It is common to see service users for each service that has this requirement. It is also common to see each service assigned a specific service role, or the admin role depending on the operations that service needs to execute. This can be confusing since there are multiple accounts modeling services in OpenStack. From a security perspective, it can be considered unfavorable to have service credentials written to a file on disk, especially if the service has administrator privileges on a project. With API keys, we can remove the credentials from service configuration files by replacing it with an API key that is specific to the service consuming it. We also have the ability to trace everything back to a single service user. For example, let's say a deployment has a single `service` role that is assigned to all service users. The deployer can generate API keys with the service user account and give each service an API key, instead of a dedicate service user and password. If a deployment has specific roles for each service (i.e. `nova_service` role, `cinder_service` role, etc...) then the service user should have each of those roles assigned. When creating API keys for this case, it should be possible to create a single API key scoped to a specific role. As a result, the nova service would only be delegated the `nova_service` role. The benefit here would be that all services would only have permission to the operations they require, while mapping all service-like operations back to a single user. This is also useful for users who have applications that need to query services for information, or perform specific operations. Instead of having to create a specific user in keystone to model that application and create a trust, the user can create an API key for the application to consume. This also keeps the user's credentials out of the applications configuration file. This provides consuming applications the ability to be more secure. .. _trusts: https://developer.openstack.org/api-ref/identity/v3-ext/index.html#os-trust-api Proposed Change =============== A new API key resource will be added to keystone. API keys should adhere to the following: * Must be immutable * Must have quota applied on a per user basis (i.e. 5 API keys per user) * Must have a role on a project that the user creating the API key has * Must only be revealed to the user once, after creation time * Must include API key Id and value at authentication time * Cannot be able to create new API keys * Cannot be able to delete API keys * Should support the ability to expire * Should have description fields Alternatives ------------ Possible alternatives are continued use of trusts and establishing trustee/trustor relationships and using OAuth authentication. Trust workflows are suboptimal in this specific case because they require application specific accounts to be created in keystone. They also might require the trustor's username and password to create the trust. Both of which increase possible attack vectors. The OAuth flow is similar to that of API keys and it can be worked on, improved, documented in parallel to API key work. Security Impact --------------- This change has an overall positive impact on the OpenStack ecosystem because of the following: * Instead of having a service user for each service, all services can use a single service account. This decreases the attack vector of gaining access to privileged operations by reducing the number of accounts to attack. * Provides a way for users to grant access to applications without creating accounts (users) to model those application and grant them passwords. * Service user names and passwords are kept out of configuration files. While API keys are still extremely sensitive, if compromised they do not allow attackers to glean service user password conventions from configuration. * API keys can be gracefully rotated out of use and deleted periodically, allowing operators another way to prevent compromised service accounts in combination with regular password rotation. The API key value must be hashed before being stored in keystone. Notifications Impact -------------------- None. Other End User Impact --------------------- End users that have applications that monitor or interact with OpenStack services should be able to leverage this feature to improve the overall security of consuming applications. Performance Impact ------------------ Authenticating via API key will require hashing in order to validate the API key information provided in the request against any pre-existing API keys. The performance impact of hashing should be documented in the implementation, but it should be no different than what is currently done for password authentication for local users stored in a database. Other Deployer Impact --------------------- Deployers should notice the following maintenance improvements: * Operators only need to enforce security on a single service account instead of multiple. * Password rotation policies for service account no longer requires redeploying service configuration files. Once a password is changes for the service, the existing API keys in the various service configuration files will still work. * Operators can gracefully rotate API keys through a deployment. A set of services can use two different API keys at the same time allowing a smooth migration. Once all services are using the new API key, the old API key can be deleted. With service accounts and passwords, this would require changing the password of the service user and redeploying the service configuration files in a short time window to ensure service uptime. API keys allow for service uptime while keeping the identity of the service user protected and secure. Developer Impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: None Other contributors: None Work Items ---------- * Implement the creation and deletion of API keys * Implement API key authentication in keystone server * Implement API key authentication in keystoneauth * Document the usage of API keys * Notify deployment projects about using API keys (Devstack, OpenStack-Ansible, Tripleo, OpenStack Puppet, etc) Dependencies ============ This work is going to require that we finish decoupling authentication methods from user identities (i.e. authenticating via federation and assuming a shadow user). Documentation Impact ==================== The documentation team, along with the documentation liaison for keystone will have to update the installation guide to account for API keys and service accounts. The user guides should also be updated to reflect the ability for users to use API keys for application authentication. References ========== None. ",,208,0
openstack%2Fdiskimage-builder~master~Ic98790461636c4136b7005bdc31ce08f8ca81e0f,openstack/diskimage-builder,master,Ic98790461636c4136b7005bdc31ce08f8ca81e0f,[suse] remove --no-confirm from zypper invocation,MERGED,2017-02-20 19:49:34.000000000,2017-02-28 01:31:50.000000000,2017-02-28 01:31:50.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 21741}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-02-20 19:49:34.000000000', 'files': ['elements/zypper-minimal/root.d/08-zypper-chroot'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/661c4c32d26b1dd4fffa10b528d66ff417adbe45', 'message': ""[suse] remove --no-confirm from zypper invocation\n\nthis is basically the deprecated version of --non-interactive, which is\nalready being used, so this is duplicate and only causes warnings but\ndoesn't help with anything\n\nChange-Id: Ic98790461636c4136b7005bdc31ce08f8ca81e0f\n""}]",0,436167,661c4c32d26b1dd4fffa10b528d66ff417adbe45,12,4,1,6593,,,0,"[suse] remove --no-confirm from zypper invocation

this is basically the deprecated version of --non-interactive, which is
already being used, so this is duplicate and only causes warnings but
doesn't help with anything

Change-Id: Ic98790461636c4136b7005bdc31ce08f8ca81e0f
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/67/436167/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/zypper-minimal/root.d/08-zypper-chroot'],1,661c4c32d26b1dd4fffa10b528d66ff417adbe45,,"ZYPPER_INSTALL_OPTS=""--no-recommends""","ZYPPER_INSTALL_OPTS=""--no-confirm --no-recommends""",1,1
openstack%2Fdiskimage-builder~master~Id3b72d41fce258af98b31976ef726d57a0a9fae4,openstack/diskimage-builder,master,Id3b72d41fce258af98b31976ef726d57a0a9fae4,gentoo: do not manually clean /tmp,MERGED,2017-02-20 16:35:50.000000000,2017-02-28 01:31:44.000000000,2017-02-28 01:31:44.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-20 16:35:50.000000000', 'files': ['elements/gentoo/finalise.d/99-cleanup'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e2192fc7b78faf0598b837d284c358fcd0ba2b1b', 'message': 'gentoo: do not manually clean /tmp\n\ndisk-image-create already does that globally after the guest is\nfinalized, see lib/img-functions:finalise_base.  Thus, there is no need\nto remove part of /tmp manually, and no other distro element does that.\n\nChange-Id: Id3b72d41fce258af98b31976ef726d57a0a9fae4\n'}]",0,436101,e2192fc7b78faf0598b837d284c358fcd0ba2b1b,12,3,1,12320,,,0,"gentoo: do not manually clean /tmp

disk-image-create already does that globally after the guest is
finalized, see lib/img-functions:finalise_base.  Thus, there is no need
to remove part of /tmp manually, and no other distro element does that.

Change-Id: Id3b72d41fce258af98b31976ef726d57a0a9fae4
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/01/436101/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/gentoo/finalise.d/99-cleanup'],1,e2192fc7b78faf0598b837d284c358fcd0ba2b1b,gentoo-tmp,,# clean up files that may have been changed during build shopt -s extglob rm -Rf /tmp/!(ccache|in_target*|profiledir*) shopt -u extglob ,0,5
openstack%2Fdiskimage-builder~master~I5c894ab6152acf5441231acc1215fe00967f4f31,openstack/diskimage-builder,master,I5c894ab6152acf5441231acc1215fe00967f4f31,pip-and-virtualenv: also handle rhel distros,MERGED,2017-02-14 15:08:31.000000000,2017-02-28 01:31:13.000000000,2017-02-28 01:31:13.000000000,"[{'_account_id': 3}, {'_account_id': 6579}, {'_account_id': 7118}, {'_account_id': 10850}, {'_account_id': 21741}, {'_account_id': 21798}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-02-14 15:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/6b501a5cba158b69f4f99ca53b96f98ca1ccda36', 'message': 'pip-and-virtualenv: also handle rhel distros\n\nThe current pip install script only checked for centos/fedora\nThis causes setuptools errrors like (with pbr install):\n""SyntaxError: \'<\' operator not allowed in environment markers""\n\nChange-Id: I5c894ab6152acf5441231acc1215fe00967f4f31\n'}, {'number': 2, 'created': '2017-02-21 15:11:38.000000000', 'files': ['elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fedea46c9e26101f292ad966024a40d621c8f65e', 'message': 'pip-and-virtualenv: also handle rhel distros\n\nThe current pip install script only checked for centos/fedora\nThis causes setuptools errrors like (with pbr install):\n""SyntaxError: \'<\' operator not allowed in environment markers""\n\nExplictly list distro names in that situation\n\nChange-Id: I5c894ab6152acf5441231acc1215fe00967f4f31\n'}]",1,433693,fedea46c9e26101f292ad966024a40d621c8f65e,23,7,2,21798,,,0,"pip-and-virtualenv: also handle rhel distros

The current pip install script only checked for centos/fedora
This causes setuptools errrors like (with pbr install):
""SyntaxError: '<' operator not allowed in environment markers""

Explictly list distro names in that situation

Change-Id: I5c894ab6152acf5441231acc1215fe00967f4f31
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/93/433693/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/pip-and-virtualenv/install.d/pip-and-virtualenv-source-install/04-install-pip'],1,6b501a5cba158b69f4f99ca53b96f98ca1ccda36,pip_install_rhel,if [[ $DISTRO_NAME =~ (centos|fedora|rhel) ]]; then,if [[ $DISTRO_NAME =~ (centos|fedora) ]]; then,1,1
openstack%2Ffuel-library~stable%2Fmitaka~I929f9d0db80b7be01675697c972ac2be2273e182,openstack/fuel-library,stable/mitaka,I929f9d0db80b7be01675697c972ac2be2273e182,Split configuration astute.yaml into common and node parts,ABANDONED,2016-09-13 11:25:45.000000000,2017-02-28 01:30:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12661}, {'_account_id': 14200}, {'_account_id': 17737}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-09-13 11:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d988ef98798e7aeccf7a5617a60bf82edc808173', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nbe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 2, 'created': '2016-09-14 14:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/09c935951b96941091c7275ea279cada342794a3', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nbe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 3, 'created': '2016-09-15 09:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/248aeb10e964e2cd9c99943e4365b2f5668b3218', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 4, 'created': '2016-09-16 08:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/077c46e7b283a994f2452997c7919aee040a6d60', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 5, 'created': '2016-09-19 12:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/699f80610063efbc856a6ecf0adf4d85eade1d75', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 6, 'created': '2016-09-20 14:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2c630b36e8611202e0fb531072a9793ee2cf606b', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 7, 'created': '2016-09-21 08:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c5223c66747f89d6f7d10b0107db3bc7873f5d4e', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 8, 'created': '2016-09-21 08:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/15bd6cd3ed4b7b8a42da47d19e9ed1eb4700e7d3', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nBackport of I114a8598460bef9063e43505f46fe38cd564d8c7\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 9, 'created': '2016-09-28 15:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f8332ac8b493e0fc879467d500bfd0077176036d', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nBackport of I114a8598460bef9063e43505f46fe38cd564d8c7\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 10, 'created': '2016-10-18 10:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c3e48192ffe8cba27e2452761634996a14c9a8f0', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 11, 'created': '2016-10-18 17:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/17c241e8ed2c6f4437b13f3a81165ed7fc1085ef', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 12, 'created': '2016-10-19 11:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/62c66ca86961bdba5d2d2b9a40479d0e9ac05241', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 13, 'created': '2016-10-21 12:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/56e478cd10e424384a01e51febdfd7387bbac6c5', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}, {'number': 14, 'created': '2016-11-08 10:22:29.000000000', 'files': ['tests/noop/spec/hosts/hiera/hiera_spec.rb', 'deployment/puppet/osnailyfacter/manifests/hiera/hiera.pp', 'deployment/puppet/openstack_tasks/examples/keystone/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/plugins/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c74fdeb7ffea4e5ef257f96e8d649ce0ec1af014', 'message': ""Split configuration astute.yaml into common and node parts\n\nThis file is huge if there are many nodes in cluster. Now\nwe generate it and store in memory for each node and it\ntakes a lot of time and memory.\n\nLet's split it into common and node-specific parts so that\nwe can generate common part once and copy it from master\nnode to each node affected by deployment.\n\nChange-Id: I929f9d0db80b7be01675697c972ac2be2273e182\nCloses-Bug: #1596987\n""}]",0,369358,c74fdeb7ffea4e5ef257f96e8d649ce0ec1af014,270,9,14,12661,,,0,"Split configuration astute.yaml into common and node parts

This file is huge if there are many nodes in cluster. Now
we generate it and store in memory for each node and it
takes a lot of time and memory.

Let's split it into common and node-specific parts so that
we can generate common part once and copy it from master
node to each node affected by deployment.

Change-Id: I929f9d0db80b7be01675697c972ac2be2273e182
Closes-Bug: #1596987
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/58/369358/14 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/hiera/hiera.pp', 'deployment/puppet/openstack_tasks/examples/keystone/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml']",3,d988ef98798e7aeccf7a5617a60bf82edc808173,bug/1596987,"- id: upload_node_configuration path: /etc/fuel/cluster/{CLUSTER_ID}/node.yaml yaql_exp: '$node.toYaml()' - id: upload_cluster_configuration type: upload_file version: 2.1.0 role: ['master'] condition: yaql_exp: 'changed($)' requires: [override_configuration] required_for: [pre_deployment_start] refresh_on: ['*'] parameters: path: /var/lib/fuel/configs/{CLUSTER_ID}/cluster.yaml permissions: '0640' dir_permissions: '0750' timeout: 180 data: yaql_exp: '$common.toYaml()' - id: copy_cluster_configuration type: copy_files version: 2.1.0 role: ['master', '/.*/'] condition: yaql_exp: 'changed($)' required_for: [pre_deployment_end] requires: [upload_cluster_configuration] parameters: files: - src: /var/lib/fuel/configs/{CLUSTER_ID}/cluster.yaml dst: /etc/fuel/cluster/{CLUSTER_ID}/cluster.yaml permissions: '0644' dir_permissions: '0755' requires: [copy_cluster_configuration] cmd: ln -sf /etc/fuel/cluster/{CLUSTER_ID}/cluster.yaml /etc/astute.yaml timeout: 180 - id: configuration_symlink_node type: shell version: 2.1.0 role: ['/.*/'] condition: yaql_exp: '$.uid in added($.nodes).uid' requires: [upload_node_configuration] required_for: [pre_deployment_start] parameters: cmd: ln -sf /etc/fuel/cluster/{CLUSTER_ID}/node.yaml /etc/hiera/node.yaml requires: [copy_cluster_configuration]",- id: upload_configuration path: /etc/fuel/cluster/{CLUSTER_ID}/astute.yaml yaql_exp: '$.toYaml()' requires: [upload_configuration] cmd: ln -sf /etc/fuel/cluster/{CLUSTER_ID}/astute.yaml /etc/astute.yaml requires: [upload_configuration],52,7
openstack%2Ftempest~master~I0634b43f94cd6ae6529a861b41549e618761c9d1,openstack/tempest,master,I0634b43f94cd6ae6529a861b41549e618761c9d1,"Revert ""Scenario manager: remove some useless `_list_*` methods""",ABANDONED,2017-02-24 22:00:17.000000000,2017-02-28 01:07:45.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 6854}, {'_account_id': 7350}, {'_account_id': 8157}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-24 22:00:17.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_security_groups_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/10fa1548fba41ee1e95a7552fc1713951dc32cbe', 'message': 'Revert ""Scenario manager: remove some useless `_list_*` methods""\n\nThis reverts commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb.\n\nThe removed methods are used by tempest plugins.\nLet\'s fix them before removing.\n\nChange-Id: I0634b43f94cd6ae6529a861b41549e618761c9d1\nCloses-Bug: #1667824\n'}]",0,438097,10fa1548fba41ee1e95a7552fc1713951dc32cbe,26,9,1,6854,,,0,"Revert ""Scenario manager: remove some useless `_list_*` methods""

This reverts commit 64e6b4457c748f74bfb4fbf3860ab65b65ae9beb.

The removed methods are used by tempest plugins.
Let's fix them before removing.

Change-Id: I0634b43f94cd6ae6529a861b41549e618761c9d1
Closes-Bug: #1667824
",git fetch https://review.opendev.org/openstack/tempest refs/changes/97/438097/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_security_groups_basic_ops.py']",4,10fa1548fba41ee1e95a7552fc1713951dc32cbe,," seen_nets = self._list_networks() seen_names = [n['name'] for n in seen_nets] seen_ids = [n['id'] for n in seen_nets] seen_subnets = [(n['id'], n['cidr'], n['network_id']) for n in self._list_subnets()] seen_routers = self._list_routers() seen_router_ids = [n['id'] for n in seen_routers] seen_router_names = [n['name'] for n in seen_routers] for i in self._list_ports(device_id=tenant.router['id']) for f in i['fixed_ips']] port_list = self._list_ports(fields=['fixed_ips', 'mac_address']) port_id = self._list_ports(device_id=server_id)[0]['id'] port_id = self._list_ports(device_id=server_id)[0]['id'] ports = self._list_ports(device_id=server_id)"," seen_nets = self.admin_manager.networks_client.list_networks() seen_names = [n['name'] for n in seen_nets['networks']] seen_ids = [n['id'] for n in seen_nets['networks']] seen_subnets = [ (n['id'], n['cidr'], n['network_id']) for n in self.admin_manager.subnets_client.list_subnets()['subnets'] ] seen_routers = self.admin_manager.routers_client.list_routers() seen_router_ids = [n['id'] for n in seen_routers['routers']] seen_router_names = [n['name'] for n in seen_routers['routers']] for i in self.admin_manager.ports_client.list_ports( device_id=tenant.router['id'])['ports'] for f in i['fixed_ips'] ] port_list = self.admin_manager.ports_client.list_ports( fields=['fixed_ips', 'mac_address'])['ports'] port_id = self.admin_manager.ports_client.list_ports( device_id=server_id)['ports'][0]['id'] port_id = self.admin_manager.ports_client.list_ports( device_id=server_id)['ports'][0]['id'] ports = self.admin_manager.ports_client.list_ports( device_id=server_id)['ports']",79,75
openstack%2Foctavia~master~Ibd39204d496c466c7673e90e2921fb34fcbd7ba0,openstack/octavia,master,Ibd39204d496c466c7673e90e2921fb34fcbd7ba0,Set project_id on sub-objects during single-create,MERGED,2017-02-23 01:04:23.000000000,2017-02-28 01:06:48.000000000,2017-02-28 01:02:21.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-23 01:04:23.000000000', 'files': ['octavia/db/prepare.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/83538892c049c910745652e67ec87f9be30a2538', 'message': 'Set project_id on sub-objects during single-create\n\nChange-Id: Ibd39204d496c466c7673e90e2921fb34fcbd7ba0\nCloses-Bug: #1667175\n'}]",0,437206,83538892c049c910745652e67ec87f9be30a2538,17,4,1,10273,,,0,"Set project_id on sub-objects during single-create

Change-Id: Ibd39204d496c466c7673e90e2921fb34fcbd7ba0
Closes-Bug: #1667175
",git fetch https://review.opendev.org/openstack/octavia refs/changes/06/437206/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/db/prepare.py'],1,83538892c049c910745652e67ec87f9be30a2538,bug/1667175, listener_dict['project_id'] = prepped_lb.get('project_id') pool['project_id'] = prepped_lb.get('project_id') hm['project_id'] = lb_dict.get('project_id') member_dict['project_id'] = prepped_lb.get('project_id'),,4,0
openstack%2Foslo.messaging~master~I573334e774ccf33ecd27a85067045f3c6489ee89,openstack/oslo.messaging,master,I573334e774ccf33ecd27a85067045f3c6489ee89,drivers: use common.ConfigOptsProxy everywhere,MERGED,2017-02-23 07:15:51.000000000,2017-02-28 01:01:33.000000000,2017-02-28 01:01:33.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-23 07:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2c63ffd937c706294c0322da4175c6a0afb9afb6', 'message': 'drivers: use common.ConfigOptsProxy everywhere\n\nConfigOptsProxy have been implemented only pika driver while\nthe oslo.messaging allow to pass the query string for all drivers.\n\nThis change fixes that.\nCloses-Bug: #1666903\n\nNext step is to validate the query with ConfigOptsProxy, to\nraise appropriate exception in case of mis-configuration.\n\nChange-Id: I573334e774ccf33ecd27a85067045f3c6489ee89\n'}, {'number': 2, 'created': '2017-02-23 09:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1566662741fdc4afea9404681f6b319710d21784', 'message': 'drivers: use common.ConfigOptsProxy everywhere\n\nConfigOptsProxy have been implemented only pika driver while\nthe oslo.messaging allow to pass the query string for all drivers.\n\nThis change fixes that.\nCloses-Bug: #1666903\n\nNext step is to validate the query with ConfigOptsProxy, to\nraise appropriate exception in case of mis-configuration.\n\nChange-Id: I573334e774ccf33ecd27a85067045f3c6489ee89\n'}, {'number': 3, 'created': '2017-02-23 21:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d2d0d7b8cd0c65ed9f63e24b5b080ac782b6a1b3', 'message': 'drivers: use common.ConfigOptsProxy everywhere\n\nConfigOptsProxy have been implemented only pika driver while\nthe oslo.messaging allow to pass the query string for all drivers.\n\nThis change fixes that.\nCloses-Bug: #1666903\nCloses-Bug: #1607889\n\nNext step is to validate the query with ConfigOptsProxy, to\nraise appropriate exception in case of mis-configuration.\n\nChange-Id: I573334e774ccf33ecd27a85067045f3c6489ee89\n'}, {'number': 4, 'created': '2017-02-27 08:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6bcf7846b0e8da9f2374ceb1fe80446003d07514', 'message': 'drivers: use common.ConfigOptsProxy everywhere\n\nConfigOptsProxy have been implemented only pika driver while\nthe oslo.messaging allow to pass the query string for all drivers.\n\nThis change fixes that.\nCloses-Bug: #1666903\nCloses-Bug: #1607889\n\nNext step is to validate the query with ConfigOptsProxy, to\nraise appropriate exception in case of mis-configuration.\n\nChange-Id: I573334e774ccf33ecd27a85067045f3c6489ee89\n'}, {'number': 5, 'created': '2017-02-27 13:15:58.000000000', 'files': ['oslo_messaging/_drivers/zmq_driver/zmq_options.py', 'oslo_messaging/_drivers/impl_zmq.py', 'oslo_messaging/_drivers/kafka_options.py', 'oslo_messaging/_drivers/impl_kafka.py', 'oslo_messaging/_drivers/impl_pika.py', 'oslo_messaging/_drivers/pika_driver/pika_engine.py', 'oslo_messaging/_drivers/impl_amqp1.py', 'oslo_messaging/tests/drivers/zmq/zmq_common.py', 'oslo_messaging/tests/drivers/zmq/test_zmq_ack_manager.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/58b026a2aae564d5b6f91a05dd8e03e237f49694', 'message': 'drivers: use common.ConfigOptsProxy everywhere\n\nConfigOptsProxy have been implemented only pika driver while\nthe oslo.messaging allow to pass the query string for all drivers.\n\nThis change fixes that.\nCloses-Bug: #1666903\nCloses-Bug: #1607889\n\nNext step is to validate the query with ConfigOptsProxy, to\nraise appropriate exception in case of mis-configuration.\n\nChange-Id: I573334e774ccf33ecd27a85067045f3c6489ee89\n'}]",1,437265,58b026a2aae564d5b6f91a05dd8e03e237f49694,21,6,5,2813,,,0,"drivers: use common.ConfigOptsProxy everywhere

ConfigOptsProxy have been implemented only pika driver while
the oslo.messaging allow to pass the query string for all drivers.

This change fixes that.
Closes-Bug: #1666903
Closes-Bug: #1607889

Next step is to validate the query with ConfigOptsProxy, to
raise appropriate exception in case of mis-configuration.

Change-Id: I573334e774ccf33ecd27a85067045f3c6489ee89
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/65/437265/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/_drivers/zmq_driver/zmq_options.py', 'oslo_messaging/_drivers/impl_zmq.py', 'oslo_messaging/_drivers/impl_pika.py', 'oslo_messaging/_drivers/pika_driver/pika_engine.py', 'oslo_messaging/_drivers/impl_amqp1.py', 'oslo_messaging/_drivers/impl_rabbit.py']",6,2c63ffd937c706294c0322da4175c6a0afb9afb6,bug/1666903," conf = rpc_common.ConfigOptsProxy(conf, url)",,8,4
openstack%2Fkolla-kubernetes~master~I30339a1e2a8b95ad21fc2c5400eb9f765b91c783,openstack/kolla-kubernetes,master,I30339a1e2a8b95ad21fc2c5400eb9f765b91c783,Configuring ironic gates (basic tests),MERGED,2017-02-23 16:23:08.000000000,2017-02-28 00:59:10.000000000,2017-02-28 00:59:10.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 9237}, {'_account_id': 10787}, {'_account_id': 19384}]","[{'number': 1, 'created': '2017-02-23 16:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/ee335a5589c6e8d815cbcaed328174a5e796ff82', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 2, 'created': '2017-02-23 16:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b44a250db50c4b086bdb466e91f7dea9a2947ed6', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 3, 'created': '2017-02-23 20:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/adf7656aebbb3726d73e54d362035a58a05985a4', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 4, 'created': '2017-02-23 23:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/68aebab5e06c7cdb7929c2d2e38c1710b647da00', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 5, 'created': '2017-02-24 00:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/03c7558b19a631610b07d20d4f66555ace9ef885', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 6, 'created': '2017-02-24 00:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/655fe7678bcbf87d1c10a2514d5bd6b8fa4e2e65', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 7, 'created': '2017-02-24 01:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/77a597ec5cd7c86734ed911ba6f272c15254aaf5', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 8, 'created': '2017-02-24 01:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/102c07c7279b6eb63e3b798353d94053d45069b8', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 9, 'created': '2017-02-24 02:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/07c768e57837fee5c64d737e06732a83e9d14a5b', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 10, 'created': '2017-02-24 02:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/a6edf147e95d9ff161a504b333ae6741f5036f19', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 11, 'created': '2017-02-24 03:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/07cc11e8a16dccc31b4cff2268668e9d743c1266', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 12, 'created': '2017-02-24 04:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c8de5384044af1afbb1b73207b1aab64db108f47', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 13, 'created': '2017-02-24 13:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/5b277cd4f17706c9abaf3b848e926175869eb4f6', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 14, 'created': '2017-02-24 13:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/881d8400305d822189c062ece23b6ceb7c3ec805', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 15, 'created': '2017-02-24 14:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/d3fd4001207cf23aeefe427f403f54a1f74e43dd', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 16, 'created': '2017-02-24 15:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/ddc5d8d2f8bd64dc4b3669b8d1bc2a9e72d73411', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 17, 'created': '2017-02-24 15:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/6ab741955197eec1781723cf6b04b1af465dabe4', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 18, 'created': '2017-02-24 16:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/e4f9eba25744216479461bd808cec4098db0a731', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 19, 'created': '2017-02-24 19:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/f00a011c8e4e81a43ea93bcfd4d9cab361d96b53', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 20, 'created': '2017-02-24 21:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/0fbc830acef42af0d9a23197c435eddcb978c5f7', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 21, 'created': '2017-02-25 15:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/5403e7746d81c7cab754b2bf6ba36b415cc5700a', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 22, 'created': '2017-02-25 16:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/468f8896c14f2c66772066508795d538a940b6bd', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 23, 'created': '2017-02-26 15:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/bad4b7e3b2a9e3525c0ea0ea4e1e6015145a5304', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 24, 'created': '2017-02-26 20:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/7fff48504387ab38a4343da4593ff259f5ca38ea', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nPartially-Implements: blueprint gate-continous-improvement\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 25, 'created': '2017-02-27 02:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/f8c3b60be340808ca8140a559c68021be01a8116', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nPartially-Implements: blueprint gate-continous-improvement\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 26, 'created': '2017-02-27 02:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/49177142d2776d1bd5bb07bb14e1a365e58e2aab', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nPartially-Implements: blueprint gate-continous-improvement\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}, {'number': 27, 'created': '2017-02-27 18:18:54.000000000', 'files': ['tools/setup_gate_common.sh', 'tests/bin/setup_config_iscsi.sh', 'tools/setup_gate_iscsi.sh', 'tests/bin/common_iscsi_config.sh', 'tests/bin/iscsi_ironic_workflow.sh', 'tools/setup_gate.sh', 'tests/bin/deploy_iscsi_common.sh', 'tests/bin/common_iscsi_config_v3.sh', 'helm/all_values.yaml', 'tests/bin/common_workflow_config.sh', 'tests/bin/deploy_ironic.sh', 'tests/bin/iscsi_generic_workflow.sh'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/3eead1904ca96dfbeeecf449cb1f8a4c6aa9039d', 'message': 'Configuring ironic gates (basic tests)\n\nConfiguring ironic gates (basic tests)\n\nPartially-Implements: blueprint gate-continous-improvement\n\nChange-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783\n'}]",32,437504,3eead1904ca96dfbeeecf449cb1f8a4c6aa9039d,125,5,27,19384,,,0,"Configuring ironic gates (basic tests)

Configuring ironic gates (basic tests)

Partially-Implements: blueprint gate-continous-improvement

Change-Id: I30339a1e2a8b95ad21fc2c5400eb9f765b91c783
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/04/437504/25 && git format-patch -1 --stdout FETCH_HEAD,"['tools/setup_gate_iscsi.sh', 'tools/setup_gate.sh']",2,ee335a5589c6e8d815cbcaed328174a5e796ff82,bp/gate-continous-improvement,"if [ ""x$4"" == ""ironic"" ]; then tools/setup_gate_iscsi.sh $1 $2 $3 $4 $5 $BRANCH $PIPELINE exit 0 fi ",,15,0
openstack%2Fneutron-fwaas~master~If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4,openstack/neutron-fwaas,master,If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4,Making netlink_conntrack be configurable,ABANDONED,2017-02-15 08:27:02.000000000,2017-02-28 00:50:30.000000000,,"[{'_account_id': 3}, {'_account_id': 8124}, {'_account_id': 15471}, {'_account_id': 15905}, {'_account_id': 20079}]","[{'number': 1, 'created': '2017-02-15 08:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/9a018ddce4c16d5912d22f6f6f76bcf8f556b5e4', 'message': 'Making netlink_conntrack be configurable\n\nThis patch enable to configure netlink_conntrack as\na firewall conntrack driver.\nIt also refactor the netlink_lib code to make it be more\nreadable and maintainable.\n\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nChange-Id: If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4\nPartial-Bug: #1664294\n'}, {'number': 2, 'created': '2017-02-15 09:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/0cff076cb6aa1b10a453fdfcbf0d84241a54b725', 'message': 'Making netlink_conntrack be configurable\n\nThis patch enable to configure netlink_conntrack as\na firewall conntrack driver.\nIt also refactor the netlink_lib code to make it be more\nreadable and maintainable.\n\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nChange-Id: If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4\nPartial-Bug: #1664294\n'}, {'number': 3, 'created': '2017-02-16 02:44:03.000000000', 'files': ['neutron_fwaas/services/firewall/drivers/linux/netlink_conntrack.py', 'neutron_fwaas/services/firewall/agents/firewall_agent_api.py', 'neutron_fwaas/services/firewall/drivers/conntrack_base.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_netlink_conntrack.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/59012b1be6f8484f1063470768af9a06c24c84f3', 'message': 'Making netlink_conntrack be configurable\n\nThis patch enable to configure netlink_conntrack as\na firewall conntrack driver.\n\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nChange-Id: If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4\nPartial-Bug: #1664294\n'}]",3,434136,59012b1be6f8484f1063470768af9a06c24c84f3,10,5,3,20079,,,0,"Making netlink_conntrack be configurable

This patch enable to configure netlink_conntrack as
a firewall conntrack driver.

Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Change-Id: If5dcc0578177e3f4dc031b7d836b3d9bc5b31ed4
Partial-Bug: #1664294
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/36/434136/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/privileged/netlink_constants.py', 'neutron_fwaas/services/firewall/drivers/linux/netlink_conntrack.py', 'neutron_fwaas/common/netlink_constants.py', 'neutron_fwaas/privileged/netlink_lib.py', 'neutron_fwaas/services/firewall/agents/firewall_agent_api.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_netlink_conntrack.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_iptables_fwaas.py', 'neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py']",8,9a018ddce4c16d5912d22f6f6f76bcf8f556b5e4,bug/1664294,"from oslo_config import cfgfrom neutron.agent.linux import iptables_manager from neutron.common import utils def load_extension_driver_class(namespace, driver): return utils.load_class_by_alias_or_classname(namespace, driver) conntrack_cls = load_extension_driver_class( 'neutron_fwaas.services.firewall.' 'drivers.linux', cfg.CONF.fwaas.conntrack_driver) self.conntrack = conntrack_cls() self.conntrack.initialize() self.conntrack.flush_entries(ipt_mgr.namespace) self.conntrack.delete_entries(removed_conntrack_rules_list, ipt_mgr.namespace)","from neutron.agent.linux import iptables_managerfrom neutron_fwaas.privileged import netlink_lib self._flush_conntrack_netlink(ipt_mgr.namespace) rules = [] for rule in removed_conntrack_rules_list: rules.append(self._get_filters_from_rules(rule)) rules = sorted(list(set(rules))) self._remove_conntrack_netlink(ipt_mgr.namespace, rules) @staticmethod def _entry2delete(rule, entry): """""" Check if an entry will be delete or not :param rule: (ipversion, protocol, sport, dport) :param entry: (ipversion, protocol, sport, dport, saddress, daddress) :return: True if the entry matches the rule The entry matches the rule if it has the same ipversion, protocol or entry source port, destination port sequentially in rule source port, destination port range. """""" return ( (entry[0] == rule[0]) and (not rule[1] or entry[1] == rule[1]) and (not rule[2] or int(entry[2]) in range(int(rule[2].split(':')[0]), int(rule[2].split(':')[-1]) + 1)) and (not rule[2] or int(entry[2]) in range(int(rule[2].split(':')[0]), int(rule[2].split(':')[-1]) + 1))) def _remove_conntrack_netlink(self, namespace, rules): # Getting a list of all entries entries = netlink_lib.list_entries(namespace) # Compare each entry to each rule to define that this entry # is to delete or not. # rule and entry have the same parameters order to be comparable: # rule: (ipversion, protocol, sport, dport) # entry: (ipversion, protocol, sport, dport, saddress, daddress) # rules and entries were sorted lists of tuples to reduce the # number of comparisons. dentries = [] ientry = 0 entryNumber = len(entries) for rule in rules: while ientry < entryNumber and entries[ientry] < rule: ientry += 1 while (ientry < entryNumber and self._entry2delete(rule, entries[ientry])): dentries.append(entries[ientry]) ientry += 1 # Calling to netlink_lib.kill_entries to delete entries netlink_lib.kill_entries(namespace, dentries) def _flush_conntrack_netlink(self, namespace): netlink_lib.flush_entries(namespace) def _get_filters_from_rules(self, rule): """"""Parse parameters from firewall rules :param: rule: A firewall rule :return filter: Tuple of parameters example: (4, 'tcp', 1111, 2222, '1.1.1.1', '2.2.2.2') """""" keys = ['ip_version', 'protocol', 'source_port', 'destination_port'] addr_keys = ['source_ip_address', 'destination_ip_address'] rule_filter = [] for key in keys: rule_filter.append(rule.get(key) or '') for key in addr_keys: if not rule.get(key): rule_filter.append('') else: rule_filter.append(rule.get(key)) return tuple(rule_filter)",612,530
openstack%2Fneutron-fwaas~master~Ic4f1f4deaa9f2814bbe2bde54d129047527c535e,openstack/neutron-fwaas,master,Ic4f1f4deaa9f2814bbe2bde54d129047527c535e,Reverting conntrack-tools in neutron-fwaas,ABANDONED,2017-02-15 09:50:35.000000000,2017-02-28 00:49:18.000000000,,"[{'_account_id': 3}, {'_account_id': 8124}, {'_account_id': 15471}, {'_account_id': 15905}]","[{'number': 1, 'created': '2017-02-15 09:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f075a3c33a8fbe19343d23dc6b63235e0d8295bf', 'message': 'Reverting conntrack-tools in neutron-fwaas\n\nThis patch enables reverting conntrack-tools in neutron-fwaas.\n\nChange-Id: Ic4f1f4deaa9f2814bbe2bde54d129047527c535e\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartial-Bug: #1664294\n'}, {'number': 2, 'created': '2017-02-16 01:57:49.000000000', 'files': ['neutron_fwaas/services/firewall/agents/firewall_agent_api.py', 'neutron_fwaas/services/firewall/drivers/linux/legacy_conntrack.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_legacy_conntrack.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/029b20faa041881db4c5fe79c30739bad7398746', 'message': 'Reverting conntrack-tools in neutron-fwaas\n\nThis patch enables reverting conntrack-tools in neutron-fwaas.\n\nChange-Id: Ic4f1f4deaa9f2814bbe2bde54d129047527c535e\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartial-Bug: #1664294\n'}]",4,434181,029b20faa041881db4c5fe79c30739bad7398746,8,4,2,20079,,,0,"Reverting conntrack-tools in neutron-fwaas

This patch enables reverting conntrack-tools in neutron-fwaas.

Change-Id: Ic4f1f4deaa9f2814bbe2bde54d129047527c535e
Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Partial-Bug: #1664294
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/81/434181/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/services/firewall/drivers/linux/legacy_conntrack.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_legacy_conntrack.py']",2,f075a3c33a8fbe19343d23dc6b63235e0d8295bf,bug/1664294,"# Copyright (c) 2017 Fujitsu Limited # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from neutron.tests import base from neutron_fwaas.services.firewall.drivers.linux import legacy_conntrack FW_RULES = [ {'position': '2', 'protocol': 'icmp', 'ip_version': 4, 'enabled': True, 'action': 'reject', 'id': 'fake-fw-rule1'}, {'source_port': '1', 'destination_port': '2', 'position': '2', 'protocol': 'tcp', 'ip_version': 4, 'enabled': True, 'action': 'reject', 'id': 'fake-fw-rule2'}, {'source_port': '1', 'destination_port': '2', 'position': '3', 'protocol': 'udp', 'ip_version': 4, 'enabled': True, 'action': 'reject', 'id': 'fake-fw-rule3'}, ] ROUTER_NAMESPACE = 'qrouter-fake-namespace' class ConntrackLegacyTestCase(base.BaseTestCase): def setUp(self): super(ConntrackLegacyTestCase, self).setUp() utils_exec_p = mock.patch( 'neutron.agent.linux.utils.execute') self.utils_exec = utils_exec_p.start() self.conntrack_driver = legacy_conntrack.ConntrackLegacy() self.conntrack_driver.initialize(execute=self.utils_exec) def test_flush_entries(self): self.conntrack_driver.flush_entries(ROUTER_NAMESPACE) self.utils_exec.assert_called_with( ['ip', 'netns', 'exec', ROUTER_NAMESPACE, 'conntrack', '-D'], check_exit_code=True, extra_ok_codes=[1], run_as_root=True) def test_delete_entries(self): self.conntrack_driver.delete_entries(FW_RULES, ROUTER_NAMESPACE) calls = [ mock.call(['ip', 'netns', 'exec', ROUTER_NAMESPACE, 'conntrack', '-D', '-p', 'icmp', '-f', 'ipv4'], check_exit_code=True, extra_ok_codes=[1], run_as_root=True), mock.call(['ip', 'netns', 'exec', ROUTER_NAMESPACE, 'conntrack', '-D', '-p', 'tcp', '-f', 'ipv4', '--dport', '2', '--sport', '1'], check_exit_code=True, extra_ok_codes=[1], run_as_root=True), mock.call(['ip', 'netns', 'exec', ROUTER_NAMESPACE, 'conntrack', '-D', '-p', 'udp', '-f', 'ipv4', '--dport', '2', '--sport', '1'], check_exit_code=True, extra_ok_codes=[1], run_as_root=True), ] self.utils_exec.assert_has_calls(calls) ",,170,0
openstack%2Fneutron-fwaas~master~I03236f831d774200e63b848d9d610e7176f9f484,openstack/neutron-fwaas,master,I03236f831d774200e63b848d9d610e7176f9f484,Refactor netlink-conntrack,ABANDONED,2017-02-16 03:00:29.000000000,2017-02-28 00:47:45.000000000,,"[{'_account_id': 3}, {'_account_id': 8124}, {'_account_id': 13702}, {'_account_id': 15471}, {'_account_id': 15905}]","[{'number': 1, 'created': '2017-02-16 03:00:29.000000000', 'files': ['neutron_fwaas/privileged/netlink_constants.py', 'neutron_fwaas/services/firewall/drivers/linux/netlink_conntrack.py', 'neutron_fwaas/common/netlink_constants.py', 'neutron_fwaas/privileged/netlink_lib.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_netlink_conntrack.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/d36987bce2e477bf0719bea43917c15724973f9b', 'message': 'Refactor netlink-conntrack\n\nThis patch makes the netlink-conntrack driver be more readable and\nmaintainable.\n\nChange-Id: I03236f831d774200e63b848d9d610e7176f9f484\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nPartial-Bug: #1664294\n'}]",3,434593,d36987bce2e477bf0719bea43917c15724973f9b,6,5,1,20079,,,0,"Refactor netlink-conntrack

This patch makes the netlink-conntrack driver be more readable and
maintainable.

Change-Id: I03236f831d774200e63b848d9d610e7176f9f484
Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Partial-Bug: #1664294
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/93/434593/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/privileged/netlink_constants.py', 'neutron_fwaas/services/firewall/drivers/linux/netlink_conntrack.py', 'neutron_fwaas/common/netlink_constants.py', 'neutron_fwaas/privileged/netlink_lib.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/linux/test_netlink_conntrack.py']",5,d36987bce2e477bf0719bea43917c15724973f9b,bug/1664294,"ICMP_ENTRY = (' [UPDATE] icmp 1 12344 ' 'src=1.1.1.1 dst=2.2.2.2 ' 'type=8 code=0 id=1234 ' '[UNREPLIED] ' 'src=2.2.2.2 dst=1.1.1.1 ' 'type=0 code=0 id=1234 ' 'mark=0 use=1') TCP_ENTRY = (' [UPDATE] tcp 6 12344 ' 'ESTABLISHED ' 'src=1.1.1.1 dst=2.2.2.2 ' 'sport=1 dport=2 ' '[UNREPLIED] ' 'src=2.2.2.2 dst=1.1.1.1 ' 'sport=2 dport=1 ' 'mark=0 use=1') UDP_ENTRY = ('[UPDATE] udp 17 26 ' 'src=1.1.1.1 dst=2.2.2.2 ' 'sport=1 dport=2 ' '[UNREPLIED] ' 'src=2.2.2.2 dst=1.1.1.1 ' 'sport=2 dport=1 ' 'mark=0 use=1') self.delete_entries.assert_called_with([], ROUTER_NAMESPACE) self.delete_entries.assert_called_with( [(4, 'icmp', '8', '0', '1.1.1.1', '2.2.2.2', '1234')], ROUTER_NAMESPACE) self.delete_entries.assert_called_with( [(4, 'tcp', '1', '2', '1.1.1.1', '2.2.2.2')], ROUTER_NAMESPACE) self.delete_entries.assert_called_with( [(4, 'udp', '1', '2', '1.1.1.1', '2.2.2.2')], ROUTER_NAMESPACE) self.delete_entries.assert_called_with( [(4, 'icmp', '8', '0', '1.1.1.1', '2.2.2.2', '1234'), (4, 'tcp', '1', '2', '1.1.1.1', '2.2.2.2'), (4, 'udp', '1', '2', '1.1.1.1', '2.2.2.2')], ROUTER_NAMESPACE)","ICMP_ENTRY = (4, 'icmp', '8', '0', '1.1.1.1', '2.2.2.2', '1234') TCP_ENTRY = (4, 'tcp', '1', '2', '1.1.1.1', '2.2.2.2') UDP_ENTRY = (4, 'udp', '1', '2', '1.1.1.1', '2.2.2.2') self.delete_entries.assert_called_with(ROUTER_NAMESPACE, []) self.delete_entries.assert_called_with(ROUTER_NAMESPACE, [ICMP_ENTRY]) self.delete_entries.assert_called_with(ROUTER_NAMESPACE, [TCP_ENTRY]) self.delete_entries.assert_called_with(ROUTER_NAMESPACE, [UDP_ENTRY]) self.delete_entries.assert_called_with(ROUTER_NAMESPACE, [ICMP_ENTRY, TCP_ENTRY, UDP_ENTRY],)",336,478
openstack%2Fneutron-fwaas~master~I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04,openstack/neutron-fwaas,master,I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04,Add functional test for netlink_lib,ABANDONED,2017-02-10 08:54:06.000000000,2017-02-28 00:45:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 10850}, {'_account_id': 13702}, {'_account_id': 13995}, {'_account_id': 15309}, {'_account_id': 15471}, {'_account_id': 15905}, {'_account_id': 20079}]","[{'number': 1, 'created': '2017-02-10 08:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/b2c4422f73c32b91d53b2f0c797eb299e360aac3', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 2, 'created': '2017-02-10 09:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/effb8b57059f0d47088d79d211b6f054f94861ce', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 3, 'created': '2017-02-16 04:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/42680ee95a71f3d99f0a0c7aa20efcb020bfa353', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 4, 'created': '2017-02-16 05:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/543dd0d36f432a1c9ee24cfe29bd34bbe65adcaf', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 5, 'created': '2017-02-16 05:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/812c95ea13ac3b0397da9f2d0f73229cf631f134', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 6, 'created': '2017-02-16 06:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/8b2fcaeec5cb5672b25ec91353dc01d15d8a689b', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\n'}, {'number': 7, 'created': '2017-02-16 10:41:09.000000000', 'files': ['neutron_fwaas/tests/contrib/functional-test-rootwrap.conf', 'neutron_fwaas/tests/functional/privileged/test_netlink_lib.py', 'neutron_fwaas/tests/contrib/functional-testing.filters', 'neutron_fwaas/tests/contrib/gate_hook.sh', 'tools/deploy_rootwrap.sh', 'neutron_fwaas/tests/functional/privileged/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/94838300602e5b924bf32c0209c391eec357c201', 'message': 'Add functional test for netlink_lib\n\nThis patch covers functional test for netlink_lib in [1] as discussing\nin [2].\n[1]: https://review.openstack.org/#/c/389654/\n[2]: https://review.openstack.org/#/c/430110/\n\nCo-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>\nChange-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04\nPartial-Bug: #1664294\n'}]",0,432183,94838300602e5b924bf32c0209c391eec357c201,19,10,7,20079,,,0,"Add functional test for netlink_lib

This patch covers functional test for netlink_lib in [1] as discussing
in [2].
[1]: https://review.openstack.org/#/c/389654/
[2]: https://review.openstack.org/#/c/430110/

Co-Authored-By: Nguyen Phuong An <AnNP@vn.fujitsu.com>
Change-Id: I4d5d7e5cad6b738c99b5924fc4239bf579f9bd04
Partial-Bug: #1664294
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/83/432183/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/contrib/functional-test-rootwrap.conf', 'neutron_fwaas/tests/functional/privileged/test_netlink_lib.py', 'neutron_fwaas/tests/contrib/functional-testing.filters', 'tools/deploy_rootwrap.sh', 'neutron_fwaas/tests/functional/privileged/__init__.py', 'tox.ini']",6,b2c4422f73c32b91d53b2f0c797eb299e360aac3,bug/1664294, {toxinidir}/tools/deploy_rootwrap.sh {toxinidir} {envdir},,230,0
openstack%2Fdiskimage-builder~master~Ia184446fe34c49a48ca079c828157ea34e662d4b,openstack/diskimage-builder,master,Ia184446fe34c49a48ca079c828157ea34e662d4b,Updated from global requirements,ABANDONED,2017-02-10 05:48:02.000000000,2017-02-28 00:43:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-10 05:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f46eb4a3aad1b1bc7cf42e69b9f18c35c5b948ba', 'message': 'Updated from global requirements\n\nChange-Id: Ia184446fe34c49a48ca079c828157ea34e662d4b\n'}, {'number': 2, 'created': '2017-02-21 21:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ce4f91b9dfa03196f5b98ebe78af5db02120bb75', 'message': 'Updated from global requirements\n\nChange-Id: Ia184446fe34c49a48ca079c828157ea34e662d4b\n'}]",0,431935,ce4f91b9dfa03196f5b98ebe78af5db02120bb75,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ia184446fe34c49a48ca079c828157ea34e662d4b
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/35/431935/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f46eb4a3aad1b1bc7cf42e69b9f18c35c5b948ba,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Foctavia~master~Ia9ac2acfdea217d594a8ec434da5e073d2abed08,openstack/octavia,master,Ia9ac2acfdea217d594a8ec434da5e073d2abed08,Work around devstack selecting incorrect image,MERGED,2017-02-27 19:46:07.000000000,2017-02-28 00:27:23.000000000,2017-02-28 00:22:52.000000000,"[{'_account_id': 3}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-27 19:46:07.000000000', 'files': ['octavia/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/2342cb65b6c54c6378fae976bed3b39f63ee15a2', 'message': 'Work around devstack selecting incorrect image\n\nCurrently devstack is selecting the amphora image instead of the\ncirros image to boot our test webservers.  This is a temporary fix\nto get our gates functional again.  This will be removed when we can\ncome up with a better solution or devstack merges their fix [1].\n\n[1] https://review.openstack.org/#/c/435106\n\nChange-Id: Ia9ac2acfdea217d594a8ec434da5e073d2abed08\n'}]",0,438680,2342cb65b6c54c6378fae976bed3b39f63ee15a2,13,4,1,11628,,,0,"Work around devstack selecting incorrect image

Currently devstack is selecting the amphora image instead of the
cirros image to boot our test webservers.  This is a temporary fix
to get our gates functional again.  This will be removed when we can
come up with a better solution or devstack merges their fix [1].

[1] https://review.openstack.org/#/c/435106

Change-Id: Ia9ac2acfdea217d594a8ec434da5e073d2abed08
",git fetch https://review.opendev.org/openstack/octavia refs/changes/80/438680/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/tests/contrib/gate_hook.sh'],1,2342cb65b6c54c6378fae976bed3b39f63ee15a2,devstack-default-image,"# Work around a devstack issue:https://review.openstack.org/#/c/435106 export DEVSTACK_LOCAL_CONFIG+="" DEFAULT_IMAGE_NAME=cirros-0.3.5-x86_64-disk "" ",,5,0
openstack%2Fneutron~stable%2Focata~Ibe640a584add3acc89520a2bbb25b6f4c5818e1b,openstack/neutron,stable/ocata,Ibe640a584add3acc89520a2bbb25b6f4c5818e1b,gate-hook: Accomodate devstack-gate local.conf changes,MERGED,2017-02-25 03:20:22.000000000,2017-02-28 00:20:55.000000000,2017-02-28 00:20:55.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 9681}]","[{'number': 1, 'created': '2017-02-25 03:20:22.000000000', 'files': ['neutron/tests/contrib/hooks/api_dvrskip_extensions', 'neutron/tests/contrib/hooks/api_all_extensions', 'neutron/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ea107f2c8b91f3cff17c687907d265e3142e25d', 'message': ""gate-hook: Accomodate devstack-gate local.conf changes\n\nWith devstack-gate switching to local.conf we can no longer use bash for\nevaluating settings variables. Also we shouldn't populate local.conf\ndirectly and let devstack-gate do that.\n\nSince now devstack never uses localrc file directly, we set [[localrc]]\nsections for local.conf instead.\n\nAs a nice side effect, it will make the gate hook work with devstack\nthat may not have the Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616 in\n(Newton and below), which may make backports easier later.\n\nConflicts:\n\tneutron/tests/contrib/gate_hook.sh\n\tneutron/tests/contrib/hooks/dstat\n\tneutron/tests/contrib/hooks/stack_base\n\nOcata changes: devstack is not used to start dstat for functional and\nfullstack jobs, so the corresponding code changes are skipped.\n\nChange-Id: Ibe640a584add3acc89520a2bbb25b6f4c5818e1b\nCloses-bug: 1667331\n(cherry picked from commit d46636112f45fdf181751285835229b16886ab28)\n""}]",0,438138,2ea107f2c8b91f3cff17c687907d265e3142e25d,16,4,1,9656,,,0,"gate-hook: Accomodate devstack-gate local.conf changes

With devstack-gate switching to local.conf we can no longer use bash for
evaluating settings variables. Also we shouldn't populate local.conf
directly and let devstack-gate do that.

Since now devstack never uses localrc file directly, we set [[localrc]]
sections for local.conf instead.

As a nice side effect, it will make the gate hook work with devstack
that may not have the Ie571b5fa5a33d9ed09f30ba7c7724b958ce17616 in
(Newton and below), which may make backports easier later.

Conflicts:
	neutron/tests/contrib/gate_hook.sh
	neutron/tests/contrib/hooks/dstat
	neutron/tests/contrib/hooks/stack_base

Ocata changes: devstack is not used to start dstat for functional and
fullstack jobs, so the corresponding code changes are skipped.

Change-Id: Ibe640a584add3acc89520a2bbb25b6f4c5818e1b
Closes-bug: 1667331
(cherry picked from commit d46636112f45fdf181751285835229b16886ab28)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/438138/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/contrib/hooks/api_all_extensions', 'neutron/tests/contrib/hooks/api_dvrskip_extensions', 'neutron/tests/contrib/gate_hook.sh']",3,2ea107f2c8b91f3cff17c687907d265e3142e25d,bug/1667331,"[[local|localrc]] config=$(cat $GATE_HOOKS/$hook) export DEVSTACK_LOCAL_CONFIG+="" # generated from hook '$hook' ${config} """, cat $GATE_HOOKS/$hook >> $LOCAL_CONF,8,90
openstack%2Fproject-config~master~I58fc37730443451b1c65ea3c445bddee73c09150,openstack/project-config,master,I58fc37730443451b1c65ea3c445bddee73c09150,Changing kolla-kubernetes ironic jobs to source type,MERGED,2017-02-27 16:24:37.000000000,2017-02-28 00:13:48.000000000,2017-02-28 00:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 16:24:37.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a41c0e91ed7f2297bc1711d66aa178b1138cd07a', 'message': 'Changing kolla-kubernetes ironic jobs to source type\n\nChanging kolla-kubernetes ironic jobs to source type\n\nChange-Id: I58fc37730443451b1c65ea3c445bddee73c09150\n'}]",0,438581,a41c0e91ed7f2297bc1711d66aa178b1138cd07a,8,4,1,19384,,,0,"Changing kolla-kubernetes ironic jobs to source type

Changing kolla-kubernetes ironic jobs to source type

Change-Id: I58fc37730443451b1c65ea3c445bddee73c09150
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/438581/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,a41c0e91ed7f2297bc1711d66aa178b1138cd07a,ironic_gate_rename, - gate-kolla-kubernetes-deploy-centos-source-3-ironic-nv - gate-kolla-kubernetes-deploy-ubuntu-source-3-ironic-nv, - gate-kolla-kubernetes-deploy-centos-binary-3-ironic-nv - gate-kolla-kubernetes-deploy-ubuntu-binary-3-ironic-nv,4,4
openstack%2Fproject-config~master~I7cb63f7dfc6f61a9086427a88820714391567144,openstack/project-config,master,I7cb63f7dfc6f61a9086427a88820714391567144,gnocchi: only run upgrade-from-2.2 from stable/3.1,MERGED,2017-02-27 10:54:52.000000000,2017-02-28 00:06:43.000000000,2017-02-28 00:06:42.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 10:54:52.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b943038949b7991cf8e12426c4b7c0aa803be710', 'message': 'gnocchi: only run upgrade-from-2.2 from stable/3.1\n\nstable/3.0 does not have the job configured and master does not care anymore.\n\nChange-Id: I7cb63f7dfc6f61a9086427a88820714391567144\n'}]",0,438428,b943038949b7991cf8e12426c4b7c0aa803be710,8,4,1,1669,,,0,"gnocchi: only run upgrade-from-2.2 from stable/3.1

stable/3.0 does not have the job configured and master does not care anymore.

Change-Id: I7cb63f7dfc6f61a9086427a88820714391567144
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/438428/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b943038949b7991cf8e12426c4b7c0aa803be710,jd/gnocchi-upgrade-jobs, branch: ^stable/3\.1$, branch: ^(?!stable/(1\..|2\..|3.0)),1,1
openstack%2Ftempest~master~I328eb214781a965d4f02692ee4349cbe53ab5044,openstack/tempest,master,I328eb214781a965d4f02692ee4349cbe53ab5044,Add reno for Tempest v15.0.0,MERGED,2017-02-21 20:48:32.000000000,2017-02-27 23:59:32.000000000,2017-02-22 04:10:11.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 8556}, {'_account_id': 12017}, {'_account_id': 14885}]","[{'number': 1, 'created': '2017-02-21 20:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee978152902a0fcfcac32d153350b74475384c66', 'message': 'Add reno for Tempest v15.0.0\n\nChange-Id: I328eb214781a965d4f02692ee4349cbe53ab5044\n'}, {'number': 2, 'created': '2017-02-21 20:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d7394f0e6289dba89fad6b7ccb7b1ff5fca6ae83', 'message': 'Add reno for Tempest v15.0.0\n\nChange-Id: I328eb214781a965d4f02692ee4349cbe53ab5044\n'}, {'number': 3, 'created': '2017-02-21 20:55:55.000000000', 'files': ['releasenotes/notes/15.0.0-start-of-pike-support-4925678d477b0745.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e9c1dcf8f5c7f743e4ad98ae9f095b1078a691f', 'message': 'Add reno for Tempest v15.0.0\n\nChange-Id: I328eb214781a965d4f02692ee4349cbe53ab5044\n'}]",2,436666,4e9c1dcf8f5c7f743e4ad98ae9f095b1078a691f,15,5,3,6167,,,0,"Add reno for Tempest v15.0.0

Change-Id: I328eb214781a965d4f02692ee4349cbe53ab5044
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/436666/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/15.0.0-start-of-pike-support-4925678d477b0745.yaml'],1,ee978152902a0fcfcac32d153350b74475384c66,tag,"--- prelude: > This release is marking the start of Newton release support in Tempest other: - | OpenStack releases supported at this time are **Mitaka**, **Newton**, and **Ocata**. The release under current development as of this tag is Pike, meaning that every Tempest commit is also tested against master during the Pike cycle. However, this does not necessarily mean that using Tempest as of this tag will work against a Pike (or future releases) cloud. ",,13,0
openstack%2Fpython-tripleoclient~stable%2Focata~Ic5cd462879ed1b8ab84144157d8f3d5f67f262b2,openstack/python-tripleoclient,stable/ocata,Ic5cd462879ed1b8ab84144157d8f3d5f67f262b2,Pass empty stack_fields to update manager,MERGED,2017-02-21 16:22:17.000000000,2017-02-27 23:53:06.000000000,2017-02-27 23:53:06.000000000,"[{'_account_id': 3}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 18575}]","[{'number': 1, 'created': '2017-02-21 16:22:17.000000000', 'files': ['tripleoclient/workflows/package_update.py', 'tripleoclient/v1/overcloud_update.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6c953327539cefba8d44cd9ec0e924bad905d435', 'message': 'Pass empty stack_fields to update manager\n\nThere is an additional stack_fields param that needs to be passed to\nthe update manager.\n\nChange-Id: Ic5cd462879ed1b8ab84144157d8f3d5f67f262b2\nCloses-Bug: #1663698\n(cherry picked from commit a137b490c931ce7eccf79e88e38a5ae14603f792)\n'}]",0,436534,6c953327539cefba8d44cd9ec0e924bad905d435,13,4,1,11166,,,0,"Pass empty stack_fields to update manager

There is an additional stack_fields param that needs to be passed to
the update manager.

Change-Id: Ic5cd462879ed1b8ab84144157d8f3d5f67f262b2
Closes-Bug: #1663698
(cherry picked from commit a137b490c931ce7eccf79e88e38a5ae14603f792)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/34/436534/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/package_update.py', 'tripleoclient/v1/overcloud_update.py']",2,6c953327539cefba8d44cd9ec0e924bad905d435,bug/1663698," raise exceptions.DeploymentError(""Package update failed."") else: package_update.update(clients, container=stack_name, queue_name=str(uuid.uuid4())) print(""Package update on stack {0} initiated."".format( parsed_args.stack))"," raise exceptions.DeploymentError(""Stack update failed."") else: status = package_update.update(clients, container=stack_name, queue_name=str(uuid.uuid4())) print(""stack {0} status: {1}"".format(parsed_args.stack, status))",13,5
openstack%2Fnova~stable%2Fmitaka~Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,openstack/nova,stable/mitaka,Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,Ignore deleted services in minimum version calculation,MERGED,2017-02-27 17:18:01.000000000,2017-02-27 23:51:01.000000000,2017-02-27 20:53:11.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16128}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-27 17:18:01.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e05c82b807624b8420df4c94d68b75563b230d2', 'message': 'Ignore deleted services in minimum version calculation\n\nWhen we go to detect the minimum version for a given service, we\nshould ignore any deleted services. Without this, we will return\nthe minimum version of all records, including those that have been\ndeleted with ""nova service-delete"". This patch filters deleted\nservices from the query.\n\nConflicts:\n        nova/db/sqlalchemy/api.py\n        nova/tests/unit/db/test_db_api.py\n\nNOTE(mriedem): The conflicts are due to not having change\n11cb56a2243faa9f2614a8f9a9a84603bc91d6b1 in Mitaka.\n\nCloses-Bug: #1668310\nChange-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b\n(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)\n(cherry picked from commit a1dd547d3ba7d9cf5b73da1ce9668e412501ace1)\n(cherry picked from commit 1ad5c7305c37079ced24bf623810e63d5eac2661)\n'}]",0,438632,2e05c82b807624b8420df4c94d68b75563b230d2,20,7,1,6873,,,0,"Ignore deleted services in minimum version calculation

When we go to detect the minimum version for a given service, we
should ignore any deleted services. Without this, we will return
the minimum version of all records, including those that have been
deleted with ""nova service-delete"". This patch filters deleted
services from the query.

Conflicts:
        nova/db/sqlalchemy/api.py
        nova/tests/unit/db/test_db_api.py

NOTE(mriedem): The conflicts are due to not having change
11cb56a2243faa9f2614a8f9a9a84603bc91d6b1 in Mitaka.

Closes-Bug: #1668310
Change-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b
(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)
(cherry picked from commit a1dd547d3ba7d9cf5b73da1ce9668e412501ace1)
(cherry picked from commit 1ad5c7305c37079ced24bf623810e63d5eac2661)
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/438632/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,2e05c82b807624b8420df4c94d68b75563b230d2,bug/1668310, filter(models.Service.deleted == 0).\,,5,0
openstack%2Fopenstack-ansible~master~I46f2812670ea17b9ff28ef6f054d82fd6dccc999,openstack/openstack-ansible,master,I46f2812670ea17b9ff28ef6f054d82fd6dccc999,unify interface lookups,MERGED,2017-02-09 15:06:56.000000000,2017-02-27 23:48:54.000000000,2017-02-27 23:48:17.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 10881}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-09 15:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8f27406ed7a574d5f35618d890263e9ec5564b08', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-02-09 15:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/614629a7e598ce3019160684c4575f97e7707614', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2017-02-12 08:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/12ffdb049cb5c617117dc12318a63bbfc032c38d', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2017-02-13 13:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0f4e09c97159355a327454baf83045e91d32e70b', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2017-02-16 05:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3b1787ba138c9252c09a20c871f5ca1ecf1ef018', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2017-02-27 20:50:07.000000000', 'files': ['playbooks/common-tasks/dynamic-address-fact.yml', 'playbooks/os-neutron-install.yml', 'playbooks/os-nova-install.yml', 'playbooks/os-cinder-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4c04c688e70ff16ebed4ddcaf20e8e8d712a47b0', 'message': 'unify interface lookups\n\nThe playbooks were running a bunch of common tasks that could be\nsimplified and unified into a single common_task include. This PR moves\nthe interface look into a single place and cleans up the duplicate code\nwithin the cinder, neutron, and nova playbooks.\n\nChange-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,431591,4c04c688e70ff16ebed4ddcaf20e8e8d712a47b0,27,6,6,7353,,,0,"unify interface lookups

The playbooks were running a bunch of common tasks that could be
simplified and unified into a single common_task include. This PR moves
the interface look into a single place and cleans up the duplicate code
within the cinder, neutron, and nova playbooks.

Change-Id: I46f2812670ea17b9ff28ef6f054d82fd6dccc999
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/91/431591/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/common-tasks/dynamic-address-fact.yml', 'playbooks/os-neutron-install.yml', 'playbooks/os-nova-install.yml', 'playbooks/os-cinder-install.yml']",4,8f27406ed7a574d5f35618d890263e9ec5564b08,," - include: dynamic-address-fact.yml vars: network_address: ""management_address"""," - name: Set the cinder storage address set_fact: # NOTE(cloudnull): # Collect the storage address interface data from the host vars of the target node then # Check if the host is running in a container. If not, pull the bridge data from the # storage network. If a storage_bridge is defined pull the IP address from the physical # network device. If no physical bridge is defined collect the storage address from the # ""storage_network_data"" variable. If nothing is defined use the ""ansible_host"" address. storage_address: >- {%- set storage_network_data = hostvars[inventory_hostname]['container_networks']['storage_address'] | default({}) -%} {%- if is_metal is defined and is_metal | bool -%} {%- set storage_bridge = storage_network_data['bridge'] | default('no_bridge_defined') | replace('-', '_') -%} {%- else -%} {%- set storage_bridge = 'no_bridge_defined' -%} {%- endif -%} {%- if storage_bridge != 'no_bridge_defined' -%} {{ hostvars[inventory_hostname]['ansible_' + storage_bridge]['ipv4']['address'] }} {%- elif storage_network_data['address'] is defined -%} {{ storage_network_data['address'] }} {%- else -%} {{ ansible_host }} {%- endif -%} tags: - always",59,72
openstack%2Fproject-config~master~I5ba3e4c7a1e73b3b3b5d57712c07a7eb28fb30db,openstack/project-config,master,I5ba3e4c7a1e73b3b3b5d57712c07a7eb28fb30db,OSA: Prevent CentOS jobs executing for Newton and older,MERGED,2017-02-27 15:20:51.000000000,2017-02-27 23:44:33.000000000,2017-02-27 23:44:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-27 15:20:51.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0bd7fb8efe465bd5c6bdcb477ecea06d4e26ae45', 'message': 'OSA: Prevent CentOS jobs executing for Newton and older\n\nFor the Newton and older branches of the openstack-ansible repo,\nthe CentOS jobs should not run.\n\nChange-Id: I5ba3e4c7a1e73b3b3b5d57712c07a7eb28fb30db\n'}]",0,438551,0bd7fb8efe465bd5c6bdcb477ecea06d4e26ae45,7,3,1,6816,,,0,"OSA: Prevent CentOS jobs executing for Newton and older

For the Newton and older branches of the openstack-ansible repo,
the CentOS jobs should not run.

Change-Id: I5ba3e4c7a1e73b3b3b5d57712c07a7eb28fb30db
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/438551/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,0bd7fb8efe465bd5c6bdcb477ecea06d4e26ae45,openstack-ansible, - name: ^gate-openstack-ansible-openstack-ansible-ceph-(centos-7|ubuntu-xenial).*$ branch: ^(?!stable/(mitaka|newton)).*$ # Skip the OpenStack-Ansible CentOS job for the openstack-ansible repository if # the branch is anything before ocata. - name: ^gate-openstack-ansible-openstack-ansible-aio-centos-7.*$, - name: ^gate-openstack-ansible-openstack-ansible-ceph-ubuntu-xenial.*$,6,1
openstack%2Fcinder~master~I62dd29b48141b439b6e170c08073ab4453f1e50a,openstack/cinder,master,I62dd29b48141b439b6e170c08073ab4453f1e50a,Add SUPPORTED flag to Lenovo iSCSI driver,MERGED,2017-02-01 20:00:36.000000000,2017-02-27 23:42:16.000000000,2017-02-02 20:24:52.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 15249}, {'_account_id': 15941}, {'_account_id': 16941}, {'_account_id': 18120}, {'_account_id': 22248}, {'_account_id': 23613}]","[{'number': 1, 'created': '2017-02-01 20:00:36.000000000', 'files': ['cinder/volume/drivers/lenovo/lenovo_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dece301529e35ffa237561eae9a49e4adb4891d8', 'message': 'Add SUPPORTED flag to Lenovo iSCSI driver\n\nChange-Id: I62dd29b48141b439b6e170c08073ab4453f1e50a\n'}]",0,427886,dece301529e35ffa237561eae9a49e4adb4891d8,68,16,1,17042,,,0,"Add SUPPORTED flag to Lenovo iSCSI driver

Change-Id: I62dd29b48141b439b6e170c08073ab4453f1e50a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/86/427886/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/lenovo/lenovo_iscsi.py'],1,dece301529e35ffa237561eae9a49e4adb4891d8,lenovo-supported-flag," SUPPORTED = True CI_WIKI_NAME = ""Lenovo_Storage_CI"""," CI_WIKI_NAME = ""Vedams-LenovoStorage_FCISCSI_CI""",3,1
openstack%2Fwatcher~master~Iba2130aca93c8e6bccb4f8ed169424c791ebc127,openstack/watcher,master,Iba2130aca93c8e6bccb4f8ed169424c791ebc127,Switch to use test_utils.call_until_true,MERGED,2017-02-09 18:50:17.000000000,2017-02-27 23:40:58.000000000,2017-02-27 23:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 8556}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 21361}, {'_account_id': 22775}, {'_account_id': 23871}]","[{'number': 1, 'created': '2017-02-09 18:50:17.000000000', 'files': ['watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'watcher_tempest_plugin/tests/api/admin/test_audit.py', 'watcher_tempest_plugin/tests/api/admin/base.py', 'watcher_tempest_plugin/tests/api/admin/test_action_plan.py', 'watcher_tempest_plugin/tests/api/admin/test_action.py', 'watcher_tempest_plugin/tests/scenario/test_execute_dummy_optim.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/a9b3534e978ba6df8ce05a755a04aec021f6619f', 'message': 'Switch to use test_utils.call_until_true\n\ntest.call_until_true has been deprecated since Newton on Tempest side,\nand now Tempest provides test_utils.call_until_true as the stable\nlibrary method. So this patch switches to use the stable method before\nremoving old test.call_until_true on Tempest side.\n\nChange-Id: Iba2130aca93c8e6bccb4f8ed169424c791ebc127\nNeeded-by: Ide11a7434a4714e5d2211af1803333535f557370\n'}]",0,431712,a9b3534e978ba6df8ce05a755a04aec021f6619f,12,7,1,6167,,,0,"Switch to use test_utils.call_until_true

test.call_until_true has been deprecated since Newton on Tempest side,
and now Tempest provides test_utils.call_until_true as the stable
library method. So this patch switches to use the stable method before
removing old test.call_until_true on Tempest side.

Change-Id: Iba2130aca93c8e6bccb4f8ed169424c791ebc127
Needed-by: Ide11a7434a4714e5d2211af1803333535f557370
",git fetch https://review.opendev.org/openstack/watcher refs/changes/12/431712/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher_tempest_plugin/tests/api/admin/test_audit.py', 'watcher_tempest_plugin/tests/scenario/test_execute_basic_optim.py', 'watcher_tempest_plugin/tests/api/admin/base.py', 'watcher_tempest_plugin/tests/api/admin/test_action_plan.py', 'watcher_tempest_plugin/tests/api/admin/test_action.py', 'watcher_tempest_plugin/tests/scenario/test_execute_dummy_optim.py']",6,a9b3534e978ba6df8ce05a755a04aec021f6619f,switch-call_until_true,from tempest.lib.common.utils import test_utils self.assertTrue(test_utils.call_until_true( self.assertTrue(test_utils.call_until_true(,from tempest import test self.assertTrue(test.call_until_true( self.assertTrue(test.call_until_true(,22,18
openstack%2Fwatcher~master~I693764145996f4c941de4b129a73c36e0db839d6,openstack/watcher,master,I693764145996f4c941de4b129a73c36e0db839d6,Updated from global requirements,MERGED,2017-02-10 06:02:19.000000000,2017-02-27 23:39:23.000000000,2017-02-27 23:39:23.000000000,"[{'_account_id': 3}, {'_account_id': 13111}, {'_account_id': 18971}]","[{'number': 1, 'created': '2017-02-10 06:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/50861b24a5eeb9714637213ddb7ccfac3bd74702', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 2, 'created': '2017-02-10 09:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/22c2c4fb2d459245f2996eac3d8a0e13731159dc', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 3, 'created': '2017-02-11 00:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/651793487e4c0d26f283a6b51cff947181905fd2', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 4, 'created': '2017-02-13 15:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0c34a5da0396c3364ab3899d822c6a4f65ab9a8a', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 5, 'created': '2017-02-15 01:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0966de7e4c4051503c6e52bf142e0645724d728c', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 6, 'created': '2017-02-15 14:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/dfc33396dd7a1798d7f8e6b5e5ba792d4e9e88d5', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 7, 'created': '2017-02-16 23:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/a15080f9e3e5be4aeed251c0c06d3b24b504a190', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}, {'number': 8, 'created': '2017-02-27 01:21:44.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/watcher/commit/8f85169c15bd70892508161747b328fb20846c1e', 'message': 'Updated from global requirements\n\nChange-Id: I693764145996f4c941de4b129a73c36e0db839d6\n'}]",0,432123,8f85169c15bd70892508161747b328fb20846c1e,25,3,8,11131,,,0,"Updated from global requirements

Change-Id: I693764145996f4c941de4b129a73c36e0db839d6
",git fetch https://review.opendev.org/openstack/watcher refs/changes/23/432123/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,50861b24a5eeb9714637213ddb7ccfac3bd74702,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Fnova~stable%2Fnewton~Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,openstack/nova,stable/newton,Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b,Ignore deleted services in minimum version calculation,MERGED,2017-02-27 17:12:56.000000000,2017-02-27 23:36:50.000000000,2017-02-27 20:52:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14571}]","[{'number': 1, 'created': '2017-02-27 17:12:56.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ad5c7305c37079ced24bf623810e63d5eac2661', 'message': 'Ignore deleted services in minimum version calculation\n\nWhen we go to detect the minimum version for a given service, we\nshould ignore any deleted services. Without this, we will return\nthe minimum version of all records, including those that have been\ndeleted with ""nova service-delete"". This patch filters deleted\nservices from the query.\n\nCloses-Bug: #1668310\nChange-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b\n(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)\n(cherry picked from commit a1dd547d3ba7d9cf5b73da1ce9668e412501ace1)\n'}]",0,438630,1ad5c7305c37079ced24bf623810e63d5eac2661,16,6,1,6873,,,0,"Ignore deleted services in minimum version calculation

When we go to detect the minimum version for a given service, we
should ignore any deleted services. Without this, we will return
the minimum version of all records, including those that have been
deleted with ""nova service-delete"". This patch filters deleted
services from the query.

Closes-Bug: #1668310
Change-Id: Ic96a5eb3728f97a3c35d2c5121e6fdcd4fd1c70b
(cherry picked from commit c79770e615799cd4457ac603dcad4fb3452fe2bc)
(cherry picked from commit a1dd547d3ba7d9cf5b73da1ce9668e412501ace1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/438630/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,1ad5c7305c37079ced24bf623810e63d5eac2661,bug/1668310, filter(models.Service.deleted == 0).\,,5,0
openstack%2Fnova~master~If3734f1c67e898f2645ff1bd62545796769bfc3c,openstack/nova,master,If3734f1c67e898f2645ff1bd62545796769bfc3c,Updated from global requirements,MERGED,2017-02-24 00:13:02.000000000,2017-02-27 23:32:05.000000000,2017-02-25 19:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2017-02-24 00:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c852a621ff93111689acf1bf7b1ab643a447ddc', 'message': 'Updated from global requirements\n\nChange-Id: If3734f1c67e898f2645ff1bd62545796769bfc3c\n'}, {'number': 2, 'created': '2017-02-24 00:51:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/ffae55d096487a13e2f474b6d0887094930e67a0', 'message': 'Updated from global requirements\n\nChange-Id: If3734f1c67e898f2645ff1bd62545796769bfc3c\n'}]",0,437732,ffae55d096487a13e2f474b6d0887094930e67a0,42,11,2,11131,,,0,"Updated from global requirements

Change-Id: If3734f1c67e898f2645ff1bd62545796769bfc3c
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/437732/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9c852a621ff93111689acf1bf7b1ab643a447ddc,openstack/requirements,"setuptools!=24.0.0,!=34.0.0,!=34.0.1,!=34.0.2,!=34.0.3,!=34.1.0,!=34.1.1,!=34.2.0,>=16.0 # PSF/ZPL","setuptools!=24.0.0,>=16.0 # PSF/ZPL",1,1
openstack%2Fnetworking-ovn~master~Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1,openstack/networking-ovn,master,Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1,Get all security groups via api in OVN DB sync functional test,MERGED,2017-02-17 04:04:05.000000000,2017-02-27 23:27:38.000000000,2017-02-27 23:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}, {'_account_id': 23458}]","[{'number': 1, 'created': '2017-02-17 04:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6928657553be5483bd5de76bc049becb67f4cf7b', 'message': 'Get all security groups via api when validating address sets\n\nCurrently,  when validating address sets in OVN DB sync functional tests,\nonly security groups used by port were compared as in neutron DB to those\nin OVN DB, but the logic is different to real OVN DB sync function.\nAn implicit problem will surface when supporting gateway sync functional\ntest, that will cause the security groups mismatch.\nThis patch makes the logic same as real sync, getting all security\ngroups via api regardless whether they are been used by port.\n\nChange-Id: Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 2, 'created': '2017-02-17 04:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/87d2c0ded864fb6c2e8b43b53fb5add5fb2a42a6', 'message': 'Get all security groups via api in OVN DB sync functional test\n\nCurrently,  when validating address sets in OVN DB sync functional test,\nonly security groups used by port were compared as in neutron DB to those\nin OVN DB, but the logic is different to real OVN DB sync function.\nAn implicit problem will surface when supporting gateway sync functional\ntest, that will cause the security groups mismatch.\nThis patch makes the logic same as real sync, getting all security\ngroups via api regardless whether they are been used by port.\n\nChange-Id: Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 3, 'created': '2017-02-23 07:19:07.000000000', 'files': ['networking_ovn/tests/functional/test_ovn_db_sync.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e42535bbeb2623204b490c1c1c73457d6c402601', 'message': 'Get all security groups via api in OVN DB sync functional test\n\nCurrently, when validating address sets in OVN DB sync functional test,\nonly security groups used by port were compared as in neutron DB to those\nin OVN DB, but the logic is different to real OVN DB sync function.\nAn implicit problem will surface when supporting gateway sync functional\ntest, that will cause the security groups mismatch.\nThis patch makes the logic same as real sync, getting all security\ngroups via api regardless whether they are used by port.\n\nChange-Id: Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,435220,e42535bbeb2623204b490c1c1c73457d6c402601,20,4,3,23458,,,0,"Get all security groups via api in OVN DB sync functional test

Currently, when validating address sets in OVN DB sync functional test,
only security groups used by port were compared as in neutron DB to those
in OVN DB, but the logic is different to real OVN DB sync function.
An implicit problem will surface when supporting gateway sync functional
test, that will cause the security groups mismatch.
This patch makes the logic same as real sync, getting all security
groups via api regardless whether they are used by port.

Change-Id: Ia8fc3fd6d56c1453d02c4b0e92a21a4cad6595d1
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/20/435220/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/tests/functional/test_ovn_db_sync.py'],1,6928657553be5483bd5de76bc049becb67f4cf7b,validate_address,"from neutron.tests.unit.extensions import test_securitygroup sg_mgr = test_securitygroup.SecurityGroupTestExtensionManager() self._sg_api = test_extensions.setup_extensions_middleware(sg_mgr) def _api_for_resource(self, resource): if resource in ['security-groups']: return self._sg_api else: return super(TestOvnNbSync, self)._api_for_resource(resource) sgs = self._list('security-groups')['security_groups'] for sg in sgs: for ip_version in ['ip4', 'ip6']: name = utils.ovn_addrset_name(sg['id'], ip_version) db_sgs[name] = [] for port in db_ports: sg_ids = utils.get_lsp_security_groups(port) db_sgs[name].extend(addresses[ip_version])"," for port in db_ports: sg_ids = port.get('security_groups', []) addr_list = db_sgs.setdefault(name, []) addr_list.extend(addresses[ip_version])",17,3
openstack%2Fnetworking-ovn~master~Ie391a02566270a421c67e9f3a849f4f2547fcaa9,openstack/networking-ovn,master,Ie391a02566270a421c67e9f3a849f4f2547fcaa9,support functional tests with python 3.5 in CI jobs,MERGED,2017-02-20 10:00:12.000000000,2017-02-27 23:27:33.000000000,2017-02-27 23:27:33.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}, {'_account_id': 23458}, {'_account_id': 24438}]","[{'number': 1, 'created': '2017-02-20 10:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/510c708fc4672b8b7323254630ac2a47e8518a88', 'message': 'compile ovs when functional tests with python 3.5 in CI jobs\n\nChange-Id: Ie391a02566270a421c67e9f3a849f4f2547fcaa9\nCloses-bug: 1666143\n'}, {'number': 2, 'created': '2017-02-20 10:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/274676ca76e70f12d8775078107303f352d354cf', 'message': 'compile ovs when functional tests with python 3.5 in CI jobs\n\nthis patch is used for\nhttps://review.openstack.org/#/c/435916/\n\nChange-Id: Ie391a02566270a421c67e9f3a849f4f2547fcaa9\nCloses-bug: 1666143\n'}, {'number': 3, 'created': '2017-02-24 06:06:25.000000000', 'files': ['networking_ovn/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c9d7195ccd98f592804ad27b2bd3a7f813de2117', 'message': ""support functional tests with python 3.5 in CI jobs\n\nadd 'dsvm-functional-py35' environment variable in gate_hook.sh\n\nthis patch is used for\nhttps://review.openstack.org/#/c/435916/\n\nChange-Id: Ie391a02566270a421c67e9f3a849f4f2547fcaa9\nCloses-bug: 1666143\n""}]",1,435912,c9d7195ccd98f592804ad27b2bd3a7f813de2117,18,5,3,24438,,,0,"support functional tests with python 3.5 in CI jobs

add 'dsvm-functional-py35' environment variable in gate_hook.sh

this patch is used for
https://review.openstack.org/#/c/435916/

Change-Id: Ie391a02566270a421c67e9f3a849f4f2547fcaa9
Closes-bug: 1666143
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/12/435912/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/tests/contrib/gate_hook.sh'],1,510c708fc4672b8b7323254630ac2a47e8518a88,bug/1666143,"""dsvm-functional""|""dsvm-functional-py35"")","""dsvm-functional"")",1,1
openstack%2Fnetworking-ovn~master~I34a51bfd5712173196f8d5c59bbae7bd8abb3bd0,openstack/networking-ovn,master,I34a51bfd5712173196f8d5c59bbae7bd8abb3bd0,fix deepcopy dict_keys exception in python3.5,MERGED,2017-02-20 06:32:50.000000000,2017-02-27 23:27:28.000000000,2017-02-27 23:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 23458}]","[{'number': 1, 'created': '2017-02-20 06:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1a2806ff366e219a368527170da3801da8bcb228', 'message': 'fix deepcopy dict_keys exception in python3.5\n\nchange dict_keys object to list\n\nChange-Id: I34a51bfd5712173196f8d5c59bbae7bd8abb3bd0\n'}, {'number': 2, 'created': '2017-02-20 06:36:12.000000000', 'files': ['networking_ovn/ovn_db_sync.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/45076c6b15ba8f34c3bc3da94589ba21b355ffd1', 'message': 'fix deepcopy dict_keys exception in python3.5\n\nchange dict_keys object to list\n\nCloses-Bug: #1666113\n\nChange-Id: I34a51bfd5712173196f8d5c59bbae7bd8abb3bd0\n'}]",0,435861,45076c6b15ba8f34c3bc3da94589ba21b355ffd1,12,3,2,24438,,,0,"fix deepcopy dict_keys exception in python3.5

change dict_keys object to list

Closes-Bug: #1666113

Change-Id: I34a51bfd5712173196f8d5c59bbae7bd8abb3bd0
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/61/435861/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/ovn_db_sync.py'],1,1a2806ff366e219a368527170da3801da8bcb228,bug/1666113," ctx, {'router_id': list(db_routers.keys())})"," ctx, {'router_id': db_routers.keys()})",1,1
openstack%2Fnetworking-ovn~master~I4161f870e819e55963867a33d09580d4b81ad4ad,openstack/networking-ovn,master,I4161f870e819e55963867a33d09580d4b81ad4ad,Ignore syncing floating IP ports when handling DB sync,MERGED,2017-02-17 09:02:12.000000000,2017-02-27 23:27:22.000000000,2017-02-27 23:27:22.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}, {'_account_id': 21550}]","[{'number': 1, 'created': '2017-02-17 09:02:12.000000000', 'files': ['networking_ovn/ovn_db_sync.py', 'networking_ovn/tests/unit/test_ovn_db_sync.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b8c319149b52847dffa4137693bdaaccac3a0fd6', 'message': 'Ignore syncing floating IP ports when handling DB sync\n\nIgnore syncing floating IP ports when handling OVN DB sync.\n\nChange-Id: I4161f870e819e55963867a33d09580d4b81ad4ad\nCloses-Bug: #1665574\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,435317,b8c319149b52847dffa4137693bdaaccac3a0fd6,8,4,1,23458,,,0,"Ignore syncing floating IP ports when handling DB sync

Ignore syncing floating IP ports when handling OVN DB sync.

Change-Id: I4161f870e819e55963867a33d09580d4b81ad4ad
Closes-Bug: #1665574
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/17/435317/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/ovn_db_sync.py', 'networking_ovn/tests/unit/test_ovn_db_sync.py']",2,b8c319149b52847dffa4137693bdaaccac3a0fd6,bug/1665574," 'network_id': 'n2'}, {'id': 'fp1', 'device_owner': 'network:floatingip', 'fixed_ips': [{'subnet_id': 'ext-subnet', 'ip_address': '90.0.0.10'}], 'network_id': 'ext-net'}] if port['id'] in ['p1n1', 'fp1']: # because p1n1 is already in lswitch-port list # and fp1 is a floating IP port", 'network_id': 'n2'}] if port['id'] == 'p1n1': # because it is already in lswitch-port list,16,12
openstack%2Fnetworking-ovn~master~I0cd9a6e1f60f1f003f7257b96226be94f6cd557e,openstack/networking-ovn,master,I0cd9a6e1f60f1f003f7257b96226be94f6cd557e,support functional tests with python 3.5,MERGED,2017-02-20 06:17:35.000000000,2017-02-27 23:27:14.000000000,2017-02-27 23:27:14.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}, {'_account_id': 21550}, {'_account_id': 23458}]","[{'number': 1, 'created': '2017-02-20 06:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9640d6427a246ed6c86330505c8deecce6b93c16', 'message': 'support functional tests with python 3.5\n\nwe can running functional tests with python 3.5 by\n""tox -e functional-py35""\nor\n""tox -e dsvm-functional-py35""\n\nChange-Id: I0cd9a6e1f60f1f003f7257b96226be94f6cd557e\n'}, {'number': 2, 'created': '2017-02-22 12:28:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b4f82bd9c0f6d8ffa94eddc9c203c82791445547', 'message': 'support functional tests with python 3.5\n\nwe can running functional tests with python 3.5 by\n""tox -e functional-py35""\nor\n""tox -e dsvm-functional-py35""\n\nChange-Id: I0cd9a6e1f60f1f003f7257b96226be94f6cd557e\n'}]",1,435860,b4f82bd9c0f6d8ffa94eddc9c203c82791445547,11,5,2,24438,,,0,"support functional tests with python 3.5

we can running functional tests with python 3.5 by
""tox -e functional-py35""
or
""tox -e dsvm-functional-py35""

Change-Id: I0cd9a6e1f60f1f003f7257b96226be94f6cd557e
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/60/435860/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9640d6427a246ed6c86330505c8deecce6b93c16,,[testenv:functional-py35] basepython = python3.5 setenv = {[testenv]setenv} OS_TEST_PATH=./networking_ovn/tests/functional deps = {[testenv]deps} [testenv:dsvm-functional-py35] basepython = python3.5 setenv = {[testenv:functional]setenv} deps = {[testenv:functional]deps} commands = bash tools/pretty_tox.sh '{posargs}' ,,14,0
openstack%2Fnetworking-ovn~master~Idc4b80f11b814689ea07f46bcde8a649319b03dd,openstack/networking-ovn,master,Idc4b80f11b814689ea07f46bcde8a649319b03dd,Integrate l3 gw test to l3_ovn unit test,MERGED,2017-02-20 07:01:47.000000000,2017-02-27 23:27:09.000000000,2017-02-27 23:27:09.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-20 07:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/12cefea03082553c6455547ef366c0a151b5ebab', 'message': 'Integrate l3 gw test to l3_ovn unit test\n\nThis patch integrates l3 gw test cases in ExtGwModeIntTestCase to l3 ovn\nunit test that ten more test cases will be ran.\n\nChange-Id: Idc4b80f11b814689ea07f46bcde8a649319b03dd\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}, {'number': 2, 'created': '2017-02-23 01:24:23.000000000', 'files': ['networking_ovn/tests/unit/l3/test_l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e018f17d311c7ba249e2c3c9c9b078c0eb4e2b91', 'message': 'Integrate l3 gw test to l3_ovn unit test\n\nThis patch integrates l3 gw test cases in ExtGwModeIntTestCase to l3 ovn\nunit test that ten more test cases will be ran.\n\nChange-Id: Idc4b80f11b814689ea07f46bcde8a649319b03dd\nSigned-off-by: Dong Jun <dongj@dtdream.com>\n'}]",0,435868,e018f17d311c7ba249e2c3c9c9b078c0eb4e2b91,12,3,2,23458,,,0,"Integrate l3 gw test to l3_ovn unit test

This patch integrates l3 gw test cases in ExtGwModeIntTestCase to l3 ovn
unit test that ten more test cases will be ran.

Change-Id: Idc4b80f11b814689ea07f46bcde8a649319b03dd
Signed-off-by: Dong Jun <dongj@dtdream.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/68/435868/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/tests/unit/l3/test_l3_ovn.py'],1,12cefea03082553c6455547ef366c0a151b5ebab,l3gw_test,"from neutron.tests.unit.api import test_extensionsfrom neutron.tests.unit.extensions import test_l3_ext_gw_mode as test_l3_gwclass OVNL3ExtrarouteTests(test_l3_gw.ExtGwModeIntTestCase, test_l3.L3NatDBIntTestCase, l3_gw_mgr = test_l3_gw.TestExtensionManager() test_extensions.setup_extensions_middleware(l3_gw_mgr)","class OVNL3ExtrarouteTests(test_l3.L3NatDBIntTestCase,",6,1
openstack%2Fnetworking-ovn~master~I5a664d5726d7d8dc383a44d16f711d24bba7cd56,openstack/networking-ovn,master,I5a664d5726d7d8dc383a44d16f711d24bba7cd56,doc: Remove modindex link.,MERGED,2017-02-16 06:59:26.000000000,2017-02-27 23:27:04.000000000,2017-02-27 23:27:03.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-16 06:59:26.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/87c7195816494c0ca30ffaf257b381cac3c84cf2', 'message': ""doc: Remove modindex link.\n\nThis generates a link to something that doesn't exist.\n\nChange-Id: I5a664d5726d7d8dc383a44d16f711d24bba7cd56\nCloses-bug: 1656342\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n""}]",0,434674,87c7195816494c0ca30ffaf257b381cac3c84cf2,7,3,1,1561,,,0,"doc: Remove modindex link.

This generates a link to something that doesn't exist.

Change-Id: I5a664d5726d7d8dc383a44d16f711d24bba7cd56
Closes-bug: 1656342
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/74/434674/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,87c7195816494c0ca30ffaf257b381cac3c84cf2,bug/1656342,,* :ref:`modindex`,0,1
openstack%2Fnetworking-ovn~master~Ife9af63c32495d0dcf16839026ba4143ce09a811,openstack/networking-ovn,master,Ife9af63c32495d0dcf16839026ba4143ce09a811,Fix typo,MERGED,2017-02-21 06:09:15.000000000,2017-02-27 23:26:56.000000000,2017-02-27 23:26:56.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-21 06:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6d23ae2ba04ae9b1738163c501d388849e747eb6', 'message': 'Fix typo\n\nChange-Id: Ife9af63c32495d0dcf16839026ba4143ce09a811\n'}, {'number': 2, 'created': '2017-02-24 09:11:00.000000000', 'files': ['networking_ovn/ml2/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e25ddaf8239cc9601b414c43d70924d9bfdc3fd5', 'message': 'Fix typo\n\nChange-Id: Ife9af63c32495d0dcf16839026ba4143ce09a811\n'}]",0,436318,e25ddaf8239cc9601b414c43d70924d9bfdc3fd5,11,3,2,21550,,,0,"Fix typo

Change-Id: Ife9af63c32495d0dcf16839026ba4143ce09a811
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/18/436318/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/ml2/mech_driver.py'],1,6d23ae2ba04ae9b1738163c501d388849e747eb6,fix_typo," port has no extra dhcp options. # will be inserted for such a subnet. So in that case, the subnet"," port has no extra dhcp optoins. # wll be inserted for such a subnet. So in that case, the subnet",2,2
openstack%2Fnetworking-ovn~master~I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8,openstack/networking-ovn,master,I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8,VM metadata access with native-dhcp,ABANDONED,2016-05-12 01:27:44.000000000,2017-02-27 23:20:03.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 8410}, {'_account_id': 10237}, {'_account_id': 11682}, {'_account_id': 12959}, {'_account_id': 14926}, {'_account_id': 18658}]","[{'number': 1, 'created': '2016-05-12 01:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8709dcaa581e85ef62fd37f94a8684821443104c', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC has been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms.\nSuch an approach was suggested here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069824.html\nand this WIP patch implements along the lines suggested above.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nThe initial thought for HA (as suggested in above link) is\nactive-passive. Active agent sets the subnet host-routes\nfor all networks to point to its metadata ports. Agent-dead\ndetection triggers active to passive transition.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n*Metadata-access for VM is working with ovn-native-dhcp\nin progress:\n* devstack and vagrant integration\n* HA\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 2, 'created': '2016-05-15 21:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ee75bff7a941caf40b4978f55ba097052e321aba', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC has been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms.\nSuch an approach was suggested here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069824.html\nand this WIP patch implements along the lines suggested above.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nThe initial thought for HA (as suggested in above link) is\nactive-passive. Active agent sets the subnet host-routes\nfor all networks to point to its metadata ports. Agent-dead\ndetection triggers active to passive transition.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* HA\n* Unit Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 3, 'created': '2016-05-27 23:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/52a55b72c71dd6ddef863cc2b4f104b336087c0b', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC/service appliance\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms.\nSuch an approach was suggested here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069824.html\nand this WIP patch implements along the lines suggested above.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 4, 'created': '2016-06-02 21:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2694fe53b5d49911c999a3c2160ae79b119ec910', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC/service appliance\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 5, 'created': '2016-06-06 01:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f920eec4e551784a8e9c281318c55f5730bb7a5a', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC/service appliance\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 6, 'created': '2016-06-07 22:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/810db87b26f1e48f12fdd46162286fbd69933477', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC/service appliance\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 7, 'created': '2016-07-06 20:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f8ce95440cc0daeb263dfbe1e838a9a63a170924', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using SFC/service appliance\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 8, 'created': '2016-07-07 21:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/57a4288bf5d3fad2eaeb2fd9a5e66760235363c8', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 9, 'created': '2016-07-12 18:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2c213263b08ebaba4d9ab59f09f1d0ce6c3172f0', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 10, 'created': '2016-07-13 01:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2f88729615af74a96e9571026bce2ef0905de53e', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 11, 'created': '2016-07-13 22:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/44c812c81dfcd3dc43b29b2e6d63fc463093fdea', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\n\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nActive/passive HA is implemented. For any network,\nboth ovn-metadata-agents try to set the subnet host-route,\nand the first one succeeds. Agent-dead detection triggers\nthe passive agent to assert subnet host route to point\nto its ports.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\n* Active/passive HA is working\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 12, 'created': '2016-07-14 20:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7186758b21b1108e80bf2b88e04fb991930bb061', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nMultiple agents with network assignment to agents, or agent HA\nare not implemented, to keep it simple for now.\nSuch functionality can be added in the future by\nrefactoring from the dhcp/l3 agents as needed.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 13, 'created': '2016-07-22 00:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/15335358ad007fd64477d779f39bee2c5a935aa5', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listen to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nMultiple agents with network assignment to agents, or agent HA\nare not implemented, to keep it simple for now.\nSuch functionality can be added in the future by\nrefactoring from the dhcp/l3 agents as needed.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 14, 'created': '2016-07-25 23:08:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ca134b321aeed8b94ea8126905ee106024fb912d', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listens to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nMultiple agents with network assignment to agents, or agent HA\nare not implemented for now.\nSuch functionality can be added in the future by\nrefactoring from the dhcp/l3 agents as needed.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 15, 'created': '2016-07-27 00:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ca4ecd5f363a602f40e6f2109f9975a01ef83ebb', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listens to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nMultiple agents with network assignment to agents, or agent HA\nare not implemented for now.\nSuch functionality can be added in the future by\nrefactoring from the dhcp/l3 agents as needed.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 16, 'created': '2016-07-27 23:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ac9e1f3a88809ea1d37ce411539b5a4fcf59139d', 'message': 'WIP - VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Function/SFC\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listens to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nMultiple agents with network assignment to agents, or agent HA\nare not implemented for now.\nSuch functionality can be added in the future by\nrefactoring from the dhcp/l3 agents as needed.\n\nDepends-On: Ia3e229f86bf66f5b9b0d867ff41f56ed4be2e8f4\nCloses-Bug: 1562132\n\nWIP status:\n* Metadata-access for VM is working with ovn-native-dhcp\nIn progress:\n* Unit Tests,Functional Tests\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 17, 'created': '2016-07-29 03:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7d39df30fa2964d4ff90edc0d629933f7994989d', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listens to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 18, 'created': '2016-08-01 04:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/263eb5c1622131456120ae1ebb3b9086a94e1563', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nExisting neutron-metadata-agent, and\nneutron-metadata-proxy, are reused as-is and\ncode is refactored from the neutron-dhcp-agent to remove\ndhcp-specific code, and retain the metadata related code.\n\nThe agent only listens to network and subnet notifications\n(port notifications are not needed).\nFor each network, a namespace is created, and a metadata-port\nis created within that namespace. A subnet host-route\nis added to point 169.254.169.254 to the metadata-port.\nNative-dhcp propagates that subnet host-route to VMs in dhcp\ntransactions via dhcp option 121.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 19, 'created': '2016-08-04 21:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/302ac72c98de5144c3ebf4052da3cf4ef0b73594', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 20, 'created': '2016-08-05 23:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ba419faa55976f40c8e7e58a721ead38451a5e4d', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 21, 'created': '2016-08-06 23:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/94c6a47fc6f38b338c169466d02a6672f27df32a', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 22, 'created': '2016-08-11 02:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f0652fd4431262bc19d3edfbd19f29c35ef37244', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality can be added in\nthe future.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 23, 'created': '2016-08-12 02:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e04ba1375eae391893eed62c9bc39e316e80ad4d', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 24, 'created': '2016-08-12 04:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/de1a138cbb1468fa45e1145bdf167c472841289c', 'message': 'VM metadata access with native-dhcp\n\nWith ovn-native-dhcp, there is no need to run the\nneutron-dhcp-agent. Since VM metadata-access was provided\nby the neutron-dhcp-agent, a new approach is needed\nto support VM metadata access with native-dhcp.\n\nOvn-native metadata access using Service Functions\nhas been proposed here:\nhttp://openvswitch.org/pipermail/dev/2016-April/069700.html\nUntil the above proposal is implemented, we need a solution using\nexisting neutron based mechanisms which is implemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 25, 'created': '2016-08-15 01:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/10446a9b768d6de4de89c68c6757499b773d1db5', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 26, 'created': '2016-08-15 01:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7132cff81e60634a6feb5f3fc76319fbeefebcab', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 27, 'created': '2016-08-25 21:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1fa8eb2cf4967a1cb2850399eeb4f060c902a9b2', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 28, 'created': '2016-09-07 22:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3310db88fee4f3083c92e28d6541e45f143d9715', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 29, 'created': '2016-09-08 05:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7935731ad0504d8d992343c9981eb586f0d01435', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 30, 'created': '2016-09-08 18:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8ce4d8af78246e71807e8ccf3d13cc36eca05685', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 31, 'created': '2016-09-13 16:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bf1b907fb1242a9918fcfd6ce27b1cb08d9007c8', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}, {'number': 32, 'created': '2016-09-13 16:23:43.000000000', 'files': ['networking_ovn/metadata/etc/ovn_metadata_agent.ini.sample', 'networking_ovn/tests/unit/metadata/test_agent.py', 'networking_ovn/metadata/agent/metadata.py', 'networking_ovn/tests/unit/metadata/__init__.py', 'networking_ovn/metadata/ovn_metadata_rpc.py', 'doc/source/design/vm_metadata.rst', 'devstack/computenode-local.conf.sample', 'networking_ovn/cmd/agent/metadata.py', 'networking_ovn/metadata/agent/__init__.py', 'networking_ovn/cmd/agent/__init__.py', 'networking_ovn/metadata/agent/config.py', 'devstack/local.conf.sample', 'networking_ovn/ml2/mech_driver.py', 'devstack/lib/networking-ovn', 'networking_ovn/metadata/__init__.py', 'setup.cfg', 'networking_ovn/metadata/agent/ovn_metadata_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/66804eadea06357b70494de87a35bfd1668b5cc9', 'message': 'VM metadata access with native-dhcp\n\nOvn-native metadata access using Service Functions has been proposed.\nUntil service functions are implemented, we need a solution for\nVM metadata using existing neutron based mechanisms which is\nimplemented here.\n\nCode is refactored from the DhcpAgent. Dhcp related\nbehaviors are removed and metadata related behaviors are retained.\nThis is achieved with a DhcpDriver which stubs out\nall DHCP related behaviors.\n\nRPC is modified to only send network and\nsubnet notifications from plugin to agent.\nPort notifications are not needed for metadata.\n\nNetwork assignment to agents, or agent HA\nare not implemented. Such functionality will be added in\nthe future by refactoring from the dhcp agent.\n\nCloses-Bug: 1562132\nRelated-Bug: 1611119\n\nChange-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8\n'}]",26,315305,66804eadea06357b70494de87a35bfd1668b5cc9,95,10,32,12959,,,0,"VM metadata access with native-dhcp

Ovn-native metadata access using Service Functions has been proposed.
Until service functions are implemented, we need a solution for
VM metadata using existing neutron based mechanisms which is
implemented here.

Code is refactored from the DhcpAgent. Dhcp related
behaviors are removed and metadata related behaviors are retained.
This is achieved with a DhcpDriver which stubs out
all DHCP related behaviors.

RPC is modified to only send network and
subnet notifications from plugin to agent.
Port notifications are not needed for metadata.

Network assignment to agents, or agent HA
are not implemented. Such functionality will be added in
the future by refactoring from the dhcp agent.

Closes-Bug: 1562132
Related-Bug: 1611119

Change-Id: I6ae7d0e0e5db49dbd3c1c753e0a9d1ac0d5a4aa8
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/05/315305/9 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/cmd/agent/__init__.py', 'networking_ovn/metadata/agent/metadata.py', 'networking_ovn/metadata/ovn_metadata_rpc.py', 'devstack/plugin.sh', 'networking_ovn/metadata/__init__.py', 'setup.cfg', 'networking_ovn/cmd/agent/metadata.py', 'networking_ovn/plugin.py', 'networking_ovn/metadata/agent/__init__.py', 'networking_ovn/metadata/agent/ovn_metadata_agent.py']",10,8709dcaa581e85ef62fd37f94a8684821443104c,bug/1562132,"# Copyright 2015 OpenStack Foundation # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet import sys from oslo_config import cfg from oslo_service import service from neutron.agent.common import config from neutron.agent.linux import interface from neutron.agent.linux import utils as agent_utils from neutron.agent.metadata import agent as metadata_agent from neutron.agent.metadata import config as metadata_config from neutron.common import config as common_config from neutron import service as neutron_service from neutron.openstack.common.cache import cache class OvnUnixDomainMetadataProxy(metadata_agent.UnixDomainMetadataProxy): def __init__(self, conf): self.conf = conf agent_utils.ensure_directory_exists_without_file( cfg.CONF.metadata_proxy_socket) def server(self): server = agent_utils.UnixDomainWSGIServer('neutron-ovn-metadata-agent') server.start(metadata_agent.MetadataProxyHandler(self.conf), self.conf.metadata_proxy_socket, workers=self.conf.metadata_workers, backlog=self.conf.metadata_backlog, mode=self._get_socket_mode()) return server def register_options(conf): config.register_interface_driver_opts_helper(conf) cfg.CONF.set_default(name='interface_driver', default='openvswitch') config.register_agent_state_opts_helper(conf) config.register_availability_zone_opts_helper(conf) conf.register_opts(metadata_config.OVN_METADATA_AGENT_OPTS) conf.register_opts(metadata_config.DRIVER_OPTS) conf.register_opts(metadata_config.SHARED_OPTS) conf.register_opts(interface.OPTS) def get_unix_metadata_server(conf): cfg.CONF.register_opts(metadata_config.UNIX_DOMAIN_METADATA_PROXY_OPTS) cfg.CONF.register_opts(metadata_config.METADATA_PROXY_HANDLER_OPTS) cache.register_oslo_configs(cfg.CONF) cfg.CONF.set_default(name='cache_url', default='memory://?default_ttl=5') proxy = OvnUnixDomainMetadataProxy(cfg.CONF) return proxy.server() def main(): register_options(cfg.CONF) common_config.init(sys.argv[1:]) config.setup_logging() server = neutron_service.Service.create( binary='neutron-ovn-metadata-agent', topic=""metadata_agent"", report_interval=cfg.CONF.AGENT.report_interval, manager='networking_ovn.metadata.agent' '.metadata.OvnMetadataAgentWithStateReport' ) pool = eventlet.GreenPool() unix_metadata_server_thread = pool.spawn( get_unix_metadata_server(cfg.CONF).wait) service_thread = pool.spawn(service.launch(cfg.CONF, server).wait) service_thread.link(lambda gt: unix_metadata_server_thread.kill()) unix_metadata_server_thread.link(lambda gt: service_thread.kill()) pool.waitall() ",,872,2
openstack%2Fcinder~master~Iee73777f7fee7aff1d18d42419c4323e91ca8999,openstack/cinder,master,Iee73777f7fee7aff1d18d42419c4323e91ca8999,Add SUPPORTED flag to HP MSA driver,MERGED,2017-02-01 19:46:04.000000000,2017-02-27 23:19:28.000000000,2017-02-02 23:31:53.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 15249}, {'_account_id': 15941}, {'_account_id': 16941}, {'_account_id': 18444}, {'_account_id': 21884}, {'_account_id': 23613}]","[{'number': 1, 'created': '2017-02-01 19:46:04.000000000', 'files': ['cinder/volume/drivers/san/hp/hpmsa_fc.py', 'cinder/volume/drivers/san/hp/hpmsa_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc0eb50cfce27f810f2540a002f88b7075bf37cb', 'message': 'Add SUPPORTED flag to HP MSA driver\n\nChange-Id: Iee73777f7fee7aff1d18d42419c4323e91ca8999\n'}]",0,427881,fc0eb50cfce27f810f2540a002f88b7075bf37cb,72,14,1,17042,,,0,"Add SUPPORTED flag to HP MSA driver

Change-Id: Iee73777f7fee7aff1d18d42419c4323e91ca8999
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/427881/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/san/hp/hpmsa_fc.py', 'cinder/volume/drivers/san/hp/hpmsa_iscsi.py']",2,fc0eb50cfce27f810f2540a002f88b7075bf37cb,restore-hpmsa-driver," CI_WIKI_NAME = ""Vedams-HPMSA_FCISCSIDriver_CI"" SUPPORTED = True ",,8,0
openstack%2Fproject-config~master~I7fd90939db9fcb0edc1afc4f62248801f3c20ca5,openstack/project-config,master,I7fd90939db9fcb0edc1afc4f62248801f3c20ca5,Bring infracloud-chocolate back online,MERGED,2017-02-27 13:20:07.000000000,2017-02-27 23:14:45.000000000,2017-02-27 23:14:44.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2017-02-27 13:20:07.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4e4f75f01091c818507bda520faec1b5915b870f', 'message': ""Bring infracloud-chocolate back online\n\nNow that the Pike PTG is over, bring infracloud-chocolate back online\nfor production. We do this, to avoid nodepool-builder issues (we are\nnot deleting diskimages from disk).\n\nMoving forward, we'll need to update nodepool to properly support 2\nnodepool launchers using a shared tenant.\n\nChange-Id: I7fd90939db9fcb0edc1afc4f62248801f3c20ca5\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,438490,4e4f75f01091c818507bda520faec1b5915b870f,7,3,1,4162,,,0,"Bring infracloud-chocolate back online

Now that the Pike PTG is over, bring infracloud-chocolate back online
for production. We do this, to avoid nodepool-builder issues (we are
not deleting diskimages from disk).

Moving forward, we'll need to update nodepool to properly support 2
nodepool launchers using a shared tenant.

Change-Id: I7fd90939db9fcb0edc1afc4f62248801f3c20ca5
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/438490/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,4e4f75f01091c818507bda520faec1b5915b870f,, - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate - name: infracloud-chocolate region-name: 'RegionOne' cloud: infracloud-chocolate api-timeout: 60 boot-timeout: 120 max-servers: 100 rate: 0.25 image-type: 'qcow2' template-hostname: '{image.name}-{timestamp}' images: - name: ubuntu-precise min-ram: 8000 name-filter: 'nodepool' diskimage: ubuntu-precise username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: ubuntu-trusty min-ram: 8000 name-filter: 'nodepool' diskimage: ubuntu-trusty username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: ubuntu-xenial min-ram: 8000 name-filter: 'nodepool' diskimage: ubuntu-xenial username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: debian-jessie min-ram: 8000 name-filter: 'nodepool' diskimage: debian-jessie username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: fedora-25 min-ram: 8000 name-filter: 'nodepool' diskimage: fedora-25 username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true - name: centos-7 min-ram: 8000 name-filter: 'nodepool' diskimage: centos-7 username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true,# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate# - name: infracloud-chocolate # region-name: 'RegionOne' # cloud: infracloud-chocolate # api-timeout: 60 # boot-timeout: 120 # max-servers: 100 # rate: 0.25 # image-type: 'qcow2' # template-hostname: '{image.name}-{timestamp}' # images: # - name: ubuntu-precise # min-ram: 8000 # name-filter: 'nodepool' # diskimage: ubuntu-precise # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true # - name: ubuntu-trusty # min-ram: 8000 # name-filter: 'nodepool' # diskimage: ubuntu-trusty # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true # - name: ubuntu-xenial # min-ram: 8000 # name-filter: 'nodepool' # diskimage: ubuntu-xenial # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true # - name: debian-jessie # min-ram: 8000 # name-filter: 'nodepool' # diskimage: debian-jessie # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true # - name: fedora-25 # min-ram: 8000 # name-filter: 'nodepool' # diskimage: fedora-25 # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true # - name: centos-7 # min-ram: 8000 # name-filter: 'nodepool' # diskimage: centos-7 # username: jenkins # private-key: /home/nodepool/.ssh/id_rsa # config-drive: true,64,64
openstack%2Fopenstack-ansible~stable%2Fnewton~I7afeabbfe7b85fd4a3010e77ee936cf412eca0fc,openstack/openstack-ansible,stable/newton,I7afeabbfe7b85fd4a3010e77ee936cf412eca0fc,Update pip_install role SHA,MERGED,2017-02-27 14:24:04.000000000,2017-02-27 23:11:31.000000000,2017-02-27 23:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-27 14:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ecf113ce504fe6e86c386e078633152f6392dcf5', 'message': 'Update pip_install role SHA\n\nIn order to ensure that the following patches are included\nin the 14.1.0 release, which will be the first release with\nthe extra repo and UCA/RDO package modifications, the SHA\nfor the pip_install role is updated.\n\nhttps://review.openstack.org/438499\nhttps://review.openstack.org/437603\n\nChange-Id: I7afeabbfe7b85fd4a3010e77ee936cf412eca0fc\n'}, {'number': 2, 'created': '2017-02-27 20:23:37.000000000', 'files': ['ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b491f259affa052adf78b9844ceb22301c6c9f63', 'message': 'Update pip_install role SHA\n\nIn order to ensure that the following patches are included\nin the 14.1.0 release, which will be the first release with\nthe extra repo and UCA/RDO package modifications, the SHA\nfor the pip_install role is updated.\n\nhttps://review.openstack.org/438499\nhttps://review.openstack.org/437603\n\nChange-Id: I7afeabbfe7b85fd4a3010e77ee936cf412eca0fc\n'}]",0,438506,b491f259affa052adf78b9844ceb22301c6c9f63,12,4,2,6816,,,0,"Update pip_install role SHA

In order to ensure that the following patches are included
in the 14.1.0 release, which will be the first release with
the extra repo and UCA/RDO package modifications, the SHA
for the pip_install role is updated.

https://review.openstack.org/438499
https://review.openstack.org/437603

Change-Id: I7afeabbfe7b85fd4a3010e77ee936cf412eca0fc
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/06/438506/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible-role-requirements.yml'],1,ecf113ce504fe6e86c386e078633152f6392dcf5,, version: 1ce6617728d339082ae18a2246fb4ea7f6345eb5, version: 32c44db63e519b4ccacc898b6dce0ff2fe904acb,1,1
openstack%2Foslo.messaging~master~I4634c082c2383569c4aa8a6d9a8a560de7e3c12f,openstack/oslo.messaging,master,I4634c082c2383569c4aa8a6d9a8a560de7e3c12f,drop topic keyword from Notifier,MERGED,2017-02-14 22:11:46.000000000,2017-02-27 23:05:57.000000000,2017-02-27 23:05:57.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-14 22:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1be734408f67b3c9466380a3b6bd9760610e3e6a', 'message': 'drop topic keyword from Notifier\n\nwe marked it for removal >=5.0.0\n\nChange-Id: I4634c082c2383569c4aa8a6d9a8a560de7e3c12f\n'}, {'number': 2, 'created': '2017-02-14 22:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ccb67ba5aa45e15e0ef7b5bab11e7f5aa2363d76', 'message': 'drop topic keyword from Notifier\n\nwe marked it for removal >=5.0.0\n\nChange-Id: I4634c082c2383569c4aa8a6d9a8a560de7e3c12f\n'}, {'number': 3, 'created': '2017-02-15 18:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/fe001370aa3fd6ac468b2019ded63f7573fb7423', 'message': 'drop topic keyword from Notifier\n\nwe marked it for removal >=5.0.0\n\nChange-Id: I4634c082c2383569c4aa8a6d9a8a560de7e3c12f\n'}, {'number': 4, 'created': '2017-02-27 14:13:11.000000000', 'files': ['oslo_messaging/tests/functional/test_functional.py', 'oslo_messaging/tests/notify/test_notifier.py', 'oslo_messaging/notify/logger.py', 'oslo_messaging/tests/notify/test_listener.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/notify/notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/94c818dc9841bbfd82dd2526ed3cabdf08ecdb86', 'message': 'drop topic keyword from Notifier\n\nwe marked it for removal >=5.0.0\n\nChange-Id: I4634c082c2383569c4aa8a6d9a8a560de7e3c12f\n'}]",0,433950,94c818dc9841bbfd82dd2526ed3cabdf08ecdb86,29,6,4,6537,,,0,"drop topic keyword from Notifier

we marked it for removal >=5.0.0

Change-Id: I4634c082c2383569c4aa8a6d9a8a560de7e3c12f
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/50/433950/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/functional/test_functional.py', 'oslo_messaging/tests/notify/test_notifier.py', 'oslo_messaging/notify/logger.py', 'oslo_messaging/tests/notify/test_listener.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/notify/notifier.py']",6,1be734408f67b3c9466380a3b6bd9760610e3e6a,cleanup," topics=['notifications']) driver=None, serializer=None, retry=None,","from debtcollector import renames topic='notifications') @renames.renamed_kwarg('topic', 'topics', message=""Please use topics instead of topic"", version='4.5.0', removal_version='5.0.0') driver=None, topic=None, serializer=None, retry=None, :param topic: the topic which to send messages on :type topic: str elif topic is not None: self._topics = [topic]",17,31
openstack%2Ftripleo-heat-templates~master~Iff879cd641f6207644b1b6309a6ec4129f1a255a,openstack/tripleo-heat-templates,master,Iff879cd641f6207644b1b6309a6ec4129f1a255a,Deploy CI scenarios with Pacemaker,MERGED,2017-02-26 19:25:43.000000000,2017-02-27 23:04:33.000000000,2017-02-27 23:04:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-26 19:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6e0d6e1842efa8537382b55f9927cc45abb1b62f', 'message': 'Deployi CI scenarios with Pacemaker\n\nPacemaker is now deployed by default and it would be great to have it\ntested for all scenarios to deploy real environments used in production.\n\nChange-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a\n'}, {'number': 2, 'created': '2017-02-26 19:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9761e848a08a994f85872716a96ba7f703b7fe70', 'message': 'Deploy CI scenarios with Pacemaker\n\nPacemaker is now deployed by default and it would be great to have it\ntested for all scenarios to deploy real environments used in production.\n\nChange-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a\n'}, {'number': 3, 'created': '2017-02-26 23:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/828788f1d17f5b14a058bf79aeafd526db842d9d', 'message': 'Deploy CI scenarios with Pacemaker\n\nPacemaker is now deployed by default and it would be great to have it\ntested for all scenarios to deploy real environments used in production.\n\nChange-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a\n'}, {'number': 4, 'created': '2017-02-27 12:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe1fb8b142971b6ed91d7b533fffd23fddd57332', 'message': 'Deploy CI scenarios with Pacemaker\n\nPacemaker is now deployed by default and it would be great to have it\ntested for all scenarios to deploy real environments used in production.\n\nChange-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a\n'}, {'number': 5, 'created': '2017-02-27 18:54:59.000000000', 'files': ['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml', 'ci/environments/multinode.yaml', 'ci/environments/multinode_major_upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f08124e8ca98e22244cb66e632e587690d3aefcb', 'message': 'Deploy CI scenarios with Pacemaker\n\nPacemaker is now deployed by default and it would be great to have it\ntested for all scenarios to deploy real environments used in production.\n\nChange-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a\n'}]",0,438287,f08124e8ca98e22244cb66e632e587690d3aefcb,24,2,5,3153,,,0,"Deploy CI scenarios with Pacemaker

Pacemaker is now deployed by default and it would be great to have it
tested for all scenarios to deploy real environments used in production.

Change-Id: Iff879cd641f6207644b1b6309a6ec4129f1a255a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/87/438287/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml', 'ci/environments/multinode.yaml', 'ci/environments/multinode_major_upgrade.yaml']",6,6e0d6e1842efa8537382b55f9927cc45abb1b62f,pacemaker/scenarios, OS::TripleO::Services::RabbitMQ: ../../puppet/services/pacemaker/rabbitmq.yaml OS::TripleO::Services::HAproxy: ../../puppet/services/pacemaker/haproxy.yaml OS::TripleO::Services::Pacemaker: ../../puppet/services/pacemaker.yaml OS::TripleO::Services::Redis: ../../puppet/services/pacemaker/database/redis.yaml OS::TripleO::Services::MySQL: ../../puppet/services/pacemaker/database/mysql.yaml OS::TripleO::Services::CinderVolume: ../../puppet/services/pacemaker/cinder-volume.yaml OS::TripleO::Services::Keepalived: OS::Heat::None OS::TripleO::Tasks::ControllerPrePuppet: ../../extraconfig/tasks/pre_puppet_pacemaker.yaml OS::TripleO::Tasks::ControllerPostPuppet: ../../extraconfig/tasks/post_puppet_pacemaker.yaml OS::TripleO::Tasks::ControllerPostPuppetRestart: ../../extraconfig/tasks/post_puppet_pacemaker_restart.yaml,,55,8
openstack%2Fneutron~master~Ia30116fff8b834486bde93c329543fce15be429f,openstack/neutron,master,Ia30116fff8b834486bde93c329543fce15be429f,Adding a code coverage threshold,MERGED,2017-02-10 19:24:35.000000000,2017-02-27 23:02:40.000000000,2017-02-27 23:02:39.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8726}, {'_account_id': 9656}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-02-10 19:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ed2bb279f4ad5e78e1a914d0d64e66738ee34d88', 'message': 'Adding a code coverage threshold\n\nThe current implementation of the coverage code job gate only fails\nwhen the report is not created. This change pretends to set a\nminimum reasonable percentage of code coverage(85%).\n\nChange-Id: Ia30116fff8b834486bde93c329543fce15be429f\n'}, {'number': 2, 'created': '2017-02-10 21:02:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f3245ae1ba3b7df44121929b9f4d895824d028a', 'message': 'Adding a code coverage threshold\n\nThe current implementation of the coverage code job gate only fails\nwhen the report is not created. This change pretends to set a\nminimum reasonable percentage of code coverage(82%).\n\nChange-Id: Ia30116fff8b834486bde93c329543fce15be429f\n'}, {'number': 3, 'created': '2017-02-25 06:30:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/49bec33d45ab7cf82aaf6be1e4de1695ba1577ab', 'message': 'Adding a code coverage threshold\n\nThe current implementation of the coverage code job gate only fails\nwhen the report is not created. This change pretends to set a\nminimum reasonable percentage of code coverage(82%).\n\nChange-Id: Ia30116fff8b834486bde93c329543fce15be429f\n'}]",5,432432,49bec33d45ab7cf82aaf6be1e4de1695ba1577ab,45,13,3,8726,,,0,"Adding a code coverage threshold

The current implementation of the coverage code job gate only fails
when the report is not created. This change pretends to set a
minimum reasonable percentage of code coverage(82%).

Change-Id: Ia30116fff8b834486bde93c329543fce15be429f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/432432/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ed2bb279f4ad5e78e1a914d0d64e66738ee34d88,432432, coverage report --fail-under=85 --skip-covered, coverage report,1,1
openstack%2Fironic~master~If4fc6b53273d39c65db0251957795d214440118d,openstack/ironic,master,If4fc6b53273d39c65db0251957795d214440118d,devstack: Adding a README for ironic-bm-logs directory,MERGED,2017-01-30 23:09:08.000000000,2017-02-27 22:53:14.000000000,2017-02-27 22:53:14.000000000,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 10118}, {'_account_id': 11655}, {'_account_id': 11878}, {'_account_id': 13295}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 23310}]","[{'number': 1, 'created': '2017-01-30 23:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b4901bcd153d14422997aec72d923dbfbfcc692', 'message': 'WIP/DNM: Testing serial console logs\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 2, 'created': '2017-01-31 00:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/257ffae9a9da9473bd4779a7e0ef171d2a93e9c3', 'message': 'WIP/DNM: Testing serial console logs\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 3, 'created': '2017-01-31 01:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/91661ea7a8a4ee165b2bf890e009b6d9826d3d6a', 'message': 'WIP/DNM: Testing serial console logs\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 4, 'created': '2017-01-31 02:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8fc5e056cc4d9ec4d1ba6a30917cf3604f61b714', 'message': 'WIP/DNM: Testing serial console logs\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 5, 'created': '2017-01-31 03:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aaa319c4cf0289195000c91b4a7432003b582f14', 'message': 'WIP/DNM: Testing serial console logs\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 6, 'created': '2017-01-31 05:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4a8ed7ce48ef9bb133662309d93bc72ac566eeda', 'message': 'WIP/DNM: Adding a README for ironic-bm-logs directory\n\nAdding a README file to be put into the ironic-bm-logs/ directory that\nexplains the virtual bare-metal log files.\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}, {'number': 7, 'created': '2017-02-06 17:32:56.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0830f44660b91cf261e369417cfe6b07a65e88d', 'message': 'devstack: Adding a README for ironic-bm-logs directory\n\nAdding a README file to be put into the ironic-bm-logs/ directory that\nexplains the virtual bare-metal log files.\n\nChange-Id: If4fc6b53273d39c65db0251957795d214440118d\n'}]",0,426965,c0830f44660b91cf261e369417cfe6b07a65e88d,40,11,7,14760,,,0,"devstack: Adding a README for ironic-bm-logs directory

Adding a README file to be put into the ironic-bm-logs/ directory that
explains the virtual bare-metal log files.

Change-Id: If4fc6b53273d39c65db0251957795d214440118d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/426965/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,1b4901bcd153d14422997aec72d923dbfbfcc692,," cat ${IRONIC_VM_LOG_DIR}/README << EOF This directory contains the serial console log files from the virtual Ironic bare-metal nodes. The *_console_* log files are the original log files and include ANSI control codes which can make the output difficult to read. The *_no_ansi_* log files have had ANSI control codes removed from the file and are easier to read. On some occasions there won't be a corresponding *_no_ansi_* log file, for example if the job failed due to a time-out. You may see a log file without a date/time in the file name. In that case you can display the logfile in your console by doing: $ curl URL_TO_LOGFILE This will have your terminal process the ANSI escape codes. Another option if you have the 'pv' executable installed is to simulate a low-speed connection. In this example simulate a 300 bps connection. $ curl URL_TO_LOGFILE | pv -q -L 300 This can allow you to see some of the content before the screen is cleared. EOF",,22,0
openstack%2Fnetworking-ovn~master~Ia9e97837e6eb1a23435f2def74060032ce0e5409,openstack/networking-ovn,master,Ia9e97837e6eb1a23435f2def74060032ce0e5409,Clarify that native L3 is always used.,MERGED,2017-02-16 07:33:09.000000000,2017-02-27 22:53:05.000000000,2017-02-27 22:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-16 07:33:09.000000000', 'files': ['doc/source/install.rst', 'networking_ovn/common/config.py', 'devstack/local.conf.sample', 'devstack/override-defaults', 'devstack/devstackgatekuryrrc', 'devstack/plugin.sh', 'devstack/upgrade/upgrade.sh', 'devstack/lib/networking-ovn'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/92952f016562cb89d1fd0ac320baff0786850aff', 'message': 'Clarify that native L3 is always used.\n\nRemove all remaining remnants of L3 agent support.\n\nChange-Id: Ia9e97837e6eb1a23435f2def74060032ce0e5409\nCloses-bug: 1626717\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",2,434690,92952f016562cb89d1fd0ac320baff0786850aff,17,3,1,1561,,,0,"Clarify that native L3 is always used.

Remove all remaining remnants of L3 agent support.

Change-Id: Ia9e97837e6eb1a23435f2def74060032ce0e5409
Closes-bug: 1626717
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/90/434690/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install.rst', 'networking_ovn/common/config.py', 'devstack/local.conf.sample', 'devstack/override-defaults', 'devstack/devstackgatekuryrrc', 'devstack/lib/networking-ovn', 'devstack/plugin.sh', 'devstack/upgrade/upgrade.sh']",8,92952f016562cb89d1fd0ac320baff0786850aff,bug/1626717,,"# Use neutron l3 as there is a check in nova upgrade, which # verifies an instance can be reached with its floating ip even # after upgrade export OVN_L3_MODE=False",29,79
openstack%2Fproject-config~master~I70216409b7a73a2eea3b92b25250cf008811fd16,openstack/project-config,master,I70216409b7a73a2eea3b92b25250cf008811fd16,Add swift func test job to run on centos,MERGED,2017-02-21 20:01:33.000000000,2017-02-27 22:49:59.000000000,2017-02-27 22:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-02-21 20:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/55b98a02937a708d091c366a4478c3d3331f683a', 'message': 'WIP: Add swift func test job to run on centos\n\nTesting adding a job to run swift func tests on centos\n\nChange-Id: I70216409b7a73a2eea3b92b25250cf008811fd16\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 2, 'created': '2017-02-21 21:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f2e03b7fe87ad4014f3dc2afdbc9a595dd70553b', 'message': 'Add swift func test job to run on centos\n\nTesting adding a job to run swift func tests on centos\n\nChange-Id: I70216409b7a73a2eea3b92b25250cf008811fd16\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 3, 'created': '2017-02-22 16:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/56146665fd647b96ed0349eeb7de52609c2f234a', 'message': 'Add swift func test job to run on centos\n\nTesting adding a job to run swift func tests on centos\n\nChange-Id: I70216409b7a73a2eea3b92b25250cf008811fd16\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 4, 'created': '2017-02-27 17:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0a39e936c44496a71d92c2c50350686a0ece1f4f', 'message': 'Add swift func test job to run on centos\n\nTesting adding a job to run swift func tests on centos\n\nChange-Id: I70216409b7a73a2eea3b92b25250cf008811fd16\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}, {'number': 5, 'created': '2017-02-27 18:59:14.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b17091c7b194f584f3b188de8bb44ea7a8a6fd36', 'message': 'Add swift func test job to run on centos\n\nTesting adding a job to run swift func tests on centos\n\nChange-Id: I70216409b7a73a2eea3b92b25250cf008811fd16\nSigned-off-by: Thiago da Silva <thiago@redhat.com>\n'}]",3,436632,b17091c7b194f584f3b188de8bb44ea7a8a6fd36,17,3,5,9625,,,0,"Add swift func test job to run on centos

Testing adding a job to run swift func tests on centos

Change-Id: I70216409b7a73a2eea3b92b25250cf008811fd16
Signed-off-by: Thiago da Silva <thiago@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/32/436632/5 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,55b98a02937a708d091c366a4478c3d3331f683a,add_centos_swift, - gate-swift-tox-xfs-tmp-func-centos-7,,4,1
openstack%2Fproject-config~master~I08fe9a699ee0065672afad0af8b070efc3f633da,openstack/project-config,master,I08fe9a699ee0065672afad0af8b070efc3f633da,Fix senlin gate job,MERGED,2017-02-24 09:20:24.000000000,2017-02-27 22:48:08.000000000,2017-02-27 22:48:08.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-24 09:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f51ba8e7fc20af346d2cce8799c695951df88982', 'message': 'Fix senlin gate job\n\nSenlin gate job is broken for local configuration generated\nin pre_test_hook is not kept. This patch fixes this issue.\n\nChange-Id: I08fe9a699ee0065672afad0af8b070efc3f633da\n'}, {'number': 2, 'created': '2017-02-26 14:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3d09ede70bb9da9fbd9d6b2d457a5b6b3b86993e', 'message': 'Fix senlin gate job\n\nSenlin gate job is broken for local configuration generated\nin pre_test_hook is not kept. This patch fixes this issue.\n\nChange-Id: I08fe9a699ee0065672afad0af8b070efc3f633da\n'}, {'number': 3, 'created': '2017-02-27 14:28:35.000000000', 'files': ['jenkins/jobs/senlin.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cbdfae2c9dec3e7f475be98a64ef11e26ebc0bec', 'message': 'Fix senlin gate job\n\nSenlin gate job is broken for local configuration generated\nin pre_test_hook is not kept. This patch fixes this issue.\n\nChange-Id: I08fe9a699ee0065672afad0af8b070efc3f633da\n'}]",1,437851,cbdfae2c9dec3e7f475be98a64ef11e26ebc0bec,23,6,3,11034,,,0,"Fix senlin gate job

Senlin gate job is broken for local configuration generated
in pre_test_hook is not kept. This patch fixes this issue.

Change-Id: I08fe9a699ee0065672afad0af8b070efc3f633da
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/437851/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/senlin.yaml'],1,f51ba8e7fc20af346d2cce8799c695951df88982,fix-senlin-gate-job, export KEEP_LOCALRC=1,,1,0
openstack%2Fdesignate-tempest-plugin~master~I97b95b3961a9d66059ee142b3c1ba7707c2f4da2,openstack/designate-tempest-plugin,master,I97b95b3961a9d66059ee142b3c1ba7707c2f4da2,Bump test timeout,MERGED,2017-02-24 17:16:08.000000000,2017-02-27 22:40:00.000000000,2017-02-27 22:40:00.000000000,"[{'_account_id': 3}, {'_account_id': 8099}]","[{'number': 1, 'created': '2017-02-24 17:16:08.000000000', 'files': ['designate_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/12bd71d27ea37a7d8625bc13f5bdd26c23be3119', 'message': ""Bump test timeout\n\nWe're working through some Mitaka gate issues, this should\nhelp temporarily\n\nChange-Id: I97b95b3961a9d66059ee142b3c1ba7707c2f4da2\n""}]",0,438011,12bd71d27ea37a7d8625bc13f5bdd26c23be3119,12,2,1,8174,,,0,"Bump test timeout

We're working through some Mitaka gate issues, this should
help temporarily

Change-Id: I97b95b3961a9d66059ee142b3c1ba7707c2f4da2
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/11/438011/1 && git format-patch -1 --stdout FETCH_HEAD,['designate_tempest_plugin/config.py'],1,12bd71d27ea37a7d8625bc13f5bdd26c23be3119,bump-timeout," default=360,"," default=240,",1,1
openstack%2Ftripleo-common~master~I198a33c8608648c7abcafc2cfb1aefb0fb8417e6,openstack/tripleo-common,master,I198a33c8608648c7abcafc2cfb1aefb0fb8417e6,Fix wrong args to update manager,MERGED,2017-02-27 16:27:29.000000000,2017-02-27 22:33:54.000000000,2017-02-27 21:01:23.000000000,"[{'_account_id': 3}, {'_account_id': 8532}, {'_account_id': 9712}]","[{'number': 1, 'created': '2017-02-27 16:27:29.000000000', 'files': ['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d2ee6d070e755cb77ec8fcddeec56bc97df10b3d', 'message': 'Fix wrong args to update manager\n\nThe abort update and clear breakpoints actions were using the wrong\nnumber of arguments to the update manager. This fixes that, and adds\nto the unit tests to detect the problem.\n\nChange-Id: I198a33c8608648c7abcafc2cfb1aefb0fb8417e6\nCloses-Bug: #1668269\n'}]",0,438583,d2ee6d070e755cb77ec8fcddeec56bc97df10b3d,9,3,1,7065,,,0,"Fix wrong args to update manager

The abort update and clear breakpoints actions were using the wrong
number of arguments to the update manager. This fixes that, and adds
to the unit tests to detect the problem.

Change-Id: I198a33c8608648c7abcafc2cfb1aefb0fb8417e6
Closes-Bug: #1668269
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/83/438583/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/package_update.py', 'tripleo_common/tests/actions/test_package_update.py']",2,d2ee6d070e755cb77ec8fcddeec56bc97df10b3d,bug/1668269," mock_update_manager.assert_called_once_with( mock_orchestration_client(), mock_compute_client(), self.stack_id, stack_fields={}) mock_update_manager.assert_called_once_with( mock_orchestration_client(), mock_compute_client(), self.stack_id, stack_fields={})",,14,2
openstack%2Foctavia~master~Iecf80d239ab0b9590cbb53fba9a4799c530eeb7d,openstack/octavia,master,Iecf80d239ab0b9590cbb53fba9a4799c530eeb7d,WIP: fix gate-neutron-lbaasv2-dsvm-api-ubuntu-xenial,ABANDONED,2017-02-27 14:02:13.000000000,2017-02-27 22:30:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6579}, {'_account_id': 11628}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-27 14:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/64813d6a205ef8dc48e173233007dfebd95f11c3', 'message': 'WIP: fix gate-neutron-lbaasv2-dsvm-api-ubuntu-xenial\n\nChange-Id: Iecf80d239ab0b9590cbb53fba9a4799c530eeb7d\nRelated-Bug: #1668194\n'}, {'number': 2, 'created': '2017-02-27 14:02:57.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/ef0663415c38f62efd5ca10fc85e3352a98c2847', 'message': 'WIP: fix gate-neutron-lbaasv2-dsvm-api-ubuntu-xenial\n\nChange-Id: Iecf80d239ab0b9590cbb53fba9a4799c530eeb7d\nRelated-Bug: #1668194\n'}]",0,438497,ef0663415c38f62efd5ca10fc85e3352a98c2847,8,4,2,6579,,,0,"WIP: fix gate-neutron-lbaasv2-dsvm-api-ubuntu-xenial

Change-Id: Iecf80d239ab0b9590cbb53fba9a4799c530eeb7d
Related-Bug: #1668194
",git fetch https://review.opendev.org/openstack/octavia refs/changes/97/438497/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,64813d6a205ef8dc48e173233007dfebd95f11c3,bug/1668194, $OCTAVIA_DIR/diskimage-create/diskimage-create.sh $octavia_dib_tracing_arg -s 2 -o $OCTAVIA_AMP_IMAGE_FILE, $OCTAVIA_DIR/diskimage-create/diskimage-create.sh $octavia_dib_tracing_arg -s 2 -o $OCTAVIA_AMP_IMAGE_FILE fi,1,2
openstack%2Fneutron-lbaas~master~Ia134c39277f30d1183c7585b09328037ded147f8,openstack/neutron-lbaas,master,Ia134c39277f30d1183c7585b09328037ded147f8,Work around devstack selecting incorrect image,MERGED,2017-02-27 20:29:18.000000000,2017-02-27 22:25:12.000000000,2017-02-27 22:25:12.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10273}, {'_account_id': 10850}]","[{'number': 1, 'created': '2017-02-27 20:29:18.000000000', 'files': ['neutron_lbaas/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/63f9d96f9814c5e3a7a01a6c52bdd8b72f9150bd', 'message': 'Work around devstack selecting incorrect image\n\nCurrently devstack is selecting the amphora image instead of the\ncirros image to boot our test webservers.  This is a temporary fix\nto get our gates functional again.  This will be removed when we can\ncome up with a better solution or devstack merges their fix [1].\n\n[1] https://review.openstack.org/#/c/435106\n\nChange-Id: Ia134c39277f30d1183c7585b09328037ded147f8\n'}]",0,438692,63f9d96f9814c5e3a7a01a6c52bdd8b72f9150bd,8,4,1,11628,,,0,"Work around devstack selecting incorrect image

Currently devstack is selecting the amphora image instead of the
cirros image to boot our test webservers.  This is a temporary fix
to get our gates functional again.  This will be removed when we can
come up with a better solution or devstack merges their fix [1].

[1] https://review.openstack.org/#/c/435106

Change-Id: Ia134c39277f30d1183c7585b09328037ded147f8
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/92/438692/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/contrib/gate_hook.sh'],1,63f9d96f9814c5e3a7a01a6c52bdd8b72f9150bd,devstack-default-image,"# Work around a devstack issue:https://review.openstack.org/#/c/435106 export DEVSTACK_LOCAL_CONFIG+="" DEFAULT_IMAGE_NAME=cirros-0.3.5-x86_64-disk "" ",,5,0
openstack%2Fpuppet-keystone~master~I65b64f7ef7bb825bdf2e3f1bbe7c13357ae1fe3e,openstack/puppet-keystone,master,I65b64f7ef7bb825bdf2e3f1bbe7c13357ae1fe3e,CI test,ABANDONED,2017-02-27 18:20:49.000000000,2017-02-27 22:12:07.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2017-02-27 18:20:49.000000000', 'files': ['spec/classes/keystone_federation_shibboleth_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/f0be3b4978d5802db85a65a97579ef3bcd1215c8', 'message': 'CI test\n\nChange-Id: I65b64f7ef7bb825bdf2e3f1bbe7c13357ae1fe3e\n'}]",0,438666,f0be3b4978d5802db85a65a97579ef3bcd1215c8,4,2,1,14985,,,0,"CI test

Change-Id: I65b64f7ef7bb825bdf2e3f1bbe7c13357ae1fe3e
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/66/438666/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/keystone_federation_shibboleth_spec.rb'],1,f0be3b4978d5802db85a65a97579ef3bcd1215c8,bug/1667866," context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts({ :concat_basedir => '/var/lib/puppet/concat' })) end it_behaves_like 'Federation Shibboleth' end", let (:facts) do facts.merge!(OSDefaults.get_facts({})) end it_behaves_like 'Federation Shibboleth',8,4
openstack%2Fceilometer~master~I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1,openstack/ceilometer,master,I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1,Use bytes for coordination member,MERGED,2017-02-22 21:50:39.000000000,2017-02-27 22:03:26.000000000,2017-02-27 22:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7385}, {'_account_id': 15843}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-22 21:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1878d4e06d26d508a4616cca406fac8f16b4703e', 'message': 'Use bytes for coordination member\n\nIt seems that we need bytes for building a member ID.\n\nChange-Id: I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1\n'}, {'number': 2, 'created': '2017-02-24 19:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dc14cc8a5bab159962434cbd6982c47d3fe5ab62', 'message': 'Use bytes for coordination member\n\nIt seems that we need bytes for building a member ID.\n\nCloses-Bug: #1667117\nChange-Id: I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1\n'}, {'number': 3, 'created': '2017-02-27 08:46:31.000000000', 'files': ['ceilometer/coordination.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04eaee64fb5e60d6d593ed15b100dbeee55d3d83', 'message': 'Use bytes for coordination member\n\nIt seems that we need bytes for building a member ID.\n\nCloses-Bug: #1667117\nChange-Id: I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1\n'}]",1,437163,04eaee64fb5e60d6d593ed15b100dbeee55d3d83,34,7,3,7385,,,0,"Use bytes for coordination member

It seems that we need bytes for building a member ID.

Closes-Bug: #1667117
Change-Id: I87bb6ebf03ce4d04776743fd1a25e67b8c8026a1
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/63/437163/3 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/coordination.py'],1,1878d4e06d26d508a4616cca406fac8f16b4703e,bug/1667117, self._my_id = my_id or str(uuid.uuid4()).encode('ascii'), self._my_id = my_id or str(uuid.uuid4()),1,1
openstack%2Fkeystone~master~Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc,openstack/keystone,master,Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc,Correct and enhance OpenId Connect docs,MERGED,2017-02-24 20:37:25.000000000,2017-02-27 22:00:41.000000000,2017-02-27 22:00:40.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-02-24 20:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/486ae573d0a77bb1024cbbf309b9be25b686e367', 'message': 'Correct and enhance OpenId Connect docs\n\nMake corrections and clarifications to the OpenID Connect federation\nplugin documentation, including:\n\n - Generalize the note about Remote IDs to include OpenID Connect\n - Add the https:// scheme to the notes about Google\'s remote ID.\n   Originally Google\'s Issuer Identifier did not use the https://\n   scheme. It now claims to allow both[1] but in testing I often ran\n   into the error ""Could not find Identity Provider:\n   https://accounts.google.com."" when the remote-id was given as\n   ""accounts.google.com"".\n - Make shell examples consistent with each other by including prompt\n   symbols and ""sudo"" where needed\n - Fix the apache module configuration instructions: on Ubuntu, the\n   package installed in the earlier step already adds the LoadModule\n   config, but does not automatically enable the module\n - Fix OIDCRedirectURI directive examples: fix typo and remove /redirect\n   ending, which would cause a 404 error\n\nAlso, this patch changes references to the \'oidc\' plugin to \'openid\'\nsince \'oidc\' does not exist. \'mapped\' could also be used as the name of\nthis plugin and protocol[2]. However, the documentation is structured in\na such a way that it demonstrates using both SAML And OIDC plugins side\nby side, which is only possible when they have different names. Rather\nthan trying to decouple these examples this patch opts to keep the\nopenid plugin examples distinct from the SAML plugin examples.\n\n[1] https://developers.google.com/identity/protocols/OpenIDConnect\n[2] https://git.openstack.org/cgit/openstack/keystone-specs/tree/specs/keystone/juno/generic-mapping-federation.rst\n\nChange-Id: Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc\n'}, {'number': 2, 'created': '2017-02-24 20:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1c38330c65ab55ece1fc31faa7800046c2a5343f', 'message': 'Correct and enhance OpenId Connect docs\n\nMake corrections and clarifications to the OpenID Connect federation\nplugin documentation, including:\n\n - Generalize the note about Remote IDs to include OpenID Connect\n - Add the https:// scheme to the notes about Google\'s remote ID.\n   Originally Google\'s Issuer Identifier did not use the https://\n   scheme. It now claims to allow both[1] but in testing I often ran\n   into the error ""Could not find Identity Provider:\n   https://accounts.google.com."" when the remote-id was given as\n   ""accounts.google.com"".\n - Make shell examples consistent with each other by including prompt\n   symbols and ""sudo"" where needed\n - Fix the apache module configuration instructions: on Ubuntu, the\n   package installed in the earlier step already adds the LoadModule\n   config, but does not automatically enable the module\n - Fix OIDCRedirectURI directive examples: fix typo and remove /redirect\n   ending, which would cause a 404 error\n\nAlso, this patch changes references to the \'oidc\' plugin to \'openid\'\nsince \'oidc\' does not exist. \'mapped\' could also be used as the name of\nthis plugin and protocol[2]. However, the documentation is structured in\na such a way that it demonstrates using both SAML And OIDC plugins side\nby side, which is only possible when they have different names. Rather\nthan trying to decouple these examples this patch opts to keep the\nopenid plugin examples distinct from the SAML plugin examples.\n\n[1] https://developers.google.com/identity/protocols/OpenIDConnect\n[2] https://git.openstack.org/cgit/openstack/keystone-specs/tree/specs/keystone/juno/generic-mapping-federation.rst\n\nChange-Id: Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc\n'}, {'number': 3, 'created': '2017-02-25 10:48:22.000000000', 'files': ['doc/source/federation/websso.rst', 'doc/source/federation/configure_federation.rst', 'doc/source/federation/openidc.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f4e31e4f4abdca194700fedb643b334c14f3b73', 'message': 'Correct and enhance OpenId Connect docs\n\nMake corrections and clarifications to the OpenID Connect federation\nplugin documentation, including:\n\n - Generalize the note about Remote IDs to include OpenID Connect\n - Add the https:// scheme to the notes about Google\'s remote ID.\n   Originally Google\'s Issuer Identifier did not use the https://\n   scheme. It now claims to allow both[1] but in testing I often ran\n   into the error ""Could not find Identity Provider:\n   https://accounts.google.com."" when the remote-id was given as\n   ""accounts.google.com"".\n - Make shell examples consistent with each other by including prompt\n   symbols and ""sudo"" where needed\n - Fix the apache module configuration instructions: on Ubuntu, the\n   package installed in the earlier step already adds the LoadModule\n   config, but does not automatically enable the module\n - Fix OIDCRedirectURI directive examples: fix typo and remove /redirect\n   ending, which would cause a 404 error\n\nAlso, this patch changes references to the \'oidc\' plugin to \'openid\'\nsince \'oidc\' does not exist. \'mapped\' could also be used as the name of\nthis plugin and protocol[2]. However, the documentation is structured in\na such a way that it demonstrates using both SAML And OIDC plugins side\nby side, which is only possible when they have different names. Rather\nthan trying to decouple these examples this patch opts to keep the\nopenid plugin examples distinct from the SAML plugin examples.\n\n[1] https://developers.google.com/identity/protocols/OpenIDConnect\n[2] https://git.openstack.org/cgit/openstack/keystone-specs/tree/specs/keystone/juno/generic-mapping-federation.rst\n\nChange-Id: Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc\n'}]",2,438069,6f4e31e4f4abdca194700fedb643b334c14f3b73,13,4,3,8482,,,0,"Correct and enhance OpenId Connect docs

Make corrections and clarifications to the OpenID Connect federation
plugin documentation, including:

 - Generalize the note about Remote IDs to include OpenID Connect
 - Add the https:// scheme to the notes about Google's remote ID.
   Originally Google's Issuer Identifier did not use the https://
   scheme. It now claims to allow both[1] but in testing I often ran
   into the error ""Could not find Identity Provider:
   https://accounts.google.com."" when the remote-id was given as
   ""accounts.google.com"".
 - Make shell examples consistent with each other by including prompt
   symbols and ""sudo"" where needed
 - Fix the apache module configuration instructions: on Ubuntu, the
   package installed in the earlier step already adds the LoadModule
   config, but does not automatically enable the module
 - Fix OIDCRedirectURI directive examples: fix typo and remove /redirect
   ending, which would cause a 404 error

Also, this patch changes references to the 'oidc' plugin to 'openid'
since 'oidc' does not exist. 'mapped' could also be used as the name of
this plugin and protocol[2]. However, the documentation is structured in
a such a way that it demonstrates using both SAML And OIDC plugins side
by side, which is only possible when they have different names. Rather
than trying to decouple these examples this patch opts to keep the
openid plugin examples distinct from the SAML plugin examples.

[1] https://developers.google.com/identity/protocols/OpenIDConnect
[2] https://git.openstack.org/cgit/openstack/keystone-specs/tree/specs/keystone/juno/generic-mapping-federation.rst

Change-Id: Ie5a07f9d6f3571b0559f91c9620f5328e4c6d7cc
",git fetch https://review.opendev.org/openstack/keystone refs/changes/69/438069/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/federation/websso.rst', 'doc/source/federation/configure_federation.rst', 'doc/source/federation/openidc.rst']",3,486ae573d0a77bb1024cbbf309b9be25b686e367,federation_docs," $ sudo apt-get install libapache2-mod-auth-openidcEnable the auth_openidc module: .. code-blocK:: bash $ sudo a2enmod auth_openidc In the keystone vhost file, locate the virtual host entry and add the following OIDCRedirectURI http://localhost:5000/v3/OS-FEDERATION/identity_providers/<idp_id>/protocols/openid/auth <LocationMatch /v3/OS-FEDERATION/identity_providers/.*?/protocols/openid/auth> $ sudo service apache2 restart1. When creating a `mapping`_, note that the 'remote' attributes will be prefixed,2. Don't forget to add openid as an [auth] plugin in keystone.conf, see.. _`mapping`: configure_federation.html#mapping"," sudo apt-get install libapache2-mod-auth-openidcIn the keystone Apache site file, add the following as a top level option, to load the `mod_auth_openidc` module: .. code-block:: xml LoadModule auth_openidc_module /usr/lib/apache2/modules/mod_auth_openidc.so Also within the same file, locate the virtual host entry and add the following OIDCRedirectURI http://localhost:5000/v3/OS-FEDERATION/identity_providers/<idp_id>/protocols/oidc/auth/redirect <LocationMatch /v3/OS-FEDERATION/identity_providers/.*?/protocols/oidc/auth> $ service apache2 restart1. When creating a mapping, note that the 'remote' attributes will be prefixed,2. Don't forget to add oidc as an [auth] plugin in keystone.conf, see",30,30
openstack%2Fkeystone~master~I47255db5e762bd2d2901b78afba2b1efa0c0f224,openstack/keystone,master,I47255db5e762bd2d2901b78afba2b1efa0c0f224,Correct and enhance Mellon federation docs,MERGED,2017-02-23 15:17:22.000000000,2017-02-27 22:00:34.000000000,2017-02-27 22:00:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 8119}, {'_account_id': 8482}, {'_account_id': 16465}, {'_account_id': 17860}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-02-23 15:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ed9dc6f53bf36d423e17e0fdebf9feb3d2b7eb57', 'message': 'Correct and enhance Mellon federation docs\n\nMake corrections to the mod_auth_mellon federation documentation for\nconsistency and clarity, including:\n\n - Remove reference to shibboleth.xml when explaining the remote-id\n   attribute in the main federation configuration instructions, as this\n   does not generalize to all IdPs\n - Change references from /etc/httpd to /etc/apache2 because the\n   document begins with an apt-get so it follows that the rest of the\n   examples should assume a Debian-like environment\n - Change references to example IdP \'idp_1\' to \'myidp\' for consistency\n   with the shibboleth examples\n - Change references to example protocol \'saml2\' to \'mapped\' since the\n   saml2 auth plugin was removed[1]\n - Remove references to wsgi-keystone.conf since devstack just calls it\n   keystone.conf, and enabling this vhost is already covered in the\n   ""Running Keystone in HTTPD"" section\n - Remove reference to the ssl mod: it\'s obviously recommended but not\n   strictly relevant to this topic\n - Remove instruction to restart apache immediately after enabling\n   auth_mellon, as it would fail while Mellon is not yet fully\n   configured. The document already mentions restarting apache after\n   Mellon is configured.\n - Add a link to the mellon_create_metadata.sh script, since this does not\n   come as an executable with the mod package.\n - Add tip about the SP metadata file generated by mod_auth_mellon\n - Move paragraph about fetching the IdP metadata to the end of the\n   section so that the information about generating and uploading the\n   SP metadata is grouped together\n\n[1] https://review.openstack.org/#/c/374508/\n\nChange-Id: I47255db5e762bd2d2901b78afba2b1efa0c0f224\n'}, {'number': 2, 'created': '2017-02-23 16:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c0a7eea4270606d9e665cbea8a4a523671710c40', 'message': 'Correct and enhance Mellon federation docs\n\nMake corrections to the mod_auth_mellon federation documentation for\nconsistency and clarity, including:\n\n - Remove reference to shibboleth.xml when explaining the remote-id\n   attribute in the main federation configuration instructions, as this\n   does not generalize to all IdPs\n - Change references from /etc/httpd to /etc/apache2 because the\n   document begins with an apt-get so it follows that the rest of the\n   examples should assume a Debian-like environment\n - Change references to example IdP \'idp_1\' to \'myidp\' for consistency\n   with the shibboleth examples\n - Change references to example protocol \'saml2\' to \'mapped\' since the\n   saml2 auth plugin was removed[1]\n - Remove references to wsgi-keystone.conf since devstack just calls it\n   keystone.conf, and enabling this vhost is already covered in the\n   ""Running Keystone in HTTPD"" section\n - Remove reference to the ssl mod: it\'s obviously recommended but not\n   strictly relevant to this topic\n - Remove instruction to restart apache immediately after enabling\n   auth_mellon, as it would fail while Mellon is not yet fully\n   configured. The document already mentions restarting apache after\n   Mellon is configured.\n - Add a link to the mellon_create_metadata.sh script, since this does not\n   come as an executable with the mod package.\n - Add tip about the SP metadata file generated by mod_auth_mellon\n - Move paragraph about fetching the IdP metadata to the end of the\n   section so that the information about generating and uploading the\n   SP metadata is grouped together\n\n[1] https://review.openstack.org/#/c/374508/\n\nChange-Id: I47255db5e762bd2d2901b78afba2b1efa0c0f224\n'}, {'number': 3, 'created': '2017-02-24 08:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3ecdffa811c21dc025c9200f7a23e924306b91c1', 'message': 'Correct and enhance Mellon federation docs\n\nMake corrections to the mod_auth_mellon federation documentation for\nconsistency and clarity, including:\n\n - Remove reference to shibboleth.xml when explaining the remote-id\n   attribute in the main federation configuration instructions, as this\n   does not generalize to all IdPs\n - Change references from /etc/httpd to /etc/apache2 because the\n   document begins with an apt-get so it follows that the rest of the\n   examples should assume a Debian-like environment\n - Change references to example IdP \'idp_1\' to \'myidp\' for consistency\n   with the shibboleth examples\n - Change references to example protocol \'saml2\' to \'mapped\' since the\n   saml2 auth plugin was removed[1]\n - Remove references to wsgi-keystone.conf since devstack just calls it\n   keystone.conf, and enabling this vhost is already covered in the\n   ""Running Keystone in HTTPD"" section\n - Remove reference to the ssl mod: it\'s obviously recommended but not\n   strictly relevant to this topic\n - Remove instruction to restart apache immediately after enabling\n   auth_mellon, as it would fail while Mellon is not yet fully\n   configured. The document already mentions restarting apache after\n   Mellon is configured.\n - Add a link to the mellon_create_metadata.sh script, since this does not\n   come as an executable with the mod package.\n - Add tip about the SP metadata file generated by mod_auth_mellon\n - Move paragraph about fetching the IdP metadata to the end of the\n   section so that the information about generating and uploading the\n   SP metadata is grouped together\n\n[1] https://review.openstack.org/#/c/374508/\n\nChange-Id: I47255db5e762bd2d2901b78afba2b1efa0c0f224\n'}, {'number': 4, 'created': '2017-02-24 20:37:25.000000000', 'files': ['doc/source/federation/configure_federation.rst', 'doc/source/federation/mellon.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/95afd48fde81aa0d279e86c08512a23e1a91536a', 'message': 'Correct and enhance Mellon federation docs\n\nMake corrections to the mod_auth_mellon federation documentation for\nconsistency and clarity, including:\n\n - Remove reference to shibboleth.xml when explaining the remote-id\n   attribute in the main federation configuration instructions, as this\n   does not generalize to all IdPs\n - Change references from /etc/httpd to /etc/apache2 because the\n   document begins with an apt-get so it follows that the rest of the\n   examples should assume a Debian-like environment\n - Change references to example IdP \'idp_1\' to \'myidp\' for consistency\n   with the shibboleth examples\n - Change references to example protocol \'saml2\' to \'mapped\' since the\n   saml2 auth plugin was removed[1]\n - Remove references to wsgi-keystone.conf since devstack just calls it\n   keystone.conf, and enabling this vhost is already covered in the\n   ""Running Keystone in HTTPD"" section\n - Remove reference to the ssl mod: it\'s obviously recommended but not\n   strictly relevant to this topic\n - Remove instruction to restart apache immediately after enabling\n   auth_mellon, as it would fail while Mellon is not yet fully\n   configured. The document already mentions restarting apache after\n   Mellon is configured.\n - Add a link to the mellon_create_metadata.sh script, since this does not\n   come as an executable with the mod package.\n - Add tip about the SP metadata file generated by mod_auth_mellon\n - Move paragraph about fetching the IdP metadata to the end of the\n   section so that the information about generating and uploading the\n   SP metadata is grouped together\n\n[1] https://review.openstack.org/#/c/374508/\n\nChange-Id: I47255db5e762bd2d2901b78afba2b1efa0c0f224\n'}]",15,437422,95afd48fde81aa0d279e86c08512a23e1a91536a,24,8,4,8482,,,0,"Correct and enhance Mellon federation docs

Make corrections to the mod_auth_mellon federation documentation for
consistency and clarity, including:

 - Remove reference to shibboleth.xml when explaining the remote-id
   attribute in the main federation configuration instructions, as this
   does not generalize to all IdPs
 - Change references from /etc/httpd to /etc/apache2 because the
   document begins with an apt-get so it follows that the rest of the
   examples should assume a Debian-like environment
 - Change references to example IdP 'idp_1' to 'myidp' for consistency
   with the shibboleth examples
 - Change references to example protocol 'saml2' to 'mapped' since the
   saml2 auth plugin was removed[1]
 - Remove references to wsgi-keystone.conf since devstack just calls it
   keystone.conf, and enabling this vhost is already covered in the
   ""Running Keystone in HTTPD"" section
 - Remove reference to the ssl mod: it's obviously recommended but not
   strictly relevant to this topic
 - Remove instruction to restart apache immediately after enabling
   auth_mellon, as it would fail while Mellon is not yet fully
   configured. The document already mentions restarting apache after
   Mellon is configured.
 - Add a link to the mellon_create_metadata.sh script, since this does not
   come as an executable with the mod package.
 - Add tip about the SP metadata file generated by mod_auth_mellon
 - Move paragraph about fetching the IdP metadata to the end of the
   section so that the information about generating and uploading the
   SP metadata is grouped together

[1] https://review.openstack.org/#/c/374508/

Change-Id: I47255db5e762bd2d2901b78afba2b1efa0c0f224
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/437422/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/federation/configure_federation.rst', 'doc/source/federation/mellon.rst']",2,ed9dc6f53bf36d423e17e0fdebf9feb3d2b7eb57,federation_docs," MellonSPPrivateKeyFile /etc/apache2/mellon/http_keystone.fqdn.key MellonSPCertFile /etc/apache2/mellon/http_keystone.fqdn.cert MellonSPMetadataFile /etc/apache2/mellon/http_keystone.fqdn.xml MellonIdPMetadataFile /etc/apache2/mellon/idp-metadata.xml MellonEndpointPath /v3/OS-FEDERATION/identity_providers/myidp/protocols/mapped/auth/mellon <Location /v3/OS-FEDERATION/identity_providers/myidp/protocols/mapped/auth> * ``mapped`` is the name of the `protocol that you will configure <configure_federation.html#protocol>`_ * ``myidp`` is the name associated with the `IdP in Keystone <configure_federation.html#identity_provider>`_Enable the ``auth_mellon`` module, for example:Mellon provides a script called `mellon_create_metadata.sh`_ which generates the values for the config directives `MellonSPPrivateKeyFile`, `MellonSPCertFile`, and `MellonSPMetadataFile`. It is run like this: $ ./mellon_create_metadata.sh http://keystone.fqdn:5000 \ http://keystone.fqdn:5000/v3/OS-FEDERATION/identity_providers/myidp/protocols/mapped/auth/mellonendpoint path corresponding to the parameter `MellonEndpointPath`. Note that the metadata generated by this script includes a signing key but not an encryption key, and your IdP (such as testshib.org) may require an encryption key. Simply change the node `<KeyDescriptor use=""signing"">` to `<KeyDescriptor use=""encryption"">` or add another key to the file. Check your IdP documentation for details. After generating the keypair and metadata, copy the files to the locations given in the Mellon directives in your apache configs. Upload the Service Provider's Metadata file which you just generated to your Identity Provider. This is the file used as the value of the `MellonSPMetadataFile` in the config. The IdP may provide a webpage where you can upload the file, or you may be required to submit the file using `wget` or `curl`. Please check your IdP documentation for details. Fetch your Identity Provider's Metadata file and copy it to the path specified by the `MellonIdPMetadataFile` directive above. For example: $ wget --cacert /path/to/ca.crt -O /etc/apache2/mellon/idp-metadata.xml \ .. _`mellon_create_metadata.sh`: https://github.com/UNINETT/mod_auth_mellon/blob/master/mellon_create_metadata.sh"," MellonSPPrivateKeyFile /etc/httpd/mellon/http_keystone.fqdn.key MellonSPCertFile /etc/httpd/mellon/http_keystone.fqdn.cert MellonSPMetadataFile /etc/httpd/mellon/http_keystone.fqdn.xml MellonIdPMetadataFile /etc/httpd/mellon/idp-metadata.xml MellonEndpointPath /v3/OS-FEDERATION/identity_providers/idp_1/protocols/saml2/auth/mellon <Location /v3/OS-FEDERATION/identity_providers/idp_1/protocols/saml2/auth> * ``saml2`` may be different in your deployment, but do not use a wildcard value. Otherwise *every* federated protocol will be handled by Mellon. * ``idp_1`` has to be replaced with the name associated with the IdP in Keystone... code-block:: bash $ a2ensite wsgi-keystone.conf Enable the ``ssl`` and ``auth_mellon`` modules, for example: $ a2enmod sslRestart the Apache instance that is serving Keystone, for example: .. code-block:: bash $ service apache2 restart Mellon provides a script called ``mellon_create_metadata.sh`` which generates the values for the config directives `MellonSPPrivateKeyFile`, `MellonSPCertFile`, and `MellonSPMetadataFile`. It is run like this: $ mellon_create_metadata.sh http://keystone.fqdn:5000 \ http://keystone.fqdn:5000/v3/OS-FEDERATION/identity_providers/idp_1/protocols/saml2/auth/mellonendpoint path corresponding to the parameter `MellonEndpointPath`. Fetch your Service Provider's Metadata file. This corresponds to the value of the `MellonIdPMetadataFile` directive above. For example: $ wget --cacert /path/to/ca.crt -O /etc/httpd/mellon/idp-metadata.xml \Upload your Service Provider's Metadata file to your Identity Provider. This is the file used as the value of the `MellonSPMetadataFile` in the config, generated by the `mellon_create_metadata.sh` script. The IdP may provide a webpage where you can upload the file, or you may be required to submit the file using `wget` or `curl`. Please check your IdP documentation for details. ",41,44
openstack%2Fkeystone~master~I4acb0d52258f2abdd6cca67c32a0bd474f3619e0,openstack/keystone,master,I4acb0d52258f2abdd6cca67c32a0bd474f3619e0,Updated from global requirements,MERGED,2017-02-27 10:56:13.000000000,2017-02-27 21:59:50.000000000,2017-02-27 21:59:50.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-27 10:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8f510722f892c472b3b819fc6ef3e1fa6299623c', 'message': 'Updated from global requirements\n\nChange-Id: I4acb0d52258f2abdd6cca67c32a0bd474f3619e0\n'}, {'number': 2, 'created': '2017-02-27 18:09:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/31f9eccdeb9a872f37a68c3547c17ce5f966d847', 'message': 'Updated from global requirements\n\nChange-Id: I4acb0d52258f2abdd6cca67c32a0bd474f3619e0\n'}]",0,438431,31f9eccdeb9a872f37a68c3547c17ce5f966d847,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: I4acb0d52258f2abdd6cca67c32a0bd474f3619e0
",git fetch https://review.opendev.org/openstack/keystone refs/changes/31/438431/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8f510722f892c472b3b819fc6ef3e1fa6299623c,openstack/requirements,cryptography>=1.6 # BSD/Apache-2.0,"cryptography!=1.3.0,>=1.0 # BSD/Apache-2.0",1,1
openstack%2Fneutron~stable%2Fmitaka~Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb,openstack/neutron,stable/mitaka,Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb,"Avoid KeyError when accessing ""dns_name"" as it may not exist",MERGED,2016-07-25 17:32:23.000000000,2017-02-27 21:58:08.000000000,2017-02-27 21:58:08.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4694}, {'_account_id': 7787}, {'_account_id': 8726}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 14611}, {'_account_id': 16376}, {'_account_id': 19303}, {'_account_id': 20330}]","[{'number': 1, 'created': '2016-07-25 17:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c2b2d2a44e52c154968d3e33d10bb9c9ebe6227', 'message': 'Avoid KeyError when accessing ""dns_name"" as it may not exist\n\nNeutron LBaaS does not pass a full copy of the request_data\ninto this function, and causes the port create to fail\nwith a KeyError\n\nChange-Id: Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb\nFixes-Bug: #1605336\n'}, {'number': 7, 'created': '2017-02-15 18:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c474fd76efcfc5e8d54ed4be18f0c7096fe9c50b', 'message': 'Avoid KeyError when accessing ""dns_name"" as it may not exist\n\nNeutron LBaaS does not pass a full copy of the request_data\ninto this function, and causes the port create to fail\nwith a KeyError\n\nChange-Id: Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb\nFixes-Bug: #1605336\n'}, {'number': 8, 'created': '2017-02-15 18:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2498464c5cae234f2a9a993d7a07d7d42092921e', 'message': 'Avoid KeyError when accessing ""dns_name"" as it may not exist\n\nNeutron LBaaS does not pass a full copy of the request_data\ninto this function, and causes the port create to fail\nwith a KeyError\n\nChange-Id: Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb\nFixes-Bug: #1605336\n(cherry picked from commit 625fdb423e289ee98dbfbd4c81edf64b598cb352)\n'}, {'number': 9, 'created': '2017-02-16 19:13:19.000000000', 'files': ['neutron/tests/unit/plugins/ml2/extensions/test_dns_integration.py', 'neutron/plugins/ml2/extensions/dns_integration.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0778fe801331284b5b43d1e7c79ac6a9b0c1cce', 'message': 'Avoid KeyError when accessing ""dns_name"" as it may not exist\n\nNeutron LBaaS does not pass a full copy of the request_data\ninto this function, and causes the port create to fail\nwith a KeyError\n\nChange-Id: Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb\nFixes-Bug: #1605336\n(cherry picked from commit 625fdb423e289ee98dbfbd4c81edf64b598cb352)\n'}]",2,346961,b0778fe801331284b5b43d1e7c79ac6a9b0c1cce,39,13,4,8099,,,0,"Avoid KeyError when accessing ""dns_name"" as it may not exist

Neutron LBaaS does not pass a full copy of the request_data
into this function, and causes the port create to fail
with a KeyError

Change-Id: Ib81cbbaf24a4ffaa983e1b05146aea0dc74e29bb
Fixes-Bug: #1605336
(cherry picked from commit 625fdb423e289ee98dbfbd4c81edf64b598cb352)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/346961/7 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/extensions/dns_integration.py'],1,5c2b2d2a44e52c154968d3e33d10bb9c9ebe6227,bug/1605336, if request_data.get(dns.DNSNAME):, if not request_data[dns.DNSNAME]:,1,1
openstack%2Fnetworking-ovn~master~I36a0e5a6beaf70fe7f1431b16e421052fd489f4d,openstack/networking-ovn,master,I36a0e5a6beaf70fe7f1431b16e421052fd489f4d,TEST: Re-enable some tests.,ABANDONED,2017-02-16 07:35:22.000000000,2017-02-27 21:52:16.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2017-02-16 07:35:22.000000000', 'files': ['devstack/devstackgaterc', 'devstack/devstackgatenativeservicesrc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3c1ba491e1b49dc45412cd7bd8c9d93d849ca10b', 'message': ""TEST: Re-enable some tests.\n\nThese tests were disabled several months ago.  Run them to see if\nthey're passing now.\n\nChange-Id: I36a0e5a6beaf70fe7f1431b16e421052fd489f4d\n""}]",0,434692,3c1ba491e1b49dc45412cd7bd8c9d93d849ca10b,4,2,1,1561,,,0,"TEST: Re-enable some tests.

These tests were disabled several months ago.  Run them to see if
they're passing now.

Change-Id: I36a0e5a6beaf70fe7f1431b16e421052fd489f4d
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/92/434692/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/devstackgaterc', 'devstack/devstackgatenativeservicesrc']",2,3c1ba491e1b49dc45412cd7bd8c9d93d849ca10b,bug-1629073,,"# TODO(chandrav): Opened bug #1629073 to track this r=""$r|(?:tempest\.scenario\.test_network_v6.*)"" ",0,6
openstack%2Fpython-neutronclient~master~I5f063c7eddbc9a91f587d5d3610092d07150f726,openstack/python-neutronclient,master,I5f063c7eddbc9a91f587d5d3610092d07150f726,doc: Patch acceptance policy after neutron CLI deprecation,MERGED,2017-02-24 16:17:51.000000000,2017-02-27 21:38:38.000000000,2017-02-27 21:38:38.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 7018}]","[{'number': 1, 'created': '2017-02-24 16:17:51.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/25e8ff67124f64518930fa3a3e84a749c45fbfb2', 'message': ""doc: Patch acceptance policy after neutron CLI deprecation\n\nNeutron CLI itself is now deprecated. It means a kind of\nfeature freeze and we don't accept any changes on\nadding/changing/dropping the existing commands.\nThe only exception is bug fixes on the deprecated neutron CLI.\n\nIt is better to document our policy on neutron CLI chnages.\n\nChange-Id: I5f063c7eddbc9a91f587d5d3610092d07150f726\n""}]",1,437967,25e8ff67124f64518930fa3a3e84a749c45fbfb2,8,3,1,841,,,0,"doc: Patch acceptance policy after neutron CLI deprecation

Neutron CLI itself is now deprecated. It means a kind of
feature freeze and we don't accept any changes on
adding/changing/dropping the existing commands.
The only exception is bug fixes on the deprecated neutron CLI.

It is better to document our policy on neutron CLI chnages.

Change-Id: I5f063c7eddbc9a91f587d5d3610092d07150f726
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/67/437967/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,25e8ff67124f64518930fa3a3e84a749c45fbfb2,doc-cli-deprecation,".. note: neutron CLI has been deprecated from Ocata release. We do not add, change and drop any existing commands any more. We only accept changes on OSC plugin, neutronclient python bindings and bug fixes on the deprecated CLI (``neutron`` command). ",,7,0
openstack%2Fsyntribos~master~I7b4b40ca54a95628e9b6d55963b5e159e6862a45,openstack/syntribos,master,I7b4b40ca54a95628e9b6d55963b5e159e6862a45,Adding XST test to syntribos,MERGED,2017-01-30 23:42:02.000000000,2017-02-27 21:37:01.000000000,2017-02-27 21:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 17709}, {'_account_id': 18462}, {'_account_id': 21297}, {'_account_id': 22221}, {'_account_id': 22781}, {'_account_id': 24311}]","[{'number': 1, 'created': '2017-01-30 23:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/0f540eeb7d996ddb151518f85955646d8880f56a', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}, {'number': 2, 'created': '2017-01-31 21:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/76f32f6b918b5bc495453805f882ac8417e2e060', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}, {'number': 3, 'created': '2017-02-02 20:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/068f2908bd4700e27f6b3358454a91df7f136fd5', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}, {'number': 4, 'created': '2017-02-02 21:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/465fa3610f7422e45ffcbe0a2b58e6d0a413454d', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}, {'number': 5, 'created': '2017-02-23 21:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/6b86069c97274d24e84dd988c98c7a01fb57021c', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}, {'number': 6, 'created': '2017-02-23 21:16:50.000000000', 'files': ['syntribos/checks/header/xst.py', 'syntribos/tests/headers/xst.py', 'syntribos/checks/header/header.py', 'syntribos/checks/header/__init__.py', 'tests/unit/test_xst.py', 'syntribos/clients/http/parser.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/5ed065aaedfbf1a21eab395d97a5c894e04beb23', 'message': 'Adding XST test to syntribos\n\nAdding cross site tracing test to syntribos. This vulnerability\ncan be exploited only if there are existing xss vulnerabilities\nin the app.\n\nMoving ""checks"" that deals specificially with header data to\n""header"" directory.\n\nChange-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45\n'}]",40,426972,5ed065aaedfbf1a21eab395d97a5c894e04beb23,26,8,6,18462,,,0,"Adding XST test to syntribos

Adding cross site tracing test to syntribos. This vulnerability
can be exploited only if there are existing xss vulnerabilities
in the app.

Moving ""checks"" that deals specificially with header data to
""header"" directory.

Change-Id: I7b4b40ca54a95628e9b6d55963b5e159e6862a45
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/72/426972/3 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/checks/header/xst.py', 'syntribos/tests/headers/xst.py', 'syntribos/checks/header/__init__.py', 'syntribos/checks/header/header.py', 'syntribos/clients/http/parser.py']",5,0f540eeb7d996ddb151518f85955646d8880f56a,xst_test," def create_request(cls, string, endpoint, meta_vars=None, http_verb="""", kwargs=None): :param dict meta_vars: Default None, dict parsed from meta.json :param http_verb: Default """", the method type explicitly passed from test :param dict kwargs: Additional headers specific to the test :rtype: :class:`syntribos.clients.http.models.RequestObject` if http_verb: method = http_verb if kwargs: if headers is not None: headers.update(kwargs) headers = kwargs"," def create_request(cls, string, endpoint, meta_vars=None):",157,1
openstack%2Fdevstack~master~I6d263c81579f8c52dcf4cb9a0085c64545ee13e5,openstack/devstack,master,I6d263c81579f8c52dcf4cb9a0085c64545ee13e5,Setup a 2nd cell for the subnode in multinode setups,ABANDONED,2017-01-16 22:16:57.000000000,2017-02-27 21:35:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-01-16 22:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a7922cfbaa3c8ca8cd920ca1c589128af83d17a', 'message': 'Setup a 2nd cell for the subnode in multinode setups\n\nThis change does two things for a multinode setup:\n\n1. Creates a nova_subnode_cell database and subnode-cell\n   cells v2 cell. This is done when setting up the nova,\n   nova_api and nova_cell0 databases on the primary node.\n\n2. Discovers the subnode compute host when setting up the\n   subnode and maps it to the subnode-cell cell.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n'}, {'number': 2, 'created': '2017-01-16 22:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6f73becdf2af1bf242c4764a5db5ef62677d657a', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 3, 'created': '2017-01-16 22:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/57eb890d0edc8cc028f6388cb90fcd00a3d40ec3', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 4, 'created': '2017-01-17 00:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0000684e57b8f0c79f535af205641f9ea9056611', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 5, 'created': '2017-01-17 02:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6b8f8d161ed6ea42faeb2e10aba6fd3873c961c3', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 6, 'created': '2017-01-17 11:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/93b087b90a4875f38dbe52f10838b7b2181d403f', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 7, 'created': '2017-01-17 14:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5612a3fd947a0169c9171e0f6a0fa823e21ca5e8', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}, {'number': 8, 'created': '2017-01-17 17:32:58.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d60e54dd74b796172215c7c84273b498138e11cc', 'message': ""Setup a 2nd cell for the subnode in multinode setups\n\nThis creates a nova_subnode_cell database and subnode-cell\ncells v2 cell. This is done when setting up the nova,\nnova_api and nova_cell0 databases on the primary node.\n\nWe have to move the call to 'nova-manage db sync' so that\nit runs after the subnode cell is created so that it's database\nschema is migrated along with the main (nova) and nova_cell0\ndatabases.\n\nThis change is necessary for testing out a multi-cell deployment\nwith cells v2.\n\nChange-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5\nDepends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f\n""}]",0,420976,d60e54dd74b796172215c7c84273b498138e11cc,36,6,8,6873,,,0,"Setup a 2nd cell for the subnode in multinode setups

This creates a nova_subnode_cell database and subnode-cell
cells v2 cell. This is done when setting up the nova,
nova_api and nova_cell0 databases on the primary node.

We have to move the call to 'nova-manage db sync' so that
it runs after the subnode cell is created so that it's database
schema is migrated along with the main (nova) and nova_cell0
databases.

This change is necessary for testing out a multi-cell deployment
with cells v2.

Change-Id: I6d263c81579f8c52dcf4cb9a0085c64545ee13e5
Depends-On: I4fb1c966e6e011b73d42a1629718abf1adc8125f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/76/420976/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/nova', 'stack.sh']",2,4a7922cfbaa3c8ca8cd920ca1c589128af83d17a,cellsv2-subnode-cell,"elif [ -n ""$DATABASE_HOST"" ] && is_service_enabled n-cpu; then # DATABASE_HOST is only set on the subnode in a multinode setup. This is # where we want to discover the subnode host and map it to the subnode_cell # created in the primary API node. subnode_cell_uuid=$(nova-manage cell_v2 list_cells | awk '$2~/subnode-cell/ {print $4}') die_if_not_set $LINENO subnode_cell_uuid ""subnode-cell was not found"" nova-manage discover_hosts --cell_uuid $subnode_cell_uuid",,33,6
openstack%2Fopenstack-ansible-os_ceilometer~master~I9be50c32ac33bd86f14b8069e604fc4719237d51,openstack/openstack-ansible-os_ceilometer,master,I9be50c32ac33bd86f14b8069e604fc4719237d51,changed the ordering for the ceilometer services,ABANDONED,2017-02-17 20:29:15.000000000,2017-02-27 21:31:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12807}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-17 20:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/61fa2317264627b72362f5fabd3945dc88f5186e', 'message': 'changed the ordering for the ceilometer services\n\nThis change simply moves the ceilometer collector service to the bottom\nof the service list. This is being done due possible issues in the\norder in which some services are started causing them to hang for\nseveral minutes before continuing.\n\nChange-Id: I9be50c32ac33bd86f14b8069e604fc4719237d51\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-02-17 20:44:47.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/13ac6eb32928232bd1b0abf4b307ddac87bbb210', 'message': 'changed the ordering for the ceilometer services\n\nThis change simply moves the ceilometer collector service to the bottom\nof the service list. This is being done due possible issues in the\norder in which some services are started causing them to hang for\nseveral minutes before continuing.\n\nChange-Id: I9be50c32ac33bd86f14b8069e604fc4719237d51\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,435590,13ac6eb32928232bd1b0abf4b307ddac87bbb210,9,4,2,7353,,,0,"changed the ordering for the ceilometer services

This change simply moves the ceilometer collector service to the bottom
of the service list. This is being done due possible issues in the
order in which some services are started causing them to hang for
several minutes before continuing.

Change-Id: I9be50c32ac33bd86f14b8069e604fc4719237d51
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/90/435590/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,61fa2317264627b72362f5fabd3945dc88f5186e,, ceilometer-agent-notification: ceilometer-collector: group: - ceilometer_collector service_name: ceilometer-collector , ceilometer-collector: group: - ceilometer_collector service_name: ceilometer-collector ceilometer-agent-notification:,6,6
openstack%2Fironic~stable%2Fnewton~I9740664f50052b073bf5ef23316839fa25b3d41b,openstack/ironic,stable/newton,I9740664f50052b073bf5ef23316839fa25b3d41b,DNM: Test Ironic in Newton with the placement service,ABANDONED,2017-01-04 21:10:49.000000000,2017-02-27 21:25:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 17998}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-01-04 21:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d4cffd53650e62dc5799c3646c5d353fc93ce61b', 'message': ""DNM: Test Ironic in Newton with the placement service\n\nI'm trying to figure out if we need to backport\n3c217acb9c55d647ca362320d697e80d7cfa5ceb to stable/newton.\n\nChange-Id: I9740664f50052b073bf5ef23316839fa25b3d41b\n""}, {'number': 2, 'created': '2017-01-11 00:37:33.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/ironic/commit/138c9e9f9ec2092016ba3484d53a54e793127ca8', 'message': ""DNM: Test Ironic in Newton with the placement service\n\nI'm trying to figure out if we need to backport\n3c217acb9c55d647ca362320d697e80d7cfa5ceb to stable/newton.\n\nDepends-On: I10b22606f704abcb970939fb2cd77f026d4d6322\n\nChange-Id: I9740664f50052b073bf5ef23316839fa25b3d41b\n""}]",0,416734,138c9e9f9ec2092016ba3484d53a54e793127ca8,10,5,2,6873,,,0,"DNM: Test Ironic in Newton with the placement service

I'm trying to figure out if we need to backport
3c217acb9c55d647ca362320d697e80d7cfa5ceb to stable/newton.

Depends-On: I10b22606f704abcb970939fb2cd77f026d4d6322

Change-Id: I9740664f50052b073bf5ef23316839fa25b3d41b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/34/416734/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,d4cffd53650e62dc5799c3646c5d353fc93ce61b,bug/1651678, enable_service placement-api,,2,0
openstack%2Fironic-lib~master~Ib3fde54d8baa2c6e3567ff3f1a902de4b25f9f70,openstack/ironic-lib,master,Ib3fde54d8baa2c6e3567ff3f1a902de4b25f9f70,Use flake8-import-order,MERGED,2017-02-16 17:51:46.000000000,2017-02-27 21:13:38.000000000,2017-02-27 21:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 13295}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-02-16 17:51:46.000000000', 'files': ['test-requirements.txt', 'ironic_lib/exception.py', 'ironic_lib/tests/test_disk_utils.py', 'ironic_lib/disk_utils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/30c946d33035ff7af7580f811e41838f21cfd557', 'message': ""Use flake8-import-order\n\nUse the flake8 plugin flake8-import-order to check import ordering. It\ncan do it automatically and don't need reviewers to check it.\n\nChange-Id: Ib3fde54d8baa2c6e3567ff3f1a902de4b25f9f70\n""}]",0,435051,30c946d33035ff7af7580f811e41838f21cfd557,10,4,1,14760,,,0,"Use flake8-import-order

Use the flake8 plugin flake8-import-order to check import ordering. It
can do it automatically and don't need reviewers to check it.

Change-Id: Ib3fde54d8baa2c6e3567ff3f1a902de4b25f9f70
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/51/435051/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'ironic_lib/exception.py', 'ironic_lib/tests/test_disk_utils.py', 'ironic_lib/disk_utils.py', 'tox.ini']",5,30c946d33035ff7af7580f811e41838f21cfd557,,import-order-style = pep8,,6,4
openstack%2Fnova-specs~master~Iace67d320984adc9ec3a0e5897cfb131938dfe65,openstack/nova-specs,master,Iace67d320984adc9ec3a0e5897cfb131938dfe65,Deprecate the os-quota-class-sets API (spec),ABANDONED,2016-12-15 02:40:38.000000000,2017-02-27 21:13:33.000000000,,"[{'_account_id': 3}, {'_account_id': 2033}, {'_account_id': 6873}, {'_account_id': 10608}, {'_account_id': 13637}, {'_account_id': 15888}]","[{'number': 1, 'created': '2016-12-15 02:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4f4b77b46b56f8964dabea168d58720a432523d4', 'message': ""Deprecate the os-quota-class-sets API (spec)\n\nThis spec aims to both clarify and restrict the concept of quota classes in\nNova which really only work with the implicit 'default' quota class.\n\nAPIImpact\n\nSpec for blueprint deprecate-os-quota-class-sets\n\nChange-Id: Iace67d320984adc9ec3a0e5897cfb131938dfe65\n""}, {'number': 2, 'created': '2016-12-15 15:40:39.000000000', 'files': ['specs/pike/approved/deprecate-os-quota-class-sets.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/edef0317a1f193566d3a7ccf2c4ef3314f168e20', 'message': ""Deprecate the os-quota-class-sets API (spec)\n\nThis spec aims to both clarify and restrict the concept of quota classes in\nNova which really only work with the implicit 'default' quota class.\n\nAPIImpact\n\nSpec for blueprint deprecate-os-quota-class-sets\n\nChange-Id: Iace67d320984adc9ec3a0e5897cfb131938dfe65\n""}]",8,411035,edef0317a1f193566d3a7ccf2c4ef3314f168e20,12,6,2,6873,,,0,"Deprecate the os-quota-class-sets API (spec)

This spec aims to both clarify and restrict the concept of quota classes in
Nova which really only work with the implicit 'default' quota class.

APIImpact

Spec for blueprint deprecate-os-quota-class-sets

Change-Id: Iace67d320984adc9ec3a0e5897cfb131938dfe65
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/35/411035/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/deprecate-os-quota-class-sets.rst'],1,4f4b77b46b56f8964dabea168d58720a432523d4,bp/deprecate-os-quota-class-sets,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================== Deprecate the os-quota-class-sets API ===================================== `<https://blueprints.launchpad.net/nova/+spec/deprecate-os-quota-class-sets>`_ This spec aims to both clarify and restrict the concept of quota classes in Nova which really only work with the implicit 'default' quota class. Problem description =================== The ability to plugin custom quota classes is a legacy artifact for an out of tree API rate limiting paste config that Rackspace used. In reality, the only quota class that anyone uses is the 'default' quota class that's baked into Nova. There is also no way, besides querying the database directly, to know what quota classes are available. Currently when updating a quota class, it's a create-or-update operation in that a new quota_classes record is created in the database if the update fails. However, there is no way in Nova to associate a non-default quota class with a tenant. Furthermore, when trying to show details on a given quota class, the default quota limits are returned if the class provided does not exist. In other words, if you run ``nova quota-class-show foo`` and there is no 'foo' quota class in the nova.quota_classes DB table, the API will simply return the default limits rather than error with a 404. There is also general confusion over the use of quota classes and default quotas. When calculating limits for a given resource and tenant, the following checks are made in order: * Depending on the resource, is there a tenant-specific limit on the resource in either the `quotas` or `project_user_quotas` tables in the database? If so, use that as the limit. You can create these resources by doing:: nova quota-update --instances 5 cc495759b32b49a7b7dfd321f22cc680 * Check to see if there is a hard limit for the given resource in the `quota_classes` table in the database for the `default` quota class. If so, use that as the limit. You can modify the default quota limit for a resource by doing:: nova quota-class-update --instances 5 default * If the above does not provide a resource limit, then rely on the ``quota_*`` configuration options for the default limit. .. note:: Once a default limit is set via the `default` quota class via the API which sets the limit in the quota_classes table, that takes precedence over any changes to that resource limit in the configuration options. In other words, once you've changed things via the API, you either have to keep those synchronized with the configuration values or remove the default limit from the database manually as there is no REST API for removing quota class values from the database. It's also worth noting that quota classes as a concept is plumbed all throughout the Nova quota code, since in theory it's mutable but in practice it's really only ever using the `default` quota class. As such we have a lot of extra complication in an already complicated and not very well understood part of Nova. Use Cases --------- As an OpenStack administrator, I want to understand how to properly manage global default quota limits in my cloud. As a Nova developer, I want to be able to understand and maintain the quota engine code and not support things which do not actually work in a vanilla deployment. Proposed change =============== Add a microversion which deprecates the `os-quota-class-sets` API extension. This eliminates the ability to create custom quota classes (which are unused) or update default quota limits via the REST API so that any global default quota changes have to be made via the configuration. Alternatives ------------ We could add a microversion which simply restricts showing or updating quota classes to just the implicit `default` quota class, but then we still have the issue of the default quota class limits overriding the configuration and not being able to undo that without changing the database manually. Plus the API is already confusing because there is no GET to list available quota classes, and it means we have a database table (which now needs to be migrated to the API DB with the other quota tables) simply because of this default limit override behavior. So it does not seem like a good alternative to keep limping this functionality along when we can just control default quota limits globally via the configuration. Data model impact ----------------- None REST API impact --------------- Similar to the 2.36 and 2.39 microversions, this just deprecates the show and update methods of the `os-quota-class-sets` REST API extension so that requests to that API after the new microversion will result in a 404 error response. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- If deployers have changed default quota limits via the `os-quota-class-sets` REST API then they should also ensure those changes are reflected back into the global `quota_*` configuration options. Developer impact ---------------- None, although this is probably something that has infected other services in OpenStack such as Cinder, and we could also make the same changes there later. Implementation ============== Assignee(s) ----------- Primary assignee: Matt Riedemann <mriedem@us.ibm.com> Work Items ---------- * Add the microversion to the `os-quota-class-sets` REST API which deprecates the show and update methods. * Deprecate the ``nova quota-class-show`` and ``nova quota-class-update`` CLIs in python-novaclient along with the QuotaClassSetManager python API bindings. Dependencies ============ None Testing ======= Unit tests should be sufficient to verify this change. Documentation Impact ==================== The API reference in Nova does not already document the `os-quota-class-sets` API which is part of what initiated this change [1]_. So as part of this change the api-ref will document the API but also note the deprecation and usage limitations with it. References ========== .. [1] https://bugs.launchpad.net/nova/+bug/1602400 There is also background discussion on this topic over the years in the openstack-dev mailing list, the latest of which is here: `<http://lists.openstack.org/pipermail/openstack-dev/2016-July/099218.html>`_ History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Pike - Introduced ",,206,0
openstack%2Fdragonflow~master~I7ead9de47fe9fc4425044e8750200e867cf389a8,openstack/dragonflow,master,I7ead9de47fe9fc4425044e8750200e867cf389a8,[10/xx] Implement mixin with common fields,MERGED,2016-12-26 13:51:19.000000000,2017-02-27 21:13:21.000000000,2017-02-27 21:13:21.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 18903}, {'_account_id': 20229}, {'_account_id': 23235}, {'_account_id': 23766}]","[{'number': 1, 'created': '2016-12-26 13:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/953c1413af3f1ced65895bbb23ebac93deed7f01', 'message': 'Proposition of model definition and construction\n\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\nPartially-Implements: bp refactor-nb-api\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 2, 'created': '2016-12-26 15:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/51420eaec25f4ec99f505924860b1acbd6de08a2', 'message': 'Proposition of model definition and construction\n\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\nPartially-Implements: bp refactor-nb-api\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 3, 'created': '2017-01-09 11:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0810802203684650ad41f2783a5443130b481d87', 'message': 'Proposition of model definition and construction\n\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\nPartially-Implements: bp refactor-nb-api\n'}, {'number': 4, 'created': '2017-01-09 14:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dd5a57b393d7284175ef9c8a522a8e5ae7992bb7', 'message': 'Proposition of model definition and construction\n\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\nPartially-Implements: bp refactor-nb-api\n'}, {'number': 5, 'created': '2017-01-09 16:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/95cbcfc5da06d4069d5549c84d7691eb8f435bf9', 'message': 'Proposition of model definition and construction\n\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\nPartially-Implements: bp refactor-nb-api\n'}, {'number': 6, 'created': '2017-01-11 09:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/476430c4c367ae900c04782e86a1fa25f191e7b2', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 7, 'created': '2017-01-11 11:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/326c34778d75715be6b916d9b848715468e1e9e8', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 8, 'created': '2017-01-14 10:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5272aed4302f10620938e8f086a5ddaad1da4a74', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 9, 'created': '2017-01-15 15:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e82232ababeb860f16db77217267bf34a252acda', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 10, 'created': '2017-01-16 14:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/39a093290b81e5c83dde8ab46c5520f0a33fe4cc', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 11, 'created': '2017-01-17 16:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c854bf46858dbbe3ddc54e4f29f976c430972be5', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 12, 'created': '2017-01-18 10:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7608007b49a890b2b1b27e46d700ed51e9912293', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 13, 'created': '2017-01-19 13:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/da5a7b494922d6096e44b21a0a95d3c08f3d8c28', 'message': '[6/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 14, 'created': '2017-01-22 16:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4e3dddda66ebb89aef96c29b7103413361252ca7', 'message': '[7/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 15, 'created': '2017-01-22 20:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3038bf35ea741706464b2447933e58b727021897', 'message': '[7/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 16, 'created': '2017-01-23 14:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9c7860e3464757ce745beb2de9abf4e28cd87683', 'message': '[7/8] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 17, 'created': '2017-01-25 09:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fcc4e21cdcf78cb9dd5fc1c543913453f358ef22', 'message': '[08/13] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nDepends-On: I5f78fe0c1cfe2f9bf11ee9a9b42b9f7a909a2cb3\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 18, 'created': '2017-01-25 13:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fe6955c5aa0cea9dc3a93c7e1f6e4522a7aa7864', 'message': '[08/13] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 19, 'created': '2017-01-25 14:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a343411ac702a98fba9d00e37af7cebeba44ba61', 'message': '[08/13] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 20, 'created': '2017-01-26 09:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/66836f35a5a9931bae9e3fd8ec4808779546e55c', 'message': '[08/13] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 21, 'created': '2017-01-26 11:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/54e20dc4bb5697d3dbc764fe30a3e2b23129bdcb', 'message': '[08/13] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 22, 'created': '2017-01-29 14:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8fa8dbb5b1e8bcfcd4ec231c0285b050537f70d0', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 23, 'created': '2017-01-29 15:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f36ee528c41e783c371c9e91991386c72f964be7', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 24, 'created': '2017-01-29 17:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/15de4611db43de75e4765a778c904dad32da9996', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 25, 'created': '2017-01-30 13:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/22ad1da6bb5dc8c243bbe30aab870ef18dd2315a', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 26, 'created': '2017-02-01 20:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2a3af83decde01e69c9311c948704cf1c034ee55', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 27, 'created': '2017-02-02 11:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/834b07b2a6c25f5149b79b78380ebe499067d949', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 28, 'created': '2017-02-05 19:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/28335803edd02baf1fcb44dcf377f32d9724f478', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 29, 'created': '2017-02-06 07:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d911a3fdfacb4848109c642d4c5e7682bdf88b37', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 30, 'created': '2017-02-12 16:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2ef6f71b6f8a7f4e9ecd183d9f6b96df573473d7', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 31, 'created': '2017-02-12 16:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c7f7a1c136f33bfb43d1c311cf9d547e61674f7f', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 32, 'created': '2017-02-14 06:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b79892f8def8cdec9a966db9b04311bd0cbecff3', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 33, 'created': '2017-02-14 09:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ab773c1176709643a0a6c1888819472bb08af76e', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 34, 'created': '2017-02-14 15:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e171b5ae59eccb30c9e415b6a7b355efbaa70e8c', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 35, 'created': '2017-02-15 13:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c20770884df3b461df5def3055112f2b325cae96', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 36, 'created': '2017-02-16 12:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/35897aaa613abb5b4bd3f5a92fe4109c0c9a72f8', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 37, 'created': '2017-02-16 15:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8ecac83856973bfa02defa0b91b3398fd1576b57', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 38, 'created': '2017-02-19 07:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b2e9aac4671e5669727e1c016310963d1e90e880', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 39, 'created': '2017-02-20 15:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2fb811923f2e7f7a8861d8ec5332c904736b794f', 'message': '[07/12] Proposition of model definition and construction\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n'}, {'number': 40, 'created': '2017-02-21 17:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/efe751f4bb24da5e19094d02cdf9e685959b26ba', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 41, 'created': '2017-02-22 09:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8a584c6a1de1c22e960afb6855264354fa835e5e', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 42, 'created': '2017-02-22 09:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/74d731f9235cddd051c6fd9270ba2d03c691ec7c', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 43, 'created': '2017-02-23 08:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/59217b87d1a8c4cdf96ee79480129fe76ea0cb9d', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 44, 'created': '2017-02-23 16:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/95371b9874cabfde991a93f6b0cd8f553653c2ac', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 45, 'created': '2017-02-24 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/32f3fd8442cedc577938d7c25c1be3f97ec8a5fb', 'message': ""[09/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 46, 'created': '2017-02-26 15:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a12c0ed9f895b981e08ca2fb6a6a5e7df83300cd', 'message': ""[10/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 47, 'created': '2017-02-26 15:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/73f751afa8c5f478f3f1a985153a665204e0a14f', 'message': ""[10/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 48, 'created': '2017-02-26 16:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3ef3fe44bff06970dd138a9d89e26c74d3580f10', 'message': ""[10/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}, {'number': 49, 'created': '2017-02-26 21:02:41.000000000', 'files': ['dragonflow/db/models2/__init__.py', 'dragonflow/db/models/mixins.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c847d9f0d4bd78277fe3e3b99f093d4525e3e97c', 'message': ""[10/xx] Implement mixin with common fields\n\nThis patch adds classes that hold fields common to many of the objects\nDragonflow's model defines. New models can use theses classes as extra\nbases to augment their fields and functionality.\n\nPartially-Implements: blueprint refactor-nb-api\nChange-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8\n""}]",33,414984,c847d9f0d4bd78277fe3e3b99f093d4525e3e97c,123,8,49,23766,,,0,"[10/xx] Implement mixin with common fields

This patch adds classes that hold fields common to many of the objects
Dragonflow's model defines. New models can use theses classes as extra
bases to augment their fields and functionality.

Partially-Implements: blueprint refactor-nb-api
Change-Id: I7ead9de47fe9fc4425044e8750200e867cf389a8
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/84/414984/20 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'dragonflow/tests/unit/test_models3.py', 'dragonflow/db/models3.py']",3,953c1413af3f1ced65895bbb23ebac93deed7f01,bp/service-function-chaining,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six from jsonmodels import fields from jsonmodels import models from dragonflow._i18n import _LE class Namespace(object): '''A class that accepts keyword parameters on creation, e.g. ns = Namespace(a=1, b=2) and exposes them as attributes: ns.a => 1, ns.b => 2 ''' def __init__(self, **kwargs): self._dict = {} for key, value in six.iteritems(kwargs): self._add_attr(key, value) def _add_attr(self, key, value): self._dict[key] = value setattr(self, key, value) def __iter__(self): for key, value in six.iteritems(self._dict): yield key, value def impose_over(self, other): for key, value in other: if key not in self._dict: self._add_attr(key, value) def _normalize(obj): '''Receives an object or a sequence, if we got an object, wrap it in a tuple of one and return it, otherwise return the sequence ''' try: if isinstance(obj, str): return (obj,) return tuple(obj) except TypeError: return (obj,) # O(a lot) db store implementation class MockDbStore(object): def __init__(self): self._store = {} def _extract_key(self, obj, index): return tuple(getattr(obj, field) for field in index) def get(self, model, index, key): index = _normalize(index) key = _normalize(key) for obj in self._store.get(model, ()): if self._extract_key(obj, index) == key: return obj raise KeyError(key) def store(self, obj): self._store.setdefault(type(obj), []).append(obj) db_store = MockDbStore() def _combine_indexes(base_class, new_indexes): result = Namespace() if new_indexes is not None: result.impose_over(new_indexes) try: result.impose_over(super(base_class, base_class).get_indexes()) except AttributeError: pass return result def _combine_events(base_class, new_events): try: base_events = tuple(super(base_class, base_class).get_events()) except AttributeError: base_events = () if new_events is None: new_events = () return tuple(set(new_events + base_events)) def construct_nb_db_model(cls_=None, indexes=None, events=None, nb_crud=None): def decorator(cls_): # Compute results ahead of time result_indexes = _combine_indexes(cls_, indexes) result_events = _combine_events(cls_, events) result_nb_crud = nb_crud or cls_.get_nb_crud() class ConstructedClass(cls_): @classmethod def get_indexes(cls): return result_indexes @classmethod def get_events(cls): return result_events @classmethod def get_nb_crud(cls): return result_nb_crud return type(cls_.__name__, (ConstructedClass,), {}) if cls_ is None: return decorator else: return decorator(cls_) class classattr(object): def __init__(self, attr): self.attr = attr def __get__(self, inst, cls): if inst is None: return self.attr else: raise AttributeError( _LE('Accessing class-only attribute through instance')) class RefWrapper(object): def __init__(self, model, key, lazy=True): self._inst = None self._model = model self._key = key self._index_field = 'id' # FIXME self._proxied_fields = set(n for n, _ in model.iterate_over_fields()) self._proxied_fields.discard(self._index_field) if not lazy: self._instance def _fetch(self): return db_store.get( self._model, self._model.get_indexes().id, self._key) @property def _instance(self): if self._inst is None: self._inst = self._fetch() return self._inst def __getattr__(self, name): if name in self._proxied_fields: return getattr(self._instance, name) elif name == self._index_field: return self._key else: raise AttributeError(name) def __setattr__(self, name, value): if name.startswith('_') or name not in self._proxied_fields: super(RefWrapper, self).__setattr__(name, value) else: setattr(self._instance, name, value) def get_field(self, name): return getattr(self, name) class Ref(fields.BaseField): def __init__(self, model, lazy=True, *args, **kwargs): super(Ref, self).__init__(*args, **kwargs) self._model = model self._lazy = lazy def validate(self, value): pass def __set__(self, instance, key): super(Ref, self).__set__( instance, RefWrapper(self._model, key, lazy=self._lazy)) @construct_nb_db_model( indexes=Namespace(id='id'), events=('created', 'updated', 'deleted'), nb_crud=object(), ) class NbDbModelBase(models.Base): id = fields.StringField(required=True) @construct_nb_db_model(indexes=Namespace(id_topic=('id', 'topic'))) class NbDbModelWithTopic(NbDbModelBase): topic = fields.StringField(required=True) ",,290,1
openstack%2Fproject-config~master~Ic6a7728d6789c37bb57ceea51b295050cd40d242,openstack/project-config,master,Ic6a7728d6789c37bb57ceea51b295050cd40d242,Skip gate-puppet-openstack-integration-4-.. jobs,MERGED,2017-02-21 19:21:29.000000000,2017-02-27 21:10:40.000000000,2017-02-27 21:10:40.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-21 19:21:29.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ca562c1d4049e297ff9ddd68251031fca09ab049', 'message': 'Skip gate-puppet-openstack-integration-4-.. jobs\n\ngate-puppet-openstack-integration-4-scenario00X-tempest-centos-7-nv\njobs were not skipped even if the patches were not related to the code.\nSo the jobs wasted the gate resource, so this patch makes them skip when\nproposing unrelated patches.\nThis issue was detected on I6f5c86778e9394ffa56bd11678f47d2939c7ab47\n\nChange-Id: Ic6a7728d6789c37bb57ceea51b295050cd40d242\n'}]",0,436598,ca562c1d4049e297ff9ddd68251031fca09ab049,9,5,1,6167,,,0,"Skip gate-puppet-openstack-integration-4-.. jobs

gate-puppet-openstack-integration-4-scenario00X-tempest-centos-7-nv
jobs were not skipped even if the patches were not related to the code.
So the jobs wasted the gate resource, so this patch makes them skip when
proposing unrelated patches.
This issue was detected on I6f5c86778e9394ffa56bd11678f47d2939c7ab47

Change-Id: Ic6a7728d6789c37bb57ceea51b295050cd40d242
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/436598/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,ca562c1d4049e297ff9ddd68251031fca09ab049,dont-run-puppet-jobs, - name: ^gate-(puppet-.*-(syntax|unit|beaker|integration-4)-|(tripleo-ci|scenario.*-tempest)-centos-7-).*$, - name: ^gate-(puppet-.*-(syntax|unit|beaker)-|tripleo-ci-centos-7-).*$,1,1
openstack%2Fnova~master~I2fb3c0fe58a2b3eb09075dc0f5e398b37b2b656d,openstack/nova,master,I2fb3c0fe58a2b3eb09075dc0f5e398b37b2b656d,[WIP]Remove mox from nova/tests/unit/test_service.py,ABANDONED,2017-02-15 18:01:47.000000000,2017-02-27 21:05:18.000000000,,"[{'_account_id': 3}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-15 18:01:47.000000000', 'files': ['nova/tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b98b9c59334d23608652d1c3472e73fe1df083d3', 'message': '[WIP]Remove mox from nova/tests/unit/test_service.py\n\nPart of blueprint remove-mox-pike\n\nChange-Id: I2fb3c0fe58a2b3eb09075dc0f5e398b37b2b656d\n'}]",0,434437,b98b9c59334d23608652d1c3472e73fe1df083d3,8,6,1,20217,,,0,"[WIP]Remove mox from nova/tests/unit/test_service.py

Part of blueprint remove-mox-pike

Change-Id: I2fb3c0fe58a2b3eb09075dc0f5e398b37b2b656d
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/434437/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_service.py'],1,b98b9c59334d23608652d1c3472e73fe1df083d3,bp/remove-mox-pike," @mock.patch.object(objects.Service, 'create') @mock.patch.object(objects.Service, 'get_by_host_and_binary') def test_init_and_start_hooks(self, mock_get_by_host_and_binary, mock_create): mock_get_by_host_and_binary.return_value = None mock_manager = mock.Mock() serv.manager = mock_manager serv.manager.service_name = self.topic serv.manager.additional_endpoints = [] # init_host is called before any service record is created serv.manager.init_host.assert_called_once_with() mock_get_by_host_and_binary.assert_called_once_with(mock.ANY, self.host, self.binary) mock_create.assert_called_once_with() # pre_start_hook is called after service record is created, # but before RPC consumer is created serv.manager.pre_start_hook.assert_called_once_with() # post_start_hook is called after RPC consumer is created. serv.manager.post_start_hook.assert_called_once_with()"," def test_init_and_start_hooks(self): self.manager_mock = self.mox.CreateMock(FakeManager) self.mox.StubOutWithMock(sys.modules[__name__], 'FakeManager', use_mock_anything=True) self.mox.StubOutWithMock(self.manager_mock, 'init_host') self.mox.StubOutWithMock(self.manager_mock, 'pre_start_hook') self.mox.StubOutWithMock(self.manager_mock, 'post_start_hook') FakeManager(host=self.host).AndReturn(self.manager_mock) self.manager_mock.service_name = self.topic self.manager_mock.additional_endpoints = [] # init_host is called before any service record is created self.manager_mock.init_host() self._service_start_mocks() # pre_start_hook is called after service record is created, # but before RPC consumer is created self.manager_mock.pre_start_hook() # post_start_hook is called after RPC consumer is created. self.manager_mock.post_start_hook() self.mox.ReplayAll() ",19,24
openstack%2Ftripleo-heat-templates~stable%2Focata~Ia79eceeea309f5508713a310849f5d366a035430,openstack/tripleo-heat-templates,stable/ocata,Ia79eceeea309f5508713a310849f5d366a035430,Don't recalculate EndpointMap to get outputs,MERGED,2017-02-27 12:18:40.000000000,2017-02-27 21:02:48.000000000,2017-02-27 21:02:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}]","[{'number': 1, 'created': '2017-02-27 12:18:40.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/94e27e64d469d6a25c9e7b5dca2f06a5479268a7', 'message': ""Don't recalculate EndpointMap to get outputs\n\nAs of Ocata, whenever Heat needs to get the value of an output from a\nnested Stack it will still load the Stack in memory and re-resolve the\noutput value. This means that the EndpointMap's endpoint_map output, which\nis huge, gets loaded and recalculated whenever showing the EndpointMap or\nKeystoneUrl outputs of the main (overcloud) stack. To avoid this, store the\nvalue locally in an OS::Heat::Value resource. This means that the\nEndpointMap will only be resolved once, during the stack create/update, and\nthe outputs can refer to that value.\n\nRelated-Bug: #1661728\nChange-Id: Ia79eceeea309f5508713a310849f5d366a035430\nDepends-On: If0f80cab94c28514d1569b1025362ab9d9d31512\n(cherry picked from commit b2ee58c7f6883011b4ba8b387eedc63d3600aea0)\n""}]",0,438468,94e27e64d469d6a25c9e7b5dca2f06a5479268a7,8,3,1,3153,,,0,"Don't recalculate EndpointMap to get outputs

As of Ocata, whenever Heat needs to get the value of an output from a
nested Stack it will still load the Stack in memory and re-resolve the
output value. This means that the EndpointMap's endpoint_map output, which
is huge, gets loaded and recalculated whenever showing the EndpointMap or
KeystoneUrl outputs of the main (overcloud) stack. To avoid this, store the
value locally in an OS::Heat::Value resource. This means that the
EndpointMap will only be resolved once, during the stack create/update, and
the outputs can refer to that value.

Related-Bug: #1661728
Change-Id: Ia79eceeea309f5508713a310849f5d366a035430
Depends-On: If0f80cab94c28514d1569b1025362ab9d9d31512
(cherry picked from commit b2ee58c7f6883011b4ba8b387eedc63d3600aea0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/68/438468/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,94e27e64d469d6a25c9e7b5dca2f06a5479268a7,," EndpointMapData: type: OS::Heat::Value properties: type: json value: {get_attr: [EndpointMap, endpoint_map]} value: {get_attr: [EndpointMapData, value, KeystonePublic, uri]} value: {get_attr: [EndpointMapData, value]}"," value: {get_attr: [EndpointMap, endpoint_map, KeystonePublic, uri]} value: {get_attr: [EndpointMap, endpoint_map]}",8,2
openstack%2Ftripleo-heat-templates~stable%2Focata~If6ee7a3801756ac445ae35534803eab175ad8e40,openstack/tripleo-heat-templates,stable/ocata,If6ee7a3801756ac445ae35534803eab175ad8e40,Install openstack-heat-agents on upgrade,MERGED,2017-02-27 12:15:57.000000000,2017-02-27 21:02:10.000000000,2017-02-27 21:02:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 18851}]","[{'number': 1, 'created': '2017-02-27 12:15:57.000000000', 'files': ['environments/major-upgrade-composable-steps.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f99e6dc5f00007d7282ddc760613822d013b552', 'message': ""Install openstack-heat-agents on upgrade\n\nThis package wasn't installed in the Newton image and we need to\ninstall it during upgrade to be able to skip preupgrade validations.\n\nChange-Id: If6ee7a3801756ac445ae35534803eab175ad8e40\nCloses-Bug: 1667967\n(cherry picked from commit 96618f85e6b92a4d1d2413e72adafab2abcbddc6)\n""}]",0,438466,7f99e6dc5f00007d7282ddc760613822d013b552,11,4,1,3153,,,0,"Install openstack-heat-agents on upgrade

This package wasn't installed in the Newton image and we need to
install it during upgrade to be able to skip preupgrade validations.

Change-Id: If6ee7a3801756ac445ae35534803eab175ad8e40
Closes-Bug: 1667967
(cherry picked from commit 96618f85e6b92a4d1d2413e72adafab2abcbddc6)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/66/438466/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/major-upgrade-composable-steps.yaml'],1,7f99e6dc5f00007d7282ddc760613822d013b552,bp/overcloud-upgrades-per-service, yum install -y openstack-heat-agents,,1,1
openstack%2Fpuppet-tripleo~master~I1ee50124bf8936e12414f984e1bcd4545d92e953,openstack/puppet-tripleo,master,I1ee50124bf8936e12414f984e1bcd4545d92e953,Add ceilometer polling agent profile,MERGED,2017-02-07 21:07:59.000000000,2017-02-27 21:01:40.000000000,2017-02-27 21:01:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6924}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-07 21:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/99a14f21b004e13df1d48bbc3e5f8b874aead7ad', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 2, 'created': '2017-02-08 00:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6fd65e42505ef1f4d506b36d327083156350e2f8', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 3, 'created': '2017-02-09 15:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f1a0648eee20ad0dd97e14f52f7731fe4ba9d4eb', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 4, 'created': '2017-02-10 19:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/9965240ec7b7c6749d6b442b76aa9ca69dd84e76', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 5, 'created': '2017-02-15 21:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0a7a032a71c42bcb9f3b5e60e29dab7787a2380f', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 6, 'created': '2017-02-18 16:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/04cfa0d9fc0d851ea46864b2dffe1f7b53d2b3d9', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 7, 'created': '2017-02-23 13:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ce058df4c3899b10f1d0c81b80f4b69f5b3c01fe', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 8, 'created': '2017-02-25 17:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e0d1f27c262cadc1baf5c3125e1b10c8a5403b6c', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}, {'number': 9, 'created': '2017-02-25 17:19:40.000000000', 'files': ['manifests/profile/base/ceilometer/agent/polling.pp', 'releasenotes/notes/add-ceilo-polling-agent-53fab550a09a6196.yaml', 'spec/classes/tripleo_profile_base_ceilometer_agent_polling_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7dddf041c5b7940fa974164c157b7f70840a1e9c', 'message': 'Add ceilometer polling agent profile\n\nCeilometer central, compute and ipmi agent classes are\ndeprecated. Instead we should be using polling agent\nwith relevant namespace.\n\nCloses-bug: #1662685\n\nChange-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953\n'}]",5,430441,7dddf041c5b7940fa974164c157b7f70840a1e9c,48,5,9,6924,,,0,"Add ceilometer polling agent profile

Ceilometer central, compute and ipmi agent classes are
deprecated. Instead we should be using polling agent
with relevant namespace.

Closes-bug: #1662685

Change-Id: I1ee50124bf8936e12414f984e1bcd4545d92e953
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/41/430441/7 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/ceilometer/agent/polling.pp'],1,99a14f21b004e13df1d48bbc3e5f8b874aead7ad,bug/1662685,"# Copyright 2016 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # == Class: tripleo::profile::base::ceilometer::agent::polling # # Ceilometer polling Agent profile for tripleo # # === Parameters # # [*central_namespace*] # (Optional) Use central namespace for polling agent. # Defaults to false. # # [*compute_namespace*] # (Optional) Use compute namespace for polling agent. # Defaults to false. # # [*ipmi_namespace*] # (Optional) Use ipmi namespace for polling agent. # Defaults to false. # # [*step*] # (Optional) The current step in deployment. See tripleo-heat-templates # for more details. # Defaults to hiera('step') # class tripleo::profile::base::ceilometer::agent::polling ( $central_namespace = hiera('central_namespace', false), $compute_namespace = hiera('compute_namespace', false), $ipmi_namespace = hiera('ipmi_namespace', false), $step = hiera('step'), ) { include ::tripleo::profile::base::ceilometer if $step >= 4 { include ::ceilometer::agent::auth class { '::ceilometer::agent::polling': central_namespace => $central_namespace compute_namespace => $compute_namespace ipmi_namespace => $ipmi_namespace coordination_url => join(['redis://:', hiera('ceilometer_redis_password'), '@', normalize_ip_for_uri(hiera('redis_vip')), ':6379/']), } } } ",,56,0
openstack%2Fdesignate~master~Ib840297139e79d9270d3b014cb9181ba428199de,openstack/designate,master,Ib840297139e79d9270d3b014cb9181ba428199de,Add basic information on sink + neutron,MERGED,2017-02-22 20:38:40.000000000,2017-02-27 20:54:10.000000000,2017-02-27 20:54:10.000000000,"[{'_account_id': 3}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-22 20:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/527a8a8089db648e972ec18f67eb5803c0a678f7', 'message': 'Add basic information on sink + neutron\n\nChange-Id: Ib840297139e79d9270d3b014cb9181ba428199de\n'}, {'number': 2, 'created': '2017-02-23 15:48:01.000000000', 'files': ['doc/source/integrations.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/83d1b25c1c3cb8a9992a1816c2f13fe604f7fc78', 'message': 'Add basic information on sink + neutron\n\nChange-Id: Ib840297139e79d9270d3b014cb9181ba428199de\n'}]",1,437134,83d1b25c1c3cb8a9992a1816c2f13fe604f7fc78,11,2,2,8099,,,0,"Add basic information on sink + neutron

Change-Id: Ib840297139e79d9270d3b014cb9181ba428199de
",git fetch https://review.opendev.org/openstack/designate refs/changes/34/437134/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/integrations.rst'],1,527a8a8089db648e972ec18f67eb5803c0a678f7,docs-clean-remove," Neutron Designate direct integration ==================================== Neutron supports creating DNS Recordsets as neutron ports are created, and pushing that information into designate. The configuration for this is in the `Networking Guide <https://docs.openstack.org/ocata/networking-guide/config-dns-int.htmls>`_ Designate Sink ============== :ref:`designate-sink` is a componant of designate that can listen to the event stream of other openstack servies and perform actions based on them. ",,16,0
openstack%2Fdesignate~master~I634d62e870333e996b7cd981c577ae7196959e02,openstack/designate,master,I634d62e870333e996b7cd981c577ae7196959e02,Point Users at the main install guide site,MERGED,2017-02-22 19:59:30.000000000,2017-02-27 20:54:04.000000000,2017-02-27 20:54:04.000000000,"[{'_account_id': 3}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-22 19:59:30.000000000', 'files': ['doc/source/index.rst', 'doc/source/install/ubuntu-kilo.rst', 'doc/source/install/ubuntu-liberty.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/e435d6adb5d325095ea46f17cf6817c65547a1cc', 'message': 'Point Users at the main install guide site\n\nChange-Id: I634d62e870333e996b7cd981c577ae7196959e02\n'}]",0,437108,e435d6adb5d325095ea46f17cf6817c65547a1cc,12,2,1,8099,,,0,"Point Users at the main install guide site

Change-Id: I634d62e870333e996b7cd981c577ae7196959e02
",git fetch https://review.opendev.org/openstack/designate refs/changes/08/437108/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/install/ubuntu-kilo.rst', 'doc/source/install/ubuntu-liberty.rst']",3,e435d6adb5d325095ea46f17cf6817c65547a1cc,docs-clean-remove,,"**************************** Installing Liberty on Ubuntu **************************** This section describes how to install Designate on Ubuntu 14.04. To install other OpenStack services, see `OpenStack Installation Guide <http://docs.openstack.org/#install-guides>`_. This section assumes the Identity service runs on the host ``controller``. Install and configure Basic Environment ======================================= Enable OpenStack repository --------------------------- #. Enable the OpenStack Liberty repository: .. code-block:: console $ sudo apt-get update $ sudo apt-get install software-properties-common $ sudo add-apt-repository cloud-archive:liberty #. Upgrade the packages on your host: .. code-block:: console $ sudo apt-get update $ sudo apt-get dist-upgrade Install and configure SQL database ---------------------------------- #. Install the MariaDB packages: .. code-block:: console $ sudo apt-get install mariadb-server python-pymysql Choose a suitable password for the database root account. Install and configure message queue ----------------------------------- #. Install the RabbitMQ packages: .. code-block:: console $ sudo apt-get install rabbitmq-server #. Add the ``openstack`` user: .. code-block:: console $ sudo rabbitmqctl add_user openstack RABBIT_PASS Creating user ""openstack"" ... Replace ``RABBIT_PASS`` with a suitable password. #. Permit configuration, write, and read access for the ``openstack`` user: .. code-block:: console $ sudo rabbitmqctl set_permissions openstack "".*"" "".*"" "".*"" Setting permissions for user ""openstack"" in vhost ""/"" ... Install DNS server ================== #. Install the BIND9 packages: .. code-block:: console $ sudo apt-get install bind9 #. Add the following options in the ``/etc/bind/named.conf.options`` file: .. code-block:: none options { ... allow-new-zones yes; request-ixfr no; recursion no; }; #. Restart the DNS service: .. code-block:: console $ sudo service bind9 restart Install Designate ================= #. Install the ``designate`` package: .. code-block:: console $ sudo apt-get install designate #. In the ``Configuring designate-common`` prompt, complete the following actions: * select ``Yes`` for the question ``Set up a database for Designate?``. * enter ``localhost`` for the ``IP address of your RabbitMQ host``. * enter the ``openstack`` as ``Username for connection to the RabbitMQ server``. * enter the ``password for connection to the RabbitMQ server`` that you chose for the RabbitMQ server at the previous step. * press the ``enter`` key at the prompt ``Authentication server hostname``. * press the ``enter`` key at the prompt ``Authentication server password``. * select ``No`` for the question ``Register Designate in the Keystone endpoint catalog?``. * select ``Yes`` for the question ``Configure database for designate-common with dbconfig-common``. * select ``mysql`` for ``database type to be used by designate-common``. * enter the ``password of the database's administrative user`` that is chosen for the root account at the previous step. * enter the ``MySQL application password for designate-common``. * enter the same password as ``password confirmation``. .. note:: the ``designate-common`` package offers automatic creation of the database tables for Designate during the installation process. Configure Designate =================== #. Source the admin credentials to gain access to admin-only CLI commands. #. Create the ``designate`` user: .. code-block:: console $ openstack user create --domain default --password-prompt designate User Password: Repeat User Password: +-----------+----------------------------------+ | Field | Value | +-----------+----------------------------------+ | domain_id | default | | enabled | True | | id | b7dd483c69654442b09a7458f7daf8d3 | | name | designate | +-----------+----------------------------------+ #. Add the admin role to the ``designate`` user and ``service`` project: .. code-block:: console $ openstack role add --project service --user designate admin #. Create the ``designate`` service entity: .. code-block:: console $ openstack service create --name designate \ --description ""OpenStack DNS service"" dns +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack DNS service | | enabled | True | | id | 6f634693062946579f678c32c006e097 | | name | designate | | type | dns | +-------------+----------------------------------+ #. Create the DNS service API endpoints: .. code-block:: console $ openstack endpoint create --region RegionOne \ dns public http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 05bf0535afad4e0897fcbc4686bf1ab9 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ dns internal http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | b8f56bf8a8ed4e88b1655655a3327ae6 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ dns admin http://controller:9001 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | f081aef76b06472cb791aa04d920f195 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6f634693062946579f678c32c006e097 | | service_name | designate | | service_type | dns | | url | http://controller:9001 | +--------------+----------------------------------+ #. Edit the ``/etc/designate/designate.conf`` file and complete the following actions: * In the ``[service:api]`` section, configure ``auth_strategy``: .. code-block:: ini [service:api] api_host = 0.0.0.0 api_port = 9001 auth_strategy = keystone enable_api_v1 = True enabled_extensions_v1 = diagnostics, quotas, reports, sync, touch enable_api_v2 = True enabled_extensions_v2 = quotas, reports * In the ``[keystone_authtoken]`` section, configure the following options: .. code-block:: ini [keystone_authtoken] auth_host = controller auth_port = 35357 auth_protocol = http admin_tenant_name = service admin_user = designate admin_password = DESIGNATE_PASS Replace DESIGNATE_PASS with the password you chose for the ``designate`` user in the Identity service. * In the ``[service:pool_manager]`` section, configure ``pool_id``: .. code-block:: ini [service:pool_manager] pool_id = 794ccc2c-d751-44fe-b57f-8894c9f5c842 * Configure the pool: .. code-block:: ini [pool:794ccc2c-d751-44fe-b57f-8894c9f5c842] nameservers = 0f66b842-96c2-4189-93fc-1dc95a08b012 targets = f26e0b32-736f-4f0a-831b-039a415c481e [pool_nameserver:0f66b842-96c2-4189-93fc-1dc95a08b012] port = 53 host = 127.0.0.1 [pool_target:f26e0b32-736f-4f0a-831b-039a415c481e] options = port: 53, host: 127.0.0.1 masters = 127.0.0.1:5354 type = bind9 * In the ``[storage:sqlalchemy]`` section, configure database access: .. code-block:: ini [storage:sqlalchemy] connection = mysql+pymysql://designate-common:DESIGNATE_DBPASS@localhost/designatedb ``DESIGNATE_DBPASS`` is automatically set to the password you chose for the Designate database. * In the ``[pool_manager_cache:sqlalchemy]`` section, configure database access: .. code-block:: ini [pool_manager_cache:sqlalchemy] connection = mysql+pymysql://designate-common:DESIGNATE_DBPASS@localhost/designate_pool_manager Replace ``DESIGNATE_DBPASS`` with a suitable password. #. Restart the Designate central and API services: .. code-block:: console $ sudo service designate-central restart $ sudo service designate-api restart Install Designate pool manager and mdns ======================================= #. Create the ``designate_pool_manager`` database and grant proper access: .. code-block:: console $ mysql -u root -p Enter password: <enter your root password here> mysql> CREATE DATABASE `designate_pool_manager` CHARACTER SET utf8 COLLATE utf8_general_ci; mysql> GRANT ALL PRIVILEGES ON designate_pool_manager.* TO 'designate-common'@'localhost' IDENTIFIED BY 'DESIGNATE_DBPASS'; mysql> exit; #. Install the ``designate-pool-manager`` and ``designate-mdns`` package: .. code-block:: console $ sudo apt-get install designate-pool-manager designate-mdns #. Sync the Pool Manager cache: .. code-block:: console $ sudo su -s /bin/sh -c ""designate-manage pool-manager-cache sync"" designate #. Restart the Designate pool manager and mDNS services: .. code-block:: console $ sudo service designate-pool-manager restart $ sudo service designate-mdns restart Verify operation ================ .. note:: If you have a firewall enabled, make sure to open port 53, as well as Designate's default port (9001). Using a web browser, curl statement, or a REST client, calls can be made to the Designate API using the following format where ""api_version"" is either v1 or v2 and ""command"" is any of the commands listed under the corresponding version at :ref:`rest`. :: http://controller:9001/api_version/command You can find the IP Address of your server by running: :: curl -s checkip.dyndns.org | sed -e 's/.*Current IP Address: //' -e 's/<.*$//' .. note:: Before Domains are created, you must create a server (/v1/servers). ",1,705
openstack%2Fironic~master~Ie5e7ff9d3afe1fb5764def1c747950c1f13b1fcc,openstack/ironic,master,Ie5e7ff9d3afe1fb5764def1c747950c1f13b1fcc,WIP/DNM: Testing gate,ABANDONED,2016-12-05 22:06:55.000000000,2017-02-27 20:53:49.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-12-05 22:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/78e818bb493f9daddb99b462e5ad9b48fff6a960', 'message': 'WIP/DNM: Test Tempest change\n\nopenstack/tempest: Update create_isolated_networks logic\nDepends-On: I1c88247c2ee01ba0de5896c9423785dc281cf0fb\n\nChange-Id: Ie5e7ff9d3afe1fb5764def1c747950c1f13b1fcc\n'}, {'number': 2, 'created': '2017-01-04 17:53:33.000000000', 'files': ['ironic/common/foo'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7d81c04923746e36c5e2c39c33cad8d1d0a3b43e', 'message': 'WIP/DNM: Testing gate\n\nChange-Id: Ie5e7ff9d3afe1fb5764def1c747950c1f13b1fcc\n'}]",0,407220,7d81c04923746e36c5e2c39c33cad8d1d0a3b43e,25,8,2,14760,,,0,"WIP/DNM: Testing gate

Change-Id: Ie5e7ff9d3afe1fb5764def1c747950c1f13b1fcc
",git fetch https://review.opendev.org/openstack/ironic refs/changes/20/407220/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/foo'],1,78e818bb493f9daddb99b462e5ad9b48fff6a960,,,,0,0
openstack%2Ftempest~master~I36b7cab44d2e443362c85f0b12e5b96d75d905f0,openstack/tempest,master,I36b7cab44d2e443362c85f0b12e5b96d75d905f0,Add unit test to verify output method,MERGED,2017-02-27 16:43:57.000000000,2017-02-27 20:52:06.000000000,2017-02-27 20:52:06.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 7350}, {'_account_id': 12024}]","[{'number': 1, 'created': '2017-02-27 16:43:57.000000000', 'files': ['tempest/tests/cmd/test_subunit_describe_calls.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/29cc1f86d786b2a20954a3d1bed10872161019cf', 'message': 'Add unit test to verify output method\n\nThe output method was only verified for the part that\nhandles json output to file, but not the part that\nhandles text file to console. Adding a test for that.\n\nChange-Id: I36b7cab44d2e443362c85f0b12e5b96d75d905f0\n'}]",0,438603,29cc1f86d786b2a20954a3d1bed10872161019cf,9,4,1,1921,,,0,"Add unit test to verify output method

The output method was only verified for the part that
handles json output to file, but not the part that
handles text file to console. Adding a test for that.

Change-Id: I36b7cab44d2e443362c85f0b12e5b96d75d905f0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/438603/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/cmd/test_subunit_describe_calls.py'],1,29cc1f86d786b2a20954a3d1bed10872161019cf,subunit_describe_calls_py3," def test_return_code_no_output(self): subunit_file = os.path.join( os.path.dirname(os.path.abspath(__file__)), 'sample_streams/calls.subunit') p = subprocess.Popen([ 'subunit-describe-calls', '-s', subunit_file], stdin=subprocess.PIPE) p.communicate() self.assertEqual(0, p.returncode) ",,10,0
openstack%2Fdevstack-gate~master~I8f855ec627c2a28db755c52ab590fccb8ef55b5d,openstack/devstack-gate,master,I8f855ec627c2a28db755c52ab590fccb8ef55b5d,bump dstools to 0.3.0,MERGED,2017-02-27 15:45:07.000000000,2017-02-27 20:51:13.000000000,2017-02-27 20:51:13.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2017-02-27 15:45:07.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/24a6ed073b547fbbd484157e544b4bc10dda8880', 'message': ""bump dstools to 0.3.0\n\nThis includes a fix that ensures that setlc works correctly if the\nlocal.conf file doesn't have a [[local|localrc]] section at all. That\nwas tripping up some existing 3rd party CI systems.\n\nChange-Id: I8f855ec627c2a28db755c52ab590fccb8ef55b5d\n""}]",0,438566,24a6ed073b547fbbd484157e544b4bc10dda8880,7,3,1,2750,,,0,"bump dstools to 0.3.0

This includes a fix that ensures that setlc works correctly if the
local.conf file doesn't have a [[local|localrc]] section at all. That
was tripping up some existing 3rd party CI systems.

Change-Id: I8f855ec627c2a28db755c52ab590fccb8ef55b5d
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/66/438566/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,24a6ed073b547fbbd484157e544b4bc10dda8880,dstools,export DSTOOLS_VERSION=${DSTOOLS_VERSION:-0.3.0},export DSTOOLS_VERSION=${DSTOOLS_VERSION:-0.2.1},1,1
openstack%2Fdevstack~master~Idd8f9698942a48b0cb18b30dcb5c3e75b1886975,openstack/devstack,master,Idd8f9698942a48b0cb18b30dcb5c3e75b1886975,Disable python3 deployment for swift,ABANDONED,2017-02-24 06:29:55.000000000,2017-02-27 20:44:44.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5638}, {'_account_id': 7350}, {'_account_id': 7787}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-02-24 06:29:55.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/8931be1ff8501f1d59c855d74ca168e8da5b35c1', 'message': 'Disable python3 deployment for swift\n\nIt\'s not gated on in swift gate, and there are obvious issues with py3\ncompatibility of their code. For example, I get the following error in\nswift-proxy-server log file in neutron gate:\n\n  File ""/opt/stack/new/swift/swift/common/middleware/slo.py"", line 799\n    def is_small_segment((seg_dict, start_byte, end_byte)):\n                         ^\nSyntaxError: invalid syntax\n\nThis issue completely blocks neutron gate. I think it\'s fair to disable\nswift special casing here until the project adds a py3 tempest job into\ntheir gate.\n\nChange-Id: Idd8f9698942a48b0cb18b30dcb5c3e75b1886975\nCloses-Bug: #1667579\n'}]",0,437802,8931be1ff8501f1d59c855d74ca168e8da5b35c1,15,14,1,9656,,,0,"Disable python3 deployment for swift

It's not gated on in swift gate, and there are obvious issues with py3
compatibility of their code. For example, I get the following error in
swift-proxy-server log file in neutron gate:

  File ""/opt/stack/new/swift/swift/common/middleware/slo.py"", line 799
    def is_small_segment((seg_dict, start_byte, end_byte)):
                         ^
SyntaxError: invalid syntax

This issue completely blocks neutron gate. I think it's fair to disable
swift special casing here until the project adds a py3 tempest job into
their gate.

Change-Id: Idd8f9698942a48b0cb18b30dcb5c3e75b1886975
Closes-Bug: #1667579
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/437802/1 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,8931be1ff8501f1d59c855d74ca168e8da5b35c1,bug/1667579," ${package_dir##*/} == ""cinder"" || \"," ${package_dir##*/} == ""cinder"" || ${package_dir##*/} == ""swift"" || \",1,1
openstack%2Fneutron-fwaas~master~Id12afb538cdfa1f7eba87a23f1e35f4b410fa331,openstack/neutron-fwaas,master,Id12afb538cdfa1f7eba87a23f1e35f4b410fa331,tempest: Stop using _list_* methods,ABANDONED,2017-02-24 22:03:59.000000000,2017-02-27 20:37:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6854}]","[{'number': 1, 'created': '2017-02-24 22:03:59.000000000', 'files': ['neutron_fwaas/tests/tempest_plugin/tests/scenario/test_fwaas_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/27371b32a01e12855787443e3478cc0fafed23c2', 'message': 'tempest: Stop using _list_* methods\n\nThey are removed in tempest.\n\nRelated-Bug: #1667824\nChange-Id: Id12afb538cdfa1f7eba87a23f1e35f4b410fa331\n'}]",0,438100,27371b32a01e12855787443e3478cc0fafed23c2,4,2,1,6854,,,0,"tempest: Stop using _list_* methods

They are removed in tempest.

Related-Bug: #1667824
Change-Id: Id12afb538cdfa1f7eba87a23f1e35f4b410fa331
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/00/438100/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/tests/tempest_plugin/tests/scenario/test_fwaas_v2.py'],1,27371b32a01e12855787443e3478cc0fafed23c2,bug/1667824," self.admin_manager.ports_client.list_ports( tenant_id=server2['tenant_id'], network_id=network2['id'])['ports']"," self._list_ports(tenant_id=server2['tenant_id'], network_id=network2['id'])",3,2
openstack%2Fnova-powervm~master~Ia81d2e08b9cc609087aa31db20ec523eff73d0db,openstack/nova-powervm,master,Ia81d2e08b9cc609087aa31db20ec523eff73d0db,Add support for File I/O Driver,MERGED,2017-01-30 23:06:07.000000000,2017-02-27 20:34:36.000000000,2017-02-27 20:34:36.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}]","[{'number': 1, 'created': '2017-01-30 23:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/2c64408cac28120abb0615e63831abf4678a7ae2', 'message': 'Add support for File I/O Driver\n\nThis blue print outlines the work to add support for File I/O based\nephemeral storage.\nblueprint file-io-driver\n\nChange-Id: Ia81d2e08b9cc609087aa31db20ec523eff73d0db\n'}, {'number': 2, 'created': '2017-02-22 16:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b062368e308ba8861658a062701df08182db2b6d', 'message': 'Add support for File I/O Driver\n\nThis blue print outlines the work to add support for File I/O based\nephemeral storage.\nblueprint file-io-driver\n\nChange-Id: Ia81d2e08b9cc609087aa31db20ec523eff73d0db\n'}, {'number': 3, 'created': '2017-02-22 16:40:08.000000000', 'files': ['specs/pike/fileio_driver.rst'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/4a4fc849878cd8ecc149380a2e3b6db00466978c', 'message': 'Add support for File I/O Driver\n\nThis blueprint outlines the work to add support for File I/O based\nephemeral storage.\nblueprint file-io-driver\n\nChange-Id: Ia81d2e08b9cc609087aa31db20ec523eff73d0db\n'}]",6,426964,4a4fc849878cd8ecc149380a2e3b6db00466978c,17,5,3,21099,,,0,"Add support for File I/O Driver

This blueprint outlines the work to add support for File I/O based
ephemeral storage.
blueprint file-io-driver

Change-Id: Ia81d2e08b9cc609087aa31db20ec523eff73d0db
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/64/426964/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/fileio_driver.rst'],1,2c64408cac28120abb0615e63831abf4678a7ae2,bp/file-io-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============== File I/O Driver =============== https://blueprints.launchpad.net/nova-powervm/+spec/file-io-driver The PowerVM driver currently uses logical volumes for localdisk ephemeral storage. This blueprint will add support for using file I/O as a localdisk ephemeral storage option. Problem description =================== The PowerVM driver only supports logical volumes for localdisk ephemeral storage. It does not currently support storage that is presented as a file. Use Cases --------- * As a user, I want to have the VMs storage backed by a file. Proposed change =============== Add nova_powervm/virt/powervm/disk/fileio.py. This would extend the existing disk driver. Alternatives ------------ None Security impact --------------- None End user impact --------------- None Performance Impact ------------------ Performance may change as the backing storage methods of VMs will be different. Deployer impact --------------- The deployer must change the DISK_DRIVER conf option from localdisk to fileio in order to utilze the changes described in the blueprint. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: tjakobs Other contributors: None Work Items ---------- * Create a nova-powervm fileio driver. Create associated UT. Dependencies ============ None Testing ======= * Unit tests for all code * Manual test will be driven using a File I/O ephemeral disk. Documentation Impact ==================== Will update the nova-powervm dev-ref to include File I/O as an additional ephemeral disk option. References ========== None ",,118,0
openstack%2Freleases~master~Idc937503e65ae2332bddbc18a7a07b3b0c32b84a,openstack/releases,master,Idc937503e65ae2332bddbc18a7a07b3b0c32b84a,nova: release newton 14.0.4,MERGED,2017-02-16 14:08:11.000000000,2017-02-27 20:26:44.000000000,2017-02-27 20:26:44.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 10135}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-02-16 14:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/a5bdb34a207689a53a87b7479b8495cf8dc32b3b', 'message': 'nova: release newton 14.0.4\n\nChange-Id: Idc937503e65ae2332bddbc18a7a07b3b0c32b84a\n'}, {'number': 2, 'created': '2017-02-18 18:22:27.000000000', 'files': ['deliverables/newton/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e52f6e4fc1d10f589a769311df592762d27ba797', 'message': 'nova: release newton 14.0.4\n\nChange-Id: Idc937503e65ae2332bddbc18a7a07b3b0c32b84a\n'}]",2,434928,e52f6e4fc1d10f589a769311df592762d27ba797,15,6,2,6873,,,0,"nova: release newton 14.0.4

Change-Id: Idc937503e65ae2332bddbc18a7a07b3b0c32b84a
",git fetch https://review.opendev.org/openstack/releases refs/changes/28/434928/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/nova.yaml'],1,a5bdb34a207689a53a87b7479b8495cf8dc32b3b,nova-newton-14.0.4, - version: 14.0.4 projects: - repo: openstack/nova hash: af44ff97dcef83e3fbae02ab23b1f47d7192e298 highlights: > - Bug fixes for placement and cells v2 to prepare for upgrading to Ocata. - Online data migration to fix orphaned build requests created in Mitaka.,,7,0
openstack%2Fpython-designateclient~master~I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d,openstack/python-designateclient,master,I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d,Simplify OSC doc structure,MERGED,2017-02-22 19:58:24.000000000,2017-02-27 20:23:08.000000000,2017-02-27 20:23:08.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 18784}]","[{'number': 1, 'created': '2017-02-22 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/f5ee84c5c8774b02a79cfffd6a89c8b92694b482', 'message': 'Make example grammar better\n\nThis page should be linked from the main docs as a place to see the various\ncommands that are possible. But some of the grammar was bugging me.\n\nChange-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d\n'}, {'number': 2, 'created': '2017-02-22 20:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/dc5a05c2df7012e85e2a4db48fcfcb2407c32c38', 'message': 'Simplify OSC doc structure\n\nThis page should be linked from the main docs as a place to see the various\ncommands that are possible. This moves the more verbose examples to one place and\ndelete the other page. There was also some grammar that bugged me so I changed it\n\nChange-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d\n'}, {'number': 3, 'created': '2017-02-22 20:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/fb1ea9bdc33727cc7741113b9411c61766ec521e', 'message': 'Simplify OSC doc structure\n\nThis page should be linked from the main docs as a place to see the\nvarious commands that are possible. This moves the more verbose\nexamples to one place and delete the other page. There was also some\ngrammar that bugged me so I changed it\n\nChange-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d\n'}, {'number': 4, 'created': '2017-02-22 20:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/18e00ea95530945deb034bea619b96872232025c', 'message': 'Simplify OSC doc structure\n\nThis page should be linked from the main docs as a place to see the\nvarious commands that are possible. This moves the more verbose\nexamples to one place and delete the other page. There was also some\ngrammar that bugged me so I changed it\n\nChange-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d\n'}, {'number': 5, 'created': '2017-02-23 15:26:09.000000000', 'files': ['doc/source/index.rst', 'doc/source/shell-v2-examples.rst', 'doc/source/shell-v2.rst'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/8d806158ae816b9b5a561c8ef2ca83538c355a32', 'message': 'Simplify OSC doc structure\n\nThis page should be linked from the main docs as a place to see the\nvarious commands that are possible. This moves the more verbose\nexamples to one place and delete the other page. There was also some\ngrammar that bugged me so I changed it\n\nChange-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d\n'}]",1,437106,8d806158ae816b9b5a561c8ef2ca83538c355a32,19,4,5,8174,,,0,"Simplify OSC doc structure

This page should be linked from the main docs as a place to see the
various commands that are possible. This moves the more verbose
examples to one place and delete the other page. There was also some
grammar that bugged me so I changed it

Change-Id: I8bc23e493794a43d7f6eb4d5bd5dce965c8ff11d
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/06/437106/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/shell-v2-examples.rst'],1,f5ee84c5c8774b02a79cfffd6a89c8b92694b482,docs-clean-remove,Blacklisting zone names enable you to block any zone pattern from creation.Working with Zone Transfers Between Projects -------------------------------------------- Zone Transfers enable you to perform the transfer of zone ownership to another project.Working with Top Level Domains ------------------------------ The tld commands enable you to manage top level domains.,Zone blacklist enable you to block any zone pattern from creation.Working with zone transfer -------------------------- Zone transfer enable you to perform the transfer of zone ownership to another project.Working with tld ----------------- tld enable you to manage top level domains.,7,7
openstack%2Fdesignate~master~I759cb747504cf47548ae4460ffa67ba62c49024b,openstack/designate,master,I759cb747504cf47548ae4460ffa67ba62c49024b,Add note for running designate-tempest-plugins,MERGED,2017-02-21 21:35:07.000000000,2017-02-27 20:17:39.000000000,2017-02-27 20:17:39.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2017-02-21 21:35:07.000000000', 'files': ['doc/source/tempest.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/fe318c2ec3396006da11e1a73a0a89ad1dedb0e8', 'message': ""Add note for running designate-tempest-plugins\n\nIt's not trivial to run tempest plugin tests if you don't\nset things up exactly right, this explains an annoying\nnuance to make it easier.\n\nChange-Id: I759cb747504cf47548ae4460ffa67ba62c49024b\n""}]",0,436688,fe318c2ec3396006da11e1a73a0a89ad1dedb0e8,10,3,1,8174,,,0,"Add note for running designate-tempest-plugins

It's not trivial to run tempest plugin tests if you don't
set things up exactly right, this explains an annoying
nuance to make it easier.

Change-Id: I759cb747504cf47548ae4460ffa67ba62c49024b
",git fetch https://review.opendev.org/openstack/designate refs/changes/88/436688/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/tempest.rst'],1,fe318c2ec3396006da11e1a73a0a89ad1dedb0e8,docs-clean-remove,"If that doesn't run any tests, ensure that the designate-tempest-plugin is installed in the tox venv. Replace ``../designate-tempest-plugin/`` with the path to the plugin on your system. Then execute the above tox command again:: $ .tox/all-plugin/bin/pip install ../designate-tempest-plugin/ $ tox -e all-plugin -- designate .. note:: This is not necessary if ``designate-tempest-plugin`` is installed to site-packages before the ``all-plugin`` tox venv is created. ",,10,0
openstack%2Fproject-config~master~Id49d37e22777323884a5028c5d02e68e80ae7945,openstack/project-config,master,Id49d37e22777323884a5028c5d02e68e80ae7945,Add recheck support to zuul.yaml,MERGED,2017-02-20 21:15:31.000000000,2017-02-27 20:11:37.000000000,2017-02-27 20:11:37.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 7069}]","[{'number': 1, 'created': '2017-02-20 21:15:31.000000000', 'files': ['zuul.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6b019c816ce62f656f0bc72bd624cc0f1036eb1f', 'message': ""Add recheck support to zuul.yaml\n\nEnable the 'recheck' comment for zuulv3 configuration.\n\nChange-Id: Id49d37e22777323884a5028c5d02e68e80ae7945\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,436195,6b019c816ce62f656f0bc72bd624cc0f1036eb1f,7,3,1,4162,,,0,"Add recheck support to zuul.yaml

Enable the 'recheck' comment for zuulv3 configuration.

Change-Id: Id49d37e22777323884a5028c5d02e68e80ae7945
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/436195/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.yaml'],1,6b019c816ce62f656f0bc72bd624cc0f1036eb1f,zuulv3, - event: comment-added comment: (?i)^(Patch Set [0-9]+:)?( [\w\\+-]*)*(\n\n)?\s*(recheck|reverify),,2,0
