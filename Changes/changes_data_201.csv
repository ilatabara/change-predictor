id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftempest~master~I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44,openstack/tempest,master,I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44,Inclusive jargon,MERGED,2020-12-27 17:45:55.000000000,2021-02-09 22:36:11.000000000,2021-02-09 22:33:47.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 17887}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 32330}]","[{'number': 1, 'created': '2020-12-27 17:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec48b9e79c24ccb02960074f0da169d86aee583b', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 2, 'created': '2020-12-27 18:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3bb310d65b2ca15c909b4a6c21c74a123424b720', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 3, 'created': '2021-01-04 19:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d30b0300a40b2455fc3340cc3441766db4946b99', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 4, 'created': '2021-01-15 13:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4409614fd42028f22e66ccce29ad733b9d2c871', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 5, 'created': '2021-01-18 17:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd63ab8f3045924c887053c69926227af0f7032c', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 6, 'created': '2021-01-19 19:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/229c3989a729d75cc3aac388dcafb8d5a15c9c73', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nThe patch also bumps min version of tox to 3.18.0 in order to\nreplace tox's whitelist_externals by allowlist_externals option:\nhttps://github.com/tox-dev/tox/blob/master/docs/changelog.rst#v3180-2020-07-23\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 7, 'created': '2021-01-19 20:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5a9a70d25113bfa9385456c362d60f9875d134dd', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nThe patch also bumps min version of tox to 3.18.0 in order to\nreplace tox's whitelist_externals by allowlist_externals option:\nhttps://github.com/tox-dev/tox/blob/master/docs/changelog.rst#v3180-2020-07-23\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}, {'number': 8, 'created': '2021-01-20 08:48:05.000000000', 'files': ['tools/check_logs.py', 'tools/generate-tempest-plugins-list.sh', 'tools/tempest-integrated-gate-networking-exclude-list.txt', 'doc/source/overview.rst', 'etc/allow-list.yaml', 'roles/run-tempest/defaults/main.yaml', 'tools/tempest-integrated-gate-compute-exclude-list.txt', 'tools/tempest-integrated-gate-storage-blacklist.txt', 'roles/run-tempest/tasks/main.yaml', 'tools/tempest-integrated-gate-storage-exclude-list.txt', 'releasenotes/notes/Inclusive-jargon-17621346744f0cf4.yaml', 'tools/tempest-integrated-gate-object-storage-exclude-list.txt', 'doc/source/data/tempest-non-active-plugins-registry.header', 'tools/generate-tempest-plugins-list.py', 'tempest/tests/cmd/test_run.py', 'roles/run-tempest/README.rst', 'tools/tempest-integrated-gate-placement-exclude-list.txt', 'tools/tempest-plugin-sanity.sh', 'tox.ini', 'doc/source/stable_branch_support_policy.rst', 'tempest/cmd/run.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dc84423b7294a19cbea4bf1e4b75a59625dec1e9', 'message': ""Inclusive jargon\n\nFollowing stestr's example where arguments such as --blacklist-file,\n--black-regex and --whitelist-file are deprecated since its\n3.1.0 release, let's do the change here as well in order to\nget tempest consumers some time for the transition.\n\nThis change deprecates the following arguments and replaces them\nby new ones which are functionally equivavelnt:\n* --black-regex is replaced by --exclude-regex\n* --blacklist-file is replaced by --exclude-list\n* --whitelist-file is replaced by --include-list\n\nFor now, Tempest will accept both (new and old) arguments to make\nthe transition smoother for all consumers.\n\nThe patch also bumps min version of tox to 3.18.0 in order to\nreplace tox's whitelist_externals by allowlist_externals option:\nhttps://github.com/tox-dev/tox/blob/master/docs/changelog.rst#v3180-2020-07-23\n\nChange-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44\n""}]",49,768583,dc84423b7294a19cbea4bf1e4b75a59625dec1e9,40,6,8,22873,,,0,"Inclusive jargon

Following stestr's example where arguments such as --blacklist-file,
--black-regex and --whitelist-file are deprecated since its
3.1.0 release, let's do the change here as well in order to
get tempest consumers some time for the transition.

This change deprecates the following arguments and replaces them
by new ones which are functionally equivavelnt:
* --black-regex is replaced by --exclude-regex
* --blacklist-file is replaced by --exclude-list
* --whitelist-file is replaced by --include-list

For now, Tempest will accept both (new and old) arguments to make
the transition smoother for all consumers.

The patch also bumps min version of tox to 3.18.0 in order to
replace tox's whitelist_externals by allowlist_externals option:
https://github.com/tox-dev/tox/blob/master/docs/changelog.rst#v3180-2020-07-23

Change-Id: I3e09b31f63d2cd7ea41c48e62432bd3bc54fcf44
",git fetch https://review.opendev.org/openstack/tempest refs/changes/83/768583/4 && git format-patch -1 --stdout FETCH_HEAD,"['tools/check_logs.py', 'tools/generate-tempest-plugins-list.sh', 'tools/tempest-integrated-gate-networking-exclude-list.txt', 'doc/source/overview.rst', 'etc/allow-list.yaml', 'doc/source/data/tempest-excluded-plugins-registry.header', 'roles/run-tempest/defaults/main.yaml', 'roles/run-tempest/tasks/main.yaml', 'tools/tempest-integrated-gate-storage-exclude-list.txt', 'releasenotes/notes/Inclusive-jargon-17621346744f0cf4.yaml', 'tools/tempest-integrated-gate-object-storage-exclude-list.txt', 'tools/generate-tempest-plugins-list.py', 'tempest/tests/cmd/test_run.py', 'tools/tempest-integrated-gate-compute-exclude_list.txt', 'roles/run-tempest/README.rst', 'tools/tempest-integrated-gate-placement-exclude-list.txt', 'tools/tempest-plugin-sanity.sh', 'tox.ini', 'doc/source/stable_branch_support_policy.rst', 'tempest/cmd/run.py']",20,ec48b9e79c24ccb02960074f0da169d86aee583b,inclusive_jargon,"* ``--exclude-list``: It allows to do simple test exclusion via passing a rejection/exclude regexp There are also the ``--exclude-list`` and ``--include-list`` options thatfrom oslo_log import logLOG = log.getLogger(__name__) # temporary method for parsing deprecated and new stestr options # and showing warning messages in order to make the transition # smoother for all tempest consumers # TODO(kopecmartin) remove this after stestr>=3.1.0 is used # in all supported OpenStack releases def parse_dep(old_o, old_v, new_o, new_v): ret = '' if old_v: LOG.warning(""'%s' option is deprecated, use '%s' instead "" ""which is functionally equivalent. Right now "" ""Tempest still supports this option for "" ""backward compatibility, however, it will be "" ""removed soon."", old_o, new_o) ret = old_v if old_v and new_v: # both options are specified LOG.warning(""'%s' and '%s' are specified at the same time, "" ""'%s' takes precedence over '%s'"", new_o, old_o, new_o, old_o) if new_v: ret = new_v return ret ex_regex = parse_dep('--black-regex', parsed_args.black_regex, '--exclude-regex', parsed_args.exclude_regex) ex_list = parse_dep('--blacklist-file', parsed_args.blacklist_file, '--exclude-list', parsed_args.exclude_list) in_list = parse_dep('--whitelist-file', parsed_args.whitelist_file, '--include-list', parsed_args.include_list) try: return_code = commands.list_command( filters=regex, include_list=in_list, exclude_list=ex_list, exclude_regex=ex_regex) except Exception: # exclude_list, include_list and exclude_regex are defined only # in stestr >= 3.1.0, this except block catches the case when # tempest is executed with an older stestr return_code = commands.list_command( filters=regex, whitelist_file=in_list, blacklist_file=ex_list, black_regex=ex_regex) params = { 'filters': regex, 'subunit_out': parsed_args.subunit, 'serial': serial, 'concurrency': parsed_args.concurrency, 'worker_path': parsed_args.worker_file, 'load_list': parsed_args.load_list, 'combine': parsed_args.combine } try: return_code = commands.run_command( **params, exclude_list=ex_list, include_list=in_list, exclude_regex=ex_regex) except Exception: # exclude_list, include_list and exclude_regex are defined only # in stestr >= 3.1.0, this except block catches the case when # tempest is executed with an older stestr return_code = commands.run_command( **params, blacklist_file=ex_list, whitelist_file=in_list, black_regex=ex_regex) help='DEPRECATED: This option will soon be ' 'replaced by --exclude-regex which is ' 'functionally equivalent. If this is ' 'specified at the same time as ' '--exclude-regex, this flag will be ignored ' 'and --exclude-regex will be used') parser.add_argument('--exclude-regex', dest='exclude_regex', help='DEPRECATED: This option will soon be ' 'replaced by --include-list which is ' 'functionally equivalent. If this is ' 'specified at the same time as ' '--include-list, this flag will be ignored ' 'and --include-list will be used') parser.add_argument('--include-list', '--include_list', help=""Path to an include file, this file "" help='DEPRECATED: This option will soon be ' 'replaced by --exclude-list which is ' 'functionally equivalent. If this is ' 'specified at the same time as ' '--exclude-list, this flag will be ignored ' 'and --exclude-list will be used') parser.add_argument('--exclude-list', '--exclude_list',","* ``--black-regex``: It allows to do simple test exclusion via passing a rejection/black regexp There are also the ``--blacklist-file`` and ``--whitelist-file`` options that return_code = commands.list_command( filters=regex, whitelist_file=parsed_args.whitelist_file, blacklist_file=parsed_args.blacklist_file, black_regex=parsed_args.black_regex) return_code = commands.run_command( filters=regex, subunit_out=parsed_args.subunit, serial=serial, concurrency=parsed_args.concurrency, blacklist_file=parsed_args.blacklist_file, whitelist_file=parsed_args.whitelist_file, black_regex=parsed_args.black_regex, worker_path=parsed_args.worker_file, load_list=parsed_args.load_list, combine=parsed_args.combine) help=""Path to a whitelist file, this file """,245,131
openstack%2Foslo.cache~stable%2Fvictoria~Ibdc6015ac1a9812976c4f3d8a737f7245599553e,openstack/oslo.cache,stable/victoria,Ibdc6015ac1a9812976c4f3d8a737f7245599553e,Add dogpile.cache.pymemcache backend,MERGED,2021-02-03 15:37:34.000000000,2021-02-09 22:09:08.000000000,2021-02-09 22:07:35.000000000,"[{'_account_id': 5046}, {'_account_id': 11904}, {'_account_id': 14250}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2021-02-03 15:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/dc4ada344fd1afb4ce1e4aa35eeeb5c253641726', 'message': 'Add dogpile.cache.pymemcache backend\n\nDepends-On: https://review.opendev.org/c/openstack/requirements/+/772684\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 2, 'created': '2021-02-05 10:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/7b8795b45d98bde3225add06c7008e06b90d4200', 'message': 'Add dogpile.cache.pymemcache backend\n\nDepends-On: https://review.opendev.org/c/openstack/requirements/+/772684\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 3, 'created': '2021-02-05 10:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/1feda918333e699d14ee05e80246e5b74118c638', 'message': 'Add dogpile.cache.pymemcache backend\n\nDepends-On: https://review.opendev.org/c/openstack/requirements/+/772684\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 4, 'created': '2021-02-05 10:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/76aae3e8b95e2867c654ee33ccc24cbdc934d386', 'message': 'Add dogpile.cache.pymemcache backend\n\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 5, 'created': '2021-02-05 10:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/55c7c33b3660d31246fc65cb96a91bad99df7bb8', 'message': 'Add dogpile.cache.pymemcache backend\n\ndogpile.cache.pymemcache is currently the best driver for using Memcached\nwith TLS. This backport is intent for security purposes.\n\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 6, 'created': '2021-02-05 11:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/6b40d568f97e6c1f4048e5e7d54a48167cf5f76b', 'message': 'Add dogpile.cache.pymemcache backend\n\ndogpile.cache.pymemcache is currently the best driver for using Memcached\nwith TLS. This backport is intent for security purposes.\n\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 7, 'created': '2021-02-09 11:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/a82d0c6daddbe06acb7428be8379f4565bdf1278', 'message': 'Add dogpile.cache.pymemcache backend\n\ndogpile.cache.pymemcache is currently the best driver for using Memcached\nwith TLS. This backport is intent for security purposes.\n\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}, {'number': 8, 'created': '2021-02-09 13:18:34.000000000', 'files': ['oslo_cache/_opts.py', 'releasenotes/notes/add-dogpile.cache.pymemcache-backend-627d31a76013f8e1.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/886928c12d71d8a2178aedf96a5797afc4476061', 'message': 'Add dogpile.cache.pymemcache backend\n\ndogpile.cache.pymemcache is currently the best driver for using Memcached\nwith TLS. This backport is intent for security purposes.\n\nChange-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e\nSigned-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>\n(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)\n'}]",1,773908,886928c12d71d8a2178aedf96a5797afc4476061,33,7,8,27954,,,0,"Add dogpile.cache.pymemcache backend

dogpile.cache.pymemcache is currently the best driver for using Memcached
with TLS. This backport is intent for security purposes.

Change-Id: Ibdc6015ac1a9812976c4f3d8a737f7245599553e
Signed-off-by: Moisés Guimarães de Medeiros <moguimar@redhat.com>
(cherry picked from commit b00b3b23b42652dc7e9af8ec54a7f117b6999895)
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/08/773908/8 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_cache/tests/functional/dogpile_cache_pymemcache/__init__.py', 'requirements.txt', 'test-requirements.txt', 'oslo_cache/_opts.py', 'oslo_cache/tests/functional/dogpile_cache_pymemcache/test_cache_backend.py', '.zuul.yaml', 'lower-constraints.txt', 'releasenotes/notes/add-dogpile.cache.pymemcache-backend-627d31a76013f8e1.yaml']",8,dc4ada344fd1afb4ce1e4aa35eeeb5c253641726,memcached-tls-stable/victoria,--- features: - | Added a new memcached driver that uses pymemcache through dogpile.cache.,,46,2
openstack%2Ftripleo-ansible~stable%2Fvictoria~I3650a68640a0ec846be24014ebc6a71110b2f6f7,openstack/tripleo-ansible,stable/victoria,I3650a68640a0ec846be24014ebc6a71110b2f6f7,Fix molecule jobs after release of cryptography3.4,MERGED,2021-02-09 18:38:33.000000000,2021-02-09 21:50:10.000000000,2021-02-09 21:50:10.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-02-09 18:38:33.000000000', 'files': ['zuul.d/playbooks/pre.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c4d9b9c893918bc2d1746a8cc9a48edf62653c51', 'message': ""Fix molecule jobs after release of cryptography3.4\n\nMolecule jobs[0] fails with below error:-\n\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which\nnow includes Rust code. It can be installed without Rust using a\nPython wheel, but only with more recent pip than version 9.0.3\navailable as RPM on CentOS 8.\n\nThe cryptography bug report [1] recommends pip>=19.1.1.\n\n[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt\n[1] https://github.com/pyca/cryptography/issues/5753\nRelated-Bug: #1915101\n\nChange-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7\n(cherry picked from commit f8a286cf3014c05105075d033178172ac030dcb6)\n""}]",0,774663,c4d9b9c893918bc2d1746a8cc9a48edf62653c51,6,3,1,14985,,,0,"Fix molecule jobs after release of cryptography3.4

Molecule jobs[0] fails with below error:-

ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which
now includes Rust code. It can be installed without Rust using a
Python wheel, but only with more recent pip than version 9.0.3
available as RPM on CentOS 8.

The cryptography bug report [1] recommends pip>=19.1.1.

[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt
[1] https://github.com/pyca/cryptography/issues/5753
Related-Bug: #1915101

Change-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7
(cherry picked from commit f8a286cf3014c05105075d033178172ac030dcb6)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/63/774663/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/pre.yml'],1,c4d9b9c893918bc2d1746a8cc9a48edf62653c51,bug/1915101-stable/victoria," - name: Ensure a recent version of pip is installed in virtualenv pip: name: ""pip>=19.1.1"" virtualenv: ""{{ ansible_user_dir }}/test-python"" virtualenv_command: ""{{ ensure_pip_virtualenv_command }}"" ",,6,0
openstack%2Ftripleo-ansible~stable%2Fussuri~I3650a68640a0ec846be24014ebc6a71110b2f6f7,openstack/tripleo-ansible,stable/ussuri,I3650a68640a0ec846be24014ebc6a71110b2f6f7,Fix molecule jobs after release of cryptography3.4,MERGED,2021-02-09 18:38:50.000000000,2021-02-09 21:45:10.000000000,2021-02-09 21:45:10.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-02-09 18:38:50.000000000', 'files': ['zuul.d/playbooks/pre.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/81fb36295b0da35e679e44f90d297b951675c8af', 'message': ""Fix molecule jobs after release of cryptography3.4\n\nMolecule jobs[0] fails with below error:-\n\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which\nnow includes Rust code. It can be installed without Rust using a\nPython wheel, but only with more recent pip than version 9.0.3\navailable as RPM on CentOS 8.\n\nThe cryptography bug report [1] recommends pip>=19.1.1.\n\n[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt\n[1] https://github.com/pyca/cryptography/issues/5753\nRelated-Bug: #1915101\n\nChange-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7\n(cherry picked from commit f8a286cf3014c05105075d033178172ac030dcb6)\n""}]",0,774664,81fb36295b0da35e679e44f90d297b951675c8af,6,3,1,14985,,,0,"Fix molecule jobs after release of cryptography3.4

Molecule jobs[0] fails with below error:-

ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which
now includes Rust code. It can be installed without Rust using a
Python wheel, but only with more recent pip than version 9.0.3
available as RPM on CentOS 8.

The cryptography bug report [1] recommends pip>=19.1.1.

[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt
[1] https://github.com/pyca/cryptography/issues/5753
Related-Bug: #1915101

Change-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7
(cherry picked from commit f8a286cf3014c05105075d033178172ac030dcb6)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/64/774664/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/pre.yml'],1,81fb36295b0da35e679e44f90d297b951675c8af,bug/1915101-stable/ussuri," - name: Ensure a recent version of pip is installed in virtualenv pip: name: ""pip>=19.1.1"" virtualenv: ""{{ ansible_user_dir }}/test-python"" virtualenv_command: ""{{ ensure_pip_virtualenv_command }}"" ",,6,0
openstack%2Fproject-config~master~Ifc2e2044cee4ad6f43999d32487e865f2a99d01b,openstack/project-config,master,Ifc2e2044cee4ad6f43999d32487e865f2a99d01b,Setup OpenInfra-Board Channel,MERGED,2021-02-09 18:06:25.000000000,2021-02-09 21:07:22.000000000,2021-02-09 20:56:34.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 18:06:25.000000000', 'files': ['accessbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7ee208b696db0222b2eee95f6755acdfd96c6266', 'message': 'Setup OpenInfra-Board Channel\n\nopenstack-board will now be openinfra-board.\n\nChange-Id: Ifc2e2044cee4ad6f43999d32487e865f2a99d01b\n'}]",0,774705,7ee208b696db0222b2eee95f6755acdfd96c6266,7,2,1,16708,,,0,"Setup OpenInfra-Board Channel

openstack-board will now be openinfra-board.

Change-Id: Ifc2e2044cee4ad6f43999d32487e865f2a99d01b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/774705/1 && git format-patch -1 --stdout FETCH_HEAD,['accessbot/channels.yaml'],1,7ee208b696db0222b2eee95f6755acdfd96c6266,openinfra-board, - name: openinfra-board,,1,0
openstack%2Fmonasca-thresh~stable%2Fussuri~Iac161d730580f5a887a3ce87fb33beba1a11090b,openstack/monasca-thresh,stable/ussuri,Iac161d730580f5a887a3ce87fb33beba1a11090b,Fix zuul publish docker image job,MERGED,2021-02-09 19:10:15.000000000,2021-02-09 20:57:53.000000000,2021-02-09 20:57:53.000000000,"[{'_account_id': 22348}, {'_account_id': 28062}]","[{'number': 1, 'created': '2021-02-09 19:10:15.000000000', 'files': ['playbooks/docker-publish.yml'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/e602fa76fe5b73b65e68a654dda57973c04e0b99', 'message': 'Fix zuul publish docker image job\n\nAdd tag to docker push command\n\nChange-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b\n(cherry picked from commit b50c1d1a1f9a61cd62adc679763d78dbcb244acf)\n'}]",0,774667,e602fa76fe5b73b65e68a654dda57973c04e0b99,8,2,1,28062,,,0,"Fix zuul publish docker image job

Add tag to docker push command

Change-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b
(cherry picked from commit b50c1d1a1f9a61cd62adc679763d78dbcb244acf)
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/67/774667/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/docker-publish.yml'],1,e602fa76fe5b73b65e68a654dda57973c04e0b99,fix-zuul-publish," shell: ""docker push monasca/thresh:{{ zuul.tag if zuul.pipeline == 'release' else zuul.branch }}"""," shell: ""docker push monasca/thresh""",1,1
openstack%2Fopenstacksdk~master~Id61f186c4b9d0209d45e0a488d7d91b47af6c1b6,openstack/openstacksdk,master,Id61f186c4b9d0209d45e0a488d7d91b47af6c1b6,Move 'collections.Mapping' to 'collections.abc',MERGED,2021-02-01 11:01:17.000000000,2021-02-09 20:50:02.000000000,2021-02-09 20:48:07.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-02-01 11:01:17.000000000', 'files': ['openstack/orchestration/util/template_utils.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8442aeab7ed2ac6cc7d496a4908a5f8e1b9e4fc1', 'message': ""Move 'collections.Mapping' to 'collections.abc'\n\nThis was moved in Python 3.3 and the alias will be removed in Python\n3.10.\n\nChange-Id: Id61f186c4b9d0209d45e0a488d7d91b47af6c1b6\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,773358,8442aeab7ed2ac6cc7d496a4908a5f8e1b9e4fc1,8,3,1,15334,,,0,"Move 'collections.Mapping' to 'collections.abc'

This was moved in Python 3.3 and the alias will be removed in Python
3.10.

Change-Id: Id61f186c4b9d0209d45e0a488d7d91b47af6c1b6
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/58/773358/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/orchestration/util/template_utils.py'],1,8442aeab7ed2ac6cc7d496a4908a5f8e1b9e4fc1,collections.abc,"import collections.abc tpl = object_request and object_request('GET', template_object) if isinstance(v, collections.abc.Mapping):","import collections tpl = object_request and object_request('GET', template_object) if isinstance(v, collections.Mapping):",3,4
openstack%2Ftempest~master~Ic005de3e56cb4fde9cfce183ee598c7e9f77f464,openstack/tempest,master,Ic005de3e56cb4fde9cfce183ee598c7e9f77f464,Change Review merge policy from two +2 to single +2 requirement,MERGED,2021-02-03 23:00:28.000000000,2021-02-09 20:31:29.000000000,2021-02-09 20:27:02.000000000,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-02-03 23:00:28.000000000', 'files': ['doc/source/contributor/contributing.rst', 'REVIEWING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/bfce1f219b292f27b902d3b34388710c0fe44a3c', 'message': 'Change Review merge policy from two +2 to single +2 requirement\n\nNow a days, Tempest does not have much active core reviewers due\nto that merging the incoming code change is taking too much time.\n\nAs you can see we have lot of backlogs in open review ~400\n\nIf situation improve in future and we have more Core review\nthen we can change the policy back to two +2 requirement.\n\nDiscussion in QA office hour:\n-  http://eavesdrop.openstack.org/meetings/qa/2021/qa.2021-01-26-14.00.log.html#l-147\n\nChange-Id: Ic005de3e56cb4fde9cfce183ee598c7e9f77f464\n'}]",0,774012,bfce1f219b292f27b902d3b34388710c0fe44a3c,10,5,1,8556,,,0,"Change Review merge policy from two +2 to single +2 requirement

Now a days, Tempest does not have much active core reviewers due
to that merging the incoming code change is taking too much time.

As you can see we have lot of backlogs in open review ~400

If situation improve in future and we have more Core review
then we can change the policy back to two +2 requirement.

Discussion in QA office hour:
-  http://eavesdrop.openstack.org/meetings/qa/2021/qa.2021-01-26-14.00.log.html#l-147

Change-Id: Ic005de3e56cb4fde9cfce183ee598c7e9f77f464
",git fetch https://review.opendev.org/openstack/tempest refs/changes/12/774012/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/contributing.rst', 'REVIEWING.rst']",2,bfce1f219b292f27b902d3b34388710c0fe44a3c,,* Every patch needs at least single +2's before being approved. A single Tempest core reviewer can approve patches but can always wait for another +2 in any case. Following cases where single +2 can be used without any issue: ,"* Every patch needs two +2's before being approved. * However, a single Tempest core reviewer can approve patches without waiting for another +2 in the following cases: * If a patch has already been approved but requires a trivial rebase to merge, then there is no need to wait for a second +2, since the patch has already had two +2's. Note that such a policy should be used judiciously, as we should strive to have two +2's on each patch set, prior to approval. ",7,13
openstack%2Fopenstacksdk~master~I508335b463b889667c4bdfecad98d91c581fcf45,openstack/openstacksdk,master,I508335b463b889667c4bdfecad98d91c581fcf45,Change microseconds to total_seconds(),MERGED,2021-02-05 07:16:23.000000000,2021-02-09 20:29:39.000000000,2021-02-09 20:27:21.000000000,"[{'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-02-05 07:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6c415062a3a18403d1d20fae2cc819be31ae9a5b', 'message': 'Change microseconds to total_seconds()\n\nChange-Id: I508335b463b889667c4bdfecad98d91c581fcf45\n'}, {'number': 2, 'created': '2021-02-05 07:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a81826db41d587e0f98d6f49815d17198f2a2158', 'message': 'Change microseconds to total_seconds()\n\nChange all instances of response.elapsed.microseconds / 1000\nto response.elapsed.total_seconds() * 1000\n\nAccording to: http://eavesdrop.openstack.org/irclogs/%23openstack-sdks/%23openstack-sdks.2021-02-03.log.html#t2021-02-03T18:45:14\n\nChange-Id: I508335b463b889667c4bdfecad98d91c581fcf45\n'}, {'number': 3, 'created': '2021-02-05 07:24:21.000000000', 'files': ['openstack/proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b25241ccc3f7aa8a81563ba28e49dfc6de72dcf5', 'message': 'Change microseconds to total_seconds()\n\n- Change all instances of response.elapsed.microseconds / 1000\nto response.elapsed.total_seconds() * 1000\n\nAccording to:\n - http://eavesdrop.openstack.org/irclogs/%23openstack-sdks/%23openstack-sdks.2021-02-03.log.html#t2021-02-03T18:45:14\n - https://storyboard.openstack.org/#!/story/2008601\n\nChange-Id: I508335b463b889667c4bdfecad98d91c581fcf45\n'}]",0,774199,b25241ccc3f7aa8a81563ba28e49dfc6de72dcf5,9,3,3,33012,,,0,"Change microseconds to total_seconds()

- Change all instances of response.elapsed.microseconds / 1000
to response.elapsed.total_seconds() * 1000

According to:
 - http://eavesdrop.openstack.org/irclogs/%23openstack-sdks/%23openstack-sdks.2021-02-03.log.html#t2021-02-03T18:45:14
 - https://storyboard.openstack.org/#!/story/2008601

Change-Id: I508335b463b889667c4bdfecad98d91c581fcf45
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/99/774199/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/proxy.py'],1,6c415062a3a18403d1d20fae2cc819be31ae9a5b,, duration = int(response.elapsed.total_seconds() * 1000) response.elapsed.total_seconds() * 1000) fields['duration'] = int(response.elapsed.total_seconds() * 1000), duration = int(response.elapsed.microseconds / 1000) response.elapsed.microseconds / 1000) fields['duration'] = int(response.elapsed.microseconds / 1000),3,3
openstack%2Ftempest~master~I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e,openstack/tempest,master,I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e,Create default network for server advance scenario tests,MERGED,2021-01-11 18:36:10.000000000,2021-02-09 20:29:30.000000000,2021-02-09 20:26:13.000000000,"[{'_account_id': 4690}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-01-11 18:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b5f3e837c6a4a447b4a571ff3c6dd20a7634f34', 'message': ""Create default network for scenario tests\n\nPreviously when fixing this bug for API tests,\nwe thought it cannot happen in scenario tests\nwith same reason as scenario base class do fetch\nthe specific network from neutron to pass it t nova\nfor creating the server.\n\nBut when 'CONF.network.port_vnic_type' and\n'CONF.network.port_profile' are not configured in Tempest\nthen Tempest scenario manager does not fetch the network\nfrom neutron.\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L242\n\nIn that case, tenant network is used, which is not present\nas scenario manager does not create the default network\nresource for credential and tenant.\n\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L298\n\nWe need to create default network resources in scenario base class\nalso.\n\nCloses-Bug: #1844568\nChange-Id: I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e\n""}, {'number': 2, 'created': '2021-01-14 21:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/59ee6ba4e702ae0490efcea085d024d69f6ad106', 'message': ""Create default network for scenario tests\n\nPreviously when fixing this bug for API tests,\nwe thought it cannot happen in scenario tests\nwith same reason as scenario base class do fetch\nthe specific network from neutron to pass it t nova\nfor creating the server.\n\nBut when 'CONF.network.port_vnic_type' and\n'CONF.network.port_profile' are not configured in Tempest\nthen Tempest scenario manager does not fetch the network\nfrom neutron.\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L242\n\nIn that case, tenant network is used, which is not present\nas scenario manager does not create the default network\nresource for credential and tenant.\n\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L298\n\nWe need to create default network resources in scenario base class\nalso.\n\nCloses-Bug: #1844568\nChange-Id: I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e\n""}, {'number': 3, 'created': '2021-01-20 22:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ad06ad706be265df4af32dbcde24a3a674ff39d1', 'message': ""Create default network for scenario tests\n\nPreviously when fixing this bug for API tests,\nwe thought it cannot happen in scenario tests\nwith same reason as scenario base class do fetch\nthe specific network from neutron to pass it t nova\nfor creating the server.\n\nBut when 'CONF.network.port_vnic_type' and\n'CONF.network.port_profile' are not configured in Tempest\nthen Tempest scenario manager does not fetch the network\nfrom neutron.\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L242\n\nIn that case, tenant network is used, which is not present\nas scenario manager does not create the default network\nresource for credential and tenant.\n\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L298\n\nWe create default network resources in scenario base class\nby default and disable in few of the tests.\n\nCloses-Bug: #1844568\nChange-Id: I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e\n""}, {'number': 4, 'created': '2021-02-08 23:00:09.000000000', 'files': ['tempest/scenario/test_server_advanced_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f5aef7bec1df36410cbee1799d88896bc7123ea7', 'message': ""Create default network for server advance scenario tests\n\nPreviously when fixing this bug for API tests,\nwe thought it cannot happen in scenario tests\nwith same reason as scenario base class do fetch\nthe specific network from neutron to pass it t nova\nfor creating the server.\n\nBut when 'CONF.network.port_vnic_type' and\n'CONF.network.port_profile' are not configured in Tempest\nthen Tempest scenario manager does not fetch the network\nfrom neutron.\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L242\n\nIn that case, tenant network is used, which is not present\nas scenario manager does not create the default network\nresource for credential and tenant.\n\n- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L298\n\nThis commit let server advance test (which is failing for multiple network\nerorr) to create the default network which will be used to pass to the\nnova API request while creating the test server.\n\nRelated-Bug: #1844568\nChange-Id: I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e\n""}]",0,770169,f5aef7bec1df36410cbee1799d88896bc7123ea7,23,6,4,8556,,,0,"Create default network for server advance scenario tests

Previously when fixing this bug for API tests,
we thought it cannot happen in scenario tests
with same reason as scenario base class do fetch
the specific network from neutron to pass it t nova
for creating the server.

But when 'CONF.network.port_vnic_type' and
'CONF.network.port_profile' are not configured in Tempest
then Tempest scenario manager does not fetch the network
from neutron.
- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L242

In that case, tenant network is used, which is not present
as scenario manager does not create the default network
resource for credential and tenant.

- https://github.com/openstack/tempest/blob/fec2c93cdcc14ad08d0a35136ee287525e7a4879/tempest/scenario/manager.py#L298

This commit let server advance test (which is failing for multiple network
erorr) to create the default network which will be used to pass to the
nova API request while creating the test server.

Related-Bug: #1844568
Change-Id: I5a73a4f25f9092a4cdddcaf86f9ff2c89720409e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/770169/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,6b5f3e837c6a4a447b4a571ff3c6dd20a7634f34,bug/1844568," # Set this to False in subclasses to stop creating a default network. See # https://bugs.launchpad.net/tempest/+bug/1844568 create_default_network = True @classmethod def setup_credentials(cls): # Setting network=True, subnet=True creates a default network cls.set_network_resources( network=cls.create_default_network, subnet=cls.create_default_network) super(ScenarioTest, cls).setup_credentials() ",,12,0
openstack%2Fopenstacksdk~stable%2Fvictoria~If08fa34672ff32dda139b0b50cc7c4af89107846,openstack/openstacksdk,stable/victoria,If08fa34672ff32dda139b0b50cc7c4af89107846,Add id query parameter to sg rules,MERGED,2021-01-28 18:04:48.000000000,2021-02-09 20:29:27.000000000,2021-02-09 20:27:26.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32673}]","[{'number': 1, 'created': '2021-01-28 18:04:48.000000000', 'files': ['openstack/network/v2/security_group_rule.py', 'openstack/tests/unit/network/v2/test_security_group_rule.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cdb3980de64d8b4b04d6c9b04a283317a6d61b04', 'message': 'Add id query parameter to sg rules\n\nid paramter is needed for filter functionality in Ansible modules. See PR https://review.opendev.org/c/openstack/ansible-collections-openstack/+/765580\n\nChange-Id: If08fa34672ff32dda139b0b50cc7c4af89107846\n(cherry picked from commit b86edc3683ea73e0ecbe3d7d2c1495a1842d836c)\n'}]",0,772809,cdb3980de64d8b4b04d6c9b04a283317a6d61b04,7,3,1,10969,,,0,"Add id query parameter to sg rules

id paramter is needed for filter functionality in Ansible modules. See PR https://review.opendev.org/c/openstack/ansible-collections-openstack/+/765580

Change-Id: If08fa34672ff32dda139b0b50cc7c4af89107846
(cherry picked from commit b86edc3683ea73e0ecbe3d7d2c1495a1842d836c)
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/09/772809/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/security_group_rule.py', 'openstack/tests/unit/network/v2/test_security_group_rule.py']",2,cdb3980de64d8b4b04d6c9b04a283317a6d61b04,," 'id': 'id',",,2,1
openstack%2Fmonasca-thresh~stable%2Fvictoria~Iac161d730580f5a887a3ce87fb33beba1a11090b,openstack/monasca-thresh,stable/victoria,Iac161d730580f5a887a3ce87fb33beba1a11090b,Fix zuul publish docker image job,MERGED,2021-02-09 19:09:36.000000000,2021-02-09 20:29:25.000000000,2021-02-09 20:29:25.000000000,"[{'_account_id': 22348}, {'_account_id': 28062}]","[{'number': 1, 'created': '2021-02-09 19:09:36.000000000', 'files': ['playbooks/docker-publish.yml'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/716733df4f87275c13011b641a5494c489b607b8', 'message': 'Fix zuul publish docker image job\n\nAdd tag to docker push command\n\nChange-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b\n(cherry picked from commit b50c1d1a1f9a61cd62adc679763d78dbcb244acf)\n'}]",0,774666,716733df4f87275c13011b641a5494c489b607b8,8,2,1,28062,,,0,"Fix zuul publish docker image job

Add tag to docker push command

Change-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b
(cherry picked from commit b50c1d1a1f9a61cd62adc679763d78dbcb244acf)
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/66/774666/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/docker-publish.yml'],1,716733df4f87275c13011b641a5494c489b607b8,fix-zuul-publish," shell: ""docker push monasca/thresh:{{ zuul.tag if zuul.pipeline == 'release' else zuul.branch }}"""," shell: ""docker push monasca/thresh""",1,1
openstack%2Ftempest~master~Id2c9f5b304106a5be15639a69f95be424a394436,openstack/tempest,master,Id2c9f5b304106a5be15639a69f95be424a394436,Fix system & domain scoped admin dynamic credential,MERGED,2021-01-29 19:13:02.000000000,2021-02-09 20:26:34.000000000,2021-02-09 20:26:34.000000000,"[{'_account_id': 5689}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-01-29 19:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ec0d256e404f4b18d52233bfeee7aa77b69e5fca', 'message': 'Fix system & domain scoped admin dynamic credential\n\nWith I8bebb5b9b6d8da62e6a5268d827787da461cc0d6 Tempest\nstarted supporting the system and domain scope along\nwith project. But system and domain admin are not created\nwith requried scope. If admin role is requested even with\nsystem or domain scope get_credentials() method does not pass\nthe requested scope to _create_creds() so it is always created\nwith project scope.\n\nThis commit fix this by passing the correct scope while creating\nthe cred.\n\nChange-Id: Id2c9f5b304106a5be15639a69f95be424a394436\n'}, {'number': 2, 'created': '2021-01-29 19:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/59e983dbd388461073576f902190253f70e4b209', 'message': 'Fix system & domain scoped admin dynamic credential\n\nWith I8bebb5b9b6d8da62e6a5268d827787da461cc0d6 Tempest\nstarted supporting the system and domain scope along\nwith project. But system and domain admin are not created\nwith requried scope. If admin role is requested even with\nsystem or domain scope get_credentials() method does not pass\nthe requested scope to _create_creds() so it is always created\nwith project scope.\n\nThis commit fix this by passing the correct scope while creating\nthe cred.\n\nChange-Id: Id2c9f5b304106a5be15639a69f95be424a394436\n'}, {'number': 3, 'created': '2021-01-29 21:38:14.000000000', 'files': ['tempest/lib/common/dynamic_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7f3942522a53d8f5d0935a48b0b74c022afa2c84', 'message': 'Fix system & domain scoped admin dynamic credential\n\nWith I8bebb5b9b6d8da62e6a5268d827787da461cc0d6 Tempest\nstarted supporting the system and domain scope along\nwith project. But system and domain admin are not created\nwith requried scope. If admin role is requested even with\nsystem or domain scope get_credentials() method does not pass\nthe requested scope to _create_creds() so it is always created\nwith project scope.\n\nThis commit fix this by passing the correct scope while creating\nthe cred.\n\nChange-Id: Id2c9f5b304106a5be15639a69f95be424a394436\n'}]",0,773173,7f3942522a53d8f5d0935a48b0b74c022afa2c84,14,3,3,8556,,,0,"Fix system & domain scoped admin dynamic credential

With I8bebb5b9b6d8da62e6a5268d827787da461cc0d6 Tempest
started supporting the system and domain scope along
with project. But system and domain admin are not created
with requried scope. If admin role is requested even with
system or domain scope get_credentials() method does not pass
the requested scope to _create_creds() so it is always created
with project scope.

This commit fix this by passing the correct scope while creating
the cred.

Change-Id: Id2c9f5b304106a5be15639a69f95be424a394436
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/773173/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/common/dynamic_creds.py', 'tempest/lib/common/cred_provider.py']",2,ec0d256e404f4b18d52233bfeee7aa77b69e5fca,secure-rbac, def get_alt_admin_creds(self): return @abc.abstractmethod,,13,6
openstack%2Fneutron~stable%2Fussuri~Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,openstack/neutron,stable/ussuri,Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,Fix incorrect exception catch when update floating ip port forwarding,MERGED,2021-02-09 04:54:00.000000000,2021-02-09 20:25:54.000000000,2021-02-09 20:21:20.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 04:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae705494138701ca0c8667feb1ea56322c4665da', 'message': 'Fix incorrect exception catch when update floating ip port forwarding\n\nCloses-Bug: #1912596\nChange-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c\n(cherry picked from commit e9e4395d578e40bb59272b409c7ca3617ec1e6e3)\n'}, {'number': 2, 'created': '2021-02-09 05:09:05.000000000', 'files': ['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9139f40145533990d7c35c2a05153857e978a078', 'message': 'Fix incorrect exception catch when update floating ip port forwarding\n\nCloses-Bug: #1912596\nChange-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c\n(cherry picked from commit e9e4395d578e40bb59272b409c7ca3617ec1e6e3)\n'}]",0,774488,9139f40145533990d7c35c2a05153857e978a078,13,3,2,28329,,,0,"Fix incorrect exception catch when update floating ip port forwarding

Closes-Bug: #1912596
Change-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c
(cherry picked from commit e9e4395d578e40bb59272b409c7ca3617ec1e6e3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/774488/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py']",2,ae705494138701ca0c8667feb1ea56322c4665da,bug/1912596-stable/ussuri,"<<<<<<< HEAD (4b7b59 Merge ""[OVN] Update metadata port ony for requested subnet"" ) ======= from oslo_config import cfg from oslo_db import exception as oslo_db_exc >>>>>>> CHANGE (e9e439 Fix incorrect exception catch when update floating ip port f) except oslo_db_exc.DBDuplicateEntry:", except obj_exc.NeutronDbObjectDuplicateEntry:,64,1
openstack%2Frequirements~master~I53067fffc40bd7e2799b09a14b4e203607e16ab2,openstack/requirements,master,I53067fffc40bd7e2799b09a14b4e203607e16ab2,Updated from generate-constraints,MERGED,2021-02-09 06:20:54.000000000,2021-02-09 20:25:47.000000000,2021-02-09 20:21:26.000000000,"[{'_account_id': 8833}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 06:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/378835e99d22b93457b95cd9083dbbf713533500', 'message': 'Updated from generate-constraints\n\nChange-Id: I53067fffc40bd7e2799b09a14b4e203607e16ab2\n'}, {'number': 2, 'created': '2021-02-09 06:27:15.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4c4bd7b57937f1050be447a42db10442ce24e0d8', 'message': 'Updated from generate-constraints\n\nChange-Id: I53067fffc40bd7e2799b09a14b4e203607e16ab2\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,774593,4c4bd7b57937f1050be447a42db10442ce24e0d8,16,3,2,11131,,,0,"Updated from generate-constraints

Change-Id: I53067fffc40bd7e2799b09a14b4e203607e16ab2
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/774593/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,378835e99d22b93457b95cd9083dbbf713533500,openstack/requirements/constraints/noclob,google-api-core===1.26.0mock===4.0.3cryptography===3.4.3boto3===1.17.4cfn-lint===0.44.7botocore===1.20.4oslo.db===8.5.0oslo.policy===3.6.2hvac===0.10.8pkg-resources===0.0.0fasteners===0.16virtualenv===20.4.2,google-api-core===1.25.1mock===3.0.5cryptography===3.4.1boto3===1.17.3cfn-lint===0.44.6botocore===1.20.3oslo.db===8.4.0oslo.policy===3.6.0hvac===0.10.7setuptools-rust===0.11.6fasteners===0.14.1virtualenv===20.2.1setuptools===53.0.0,12,13
openstack%2Fetcd3gw~master~I1d1d2ab862725bed2585406e5f215450a42f225e,openstack/etcd3gw,master,I1d1d2ab862725bed2585406e5f215450a42f225e,Use unittest.mock instead of mock,MERGED,2021-01-03 03:38:24.000000000,2021-02-09 19:48:46.000000000,2021-02-09 19:46:43.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-01-03 03:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/a44e20a9c9c90be53141d1b5e78bbc2cf1c23ef7', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I1d1d2ab862725bed2585406e5f215450a42f225e\n'}, {'number': 2, 'created': '2021-02-09 19:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/601a271a1da0d7741ab36f101bf3a85376346e80', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I1d1d2ab862725bed2585406e5f215450a42f225e\n'}, {'number': 3, 'created': '2021-02-09 19:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/9f337d097413c3e8926769fe9bff7ab0d85b48e0', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I1d1d2ab862725bed2585406e5f215450a42f225e\n'}, {'number': 4, 'created': '2021-02-09 19:27:17.000000000', 'files': ['test-requirements.txt', 'etcd3gw/tests/test_client.py'], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/28daa7970baa8eb3bb01c82a63b5f513cc544057', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I1d1d2ab862725bed2585406e5f215450a42f225e\n'}]",0,768949,28daa7970baa8eb3bb01c82a63b5f513cc544057,13,3,4,30092,,,0,"Use unittest.mock instead of mock

The mock third party library was needed for mock support in py2
runtimes. Since we now only support py36 and later, we can use the
standard lib unittest.mock module instead.

Change-Id: I1d1d2ab862725bed2585406e5f215450a42f225e
",git fetch https://review.opendev.org/openstack/etcd3gw refs/changes/49/768949/4 && git format-patch -1 --stdout FETCH_HEAD,['etcd3gw/tests/test_client.py'],1,a44e20a9c9c90be53141d1b5e78bbc2cf1c23ef7,,from unittest import mock,import mock,1,1
openstack%2Freleases~master~Iac1caf1d96b7ede9dfc57883438aab67a214c54c,openstack/releases,master,Iac1caf1d96b7ede9dfc57883438aab67a214c54c,Release OpenStack-Ansible Victoria,MERGED,2021-02-09 08:28:41.000000000,2021-02-09 19:26:00.000000000,2021-02-09 19:26:00.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-09 08:28:41.000000000', 'files': ['deliverables/victoria/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/259d8df5be7dfd04acad0de20cac960433f26083', 'message': 'Release OpenStack-Ansible Victoria\n\nChange-Id: Iac1caf1d96b7ede9dfc57883438aab67a214c54c\n'}]",0,774599,259d8df5be7dfd04acad0de20cac960433f26083,9,4,1,28619,,,0,"Release OpenStack-Ansible Victoria

Change-Id: Iac1caf1d96b7ede9dfc57883438aab67a214c54c
",git fetch https://review.opendev.org/openstack/releases refs/changes/99/774599/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/victoria/openstack-ansible.yaml'],1,259d8df5be7dfd04acad0de20cac960433f26083,release_osa, - version: 22.0.1 projects: - repo: openstack/openstack-ansible hash: e1dc35d8e10d01d8823065cccfb5c8f341be7446,,4,0
openstack%2Fetcd3gw~master~Ib35c042f8aff8c2907c9b7f4097945e58858dacf,openstack/etcd3gw,master,Ib35c042f8aff8c2907c9b7f4097945e58858dacf,remove unicode from code,ABANDONED,2021-01-07 03:31:16.000000000,2021-02-09 19:25:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-07 03:31:16.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/c3e169d805f93bac86b740a3cc4c1cb776a4592b', 'message': 'remove unicode from code\n\nChange-Id: Ib35c042f8aff8c2907c9b7f4097945e58858dacf\n'}]",0,769655,c3e169d805f93bac86b740a3cc4c1cb776a4592b,4,1,1,32921,,,0,"remove unicode from code

Change-Id: Ib35c042f8aff8c2907c9b7f4097945e58858dacf
",git fetch https://review.opendev.org/openstack/etcd3gw refs/changes/55/769655/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,c3e169d805f93bac86b740a3cc4c1cb776a4592b,,"project = 'etcd3gw Release Notes' copyright = '2016, OpenStack Foundation' ('index', 'GlanceReleaseNotes.tex', 'Glance Release Notes Documentation', 'Glance Developers', 'manual'), ('index', 'glancereleasenotes', 'Glance Release Notes Documentation', ['Glance Developers'], 1) ('index', 'GlanceReleaseNotes', 'Glance Release Notes Documentation', 'Glance Developers', 'GlanceReleaseNotes',","project = u'etcd3gw Release Notes' copyright = u'2016, OpenStack Foundation' ('index', 'GlanceReleaseNotes.tex', u'Glance Release Notes Documentation', u'Glance Developers', 'manual'), ('index', 'glancereleasenotes', u'Glance Release Notes Documentation', [u'Glance Developers'], 1) ('index', 'GlanceReleaseNotes', u'Glance Release Notes Documentation', u'Glance Developers', 'GlanceReleaseNotes',",17,17
openstack%2Fbifrost~master~I18b123044793fa0662328636517a75dbc8e95834,openstack/bifrost,master,I18b123044793fa0662328636517a75dbc8e95834,Misplaced variable preventing fast-track after inspection,MERGED,2021-02-04 12:54:49.000000000,2021-02-09 19:16:32.000000000,2021-02-09 19:14:02.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-04 12:54:49.000000000', 'files': ['releasenotes/notes/inspect-fast-track-36007cc32bdf7e5c.yaml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/73c3fd0eac6e4092fd9c0532101180ef78b99d08', 'message': 'Misplaced variable preventing fast-track after inspection\n\nChange-Id: I18b123044793fa0662328636517a75dbc8e95834\n'}]",0,774080,73c3fd0eac6e4092fd9c0532101180ef78b99d08,12,3,1,10239,,,0,"Misplaced variable preventing fast-track after inspection

Change-Id: I18b123044793fa0662328636517a75dbc8e95834
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/80/774080/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/inspect-fast-track-36007cc32bdf7e5c.yaml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2']",2,73c3fd0eac6e4092fd9c0532101180ef78b99d08,inspect-fast-track,power_off = {{ power_off_after_inspection }} ,power_off = {{ power_off_after_inspection }},7,1
openstack%2Fansible-role-uwsgi~stable%2Ftrain~I000b8a4ae4c8ee0c9ce44e520e0c74cdd0f4afea,openstack/ansible-role-uwsgi,stable/train,I000b8a4ae4c8ee0c9ce44e520e0c74cdd0f4afea,Run uwsgi tasks only when uwsgi_services defined,MERGED,2021-02-09 10:17:42.000000000,2021-02-09 19:13:43.000000000,2021-02-09 19:11:41.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-09 10:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-uwsgi/commit/9ec917ea3bc82fd634f4516dddc26017932dcf08', 'message': 'Run uwsgi tasks only when uwsgi_services defined\n\nChange-Id: I000b8a4ae4c8ee0c9ce44e520e0c74cdd0f4afea\n(cherry picked from commit b2a0db4b47ae2ee704be5695f249b952c51eb194)\n'}, {'number': 2, 'created': '2021-02-09 10:19:37.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-uwsgi/commit/546253abdd967c9d8abddcd1b7cb2310f6ed6a58', 'message': 'Run uwsgi tasks only when uwsgi_services defined\n\nChange-Id: I000b8a4ae4c8ee0c9ce44e520e0c74cdd0f4afea\n(cherry picked from commit b2a0db4b47ae2ee704be5695f249b952c51eb194)\n'}]",0,774494,546253abdd967c9d8abddcd1b7cb2310f6ed6a58,9,3,2,28619,,,0,"Run uwsgi tasks only when uwsgi_services defined

Change-Id: I000b8a4ae4c8ee0c9ce44e520e0c74cdd0f4afea
(cherry picked from commit b2a0db4b47ae2ee704be5695f249b952c51eb194)
",git fetch https://review.opendev.org/openstack/ansible-role-uwsgi refs/changes/94/774494/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,9ec917ea3bc82fd634f4516dddc26017932dcf08,, when: uwsgi_services when: uwsgi_services when: uwsgi_services when: uwsgi_services,,4,0
openstack%2Fsushy~stable%2Fvictoria~I16eabdce9bb6e9303df8fb3baa48e490f4afa966,openstack/sushy,stable/victoria,I16eabdce9bb6e9303df8fb3baa48e490f4afa966,Fix deprecation on collections.MutableMapping,MERGED,2021-02-09 16:21:03.000000000,2021-02-09 19:13:04.000000000,2021-02-09 19:10:19.000000000,"[{'_account_id': 13294}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 16:21:03.000000000', 'files': ['sushy/main.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/8e28a4ad8ba220fb2b09792afadb00b50ecb58c9', 'message': 'Fix deprecation on collections.MutableMapping\n\nPython 3.10 removes the deprecated aliases to collections abstract\nbase clases [1].\n\n[1] - https://bugs.python.org/issue37324\n\nChange-Id: I16eabdce9bb6e9303df8fb3baa48e490f4afa966\n(cherry picked from commit d9004ec7d541d139f94bdb6e1be86f7492bba1fa)\n'}]",0,774662,8e28a4ad8ba220fb2b09792afadb00b50ecb58c9,9,3,1,10239,,,0,"Fix deprecation on collections.MutableMapping

Python 3.10 removes the deprecated aliases to collections abstract
base clases [1].

[1] - https://bugs.python.org/issue37324

Change-Id: I16eabdce9bb6e9303df8fb3baa48e490f4afa966
(cherry picked from commit d9004ec7d541d139f94bdb6e1be86f7492bba1fa)
",git fetch https://review.opendev.org/openstack/sushy refs/changes/62/774662/1 && git format-patch -1 --stdout FETCH_HEAD,['sushy/main.py'],1,8e28a4ad8ba220fb2b09792afadb00b50ecb58c9,,class LazyRegistries(collections.abc.MutableMapping):,class LazyRegistries(collections.MutableMapping):,1,1
openstack%2Fmonasca-thresh~master~Iac161d730580f5a887a3ce87fb33beba1a11090b,openstack/monasca-thresh,master,Iac161d730580f5a887a3ce87fb33beba1a11090b,Fix zuul publish docker image job,MERGED,2021-02-08 11:21:33.000000000,2021-02-09 18:55:04.000000000,2021-02-09 18:55:04.000000000,"[{'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 28062}]","[{'number': 1, 'created': '2021-02-08 11:21:33.000000000', 'files': ['playbooks/docker-publish.yml'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/b50c1d1a1f9a61cd62adc679763d78dbcb244acf', 'message': 'Fix zuul publish docker image job\n\nAdd tag to docker push command\n\nChange-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b\n'}]",0,774436,b50c1d1a1f9a61cd62adc679763d78dbcb244acf,7,3,1,28062,,,0,"Fix zuul publish docker image job

Add tag to docker push command

Change-Id: Iac161d730580f5a887a3ce87fb33beba1a11090b
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/36/774436/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/docker-publish.yml'],1,b50c1d1a1f9a61cd62adc679763d78dbcb244acf,fix-zuul-publish," shell: ""docker push monasca/thresh:{{ zuul.tag if zuul.pipeline == 'release' else zuul.branch }}"""," shell: ""docker push monasca/thresh""",1,1
openstack%2Fmanila-specs~master~I0c0119595019d6c2f1655f45649cb55925351fe5,openstack/manila-specs,master,I0c0119595019d6c2f1655f45649cb55925351fe5,Add Manila Support on OpenStack SDK,MERGED,2020-12-25 17:54:28.000000000,2021-02-09 18:51:27.000000000,2021-02-09 18:48:51.000000000,"[{'_account_id': 16643}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 31213}]","[{'number': 1, 'created': '2020-12-25 17:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/ff4e9a74083c2c44ee24deb244ad1124cf0c44e8', 'message': 'Add Manila Support on OpenStack SDK\n\nThis is the spec for adding Manila supprt on the OpenStackSDK.\n\nChange-Id: I0c0119595019d6c2f1655f45649cb55925351fe5\n'}, {'number': 2, 'created': '2021-01-29 19:50:11.000000000', 'files': ['specs/release_independent/openstacksdk-manila-support.rst'], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/181b1c400ebced6d51517bb38cc73b7612943c85', 'message': 'Add Manila Support on OpenStack SDK\n\nThis is the spec for adding Manila supprt on the OpenStackSDK.\n\nChange-Id: I0c0119595019d6c2f1655f45649cb55925351fe5\n'}]",8,768516,181b1c400ebced6d51517bb38cc73b7612943c85,17,5,2,32594,,,0,"Add Manila Support on OpenStack SDK

This is the spec for adding Manila supprt on the OpenStackSDK.

Change-Id: I0c0119595019d6c2f1655f45649cb55925351fe5
",git fetch https://review.opendev.org/openstack/manila-specs refs/changes/16/768516/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/manila-openstacksdk.rst'],1,ff4e9a74083c2c44ee24deb244ad1124cf0c44e8,768516,"======================================= Support Manila APIs in the OpenStackSDK ======================================= Blueprint link: https://tree.taiga.io/project/ashrod98-openstacksdk-manila-support/kanban Problem Description =================== Manila is an open source OpenStack Shared File System service that is a software that exists within the OpenStack cloud. It is a collection of microservices and other components that provide self-service management of elastic file system storage infrastructure that can allow you to work with and provision storage via 30+ storage technologies over file system protocols. It is unique in how it is able to add RESTful semantics to consuming shared storage in a reliable and scalable manner. We aim to improve the common user experience by adding Manilla support to the OpenStackSDK, and to reuse OpenStack Identity, Logging, Configuration integration modules without duplicating them into a separate SDK. This project is part of the resolution defined by the TC Stance on OpenStackSDK and the OpenStackClient. Use Cases ========= OpenStack Client will be affected as current manila commands are being implemented using python-manilaclient SDK. OpenStack's Ansible Collections will be affected as it directly uses of the OpenStack SDK. Developers that use automation tooling will also benefit from incorporating Manila into OpenStack SDK. Proposed Changes ================ Resources and methods are listed in order of priority The following resrouces will be a part of the ``Wallaby Cycle`` Priority 1 ------------ * Shares * Share Export Locations * Share networks * Share network subnets * Share types Priority 2 ------------ * Share actions - grant access, revoke access, list access rules, change share size, revert to snapshot * Security services * User messages * Share access rules The following will be part of the cycle(s) following Wallaby Priority 3 ------------ * Share metadata * Share snapshots - List share snapshots, Show share snapshot details, Create share snapshot, * Update share snapshot, Delete share snapshot * Scheduler stats * Availability zones * Quota sets * Quota class sets Priority 4 ------------ * Share replicas * Share replica export locations * Share servers * Services * Share access rule metadata * Share groups * Share group types * Share group snapshots Priority 5 ------------ * Share Actions - Reset share state, force delete share, unmanage share * Share Snapshot - manage share snapshot, unmanage share snapshot, reset share snapshot state, force delete share snapshot * Share Replicas - resync share replica, reset status of share replica, reset state of share replica, force delete share replica * Share Servers - reset status of share server Priority 6 ------------ * Share snapshot instances * Share instances * Share instance export location * Experimental api/share migration Alternatives --------------- Continue using python-manilaclient SDK. Continue maintenance for python-manilaclient SDK. Do not implement support for manilla in OpenStackSDK. Data model impact -------------------------- No impact on the data model. Security impact --------------------- No security impact as authentication is already provided by OpenStackCloud before OpenStackSDK is used. Notifications impact --------------------------- No notifications impact. Other end user impact ------------------------------ Improves user experience by provided user the ability to interact with Manila API through OpenStackSDK. Performance Impact ---------------------------- No current performance impact. Future impact may include mitigating the use of plug-in clients. Other deployer impact ----------------------------- No other deployer impact. Developer impact ------------------------ Implementing Manila support may make it easier for developers to code scripts using the SDK. Manila will not stand out within the OpenStackSDK as it is part of a cohesive design. Implementation ============== Assignee(s) ---------------- Primary assignee: * Ashley Rodriguez <ashrod98> * Nicole Chen <arkaruki> * Mark Tony Other contributors: Work Items ---------------- * Implement proposed changed * Write unit tests * Write documentation * Write functional tests * Write end user guide Dependencies ============ No dependencies at the moment of writing for this project. Testing ======= Unit tests will be required for each resource. Functional tests will also be written. Documentation Impact ==================== For each resource coded, we will concurrently write its documentation. We will also write an End User Guide. References ========== * End User Guide OSSDK: https://docs.openstack.org/openstacksdk/latest/user/guides * Manila API Ref: https://docs.openstack.org/api-ref/shared-file-system/ * TC Stance: https://review.opendev.org/c/openstack/governance/+/759904 ",,179,0
openstack%2Fcliff~master~I4803051a6dd05c143a15923254af97e32cd39693,openstack/cliff,master,I4803051a6dd05c143a15923254af97e32cd39693,Handle null values when sorting,MERGED,2021-01-28 11:03:01.000000000,2021-02-09 18:48:10.000000000,2021-02-09 18:35:31.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-01-28 11:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/609b2fc987664b77a51ab9f099461440a04202f9', 'message': 'Handle null values when sorting\n\nOne unfortunate change (or fortunate, depending on how you look at\ntypes) in Python 3 is the inability to sort iterables of different\ntypes. For example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x)\n  Traceback (most recent call last):\n    File ""<stdin>"", line 1, in <module>\n  TypeError: \'<\' not supported between instances of \'NoneType\' and \'str\'\n\nFortunately, we can take advantage of the fact that by providing a\nfunction for the \'key\' that returns a tuple, we can sort on multiple\nconditions. In this case, ""when the first key returns that two elements\nare equal, the second key is used to compare."" [1] We can use this to\nfirst separate the values by whether they are None or not, punting those\nthat are not to the end, before sorting the non-None values normally.\nFor example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x, key=lambda k: (k is None, k))\n  [\'bar\', \'foo\', \'qux\', None]\n\nWe were already using this feature implicitly through our use of\n\'operator.itemgetter(*indexes)\', which will return a tuple if there is\nmore than one item in \'indexes\', and now we simply make that explicit,\nfixing the case where we\'re attempting to compare a comparable type\nwith None. For all other cases, such as comparing a value that isn\'t\ncomparable, we surround things with a try-catch and a debug logging\nstatement to allow things to continue.\n\nNote that we could optimize what we\'re done further by building a key\nvalue that covers all indexes, rather than using a for loop to do so.\nFor example:\n\n  >>> x = [(\'baz\', 2), (None, 0), (\'bar\', 3), (\'baz\', 4), (\'qux\', 0)]\n  >>> sorted(x, key=lambda k: list(\n  ...     itertools.chain((k[i] is None, k[i]) for i in (0, 1)))\n  ... )\n  [(\'bar\', 3), (\'baz\', 2), (\'baz\', 4), (\'qux\', 0), (None, 0)]\n\nHowever, this would be harder to grok and would also mean we\'re unable\nto handle exceptions on a single column where e.g. there are mixed types\nor types that are not comparable while still sorting on the other\ncolumns. Perhaps this would be desirable for some users, but sorting on\na best-effort basis does seem wiser and generally more user friendly.\nAnyone that wants to sort on such columns should ensure their types are\ncomparable or implement their own sorting implementation.\n\n[1] https://www.kite.com/python/answers/how-to-sort-by-two-keys-in-python\n\nChange-Id: I4803051a6dd05c143a15923254af97e32cd39693\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nStory: 2008456\nTask: 41466\n'}, {'number': 2, 'created': '2021-01-28 16:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/e86f653b91c210ddcc9136d8fba61ae1c44b8e92', 'message': 'Handle null values when sorting\n\nOne unfortunate change (or fortunate, depending on how you look at\ntypes) in Python 3 is the inability to sort iterables of different\ntypes. For example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x)\n  Traceback (most recent call last):\n    File ""<stdin>"", line 1, in <module>\n  TypeError: \'<\' not supported between instances of \'NoneType\' and \'str\'\n\nFortunately, we can take advantage of the fact that by providing a\nfunction for the \'key\' that returns a tuple, we can sort on multiple\nconditions. In this case, ""when the first key returns that two elements\nare equal, the second key is used to compare."" [1] We can use this to\nfirst separate the values by whether they are None or not, punting those\nthat are not to the end, before sorting the non-None values normally.\nFor example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x, key=lambda k: (k is None, k))\n  [\'bar\', \'foo\', \'qux\', None]\n\nWe were already using this feature implicitly through our use of\n\'operator.itemgetter(*indexes)\', which will return a tuple if there is\nmore than one item in \'indexes\', and now we simply make that explicit,\nfixing the case where we\'re attempting to compare a comparable type\nwith None. For all other cases, such as comparing a value that isn\'t\ncomparable, we surround things with a try-catch and a debug logging\nstatement to allow things to continue.\n\nNote that we could optimize what we\'re done further by building a key\nvalue that covers all indexes, rather than using a for loop to do so.\nFor example:\n\n  >>> x = [(\'baz\', 2), (None, 0), (\'bar\', 3), (\'baz\', 4), (\'qux\', 0)]\n  >>> sorted(x, key=lambda k: list(\n  ...     itertools.chain((k[i] is None, k[i]) for i in (0, 1)))\n  ... )\n  [(\'bar\', 3), (\'baz\', 2), (\'baz\', 4), (\'qux\', 0), (None, 0)]\n\nHowever, this would be harder to grok and would also mean we\'re unable\nto handle exceptions on a single column where e.g. there are mixed types\nor types that are not comparable while still sorting on the other\ncolumns. Perhaps this would be desirable for some users, but sorting on\na best-effort basis does seem wiser and generally more user friendly.\nAnyone that wants to sort on such columns should ensure their types are\ncomparable or implement their own sorting implementation.\n\n[1] https://www.kite.com/python/answers/how-to-sort-by-two-keys-in-python\n\nChange-Id: I4803051a6dd05c143a15923254af97e32cd39693\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nStory: 2008456\nTask: 41466\n'}, {'number': 3, 'created': '2021-01-29 15:40:54.000000000', 'files': ['cliff/lister.py', 'cliff/tests/test_lister.py', 'releasenotes/notes/handle-none-values-when-sorting-de40e36c66ad95ca.yaml'], 'web_link': 'https://opendev.org/openstack/cliff/commit/4f45f9a30e657265c5b5ac119af3aaa0e5ec7184', 'message': 'Handle null values when sorting\n\nOne unfortunate change (or fortunate, depending on how you look at\ntypes) in Python 3 is the inability to sort iterables of different\ntypes. For example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x)\n  Traceback (most recent call last):\n    File ""<stdin>"", line 1, in <module>\n  TypeError: \'<\' not supported between instances of \'NoneType\' and \'str\'\n\nFortunately, we can take advantage of the fact that by providing a\nfunction for the \'key\' that returns a tuple, we can sort on multiple\nconditions. In this case, ""when the first key returns that two elements\nare equal, the second key is used to compare."" [1] We can use this to\nfirst separate the values by whether they are None or not, punting those\nthat are not to the end, before sorting the non-None values normally.\nFor example:\n\n  >>> x = [\'foo\', \'bar\', None, \'qux\']\n  >>> sorted(x, key=lambda k: (k is None, k))\n  [\'bar\', \'foo\', \'qux\', None]\n\nWe were already using this feature implicitly through our use of\n\'operator.itemgetter(*indexes)\', which will return a tuple if there is\nmore than one item in \'indexes\', and now we simply make that explicit,\nfixing the case where we\'re attempting to compare a comparable type\nwith None. For all other cases, such as comparing a value that isn\'t\ncomparable, we surround things with a try-catch and a debug logging\nstatement to allow things to continue.\n\nNote that we could optimize what we\'re done further by building a key\nvalue that covers all indexes, rather than using a for loop to do so.\nFor example:\n\n  >>> x = [(\'baz\', 2), (None, 0), (\'bar\', 3), (\'baz\', 4), (\'qux\', 0)]\n  >>> sorted(x, key=lambda k: list(\n  ...     itertools.chain((k[i] is None, k[i]) for i in (0, 1)))\n  ... )\n  [(\'bar\', 3), (\'baz\', 2), (\'baz\', 4), (\'qux\', 0), (None, 0)]\n\nHowever, this would be harder to grok and would also mean we\'re unable\nto handle exceptions on a single column where e.g. there are mixed types\nor types that are not comparable while still sorting on the other\ncolumns. Perhaps this would be desirable for some users, but sorting on\na best-effort basis does seem wiser and generally more user friendly.\nAnyone that wants to sort on such columns should ensure their types are\ncomparable or implement their own sorting implementation.\n\n[1] https://www.kite.com/python/answers/how-to-sort-by-two-keys-in-python\n\nChange-Id: I4803051a6dd05c143a15923254af97e32cd39693\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nStory: 2008456\nTask: 41466\n'}]",5,772854,4f45f9a30e657265c5b5ac119af3aaa0e5ec7184,17,3,3,15334,,,0,"Handle null values when sorting

One unfortunate change (or fortunate, depending on how you look at
types) in Python 3 is the inability to sort iterables of different
types. For example:

  >>> x = ['foo', 'bar', None, 'qux']
  >>> sorted(x)
  Traceback (most recent call last):
    File ""<stdin>"", line 1, in <module>
  TypeError: '<' not supported between instances of 'NoneType' and 'str'

Fortunately, we can take advantage of the fact that by providing a
function for the 'key' that returns a tuple, we can sort on multiple
conditions. In this case, ""when the first key returns that two elements
are equal, the second key is used to compare."" [1] We can use this to
first separate the values by whether they are None or not, punting those
that are not to the end, before sorting the non-None values normally.
For example:

  >>> x = ['foo', 'bar', None, 'qux']
  >>> sorted(x, key=lambda k: (k is None, k))
  ['bar', 'foo', 'qux', None]

We were already using this feature implicitly through our use of
'operator.itemgetter(*indexes)', which will return a tuple if there is
more than one item in 'indexes', and now we simply make that explicit,
fixing the case where we're attempting to compare a comparable type
with None. For all other cases, such as comparing a value that isn't
comparable, we surround things with a try-catch and a debug logging
statement to allow things to continue.

Note that we could optimize what we're done further by building a key
value that covers all indexes, rather than using a for loop to do so.
For example:

  >>> x = [('baz', 2), (None, 0), ('bar', 3), ('baz', 4), ('qux', 0)]
  >>> sorted(x, key=lambda k: list(
  ...     itertools.chain((k[i] is None, k[i]) for i in (0, 1)))
  ... )
  [('bar', 3), ('baz', 2), ('baz', 4), ('qux', 0), (None, 0)]

However, this would be harder to grok and would also mean we're unable
to handle exceptions on a single column where e.g. there are mixed types
or types that are not comparable while still sorting on the other
columns. Perhaps this would be desirable for some users, but sorting on
a best-effort basis does seem wiser and generally more user friendly.
Anyone that wants to sort on such columns should ensure their types are
comparable or implement their own sorting implementation.

[1] https://www.kite.com/python/answers/how-to-sort-by-two-keys-in-python

Change-Id: I4803051a6dd05c143a15923254af97e32cd39693
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Story: 2008456
Task: 41466
",git fetch https://review.opendev.org/openstack/cliff refs/changes/54/772854/1 && git format-patch -1 --stdout FETCH_HEAD,"['cliff/lister.py', 'cliff/tests/test_lister.py', 'releasenotes/notes/handle-none-values-when-sorting-de40e36c66ad95ca.yaml']",3,609b2fc987664b77a51ab9f099461440a04202f9,sort-dir,"--- fixes: - | Sorting output using the ``--sort-column`` option will now handle ``None`` values. This was supported implicitly in Python 2 but was broken in the move to Python 3. In addition, requests to sort a column containing non-comparable types will now be ignored. Previously, these request would result in a ``TypeError``. ",,73,7
openstack%2Fnova~master~I1c2e87f4ff4f7115611f33ee7ddb4820309ef104,openstack/nova,master,I1c2e87f4ff4f7115611f33ee7ddb4820309ef104,db: Compact Pike database migrations,MERGED,2020-10-21 15:52:33.000000000,2021-02-09 18:45:59.000000000,2021-02-09 18:34:15.000000000,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-10-21 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8644de638dca3181bc8b435fd2676697cb13c210', 'message': ""db: Compact Pike database migrations\n\nCompact Pike database migrations into a single migration, '362_pike.py'.\n\nUsers will now need to update to Pike before updating to Queens or\nlater.\n\nSpecific changes include:\n\n- Add 'attachment_id' column to 'block_device_mapping' table (358)\n- Add 'uuid' column to 'services' table (359)\n- Add index covering 'uuid' column of 'services' table (359)\n- Add 'mapped' column to 'compute_nodes' table (360)\n- Add index covering 'uuid' column of 'compute_nodes' table (361)\n- Add 'uuid' column to 'pci_devices' table (362)\n\nChange-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-10-22 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f320d857584e7aa0904a7a0349c402fd3273d30', 'message': ""db: Compact Pike database migrations\n\nCompact Pike database migrations into a single migration, '362_pike.py'.\n\nUsers will now need to update to Pike before updating to Queens or\nlater.\n\nSpecific changes include:\n\n- Add 'attachment_id' column to 'block_device_mapping' table (358)\n- Add 'uuid' column to 'services' table (359)\n- Add index covering 'uuid' column of 'services' table (359)\n- Add 'mapped' column to 'compute_nodes' table (360)\n- Add index covering 'uuid' column of 'compute_nodes' table (361)\n- Add 'uuid' column to 'pci_devices' table (362)\n\nChange-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-10-23 10:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f33442bb4d5bb6d448cf21a55555e971ba6a6e55', 'message': ""db: Compact Pike database migrations\n\nCompact Pike database migrations into a single migration, '362_pike.py'.\n\nUsers will now need to update to Pike before updating to Queens or\nlater.\n\nSpecific changes include:\n\n- Add 'attachment_id' column to 'block_device_mapping' table (358)\n- Add 'uuid' column to 'services' table (359)\n- Add index covering 'uuid' column of 'services' table (359)\n- Add 'mapped' column to 'compute_nodes' table (360)\n- Add index covering 'uuid' column of 'compute_nodes' table (361)\n- Add 'uuid' column to 'pci_devices' table (362)\n\nChange-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-10-28 11:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b16068dab8ffb5275a2934ab0f25c9b285c867eb', 'message': ""db: Compact Pike database migrations\n\nCompact Pike database migrations into a single migration, '362_pike.py'.\n\nUsers will now need to update to Pike before updating to Queens or\nlater.\n\nSpecific changes include:\n\n- Add 'attachment_id' column to 'block_device_mapping' table (358)\n- Add 'uuid' column to 'services' table (359)\n- Add index covering 'uuid' column of 'services' table (359)\n- Add 'mapped' column to 'compute_nodes' table (360)\n- Add index covering 'uuid' column of 'compute_nodes' table (361)\n- Add 'uuid' column to 'pci_devices' table (362)\n\nChange-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2021-01-07 11:47:59.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/362_pike.py', 'nova/db/sqlalchemy/migrate_repo/versions/361_add_compute_nodes_uuid_index.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/353_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/351_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/360_add_compute_node_mapped.py', 'nova/db/sqlalchemy/migrate_repo/versions/354_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/356_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/357_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/352_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/349_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/350_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/362_add_pci_devices_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/348_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/355_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/358_bdm_attachment_id.py', 'nova/db/sqlalchemy/migrate_repo/versions/359_add_service_uuid.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7674fc6cd8b1467a345cb61ca8a0db337a8b4198', 'message': ""db: Compact Pike database migrations\n\nCompact Pike database migrations into a single migration, '362_pike.py'.\n\nUsers will now need to update to Pike before updating to Queens or\nlater.\n\nSpecific changes include:\n\n- Add 'attachment_id' column to 'block_device_mapping' table (358)\n- Add 'uuid' column to 'services' table (359)\n- Add index covering 'uuid' column of 'services' table (359)\n- Add 'mapped' column to 'compute_nodes' table (360)\n- Add index covering 'uuid' column of 'compute_nodes' table (361)\n- Add 'uuid' column to 'pci_devices' table (362)\n\nChange-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,759087,7674fc6cd8b1467a345cb61ca8a0db337a8b4198,89,14,5,15334,,,0,"db: Compact Pike database migrations

Compact Pike database migrations into a single migration, '362_pike.py'.

Users will now need to update to Pike before updating to Queens or
later.

Specific changes include:

- Add 'attachment_id' column to 'block_device_mapping' table (358)
- Add 'uuid' column to 'services' table (359)
- Add index covering 'uuid' column of 'services' table (359)
- Add 'mapped' column to 'compute_nodes' table (360)
- Add index covering 'uuid' column of 'compute_nodes' table (361)
- Add 'uuid' column to 'pci_devices' table (362)

Change-Id: I1c2e87f4ff4f7115611f33ee7ddb4820309ef104
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/759087/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/362_pike.py', 'nova/db/sqlalchemy/migrate_repo/versions/361_add_compute_nodes_uuid_index.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/353_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/351_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/360_add_compute_node_mapped.py', 'nova/db/sqlalchemy/migrate_repo/versions/354_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/356_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/357_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/352_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/349_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/350_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/362_add_pci_devices_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/348_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/355_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/358_bdm_attachment_id.py', 'nova/db/sqlalchemy/migrate_repo/versions/359_add_service_uuid.py']",18,8644de638dca3181bc8b435fd2676697cb13c210,bp/compact-db-migrations-wallaby,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Column from sqlalchemy.engine.reflection import Inspector from sqlalchemy import Index from sqlalchemy import MetaData from sqlalchemy import String from sqlalchemy import Table def upgrade(migrate_engine): meta = MetaData(bind=migrate_engine) for prefix in ('', 'shadow_'): services = Table(prefix + 'services', meta, autoload=True) if not hasattr(services.c, 'uuid'): services.create_column(Column('uuid', String(36), nullable=True)) uuid_index_name = 'services_uuid_idx' indexes = Inspector(migrate_engine).get_indexes('services') if uuid_index_name not in (i['name'] for i in indexes): services = Table('services', meta, autoload=True) Index(uuid_index_name, services.c.uuid, unique=True).create() ",8,415
openstack%2Fcliff~master~Ib4784d9da96d05a54acdfbb3744af0cb053c0c6c,openstack/cliff,master,Ib4784d9da96d05a54acdfbb3744af0cb053c0c6c,Remove lower-constraints,MERGED,2021-01-28 11:03:01.000000000,2021-02-09 18:45:47.000000000,2021-02-09 18:34:55.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-01-28 11:03:01.000000000', 'files': ['.zuul.yaml', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cliff/commit/b04cba81ac966717472ae714b6c65c9cc7535978', 'message': ""Remove lower-constraints\n\nThis is not part of the PTI and is currently broken. While discussions\nare ongoing about removing it from every project, there's a definite\nlean towards doing so. Let's do just that. We can re-add in the future\nif necessary.\n\nWhile we're here, we fix some indentation in 'tox.ini'.\n\nChange-Id: Ib4784d9da96d05a54acdfbb3744af0cb053c0c6c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,772853,b04cba81ac966717472ae714b6c65c9cc7535978,8,3,1,15334,,,0,"Remove lower-constraints

This is not part of the PTI and is currently broken. While discussions
are ongoing about removing it from every project, there's a definite
lean towards doing so. Let's do just that. We can re-add in the future
if necessary.

While we're here, we fix some indentation in 'tox.ini'.

Change-Id: Ib4784d9da96d05a54acdfbb3744af0cb053c0c6c
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/cliff refs/changes/53/772853/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'lower-constraints.txt', 'tox.ini']",3,b04cba81ac966717472ae714b6c65c9cc7535978,sort-dir, VIRTUAL_ENV={envdir} OS_STDOUT_CAPTURE=1 OS_STDERR_CAPTURE=1 OS_TEST_TIMEOUT=60 {[testenv]setenv} PYTHON=coverage run --source cliff --parallel-mode stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml, VIRTUAL_ENV={envdir} OS_STDOUT_CAPTURE=1 OS_STDERR_CAPTURE=1 OS_TEST_TIMEOUT=60[testenv:lower-constraints] deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt {[testenv]setenv} PYTHON=coverage run --source cliff --parallel-mode stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml,10,50
openstack%2Fcliff~master~I27a3689c2e22452c082764eed8d26cd8f3bbcd13,openstack/cliff,master,I27a3689c2e22452c082764eed8d26cd8f3bbcd13,gitignore: Ignore reno artefacts,MERGED,2020-12-10 11:00:58.000000000,2021-02-09 18:35:18.000000000,2021-02-09 18:35:18.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-12-10 11:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/ab038ff149494c86f8c2f6e5f13aa8ef34b0e0d7', 'message': 'gitignore: Ignore reno artefacts\n\nChange-Id: I27a3689c2e22452c082764eed8d26cd8f3bbcd13\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2020-12-10 16:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/cb736f4927a9580ab59cb182d26b5e9ce05aaaa5', 'message': 'gitignore: Ignore reno artefacts\n\nChange-Id: I27a3689c2e22452c082764eed8d26cd8f3bbcd13\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2021-01-28 11:03:01.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/cliff/commit/36134739396213fa11d1c4ca1e9cacb8f40215eb', 'message': 'gitignore: Ignore reno artefacts\n\nChange-Id: I27a3689c2e22452c082764eed8d26cd8f3bbcd13\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,766451,36134739396213fa11d1c4ca1e9cacb8f40215eb,10,3,3,15334,,,0,"gitignore: Ignore reno artefacts

Change-Id: I27a3689c2e22452c082764eed8d26cd8f3bbcd13
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/cliff refs/changes/51/766451/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,ab038ff149494c86f8c2f6e5f13aa8ef34b0e0d7,sort-dir,# reno output RELEASENOTES.rst releasenotes/notes/reno.cache ,#Mr Developer .mr.developer.cfg #sample output *.log *.log.* ,4,7
openstack%2Fcliff~master~I040fccd1714dccd7a87aaf10d397ad3a3ef476d3,openstack/cliff,master,I040fccd1714dccd7a87aaf10d397ad3a3ef476d3,Remove unicode from code,MERGED,2021-01-03 07:38:19.000000000,2021-02-09 18:35:01.000000000,2021-02-09 18:35:01.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 07:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/3f141a5c26759c2ca87291c1208a7e1fd523d9b9', 'message': 'Remove unicode from code\n\nChange-Id: I040fccd1714dccd7a87aaf10d397ad3a3ef476d3\n'}, {'number': 2, 'created': '2021-01-28 17:00:45.000000000', 'files': ['cliff/tests/test_columns.py', 'cliff/tests/test_app.py', 'doc/source/conf.py', 'demoapp/cliffdemo/encoding.py', 'cliff/tests/test_formatters_csv.py', 'cliff/formatters/value.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/0d18e8812cfead09c0ce1dfbc213c4200a5ee230', 'message': 'Remove unicode from code\n\nChange-Id: I040fccd1714dccd7a87aaf10d397ad3a3ef476d3\n'}]",0,768979,0d18e8812cfead09c0ce1dfbc213c4200a5ee230,12,2,2,30092,,,0,"Remove unicode from code

Change-Id: I040fccd1714dccd7a87aaf10d397ad3a3ef476d3
",git fetch https://review.opendev.org/openstack/cliff refs/changes/79/768979/2 && git format-patch -1 --stdout FETCH_HEAD,"['cliff/tests/test_columns.py', 'cliff/tests/test_app.py', 'doc/source/conf.py', 'cliff/tests/test_formatters_csv.py', 'demoapp/cliffdemo/encoding.py', 'cliff/formatters/value.py']",6,3f141a5c26759c2ca87291c1208a7e1fd523d9b9,, for c in row) + '\n'), for c in row) + u'\n'),18,18
openstack%2Ftripleo-ansible~master~I3650a68640a0ec846be24014ebc6a71110b2f6f7,openstack/tripleo-ansible,master,I3650a68640a0ec846be24014ebc6a71110b2f6f7,Fix molecule jobs after release of cryptography3.4,MERGED,2021-02-09 12:52:30.000000000,2021-02-09 18:28:20.000000000,2021-02-09 18:28:20.000000000,"[{'_account_id': 7353}, {'_account_id': 8297}, {'_account_id': 8833}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-02-09 12:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a84506f5a57887aa42f7978938aaa28c8eea83dd', 'message': 'Install pip from source\n\nMolecule job[0] fails with below error:-\n\nModuleNotFoundError: No module named \'setuptools_rust\'\n\nThis error appeared following the release of cryptography 3.4, which\nnow includes Rust code. It can be installed without Rust using a\nPython wheel, but only with more recent pip than version 9.0.3\navailable as RPM on CentOS 8.\n\nThe cryptography bug report [1] recommends pip>=19.1.1.\n\nWith this patch we are passing  ""ensure_pip_from_upstream: true"" to\nensure-pip role to install pip from source.\n\n[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt\n[1] https://github.com/pyca/cryptography/issues/5753\nRelated-Bug: #1915101\n\nChange-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7\n'}, {'number': 2, 'created': '2021-02-09 14:54:04.000000000', 'files': ['zuul.d/playbooks/pre.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f8a286cf3014c05105075d033178172ac030dcb6', 'message': ""Fix molecule jobs after release of cryptography3.4\n\nMolecule jobs[0] fails with below error:-\n\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which\nnow includes Rust code. It can be installed without Rust using a\nPython wheel, but only with more recent pip than version 9.0.3\navailable as RPM on CentOS 8.\n\nThe cryptography bug report [1] recommends pip>=19.1.1.\n\n[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt\n[1] https://github.com/pyca/cryptography/issues/5753\nRelated-Bug: #1915101\n\nChange-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7\n""}]",1,774637,f8a286cf3014c05105075d033178172ac030dcb6,12,9,2,29775,,,0,"Fix molecule jobs after release of cryptography3.4

Molecule jobs[0] fails with below error:-

ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which
now includes Rust code. It can be installed without Rust using a
Python wheel, but only with more recent pip than version 9.0.3
available as RPM on CentOS 8.

The cryptography bug report [1] recommends pip>=19.1.1.

[0] https://e99635be2c7386b5beda-3dea60a35fb0d38e41c535f13b48e895.ssl.cf1.rackcdn.com/773531/1/gate/tripleo-ansible-centos-8-molecule-tripleo_network_config/b1284cd/job-output.txt
[1] https://github.com/pyca/cryptography/issues/5753
Related-Bug: #1915101

Change-Id: I3650a68640a0ec846be24014ebc6a71110b2f6f7
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/37/774637/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/pre.yml'],1,a84506f5a57887aa42f7978938aaa28c8eea83dd,bug/1915101, vars: ensure_pip_from_upstream: true,,2,0
openstack%2Fmonasca-common~master~Iea1d4fa42159984efff262d459292e5c6f941504,openstack/monasca-common,master,Iea1d4fa42159984efff262d459292e5c6f941504,Bump librdkafka to 1.6.0,MERGED,2021-02-09 15:48:43.000000000,2021-02-09 18:23:40.000000000,2021-02-09 18:23:40.000000000,"[{'_account_id': 22348}, {'_account_id': 28062}]","[{'number': 1, 'created': '2021-02-09 15:48:43.000000000', 'files': ['docker/Dockerfile'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/f59a2f296ea9d2ff255de75ff39f7c807b755481', 'message': 'Bump librdkafka to 1.6.0\n\nPackage confluent-kafka-python v1.6.0 requires librdkafka >= 1.6.0\n\nChange-Id: Iea1d4fa42159984efff262d459292e5c6f941504\n'}]",0,774690,f59a2f296ea9d2ff255de75ff39f7c807b755481,8,2,1,28062,,,0,"Bump librdkafka to 1.6.0

Package confluent-kafka-python v1.6.0 requires librdkafka >= 1.6.0

Change-Id: Iea1d4fa42159984efff262d459292e5c6f941504
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/90/774690/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/Dockerfile'],1,f59a2f296ea9d2ff255de75ff39f7c807b755481,, # For librdkafka bigger than v1.6.0 we need newer versions of some curl https://codeload.github.com/edenhill/librdkafka/tar.gz/v1.6.0 | tar xzf - -C /tmp/ && \ cd /tmp/librdkafka-1.6.0/ && \, # For librdkafka bigger than v1.4.0 we need newer versions of some curl https://codeload.github.com/edenhill/librdkafka/tar.gz/v1.4.0 | tar xzf - -C /tmp/ && \ cd /tmp/librdkafka-1.4.0/ && \,3,3
openstack%2Fheat~master~Ie271e208027a4c28416b41c2445591aafc7363e9,openstack/heat,master,Ie271e208027a4c28416b41c2445591aafc7363e9,WIP do not merge! removed all the to be deprecated policies and fixed the enforcement to see how the gates behave,NEW,2021-01-25 08:40:44.000000000,2021-02-09 18:13:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-25 08:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a0681ba0cf9740cfcde82cc3563eb57910e2b6bb', 'message': 'WIP do not merge! removed all the to be deprecated policies\nand fixed the enforcement to see how the gates behave\n\nChange-Id: Ie271e208027a4c28416b41c2445591aafc7363e9\n'}, {'number': 2, 'created': '2021-02-01 14:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d95c2d77ac0f3a595d40e5268db7d4cf746f9674', 'message': ""WIP do not merge! removed all the to be deprecated policies\nand fixed the enforcement to see how the gates behave\n\nThings are broken but that's fine.\n\nChange-Id: Ie271e208027a4c28416b41c2445591aafc7363e9\n""}, {'number': 3, 'created': '2021-02-05 14:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0d4eac586bc7d5c466055a81321cef0884b9e36c', 'message': ""WIP do not merge! removed all the to be deprecated policies\nand fixed the enforcement to see how the gates behave\n\nThings are broken but that's fine.\n\nChange-Id: Ie271e208027a4c28416b41c2445591aafc7363e9\n""}, {'number': 4, 'created': '2021-02-09 16:41:46.000000000', 'files': ['heat/tests/api/openstack_v1/test_stacks.py', 'heat/policies/events.py', 'heat/policies/build_info.py', 'heat/tests/test_common_policy.py', 'heat/api/openstack/v1/util.py', 'heat/common/policy.py', 'heat/policies/service.py', 'heat/policies/actions.py', 'heat/tests/api/openstack_v1/tools.py', 'heat/policies/base.py', 'heat/policies/cloudformation.py', 'heat/tests/api/openstack_v1/test_util.py', 'heat/common/context.py', 'heat/policies/software_deployments.py', 'heat/policies/stacks.py', 'heat/tests/test_acl_existing.yaml', 'heat/tests/test_common_context.py', 'heat/policies/resource.py', 'heat/policies/software_configs.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f78598d01c3af48c81aa6b447273789a35802fa2', 'message': ""WIP do not merge! removed all the to be deprecated policies\nand fixed the enforcement to see how the gates behave\n\nThings are broken but that's fine.\n\nChange-Id: Ie271e208027a4c28416b41c2445591aafc7363e9\n""}]",47,772258,f78598d01c3af48c81aa6b447273789a35802fa2,17,1,4,15895,,,0,"WIP do not merge! removed all the to be deprecated policies
and fixed the enforcement to see how the gates behave

Things are broken but that's fine.

Change-Id: Ie271e208027a4c28416b41c2445591aafc7363e9
",git fetch https://review.opendev.org/openstack/heat refs/changes/58/772258/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/policies/events.py', 'heat/policies/build_info.py', 'heat/tests/test_common_policy.py', 'heat/api/openstack/v1/util.py', 'heat/policies/service.py', 'heat/policies/actions.py', 'heat/policies/base.py', 'heat/policies/cloudformation.py', 'heat/policies/software_deployments.py', 'heat/policies/stacks.py', 'heat/tests/test_acl_existing.yaml', 'heat/policies/resource.py', 'heat/policies/software_configs.py']",13,a0681ba0cf9740cfcde82cc3563eb57910e2b6bb,secure-rbac, ] ] ] ] ],"deprecated_global_index = policy.DeprecatedRule( name=POLICY_ROOT % 'global_index', check_str=base.RULE_DENY_EVERYBODY ) deprecated_index = policy.DeprecatedRule( name=POLICY_ROOT % 'index', check_str=base.RULE_DENY_STACK_USER ) deprecated_create = policy.DeprecatedRule( name=POLICY_ROOT % 'create', check_str=base.RULE_DENY_STACK_USER ) deprecated_show = policy.DeprecatedRule( name=POLICY_ROOT % 'show', check_str=base.RULE_DENY_STACK_USER ) deprecated_delete = policy.DeprecatedRule( name=POLICY_ROOT % 'delete', check_str=base.RULE_DENY_STACK_USER ) ], deprecated_rule=deprecated_global_index, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY ], deprecated_rule=deprecated_index, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY ], deprecated_rule=deprecated_create, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY ], deprecated_rule=deprecated_show, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY ], deprecated_rule=deprecated_delete, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY",87,585
openstack%2Foslo.messaging~master~Id5cddbefbe24ef100f1cc522f44430df77d217cb,openstack/oslo.messaging,master,Id5cddbefbe24ef100f1cc522f44430df77d217cb,Correctly handle missing RabbitMQ queues,MERGED,2021-01-18 15:12:15.000000000,2021-02-09 18:04:14.000000000,2021-02-09 18:01:29.000000000,"[{'_account_id': 8770}, {'_account_id': 9257}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 31245}]","[{'number': 1, 'created': '2021-01-18 15:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ee758f0b00960a08167d4dcaf591930ab3bb013c', 'message': ""[WIP] Allow to loop for timeout when a MessageUndeliverable is caught\n\nMessageUnderliverable exception have been introduced by recently added\nmandatory flag feature, however clients aren't prepared to handle\nrecover on their side and so it doesn't lets a chance to the requester to\nrestablishes itself.\n\nThese changes leave the mandatory flag feature as it was implemented\nhowever they add the possibility to also define `at_least_once` in\nconfiguration to allow to loop for a timeout while a message remains\nunderliverable, as did with AMQPDestinationNotFound exception.\n\nIf the client explicitly set at_least_once=True, then when\nMessageUndeliverable is raised, we re-raise it back to the\nclient, with the assumption that it knows how to handle it.\n\nIf the client did not explicitly ask for it (the current case where nova\nand such do not use this API), then we can still use the\nfunctionality (the mandatory flag) within oslo.messaging, but we catch\nit and not re-raise it, the same way AMQPDestinationNotFound works currently.\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 2, 'created': '2021-01-21 09:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f3b875c35305dc418e08c3cdabfeae90bfd1b115', 'message': ""[WIP] Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 3, 'created': '2021-01-22 10:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/306a9e53b1137eec0a112dd99fd51a86c51313cd', 'message': ""[WIP] Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 4, 'created': '2021-01-22 10:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5f840d5984390389e809ac6cb41e96495c5e145e', 'message': ""[WIP] Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 5, 'created': '2021-01-22 10:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1f1bbe16543fd36e7b99bfe4fae7bdc4e611262d', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 6, 'created': '2021-01-22 10:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/37c405c5af381b9a6c69645f0652239146855a59', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 7, 'created': '2021-01-22 11:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e6b2805915aeffbb884619006331d12314c11920', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\n""}, {'number': 8, 'created': '2021-01-22 13:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c1cf0ff4050a883a0f9bfa9b925d6890c4ad8c33', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nCloses-Bug: #1905965\n""}, {'number': 9, 'created': '2021-01-25 20:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7e5f7dc5b5eb4d85398bf2172c95295d08a50eb7', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nCloses-Bug: #1905965\n""}, {'number': 10, 'created': '2021-02-01 09:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/55fc4ec21eb06e82640056fde6640df4281f16bc', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nCloses-Bug: #1905965\n""}, {'number': 11, 'created': '2021-02-02 15:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/61470013d64a287d4ba9382786758282195c8f77', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nCloses-Bug: #1905965\n""}, {'number': 12, 'created': '2021-02-03 14:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/57e6ba879ec1a19f142c50134367b4d512f223e7', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\nThe mandatory flag is deprecated since oslo.messaging 12.7.0\n(the last version of oslo.messaging c.f the depends-on below).\nThese changes want to drop the mandatory flag feature ASAP to avoid\nadoption as services aren't not really ready to handle MessageUndeliverable\nexception on their own. Also we want to abandon it quickly to avoid\nbacks and forths with related config and avoid to mislead users.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nDepends-On: ihttps://review.opendev.org/c/openstack/releases/+/773895\nCloses-Bug: #1905965\n""}, {'number': 13, 'created': '2021-02-03 15:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/81edc2267a305f04d6ec21dd21def6f8a1a6f7f7', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\nAlso these changes drop the deactivation mechanism\n(direct_mandatory_flag) as it doesn't really make sense to ignore\nmissing queues.\n\nThe mandatory flag is deprecated since oslo.messaging 12.7.0\n(the last version of oslo.messaging c.f the depends-on below).\nThese changes want to drop the mandatory flag feature ASAP to avoid\nadoption as services aren't not really ready to handle MessageUndeliverable\nexception on their own. Also we want to abandon it quickly to avoid\nbacks and forths with related config and avoid to mislead users.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nDepends-On: ihttps://review.opendev.org/c/openstack/releases/+/773895\nCloses-Bug: #1905965\n""}, {'number': 14, 'created': '2021-02-03 15:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/96315f51b2167902a7f7413fab939abb7c38f573', 'message': 'Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nThe MessageUndeliverable would normally by raised only at a more low\nlevel than a 404 error, if a queue is missing we will catch a\nMessageUndeliverable exception, and if an exchange is missing then we\nwill catch a 404 errors, so I think they can live together.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nDepends-On: ihttps://review.opendev.org/c/openstack/releases/+/773895\nCloses-Bug: #1905965\n'}, {'number': 15, 'created': '2021-02-03 16:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/17b36bc1ceb1b4fa43caf36873aa54dc13dbc703', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nCurrently, setting the '[oslo_messaging] direct_mandatory_flag' config\noption to 'True' (the default) will result in a 'MessageUndeliverable'\nexception being raised when sending a reply if a RabbitMQ queue is missing.\nIt was the responsibility of the application to handle this exception,\nhowever, many applications are not doing so. This has resulted in a\nnumber of bug reports.\n\nStart handling this error condition, using a retry loop to attempt to resend\nthe message and work around any temporary glitches. Since attempting to send\na reply will will no longer raise an exception, there is little benefit in\nretaining the '[oslo_messaging] direct_mandatory_flag' config option, since\nusers setting this to False will not benefit from the retry logic and\nimproved logging added here. As a result, This option is already deprecated\nand will be fully removed in a future release.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nDepends-On: ihttps://review.opendev.org/c/openstack/releases/+/773895\nCloses-Bug: #1905965\n""}, {'number': 16, 'created': '2021-02-04 08:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d6c1405cab5dc973232cf177b8108543dac62355', 'message': ""Allow to manage missing queue\n\nMessageUndeliverable inform us that a queue is missing so we can handle\nthat to provide more fine grained retries.\n\nUntil now our retry strategy was based on 404 errors that could\nreflect a missing exchange or a missing queue [1]. By using the\nmandatory flag/MessageUndeliverable we can isolate queue issue and keep\nAMQPDestinationNotFound/404 errors to handle missing exchange case.\n\nCurrently, setting the '[oslo_messaging] direct_mandatory_flag' config\noption to 'True' (the default) will result in a 'MessageUndeliverable'\nexception being raised when sending a reply if a RabbitMQ queue is missing.\nIt was the responsibility of the application to handle this exception,\nhowever, many applications are not doing so. This has resulted in a\nnumber of bug reports.\n\nStart handling this error condition, using a retry loop to attempt to resend\nthe message and work around any temporary glitches. Since attempting to send\na reply will will no longer raise an exception, there is little benefit in\nretaining the '[oslo_messaging] direct_mandatory_flag' config option, since\nusers setting this to False will not benefit from the retry logic and\nimproved logging added here. As a result, This option is already deprecated\nand will be fully removed in a future release.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nDepends-On: ihttps://review.opendev.org/c/openstack/releases/+/773895\nCloses-Bug: #1905965\n""}, {'number': 17, 'created': '2021-02-04 09:47:15.000000000', 'files': ['releasenotes/notes/handle-missing-queue-553a803f94976be7.yaml', 'oslo_messaging/_drivers/amqpdriver.py', 'doc/source/admin/rabbit.rst', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4937949dffecdf8863a7876e5a6b0b18e811c3ac', 'message': ""Correctly handle missing RabbitMQ queues\n\nCurrently, setting the '[oslo_messaging] direct_mandatory_flag' config\noption to 'True' (the default) will result in a 'MessageUndeliverable'\nexception being raised when sending a reply if a RabbitMQ queue is\nmissing [1]. It was the responsibility of the application to handle\nthis exception, however, many applications are not doing so. This has\nresulted in a number of bug reports.\n\nStart handling this error condition, using a retry loop to attempt to\nresend the message and work around any temporary glitches. Since\nattempting to send a reply will will no longer raise an exception,\nthere is little benefit in retaining the '[oslo_messaging]\ndirect_mandatory_flag' config option: users setting this to False will\nsimply not benefit from the retry logic and improved logging added\nhere. This option is already deprecated though and will be fully\nremoved in a future release.\n\n[1] https://www.rabbitmq.com/channels.html\n\nChange-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb\nCloses-Bug: #1905965\n""}]",22,771232,4937949dffecdf8863a7876e5a6b0b18e811c3ac,54,5,17,28522,,,0,"Correctly handle missing RabbitMQ queues

Currently, setting the '[oslo_messaging] direct_mandatory_flag' config
option to 'True' (the default) will result in a 'MessageUndeliverable'
exception being raised when sending a reply if a RabbitMQ queue is
missing [1]. It was the responsibility of the application to handle
this exception, however, many applications are not doing so. This has
resulted in a number of bug reports.

Start handling this error condition, using a retry loop to attempt to
resend the message and work around any temporary glitches. Since
attempting to send a reply will will no longer raise an exception,
there is little benefit in retaining the '[oslo_messaging]
direct_mandatory_flag' config option: users setting this to False will
simply not benefit from the retry logic and improved logging added
here. This option is already deprecated though and will be fully
removed in a future release.

[1] https://www.rabbitmq.com/channels.html

Change-Id: Id5cddbefbe24ef100f1cc522f44430df77d217cb
Closes-Bug: #1905965
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/32/771232/5 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/transport.py', 'oslo_messaging/rpc/server.py', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/impl_rabbit.py']",4,ee758f0b00960a08167d4dcaf591930ab3bb013c,bug/1905965, self.at_least_once = conf.at_least_once at_least_once=self.at_least_once), at_least_once=self.direct_mandatory_flag),27,5
openstack%2Fkuryr-kubernetes~master~Ic13393c841f04e6748f3fe716656cb5a8b3dcd71,openstack/kuryr-kubernetes,master,Ic13393c841f04e6748f3fe716656cb5a8b3dcd71,Make parse_network_policy_rules private.,MERGED,2021-02-08 12:06:02.000000000,2021-02-09 17:58:16.000000000,2021-02-09 17:56:14.000000000,"[{'_account_id': 11600}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2021-02-08 12:06:02.000000000', 'files': ['kuryr_kubernetes/controller/drivers/network_policy.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_network_policy.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2611dc3b3ab034dc850222e968930e0ce0f92861', 'message': ""Make parse_network_policy_rules private.\n\nNetwork policy parse_network_policy_rules is used only within the\nNetworkPolicyDriver class. Let's make it private, as it should be.\n\nAlso, changed layout of the code a bit, just to easily distinguish\nbetween helper methods from signature of the class.\n\nChange-Id: Ic13393c841f04e6748f3fe716656cb5a8b3dcd71\n""}]",0,774441,2611dc3b3ab034dc850222e968930e0ce0f92861,8,3,1,13692,,,0,"Make parse_network_policy_rules private.

Network policy parse_network_policy_rules is used only within the
NetworkPolicyDriver class. Let's make it private, as it should be.

Also, changed layout of the code a bit, just to easily distinguish
between helper methods from signature of the class.

Change-Id: Ic13393c841f04e6748f3fe716656cb5a8b3dcd71
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/41/774441/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/drivers/network_policy.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_network_policy.py']",2,2611dc3b3ab034dc850222e968930e0ce0f92861,np-ns-selectors, '_parse_network_policy_rules') '_parse_network_policy_rules') '_parse_network_policy_rules') self._driver._parse_network_policy_rules(self._policy) self._driver._parse_network_policy_rules(policy) self._driver._parse_network_policy_rules(policy) self._driver._parse_network_policy_rules(policy) self._driver._parse_network_policy_rules(policy), 'parse_network_policy_rules') 'parse_network_policy_rules') 'parse_network_policy_rules') self._driver.parse_network_policy_rules(self._policy) self._driver.parse_network_policy_rules(policy) self._driver.parse_network_policy_rules(policy) self._driver.parse_network_policy_rules(policy) self._driver.parse_network_policy_rules(policy),90,90
openstack%2Fironic-python-agent~stable%2Fvictoria~I155a47242b526b8f243a5e94bc14da8431f1ab91,openstack/ironic-python-agent,stable/victoria,I155a47242b526b8f243a5e94bc14da8431f1ab91,Mock tests to return bios boot mode,MERGED,2021-02-09 14:49:58.000000000,2021-02-09 17:46:21.000000000,2021-02-09 17:43:32.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 14:49:58.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_standby.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a820851fa800915b7bf948d9bc6ee4411e1f98c1', 'message': 'Mock tests to return bios boot mode\n\nWhen running IPA unit tests on machines configured\nwith UEFI and GPT partition table, some tests will\nfail.\n\nChange-Id: I155a47242b526b8f243a5e94bc14da8431f1ab91\n(cherry picked from commit d2495a092c2720eb4d7e795c9c03a9b217ab471e)\n'}]",0,774660,a820851fa800915b7bf948d9bc6ee4411e1f98c1,7,2,1,23851,,,0,"Mock tests to return bios boot mode

When running IPA unit tests on machines configured
with UEFI and GPT partition table, some tests will
fail.

Change-Id: I155a47242b526b8f243a5e94bc14da8431f1ab91
(cherry picked from commit d2495a092c2720eb4d7e795c9c03a9b217ab471e)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/60/774660/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/tests/unit/extensions/test_standby.py'],1,a820851fa800915b7bf948d9bc6ee4411e1f98c1,fix_unit_tests-stable/victoria," @mock.patch.object(utils, 'get_node_boot_mode', lambda self: 'bios') @mock.patch.object(utils, 'get_node_boot_mode', lambda self: 'bios') @mock.patch.object(utils, 'get_node_boot_mode', lambda self: 'bios')",,3,0
openstack%2Fopenstack-ansible-lxc_container_create~master~I631868db1d460bfbed88b74534b39855279a5384,openstack/openstack-ansible-lxc_container_create,master,I631868db1d460bfbed88b74534b39855279a5384,Openstack-Ansible Install Fails with OVS,ABANDONED,2017-11-07 05:50:27.000000000,2021-02-09 17:34:07.000000000,,"[{'_account_id': 15362}, {'_account_id': 16079}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 26445}, {'_account_id': 29392}]","[{'number': 1, 'created': '2017-11-07 05:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/30770c9653cb45a7d2f824a5bddf00311e390dad', 'message': '[WIP] Openstack-Ansible Install Fails with OVS\n\nThe initial wiring is required for veth interfaces with OVS bridge,\notherwise installation fails in creating provider networks.\n\nCloses-bug: 1708360\n\nChange-Id: I631868db1d460bfbed88b74534b39855279a5384\nSigned-off-by: Periyasamy Palanisamy <periyasamy.palanisamy@ericsson.com>\n'}, {'number': 2, 'created': '2017-11-08 14:00:28.000000000', 'files': ['files/lxc-veth-wiring.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/ff6d9f9632e0b5123a108eb11510693312104d33', 'message': 'Openstack-Ansible Install Fails with OVS\n\nThe initial wiring is required for veth interfaces with OVS bridge,\notherwise installation fails in creating provider networks.\n\nCloses-bug: 1708360\n\nChange-Id: I631868db1d460bfbed88b74534b39855279a5384\nSigned-off-by: Periyasamy Palanisamy <periyasamy.palanisamy@ericsson.com>\n'}]",7,518230,ff6d9f9632e0b5123a108eb11510693312104d33,21,6,2,26445,,,0,"Openstack-Ansible Install Fails with OVS

The initial wiring is required for veth interfaces with OVS bridge,
otherwise installation fails in creating provider networks.

Closes-bug: 1708360

Change-Id: I631868db1d460bfbed88b74534b39855279a5384
Signed-off-by: Periyasamy Palanisamy <periyasamy.palanisamy@ericsson.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/30/518230/2 && git format-patch -1 --stdout FETCH_HEAD,['files/lxc-veth-wiring.sh'],1,30770c9653cb45a7d2f824a5bddf00311e390dad,,"if [[ -x /usr/bin/ovs-vsctl ]]; then if ! ovs-vsctl list-ports ""${BRIDGE}"" | grep -q ""${VETH}""; then ovs-vsctl add-port ""${BRIDGE}"" ""{$VETH}"" EXIT=3 fi elif [[ -x /sbin/brctl ]]; then if ! brctl show ""${BRIDGE}"" | grep -q ""${VETH}""; then brctl addif ""${BRIDGE}"" ""${VETH}"" EXIT=3 fi","if ! brctl show ""${BRIDGE}"" | grep -q ""${VETH}""; then brctl addif ""${BRIDGE}"" ""${VETH}"" EXIT=3",10,3
openstack%2Fopenstack-ansible~master~Ida93dd2fa5724f61f266fef8be2618cc43989499,openstack/openstack-ansible,master,Ida93dd2fa5724f61f266fef8be2618cc43989499,Change haproxy galera backend to balance between all galera nodes,ABANDONED,2020-07-09 20:08:05.000000000,2021-02-09 17:29:36.000000000,,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32176}]","[{'number': 1, 'created': '2020-07-09 20:08:05.000000000', 'files': ['inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c5e9f87eba9de73d573ab674132decdda6e28d7b', 'message': ""Change haproxy galera backend to balance between all galera nodes\n\nIn the current HAProxy backend configuration for galera enables a backup\nmodel in which only the first galera node in the `galera_all` group is\nused and all other nodes in the group are enabled as backups in case the\nfirst one fails.\n\nI propose we change the HAProxy configuration to allow for load\nbalancing between all galera nodes by default, since galera allows for\nread/write operations on any node in the cluster anyhow. This will\nenhance performance of database operations and increase the number of\nsimultaneous connections to the galera cluster without having to modify\nmariadb's configuration.\n\nIf needed, we could instead add a snippet into the documentation\ndescribing potential ways to load balance across a galera cluster\ndepending on the use case, and use this change as an example.\n\nChange-Id: Ida93dd2fa5724f61f266fef8be2618cc43989499\n""}]",0,740355,c5e9f87eba9de73d573ab674132decdda6e28d7b,7,3,1,32176,,,0,"Change haproxy galera backend to balance between all galera nodes

In the current HAProxy backend configuration for galera enables a backup
model in which only the first galera node in the `galera_all` group is
used and all other nodes in the group are enabled as backups in case the
first one fails.

I propose we change the HAProxy configuration to allow for load
balancing between all galera nodes by default, since galera allows for
read/write operations on any node in the cluster anyhow. This will
enhance performance of database operations and increase the number of
simultaneous connections to the galera cluster without having to modify
mariadb's configuration.

If needed, we could instead add a snippet into the documentation
describing potential ways to load balance across a galera cluster
depending on the use case, and use this change as an example.

Change-Id: Ida93dd2fa5724f61f266fef8be2618cc43989499
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/55/740355/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/haproxy/haproxy.yml'],1,c5e9f87eba9de73d573ab674132decdda6e28d7b,feature-change-haproxy-galera-backend," haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([])) }}"" # list expected"," haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['galera_all'] | default([]))[1:] }}""",1,2
openstack%2Fvalidations-common~master~Ice9a3ddbced8562ab4c71d0331ace53b83f4fc93,openstack/validations-common,master,Ice9a3ddbced8562ab4c71d0331ace53b83f4fc93,Make the measuring code coverage test working,MERGED,2021-02-08 11:51:29.000000000,2021-02-09 17:25:35.000000000,2021-02-09 17:25:35.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-02-08 11:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/validations-common/commit/90851ddbb2bdf4027d602b232872db6c117d5017', 'message': 'Make the measuring code coverage test working\n\nChange-Id: Ice9a3ddbced8562ab4c71d0331ace53b83f4fc93\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2021-02-08 12:26:04.000000000', 'files': ['.gitignore', '.zuul.yaml', '.coveragerc', 'tox.ini', '.stestr.conf'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/4c610b35b9fd5bd20f98b02414c633bf67b38f66', 'message': 'Make the measuring code coverage test working\n\nChange-Id: Ice9a3ddbced8562ab4c71d0331ace53b83f4fc93\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",1,774440,4c610b35b9fd5bd20f98b02414c633bf67b38f66,13,5,2,11491,,,0,"Make the measuring code coverage test working

Change-Id: Ice9a3ddbced8562ab4c71d0331ace53b83f4fc93
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/40/774440/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.zuul.yaml', '.coveragerc', 'tox.ini', '.stestr.conf']",5,90851ddbb2bdf4027d602b232872db6c117d5017,coverage,test_path=${TEST_PATH:-./validations_common/tests},test_path=./validations_common/tests,30,13
openstack%2Ftripleo-ansible~master~I02541adfec2fa604e728aece343e7f0722b84ec6,openstack/tripleo-ansible,master,I02541adfec2fa604e728aece343e7f0722b84ec6,Write passwords to env file when rotating,MERGED,2021-02-05 03:06:36.000000000,2021-02-09 17:22:40.000000000,2021-02-09 17:22:40.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-05 03:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c3e121fc7c35231308cc963bdbb2ed53946d767b', 'message': ""Write passwords to env file when rotating\n\nNow that we've removed the plan, we should generate\nan environmnent file with rotated passwords which\nshould be used in the next overcloud deploy.\n\nWhen we move to ephemeral heat stack this would\nupdate wherever initial passwords are stored.\n\nChange-Id: I02541adfec2fa604e728aece343e7f0722b84ec6\n""}, {'number': 2, 'created': '2021-02-08 19:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d1583bf5da37a4c2ccf9418b8a16f3db7b1f3645', 'message': ""Write passwords to env file when rotating\n\nNow that we've removed the plan, we should generate\nan environmnent file with rotated passwords which\nshould be used in the next overcloud deploy.\n\nWhen we move to ephemeral heat stack this would\nupdate wherever initial passwords are stored.\n\nChange-Id: I02541adfec2fa604e728aece343e7f0722b84ec6\n""}, {'number': 3, 'created': '2021-02-09 02:44:34.000000000', 'files': ['tripleo_ansible/playbooks/rotate-passwords.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6b19ea5e3e9733f72675544c66a346bb914ef695', 'message': ""Write passwords to env file when rotating\n\nNow that we've removed the plan, we should generate\nan environmnent file with rotated passwords which\nshould be used in the next overcloud deploy.\n\nWhen we move to ephemeral heat stack this would\nupdate wherever initial passwords are stored.\n\nChange-Id: I02541adfec2fa604e728aece343e7f0722b84ec6\n""}]",8,774187,6b19ea5e3e9733f72675544c66a346bb914ef695,24,6,3,8833,,,0,"Write passwords to env file when rotating

Now that we've removed the plan, we should generate
an environmnent file with rotated passwords which
should be used in the next overcloud deploy.

When we move to ephemeral heat stack this would
update wherever initial passwords are stored.

Change-Id: I02541adfec2fa604e728aece343e7f0722b84ec6
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/87/774187/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/rotate-passwords.yaml'],1,c3e121fc7c35231308cc963bdbb2ed53946d767b,env_merging," stack: overcloud passwords_environment_path: rotated_passwords.yaml tasks: - name: Set passwords_environment_path set_fact: passwords_environment_path: ""{{ lookup('env', 'HOME')~'/rotated_passwords.yaml'}}"" when: passwords_environment_path is not defined - name: Rotate passwords register: rotated_passwords_result - name: Write environment to {{ passwords_environment_path }} block: - name: create derived params dictionary set_fact: passwords_params_env: ""{{ {'parameter_defaults': rotated_passwords_result['passwords'] | default({})} }}"" - name: Write environment copy: dest: ""{{ passwords_environment_path }}"" content: ""{{ passwords_params_env | to_nice_yaml(indent=2) }}"" when: - passwords_environment_path is defined - rotated_passwords_result is defined no_log: ""{{ hide_sensitive_logs | bool }}""", container: overcloud tasks: - name: Rotate passwords in plan,23,2
openstack%2Fcharm-mysql-innodb-cluster~master~I914e91f632c4670282febe24bc792429dfa28863,openstack/charm-mysql-innodb-cluster,master,I914e91f632c4670282febe24bc792429dfa28863,Disable scale-in/scale-out tests as unstable in gate,MERGED,2021-02-08 12:55:46.000000000,2021-02-09 17:22:02.000000000,2021-02-09 17:22:02.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2021-02-08 12:55:46.000000000', 'files': ['src/tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/19aa62006941cc49699b908af585e1f5aaf033aa', 'message': ""Disable scale-in/scale-out tests as unstable in gate\n\nThe gate is unstable as these tests sometimes pass and sometimes don't.\nThe linked bug will be used to track when to bring these tests back into\ngate.\n\nChange-Id: I914e91f632c4670282febe24bc792429dfa28863\nRelated-Bug: #1915016\n""}]",1,774443,19aa62006941cc49699b908af585e1f5aaf033aa,11,4,1,20870,,,0,"Disable scale-in/scale-out tests as unstable in gate

The gate is unstable as these tests sometimes pass and sometimes don't.
The linked bug will be used to track when to bring these tests back into
gate.

Change-Id: I914e91f632c4670282febe24bc792429dfa28863
Related-Bug: #1915016
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/43/774443/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/tests.yaml'],1,19aa62006941cc49699b908af585e1f5aaf033aa,bug/1915016,dev_bundles: - scale_in_out: groovy - scale_in_out: focal,- scale_in_out: groovy- scale_in_out: focal,3,2
openstack%2Foslo.policy~master~Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01,openstack/oslo.policy,master,Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01,Add nova/neutron project unit/functional tests job in gate,MERGED,2021-02-03 16:55:19.000000000,2021-02-09 17:14:10.000000000,2021-02-09 16:57:54.000000000,"[{'_account_id': 5046}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-03 16:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/f4ee743757cc039aafa2d275c63e683bc5235885', 'message': 'Add project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 2, 'created': '2021-02-03 17:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/627c1890e5a78d3bce50ab3b33fe0de966714f37', 'message': 'Add nova project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrnetly this commit adds only nova testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 3, 'created': '2021-02-03 17:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/943e52609bdf57f5c81aa91a875068203c24fcd1', 'message': 'Add nova project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrnetly this commit adds only nova testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 4, 'created': '2021-02-04 17:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/6c9e6529cf86b5da5ec02837bbed9bef1800661b', 'message': 'Add nova project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrnetly this commit adds only nova testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 5, 'created': '2021-02-04 21:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/a2469533b13fd562ea5713dacff4f6a4c60b8c65', 'message': 'Add nova project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrnetly this commit adds only nova testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 6, 'created': '2021-02-08 15:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/f77a3d62886b44c00da4be6a994322671fa69654', 'message': 'Add nova/neutron project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrently this commit adds only nova & neutron testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}, {'number': 7, 'created': '2021-02-08 17:06:51.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/d57dd1a7c377c94d2a5880ef271936d642cb06a5', 'message': 'Add nova/neutron project unit/functional tests job in gate\n\nWe do not test the olso policy master code changes with\nservices unit or functional tests. Tempest job initialize\npolicy once and run with default rules so it will not be able\nto catch all the scenario what unit or functional job does.\nThey initialize or override policy in parallel and sometime\nthat help to find the issue like\n- https://bugs.launchpad.net/oslo.policy/+bug/1914095\n\nAlso this will help us to avoid any new breaking release which\nis detected at the time when requirement u-c are updated\nExample: https://review.opendev.org/c/openstack/requirements/+/773779\n\nCurrently this commit adds only nova & neutron testing but we can add\nmore service testing later.\n\nChange-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01\n'}]",4,773947,d57dd1a7c377c94d2a5880ef271936d642cb06a5,33,5,7,8556,,,0,"Add nova/neutron project unit/functional tests job in gate

We do not test the olso policy master code changes with
services unit or functional tests. Tempest job initialize
policy once and run with default rules so it will not be able
to catch all the scenario what unit or functional job does.
They initialize or override policy in parallel and sometime
that help to find the issue like
- https://bugs.launchpad.net/oslo.policy/+bug/1914095

Also this will help us to avoid any new breaking release which
is detected at the time when requirement u-c are updated
Example: https://review.opendev.org/c/openstack/requirements/+/773779

Currently this commit adds only nova & neutron testing but we can add
more service testing later.

Change-Id: Ic54b229a4bf1325adac2cab747bcd19b9f8ecb01
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/47/773947/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f4ee743757cc039aafa2d275c63e683bc5235885,bug/1914095, check: jobs: - cross-cinder-py36 - cross-glance-py36 - cross-horizon-py36 - cross-keystone-py36 - cross-neutron-py36 - cross-nova-py36 - cross-nova-functional gate: jobs: - cross-cinder-py36 - cross-glance-py36 - cross-horizon-py36 - cross-keystone-py36 - cross-neutron-py36 - cross-nova-py36 - cross-nova-functional ,,19,0
openstack%2Fdevstack~stable%2Frocky~If97e5b709e4704d29692fddd25b818990bebec1e,openstack/devstack,stable/rocky,If97e5b709e4704d29692fddd25b818990bebec1e,DNM: testing tempest new run-tempest,ABANDONED,2021-01-18 17:46:12.000000000,2021-02-09 17:11:01.000000000,,"[{'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-01-18 17:46:12.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6f06af620ed7fabf9033365f5d67ae2c244218c2', 'message': 'DNM: testing tempest new run-tempest\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/768583\nChange-Id: If97e5b709e4704d29692fddd25b818990bebec1e\n'}]",0,771259,6f06af620ed7fabf9033365f5d67ae2c244218c2,11,2,1,8556,,,0,"DNM: testing tempest new run-tempest

Depends-On: https://review.opendev.org/c/openstack/tempest/+/768583
Change-Id: If97e5b709e4704d29692fddd25b818990bebec1e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/59/771259/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,6f06af620ed7fabf9033365f5d67ae2c244218c2,,#test,,1,0
openstack%2Fopenstack-ansible-tests~master~I351b3f2ae458abc14a899768a04999ca10c86ea4,openstack/openstack-ansible-tests,master,I351b3f2ae458abc14a899768a04999ca10c86ea4,Unpin virtualenv version,MERGED,2021-02-09 14:04:29.000000000,2021-02-09 17:04:16.000000000,2021-02-09 16:56:10.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-09 14:04:29.000000000', 'files': ['run_tests_common.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/7fb5312be3190306eaebf92b30c339c486c074cd', 'message': 'Unpin virtualenv version\n\nThis is required to allow the latest cryptography wheel to be\ninstalled from pypi\n\nChange-Id: I351b3f2ae458abc14a899768a04999ca10c86ea4\n'}]",0,774651,7fb5312be3190306eaebf92b30c339c486c074cd,8,3,1,25023,,,0,"Unpin virtualenv version

This is required to allow the latest cryptography wheel to be
installed from pypi

Change-Id: I351b3f2ae458abc14a899768a04999ca10c86ea4
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/51/774651/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests_common.sh'],1,7fb5312be3190306eaebf92b30c339c486c074cd,,"sudo ""${PIP_EXEC_PATH}"" install 'bindep>=2.4.0' tox","sudo ""${PIP_EXEC_PATH}"" install 'bindep>=2.4.0' tox 'virtualenv<20.2.2'",1,1
openstack%2Fkolla~master~Ib61768465a58e70af5ca43de80fbfb5099f51cac,openstack/kolla,master,Ib61768465a58e70af5ca43de80fbfb5099f51cac,doc: add wu.chunyang to list of core developers,MERGED,2021-02-09 09:34:06.000000000,2021-02-09 16:31:52.000000000,2021-02-09 16:29:42.000000000,"[{'_account_id': 14826}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-09 09:34:06.000000000', 'files': ['doc/source/contributor/contributing.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/383b1aef6f4ddd32f83cd700642e7c4769802e0d', 'message': 'doc: add wu.chunyang to list of core developers\n\nChange-Id: Ib61768465a58e70af5ca43de80fbfb5099f51cac\n'}]",0,774612,383b1aef6f4ddd32f83cd700642e7c4769802e0d,12,5,1,24072,,,0,"doc: add wu.chunyang to list of core developers

Change-Id: Ib61768465a58e70af5ca43de80fbfb5099f51cac
",git fetch https://review.opendev.org/openstack/kolla refs/changes/12/774612/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/contributing.rst'],1,383b1aef6f4ddd32f83cd700642e7c4769802e0d,,| `wu.chunyang`_ | wuchunyang | wuchunyang@yovole.com | +-----------------------+---------------+------------------------------------+.. _wu.chunyang: https://launchpad.net/~wuchunyang,,3,0
openstack%2Fneutron~stable%2Fvictoria~Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,openstack/neutron,stable/victoria,Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,Fix incorrect exception catch when update floating ip port forwarding,MERGED,2021-02-09 04:52:41.000000000,2021-02-09 16:16:56.000000000,2021-02-09 16:13:51.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 04:52:41.000000000', 'files': ['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2bad8cc18247d39403ddb826b4ff6ae7808cc11', 'message': 'Fix incorrect exception catch when update floating ip port forwarding\n\nCloses-Bug: #1912596\nChange-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c\n(cherry picked from commit e9e4395d578e40bb59272b409c7ca3617ec1e6e3)\n'}]",0,774487,d2bad8cc18247d39403ddb826b4ff6ae7808cc11,9,3,1,28329,,,0,"Fix incorrect exception catch when update floating ip port forwarding

Closes-Bug: #1912596
Change-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c
(cherry picked from commit e9e4395d578e40bb59272b409c7ca3617ec1e6e3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/774487/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py']",2,d2bad8cc18247d39403ddb826b4ff6ae7808cc11,bug/1912596-stable/victoria,from oslo_db import exception as oslo_db_exc except oslo_db_exc.DBDuplicateEntry:, except obj_exc.NeutronDbObjectDuplicateEntry:,60,1
openstack%2Fmagnum~master~I5581650b15ce94e31a44de09f82aef1790013b54,openstack/magnum,master,I5581650b15ce94e31a44de09f82aef1790013b54,4. Update cluster monitoring documentation,MERGED,2020-10-06 09:57:45.000000000,2021-02-09 16:13:35.000000000,2021-02-09 15:55:09.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-10-06 09:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e5858a0736321f6f8fee86051da2e85fdb82cefa', 'message': 'Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\n'}, {'number': 2, 'created': '2020-10-06 10:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/207b5eab03c7c148cf152caa2524161d12b2f137', 'message': 'Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\n'}, {'number': 3, 'created': '2020-10-06 12:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cd29b2e66f4c1070181d49aa7e22b8b631a5df74', 'message': 'Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\n'}, {'number': 4, 'created': '2020-10-06 12:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f7bed40c5bcf65e76b48501dfab598fd80a0d624', 'message': 'Update cluster monitoring documentation\n\nMove all the relevant monitoring documentation to a separate file.\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\n'}, {'number': 5, 'created': '2020-10-06 14:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d288ffcb695cb282a916fe83706248beaff5a4b1', 'message': 'Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\n'}, {'number': 6, 'created': '2021-02-05 15:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cf64a941e897d1c472ef66ff446bfbea37185a1f', 'message': '4. Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nDepends-On: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@gmail.com>\n'}, {'number': 7, 'created': '2021-02-05 16:02:12.000000000', 'files': ['doc/source/user/index.rst', 'doc/source/user/monitoring.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a3d8b4fe8ddc4e12dbd2e5bdf946effc0eab55c7', 'message': '4. Update cluster monitoring documentation\n\nChange the User Documentation to introduce the new way of installing\nthe prometheus monitoring suite by using label monitoring_enabled.\nGive a broad overview of the existent monitoring features available\nout-of-the-box and which components exist and what they do.\nExplain which FAQ can be solved with already existent integrations\nby manipulating monitoring specific labels.\n\ntask: 39627\nstory: 2006765\n\nDepends-On: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nChange-Id: I5581650b15ce94e31a44de09f82aef1790013b54\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@gmail.com>\n'}]",0,756238,a3d8b4fe8ddc4e12dbd2e5bdf946effc0eab55c7,20,4,7,29425,,,0,"4. Update cluster monitoring documentation

Change the User Documentation to introduce the new way of installing
the prometheus monitoring suite by using label monitoring_enabled.
Give a broad overview of the existent monitoring features available
out-of-the-box and which components exist and what they do.
Explain which FAQ can be solved with already existent integrations
by manipulating monitoring specific labels.

task: 39627
story: 2006765

Depends-On: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3
Change-Id: I5581650b15ce94e31a44de09f82aef1790013b54
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@gmail.com>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/38/756238/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'doc/source/user/monitoring.rst']",2,e5858a0736321f6f8fee86051da2e85fdb82cefa,monitoring,"As of this moment, monitoring is only supported for kubernetes clusters. Container Monitoring in Kubernetes ---------------------------------- The current monitoring capabilities that can be deployed with magnum span through different components. These are: * *metrics-server:* is responsible respond to metrics.k8s.io requests. This includes the most basic functionality when using simple HPA metrics or when using the *kubectl top* command * *prometheus:* is a full fledged service that allows the user to access advanced metrics capabilities. These metrics are collected with a resolution of 30 seconds and include resources such as CPU, Memory, Disk and Network IO as well as R/W rates. These metrics of fine granularity are available on your cluster for up to a period of 14 days (default). * *prometheus-adapter:* is an extra component that integrates with the prometheus service and allows a user to create more sophisticated `HPA <https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>`_ rules. The service integrates fully with the metrics.k8s.io API but at this time only custom.metrics.k8s.io is being actively used. The installation of these services is controlled with the following labels: _`metrics_server_enabled` This label accepts a boolean value. If *True*, the metrics-server will be installed. By default *metrics_server_enabled = True*. _`monitoring_enabled` This label accepts a boolean value. If *True*, the monitoring stack will be installed. By default *monitoring_enabled = False*. _`prometheus_adapter_enabled` This label accepts a boolean value. If *True*, the custom metrics API server will be configured. By default *prometheus_adapter_enabled = True*. Please note that this component depends on *monitoring_enabled = False*. Full fledged cluster monitoring +++++++++++++++++++++++++++++++ The prometheus installation provided with the _`monitoring_enabled` label is in fact a multi component service. This installation is managed with the prometheus-operator helm chart and the constituent components are: * prometheus (data collection, storage and search) ** node-exporter (data source for the kubelet/node) ** kube-state-metrics (data source for the running kubernetes objects {deployments, pods, nodes, etc}) * alertmanager (alarm aggregation, processing and dispatch) * grafana (metrics visualization) These components are installed in a generic way that makes it easy to have a cluster wide monitoring infrastructure running with no effort. .. warning:: The existent monitoring infra does not take into account the existence of nodegroups. If you plan to use nodegroups in your cluster you can take into account the maximum number of total nodes and use _`max_node_count` to correctly setup the prometheus server. .. note:: Before creating your cluster take into account the scale of the cluster. This is important as the Prometheus server pod might not fit your nodes. This is particularly important if you are using *Cluster Autoscaling* as the Prometheus server will schedule resources needed to meet the maximum number of nodes that your cluster can scale up to defined by label (if existent) _`max_node_count`. The Prometheus server will consume the following resources: :: RAM:: 256 (base) + Nodes * 40 [MB] CPU:: 128 (base) + Nodes * 7 [mCPU] Disk:: 15 GB for 2 weeks (depends on usage) Tuning parameters +++++++++++++++++ The existent setup configurations allows you to tune the metric infrastructure to your requisites. Below is a list of labels that can be used for specific cases: _`grafana_admin_passwd` This label lets users create their own *admin* user password for the Grafana interface. It expects a string value. By default it is set to *admin*. _`monitoring_retention_days` This label lets users specify the maximum retention time for data collected in the prometheus server in days. _`monitoring_interval_seconds` This label lets users specify the time between metric samples in seconds. _`monitoring_retention_size_gi` This label lets users specify the maximum size (in gigibytes) for data stored by the prometheus server. This label must be used together with `monitoring_storage_class_name`_ _`monitoring_storage_class_name` This label lets users specify the storage class to be used for the pvc instance that will be created for the prometheus server. Using this label will also create a 2GB pvc volume for the Grafana service enabling the use of dashboard persistency. _`monitoring_ingress_enabled` This label set's up all the underlying services to be accessible in a 'route by path' way. This means that the services will be exposed as: :: my.domain.com/alertmanager my.domain.com/prometheus my.domain.com/grafana This label must be used together with `cluster_root_domain_name`_ _`cluster_root_domain_name` This label sets the root domain name to be used when setting up path based routing for the underlying monitoring services. _`cluster_basic_auth_secret` This label can be used to setup basic authentication on the ingress lb when accessing the configured endpoints. To create this secret you can follow: :: $ htpasswd -c auth foo $ kubectl create secret generic basic-auth --from-file=auth _`prometheus_adapter_configmap` This label can be used to specify a user provided configmap to be used instead of the automatically configured one. ",,138,60
openstack%2Fbifrost~stable%2Fvictoria~I034bcd24031b5881ae49b8bc03bed6654cd1d335,openstack/bifrost,stable/victoria,I034bcd24031b5881ae49b8bc03bed6654cd1d335,Install at least pip version 19.1.1,MERGED,2021-02-09 13:59:57.000000000,2021-02-09 16:13:23.000000000,2021-02-09 15:58:16.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 13:59:57.000000000', 'files': ['scripts/install-deps.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1855fbdb9fa2d5e0a3cf4cbd0d254c52481d8c20', 'message': 'Install at least pip version 19.1.1\n\nThis is to avoid a known issue with a recent version of cryptography [1]\n\n[1] https://github.com/pyca/cryptography/issues/5771\n\nChange-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335\n(cherry picked from commit 5360d0e869daaa9bdb6ab0eeedfd1600453bfd4d)\n'}]",0,774659,1855fbdb9fa2d5e0a3cf4cbd0d254c52481d8c20,8,2,1,23851,,,0,"Install at least pip version 19.1.1

This is to avoid a known issue with a recent version of cryptography [1]

[1] https://github.com/pyca/cryptography/issues/5771

Change-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335
(cherry picked from commit 5360d0e869daaa9bdb6ab0eeedfd1600453bfd4d)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/59/774659/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/install-deps.sh'],1,1855fbdb9fa2d5e0a3cf4cbd0d254c52481d8c20,crypto_pip_workaround-stable/victoria,"# NOTE(rpittau): we need a stable recent version of pip to avoid issues with # the cryptography package. PIP_MIN_REQ=""19.1.1"" PIP_TUPLE=""(19, 1, 1)"" echo ""Installing Python and PIP""# NOTE(rpittau): we need a stable recent version of pip to avoid issues with # the cryptography package. PIP_REQUIRED=$($PYTHON -c ""import pip; print(tuple(map(int, pip.__version__.split('.'))) >= $PIP_TUPLE)"") if [[ $PIP_REQUIRED == ""False"" ]]; then ${PIP} install ""pip==$PIP_MIN_REQ"" fi","echo Installing Python and PIP$PYTHON << EOF import pip version = tuple(map(int, pip.__version__.split('.'))) assert version >= (7, 1) EOF",12,6
openstack%2Fsushy~master~I16eabdce9bb6e9303df8fb3baa48e490f4afa966,openstack/sushy,master,I16eabdce9bb6e9303df8fb3baa48e490f4afa966,Fix deprecation on collections.MutableMapping,MERGED,2021-02-09 08:27:09.000000000,2021-02-09 16:13:00.000000000,2021-02-09 15:58:19.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 08:27:09.000000000', 'files': ['sushy/main.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/d9004ec7d541d139f94bdb6e1be86f7492bba1fa', 'message': 'Fix deprecation on collections.MutableMapping\n\nPython 3.10 removes the deprecated aliases to collections abstract\nbase clases [1].\n\n[1] - https://bugs.python.org/issue37324\n\nChange-Id: I16eabdce9bb6e9303df8fb3baa48e490f4afa966\n'}]",0,774598,d9004ec7d541d139f94bdb6e1be86f7492bba1fa,9,2,1,13294,,,0,"Fix deprecation on collections.MutableMapping

Python 3.10 removes the deprecated aliases to collections abstract
base clases [1].

[1] - https://bugs.python.org/issue37324

Change-Id: I16eabdce9bb6e9303df8fb3baa48e490f4afa966
",git fetch https://review.opendev.org/openstack/sushy refs/changes/98/774598/1 && git format-patch -1 --stdout FETCH_HEAD,['sushy/main.py'],1,d9004ec7d541d139f94bdb6e1be86f7492bba1fa,,class LazyRegistries(collections.abc.MutableMapping):,class LazyRegistries(collections.MutableMapping):,1,1
openstack%2Fkolla-ansible~master~I12185b48dd98318ed9dce7b8e64633f4d73fd41c,openstack/kolla-ansible,master,I12185b48dd98318ed9dce7b8e64633f4d73fd41c,Add Ansible Role Zaqar,ABANDONED,2016-12-06 23:21:33.000000000,2021-02-09 16:12:12.000000000,,"[{'_account_id': 6484}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 16006}, {'_account_id': 16233}, {'_account_id': 19316}, {'_account_id': 21486}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22406}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 24164}, {'_account_id': 27336}, {'_account_id': 27781}, {'_account_id': 28176}]","[{'number': 1, 'created': '2016-12-06 23:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a9c9ae1b2fe28ca4baccb1801c7f3f8918d6200f', 'message': 'WIP: zaqar ansible\n\nDepends: #\nImplement-Blueprint: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 2, 'created': '2016-12-06 23:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e20b23f4d199a4f35cb4f77c3d3682dbd22cfe3b', 'message': 'WIP: zaqar ansible\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 3, 'created': '2016-12-08 17:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/461565273a3213185a8e772a7c0e85f3c2a9cc58', 'message': 'WIP: zaqar ansible\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 4, 'created': '2016-12-08 17:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/030e5df0209fb4e450e637d80ae771066af60e06', 'message': 'WIP: zaqar ansible\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 5, 'created': '2016-12-09 10:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/099a392471ead1818baa16fadfbd38341f145c1c', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 6, 'created': '2016-12-09 10:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6bb68ba78ba38800fa2beb3fcd35c2a8bbc385cb', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 7, 'created': '2016-12-09 12:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/64becaf7670b3b72addb631e0b78fd45145515f9', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 8, 'created': '2016-12-12 09:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5aaa9578691c6da121c19c8c4dec712d58345194', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 9, 'created': '2016-12-13 13:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f5567badc1ce74fcb215f0588211c14dae7e7b19', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 10, 'created': '2016-12-14 16:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9f2de221c2aceeb7fa487a155bb2c1ffad7f04d5', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 11, 'created': '2017-01-09 14:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ce7f7d3e37fba5150217fcb865adb1db35be74d4', 'message': 'Zaqar ansible role\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nDepends-On: I9c6716b64345d9e846902ffbfbf033135e3eabd9\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 12, 'created': '2018-10-12 09:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f593f565481f1c1cf313d7fa4f383420a8ee5c7a', 'message': '[WIP][DNM] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 13, 'created': '2018-10-16 10:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a15db9563de4a0f9476fd2d1d9f24fcbc1011a1c', 'message': '[WIP][DNM] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\nConfigure MongoDB as storage backend and wsgi\nfor transport backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/407760/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 14, 'created': '2018-10-22 10:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bb1b8f5bd3600bdb82e98694f197b65b429feada', 'message': '[WIP][DNM] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend..\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 15, 'created': '2018-10-23 04:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5c1f51159557faedbced6b44b2383bcfa52bb9d3', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend..\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 16, 'created': '2018-10-26 02:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a4fdb6aed731d732b75e245245674a916d9d83f6', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend..\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 17, 'created': '2018-10-26 03:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f0d294d75b3a5dc77e463bd4ff63dd48dbfc4315', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 18, 'created': '2018-10-26 12:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/87b5a73414e6f76fcfe2ba2e6fff8e2fdec025e4', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 19, 'created': '2018-10-28 03:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7828aa23b15695f5cfd6c5aa56adbfe12c64ff65', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 20, 'created': '2018-10-29 03:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fa7201c318d52679938098e41935aa0a4c481a26', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 21, 'created': '2018-10-29 04:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/94c7ee8123ce8940d64c99e73661ce696af2c836', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 22, 'created': '2018-10-29 04:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/efe5e68e62335358fc6edf0a3ca02f35d5d9a96d', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 23, 'created': '2018-10-29 08:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/640c57dedbe806e72a4f8acb84d708149e1f3b3f', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 24, 'created': '2018-10-30 01:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3d7aa1962e86b1c52db2d5d3d08e6c26f121a82b', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 25, 'created': '2018-10-30 03:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b49f4f0150c4403f32f118bc1d8a4e208a9bbe23', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 26, 'created': '2018-10-30 04:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c5957da5ac510dd3115546e4a275d288350995d7', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 27, 'created': '2018-10-30 08:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6cdeadd1432646d45ab98d549c51398f235cd425', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 28, 'created': '2018-10-31 04:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a53832a119a986478a7d5cfbbbaa8ed674172a9a', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 29, 'created': '2018-10-31 07:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dceda7a7c930b51c8909ed991f51fa62ef156e4b', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 30, 'created': '2018-10-31 08:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0e39bb789aa37b6398ea5c35ea725c627277d345', 'message': '[WIP] Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage.\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 31, 'created': '2018-11-07 02:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bd5cbce7263e93b73ce06f904a325fa239e30185', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 32, 'created': '2018-11-29 11:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d61311a0bef8aba314ac3e81a00d34734b0df686', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 33, 'created': '2018-12-11 02:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5acc6c4412d4290178fed0f949772fa18f9e4ff2', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 34, 'created': '2018-12-14 01:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/91880fe0c91bfb5f1d508800fbe642076868a7a6', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 35, 'created': '2018-12-19 09:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fe4d8f3f482ffd21080b24ae9286683a4af454d6', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 36, 'created': '2018-12-19 09:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2a39f9ecc6f97e85b3db3aef1627e7157552e9a7', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 37, 'created': '2019-03-27 08:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/718f3f912d4560b6e1fe403debe80613327e7e05', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}, {'number': 38, 'created': '2019-04-09 07:02:43.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.14.conf.j2', 'ansible/roles/common/templates/cron.json.j2', 'ansible/roles/zaqar/tasks/check.yml', 'ansible/roles/zaqar/defaults/main.yml', 'ansible/roles/zaqar/tasks/stop.yml', 'README.rst', 'ansible/site.yml', 'ansible/inventory/all-in-one', 'releasenotes/notes/zaqar-ansible-support-9a00f5a408e3ca3c.yaml', 'ansible/roles/zaqar/tasks/loadbalancer.yml', 'ansible/roles/zaqar/tasks/precheck.yml', 'ansible/roles/zaqar/handlers/main.yml', 'ansible/roles/zaqar/meta/main.yml', 'ansible/roles/zaqar/tasks/main.yml', 'etc/kolla/globals.yml', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.12.conf.j2', 'ansible/roles/common/templates/conf/input/00-global.conf.j2', 'ansible/roles/zaqar/tasks/config.yml', 'ansible/roles/zaqar/templates/zaqar-wsgi.json.j2', 'ansible/roles/zaqar/tasks/upgrade.yml', 'ansible/roles/zaqar/tasks/clone.yml', 'ansible/roles/zaqar/tasks/reconfigure.yml', 'etc/kolla/passwords.yml', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/zaqar/tasks/register.yml', 'ansible/roles/zaqar/templates/zaqar.conf.j2', 'ansible/roles/zaqar/templates/zaqar-server.json.j2', 'ansible/roles/zaqar/tasks/pull.yml', 'ansible/group_vars/all.yml', 'ansible/roles/mongodb/defaults/main.yml', 'ansible/roles/zaqar/templates/wsgi-zaqar.conf.j2', 'ansible/roles/zaqar/tasks/deploy.yml', 'ansible/roles/common/templates/cron-logrotate-zaqar.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b5993d6bacbadecabc2a63ae43fafea1a8f406a6', 'message': 'Add Ansible Role Zaqar\n\nZaqar is a messaging queue service in OpenStack.\nThis PS add Ansible role and related configuration\nin order to make it work with kolla-ansible.\n\n* Configure MongoDB as storage (without authentication).\n* Configure zaqar-server using websocket and\nwsgi as queue service backend.\n\nCo-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>\nCo-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>\nImplements: blueprint ansible-zaqar\nDepends-On: https://review.openstack.org/#/c/610929/\nChange-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c\n'}]",26,407760,b5993d6bacbadecabc2a63ae43fafea1a8f406a6,120,17,38,19316,,,0,"Add Ansible Role Zaqar

Zaqar is a messaging queue service in OpenStack.
This PS add Ansible role and related configuration
in order to make it work with kolla-ansible.

* Configure MongoDB as storage (without authentication).
* Configure zaqar-server using websocket and
wsgi as queue service backend.

Co-Authored-By: Kien Nguyen <kiennt65@viettel.com.vn>
Co-Authored-By: Ha Manh Dong <donghm@vn.fujitsu.com>
Implements: blueprint ansible-zaqar
Depends-On: https://review.openstack.org/#/c/610929/
Change-Id: I12185b48dd98318ed9dce7b8e64633f4d73fd41c
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/60/407760/6 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/common/templates/cron.json.j2', 'ansible/roles/haproxy/templates/haproxy.cfg.j2', 'ansible/roles/zaqar/defaults/main.yml', 'ansible/roles/zaqar/tasks/start.yml', 'ansible/site.yml', 'ansible/roles/prechecks/tasks/port_checks.yml', 'ansible/inventory/all-in-one', 'ansible/roles/zaqar/meta/main.yml', 'ansible/roles/zaqar/tasks/main.yml', 'ansible/roles/zaqar/templates/zaqar.json.j2', 'etc/kolla/globals.yml', 'ansible/roles/zaqar/tasks/config.yml', 'ansible/roles/zaqar/tasks/upgrade.yml', 'ansible/roles/zaqar/tasks/reconfigure.yml', 'etc/kolla/passwords.yml', 'ansible/roles/common/tasks/config.yml', 'ansible/roles/zaqar/tasks/register.yml', 'ansible/roles/zaqar/templates/zaqar.conf.j2', 'ansible/roles/zaqar/tasks/bootstrap.yml', 'ansible/roles/zaqar/tasks/pull.yml', 'ansible/group_vars/all.yml', 'ansible/roles/zaqar/tasks/deploy.yml', 'ansible/roles/common/templates/cron-logrotate-zaqar.conf.j2', 'ansible/roles/common/templates/heka-openstack.toml.j2']",25,a9c9ae1b2fe28ca4baccb1801c7f3f8918d6200f,bp/ansible-zaqar,file_match = '(?P<Service>cloudkitty|nova|glance|keystone|neutron|ceph|cinder|heat|murano|magnum|mistral|manila|searchlight|senlin|sahara|tacker|zaqar)/(?P<Program>.*)\.log\.?(?P<Seq>\d*)$',file_match = '(?P<Service>cloudkitty|nova|glance|keystone|neutron|ceph|cinder|heat|murano|magnum|mistral|manila|searchlight|senlin|sahara|tacker)/(?P<Program>.*)\.log\.?(?P<Seq>\d*)$',374,2
openstack%2Fmagnum~master~I42117837e8e3cd03f3cb723df4d73692ead0d169,openstack/magnum,master,I42117837e8e3cd03f3cb723df4d73692ead0d169,1. Configurable prometheus monitoring persistent storage,MERGED,2020-04-21 10:58:08.000000000,2021-02-09 16:10:59.000000000,2021-02-09 15:50:51.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-04-21 10:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/29e6900ceb83c6c53c1eb696b5a0be8f5081d286', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 2, 'created': '2020-04-21 13:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d3e7191059eb7796aa98b951310ac209a054990a', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 3, 'created': '2020-04-22 12:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/41ca1e2eebb2692bfaf621607da478be41e83a80', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 4, 'created': '2020-04-23 16:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/db331664e500ef14adbcda050c643ff4a1d82d1d', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 5, 'created': '2020-05-19 15:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1f83a676c7918a7b38b839cbf4c1ca069dc2975f', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 6, 'created': '2020-05-20 16:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d58d4ee89c3ae5e293483b607e9f9eab29f26edd', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 7, 'created': '2020-10-05 12:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ddbf3473a447fc18b0859afc2e72901d12dba612', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 8, 'created': '2020-10-06 14:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5157f6652d5add5f6493af3bf2f2c2a269aa7436', 'message': 'Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 9, 'created': '2021-02-05 15:53:23.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'releasenotes/notes/monitoring_persistent_storage-c5857fc099bd2f65.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/37497ccf5b3b92b6b5186f46fb8a059360824318', 'message': '1. Configurable prometheus monitoring persistent storage\n\n* Add metrics_retention_days magnum label allowing user to specify\nprometheus server scraped metrics retention days (default: 14)\n* Add metrics_retention_size magnum label allowing user to specify\nprometheus server metrics storage maximum size in Gib (default: 14)\n* Add metrics_scrape_interval allowing user to specify prometheus\nscrape frequency in seconds (default: 30)\n* Add metrics_storage_class_name allowing user to specify the\nstorageClass to use as external retention for pod fail-over data\npersistency\n\ntask: 39509\nstory: 2006765\n\nChange-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}]",9,721572,37497ccf5b3b92b6b5186f46fb8a059360824318,34,4,9,29425,,,0,"1. Configurable prometheus monitoring persistent storage

* Add metrics_retention_days magnum label allowing user to specify
prometheus server scraped metrics retention days (default: 14)
* Add metrics_retention_size magnum label allowing user to specify
prometheus server metrics storage maximum size in Gib (default: 14)
* Add metrics_scrape_interval allowing user to specify prometheus
scrape frequency in seconds (default: 30)
* Add metrics_storage_class_name allowing user to specify the
storageClass to use as external retention for pod fail-over data
persistency

task: 39509
story: 2006765

Change-Id: I42117837e8e3cd03f3cb723df4d73692ead0d169
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/72/721572/7 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'releasenotes/notes/monitoring_persistent_storage-c5857fc099bd2f65.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh']",10,29e6900ceb83c6c53c1eb696b5a0be8f5081d286,monitoring,"MONITORING_RETENTION_DAYS=""$MONITORING_RETENTION_DAYS"" MONITORING_RETENTION_SIZE=""$MONITORING_RETENTION_SIZE"" MONITORING_SCRAPE_INTERVAL=""$MONITORING_SCRAPE_INTERVAL"" MONITORING_STORAGE_CLASS_NAME=""$MONITORING_STORAGE_CLASS_NAME""",,193,3
openstack%2Fopenstack-helm~master~I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943,openstack/openstack-helm,master,I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943,[WIP] Enable HttpOnly and Secure flag in horizon,ABANDONED,2021-02-04 12:28:42.000000000,2021-02-09 16:02:01.000000000,,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 30449}]","[{'number': 1, 'created': '2021-02-04 12:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/55b4f76a824b622b8e0eaf4f6c7a9e8ea3ea01b5', 'message': 'Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}, {'number': 2, 'created': '2021-02-05 13:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ddd982375216f711cdc126961291843bf4458a66', 'message': '[WIP] Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}, {'number': 3, 'created': '2021-02-06 03:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/26bd4f77bd8cdf880ffba4582ddeec9b0b39a5ca', 'message': '[WIP] Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}, {'number': 4, 'created': '2021-02-06 06:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/444d47e1e41a50b34f1d08d6f33f18eecd0358d6', 'message': '[WIP] Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}, {'number': 5, 'created': '2021-02-09 09:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0940d1998af80ca89036445522b291aa99d33add', 'message': '[WIP] Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}, {'number': 6, 'created': '2021-02-09 10:02:48.000000000', 'files': ['horizon/Chart.yaml', 'horizon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ecc5a06aca18b8c41bd91c55f4e52d0ef93655ae', 'message': '[WIP] Enable HttpOnly and Secure flag in horizon\n\nThe HTTP only flag prevents the cookie from being accessed\nby client side scipt. The Secure flag prevents the cookie\nfrom being transmitted over an unencrypted channel.\n\nChange-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943\n'}]",1,774077,ecc5a06aca18b8c41bd91c55f4e52d0ef93655ae,19,3,6,31479,,,0,"[WIP] Enable HttpOnly and Secure flag in horizon

The HTTP only flag prevents the cookie from being accessed
by client side scipt. The Secure flag prevents the cookie
from being transmitted over an unencrypted channel.

Change-Id: I0ae1ab0a2455e1ab1102b7aaf44dccd8bfa8f943
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/77/774077/6 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/Chart.yaml', 'horizon/values.yaml']",2,55b4f76a824b622b8e0eaf4f6c7a9e8ea3ea01b5,," session_cookie_secure: ""True"" session_cookie_httponly: ""True"""," session_cookie_secure: ""False"" session_cookie_httponly: ""False""",3,3
openstack%2Ftripleo-ci~master~I7f4f3f0f90187ec86534cdc61b8c88b079552810,openstack/tripleo-ci,master,I7f4f3f0f90187ec86534cdc61b8c88b079552810,Fix image build after release of cryptography 3.4,MERGED,2021-02-09 09:11:26.000000000,2021-02-09 15:57:58.000000000,2021-02-09 15:57:58.000000000,"[{'_account_id': 8833}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-09 09:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5c4011f50a68844a5ab96a19fa7fc44c8cfc7dfa', 'message': ""Fix image build after release of cryptography 3.4\n\nImage build job fails with:\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which now\nincludes Rust code. It can be installed without Rust using a Python\nwheel, but only with more recent pip than version 9.0.3 available as RPM\non CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.\n\n[1] https://github.com/pyca/cryptography/issues/5753\nCloses-Bug: #1915101\nChange-Id: I5aea36a3fd4a0e00574d402eb6b8402a34c0315b\n\nChange-Id: I7f4f3f0f90187ec86534cdc61b8c88b079552810\n""}, {'number': 2, 'created': '2021-02-09 10:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ed37c47bda23c05559e0110edab8aa4aaf5d3d14', 'message': ""Fix image build after release of cryptography 3.4\n\nImage build job fails with:\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which now\nincludes Rust code. It can be installed without Rust using a Python\nwheel, but only with more recent pip than version 9.0.3 available as RPM\non CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.\n\n[1] https://github.com/pyca/cryptography/issues/5753\nCloses-Bug: #1915101\nChange-Id: I7f4f3f0f90187ec86534cdc61b8c88b079552810\n""}, {'number': 3, 'created': '2021-02-09 11:00:07.000000000', 'files': ['roles/oooci-build-images/tasks/pre.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/632143ca84ded38467995f2ee994c8691c02cb51', 'message': ""Fix image build after release of cryptography 3.4\n\nImage build job fails with:\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which now\nincludes Rust code. It can be installed without Rust using a Python\nwheel, but only with more recent pip than version 9.0.3 available as RPM\non CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.\n\n[1] https://github.com/pyca/cryptography/issues/5753\nCloses-Bug: #1915101\nChange-Id: I7f4f3f0f90187ec86534cdc61b8c88b079552810\n""}]",4,774603,632143ca84ded38467995f2ee994c8691c02cb51,18,5,3,29775,,,0,"Fix image build after release of cryptography 3.4

Image build job fails with:
ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which now
includes Rust code. It can be installed without Rust using a Python
wheel, but only with more recent pip than version 9.0.3 available as RPM
on CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.

[1] https://github.com/pyca/cryptography/issues/5753
Closes-Bug: #1915101
Change-Id: I7f4f3f0f90187ec86534cdc61b8c88b079552810
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/03/774603/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/oooci-build-images/tasks/pre.yaml'],1,5c4011f50a68844a5ab96a19fa7fc44c8cfc7dfa,bug/1915101,"- name: Ensure a recent version of pip is installed when: ansible_distribution == 'CentOS' pip: name: ""pip>=19.1.1"" virtualenv: ""{{ workspace }}/venv"" virtualenv_command: ""/usr/bin/python3 -m venv"" ",,7,0
openstack%2Ftripleo-validations~stable%2Ftrain~Ic91a3327852298b1452437a1cd3199c673d48c6c,openstack/tripleo-validations,stable/train,Ic91a3327852298b1452437a1cd3199c673d48c6c,Restore layout.yaml file,MERGED,2020-11-24 12:37:17.000000000,2021-02-09 15:57:50.000000000,2021-02-09 15:57:50.000000000,"[{'_account_id': 9592}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2020-11-24 12:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/6644f3d5819369fce0c52338c6acb15fa1a1bff5', 'message': 'Restore layout.yaml file\n\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\nChange-Id: Ic91a3327852298b1452437a1cd3199c673d48c6c\n'}, {'number': 2, 'created': '2021-01-05 16:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/20c5e67e98b3c5b206b98c6ee24da7ffaa4ef515', 'message': 'Restore layout.yaml file\n\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\nChange-Id: Ic91a3327852298b1452437a1cd3199c673d48c6c\n'}, {'number': 3, 'created': '2021-01-06 08:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5e6df8332a99166bd4b97dfd43aac5ec557f8711', 'message': 'Restore layout.yaml file\n\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\nChange-Id: Ic91a3327852298b1452437a1cd3199c673d48c6c\n'}, {'number': 4, 'created': '2021-01-21 14:40:21.000000000', 'files': ['zuul.d/layout.yaml', 'zuul.d/layout.yaml.bak'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/2467f848408232ee798bd8a0856829b92e5235c6', 'message': 'Restore layout.yaml file\n\nDepends-On: https://review.rdoproject.org/r/#/c/31640/\n\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\nChange-Id: Ic91a3327852298b1452437a1cd3199c673d48c6c\n'}]",0,763969,2467f848408232ee798bd8a0856829b92e5235c6,26,6,4,11491,,,0,"Restore layout.yaml file

Depends-On: https://review.rdoproject.org/r/#/c/31640/

Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
Change-Id: Ic91a3327852298b1452437a1cd3199c673d48c6c
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/69/763969/4 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'zuul.d/layout.yaml.bak']",2,6644f3d5819369fce0c52338c6acb15fa1a1bff5,rhbz#1877688-train-bp,,- project: templates: - tripleo-multinode-container-minimal-pipeline - openstack-python3-train-jobs - tripleo-validations-molecule-jobs - check-requirements - release-notes-jobs-python3 check: jobs: - openstack-tox-linters - tripleo-ci-centos-8-content-provider: &content_provider dependencies: &deps_lint - openstack-tox-linters - openstack-tox-docs: &tripleo-docs files: - ^doc/.* - ^README.rst - openstack-tox-lower-constraints - tripleo-ci-centos-8-scenario004-standalone: &scenario004 vars: &sa_consumer_vars consumer_job: true build_container_images: false tags: - standalone dependencies: &deps - tripleo-ci-centos-8-content-provider files: - ^roles/ceph.*$ gate: jobs: - openstack-tox-linters - tripleo-ci-centos-8-content-provider: *content_provider - openstack-tox-docs: *tripleo-docs - openstack-tox-lower-constraints - tripleo-ci-centos-8-scenario004-standalone: *scenario004 promote: jobs: - promote-openstack-tox-docs: *tripleo-docs ,15,39
openstack%2Ftripleo-heat-templates~master~Ib58b6152bc98002c048a4ae483454813c8298df9,openstack/tripleo-heat-templates,master,Ib58b6152bc98002c048a4ae483454813c8298df9,Make DnfStreams support RoleParameters,MERGED,2021-02-08 20:23:49.000000000,2021-02-09 15:57:05.000000000,2021-02-09 15:57:05.000000000,"[{'_account_id': 6816}, {'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-08 20:23:49.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/69357c3a6449b769b53e1b3a2ada75414d29d91c', 'message': 'Make DnfStreams support RoleParameters\n\nThis is useful in case the list of modules to enable is different for\nthe various roles; for example CephStorage vs Compute\n\nChange-Id: Ib58b6152bc98002c048a4ae483454813c8298df9\nCloses-Bug: #1915067\n'}]",1,774537,69357c3a6449b769b53e1b3a2ada75414d29d91c,9,6,1,6796,,,0,"Make DnfStreams support RoleParameters

This is useful in case the list of modules to enable is different for
the various roles; for example CephStorage vs Compute

Change-Id: Ib58b6152bc98002c048a4ae483454813c8298df9
Closes-Bug: #1915067
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/774537/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,69357c3a6449b769b53e1b3a2ada75414d29d91c,,"resources: RoleParametersValue: type: OS::Heat::Value properties: type: json value: map_replace: - map_replace: - dnf_module_list: DnfStreams - values: {get_param: [RoleParameters]} - values: DnfStreams: {get_param: DnfStreams} dnf_module_list: {get_attr: [RoleParametersValue, value, 'dnf_module_list']} dnf_module_list: {get_attr: [RoleParametersValue, value, 'dnf_module_list']}", dnf_module_list: {get_param: DnfStreams} dnf_module_list: {get_param: DnfStreams},15,2
openstack%2Fmagnum~master~Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3,openstack/magnum,master,Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3,3. Configure monitoring apps path based endpoints,MERGED,2020-04-21 12:17:33.000000000,2021-02-09 15:54:09.000000000,2021-02-09 15:54:09.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-04-21 12:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/57fe0be4659c4d7f97da9cfe7ce758a7dd8760df', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 2, 'created': '2020-04-22 12:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/78241afcd5ee1178abe628e067a9b2d782263879', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 3, 'created': '2020-04-23 16:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/95047f48e0f08d5ed2c1f9f86b7a6920d8148202', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 4, 'created': '2020-05-20 16:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bb3dafc80cb4b07ccb83915529d0b999839861b4', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 5, 'created': '2020-10-05 12:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/884a41515d3ee83ce0cd2a1c9d16c8dc2465b419', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 6, 'created': '2020-10-06 14:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6e591669138880b9e6493f4d4caf4c28269634b8', 'message': 'Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 7, 'created': '2021-02-05 15:53:23.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'releasenotes/notes/configure_monitoring_app_endpoints-f00600c244a76cf4.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/ea64468ab31b493191e9419f10542810a9ba7b4d', 'message': '3. Configure monitoring apps path based endpoints\n\n* Add monitoring_ingress_enabled magnum label to set up ingress with\npath based routing for all the configured services\n{alertmanager,grafana,prometheus}. When using this,\ncluster_root_domain_name magnum label must be used to setup base path\nwhere this services are available.\n* Add cluster_basic_auth_secret magnum label to configure basic auth\non unprotected services {alertmanager and  prometheus}. This is only\nin effect when app access is routed by ingress.\n* Set services logFormat to json to enable easier machine log parsing.\n\ntask: 39477\nstory: 2006765\n\nDepends-On: Ieb90605182626869528349a7fdeed65061914bcb\nChange-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}]",1,721592,ea64468ab31b493191e9419f10542810a9ba7b4d,28,5,7,29425,,,0,"3. Configure monitoring apps path based endpoints

* Add monitoring_ingress_enabled magnum label to set up ingress with
path based routing for all the configured services
{alertmanager,grafana,prometheus}. When using this,
cluster_root_domain_name magnum label must be used to setup base path
where this services are available.
* Add cluster_basic_auth_secret magnum label to configure basic auth
on unprotected services {alertmanager and  prometheus}. This is only
in effect when app access is routed by ingress.
* Set services logFormat to json to enable easier machine log parsing.

task: 39477
story: 2006765

Depends-On: Ieb90605182626869528349a7fdeed65061914bcb
Change-Id: Ie0e7000e0d94b2037f2c398fa67a2a2b7e256bc3
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/92/721592/5 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'releasenotes/notes/configure_monitoring_app_endpoints-f00600c244a76cf4.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh']",10,57fe0be4659c4d7f97da9cfe7ce758a7dd8760df,monitoring,"MONITORING_INGRESS_ENABLED=""$MONITORING_INGRESS_ENABLED"" CLUSTER_BASIC_AUTH_SECRET=""$CLUSTER_BASIC_AUTH_SECRET"" CLUSTER_ROOT_DOMAIN_NAME=""$CLUSTER_ROOT_DOMAIN_NAME""",,261,3
openstack%2Fmagnum~master~Ieb90605182626869528349a7fdeed65061914bcb,openstack/magnum,master,Ieb90605182626869528349a7fdeed65061914bcb,2. Add persistency for grafana dashboards,MERGED,2020-04-23 16:09:32.000000000,2021-02-09 15:51:30.000000000,2021-02-09 15:51:30.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-04-23 16:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/739172a6134d544a791f6b1d59725f8c61e5da28', 'message': 'Add persistency for grafana dashboards\n\nWhen label monitoring_storage_class_name is specified\ndashboards altered using the grafana UI are now\npersisted if the pod is terminated.\nIt is still recommended that the user utilizes a\nkubernetes configMap to persist the dashboard.\n\ntask: 39514\nstory: 2006765\n\nChange-Id: Ieb90605182626869528349a7fdeed65061914bcb\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 2, 'created': '2020-05-20 16:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/15fd27fce2a93d990ae79d5b45f028a634835cf2', 'message': 'Add persistency for grafana dashboards\n\nWhen label monitoring_storage_class_name is specified\ndashboards altered using the grafana UI are now\npersisted if the pod is terminated.\nIt is still recommended that the user utilizes a\nkubernetes configMap to persist the dashboard.\n\ntask: 39514\nstory: 2006765\n\nChange-Id: Ieb90605182626869528349a7fdeed65061914bcb\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 3, 'created': '2020-10-05 12:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1ecd84f11639760c248a70a3d532847a56b9f7ef', 'message': 'Add persistency for grafana dashboards\n\nWhen label monitoring_storage_class_name is specified\ndashboards altered using the grafana UI are now\npersisted if the pod is terminated.\nIt is still recommended that the user utilizes a\nkubernetes configMap to persist the dashboard.\n\ntask: 39514\nstory: 2006765\n\nChange-Id: Ieb90605182626869528349a7fdeed65061914bcb\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 4, 'created': '2020-10-06 14:13:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f6786d3d190fe33476ab9f70605e35231e717301', 'message': 'Add persistency for grafana dashboards\n\nWhen label monitoring_storage_class_name is specified\ndashboards altered using the grafana UI are now\npersisted if the pod is terminated.\nIt is still recommended that the user utilizes a\nkubernetes configMap to persist the dashboard.\n\ntask: 39514\nstory: 2006765\n\nChange-Id: Ieb90605182626869528349a7fdeed65061914bcb\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 5, 'created': '2021-02-05 15:53:23.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'doc/source/user/index.rst', 'releasenotes/notes/altered_grafanaUI_dashboards_persistency-1106b2e259a769b0.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/aec5d469bea83312a4886f88603945407a7f166e', 'message': '2. Add persistency for grafana dashboards\n\nWhen label monitoring_storage_class_name is specified\ndashboards altered using the grafana UI are now\npersisted if the pod is terminated.\nIt is still recommended that the user utilizes a\nkubernetes configMap to persist the dashboard.\n\ntask: 39514\nstory: 2006765\n\nDepends-On: I42117837e8e3cd03f3cb723df4d73692ead0d169\nChange-Id: Ieb90605182626869528349a7fdeed65061914bcb\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}]",2,722396,aec5d469bea83312a4886f88603945407a7f166e,18,4,5,29425,,,0,"2. Add persistency for grafana dashboards

When label monitoring_storage_class_name is specified
dashboards altered using the grafana UI are now
persisted if the pod is terminated.
It is still recommended that the user utilizes a
kubernetes configMap to persist the dashboard.

task: 39514
story: 2006765

Depends-On: I42117837e8e3cd03f3cb723df4d73692ead0d169
Change-Id: Ieb90605182626869528349a7fdeed65061914bcb
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/96/722396/5 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'doc/source/user/index.rst', 'releasenotes/notes/altered_grafanaUI_dashboards_persistency-1106b2e259a769b0.yaml']",3,739172a6134d544a791f6b1d59725f8c61e5da28,monitoring,"--- features: - | Add persistency for grafana UI altered dashboards. To enable this use monitoring_storage_class_name label. It is recommended that dashboards be persisted by other means, mainly by using kubernetes configMaps. More info [0]. [0] https://github.com/helm/charts/tree/master/stable/grafana#sidecar-for-dashboards ",,18,0
openstack%2Foslo.metrics~master~I9ed133543ae6846256c1ea81602ca864f3847dec,openstack/oslo.metrics,master,I9ed133543ae6846256c1ea81602ca864f3847dec,"Add timeout, method to RPC Client Label",MERGED,2021-02-09 08:38:56.000000000,2021-02-09 15:46:17.000000000,2021-02-09 15:42:31.000000000,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 08:38:56.000000000', 'files': ['oslo_metrics/metrics/oslo_messaging.py', 'oslo_metrics/tests/test_message_process.py'], 'web_link': 'https://opendev.org/openstack/oslo.metrics/commit/ef4a4e3b24abbbfdc56b70a29a162fb1f92507c5', 'message': 'Add timeout, method to RPC Client Label\n\nWe are missing timeout and method in label definition for rpc client\nthis will cause message router to failed to parse messages as there are\nunexpected labels sent from oslo.messaging.\n\nThis commit added timeout and method to rpc client labels to fix the\nissue.\n\nChange-Id: I9ed133543ae6846256c1ea81602ca864f3847dec\n'}]",0,774600,ef4a4e3b24abbbfdc56b70a29a162fb1f92507c5,11,2,1,32523,,,0,"Add timeout, method to RPC Client Label

We are missing timeout and method in label definition for rpc client
this will cause message router to failed to parse messages as there are
unexpected labels sent from oslo.messaging.

This commit added timeout and method to rpc client labels to fix the
issue.

Change-Id: I9ed133543ae6846256c1ea81602ca864f3847dec
",git fetch https://review.opendev.org/openstack/oslo.metrics refs/changes/00/774600/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_metrics/metrics/oslo_messaging.py', 'oslo_metrics/tests/test_message_process.py']",2,ef4a4e3b24abbbfdc56b70a29a162fb1f92507c5,fix_missing_labels," ""method"": ""get"", ""fanout"": ""foo"", ""timeout"": 10"," ""fanout"": ""foo""",4,2
openstack%2Ftripleo-common~master~Ifee9d90f30c4ad4a401149b979f220d8028d2643,openstack/tripleo-common,master,Ifee9d90f30c4ad4a401149b979f220d8028d2643,Add healthcheck to the frr image,MERGED,2021-02-05 08:11:01.000000000,2021-02-09 15:32:20.000000000,2021-02-09 15:29:24.000000000,"[{'_account_id': 6469}, {'_account_id': 6926}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-05 08:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c45703d7b96ccf8c429dc17e95aaf7288bcc9511', 'message': 'Add healthcheck to the frr image\n\nWe could not do that in the initial review because CI runs its\ntests on a non-rebuild rpm. See:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/763087/6..11\n\nSo we add it now that the initial image has already been added.\n\nChange-Id: Ifee9d90f30c4ad4a401149b979f220d8028d2643\n'}, {'number': 2, 'created': '2021-02-08 07:15:31.000000000', 'files': ['container-images/tcib/base/frr/frr.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fcbda76d9ecc35eb297f81b5fe955b11927a40b1', 'message': 'Add healthcheck to the frr image\n\nWe could not do that in the initial review because CI runs its\ntests on a non-rebuild rpm. See:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/763087/6..11\n\nSo we add it now that the initial image has already been added.\n\nChange-Id: Ifee9d90f30c4ad4a401149b979f220d8028d2643\n'}]",0,774203,fcbda76d9ecc35eb297f81b5fe955b11927a40b1,13,5,2,20172,,,0,"Add healthcheck to the frr image

We could not do that in the initial review because CI runs its
tests on a non-rebuild rpm. See:
https://review.opendev.org/c/openstack/tripleo-common/+/763087/6..11

So we add it now that the initial image has already been added.

Change-Id: Ifee9d90f30c4ad4a401149b979f220d8028d2643
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/03/774203/2 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/frr/frr.yaml'],1,c45703d7b96ccf8c429dc17e95aaf7288bcc9511,bgpsupport,- run: ln -s /usr/share/openstack-tripleo-common/healthcheck/frr /openstack/healthcheck && chmod a+rx /openstack/healthcheck,,1,0
openstack%2Ftripleo-common~stable%2Fussuri~Iba06dc0f8afe9bc6a8820742c656dca5bf75df15,openstack/tripleo-common,stable/ussuri,Iba06dc0f8afe9bc6a8820742c656dca5bf75df15,Fix placement endpoint check when endpoints are not set,MERGED,2021-02-08 15:04:42.000000000,2021-02-09 15:32:05.000000000,2021-02-09 15:29:08.000000000,"[{'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-08 15:04:42.000000000', 'files': ['tripleo_common/tests/utils/test_plan.py', 'tripleo_common/utils/plan.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3de751d9cf3f725c6999ece01b081bc7c0210a8c', 'message': ""Fix placement endpoint check when endpoints are not set\n\nWhen endpoint are not set in the heat resource, None is returned, not an empty\ndict. The check then raises a 'NoneType' is not iterable exception.\n\nFix the logic to handle None and update the unit test.\n\nCloses-bug: #1913416\nChange-Id: Iba06dc0f8afe9bc6a8820742c656dca5bf75df15\n(cherry picked from commit 86d0e65a2905f46eca05cbf4070f97feaa392463)\n""}]",0,774480,3de751d9cf3f725c6999ece01b081bc7c0210a8c,12,6,1,6816,,,0,"Fix placement endpoint check when endpoints are not set

When endpoint are not set in the heat resource, None is returned, not an empty
dict. The check then raises a 'NoneType' is not iterable exception.

Fix the logic to handle None and update the unit test.

Closes-bug: #1913416
Change-Id: Iba06dc0f8afe9bc6a8820742c656dca5bf75df15
(cherry picked from commit 86d0e65a2905f46eca05cbf4070f97feaa392463)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/80/774480/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/utils/test_plan.py', 'tripleo_common/utils/plan.py']",2,3de751d9cf3f725c6999ece01b081bc7c0210a8c,," placement_extracted = False endpoints = endpoint_res.attributes.get('endpoint_map', None) placement_extracted = endpoints and 'PlacementPublic' in endpoints except heat_exc.HTTPNotFound: pass"," endpoints = endpoint_res.attributes.get('endpoint_map', {}) placement_extracted = 'PlacementPublic' in endpoints except heat_exc.HTTPNotFound: placement_extracted = False",5,4
openstack%2Fpython-tripleoclient~stable%2Ftrain~I9b5445cbccf34e31daf055d264975d0a1eba9aba,openstack/python-tripleoclient,stable/train,I9b5445cbccf34e31daf055d264975d0a1eba9aba,Dumping task key instead of tasks from validation_output,MERGED,2021-02-01 11:17:04.000000000,2021-02-09 15:32:04.000000000,2021-02-09 15:29:02.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27419}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-02-01 11:17:04.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e3ef26ab0ccf3d1a48cf6ef018ad134a3efcee00', 'message': 'Dumping task key instead of tasks from validation_output\n\nChange-Id: I9b5445cbccf34e31daf055d264975d0a1eba9aba\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit c8137f8f016e26043903f63b4ec794467b69eea5)\n(cherry picked from commit f5af50f5dc5370c61eba073076dc8e786aacc741)\n(cherry picked from commit 4886a706712181265bb621e183a1d48da1c7c46d)\n'}]",0,773368,e3ef26ab0ccf3d1a48cf6ef018ad134a3efcee00,13,6,1,11491,,,0,"Dumping task key instead of tasks from validation_output

Change-Id: I9b5445cbccf34e31daf055d264975d0a1eba9aba
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
(cherry picked from commit c8137f8f016e26043903f63b4ec794467b69eea5)
(cherry picked from commit f5af50f5dc5370c61eba073076dc8e786aacc741)
(cherry picked from commit 4886a706712181265bb621e183a1d48da1c7c46d)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/68/773368/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,e3ef26ab0ccf3d1a48cf6ef018ad134a3efcee00,train," print(json.dumps(p['task'],"," print(json.dumps(p['tasks'],",1,1
openstack%2Fswift~master~I4f900f81b446449ee699b4183ed061209709cf6c,openstack/swift,master,I4f900f81b446449ee699b4183ed061209709cf6c,Add unit test for relinker conf file option,ABANDONED,2021-02-08 16:04:28.000000000,2021-02-09 15:30:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-08 16:04:28.000000000', 'files': ['test/unit/cli/test_relinker.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/17368c6aa39d8f022d918f5ac29e4ab80e29eab4', 'message': 'Add unit test for relinker conf file option\n\nRelated-Change: I32f979f068592eaac39dcc6807b3114caeaaa814\nChange-Id: I4f900f81b446449ee699b4183ed061209709cf6c\n'}]",1,774510,17368c6aa39d8f022d918f5ac29e4ab80e29eab4,4,1,1,7847,,,0,"Add unit test for relinker conf file option

Related-Change: I32f979f068592eaac39dcc6807b3114caeaaa814
Change-Id: I4f900f81b446449ee699b4183ed061209709cf6c
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/774510/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/cli/test_relinker.py'],1,17368c6aa39d8f022d918f5ac29e4ab80e29eab4,,"import logging from textwrap import dedent def test_conf_file(self): config = """""" [DEFAULT] swift_dir = test/swift/dir devices = /test/node mount_check = false [object-relinker] log_level = WARNING log_name = test-relinker """""" conf_file = os.path.join(self.testdir, 'relinker.conf') with open(conf_file, 'w') as f: f.write(dedent(config)) # cite conf file on command line with mock.patch('swift.cli.relinker.relink') as mock_relink: relinker.main(['relink', conf_file, '--device', 'sdx', '--debug']) mock_relink.assert_called_once_with( 'test/swift/dir', '/test/node', True, mock.ANY, device='sdx') logger = mock_relink.call_args[0][3] # --debug is overridden by conf file self.assertTrue(logging.INFO, logger.logger.level) self.assertEqual('test-relinker', logger.logger.name) # flip mount_check... config = """""" [DEFAULT] swift_dir = test/swift/dir devices = /test/node mount_check = true [object-relinker] log_level = WARNING log_name = test-relinker """""" with open(conf_file, 'w') as f: f.write(dedent(config)) with mock.patch('swift.cli.relinker.relink') as mock_relink: relinker.main(['relink', conf_file, '--device', 'sdx', '--debug']) mock_relink.assert_called_once_with( 'test/swift/dir', '/test/node', False, mock.ANY, device='sdx') # override with cli options... with mock.patch('swift.cli.relinker.relink') as mock_relink: relinker.main(['relink', conf_file, '--device', 'sdx', '--debug', '--swift-dir', 'cli-dir', '--devices', 'cli-devs', '--skip-mount-check']) mock_relink.assert_called_once_with( 'cli-dir', 'cli-devs', True, mock.ANY, device='sdx') with mock.patch('swift.cli.relinker.relink') as mock_relink: relinker.main(['relink', '--device', 'sdx', '--debug', '--swift-dir', 'cli-dir', '--devices', 'cli-devs', '--skip-mount-check']) mock_relink.assert_called_once_with( 'cli-dir', 'cli-devs', True, mock.ANY, device='sdx') logger = mock_relink.call_args[0][3] # --debug is now effective self.assertTrue(logging.DEBUG, logger.level) self.assertEqual('root', logger.name) ",,65,0
openstack%2Fswift~master~I3432730557c423974c8c8da90ef4178613ca7f58,openstack/swift,master,I3432730557c423974c8c8da90ef4178613ca7f58,relinker: unit test drop_privileges,ABANDONED,2021-02-08 21:09:41.000000000,2021-02-09 15:29:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-08 21:09:41.000000000', 'files': ['test/unit/cli/test_relinker.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4940d352dc4f6f6896c9144f5b4ff4e91645633a', 'message': 'relinker: unit test drop_privileges\n\nChange-Id: I3432730557c423974c8c8da90ef4178613ca7f58\n'}]",0,774541,4940d352dc4f6f6896c9144f5b4ff4e91645633a,3,1,1,7847,,,0,"relinker: unit test drop_privileges

Change-Id: I3432730557c423974c8c8da90ef4178613ca7f58
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/774541/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/cli/test_relinker.py'],1,4940d352dc4f6f6896c9144f5b4ff4e91645633a,,"from contextlib import contextmanager def _do_test_relinker_drop_privileges(self, command): @contextmanager def do_mocks(): # attach mocks to call_capture so that call order can be asserted call_capture = mock.Mock() with mock.patch('swift.cli.relinker.drop_privileges') as mock_dp: with mock.patch('swift.cli.relinker.' + command, return_value=0) as mock_command: call_capture.attach_mock(mock_dp, 'drop_privileges') call_capture.attach_mock(mock_command, command) yield call_capture # no user option with do_mocks() as capture: self.assertEqual(0, relinker.main([command])) self.assertEqual([(command, mock.ANY, mock.ANY)], capture.method_calls) # cli option --user with do_mocks() as capture: self.assertEqual(0, relinker.main([command, '--user', 'cli_user'])) self.assertEqual([('drop_privileges', ('cli_user',), {}), (command, mock.ANY, mock.ANY)], capture.method_calls) # cli option --user takes precedence over conf file user with do_mocks() as capture: with mock.patch('swift.cli.relinker.readconf', return_value={'user': 'conf_user'}): self.assertEqual(0, relinker.main([command, 'conf_file', '--user', 'cli_user'])) self.assertEqual([('drop_privileges', ('cli_user',), {}), (command, mock.ANY, mock.ANY)], capture.method_calls) # conf file user with do_mocks() as capture: with mock.patch('swift.cli.relinker.readconf', return_value={'user': 'conf_user'}): self.assertEqual(0, relinker.main([command, 'conf_file'])) self.assertEqual([('drop_privileges', ('conf_user',), {}), (command, mock.ANY, mock.ANY)], capture.method_calls) def test_relinker_drop_privileges(self): self._do_test_relinker_drop_privileges('relink') self._do_test_relinker_drop_privileges('cleanup') ",,50,0
openstack%2Foslo.cache~master~I8c7f9291652a58b8291c3df90571501eed43bf18,openstack/oslo.cache,master,I8c7f9291652a58b8291c3df90571501eed43bf18,Dropping lower constraints testing.,MERGED,2021-02-05 12:17:14.000000000,2021-02-09 15:18:38.000000000,2021-02-09 15:15:52.000000000,"[{'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-05 12:17:14.000000000', 'files': ['lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/9606e8531d87cfcf0028f5a414212fcb704f598a', 'message': 'Dropping lower constraints testing.\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints[1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I8c7f9291652a58b8291c3df90571501eed43bf18\n'}]",0,774232,9606e8531d87cfcf0028f5a414212fcb704f598a,10,3,1,31245,,,0,"Dropping lower constraints testing.

We facing errors related to the new pip resolver, this
topic was discussed on the ML and QA team proposed to
to test lower-constraints[1].

I propose to drop this test because the complexity and recurring pain needed
to maintain that now exceeds the benefits provided by this mechanismes.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html

Change-Id: I8c7f9291652a58b8291c3df90571501eed43bf18
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/32/774232/1 && git format-patch -1 --stdout FETCH_HEAD,"['lower-constraints.txt', 'tox.ini']",2,9606e8531d87cfcf0028f5a414212fcb704f598a,remove_lower_constaints,, [testenv:lower-constraints] deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt,0,71
openstack%2Fwhitebox-tempest-plugin~master~Ib3e66b249aca80756b1e2e02293598bbf68b2dbf,openstack/whitebox-tempest-plugin,master,Ib3e66b249aca80756b1e2e02293598bbf68b2dbf,[Very WIP] TripleO CI job,ABANDONED,2020-01-30 20:40:48.000000000,2021-02-09 15:15:24.000000000,,"[{'_account_id': 8367}, {'_account_id': 8864}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 28006}, {'_account_id': 30742}, {'_account_id': 31033}]","[{'number': 1, 'created': '2020-01-30 20:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/5e09101fab40ad150c1e909e749dcb5065e1ec10', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 2, 'created': '2020-01-30 22:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/674f0685decfde4d90189c6ef0bec2cf48744ebe', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 3, 'created': '2020-01-31 21:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/6945ddf9a7b9b753cf3a8c06e34401f402ced3ff', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 4, 'created': '2020-02-06 21:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/445b3dfc5e1a9347afcd58d1a7f006693af3c554', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 5, 'created': '2020-02-07 00:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/e06c2d7906f03489315866c66d24b774f834a262', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 6, 'created': '2020-02-07 01:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/baf8069d2f26d9695ee36df4990f6280528d33c9', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 7, 'created': '2020-02-07 15:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/a3d86c985eb78f7fde18b9c9960059ffd0f40350', 'message': '[WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 8, 'created': '2020-09-15 21:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/c8d38eaa409e4bc07217eaa57752396f97a10897', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 9, 'created': '2020-10-19 19:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/dd274e326dd1388aa7a38425118e9387244ab4ff', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 10, 'created': '2020-10-19 20:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/2d5e03b963766f0ecfb8ba5c201d629684099172', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 11, 'created': '2020-10-19 22:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/d65e696b3be823f00ac49262aeecc3ba4a9f8016', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 12, 'created': '2020-10-19 23:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/683e2a8ddffcc5f4bd1b818ef060fe4362658cff', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 13, 'created': '2020-10-20 00:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/8af6c56ed2cca7329f6b2a049139fd98d5932aaf', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 14, 'created': '2020-10-20 01:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/9b73af73f8d62ae322a03ccaf4488dd43ffb8fc4', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 15, 'created': '2020-10-20 01:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/2afb5be738797121aacc586d9109265f99f879ef', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 16, 'created': '2020-10-20 01:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/1efcc935dea7026d0880f891c7214f8f0040a27f', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 17, 'created': '2020-10-20 02:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/7362fd71c0da513fca86795eb5adc1fe11309ab3', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 18, 'created': '2020-10-23 13:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/6a4393776e2ab86297d58fdd27a839a66d88dc44', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 19, 'created': '2020-10-23 14:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/34f91ee24181eb6126c8de12407292a78ebec8c3', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 20, 'created': '2020-10-23 14:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/e1aa2580307812da8b6578084c6b61ad61bf521b', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 21, 'created': '2020-11-02 22:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/470dec531bb7ea64051bb1f6ffb0765617a7a514', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 22, 'created': '2020-11-03 00:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/b79d1a31ba60d45ec372706cbf35a3eb04571a9e', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 23, 'created': '2020-11-03 01:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/ff42dfe4122fd2c53499c1d663ff347d93198b45', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 24, 'created': '2020-11-03 03:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/57f569303da8475236433e0dd6e1f40300de3a4f', 'message': '[Very WIP] TripleO CI job\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n'}, {'number': 25, 'created': '2020-11-03 16:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/4a2acaeef4bd81d50b7f208e12a8e7f1b83b28a0', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe prupose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}, {'number': 26, 'created': '2020-11-03 17:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/756953fab620e17f2ad92f874eb5aa6b63eea8ef', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe prupose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}, {'number': 27, 'created': '2020-11-03 18:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/dd171cd3e75400baa7317af8d250ee32f3e7974d', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe prupose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}, {'number': 28, 'created': '2020-11-03 19:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/bccb6479f127699febcc844dfc75dda52c6a82ac', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe prupose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}, {'number': 29, 'created': '2020-11-03 20:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/18afb6a67cbfceab7a8a90811ccbaf5b83a6a94f', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe purpose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}, {'number': 30, 'created': '2020-11-06 20:59:04.000000000', 'files': ['playbooks/standalone_parameters.yaml.j2', '.zuul.yaml', 'playbooks/tripleo-standalone-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/db900a3eeeb47548a025f5be3862ea430507d510', 'message': ""[Very WIP] TripleO CI job\n\nTripleO doesn't officially support multinode standalone, but I was\ntold it should still work.\n\nThe purpose of this patch is to use multinode standalone to deploy a\n2-node environment to then run whitebox Tempest plugin tests.\n\nChange-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf\n""}]",12,705113,db900a3eeeb47548a025f5be3862ea430507d510,85,12,30,8864,,,0,"[Very WIP] TripleO CI job

TripleO doesn't officially support multinode standalone, but I was
told it should still work.

The purpose of this patch is to use multinode standalone to deploy a
2-node environment to then run whitebox Tempest plugin tests.

Change-Id: Ib3e66b249aca80756b1e2e02293598bbf68b2dbf
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/13/705113/9 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5e09101fab40ad150c1e909e749dcb5065e1ec10,tripleo-job, name: whitebox-multinode-tripleo nodeset: multi-numa-multinode parent: tripleo-ci-base-multinode vars: run_tempest: true tempest_run_concurrency: 1 tempest_plugins: - 'whitebox-tempest-plugin' tempest_white_regex: '^whitebox_tempest_plugin\.' tempest_conf_overrides: whitebox.max_compute_nodes: 2 whitebox.ctlplane_ssh_username: heat-admin whitebox.ctlplane_ssh_private_key_path: /home/stack/.ssh/id_rsa whitebox.containers: true whitebox.container_runtime: podman # whitebox.hypervisors: TODO # whitebox-nova-compute.config_path: TODO whitebox-nova-compute.restart_command: 'podman restart nova_compute' # whitebox-database.host: TODO # whitebox-database.password: TODO # whitebox-database.nova_cell1_db_name: TODO # TODO(artom) Figure out how to set the virt_type to kvm - job:,,24,0
openstack%2Fvalidations-common~master~I515883c33901253966179063942fde77c2840eac,openstack/validations-common,master,I515883c33901253966179063942fde77c2840eac,Restrict execution to localhost only,MERGED,2021-02-09 05:57:11.000000000,2021-02-09 15:08:11.000000000,2021-02-09 15:08:11.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 29773}, {'_account_id': 32231}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-02-09 05:57:11.000000000', 'files': ['validations_common/playbooks/check-latest-packages-version.yaml'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/bcc35b8cc706474e79a15ae34d87abd7b22c34d1', 'message': 'Restrict execution to localhost only\n\nThe check-latest-packages-version validation was running on all hosts\nand was failing on Overcloud nodes because python*-tripleoclient is\nonly installed on the Undercloud.\n\nThis patch restricts the execution of this validation on localhost\nonly (i.e the Undercloud only).\n\nCloses-Bug: #1915111\n\nChange-Id: I515883c33901253966179063942fde77c2840eac\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n'}]",2,774591,bcc35b8cc706474e79a15ae34d87abd7b22c34d1,12,7,1,11491,,,0,"Restrict execution to localhost only

The check-latest-packages-version validation was running on all hosts
and was failing on Overcloud nodes because python*-tripleoclient is
only installed on the Undercloud.

This patch restricts the execution of this validation on localhost
only (i.e the Undercloud only).

Closes-Bug: #1915111

Change-Id: I515883c33901253966179063942fde77c2840eac
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/91/774591/1 && git format-patch -1 --stdout FETCH_HEAD,['validations_common/playbooks/check-latest-packages-version.yaml'],1,bcc35b8cc706474e79a15ae34d87abd7b22c34d1,rhbz_1926238,- hosts: localhost,- hosts: all,1,1
openstack%2Ftripleo-ci~master~Ic41ec2c29219c4a4f543177e10c9de21b12d2e9d,openstack/tripleo-ci,master,Ic41ec2c29219c4a4f543177e10c9de21b12d2e9d,remove periodic rocky job from upstream,MERGED,2021-02-08 20:19:37.000000000,2021-02-09 15:08:05.000000000,2021-02-09 15:08:05.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-08 20:19:37.000000000', 'files': ['zuul.d/periodic.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/82f442f1a080985c467e5adc31e7533041007b85', 'message': 'remove periodic rocky job from upstream\n\nChange-Id: Ic41ec2c29219c4a4f543177e10c9de21b12d2e9d\n'}]",0,774536,82f442f1a080985c467e5adc31e7533041007b85,9,4,1,9592,,,0,"remove periodic rocky job from upstream

Change-Id: Ic41ec2c29219c4a4f543177e10c9de21b12d2e9d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/36/774536/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/periodic.yaml'],1,82f442f1a080985c467e5adc31e7533041007b85,tripleo-ci-reduce,, - tripleo-ci-centos-7-containers-multinode-rocky: vars: force_non_periodic: true,0,3
openstack%2Ftripleo-ci~master~I5aea36a3fd4a0e00574d402eb6b8402a34c0315b,openstack/tripleo-ci,master,I5aea36a3fd4a0e00574d402eb6b8402a34c0315b,[dnm] Test only - Fix image build jobs after release of cryptography 3.4,ABANDONED,2021-02-09 07:53:37.000000000,2021-02-09 15:02:49.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-09 07:53:37.000000000', 'files': ['roles/oooci-build-images/tasks/pre.yaml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9fa78d83cc15888f7c94888d8c0aacb676e42856', 'message': ""[dnm] Test only - Fix image build jobs after release of cryptography 3.4\n\nModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which now\nincludes Rust code. It can be installed without Rust using a Python\nwheel, but only with more recent pip than version 9.0.3 available as RPM\non CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.\n\n[1] https://github.com/pyca/cryptography/issues/5753\n\nChange-Id: I5aea36a3fd4a0e00574d402eb6b8402a34c0315b\n""}]",0,774597,9fa78d83cc15888f7c94888d8c0aacb676e42856,4,2,1,29775,,,0,"[dnm] Test only - Fix image build jobs after release of cryptography 3.4

ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which now
includes Rust code. It can be installed without Rust using a Python
wheel, but only with more recent pip than version 9.0.3 available as RPM
on CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.

[1] https://github.com/pyca/cryptography/issues/5753

Change-Id: I5aea36a3fd4a0e00574d402eb6b8402a34c0315b
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/97/774597/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/oooci-build-images/tasks/pre.yaml', 'zuul.d/layout.yaml']",2,9fa78d83cc15888f7c94888d8c0aacb676e42856,bug/1915101,," templates: - tripleo-ci-build-containers-jobs - tripleo-ci-buildimage-jobs - tripleo-multinode-branchful - tripleo-multinode-container-full-pipeline - tripleo-standalone-scenarios-pipeline - tripleo-undercloud-jobs-pipeline - tripleo-periodic - tripleo-tox-molecule: vars: tox_environment: PYTEST_REQPASS: 1 - openstack-tox-py36: success-url: ""tox/reports.html"" failure-url: ""tox/reports.html"" files: &py_files - ^bindep.txt$ - ^requirements.txt$ - ^scripts/emit_releases_file/.*$ - ^setup.cfg$ - ^setup.py$ - ^tox.ini$ vars: tox_environment: PYTEST_REQPASS: 84 gate: queue: tripleo jobs: # Don't put a files section on the linters job, otherwise no # jobs might be defined and nothing can merge in this repo. - openstack-tox-linters - tripleo-tox-molecule - openstack-tox-py36: files: *py_files",7,34
openstack%2Fbarbican-tempest-plugin~master~I1f0d8be1b237da0c96e820c4b3dca09a83b29752,openstack/barbican-tempest-plugin,master,I1f0d8be1b237da0c96e820c4b3dca09a83b29752,Copy created image into all available glance stores,MERGED,2020-11-20 00:33:50.000000000,2021-02-09 14:55:16.000000000,2021-02-09 14:55:16.000000000,"[{'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-20 00:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/b9e0a6e63e4d1a653f7439630db41b851257e695', 'message': 'Copy created image into all available glance stores\n\nThe openstack can have multiple glance stores deployed/available.\nIt may be a proper thing to copy newly created signed image into\nall the available glance stores so barbican tempest tests can access\nimage regardless on which compute and storage backend they are ran on\nand regardless on which glance store is local.\nAdditionally there is a nova-compute conf parameter[1] which can even\nprevent instances being spawned from image which is not available in local\nglance store.\nThe copy-image would happen only if import_image tempest cong option\nis available which indicates glance multistore is available.\n\n[1] https://review.opendev.org/#/c/657078/\n\nChange-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752\n'}, {'number': 2, 'created': '2020-11-20 01:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/2ebe3b29e77076e369db6f693a61aa6f1c2d90d4', 'message': 'Copy created image into all available glance stores\n\nThe openstack can have multiple glance stores deployed/available.\nIt may be a proper thing to copy newly created signed image into\nall the available glance stores so barbican tempest tests can access\nimage regardless on which compute and storage backend they are ran on\nand regardless on which glance store is local.\nAdditionally there is a nova-compute conf parameter[1] which can even\nprevent instances being spawned from image which is not available in local\nglance store.\nThe copy-image would happen only if import_image tempest cong option\nis available which indicates glance multistore is available.\n\n[1] https://review.opendev.org/#/c/657078/\n\nChange-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752\n'}, {'number': 3, 'created': '2020-11-20 03:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/ede87c5c3ecedf772ed50e24009e84f448813d02', 'message': 'Copy created image into all available glance stores\n\nThe openstack can have multiple glance stores deployed/available.\nIt may be a proper thing to copy newly created signed image into\nall the available glance stores so barbican tempest tests can access\nimage regardless on which compute and storage backend they are ran on\nand regardless on which glance store is local.\nAdditionally there is a nova-compute conf parameter[1] which can even\nprevent instances being spawned from image which is not available in local\nglance store.\nThe copy-image would happen only if import_image tempest cong option\nis available which indicates glance multistore is available.\n\n[1] https://review.opendev.org/#/c/657078/\n\nChange-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752\n'}, {'number': 4, 'created': '2020-12-09 07:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/ef84a26d0ff4621f3b1b9fc766813e55eb070ce8', 'message': 'Copy created image into all available glance stores\n\nThe openstack can have multiple glance stores deployed/available.\nIt may be a proper thing to copy newly created signed image into\nall the available glance stores so barbican tempest tests can access\nimage regardless on which compute and storage backend they are ran on\nand regardless on which glance store is local.\nAdditionally there is a nova-compute conf parameter[1] which can even\nprevent instances being spawned from image which is not available in local\nglance store.\nThe copy-image would happen only if import_image tempest cong option\nis available which indicates glance multistore is available.\n\n[1] https://review.opendev.org/#/c/657078/\n\nChange-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752\n'}, {'number': 5, 'created': '2021-02-08 23:00:39.000000000', 'files': ['barbican_tempest_plugin/tests/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/1972c4692428a61fafc7e1290632395d5824a4d8', 'message': 'Copy created image into all available glance stores\n\nThe openstack can have multiple glance stores deployed/available.\nIt may be a proper thing to copy newly created signed image into\nall the available glance stores so barbican tempest tests can access\nimage regardless on which compute and storage backend they are ran on\nand regardless on which glance store is local.\nAdditionally there is a nova-compute conf parameter[1] which can even\nprevent instances being spawned from image which is not available in local\nglance store.\nThe copy-image would happen only if import_image tempest cong option\nis available which indicates glance multistore is available.\n\n[1] https://review.opendev.org/#/c/657078/\n\nChange-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752\n'}]",12,763485,1972c4692428a61fafc7e1290632395d5824a4d8,22,3,5,15206,,,0,"Copy created image into all available glance stores

The openstack can have multiple glance stores deployed/available.
It may be a proper thing to copy newly created signed image into
all the available glance stores so barbican tempest tests can access
image regardless on which compute and storage backend they are ran on
and regardless on which glance store is local.
Additionally there is a nova-compute conf parameter[1] which can even
prevent instances being spawned from image which is not available in local
glance store.
The copy-image would happen only if import_image tempest cong option
is available which indicates glance multistore is available.

[1] https://review.opendev.org/#/c/657078/

Change-Id: I1f0d8be1b237da0c96e820c4b3dca09a83b29752
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/85/763485/4 && git format-patch -1 --stdout FETCH_HEAD,['barbican_tempest_plugin/tests/scenario/manager.py'],1,b9e0a6e63e4d1a653f7439630db41b851257e695,glance-multistore," if CONF.image_feature_enabled.import_image: available_stores = [] try: available_stores = self.image_client.info_stores()['stores'] except exceptions.NotFound: pass available_import_methods = self.image_client.info_import()[ 'import-methods']['value'] if ('copy-image' in available_import_methods and len(available_stores) > 1): self.image_client.image_import(image['id'], method='copy-image', all_stores = True, all_stores_must_succeed = False) failed_stores = waiters.wait_for_image_copied_to_stores( self.image_client, image['id']) self.assertEqual(0, len(failed_stores), ""Failed to copy the following stores: %s"" % str(failed_stores)) ",,22,0
openstack%2Fcinder~stable%2Fussuri~I74c86ac5be06e5dc845dfc712b67f6213c232c43,openstack/cinder,stable/ussuri,I74c86ac5be06e5dc845dfc712b67f6213c232c43,"[storwize] test commit, to be abandoned.",ABANDONED,2020-09-17 06:31:01.000000000,2021-02-09 14:45:56.000000000,,"[{'_account_id': 4523}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26537}, {'_account_id': 30615}, {'_account_id': 32036}]","[{'number': 1, 'created': '2020-09-17 06:31:01.000000000', 'files': ['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/02e78b076c971a58fa577884c6d8cdf320a8874d', 'message': '[storwize] test commit, to be abandoned.\n\nThis change will be abandoned once IBM Storage CI\nis run on Ussuri.\n\nChange-Id: I74c86ac5be06e5dc845dfc712b67f6213c232c43\n'}]",0,752374,02e78b076c971a58fa577884c6d8cdf320a8874d,43,17,1,32036,,,0,"[storwize] test commit, to be abandoned.

This change will be abandoned once IBM Storage CI
is run on Ussuri.

Change-Id: I74c86ac5be06e5dc845dfc712b67f6213c232c43
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/752374/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'],1,02e78b076c971a58fa577884c6d8cdf320a8874d,ussuri, LOG.debug('enter: run_consistgrp_snapshots'),,1,0
openstack%2Fcinder~stable%2Ftrain~Ia444b56de264874858b2ee940dfb2031b32905f1,openstack/cinder,stable/train,Ia444b56de264874858b2ee940dfb2031b32905f1,"[storwize] test commit, to be abandoned",ABANDONED,2020-09-20 06:33:33.000000000,2021-02-09 14:45:53.000000000,,"[{'_account_id': 4523}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 32036}]","[{'number': 1, 'created': '2020-09-20 06:33:33.000000000', 'files': ['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/67031240ba3db18f22f1ea75ad24cda9f1b18648', 'message': '[storwize] test commit, to be abandoned\n\nChange-Id: Ia444b56de264874858b2ee940dfb2031b32905f1\n'}]",0,752810,67031240ba3db18f22f1ea75ad24cda9f1b18648,23,13,1,32036,,,0,"[storwize] test commit, to be abandoned

Change-Id: Ia444b56de264874858b2ee940dfb2031b32905f1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/752810/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'],1,67031240ba3db18f22f1ea75ad24cda9f1b18648,train, LOG.debug('Entered run_consistgrp_snapshots'),,1,0
openstack%2Fcharm-guide~master~Ia59776eddf2fe7c595f123acf346d77e7d9f209a,openstack/charm-guide,master,Ia59776eddf2fe7c595f123acf346d77e7d9f209a,Add known issue for OVS-OVN migration on Groovy,MERGED,2021-01-28 07:19:45.000000000,2021-02-09 14:36:45.000000000,2021-02-09 14:34:57.000000000,"[{'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2021-01-28 07:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/e50a7d54d68963cbc57317c2e7e9925424d3187a', 'message': ""Add known issue for OVS-OVN migration on Groovy\n\nThe root of the issue is in Open vSwitch itself and it is not\neasilly workaroundable in the charms.\n\nWe'll pursue a upstream/package level fix.\n\nRelated-Bug: #1852221\nChange-Id: Ia59776eddf2fe7c595f123acf346d77e7d9f209a\n""}, {'number': 2, 'created': '2021-01-28 10:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/45904e5aa2395f3f95521e1664ed265b9e778f6e', 'message': ""Add known issue for OVS-OVN migration on Groovy\n\nThe root of the issue is in Open vSwitch itself and it is not\neasilly workaroundable in the charms.\n\nWe'll pursue a upstream/package level fix.\n\nRelated-Bug: #1852221\nChange-Id: Ia59776eddf2fe7c595f123acf346d77e7d9f209a\n""}, {'number': 3, 'created': '2021-02-09 13:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/5f7987ee7e67a18afabbaf91e216b46e05f64ae1', 'message': ""Add known issue for OVS-OVN migration on Groovy\n\nThe root of the issue is in Open vSwitch itself and it is not\neasilly workaroundable in the charms.\n\nWe'll pursue a upstream/package level fix.\n\nRelated-Bug: #1852221\nChange-Id: Ia59776eddf2fe7c595f123acf346d77e7d9f209a\n""}, {'number': 4, 'created': '2021-02-09 13:57:28.000000000', 'files': ['doc/source/2101.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/e71b06319b55e07b0936016dba754efc09df3c84', 'message': ""Add known issue for OVS-OVN migration on Groovy\n\nThe root of the issue is in Open vSwitch itself and it is not\neasilly workaroundable in the charms.\n\nWe'll pursue a upstream/package level fix.\n\nRelated-Bug: #1852221\nChange-Id: Ia59776eddf2fe7c595f123acf346d77e7d9f209a\n""}]",12,772832,e71b06319b55e07b0936016dba754efc09df3c84,14,2,4,13686,,,0,"Add known issue for OVS-OVN migration on Groovy

The root of the issue is in Open vSwitch itself and it is not
easilly workaroundable in the charms.

We'll pursue a upstream/package level fix.

Related-Bug: #1852221
Change-Id: Ia59776eddf2fe7c595f123acf346d77e7d9f209a
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/32/772832/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/2101.rst'],1,e50a7d54d68963cbc57317c2e7e9925424d3187a,bug/1852221,"OVS to OVN migration process on Ubuntu Groovy ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ When performed on Ubuntu Groovy, the procedure for migrating an OpenStack cloud from ML2+OVS to ML2+OVN may require a extra step due to Open vSwitch bug `LP #1852221`_. Following the procedure in the `Migration from Neutron ML2+OVS to ML2+OVN`_ section of the deploy guide, the workaround is to restart the `ovs-vswitchd` service after resuming the ovn-chassis charm in step 15. .. _Migration from Neutron ML2+OVS to ML2+OVN: https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/app-ovn.html#migration-from-neutron-ml2-ovs-to-ml2-ovn.. _LP #1852221: https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1852221",,11,0
openstack%2Fswift~master~I32f979f068592eaac39dcc6807b3114caeaaa814,openstack/swift,master,I32f979f068592eaac39dcc6807b3114caeaaa814,relinker: Allow conf files for configuration,MERGED,2021-02-02 05:33:07.000000000,2021-02-09 14:33:43.000000000,2021-02-09 14:26:41.000000000,"[{'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 05:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/806fdc304503e9cfe94d23d9d49025cb43e5eec6', 'message': 'relinker: Allow conf files for configuration\n\nSwap out the standard logger stuff in place of --logfile and --debug.\nKeep --device as a CLI-only option. Everything else is pretty standard\nstuff that ought to be in [DEFAULT].\n\nChange-Id: I32f979f068592eaac39dcc6807b3114caeaaa814\n'}, {'number': 2, 'created': '2021-02-02 17:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7294270291db331bacda72593b07e9a4f4cad92f', 'message': 'relinker: Allow conf files for configuration\n\nSwap out the standard logger stuff in place of --logfile and --debug.\nKeep --device as a CLI-only option. Everything else is pretty standard\nstuff that ought to be in [DEFAULT].\n\nChange-Id: I32f979f068592eaac39dcc6807b3114caeaaa814\n'}, {'number': 3, 'created': '2021-02-08 23:44:22.000000000', 'files': ['doc/saio/swift/object-server/4.conf', 'test/probe/test_object_partpower_increase.py', 'doc/saio/swift/object-server/3.conf', 'test/unit/cli/test_relinker.py', 'doc/saio/swift/object-server/2.conf', 'swift/cli/relinker.py', 'doc/saio/swift/object-server/1.conf', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/1b7dd34d38c26c3d26c98341499973cc87bad2e1', 'message': 'relinker: Allow conf files for configuration\n\nSwap out the standard logger stuff in place of --logfile. Keep --device\nas a CLI-only option. Everything else is pretty standard stuff that\nought to be in [DEFAULT].\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I32f979f068592eaac39dcc6807b3114caeaaa814\n'}]",12,773572,1b7dd34d38c26c3d26c98341499973cc87bad2e1,19,2,3,15343,,,0,"relinker: Allow conf files for configuration

Swap out the standard logger stuff in place of --logfile. Keep --device
as a CLI-only option. Everything else is pretty standard stuff that
ought to be in [DEFAULT].

Co-Authored-By: Alistair Coles <alistairncoles@gmail.com>
Change-Id: I32f979f068592eaac39dcc6807b3114caeaaa814
",git fetch https://review.opendev.org/openstack/swift refs/changes/72/773572/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/saio/swift/object-server/4.conf', 'test/probe/test_object_partpower_increase.py', 'doc/saio/swift/object-server/3.conf', 'doc/saio/swift/object-server/2.conf', 'swift/cli/relinker.py', 'doc/saio/swift/object-server/1.conf', 'etc/object-server.conf-sample']",7,806fdc304503e9cfe94d23d9d49025cb43e5eec6,relinker, [object-relinker],,39,28
openstack%2Fneutron~stable%2Fussuri~I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8,openstack/neutron,stable/ussuri,I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8,Add extension unit tests for conntrack_helper plugin,MERGED,2021-02-09 05:30:34.000000000,2021-02-09 14:33:42.000000000,2021-02-09 14:27:10.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 05:30:34.000000000', 'files': ['neutron/tests/unit/extensions/test_l3_conntrack_helper.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/75b8fa7e7b6761fa7a78183d0b77499464ea2bdf', 'message': 'Add extension unit tests for conntrack_helper plugin\n\nChange-Id: I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8\n(cherry picked from commit cbfac6b7a849a5b7344c525d8fd070e48bdbe6b2)\n'}]",0,774491,75b8fa7e7b6761fa7a78183d0b77499464ea2bdf,9,3,1,28329,,,0,"Add extension unit tests for conntrack_helper plugin

Change-Id: I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8
(cherry picked from commit cbfac6b7a849a5b7344c525d8fd070e48bdbe6b2)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/774491/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/extensions/test_l3_conntrack_helper.py'],1,75b8fa7e7b6761fa7a78183d0b77499464ea2bdf,add-conntrack-helper-extension-unit-test-stable/ussuri,"# Copyright 2021 Troila # All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from unittest import mock from webob import exc from neutron_lib.api.definitions import l3 as l3_apidef from neutron_lib.api.definitions import l3_conntrack_helper as l3_ct from neutron_lib import context from oslo_utils import uuidutils from neutron.extensions import l3 from neutron.extensions import l3_conntrack_helper from neutron.tests.unit.api import test_extensions from neutron.tests.unit.extensions import test_l3 _uuid = uuidutils.generate_uuid class TestL3ConntrackHelperServicePlugin(test_l3.TestL3NatServicePlugin): supported_extension_aliases = [l3_apidef.ALIAS, l3_ct.ALIAS] class ExtendL3ConntrackHelperExtensionManager(object): def get_resources(self): return (l3.L3.get_resources() + l3_conntrack_helper.L3_conntrack_helper.get_resources()) def get_actions(self): return [] def get_request_extensions(self): return [] class L3NConntrackHelperTestCase(test_l3.L3BaseForIntTests, test_l3.L3NatTestCaseMixin): tenant_id = _uuid() fmt = ""json"" def setUp(self): mock.patch('neutron.api.rpc.handlers.resources_rpc.' 'ResourcesPushRpcApi').start() svc_plugins = ('neutron.services.conntrack_helper.plugin.Plugin', 'neutron.tests.unit.extensions.' 'test_l3_conntrack_helper.' 'TestL3ConntrackHelperServicePlugin') plugin = ('neutron.tests.unit.extensions.test_l3.TestL3NatIntPlugin') ext_mgr = ExtendL3ConntrackHelperExtensionManager() super(L3NConntrackHelperTestCase, self).setUp( ext_mgr=ext_mgr, service_plugins=svc_plugins, plugin=plugin) self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr) def _create_router_conntrack_helper(self, fmt, router_id, protocol, port, helper): tenant_id = self.tenant_id or _uuid() data = {'conntrack_helper': { ""protocol"": protocol, ""port"": port, ""helper"": helper} } router_ct_req = self._req( 'POST', 'routers', data, fmt or self.fmt, id=router_id, subresource='conntrack_helpers') router_ct_req.environ['neutron.context'] = context.Context( '', tenant_id, is_admin=True) return router_ct_req.get_response(self.ext_api) def _update_router_conntrack_helper(self, fmt, router_id, conntrack_helper_id, **kwargs): conntrack_helper = {} for k, v in kwargs.items(): conntrack_helper[k] = v data = {'conntrack_helper': conntrack_helper} router_ct_req = self._req( 'PUT', 'routers', data, fmt or self.fmt, id=router_id, sub_id=conntrack_helper_id, subresource='conntrack_helpers') return router_ct_req.get_response(self.ext_api) def test_create_ct_with_duplicate_entry(self): with self.router() as router: ct1 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct1.status_code) ct2 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPBadRequest.code, ct2.status_code) expect_msg = (""Bad conntrack_helper request: A duplicate "" ""conntrack helper entry with same attributes "" ""already exists, conflicting values are "" ""{'router_id': '%s', 'protocol': 'udp', "" ""'port': 69, 'helper': "" ""'tftp'}."") % router['router']['id'] self.assertEqual( expect_msg, ct2.json_body['NeutronError']['message']) def test_update_ct_with_duplicate_entry(self): with self.router() as router: ct1 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct1.status_code) ct2 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 68, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct2.status_code) result = self._update_router_conntrack_helper( self.fmt, router['router']['id'], ct1.json['conntrack_helper']['id'], **{'port': 68}) self.assertEqual(exc.HTTPBadRequest.code, result.status_code) expect_msg = (""Bad conntrack_helper request: A duplicate "" ""conntrack helper entry with same attributes "" ""already exists, conflicting values are "" ""{'router_id': '%s', 'protocol': 'udp', "" ""'port': 68, 'helper': "" ""'tftp'}."") % router['router']['id'] self.assertEqual( expect_msg, result.json_body['NeutronError']['message']) ",,141,0
openstack%2Fswift~master~Ifc47b00c597217efb4d705bd84dc8f7df117ae9d,openstack/swift,master,Ifc47b00c597217efb4d705bd84dc8f7df117ae9d,relinker: Pull arg parsing into module,MERGED,2021-02-02 05:33:07.000000000,2021-02-09 14:31:12.000000000,2021-02-09 14:25:40.000000000,"[{'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 05:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0c4c995cfb9646e5a1856b82e36bc625d1e88aef', 'message': ""relinker: Pull arg parsing into module\n\nThis allows us to do testing that's more end-to-end.\n\nChange-Id: Ifc47b00c597217efb4d705bd84dc8f7df117ae9d\n""}, {'number': 2, 'created': '2021-02-02 17:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c7d40508a1682c0a5fd363d682089d7f10a6cd18', 'message': ""relinker: Pull arg parsing into module\n\nThis allows us to do testing that's more end-to-end.\n\nChange-Id: Ifc47b00c597217efb4d705bd84dc8f7df117ae9d\n""}, {'number': 3, 'created': '2021-02-08 23:44:22.000000000', 'files': ['test/probe/test_object_partpower_increase.py', 'bin/swift-object-relinker', 'test/unit/cli/test_relinker.py', 'swift/cli/relinker.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e72aaf0c57eb3b7ed4ef1561fb544c1e6c6e8725', 'message': ""relinker: Pull arg parsing into module\n\nThis allows us to do testing that's more end-to-end.\n\nChange-Id: Ifc47b00c597217efb4d705bd84dc8f7df117ae9d\n""}]",6,773571,e72aaf0c57eb3b7ed4ef1561fb544c1e6c6e8725,15,3,3,15343,,,0,"relinker: Pull arg parsing into module

This allows us to do testing that's more end-to-end.

Change-Id: Ifc47b00c597217efb4d705bd84dc8f7df117ae9d
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/773571/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/test_object_partpower_increase.py', 'bin/swift-object-relinker', 'test/unit/cli/test_relinker.py', 'swift/cli/relinker.py']",4,0c4c995cfb9646e5a1856b82e36bc625d1e88aef,relinker,"import argparse audit_location_generator diskfile_router = diskfile.DiskFileRouter(conf, logger) parser = argparse.ArgumentParser( description='Relink and cleanup objects to increase partition power') parser.add_argument('action', choices=['relink', 'cleanup']) parser.add_argument('--swift-dir', default='/etc/swift', dest='swift_dir', help='Path to swift directory') parser.add_argument('--devices', default='/srv/node', dest='devices', help='Path to swift device directory') parser.add_argument('--device', default=None, dest='device', help='Device name to relink (default: all)') parser.add_argument('--skip-mount-check', default=False, help='Don\'t test if disk is mounted', action=""store_true"", dest='skip_mount_check') parser.add_argument('--logfile', default=None, dest='logfile', help='Set log file name') parser.add_argument('--debug', default=False, action='store_true', help='Enable debug mode') args = parser.parse_args(args) "," audit_location_generator, get_logger diskfile_router = diskfile.DiskFileRouter(conf, get_logger(conf))",129,49
openstack%2Fneutron~master~I3c106ace74b5c6e4ed0cb7e827baf5d6595ec5d0,openstack/neutron,master,I3c106ace74b5c6e4ed0cb7e827baf5d6595ec5d0,[OVN] Fix RowNotFound exception while waiting for metadata networks,MERGED,2021-02-03 14:09:28.000000000,2021-02-09 14:31:02.000000000,2021-02-09 14:24:54.000000000,"[{'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2021-02-03 14:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/acbb83a9b40530b22ce586ae8a448a5fbb2b35f9', 'message': '[OVN] Fix RowNotFound exception while waiting for metadata networks\n\nIn the set_port_status_up() the OVN driver waits for the metadata to be\nprovisioned (15 seconds) [0] prior to sending the event to Nova notifying\nthat the provisioning of the port is done (network-vif-plugged). But\nthere could be a race condition while trying to get that information\nwhich results in a RowNotFound being raise in the waiting loop.\n\nOnce that happens, the exception is bubbled up and the OVN driver end up\nnot sending the event to Nova and the instance will fail to deploy (it\nwill be stuck in BUILD state until it times out).\n\nThis patch changes the logic of the method looking for the metadata\nnetwork information to not raise RowNotFound so that the waiting loop\ncan iteract again [0] until the information is available.\n\n[0]\nhttps://github.com/openstack/neutron/blob/cbd72e2f4846ec64ff6e6ef24099a8e90ddebf31/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py#L1124\n\nChange-Id: I3c106ace74b5c6e4ed0cb7e827baf5d6595ec5d0\nCloses-Bug: #1914394\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2021-02-08 12:17:36.000000000', 'files': ['neutron/tests/unit/fake_resources.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b618d98541599ad0ef73be41a3edd83d1fc75a56', 'message': '[OVN] Fix RowNotFound exception while waiting for metadata networks\n\nIn the set_port_status_up() the OVN driver waits for the metadata to be\nprovisioned (15 seconds) [0] prior to sending the event to Nova notifying\nthat the provisioning of the port is done (network-vif-plugged). But\nthere could be a race condition while trying to get that information\nwhich results in a RowNotFound being raise in the waiting loop.\n\nOnce that happens, the exception is bubbled up and the OVN driver end up\nnot sending the event to Nova and the instance will fail to deploy (it\nwill be stuck in BUILD state until it times out).\n\nThis patch changes the logic of the method looking for the metadata\nnetwork information to not raise RowNotFound so that the waiting loop\ncan iteract again [0] until the information is available.\n\n[0]\nhttps://github.com/openstack/neutron/blob/cbd72e2f4846ec64ff6e6ef24099a8e90ddebf31/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py#L1124\n\nChange-Id: I3c106ace74b5c6e4ed0cb7e827baf5d6595ec5d0\nCloses-Bug: #1914394\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",2,773893,b618d98541599ad0ef73be41a3edd83d1fc75a56,32,7,2,6773,,,0,"[OVN] Fix RowNotFound exception while waiting for metadata networks

In the set_port_status_up() the OVN driver waits for the metadata to be
provisioned (15 seconds) [0] prior to sending the event to Nova notifying
that the provisioning of the port is done (network-vif-plugged). But
there could be a race condition while trying to get that information
which results in a RowNotFound being raise in the waiting loop.

Once that happens, the exception is bubbled up and the OVN driver end up
not sending the event to Nova and the instance will fail to deploy (it
will be stuck in BUILD state until it times out).

This patch changes the logic of the method looking for the metadata
network information to not raise RowNotFound so that the waiting loop
can iteract again [0] until the information is available.

[0]
https://github.com/openstack/neutron/blob/cbd72e2f4846ec64ff6e6ef24099a8e90ddebf31/neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py#L1124

Change-Id: I3c106ace74b5c6e4ed0cb7e827baf5d6595ec5d0
Closes-Bug: #1914394
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/773893/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py'],1,acbb83a9b40530b22ce586ae8a448a5fbb2b35f9,bug/1914394-ovn-metadata-networks," cmd = self.db_find('Chassis', ('name', '=', chassis_name)).execute( check_error=True) result = cmd[0] if cmd else None if not result: LOG.warning(""Couldn't find Chassis named %s in OVN while looking "" ""for metadata networks"", chassis_name) return [] proxy_networks = result['external_ids'].get("," chassis = self.lookup('Chassis', chassis_name) proxy_networks = chassis.external_ids.get(",8,2
openstack%2Fneutron~stable%2Fussuri~I1d0b3975ae6e92e34e9da20a0e26ce024422d332,openstack/neutron,stable/ussuri,I1d0b3975ae6e92e34e9da20a0e26ce024422d332,Optimize get_ports with QoS extension,MERGED,2021-02-02 06:13:16.000000000,2021-02-09 14:30:59.000000000,2021-02-09 14:24:45.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 06:13:16.000000000', 'files': ['neutron/services/qos/qos_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/76a57e9cf5ea25a7ff4bca9c94b08b97f308da7e', 'message': 'Optimize get_ports with QoS extension\n\nApply qos resource extend func for a full list of ports,\nnot for each port individually, thus avoiding DB queries for each\nindividual port.\nThis should drastically improve port list time in case of many\nports/network with QoS policies assigned.\n\nChange-Id: I1d0b3975ae6e92e34e9da20a0e26ce024422d332\nCloses-Bug: #1905726\n(cherry picked from commit 2a6fd9d44d8ab1eed038ad1348ed767bd6a6e61a)\n'}]",0,773581,76a57e9cf5ea25a7ff4bca9c94b08b97f308da7e,48,3,1,5948,,,0,"Optimize get_ports with QoS extension

Apply qos resource extend func for a full list of ports,
not for each port individually, thus avoiding DB queries for each
individual port.
This should drastically improve port list time in case of many
ports/network with QoS policies assigned.

Change-Id: I1d0b3975ae6e92e34e9da20a0e26ce024422d332
Closes-Bug: #1905726
(cherry picked from commit 2a6fd9d44d8ab1eed038ad1348ed767bd6a6e61a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/773581/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/qos/qos_plugin.py'],1,76a57e9cf5ea25a7ff4bca9c94b08b97f308da7e,bug/1905726-stable/ussuri," if port_res.get('bulk'): port_res['resource_request'] = { 'qos_id': qos_id, 'network_id': port_db.network_id, 'vnic_type': port_res[portbindings.VNIC_TYPE]} return port_res min_bw_rules = rule_object.QosMinimumBandwidthRule.get_objects( context.get_admin_context(), qos_policy_id=qos_id) resources = QoSPlugin._get_resources(min_bw_rules) if not resources: return port_res segments = network_object.NetworkSegment.get_objects( context.get_admin_context(), network_id=port_db.network_id) traits = QoSPlugin._get_traits(port_res[portbindings.VNIC_TYPE], segments) if not traits: return port_res port_res['resource_request'] = { 'required': traits, 'resources': resources} return port_res @staticmethod def _get_resources(min_bw_rules): return resources @staticmethod def _get_traits(vnic_type, segments): # TODO(lajoskatona): Change to handle all segments when any traits # support will be available. See Placement spec: # https://review.opendev.org/565730 first_segment = segments[0] if not first_segment or not first_segment.physical_network: return [] physnet_trait = pl_utils.physnet_trait( first_segment.physical_network) vnic_trait = pl_utils.vnic_type_trait(vnic_type) return [physnet_trait, vnic_trait] @staticmethod # TODO(obondarev): use neutron_lib constant @resource_extend.extends(['ports_bulk']) def _extend_port_resource_request_bulk(ports_res, noop): """"""Add resource request to a list of ports."""""" min_bw_rules = dict() net_segments = dict() for port_res in ports_res: if port_res.get('resource_request') is None: continue qos_id = port_res['resource_request'].pop('qos_id', None) if not qos_id: port_res['resource_request'] = None continue net_id = port_res['resource_request'].pop('network_id') vnic_type = port_res['resource_request'].pop('vnic_type') if qos_id not in min_bw_rules: rules = rule_object.QosMinimumBandwidthRule.get_objects( context.get_admin_context(), qos_policy_id=qos_id) min_bw_rules[qos_id] = rules resources = QoSPlugin._get_resources(min_bw_rules[qos_id]) if not resources: continue if net_id not in net_segments: segments = network_object.NetworkSegment.get_objects( context.get_admin_context(), network_id=net_id) net_segments[net_id] = segments traits = QoSPlugin._get_traits(vnic_type, net_segments[net_id]) if not traits: continue port_res['resource_request'] = { 'required': traits, 'resources': resources} return ports_res"," min_bw_rules = rule_object.QosMinimumBandwidthRule.get_objects( context.get_admin_context(), qos_policy_id=qos_id) if not resources: return port_res vnic_trait = pl_utils.vnic_type_trait( port_res[portbindings.VNIC_TYPE]) # TODO(lajoskatona): Change to handle all segments when any traits # support will be available. See Placement spec: # https://review.opendev.org/565730 first_segment = network_object.NetworkSegment.get_objects( context.get_admin_context(), network_id=port_db.network_id)[0] if not first_segment or not first_segment.physical_network: return port_res physnet_trait = pl_utils.physnet_trait( first_segment.physical_network) port_res['resource_request'] = { 'required': [physnet_trait, vnic_trait], 'resources': resources} return port_res",82,19
openstack%2Foctavia-tempest-plugin~master~I0d89f1408a7a539d3982a3710635563939820758,openstack/octavia-tempest-plugin,master,I0d89f1408a7a539d3982a3710635563939820758,WIP DNM Fix IPv6 VIP network connectivity,ABANDONED,2021-02-04 14:26:53.000000000,2021-02-09 14:28:33.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 14:26:53.000000000', 'files': ['octavia_tempest_plugin/tests/test_base.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/ee3a7dcd17fc96c24d14103be6b8a00c3f752955', 'message': 'WIP DNM Fix IPv6 VIP network connectivity\n\nThis commit adds a route to an ipv6 subnet from the devstack\nnode.\n\nDepends-On: https://review.opendev.org/c/openstack/octavia/+/773798\n\nChange-Id: I0d89f1408a7a539d3982a3710635563939820758\n'}]",0,774086,ee3a7dcd17fc96c24d14103be6b8a00c3f752955,3,2,1,29244,,,0,"WIP DNM Fix IPv6 VIP network connectivity

This commit adds a route to an ipv6 subnet from the devstack
node.

Depends-On: https://review.opendev.org/c/openstack/octavia/+/773798

Change-Id: I0d89f1408a7a539d3982a3710635563939820758
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/86/774086/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/tests/test_base.py'],1,ee3a7dcd17fc96c24d14103be6b8a00c3f752955,," subnet_kwargs = { 'name': data_utils.rand_name(""lb_member_vip_ipv6_subnet""), 'network_id': cls.lb_member_vip_net['id'], 'cidr': CONF.load_balancer.vip_ipv6_subnet_cidr, 'ip_version': 6} result = cls.lb_mem_subnet_client.create_subnet( **subnet_kwargs) cls.lb_member_vip_ipv6_net = cls.lb_member_vip_net cls.lb_member_vip_ipv6_subnet = result['subnet'] cls.addClassResourceCleanup( waiters.wait_for_not_found, cls._logging_delete_subnet, cls.lb_mem_subnet_client.show_subnet, cls.lb_member_vip_ipv6_subnet['id']) if CONF.load_balancer.test_with_ipv6: # Add IPv6 VIP subnet to router cls.lb_mem_routers_client.add_router_interface( cls.lb_member_router['id'], subnet_id=cls.lb_member_vip_ipv6_subnet['id']) cls.addClassResourceCleanup( waiters.wait_for_not_found, cls.lb_mem_routers_client.remove_router_interface, cls.lb_mem_routers_client.remove_router_interface, cls.lb_member_router['id'], subnet_id=cls.lb_member_vip_ipv6_subnet['id']) external_gateway_info = ( cls.lb_member_router['external_gateway_info']) external_ipv6_gateway = [ fixed_ips['ip_address'] for fixed_ips in external_gateway_info['external_fixed_ips'] if ':' in fixed_ips['ip_address'] # XXX ][0] ipv6_subnet_cidr = cls.lb_member_vip_ipv6_subnet['cidr'] # XXX Don't look! this is just a test cmd = ""sudo ip -6 route add {} via {}"".format( ipv6_subnet_cidr, external_ipv6_gateway) p = subprocess.check_output(cmd, shell=True) print(p) def _delete_route(cidr, gateway): cmd = ""sudo ip -6 route delete {} via {}"".format(cidr, gateway) p = subprocess.check_output(cmd, shell=True) print(p) cls.addClassResourceCleanup(_delete_route, ipv6_subnet_cidr, external_ipv6_gateway) "," # See if ipv6-private-subnet exists and use it if so. priv_ipv6_subnet = cls.os_admin.subnets_client.list_subnets( name='ipv6-private-subnet')['subnets'] if len(priv_ipv6_subnet) == 1: if (priv_ipv6_subnet[0]['ipv6_address_mode'] == 'dhcpv6-stateful'): cls.lb_member_vip_ipv6_subnet_stateful = True cls.lb_member_vip_ipv6_subnet = priv_ipv6_subnet[0] cls.lb_member_vip_ipv6_net = { 'id': priv_ipv6_subnet[0]['network_id']} else: subnet_kwargs = { 'name': data_utils.rand_name(""lb_member_vip_ipv6_subnet""), 'network_id': cls.lb_member_vip_net['id'], 'cidr': CONF.load_balancer.vip_ipv6_subnet_cidr, 'ip_version': 6} result = cls.lb_mem_subnet_client.create_subnet( **subnet_kwargs) cls.lb_member_vip_ipv6_net = cls.lb_member_vip_net cls.lb_member_vip_ipv6_subnet = result['subnet'] cls.addClassResourceCleanup( waiters.wait_for_not_found, cls._logging_delete_subnet, cls.lb_mem_subnet_client.show_subnet, cls.lb_member_vip_ipv6_subnet['id'])",49,26
openstack%2Fneutron~stable%2Fussuri~I89438feae3c0244f6da5e6a2a035d45b956ac247,openstack/neutron,stable/ussuri,I89438feae3c0244f6da5e6a2a035d45b956ac247,Process DHCP events in order if related,MERGED,2021-02-07 10:05:32.000000000,2021-02-09 14:21:18.000000000,2021-02-09 14:17:37.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 10:05:32.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc01f5b33011675a919bd80cc4f021066d7f2fc4', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}]",0,774272,dc01f5b33011675a919bd80cc4f021066d7f2fc4,10,4,1,16688,,,0,"Process DHCP events in order if related

When processing port events (create, update, delete), the port
provisioning (port creation) has priority over the other events [1].
As reported in the related bug, if a port deletion with an IP
address and another port creation with the same IP address arrive
to the DHCP agent, those events can be processed in the same queue.

Because of the creation event priority, even when this event arrived
after the deletion event, it will be processed first. That will
clash with the DHCP agent cache, that contains a port (not deleted
yet) with the same IP address. That will trigger an unwanted resync.

This patch implements a specific logic to store the events in
""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When
a port event arrives, the event comparison method checks the
(subnet, fixed_ips) tuple set of both elements. If there is a
coincidence, that means those ports are the same or are using
the same IP addreses (the race condition explained in the bug).
In this case, the priority is defined only by the timestamp;
that means the events are processed in order of arrival.

Because the Neutron server do not allow to have two ports in the
same subnet with the same IP address, the order of the events is
guaranteed. In the case explained in the bug, the deletion event
will be processed first.

[1]https://review.opendev.org/c/openstack/neutron/+/626830
[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue

Closes-Bug: #1913723

Change-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/774272/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py']",4,dc01f5b33011675a919bd80cc4f021066d7f2fc4,bug/1913723-stable/ussuri," port={'id': 'foo_port_id', 'network_id': 'foo_network_id', 'fixed_ips': {'subnet_id': 'subnet1', 'ip_address': '10.0.0.1'}}),"," port={'id': 'foo_port_id', 'network_id': 'foo_network_id'}),",129,42
openstack%2Fcharm-glance~master~I5cf12b5959ac116f95c15c516b69d85d6f160bf7,openstack/charm-glance,master,I5cf12b5959ac116f95c15c516b69d85d6f160bf7,Clarify object storage and multi-backend support,MERGED,2021-02-04 01:26:38.000000000,2021-02-09 14:12:54.000000000,2021-02-09 14:12:54.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2021-02-04 01:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/590f2b94b699189292832a78c0f0f2f72788a1b5', 'message': 'Clarify object storage and multi-backend support\n\nChange-Id: I5cf12b5959ac116f95c15c516b69d85d6f160bf7\n'}, {'number': 2, 'created': '2021-02-04 01:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/dcc4adc6ae1c03edefc6bec1086ef3f2fedb7271', 'message': 'Clarify object storage and multi-backend support\n\nUpdate README.md\n\nChange-Id: I5cf12b5959ac116f95c15c516b69d85d6f160bf7\n'}, {'number': 3, 'created': '2021-02-04 01:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/ccd0438c09f38f6feed9e0046b025a73899aba56', 'message': 'Clarify object storage and multi-backend support\n\nUpdate README.md\n\nChange-Id: I5cf12b5959ac116f95c15c516b69d85d6f160bf7\n'}, {'number': 4, 'created': '2021-02-08 17:02:48.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/f83ab69d757fad7f04aa3e9cd338e18c3eb1c2f1', 'message': 'Clarify object storage and multi-backend support\n\nUpdate README.md\n\nChange-Id: I5cf12b5959ac116f95c15c516b69d85d6f160bf7\n'}]",2,774026,f83ab69d757fad7f04aa3e9cd338e18c3eb1c2f1,18,5,4,30561,,,0,"Clarify object storage and multi-backend support

Update README.md

Change-Id: I5cf12b5959ac116f95c15c516b69d85d6f160bf7
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/26/774026/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,590f2b94b699189292832a78c0f0f2f72788a1b5,talk-about-multi-backend-support,"This section includes four different deployment scenarios (with their respective backends). Each scenario requires these applications to be present: keystone, nova-cloud-controller, nova-compute, and a cloud database. > **Note**: The database application is determined by the series. Prior to focal [percona-cluster][percona-cluster-charm] is used, otherwise it is [mysql-innodb-cluster][mysql-innodb-cluster-charm]. In the example deployments below mysql-innodb-cluster has been chosen.### Object storage-backed storage Glance can use Object storage as its storage backend. OpenStack Swift and Ceph RADOS Gateway are supported, and both resulting configurations can be used to support Glance in HA/scale-out deployments. #### Swift The steps below assume a pre-existing Swift deployment (see the [swift-proxy][swift-proxy-charm] and [swift-storage][swift-storage-charm] charms).#### Ceph RADOS Gateway The steps below assume a pre-existing Ceph RADOS Gateway deployment (see the [ceph-radosgw][ceph-radosgw-charm]). Here, Glance is deployed to a container on machine '1' and related to the ceph-radosgw application: juju deploy --to lxd:1 glance juju add-relation glance:object-store ceph-radosgw:object-store Proceed with the common group of commands from the Ceph scenario.## Multiple backends If multiple storage backends are configured the cloud operator can, at image upload time, select a backend by using the `--store` option to the `glance` CLI client: glance image-create --store <backend-name> ... Otherwise, the default backend is determined by the following precedence order of backend names: 'ceph', 'swift', and then 'local'. > **Important**: The backend name of 'swift' denotes both object storage solutions (i.e. Swift and Ceph RADOS Gateway). [ceph-radosgw-charm]: https://jaas.ai/ceph-radosgw","This section includes three different deployment scenarios, each of which requires these applications to be present: keystone, nova-cloud-controller, nova-compute, and a cloud database. The database application is determined by the series. Prior to focal [percona-cluster][percona-cluster-charm] is used, otherwise it is [mysql-innodb-cluster][mysql-innodb-cluster-charm]. In the example deployment below mysql-innodb-cluster has been chosen.### Swift-backed storage Glance can use OpenStack Swift as its storage backend. The steps below assume a pre-existing Swift deployment (see the [swift-proxy][swift-proxy-charm] and [swift-storage][swift-storage-charm] charms).This configuration can be used to support Glance in HA/scale-out deployments.",44,12
openstack%2Ftripleo-common~master~I890134743c0cc928d10f43a35924b07ea67f9adf,openstack/tripleo-common,master,I890134743c0cc928d10f43a35924b07ea67f9adf,Replace swift backend with native OS calls,ABANDONED,2020-09-22 18:42:35.000000000,2021-02-09 14:11:49.000000000,,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-09-22 18:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3a2c7dcacd4189795937f0753f9d16808d557f12', 'message': 'WIP - replace swift backend with native OS calls\n\nThis will replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the\nbackend, allowing us to disable swift with no impact on the function\nof the undercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2020-09-22 22:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c71f666498c56b203bc2952077a20cbda9663682', 'message': 'WIP - replace swift backend with native OS calls\n\nThis will replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the\nbackend, allowing us to disable swift with no impact on the function\nof the undercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2020-09-23 21:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ce6915f90eeecabb52a955d41476517b75f01d2b', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 4, 'created': '2020-10-08 17:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/71266ebdba878a121808f4fb8b9a4a0186f7f5e5', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 5, 'created': '2020-10-09 17:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1e2b814144e0bdcaabe1b90d2eb66e21f7ba5731', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 6, 'created': '2020-10-12 13:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f961f2fe114fa55e12c1ebf50145af5750b75ff5', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 7, 'created': '2020-10-12 20:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cb94854aa3ed9a5bac99c519825fbea95058c68c', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 8, 'created': '2020-10-12 21:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/69b08947958a3c806bba1b6363a1d4c3e9c991e8', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 9, 'created': '2020-10-12 22:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/eb253345ae090f18b7ab748cf111bfbd02c95bc8', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 10, 'created': '2020-10-13 13:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/295b622180a6e3d53b1507c79601417959c05b74', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 11, 'created': '2020-10-13 14:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d7d9ec7dd559f91bfb5893b35bab349719ba1d04', 'message': ""WIP - Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: I7531612a49527f8a21df415c648acb41ac7a0b10\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 12, 'created': '2020-10-13 18:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e9aee50af6d31f8e3b653c92b0fe9b632ec3c3aa', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 13, 'created': '2020-10-13 18:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/964216b8b26c6615ae6c91ff1282e86950cfcbeb', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 14, 'created': '2020-10-13 19:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3acf37218fe4468ac3633c164260bd336f4ceb0d', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 15, 'created': '2020-12-01 14:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/34cb90817d6b9e9938417b08e33346c27352ee4e', 'message': ""WIP - replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 16, 'created': '2020-12-01 14:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ceeedcec55ee1fce67ce9e311ac43da31f61107f', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 17, 'created': '2021-01-07 16:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a07fe49b453488bd8c7c5065d219d848bf1fe3b3', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 18, 'created': '2021-01-16 01:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/432ad42b0fb9abd5dcce9b55e0f053afe0f9717c', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 19, 'created': '2021-01-29 15:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5bf34af0b2703ffd0c58850e27d298d55f4a7629', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 20, 'created': '2021-01-29 18:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1da7b53a64e0b180bff25f870afa2a9c08f900bc', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 21, 'created': '2021-01-29 19:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a91d202ca0f602b795f586234c750de6a4f4dae1', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 22, 'created': '2021-01-29 21:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/20c24020c18715b7fe609a7396bd46e9fe3b0a1f', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 23, 'created': '2021-01-29 21:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/34124262568d55986629dccddaf6e501152db7c2', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}, {'number': 24, 'created': '2021-01-29 23:33:08.000000000', 'files': ['tripleo_common/utils/tarball.py', 'tripleo_common/tests/utils/test_stack.py', 'tripleo_common/tests/utils/test_plan.py', 'tripleo_common/tests/actions/test_plan.py', 'tripleo_common/tests/utils/test_config.py', 'tripleo_common/tests/utils/test_stack_parameters.py', 'tripleo_common/tests/utils/test_overcloudrc.py', 'tripleo_common/tests/utils/test_swift.py', 'tripleo_common/tests/actions/test_scale.py', 'tripleo_common/utils/artifact_store.py', 'tripleo_common/tests/utils/test_template.py', 'tripleo_common/utils/plan.py', 'tripleo_common/utils/template.py', 'tripleo_common/utils/swift.py', 'tripleo_common/utils/stack.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/061ef63564a2705e6ec14931ad40a1bc150133d5', 'message': ""Replace swift backend with native OS calls\n\nAdd a parallel stack to the swift backend to write objects to the local\nfile system on the undercloud.\n\nA new module has been created. This module will be used to transition\naway from the swift backend.\n\nEventually we'll replace all of the swift backend API calls with native OS\ncalls. The intention of this change is to transperently replace the backend,\nallowing us to disable swift with no impact on the function of the\nundercloud.\n\nDepends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b\nChange-Id: I890134743c0cc928d10f43a35924b07ea67f9adf\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n""}]",84,753427,061ef63564a2705e6ec14931ad40a1bc150133d5,74,5,24,7353,,,0,"Replace swift backend with native OS calls

Add a parallel stack to the swift backend to write objects to the local
file system on the undercloud.

A new module has been created. This module will be used to transition
away from the swift backend.

Eventually we'll replace all of the swift backend API calls with native OS
calls. The intention of this change is to transperently replace the backend,
allowing us to disable swift with no impact on the function of the
undercloud.

Depends-On: Ibe9b2ffe94cdf493fc84366979d1d78b8528ea1b
Change-Id: I890134743c0cc928d10f43a35924b07ea67f9adf
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/27/753427/24 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/swift.py'],1,3a2c7dcacd4189795937f0753f9d16808d557f12,config-download/swift,"import shutilTRIPLEO_STORE = os.path.abspath(os.path.expanduser('~/.tripleo')) """"""Proxy to remove a directory."""""" delete_container(swiftclient, name) """"""Remove a directory."""""" shutil.rmtree(os.path.join(TRIPLEO_STORE, name)) """"""This function no longer does anything and will be removed."""""" pass container_path = os.path.join(TRIPLEO_STORE, container) if not os.path.exists(container_path): os.makedirs(container_path) """"""This function no longer does anything and will be removed."""""" pass container_path = os.path.join(TRIPLEO_STORE, container) with open(os.path.join(container_path, object_name)) as f: return f.read() container_path = os.path.join(TRIPLEO_STORE, container) with open(os.path.join(container_path, object_name), 'w') as f: return f.write(contents) """"""This function no longer does anything and will be removed."""""" pass"," container_names = [container[""name""] for container in swiftclient.get_account()[1]] if name in container_names: headers, objects = swiftclient.get_container(name) # FIXME(rbrady): remove delete_object loop when # LP#1615830 is fixed. See LP#1615825 for more info. # delete files from plan for o in objects: swiftclient.delete_object(name, o['name']) else: error_text = ""The {name} container does not exist."".format(name=name) raise ValueError(error_text) try: empty_container(swiftclient, name) swiftclient.delete_container(name) except ValueError as e: # ValueError is raised when we can't find the container, which means # that it's already deleted. LOG.info(six.text_type(e)) """"""Download the contents of a Swift container to a directory"""""" objects = swiftclient.get_container(container)[1] for obj in objects: is_newer = False filename = obj['name'] contents = swiftclient.get_object(container, filename)[1] try: contents = contents.encode('utf-8') except (UnicodeDecodeError, AttributeError): pass path = os.path.join(dest, filename) dirname = os.path.dirname(path) already_exists = os.path.exists(path) if already_exists: last_modified = obj.get('last_modified', None) if last_modified is not None: last_mod_swift = int(dateutil.parser.parse( obj['last_modified']).strftime('%s')) last_mod_disk = int(os.path.getmtime(path)) if last_mod_swift > last_mod_disk: is_newer = True # write file if `overwrite_only_newer` is not set, # or if file does not exist at destination, # or if we found a newer file at source if (not overwrite_only_newer or not already_exists or (overwrite_only_newer and is_newer)): if not os.path.exists(dirname): os.makedirs(dirname) # open in binary as the swift client returns error # under python3 if opened as text with open(path, 'wb') as f: f.write(contents) swiftclient.put_container(container) """"""Create a tarball containing the tmp_dir and upload it to Swift. This method allows to upload files bigger than 5GB. It will create 2 swift containers to store the segments and one container to reference the manifest with the segment pointers """""" try: with tempfile.NamedTemporaryFile() as tmp_tarball: tarball.create_tarball(tmp_dir, tmp_tarball.name, tarball_options) objs = [SwiftUploadObject(tmp_tarball, object_name=tarball_name)] options = {'meta': [], 'header': ['X-Delete-After: ' + str(delete_after)], 'segment_size': segment_size, 'use_slo': use_slo, 'segment_container': segment_container, 'leave_segments': leave_segments, 'changed': changed, 'skip_identical': skip_identical, 'fail_fast': fail_fast, 'dir_marker': dir_marker } for r in swiftservice.upload(container, objs, options=options): if r['success']: if 'object' in r: LOG.info(r['object']) elif 'for_object' in r: LOG.info( '%s segment %s' % (r['for_object'], r['segment_index']) ) else: error = r['error'] if r['action'] == ""create_container"": LOG.warning( 'Warning: failed to create container ' ""'%s'%s"", container, error ) elif r['action'] == ""upload_object"": LOG.error( ""Failed to upload object %s to container %s: %s"" % (container, r['object'], error) ) else: LOG.error(""%s"" % error) except SwiftError as e: LOG.error(e.value) data = swift.get_object(container, object_name)[1] try: return data.decode('utf-8') except AttributeError: return data try: contents = contents.decode('utf-8') except AttributeError: pass return swift.put_object(container, object_name, contents) try: cont_stat = swift.head_container(container) except swiftexceptions.ClientException: cont_stat = {} key = cont_stat.get('x-container-meta-temp-url-key') if not key: key = str(uuid.uuid4()) cont_stat = swift.put_container( container, {'X-Container-Meta-Temp-Url-Key': key}) parsed = urllib.parse.urlparse(swift.url) path = ""%s/%s/%s"" % (parsed.path, container, object_name) temp_path = generate_temp_url(path, valid, key, method) return ""%s://%s%s"" % (parsed.scheme, parsed.netloc, temp_path)",25,135
openstack%2Fbarbican-tempest-plugin~master~Ia59a23a36ebb8548a20e894000f7342c73012eac,openstack/barbican-tempest-plugin,master,Ia59a23a36ebb8548a20e894000f7342c73012eac,Update hacking for Python3,MERGED,2019-01-04 15:55:21.000000000,2021-02-09 14:08:26.000000000,2021-02-09 14:08:26.000000000,"[{'_account_id': 7973}, {'_account_id': 9914}, {'_account_id': 10459}, {'_account_id': 11075}, {'_account_id': 15206}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27078}, {'_account_id': 27781}, {'_account_id': 27954}]","[{'number': 1, 'created': '2019-01-04 15:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/682c8ca87acf85c9f7919aa8f4ce8e1bd33cb4d5', 'message': 'Update hacking version to latest\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 2, 'created': '2019-01-04 17:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/e6a894e69521fd35a89d4d296c0673fae38aab04', 'message': 'Update hacking version to latest\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 3, 'created': '2019-03-20 16:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/950856e5bb06d576758137fa72b4f63971524a41', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 4, 'created': '2019-03-20 16:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/880d0d5a60a02e3de7dd9b8f6e5699f54ad1f85d', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 5, 'created': '2019-10-13 03:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/74a27952d4f84458102eef21a17047f22cd7a3d0', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 6, 'created': '2020-03-13 21:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/b310355cd4f0ac886cc5d01812d1c35278d3ab33', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 7, 'created': '2020-05-06 05:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/1fbcf96d6f10f2b315d7f654bb634a961d3dd0b1', 'message': 'Update hacking for Python3\n\nThe repo is Python 3 now, so update hacking to version 3.0 which\nsupports Python 3.\n\nFix problems found.\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 8, 'created': '2020-12-11 03:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/c090e3425a8ac144cb36d12b0a3e673e06b26bbc', 'message': 'Update hacking for Python3\n\nThe repo is Python 3 now, so update hacking to version 3.0 which\nsupports Python 3.\n\nFix problems found.\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}, {'number': 9, 'created': '2021-02-08 22:05:37.000000000', 'files': ['test-requirements.txt', '.zuul.yaml', 'tox.ini', 'barbican_tempest_plugin/tests/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/a318f6d77c0b354b4aee2fe9d7651d595adcf38e', 'message': 'Update hacking for Python3\n\nThe repo is Python 3 now, so update hacking to version 3.0 which\nsupports Python 3.\n\nFix problems found.\n\nChange-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac\n'}]",0,628499,a318f6d77c0b354b4aee2fe9d7651d595adcf38e,36,11,9,28614,,,0,"Update hacking for Python3

The repo is Python 3 now, so update hacking to version 3.0 which
supports Python 3.

Fix problems found.

Change-Id: Ia59a23a36ebb8548a20e894000f7342c73012eac
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/99/628499/9 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,682c8ca87acf85c9f7919aa8f4ce8e1bd33cb4d5,change-628499-7,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.13,>=0.12.0 # Apache-2.0",1,1
openstack%2Fbifrost~master~Ia68bef56edd7edec14f678155220b6e4e15e57f6,openstack/bifrost,master,Ia68bef56edd7edec14f678155220b6e4e15e57f6,Exit on all errors in bash scripts when possible,MERGED,2021-02-09 11:07:15.000000000,2021-02-09 14:04:30.000000000,2021-02-09 13:59:19.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 11:07:15.000000000', 'files': ['scripts/collect-test-info.sh', 'scripts/install-deps.sh', 'scripts/env-setup.sh', 'scripts/test-bifrost.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/422bafd6ea4a42d818e564a1778407dcc522aaed', 'message': 'Exit on all errors in bash scripts when possible\n\nExcept for the collect-test-info script, the other bash scripts should\njust exit on error.\n\nChange-Id: Ia68bef56edd7edec14f678155220b6e4e15e57f6\n'}]",0,774623,422bafd6ea4a42d818e564a1778407dcc522aaed,8,3,1,23851,,,0,"Exit on all errors in bash scripts when possible

Except for the collect-test-info script, the other bash scripts should
just exit on error.

Change-Id: Ia68bef56edd7edec14f678155220b6e4e15e57f6
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/23/774623/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/collect-test-info.sh', 'scripts/install-deps.sh', 'scripts/env-setup.sh', 'scripts/test-bifrost.sh']",4,422bafd6ea4a42d818e564a1778407dcc522aaed,exit-on-error,set -euxo pipefail ,set -eux set -o pipefail,6,6
openstack%2Fbifrost~master~I034bcd24031b5881ae49b8bc03bed6654cd1d335,openstack/bifrost,master,I034bcd24031b5881ae49b8bc03bed6654cd1d335,Install at least pip version 19.1.1,MERGED,2021-02-09 09:31:04.000000000,2021-02-09 14:01:54.000000000,2021-02-09 13:59:01.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 09:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/bd812bf2cedcb22f20a41f6ce2b6929fd58a282b', 'message': 'Install at least pip version 19.1.1\n\nThis is to avoid a known issue with a recent version of cryptography.\n\nChange-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335\n'}, {'number': 2, 'created': '2021-02-09 09:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5352a4152d837cd672917d6b857ed6548e74f7bf', 'message': 'Install at least pip version 19.1.1\n\nThis is to avoid a known issue with a recent version of cryptography [1]\n\n[1] https://github.com/pyca/cryptography/issues/5771\n\nChange-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335\n'}, {'number': 3, 'created': '2021-02-09 11:03:52.000000000', 'files': ['scripts/install-deps.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5360d0e869daaa9bdb6ab0eeedfd1600453bfd4d', 'message': 'Install at least pip version 19.1.1\n\nThis is to avoid a known issue with a recent version of cryptography [1]\n\n[1] https://github.com/pyca/cryptography/issues/5771\n\nChange-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335\n'}]",0,774611,5360d0e869daaa9bdb6ab0eeedfd1600453bfd4d,12,3,3,23851,,,0,"Install at least pip version 19.1.1

This is to avoid a known issue with a recent version of cryptography [1]

[1] https://github.com/pyca/cryptography/issues/5771

Change-Id: I034bcd24031b5881ae49b8bc03bed6654cd1d335
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/11/774611/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/install-deps.sh'],1,bd812bf2cedcb22f20a41f6ce2b6929fd58a282b,crypto_pip_workaround,"# NOTE(rpittau): we need a stable recent version of pip to avoid issues with # the cryptography package. PIP_MIN_REQ=""19.1.1"" PIP_TUPLE=""(19, 1, 1)"" echo ""Installing Python and PIP""# NOTE(rpittau): we need a stable recent version of pip to avoid issues with # the cryptography package. PIP_REQUIRED=$($PYTHON -c ""import pip; print(tuple(map(int, pip.__version__.split('.'))) >= $PIP_TUPLE)"") if [ $PIP_REQUIRED == ""False""]; then ${PIP} install ""pip==$PIP_MIN_REQ"" fi","echo Installing Python and PIP$PYTHON << EOF import pip version = tuple(map(int, pip.__version__.split('.'))) assert version >= (7, 1) EOF",12,6
openstack%2Fopenstack-ansible~master~Iff0e3c544b12215b2e2a654364d0529fb2d1983c,openstack/openstack-ansible,master,Iff0e3c544b12215b2e2a654364d0529fb2d1983c,Add reference to netplan config example,MERGED,2021-02-08 09:48:22.000000000,2021-02-09 13:58:21.000000000,2021-02-09 13:54:48.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-08 09:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ecc638b1a355294c3b2d14338bddfb82bf027b62', 'message': 'Add reference to netplan config example\n\nChange-Id: Iff0e3c544b12215b2e2a654364d0529fb2d1983c\n'}, {'number': 2, 'created': '2021-02-08 18:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8320497af45d2b344e4ada309b228193eeaabeef', 'message': 'Add reference to netplan config example\n\nChange-Id: Iff0e3c544b12215b2e2a654364d0529fb2d1983c\n'}, {'number': 3, 'created': '2021-02-09 08:50:44.000000000', 'files': ['doc/source/user/network-arch/example.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e86488e30560bb4d76b4d3b17bc802a74b617ddb', 'message': 'Add reference to netplan config example\n\nChange-Id: Iff0e3c544b12215b2e2a654364d0529fb2d1983c\n'}]",2,774425,e86488e30560bb4d76b4d3b17bc802a74b617ddb,14,3,3,25023,,,0,"Add reference to netplan config example

Change-Id: Iff0e3c544b12215b2e2a654364d0529fb2d1983c
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/25/774425/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/network-arch/example.rst'],1,ecc638b1a355294c3b2d14338bddfb82bf027b62,,"Configuring network interfaces ------------------------------ OpenStack-Ansible does not mandate any specific method of configuring network interfaces on the host. You may choose any tool, such as ifupdown, netplan, systemd-networkd, networkmanager or another operating-system specific tool. The only requirement is that a set of functioning network bridges and interfaces are created which match those expected by OpenStack-Ansible ansible, plus any that you choose to specify for neutron physical interfaces. A selection of network configuration example files are given in the ``etc/network`` and ``etc/netplan`` for ubuntu systems, and it is expected that these will need adjustment for the specific requirements of each deployment. ",,16,0
openstack%2Fopenstack-ansible~master~I2573bcccef3e69da0a6671e6dff428a5c0e30549,openstack/openstack-ansible,master,I2573bcccef3e69da0a6671e6dff428a5c0e30549,Disable ssl for rabbitmq,MERGED,2021-02-01 12:27:09.000000000,2021-02-09 13:34:43.000000000,2021-02-09 13:32:39.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-01 12:27:09.000000000', 'files': ['inventory/group_vars/all/infra.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f523a24b89eb15e9e305ea7e9006660f35c19dd7', 'message': 'Disable ssl for rabbitmq\n\nThis is necessary as new versions of amqp in u-c significantly change\nthe ssl behaviour for rabbitmq requiring a proper CA cert alongside\na self signed certificate on the rabbitmq server.\n\nChange-Id: I2573bcccef3e69da0a6671e6dff428a5c0e30549\n'}]",0,773377,f523a24b89eb15e9e305ea7e9006660f35c19dd7,32,3,1,25023,,,0,"Disable ssl for rabbitmq

This is necessary as new versions of amqp in u-c significantly change
the ssl behaviour for rabbitmq requiring a proper CA cert alongside
a self signed certificate on the rabbitmq server.

Change-Id: I2573bcccef3e69da0a6671e6dff428a5c0e30549
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/77/773377/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/infra.yml'],1,f523a24b89eb15e9e305ea7e9006660f35c19dd7,,rabbitmq_use_ssl: False,rabbitmq_use_ssl: True,1,1
openstack%2Freleases~master~Ic2b688e234b92a5e98e617531323738a51db7151,openstack/releases,master,Ic2b688e234b92a5e98e617531323738a51db7151,New bugfix release for train oslo.serialization.,MERGED,2021-02-09 12:47:15.000000000,2021-02-09 13:27:50.000000000,2021-02-09 13:27:50.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-09 12:47:15.000000000', 'files': ['deliverables/train/oslo.serialization.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/93902e50493b8d2462c681a04895aa023580fc1a', 'message': 'New bugfix release for train oslo.serialization.\n\nA new bugfix oslo.serialization for train. With the fix about json\nto_primitive.\n\nChange-Id: Ic2b688e234b92a5e98e617531323738a51db7151\n'}]",0,774636,93902e50493b8d2462c681a04895aa023580fc1a,8,3,1,31245,,,0,"New bugfix release for train oslo.serialization.

A new bugfix oslo.serialization for train. With the fix about json
to_primitive.

Change-Id: Ic2b688e234b92a5e98e617531323738a51db7151
",git fetch https://review.opendev.org/openstack/releases refs/changes/36/774636/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/oslo.serialization.yaml'],1,93902e50493b8d2462c681a04895aa023580fc1a,oslo.serialization_bugfix_for_train_json_to_primitive, - version: 2.29.3 projects: - repo: openstack/oslo.serialization hash: a9c4bfab354496827ec802f60a46c531107f5de4,,4,0
openstack%2Ftempest~master~I3f82b1e753bb097cd5829dfd1c5f0b22d73cf5d5,openstack/tempest,master,I3f82b1e753bb097cd5829dfd1c5f0b22d73cf5d5,Add support for building snap package.,ABANDONED,2016-09-29 19:53:55.000000000,2021-02-09 13:19:23.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 10068}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-09-29 19:53:55.000000000', 'files': ['.gitignore', 'snapcraft.yaml.tmpl', 'tools/snap.sh'], 'web_link': 'https://opendev.org/openstack/tempest/commit/18b74a051a7d7015e38f4aa217ab421d9864cc50', 'message': ""Add support for building snap package.\n\nThis allows building a snap package for tempest. The config file\nlocation needs to be specified via the config-file option to run,\nbecause the snap's confinement won't allow it to access /etc.\n\nChange-Id: I3f82b1e753bb097cd5829dfd1c5f0b22d73cf5d5\n""}]",0,379789,18b74a051a7d7015e38f4aa217ab421d9864cc50,6,4,1,22446,,,0,"Add support for building snap package.

This allows building a snap package for tempest. The config file
location needs to be specified via the config-file option to run,
because the snap's confinement won't allow it to access /etc.

Change-Id: I3f82b1e753bb097cd5829dfd1c5f0b22d73cf5d5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/89/379789/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'snapcraft.yaml.tmpl', 'tools/snap.sh']",3,18b74a051a7d7015e38f4aa217ab421d9864cc50,initial-snapcraft,"#!/usr/bin/env bash set -ue SCRIPT_DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )"" cd $SCRIPT_DIR/.. export TEMPEST_VERSION=$(git describe --dirty) envsubst '$TEMPEST_VERSION' < snapcraft.yaml.tmpl > snapcraft.yaml snapcraft snap ",,34,0
openstack%2Ftempest~master~I5fa298bf51cc2d151a903f5eda929e2bfb06eb92,openstack/tempest,master,I5fa298bf51cc2d151a903f5eda929e2bfb06eb92,Trove related changes in Tempest,ABANDONED,2013-10-23 11:37:07.000000000,2021-02-09 13:12:05.000000000,,"[{'_account_id': 8293}, {'_account_id': 8311}, {'_account_id': 8415}, {'_account_id': 8826}, {'_account_id': 9068}, {'_account_id': 11019}]","[{'number': 1, 'created': '2013-10-23 11:37:07.000000000', 'files': ['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/test_trove.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d3e1ae7d0631efa08220a8e0d055f651eb17e375', 'message': 'Trove related changes in Tempest\n\nChange-Id: I5fa298bf51cc2d151a903f5eda929e2bfb06eb92\n'}]",2,53322,d3e1ae7d0631efa08220a8e0d055f651eb17e375,3,6,1,9122,,,0,"Trove related changes in Tempest

Change-Id: I5fa298bf51cc2d151a903f5eda929e2bfb06eb92
",git fetch https://review.opendev.org/openstack/tempest refs/changes/22/53322/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/__init__.py', 'tempest/cli/simple_read_only/test_trove.py']",2,d3e1ae7d0631efa08220a8e0d055f651eb17e375,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import subprocess from oslo.config import cfg #import testtools import tempest.cli from tempest.openstack.common import log as logging CONF = cfg.CONF LOG = logging.getLogger(__name__) ID = '' class SimpleReadOnlyTroveClientTest(tempest.cli.ClientTestBase): """""" This is a first pass at a simple read only python-troveclient test. This only exercises client commands that are read only. This should test commands: * as a regular user * as a admin user * with and without optional parameters * initially just check return codes, and later test command outputs """""" # def __init__(self, a): # self.id = '' def test_admin_fake_action(self): self.assertRaises(subprocess.CalledProcessError, self.trove, 'this-does-trove-exist') # NOTE(jogo): Commands in order listed in 'nova help' # Positional arguments: def test_trove_flavor_list(self): out = self.trove('flavor-list') endpoints = self.parser.listing(out) self.assertTableStruct(endpoints, [ 'id', 'name', 'ram']) def test_trove_instance_list(self): out = self.trove('list') endpoints = self.parser.listing(out) self.assertTableStruct(endpoints, [ 'id', 'name', 'status', 'flavor_id', 'size']) def test_trove_flavor_show(self): out = self.trove('flavor-show', params='2') endpoints = self.parser.listing(out) self.assertTableStruct(endpoints, [ 'Property', 'Value']) def test_trove_create_instance(self): out = self.trove('create', params='--size 2 test 2') elements = out.split() for i in elements: if i == ""id"": INDEX = elements.index(i) id1 = elements[INDEX] global ID ID = str(id1) break def test_trove_create_database(self): global ID self.trove('database-create', params='855f836b-1895-4e86-89be-16d395c690d2 testDB') def test_trove_list_database(self): global ID self.trove('database-list', params='855f836b-1895-4e86-89be-16d395c690d2') def test_trove_delete_database(self): global ID self.trove('database-delete', params=ID + ' testDB') def test_trove_create_user(self): global ID self.trove('user-create', params=ID + ' user1 passwd') ",,108,5
openstack%2Ftempest~master~I43aef6de09f705ca2094fed21f2f0e143a5980dd,openstack/tempest,master,I43aef6de09f705ca2094fed21f2f0e143a5980dd,Adding networks JSON client for nova-network,ABANDONED,2013-02-05 16:22:05.000000000,2021-02-09 13:12:00.000000000,,"[{'_account_id': 4325}, {'_account_id': 5679}, {'_account_id': 6683}, {'_account_id': 6690}]","[{'number': 1, 'created': '2013-02-05 16:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6782fbb1be01723fdfa10601eb8884827fc01446', 'message': 'Create basic network client for nova-network\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 2, 'created': '2013-02-05 19:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e91dd8a051a3844eea2c00a6c9e0a0aa4e42c55d', 'message': 'Create basic network client for nova-network\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 3, 'created': '2013-02-05 20:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/db8c6899c4b0c149c661c1c69504cfc68cea7321', 'message': 'Create basic networks client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 4, 'created': '2013-02-05 20:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1cdb514fc0181433bcee531525f9e29c7b08e990', 'message': 'Create basic networks client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 5, 'created': '2013-02-05 20:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/88d288266e7e3798d75566964c332d2effb53a6e', 'message': 'Create basic networks client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 6, 'created': '2013-02-06 08:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/21f3d6c1483e154479704a986ae1883d40db76c1', 'message': 'Adding networks JSON client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 7, 'created': '2013-02-07 19:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/21a3c3b65850ed7be2709f05a754975b30321a34', 'message': 'Adding networks JSON client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 8, 'created': '2013-02-10 08:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/929258729e09fb4c7a0f866f53ead37fe2829e4c', 'message': 'Adding networks JSON client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}, {'number': 9, 'created': '2013-02-11 08:10:26.000000000', 'files': ['tempest/services/compute/json/networks_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/63d10c842ce0e164305fa51874cc4c7710cd3af1', 'message': 'Adding networks JSON client for nova-network\n\nBased on the Networks section of the OpenStack API Reference\ndocumentation in http://api.openstack.org/api-ref.html\n\nChange-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd\n'}]",2,21225,63d10c842ce0e164305fa51874cc4c7710cd3af1,12,4,9,6690,,,0,"Adding networks JSON client for nova-network

Based on the Networks section of the OpenStack API Reference
documentation in http://api.openstack.org/api-ref.html

Change-Id: I43aef6de09f705ca2094fed21f2f0e143a5980dd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/25/21225/7 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/compute/json/network_client.py'],1,6782fbb1be01723fdfa10601eb8884827fc01446,net,"import json from tempest.common.rest_client import RestClient class NetworkClient(RestClient): """""" nova-network REST-API client """""" def __init__(self, config, username, password, auth_url, tenant_name=None): super(NetworkClient, self).__init__(config, username, password, auth_url, tenant_name) self.service = self.config.network.catalog_type def list_networks(self): """""" List all networks in the project """""" resp, body = self.get('os-networks') return resp, json.loads(body) def get_network(self, uuid): """""" Get information about a specific network in the project """""" resp, body = self.get('/'.join(['os-networks', uuid])) return resp, json.loads(body) def create_network(self, name, cidr, bridge='', bridge_iface='', vlan='', multi_host='false', key='network'): """""" Create a network in the project """""" post_body = { key: [{ 'bridge': bridge, 'bridge_itnerface': bridge_iface, 'cidr': cidr, 'multi_host': multi_host, 'vlan': vlan, 'label': name }] } headers = {'Content-Type': 'application/json'} body = json.dumps(post_body) resp, body = self.post('os-networks', headers=headers, body=body) return resp, json.loads(body) def delete_network(self, uuid): """""" Delete network from the project """""" resp, body = self.delete('/'.join(['os-networks', uuid])) return resp, body def add_network_to_project(self, uuid, key='id'): """""" Add a network to the project """""" post_body = json.dumps({key: uuid}) headers = {'Content-Type': 'application/json'} resp, body = self.post('/'.join(['os-networks', 'add']), headers=headers, body=body) return resp, json.loads(body) def _post_network_action(self, uuid, key, value): """""" Generic method for POST requests with action The HTTP's body is a json with format {key=value} """""" post_body = json.dumps({key: uuid}) headers = {'Content-Type': 'application/json'} resp, body = self.post('/'.join(['os-networks', uuid, 'action']), headers=headers, body=body) return resp, json.loads(body) def associate_network_to_host(self, uuid, host_name): """""" Associate network to host in the project """""" self._post_network_action(uuid, 'associate_host', host_name) def disassociate_host_from_network(self, uuid): """""" Disassociate only host from network """""" self._post_network_action(uuid, 'disassociate_host', None) def disassociate_network_from_project(self, uuid): """""" Disassociate a network from a project so it can be reused """""" self._post_network_action(uuid, 'disassociate', None) def disassociate_project_from_network(self, uuid): """""" Disassociate only project from network """""" self._post_network_action(uuid, 'disassociate_project', None) ",,100,0
openstack%2Ftempest~master~I52e14abe6081448b1651c6de033b2d728282a2ce,openstack/tempest,master,I52e14abe6081448b1651c6de033b2d728282a2ce,Test rescue compute API extension,ABANDONED,2012-12-19 20:16:37.000000000,2021-02-09 13:11:52.000000000,,[],"[{'number': 1, 'created': '2012-12-19 20:16:37.000000000', 'files': ['tempest/config.py', 'tempest/tests/compute/test_extensions.py', 'tempest/services/compute/json/extensions_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f5605ba0efec851f16c809979cdf8276974e8c66', 'message': 'Test rescue compute API extension\n\nAdded a test case to test the rescue API extension.  The update\nincludes a new configuration option in tempest.conf in case the\nextension is disabled in certain environments.\n\nWIP\n\nChange-Id: I52e14abe6081448b1651c6de033b2d728282a2ce\n'}]",0,18411,f5605ba0efec851f16c809979cdf8276974e8c66,1,0,1,5713,,,0,"Test rescue compute API extension

Added a test case to test the rescue API extension.  The update
includes a new configuration option in tempest.conf in case the
extension is disabled in certain environments.

WIP

Change-Id: I52e14abe6081448b1651c6de033b2d728282a2ce
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/18411/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/config.py', 'tempest/tests/compute/test_extensions.py', 'tempest/services/compute/json/extensions_client.py']",3,f5605ba0efec851f16c809979cdf8276974e8c66,feature/resume-test," def rescue_server(self, server_id, admin_pass): post_body = { 'rescue': { 'adminPass': admin_pass, } } post_body = json.dumps(post_body) resp, body = self.post(""servers/%s/action"" % server_id, post_body, self.headers) body = json.loads(body) return resp, body def unrescue_server(self, server_id, admin_pass): post_body = { 'unrescue': None, } post_body = json.dumps(post_body) resp, body = self.post(""servers/%s/action"" % server_id, post_body, self.headers) body = json.loads(body) return resp, body",,82,0
openstack%2Ftempest~master~If061f53ed831f104c9b0236da4868ecabab71856,openstack/tempest,master,If061f53ed831f104c9b0236da4868ecabab71856,[WIP]Add Tests for shelve/unshelve operation with different tenant,ABANDONED,2018-01-30 07:27:16.000000000,2021-02-09 13:10:04.000000000,,"[{'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 11278}, {'_account_id': 12033}, {'_account_id': 19457}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27078}, {'_account_id': 27616}]","[{'number': 1, 'created': '2018-01-30 07:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/33d81a8edaee87d15ea56b4726ed7cbb22087554', 'message': ""[WIP]Fix of Shelved and unshelved\n\nThis patch is for Tempest Test in which Instance created by\nnon-admin user which changes status to 'ACTIVE',shelved by\nadmin user and changes its status to 'SHELVED_OFFLOADED' and\nthen unshelved by non-admin user changes its status to 'ACTIVE'\n\ncloses-bug : #1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 2, 'created': '2018-01-30 07:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1f3b3acb44cebc7f9263813b88a95ae3f068815', 'message': ""[WIP]Fix of Shelved and unshelved\n\nThis patch is for Tempest Test in which Instance created by\nnon-admin user which changes status to 'ACTIVE',shelved by\nadmin user and changes its status to 'SHELVED_OFFLOADED' and\nthen unshelved by non-admin user changes its status to 'ACTIVE'\n\ncloses-bug : #1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 3, 'created': '2018-01-30 10:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0fdbc58660ec9a7999a01e60278f081f82576c5c', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is for Tempest Test in which Instance created by\nnon-admin user which changes status to 'ACTIVE',shelved by\nadmin user and changes its status to 'FORCE_SHELVED_OFFLOAD' and\nthen unshelved by owner changes its status to 'ACTIVE'\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 4, 'created': '2018-01-31 05:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4478929a0b2a5756e38b0df9833ffb5a483e3c43', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is for Tempest Test in which Instance created by\nnon-admin user which changes status to 'ACTIVE',shelved by\nadmin user and changes its status to 'FORCE_SHELVED_OFFLOAD' and\nthen unshelved by owner changes its status to 'ACTIVE'\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 5, 'created': '2018-02-02 10:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/76ba1a96741ed95d354c8b435e0c57aed7ea5cee', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is to add tempest test in which Instance created by\nnon-admin user, shelved by admin user and changes its status\nto 'FORCE_SHELVED_OFFLOAD' and then unshelved by owner changes its\nstatus to 'ACTIVE'\n\nRelated-Bug:#1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 6, 'created': '2018-02-06 09:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cdd83715db8cdff31759ce3aceb356b7765a9131', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is to add tempest test in which Instance created by\nnon-admin user, shelved by admin user and changes its status\nto 'FORCE_SHELVED_OFFLOAD' and then unshelved by owner changes its\nstatus to 'ACTIVE'\n\nRelated-Bug:#1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 7, 'created': '2018-02-06 10:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a91bb9c109c7dfe9a76db14215f9cd2dc78f746d', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is to add tempest test in which Instance created by\nnon-admin user, shelved by admin user and changes its status\nto 'FORCE_SHELVED_OFFLOAD' and then unshelved by owner changes its\nstatus to 'ACTIVE'\n\nRelated-Bug:#1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}, {'number': 8, 'created': '2018-02-07 03:04:14.000000000', 'files': ['tempest/api/compute/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/77f1de8cdb5a678078b38d8d073989b73be9e284', 'message': ""[WIP]Add Tests for shelve/unshelve operation with different tenant\n\nThis patch is to add tempest test in which Instance created by\nnon-admin user, shelved by admin user and changes its status\nto 'FORCE_SHELVED_OFFLOAD' and then unshelved by owner changes its\nstatus to 'ACTIVE'\n\nRelated-Bug:#1675791\n\nChange-Id: If061f53ed831f104c9b0236da4868ecabab71856\n""}]",16,539118,77f1de8cdb5a678078b38d8d073989b73be9e284,34,10,8,27616,,,0,"[WIP]Add Tests for shelve/unshelve operation with different tenant

This patch is to add tempest test in which Instance created by
non-admin user, shelved by admin user and changes its status
to 'FORCE_SHELVED_OFFLOAD' and then unshelved by owner changes its
status to 'ACTIVE'

Related-Bug:#1675791

Change-Id: If061f53ed831f104c9b0236da4868ecabab71856
",git fetch https://review.opendev.org/openstack/tempest refs/changes/18/539118/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_servers.py'],1,33d81a8edaee87d15ea56b4726ed7cbb22087554,bug/1675791," @decorators.idempotent_id('ca9639bd-ca25-41a9-a45d-21749161c32e') def test_shelve_unshelve(self): server = self.create_test_server(wait_until='ACTIVE') self.client.shelve_server(server['id']) waiters.wait_for_server_status(self.client, server['id'], 'SHELVED_OFFLOADED', ) self.non_admin_client.unshelve_server(server['id']) waiters.wait_for_server_status(self.client, server['id'], 'ACTIVE', ) ",,15,0
openstack%2Ftempest~master~I8baa3e61789b0553b9f85214b60c9e0b8dafde31,openstack/tempest,master,I8baa3e61789b0553b9f85214b60c9e0b8dafde31,Wait for port status when getting IPv4 address,ABANDONED,2017-10-30 16:10:40.000000000,2021-02-09 13:08:40.000000000,,"[{'_account_id': 5756}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9542}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 22066}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23186}, {'_account_id': 27078}, {'_account_id': 27552}]","[{'number': 1, 'created': '2017-10-30 16:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/56cc919f3e7845ecd73a4e613152c99b98c5c634', 'message': ""Fix for port status, sometimes ti doesn't become ACTIVE quickly\n\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}, {'number': 2, 'created': '2018-01-31 13:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e632f4ac1ecb6ec219bd4f0b25f7c080fc6cf11', 'message': ""Fix for port status, sometimes ti doesn't become ACTIVE quickly\n\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}, {'number': 3, 'created': '2018-02-02 10:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/389b924a0e32554f2dc81caaf6134caa0fe6724f', 'message': ""Fix for port status, sometimes it doesn't become ACTIVE quickly\n\nThis is fix for tes test_network_basic_ops\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}, {'number': 4, 'created': '2018-04-24 10:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/81ff3dc81a4369aec8cf0b3998eda8313a10ee04', 'message': ""Wait for port status when getting IPv4 address\n\nin some deployments ports might take some time to become active and\nusable for ssh-ing etc, so the test needs to wait for them become\nactive.\n\nReuse waiters.wait_for_interface_status (which was amended to accept\nlist of port statuses to wait for), which in turn will reuse the\nbuild_timeout and build_inerval options from 'compute' config sections.\n\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}, {'number': 5, 'created': '2018-04-25 11:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c5dd82d424f10ebbb5ef89b2e23c145fe854924c', 'message': ""Wait for port status when getting IPv4 address\n\nDepending on neutron backend, ports may take some time to become active,\nand im most cases we need them active to be able to successfully access\nthe node (e.g. via SSH).\n\nThis patch reuses `waiters.wait_for_interface_status` function\n(which was amended to accept list of port statuses to wait for),\nwhich in turn uses the build_timeout and build_inerval options from\n'compute' config sections. The logic of the function is preserved.\n\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}, {'number': 6, 'created': '2018-12-14 15:07:03.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/common/waiters.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b809d2e216f478b42723cce6f3d5dee7be6f1d1', 'message': ""Wait for port status when getting IPv4 address\n\nDepending on neutron backend, ports may take some time to become active,\nand im most cases we need them active to be able to successfully access\nthe node (e.g. via SSH).\n\nThis patch reuses `waiters.wait_for_interface_status` function\n(which was amended to accept list of port statuses to wait for),\nwhich in turn uses the build_timeout and build_inerval options from\n'compute' config sections. The logic of the function is preserved.\n\nChange-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31\nCloses-Bug: #1728600\n""}]",13,516372,6b809d2e216f478b42723cce6f3d5dee7be6f1d1,40,14,6,20675,,,0,"Wait for port status when getting IPv4 address

Depending on neutron backend, ports may take some time to become active,
and im most cases we need them active to be able to successfully access
the node (e.g. via SSH).

This patch reuses `waiters.wait_for_interface_status` function
(which was amended to accept list of port statuses to wait for),
which in turn uses the build_timeout and build_inerval options from
'compute' config sections. The logic of the function is preserved.

Change-Id: I8baa3e61789b0553b9f85214b60c9e0b8dafde31
Closes-Bug: #1728600
",git fetch https://review.opendev.org/openstack/tempest refs/changes/72/516372/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/config.py']",2,56cc919f3e7845ecd73a4e613152c99b98c5c634,bug/1728600," cfg.IntOpt('port_timeout', default = 300, help = ""Timeout in seconds to wait for port operation to"" ""ACTIVE.""),",,31,20
openstack%2Ftempest~master~Id641aaacdf675e74169b8afb7b86bea182037c83,openstack/tempest,master,Id641aaacdf675e74169b8afb7b86bea182037c83,"Keystone authentication enabled version defaults to v3,the dependency needs to be set to true by sync",ABANDONED,2018-11-27 02:09:00.000000000,2021-02-09 13:06:07.000000000,,"[{'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2018-11-27 02:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ffa9d6f228aec0bb828b179ca09917df73fb68f', 'message': 'Keystone authentication enabled version defaults to v3\n,the dependency needs to be set to true by sync\n\nChange-Id: Id641aaacdf675e74169b8afb7b86bea182037c83\n'}, {'number': 2, 'created': '2018-11-27 02:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b688cb44aaad52e754bad540625e94c70adb5acc', 'message': 'Keystone authentication enabled version defaults to v3\n,the dependency needs to be set to true by sync\nCloses-Bug:#1805319\n\nChange-Id: Id641aaacdf675e74169b8afb7b86bea182037c83\n'}, {'number': 3, 'created': '2018-11-27 02:13:54.000000000', 'files': ['tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3bf9cb80553ee3ab2b8a18277860148a94896582', 'message': 'Keystone authentication enabled version defaults to\nv3,the dependency needs to be set to true by sync\n\nCloses-Bug:#1805319\n\nChange-Id: Id641aaacdf675e74169b8afb7b86bea182037c83\n'}]",4,620199,3bf9cb80553ee3ab2b8a18277860148a94896582,9,5,3,26975,,,0,"Keystone authentication enabled version defaults to
v3,the dependency needs to be set to true by sync

Closes-Bug:#1805319

Change-Id: Id641aaacdf675e74169b8afb7b86bea182037c83
",git fetch https://review.opendev.org/openstack/tempest refs/changes/99/620199/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,9ffa9d6f228aec0bb828b179ca09917df73fb68f,bug/1805319," default=True,"," default=False,",1,1
openstack%2Ftempest~master~Iab2e4b22d80d16b48fc28568b8737b2432a6595c,openstack/tempest,master,Iab2e4b22d80d16b48fc28568b8737b2432a6595c,wait for port status to be ACTIVE,ABANDONED,2016-10-06 15:47:30.000000000,2021-02-09 13:04:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7350}, {'_account_id': 7787}, {'_account_id': 8213}, {'_account_id': 8871}, {'_account_id': 9725}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 12604}, {'_account_id': 16034}, {'_account_id': 16437}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2016-10-06 15:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5fae46fff3c373a44bdc827d2d59c492fda72b15', 'message': 'WIP: wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 2, 'created': '2016-10-07 10:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/77959d8293531ba7cf6df537e361408f0cfab863', 'message': 'WIP: wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 3, 'created': '2016-10-10 08:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cca31bcb98c9b8d68756c69b039d5479fac821e9', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 4, 'created': '2016-10-11 10:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee0da5aec4a09458a87f4fb9514293415437f5a5', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 5, 'created': '2016-10-11 12:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/07e5b02035df9b2ce90175c283a8395890912d0e', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 6, 'created': '2016-10-11 15:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e66e15d5afc0e6d09c8025e41cbd8e38cb7c13eb', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 7, 'created': '2016-10-18 11:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0323ced0f5dd9994b9e588329069dac50e4f792c', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 8, 'created': '2016-11-02 18:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3fe60f9654e641d9b091f23700c6c65f9b731df9', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 9, 'created': '2016-11-03 13:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16e0558e293909bda80325012ecde98ae53d7127', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 10, 'created': '2016-11-23 16:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4d6a0e489f690465c402cbefc2dfb32a7f4b3e6', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 11, 'created': '2017-02-08 12:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1eede2d14ce325120dda1e6df2030472456757d', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 12, 'created': '2017-02-27 15:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a33f221e91e078cf889c39dc40a231e1692483ca', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 13, 'created': '2017-03-02 07:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/01d26e07fa17c3eeab96ac3e4823e513cf983d82', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 14, 'created': '2018-07-03 07:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b5cf0391b7613d3cc30e600698abecfe621c3a76', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 15, 'created': '2018-07-04 14:30:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4b44a0c4e010d0f118a3b5049bdbb23ea3639df2', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}, {'number': 16, 'created': '2018-08-22 15:36:07.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/common/waiters.py', 'tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1336b3c29ffee465081793e5d575ad7ef38818f8', 'message': 'wait for port status to be ACTIVE\n\nSome tests are failing on the Hyper-V CI due to the\nfact that tempest does not wait for the neutron\nports to be come active. All ports that are not active\nare ignored, leading to failed tests [1].\n\nWaiting for the ports to become active solves the issue.\n\n[1] http://paste.openstack.org/show/584712/\n\nCloses-Bug: #1631872\n\nChange-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c\n'}]",16,383049,1336b3c29ffee465081793e5d575ad7ef38818f8,111,19,16,8213,,,0,"wait for port status to be ACTIVE

Some tests are failing on the Hyper-V CI due to the
fact that tempest does not wait for the neutron
ports to be come active. All ports that are not active
are ignored, leading to failed tests [1].

Waiting for the ports to become active solves the issue.

[1] http://paste.openstack.org/show/584712/

Closes-Bug: #1631872

Change-Id: Iab2e4b22d80d16b48fc28568b8737b2432a6595c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/49/383049/10 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/common/waiters.py', 'tempest/exceptions.py']",3,5fae46fff3c373a44bdc827d2d59c492fda72b15,bug/1631872,"class PortBuildErrorException(exceptions.TempestException): message = ""Port %(port_id)s failed to build and is in ERROR status"" ",,64,1
openstack%2Ftempest~master~Id017fbd7a997bf211d71d4f94ee706cd22bbd66e,openstack/tempest,master,Id017fbd7a997bf211d71d4f94ee706cd22bbd66e,return the correct roles_client for auth_version,ABANDONED,2018-08-23 08:53:30.000000000,2021-02-09 13:01:20.000000000,,"[{'_account_id': 5689}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 24427}, {'_account_id': 25764}, {'_account_id': 26196}, {'_account_id': 27078}]","[{'number': 1, 'created': '2018-08-23 08:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/015c93e8fa25f699fc37848b1fcf16ddbd3ba723', 'message': ""return the correct roles_client for auth_version\n\nThis PS fixes to get correct roles_client when set auth_version='v3'.\n\nChange-Id: Id017fbd7a997bf211d71d4f94ee706cd22bbd66e\nCloses-Bug: #1788561\n""}, {'number': 2, 'created': '2018-09-18 09:16:37.000000000', 'files': ['tempest/cmd/cleanup_service.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/958b84a0a8ce6dd3954df745af8954b6a6e1b45a', 'message': ""return the correct roles_client for auth_version\n\nThis PS fixes to get correct roles_client when set auth_version='v3'.\n\nChange-Id: Id017fbd7a997bf211d71d4f94ee706cd22bbd66e\nCloses-Bug: #1788561\n""}]",6,595548,958b84a0a8ce6dd3954df745af8954b6a6e1b45a,25,10,2,24427,,,0,"return the correct roles_client for auth_version

This PS fixes to get correct roles_client when set auth_version='v3'.

Change-Id: Id017fbd7a997bf211d71d4f94ee706cd22bbd66e
Closes-Bug: #1788561
",git fetch https://review.opendev.org/openstack/tempest refs/changes/48/595548/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/cleanup_service.py'],1,015c93e8fa25f699fc37848b1fcf16ddbd3ba723,bug/1788561, if CONF.identity.auth_version == 'v3': self.client = manager.roles_v3_client else: self.client = manager.roles_client, self.client = manager.roles_client,4,1
openstack%2Ftempest~master~I6c4dd908658609e7c082a8234af33f812b8afd06,openstack/tempest,master,I6c4dd908658609e7c082a8234af33f812b8afd06,Fix for domain_id in V3 keystone authorization,ABANDONED,2016-10-07 09:20:48.000000000,2021-02-09 13:00:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11869}, {'_account_id': 12017}, {'_account_id': 20190}, {'_account_id': 23771}, {'_account_id': 27078}, {'_account_id': 27587}]","[{'number': 1, 'created': '2016-10-07 09:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1c45bfec00aff2b74078fe1e84ddd005cc1151d6', 'message': ""The cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 2, 'created': '2016-10-07 09:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c02710a4397e561a1c039fab4098b51d4076726c', 'message': ""The cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 3, 'created': '2016-10-07 12:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dfa8998c64ae38280a1548581a9f92007f177274', 'message': ""The cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 4, 'created': '2016-10-07 12:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/810fa0af8e357959f05fe1b22b8ef5ba87441087', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 5, 'created': '2016-10-07 13:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4f0aa7200c1583133805c2e0f7bb1c8b14ab0851', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 6, 'created': '2016-10-07 15:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a7256553732630ad427aea1ca6ea4bc519b1a60b', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 7, 'created': '2016-10-10 09:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/660cfd7baa7207eed08163d02f0d7d8f182b2332', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 8, 'created': '2016-10-19 14:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/89e63062477ebba83e1368ec758d11af9aa5dad8', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone. I suppose to tempest use of default_domain_id from config file during this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 9, 'created': '2016-10-19 16:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9455e732fd4c8b9faf0de5f232699fa3d4328b4f', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 10, 'created': '2016-10-25 12:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16d68dc3335b9c3f773207a2f0359876a0474794', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 11, 'created': '2016-10-25 14:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a01fb87e7fdfbd790439e9dbaa0eda04df0a5593', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 12, 'created': '2016-11-08 08:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7eb7db2b4badd6b9e2b5821a5d5e0241ad3670d6', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 13, 'created': '2016-11-08 12:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/93ea57e95815615757f93361d0b5e966d05566af', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 14, 'created': '2016-12-16 13:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/55628f95655a14555338d52130a66b4956cad05e', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\nSigned-off-by: Dmitry Kudyukin <gmorfy@gmail.com>\n""}, {'number': 15, 'created': '2016-12-16 13:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd7d8d64e33beaa80be7297baa260962f52a3af4', 'message': ""Add default_domain_id field to keystone request.\n\nThe cause of bug is tempest don't send domain_id in request to keystone.\nI suppose to tempest use of default_domain_id from config file\nduring this request.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\n""}, {'number': 16, 'created': '2016-12-19 08:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d9a2ceafd2e4620ad6f09b6eb417b8b54da21cf0', 'message': 'Fix for domain_id in V3 keystone authorization\n\nIn case of using V3 keystone authorization with Default domain name,\nwhich id not default, create_user failed, with error ""Could not find\ndomain: default"". So, this patch add domain_id field to the keystone\nrequest and authorization continues normally.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\n'}, {'number': 17, 'created': '2016-12-27 12:54:06.000000000', 'files': ['tempest/lib/common/cred_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6f7109b2faeaac5e8c55b12b1d959c26634d21f6', 'message': 'Fix for domain_id in V3 keystone authorization\n\nIn case of using V3 keystone authorization with Default domain name,\nwhich id not default, create_user failed, with error ""Could not find\ndomain: default"". So, this patch add domain_id field to the keystone\nrequest and authorization continues normally.\n\nCloses-Bug: #1613819\n\nChange-Id: I6c4dd908658609e7c082a8234af33f812b8afd06\n'}]",19,383601,6f7109b2faeaac5e8c55b12b1d959c26634d21f6,103,17,17,23771,,,0,"Fix for domain_id in V3 keystone authorization

In case of using V3 keystone authorization with Default domain name,
which id not default, create_user failed, with error ""Could not find
domain: default"". So, this patch add domain_id field to the keystone
request and authorization continues normally.

Closes-Bug: #1613819

Change-Id: I6c4dd908658609e7c082a8234af33f812b8afd06
",git fetch https://review.opendev.org/openstack/tempest refs/changes/01/383601/11 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/cred_client.py', 'tempest/common/dynamic_creds.py']",2,1c45bfec00aff2b74078fe1e84ddd005cc1151d6,bug/1613819," domain_id = CONF.identity.default_domain_id username, user_password, project, email, domain_id)"," username, user_password, project, email)",5,3
openstack%2Ftempest~master~I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698,openstack/tempest,master,I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698,Fix fip association issue when multi servers are created,ABANDONED,2018-02-24 09:01:48.000000000,2021-02-09 12:58:02.000000000,,"[{'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-02-24 09:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0f7b8c13fab90d165ee1c589814fcef64eea0067', 'message': 'Fix fip association issue when multi servers are created\n\nIn test_resize_volume_backed_server_confirm, when connect_method=floating,\nbecause create_test_server doesn\'t use validatable=True and\nvalidation_resources=validation_resources, so the created server hasn\'t any\nfloating ip associated to it, and so the following self.get_server_ip(server,\nvalidation_resources) just refers to other server (the one created in setUp),\nthis is an amusing hidden error.\n\nThis is to move the setup_validation_fip from create_test_server to\nget_server_ip, that is, one floating ip can be used for different servers,\nso we should associate the floating ip to the server when the server is ready\nto ssh, while not when the server is created.\n\nBesides, compute.create_test_server will no longer have the limitation that\n""multiple pingable or sshable servers will not be supported"", because all other\nvalidation resources can be shared except floating ip, such as keypair,\nsecurity group. And as to floating ip, we will associate it to the server which\nis ready to ssh.\n\nChange-Id: I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698\nCloses-Bug: #1751418\n'}, {'number': 2, 'created': '2018-02-26 02:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/732dc31ad75f949f09c796f04170be3c6579175e', 'message': 'Fix fip association issue when multi servers are created\n\nIn test_resize_volume_backed_server_confirm, when connect_method=floating,\nbecause create_test_server doesn\'t use validatable=True and\nvalidation_resources=validation_resources, so the created server hasn\'t any\nfloating ip associated to it, and so the following self.get_server_ip(server,\nvalidation_resources) just refers to other server (the one created in setUp),\nthis is an amusing hidden error.\n\nThis is to move the setup_validation_fip from create_test_server to\nget_server_ip, that is, one floating ip can be used for different servers,\nso we should associate the floating ip to the server when the server is ready\nto ssh, while not when the server is created.\n\nBesides, compute.create_test_server will no longer have the limitation that\n""multiple pingable or sshable servers will not be supported"", because all other\nvalidation resources can be shared except floating ip, such as keypair,\nsecurity group. And as to floating ip, we will associate it to the server one\nat a time.\n\nChange-Id: I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698\nCloses-Bug: #1751418\n'}, {'number': 3, 'created': '2018-02-26 06:21:03.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/base.py', 'tempest/common/compute.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9f5f2d6b7d9c149ef499c2a5f39b110db04fee52', 'message': 'Fix fip association issue when multi servers are created\n\nIn test_resize_volume_backed_server_confirm, when connect_method=floating,\nbecause create_test_server doesn\'t use validatable=True and\nvalidation_resources=validation_resources, so the created server hasn\'t any\nfloating ip associated to it, and so the following self.get_server_ip(server,\nvalidation_resources) just refers to other server (the one created in setUp),\nthis is an amusing hidden error.\n\nThis is to move the setup_validation_fip from create_test_server to\nget_server_ip, that is, one floating ip can be used for different servers,\nso we should associate the floating ip to the server when the server is ready\nto ssh, while not when the server is created.\n\nBesides, compute.create_test_server will no longer have the limitation that\n""multiple pingable or sshable servers will not be supported"", because all other\nvalidation resources can be shared except floating ip, such as keypair,\nsecurity group. And as to floating ip, we will associate it to the server one\nat a time.\n\nChange-Id: I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698\nCloses-Bug: #1751418\n'}]",0,547728,9f5f2d6b7d9c149ef499c2a5f39b110db04fee52,12,8,3,20190,,,0,"Fix fip association issue when multi servers are created

In test_resize_volume_backed_server_confirm, when connect_method=floating,
because create_test_server doesn't use validatable=True and
validation_resources=validation_resources, so the created server hasn't any
floating ip associated to it, and so the following self.get_server_ip(server,
validation_resources) just refers to other server (the one created in setUp),
this is an amusing hidden error.

This is to move the setup_validation_fip from create_test_server to
get_server_ip, that is, one floating ip can be used for different servers,
so we should associate the floating ip to the server when the server is ready
to ssh, while not when the server is created.

Besides, compute.create_test_server will no longer have the limitation that
""multiple pingable or sshable servers will not be supported"", because all other
validation resources can be shared except floating ip, such as keypair,
security group. And as to floating ip, we will associate it to the server one
at a time.

Change-Id: I2cd55b151f3bbf5d765e65c8d29578b9f0a7d698
Closes-Bug: #1751418
",git fetch https://review.opendev.org/openstack/tempest refs/changes/28/547728/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/base.py', 'tempest/common/compute.py']",3,0f7b8c13fab90d165ee1c589814fcef64eea0067,bug/1751418,"def setup_validation_fip(clients, server, validation_resources): if CONF.service_available.neutron: ifaces = clients.interfaces_client.list_interfaces(server['id']) validation_port = None # NOTE(zhufl) when calling compute.create_test_server, # tenant_network will be preserved in the server info dict. # If 'tenant_network' is not found in server, then use first port. if 'tenant_network' not in server: if ifaces['interfaceAttachments']: validation_port = ifaces['interfaceAttachments'][0]['port_id'] else: for iface in ifaces['interfaceAttachments']: if iface['net_id'] == server['tenant_network']['id']: validation_port = iface['port_id'] break if not validation_port: # NOTE(artom) This will get caught by the catch-all clause in # the wait_until loop below raise ValueError('Unable to setup floating IP for validation: ' 'port not found on tenant network') # NOTE(zhufl) Disassociate floating ip first in case it has been # associated to other port. clients.floating_ips_client.update_floatingip( validation_resources['floating_ip']['id'], port_id=None) clients.floating_ips_client.update_floatingip( validation_resources['floating_ip']['id'], port_id=validation_port) else: # NOTE(zhufl) Floating ip will be disassociated from the old server # automatically. fip_client = clients.compute_floating_ips_client fip_client.associate_floating_ip_to_server( floating_ip=validation_resources['floating_ip']['ip'], server_id=server['id']) server['tenant_network'] = tenant_network"," # As a first implementation, multiple pingable or sshable servers will # not be supported if multiple_create_request: msg = (""Multiple pingable or sshable servers not supported at "" ""this stage."") raise ValueError(msg) def _setup_validation_fip(): if CONF.service_available.neutron: ifaces = clients.interfaces_client.list_interfaces(server['id']) validation_port = None for iface in ifaces['interfaceAttachments']: if iface['net_id'] == tenant_network['id']: validation_port = iface['port_id'] break if not validation_port: # NOTE(artom) This will get caught by the catch-all clause in # the wait_until loop below raise ValueError('Unable to setup floating IP for validation: ' 'port not found on tenant network') clients.floating_ips_client.update_floatingip( validation_resources['floating_ip']['id'], port_id=validation_port) else: fip_client = clients.compute_floating_ips_client fip_client.associate_floating_ip_to_server( floating_ip=validation_resources['floating_ip']['ip'], server_id=servers[0]['id']) # Multiple validatable servers are not supported for now. Their # creation will fail with the condition above. if CONF.validation.run_validation and validatable: if CONF.validation.connect_method == 'floating': _setup_validation_fip()",57,38
openstack%2Ftempest~master~Ic09089fbd488825ba85099171d97bb31921f4993,openstack/tempest,master,Ic09089fbd488825ba85099171d97bb31921f4993,Object test not cleaning up containers.,ABANDONED,2018-05-17 09:20:16.000000000,2021-02-09 12:57:10.000000000,,"[{'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-05-17 09:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1d9297dabfee412fdcdfec644f78f0cc808d2423', 'message': 'Object test not cleaning up containers Edit\n\nThe below test will not clean up containers\n\ntempest.api.object_storage.test_object_services.PublicObjectTest\ntempest.api.object_storage.test_container_acl_negative.ObjectACLsNegativeTest\n\nThis patch set will directly call the delete function.\n\nChange-Id: Ic09089fbd488825ba85099171d97bb31921f4993\nCloses-Bug: #1769005\n'}, {'number': 2, 'created': '2018-05-17 09:21:25.000000000', 'files': ['tempest/api/object_storage/test_object_services.py', 'tempest/api/object_storage/test_container_acl_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f49fe7034bd861cca8b81a76b2e21da9b35dd64a', 'message': 'Object test not cleaning up containers.\n\nThe below test will not clean up containers\n\ntempest.api.object_storage.test_object_services.PublicObjectTest\ntempest.api.object_storage.test_container_acl_negative.ObjectACLsNegativeTest\n\nThis patch set will directly call the delete function.\n\nChange-Id: Ic09089fbd488825ba85099171d97bb31921f4993\nCloses-Bug: #1769005\n'}]",2,569066,f49fe7034bd861cca8b81a76b2e21da9b35dd64a,9,6,2,25695,,,0,"Object test not cleaning up containers.

The below test will not clean up containers

tempest.api.object_storage.test_object_services.PublicObjectTest
tempest.api.object_storage.test_container_acl_negative.ObjectACLsNegativeTest

This patch set will directly call the delete function.

Change-Id: Ic09089fbd488825ba85099171d97bb31921f4993
Closes-Bug: #1769005
",git fetch https://review.opendev.org/openstack/tempest refs/changes/66/569066/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/object_storage/test_object_services.py', 'tempest/api/object_storage/test_container_acl_negative.py']",2,1d9297dabfee412fdcdfec644f78f0cc808d2423,bug/1769005," base.delete_containers([self.container_name], self.container_client, self.object_client)", self.delete_containers([self.container_name]),4,2
openstack%2Fironic-lib~master~I8f8967d9c4171057ad3b2f08772821769f575c47,openstack/ironic-lib,master,I8f8967d9c4171057ad3b2f08772821769f575c47,[DNM] Test CI,NEW,2021-02-08 19:49:01.000000000,2021-02-09 12:56:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-08 19:49:01.000000000', 'files': ['zuul.d/ironic-lib-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/cebd96e85c7ecea9172fa679c6b6a6fe0ef62c0d', 'message': '[DNM] Test CI\n\nChange-Id: I8f8967d9c4171057ad3b2f08772821769f575c47\n'}]",0,774534,cebd96e85c7ecea9172fa679c6b6a6fe0ef62c0d,6,1,1,15519,,,0,"[DNM] Test CI

Change-Id: I8f8967d9c4171057ad3b2f08772821769f575c47
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/34/774534/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-lib-jobs.yaml'],1,cebd96e85c7ecea9172fa679c6b6a6fe0ef62c0d,dnm, BUILD_TIMEOUT: 901, BUILD_TIMEOUT: 900,1,1
openstack%2Ftempest~master~Ic5c4b036ac111ad7a7326fd1caa7460659a3026e,openstack/tempest,master,Ic5c4b036ac111ad7a7326fd1caa7460659a3026e,Move value of notifications in TestSwiftTelemetry to config.py,ABANDONED,2015-08-28 09:05:33.000000000,2021-02-09 12:56:00.000000000,,"[{'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11022}, {'_account_id': 16986}, {'_account_id': 18137}]","[{'number': 1, 'created': '2015-08-28 09:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b049e9b5ba067cd5f3a0e1e648358253e6605b0d', 'message': 'Move value of notifications wait&sleep in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}, {'number': 2, 'created': '2015-08-28 15:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6a3e8d166955bd3628b184a8465044aa586a7de', 'message': 'Move value of notifications wait&sleep in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}, {'number': 3, 'created': '2015-09-18 03:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0a363c01074b01f30bdb22e81a6f94e22dd6b77c', 'message': 'Move value of notifications wait&sleep in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}, {'number': 4, 'created': '2015-09-18 03:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae3044c9347bb1b592fa0128faa5079ea8681e49', 'message': 'Move value of notifications in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}, {'number': 5, 'created': '2015-09-21 13:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dd5ba3c16500ba2e55b41bd362b93d7047ca457b', 'message': 'Move value of notifications in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}, {'number': 6, 'created': '2015-11-02 13:07:54.000000000', 'files': ['tempest/scenario/test_object_storage_telemetry_middleware.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/39f7af7fe550ec0cae1ca62d4ad3c648d80bb70c', 'message': 'Move value of notifications in TestSwiftTelemetry to config.py\n\nCurrently the value of notifications wait&sleep is hard coding which is\nnot allowed to change them by config. We should move them to\nTelemetryGroup in config.py.\n\nChange-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e\nCloses-Bug: #1489772\n'}]",7,218159,39f7af7fe550ec0cae1ca62d4ad3c648d80bb70c,47,8,6,16986,,,0,"Move value of notifications in TestSwiftTelemetry to config.py

Currently the value of notifications wait&sleep is hard coding which is
not allowed to change them by config. We should move them to
TelemetryGroup in config.py.

Change-Id: Ic5c4b036ac111ad7a7326fd1caa7460659a3026e
Closes-Bug: #1489772
",git fetch https://review.opendev.org/openstack/tempest refs/changes/59/218159/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/config.py', 'tempest/scenario/test_swift_telemetry_middleware.py']",2,b049e9b5ba067cd5f3a0e1e648358253e6605b0d,bug/1489772," # Loop for up to 120 seconds waiting on notifications # NOTE(chdent): The choice of 120 seconds is fairly # arbitrary: Long enough to give the notifications the # chance to travel across a highly latent bus but not # so long as to allow excessive latency to never be visible. self.assertTrue(test.call_until_true( _check_samples, CONF.TelemetryGroup.notification_wait, CONF.TelemetryGroup.notification_sleep), '%s seconds.' % CONF.TelemetryGroup.notification_wait)","# Loop for up to 120 seconds waiting on notifications # NOTE(chdent): The choice of 120 seconds is fairly # arbitrary: Long enough to give the notifications the # chance to travel across a highly latent bus but not # so long as to allow excessive latency to never be visible. # TODO(chdent): Ideally this value would come from configuration. NOTIFICATIONS_WAIT = 120 NOTIFICATIONS_SLEEP = 1 self.assertTrue(test.call_until_true(_check_samples, NOTIFICATIONS_WAIT, NOTIFICATIONS_SLEEP), '%s seconds.' % NOTIFICATIONS_WAIT)",20,14
openstack%2Ftempest~master~Ife958846a559f8b4be3e9070c0671f59b09b3c36,openstack/tempest,master,Ife958846a559f8b4be3e9070c0671f59b09b3c36,Force mke2fs to format even if entire device,ABANDONED,2017-02-13 17:43:12.000000000,2021-02-09 12:55:16.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8213}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 18718}]","[{'number': 1, 'created': '2017-02-13 17:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e518a9556da30ccaea156ec151a79ffd5c998872', 'message': 'Force mke2fs to format even if entire device\n\nWhen formatting an entire device, mke2fs prompts for confirmation\nleading to fail the test\n\nChange-Id: Ife958846a559f8b4be3e9070c0671f59b09b3c36\n'}, {'number': 2, 'created': '2017-02-13 17:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c6566cf29ee7f5f2257c666d35df1432131355a3', 'message': 'Force mke2fs to format even if entire device\n\nWhen formatting an entire device, mke2fs prompts for confirmation\nleading to fail the test\n\nChange-Id: Ife958846a559f8b4be3e9070c0671f59b09b3c36\n'}, {'number': 3, 'created': '2017-02-13 18:11:40.000000000', 'files': ['tempest/common/utils/linux/remote_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ddc5b96b5517a3db9e537e01c6475b97714ef0d', 'message': 'Force mke2fs to format even if entire device\n\nWhen formatting an entire device, mke2fs prompts for confirmation\nleading to fail the test\n\nCloses-Bug: #1664313\n\nChange-Id: Ife958846a559f8b4be3e9070c0671f59b09b3c36\n'}]",2,433213,9ddc5b96b5517a3db9e537e01c6475b97714ef0d,10,11,3,18695,,,0,"Force mke2fs to format even if entire device

When formatting an entire device, mke2fs prompts for confirmation
leading to fail the test

Closes-Bug: #1664313

Change-Id: Ife958846a559f8b4be3e9070c0671f59b09b3c36
",git fetch https://review.opendev.org/openstack/tempest refs/changes/13/433213/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/utils/linux/remote_client.py'],1,e518a9556da30ccaea156ec151a79ffd5c998872,bug/1664313," cmd_mkfs = 'sudo /usr/sbin/mke2fs -F -t %s /dev/%s' % (fs, dev_name)"," cmd_mkfs = 'sudo /usr/sbin/mke2fs -t %s /dev/%s' % (fs, dev_name)",1,1
openstack%2Fkayobe~stable%2Fvictoria~Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,openstack/kayobe,stable/victoria,Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,Fix --limit with commas,MERGED,2021-01-15 16:59:18.000000000,2021-02-09 12:52:30.000000000,2021-02-09 12:50:31.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-15 16:59:18.000000000', 'files': ['kayobe/kolla_ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/ansible.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/6ec66524fa0399e4625c45a3d2df720469a0b337', 'message': 'Fix --limit with commas\n\nKayobe allows specifying a --limit argument, which is passed through to\nAnsible. In some cases we wish to add an intersection with a group. This\nallows us to reuse playbooks for the seed, overcloud etc.\n\nFor example, the lvm.yml playbook specifies a host list of\nseed-hypervisor:seed:overcloud. When executed as part of a kayobe\novercloud host configure command, Kayobe passes a limit of overcloud. If\nthe user specifies a --limit argument, this gets intersected with the\novercloud limit: host1:&overcloud.\n\nThe problem happens if the user specifies multiple parts to the host\npattern in their limit using a comma, e.g. host1,host2. This results in\nhost1,host2:&overcloud. Ansible ignores the colon, and treats this as\nhost1 or host2:&overcloud.\n\nThe solution is to use a comma to join the patterns if the user has used\na comma: host1,host2,&overcloud\n\nChange-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d\nStory: 2008255\nTask: 41111\n(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)\n'}]",0,770958,6ec66524fa0399e4625c45a3d2df720469a0b337,26,3,1,14826,,,0,"Fix --limit with commas

Kayobe allows specifying a --limit argument, which is passed through to
Ansible. In some cases we wish to add an intersection with a group. This
allows us to reuse playbooks for the seed, overcloud etc.

For example, the lvm.yml playbook specifies a host list of
seed-hypervisor:seed:overcloud. When executed as part of a kayobe
overcloud host configure command, Kayobe passes a limit of overcloud. If
the user specifies a --limit argument, this gets intersected with the
overcloud limit: host1:&overcloud.

The problem happens if the user specifies multiple parts to the host
pattern in their limit using a comma, e.g. host1,host2. This results in
host1,host2:&overcloud. Ansible ignores the colon, and treats this as
host1 or host2:&overcloud.

The solution is to use a comma to join the patterns if the user has used
a comma: host1,host2,&overcloud

Change-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d
Story: 2008255
Task: 41111
(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/58/770958/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/kolla_ansible.py', 'kayobe/ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml']",5,6ec66524fa0399e4625c45a3d2df720469a0b337,,--- fixes: - | Fixes an issue when using the ``--limit`` argument with a host pattern including commas. See `story 2008255 <https://storyboard.openstack.org/#!/story/2008255>`__ for details. ,,74,4
openstack%2Fneutron~master~Ib05c4b60ac06facd5d6f31668af3ab51b854d543,openstack/neutron,master,Ib05c4b60ac06facd5d6f31668af3ab51b854d543,Workaround problem with deepcopy of the regex object in python 3.6,ABANDONED,2021-02-09 10:22:00.000000000,2021-02-09 12:45:12.000000000,,[{'_account_id': 15334}],"[{'number': 1, 'created': '2021-02-09 10:22:00.000000000', 'files': ['neutron/policy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e575ac50b0d39975ec011616c341e381e189859b', 'message': ""Workaround problem with deepcopy of the regex object in python 3.6\n\nOslo.policy in version 3.6.2 introduced deepcopy of the rule objects\nduring initialize of the policy.\nIt breaks Neutron when running on Python 3.6 or older due to bug [1]\nbecause in the FieldCheck class, which is defined in our repo we are\nusing regex and that regex can't be deepcopied properly.\n\nThis patch workarounds that problem by implementing custom __deepcopy__\nmethod in that class for python 3.6 and older.\n\n[1] https://bugs.python.org/issue10076\n\nRelated-Bug: #1913718\nChange-Id: Ib05c4b60ac06facd5d6f31668af3ab51b854d543\n""}]",2,774617,e575ac50b0d39975ec011616c341e381e189859b,4,1,1,11975,,,0,"Workaround problem with deepcopy of the regex object in python 3.6

Oslo.policy in version 3.6.2 introduced deepcopy of the rule objects
during initialize of the policy.
It breaks Neutron when running on Python 3.6 or older due to bug [1]
because in the FieldCheck class, which is defined in our repo we are
using regex and that regex can't be deepcopied properly.

This patch workarounds that problem by implementing custom __deepcopy__
method in that class for python 3.6 and older.

[1] https://bugs.python.org/issue10076

Related-Bug: #1913718
Change-Id: Ib05c4b60ac06facd5d6f31668af3ab51b854d543
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/774617/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/policy.py'],1,e575ac50b0d39975ec011616c341e381e189859b,secure-rbac," # Store kind and match if it would be need to deepcopy this object in # Python 3.6 or older self.original_kind = kind self.original_match = match def __deepcopy__(self, *args, **kwargs): if sys.version_info >= (3, 7): return super(FieldCheck, self).__deepcopy__(args, kwargs) # NOTE(slaweq): for Python 3.6 and lower we need workaround as deepcopy # of the regex modules don't works there, see bug # https://bugs.python.org/issue10076 return FieldCheck(self.original_kind, self.original_match) ",,13,0
openstack%2Fkolla-ansible~stable%2Fvictoria~I6d03fa8c81c52b6f061514a836bbd15bb6639aaf,openstack/kolla-ansible,stable/victoria,I6d03fa8c81c52b6f061514a836bbd15bb6639aaf,Fix Barbican API log config,MERGED,2021-02-08 19:12:29.000000000,2021-02-09 12:43:13.000000000,2021-02-09 12:40:25.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-08 19:12:29.000000000', 'files': ['ansible/roles/common/templates/conf/filter/01-rewrite-0.14.conf.j2', 'ansible/roles/barbican/templates/barbican-api.json.j2', 'releasenotes/notes/fix-barbican-logging-42068f47fe1e4e4d.yaml', 'ansible/roles/barbican/templates/barbican-api.ini.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.12.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4f6988564aae749464377995ba7387d1d0301f7a', 'message': ""Fix Barbican API log config\n\nThere are a few issues fixed here:\n\n- The Barbican API service doesn't set a log file, so all the Barbican API\n  service logs go to loadwsgi.py.log by default.\n- The logs in loadwsgi.py.log are not ingested properly by Fluentd.\n- uWSGI logs go to barbican-api.log. This would normally be used as the log\n  file for the Barbican API service logs.\n\nThis patch makes the following changes to address the above issues:\n\n- All uWSGI logs (from the Emperor and Vassals) go to barbican_api_uwsgi_access.log\n  Although these logs aren't strictly all access logs, this follows the existing\n  pattern for WSGI logs.\n- The Barbican API service logs are written to barbican-api.log instead of\n  loadwsgi.py.log. This follows the pattern used by other OpenStack services.\n- Fluentd is configured to parse the Barbican API service logs as it would with\n  other OpenStack Python services.\n\nChange-Id: I6d03fa8c81c52b6f061514a836bbd15bb6639aaf\nCloses-Bug: #1891343\n""}]",0,774484,4f6988564aae749464377995ba7387d1d0301f7a,9,4,1,30523,,,0,"Fix Barbican API log config

There are a few issues fixed here:

- The Barbican API service doesn't set a log file, so all the Barbican API
  service logs go to loadwsgi.py.log by default.
- The logs in loadwsgi.py.log are not ingested properly by Fluentd.
- uWSGI logs go to barbican-api.log. This would normally be used as the log
  file for the Barbican API service logs.

This patch makes the following changes to address the above issues:

- All uWSGI logs (from the Emperor and Vassals) go to barbican_api_uwsgi_access.log
  Although these logs aren't strictly all access logs, this follows the existing
  pattern for WSGI logs.
- The Barbican API service logs are written to barbican-api.log instead of
  loadwsgi.py.log. This follows the pattern used by other OpenStack services.
- Fluentd is configured to parse the Barbican API service logs as it would with
  other OpenStack Python services.

Change-Id: I6d03fa8c81c52b6f061514a836bbd15bb6639aaf
Closes-Bug: #1891343
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/84/774484/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/templates/conf/filter/01-rewrite-0.14.conf.j2', 'ansible/roles/barbican/templates/barbican-api.json.j2', 'releasenotes/notes/fix-barbican-logging-42068f47fe1e4e4d.yaml', 'ansible/roles/barbican/templates/barbican-api.ini.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.12.conf.j2']",6,4f6988564aae749464377995ba7387d1d0301f7a,, rewriterule2 programname ^(aodh_wsgi_access|barbican_api_uwsgi_access|zun_api_wsgi_access|vitrage_wsgi_access)$ wsgi_access rewriterule12 programname ^(barbican-api|barbican-worker|barbican-keystone-listener|barbican-db-manage|app)$ openstack_python, rewriterule2 programname ^(aodh_wsgi_access|barbican-api|zun_api_wsgi_access|vitrage_wsgi_access)$ wsgi_access rewriterule12 programname ^(barbican-worker|barbican-keystone-listener|barbican-db-manage|app)$ openstack_python,14,5
openstack%2Fkolla-ansible~stable%2Ftrain~I6d03fa8c81c52b6f061514a836bbd15bb6639aaf,openstack/kolla-ansible,stable/train,I6d03fa8c81c52b6f061514a836bbd15bb6639aaf,Fix Barbican API log config,MERGED,2021-02-08 20:06:12.000000000,2021-02-09 12:43:07.000000000,2021-02-09 12:40:29.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-08 20:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/017c4583e3493bf1ffa5279a50cb3fcd50188e8b', 'message': ""Fix Barbican API log config\n\nThere are a few issues fixed here:\n\n- The Barbican API service doesn't set a log file, so all the Barbican API\n  service logs go to loadwsgi.py.log by default.\n- The logs in loadwsgi.py.log are not ingested properly by Fluentd.\n- uWSGI logs go to barbican-api.log. This would normally be used as the log\n  file for the Barbican API service logs.\n\nThis patch makes the following changes to address the above issues:\n\n- All uWSGI logs (from the Emperor and Vassals) go to barbican_api_uwsgi_access.log\n  Although these logs aren't strictly all access logs, this follows the existing\n  pattern for WSGI logs.\n- The Barbican API service logs are written to barbican-api.log instead of\n  loadwsgi.py.log. This follows the pattern used by other OpenStack services.\n- Fluentd is configured to parse the Barbican API service logs as it would with\n  other OpenStack Python services.\n\nChange-Id: I6d03fa8c81c52b6f061514a836bbd15bb6639aaf\nCloses-Bug: #1891343\n""}, {'number': 2, 'created': '2021-02-08 20:10:59.000000000', 'files': ['ansible/roles/common/templates/conf/filter/01-rewrite-0.14.conf.j2', 'ansible/roles/barbican/templates/barbican-api.json.j2', 'releasenotes/notes/fix-barbican-logging-42068f47fe1e4e4d.yaml', 'ansible/roles/barbican/templates/barbican-api.ini.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.12.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e8030d0fc044c2884e299347bfebe1439f1c2e8f', 'message': ""Fix Barbican API log config\n\nThere are a few issues fixed here:\n\n- The Barbican API service doesn't set a log file, so all the Barbican API\n  service logs go to loadwsgi.py.log by default.\n- The logs in loadwsgi.py.log are not ingested properly by Fluentd.\n- uWSGI logs go to barbican-api.log. This would normally be used as the log\n  file for the Barbican API service logs.\n\nThis patch makes the following changes to address the above issues:\n\n- All uWSGI logs (from the Emperor and Vassals) go to barbican_api_uwsgi_access.log\n  Although these logs aren't strictly all access logs, this follows the existing\n  pattern for WSGI logs.\n- The Barbican API service logs are written to barbican-api.log instead of\n  loadwsgi.py.log. This follows the pattern used by other OpenStack services.\n- Fluentd is configured to parse the Barbican API service logs as it would with\n  other OpenStack Python services.\n\nChange-Id: I6d03fa8c81c52b6f061514a836bbd15bb6639aaf\nCloses-Bug: #1891343\n""}]",0,774486,e8030d0fc044c2884e299347bfebe1439f1c2e8f,9,4,2,30491,,,0,"Fix Barbican API log config

There are a few issues fixed here:

- The Barbican API service doesn't set a log file, so all the Barbican API
  service logs go to loadwsgi.py.log by default.
- The logs in loadwsgi.py.log are not ingested properly by Fluentd.
- uWSGI logs go to barbican-api.log. This would normally be used as the log
  file for the Barbican API service logs.

This patch makes the following changes to address the above issues:

- All uWSGI logs (from the Emperor and Vassals) go to barbican_api_uwsgi_access.log
  Although these logs aren't strictly all access logs, this follows the existing
  pattern for WSGI logs.
- The Barbican API service logs are written to barbican-api.log instead of
  loadwsgi.py.log. This follows the pattern used by other OpenStack services.
- Fluentd is configured to parse the Barbican API service logs as it would with
  other OpenStack Python services.

Change-Id: I6d03fa8c81c52b6f061514a836bbd15bb6639aaf
Closes-Bug: #1891343
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/86/774486/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/common/templates/conf/filter/01-rewrite-0.14.conf.j2', 'ansible/roles/barbican/templates/barbican-api.json.j2', 'releasenotes/notes/fix-barbican-logging-42068f47fe1e4e4d.yaml', 'ansible/roles/barbican/templates/barbican-api.ini.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/common/templates/conf/filter/01-rewrite-0.12.conf.j2']",6,017c4583e3493bf1ffa5279a50cb3fcd50188e8b,,<<<<<<< HEAD (3be149 CI: Use Python2 compatible pip)======= rewriterule1 programname ^(cinder-api-access|cloudkitty-api-access|gnocchi-api-access|horizon-access|keystone-apache-admin-access|keystone-apache-public-access|monasca-api-access|placement-api-access|panko-api-access)$ apache_access rewriterule2 programname ^(aodh_wsgi_access|barbican_api_uwsgi_access|zun_api_wsgi_access|vitrage_wsgi_access)$ wsgi_access >>>>>>> CHANGE (a89a23 Fix Barbican API log config) rewriterule12 programname ^(barbican-api|barbican-worker|barbican-keystone-listener|barbican-db-manage|app)$ openstack_python, rewriterule12 programname ^(barbican-worker|barbican-keystone-listener|barbican-db-manage|app)$ openstack_python,18,4
openstack%2Fkolla~stable%2Fussuri~I4d20f23a9b26364943bf967908255d82c8f6621b,openstack/kolla,stable/ussuri,I4d20f23a9b26364943bf967908255d82c8f6621b,get rid of traces of CentOS 7 support,MERGED,2021-02-05 09:19:03.000000000,2021-02-09 12:42:36.000000000,2021-02-09 12:40:20.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-05 09:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f60cb395af93616bb5686b63e10852028a4b12f6', 'message': 'get rid of traces of CentOS 7 support\n\nChange-Id: I4d20f23a9b26364943bf967908255d82c8f6621b\n'}, {'number': 2, 'created': '2021-02-05 15:48:21.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2419efb5d0e9057300ab6565bc3fdcb4e474c99c', 'message': 'get rid of traces of CentOS 7 support\n\nChange-Id: I4d20f23a9b26364943bf967908255d82c8f6621b\n'}]",0,774123,2419efb5d0e9057300ab6565bc3fdcb4e474c99c,12,3,2,24072,,,0,"get rid of traces of CentOS 7 support

Change-Id: I4d20f23a9b26364943bf967908255d82c8f6621b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/23/774123/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2']",2,f60cb395af93616bb5686b63e10852028a4b12f6,, {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %}, {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'OVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% endif %} {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'AAVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %} {% endif %},18,61
openstack%2Foslo.cache~stable%2Fvictoria~I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792,openstack/oslo.cache,stable/victoria,I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792,Dropping lower constraints testing,MERGED,2021-01-27 11:46:53.000000000,2021-02-09 12:40:07.000000000,2021-02-09 12:34:46.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 31245}]","[{'number': 1, 'created': '2021-01-27 11:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/2828ef4fde22343a73bb593274eff5f0c8573b84', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints [1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792\n(cherry picked from commit bc9c70fd666f83feff77a3ac87ab82f9b450edac)\n'}, {'number': 2, 'created': '2021-02-05 11:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/d563bc41fde0b6b1a26bff4708a18ecf1f368c7c', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints [1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792\n'}, {'number': 3, 'created': '2021-02-08 13:33:54.000000000', 'files': ['.zuul.yaml', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/8115fb411faca4560da640fa875a0ec33675352b', 'message': 'Dropping lower constraints testing\n\nWe facing errors related to the new pip resolver, this\ntopic was discussed on the ML and QA team proposed to\nto test lower-constraints [1].\n\nI propose to drop this test because the complexity and recurring pain needed\nto maintain that now exceeds the benefits provided by this mechanismes.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html\n\nChange-Id: I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792\n'}]",0,772677,8115fb411faca4560da640fa875a0ec33675352b,14,4,3,28522,,,0,"Dropping lower constraints testing

We facing errors related to the new pip resolver, this
topic was discussed on the ML and QA team proposed to
to test lower-constraints [1].

I propose to drop this test because the complexity and recurring pain needed
to maintain that now exceeds the benefits provided by this mechanismes.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-December/019390.html

Change-Id: I64f3ddcdfb21d69ae8a6fc7abaeddee2a9289792
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/77/772677/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'lower-constraints.txt']",2,2828ef4fde22343a73bb593274eff5f0c8573b84,memcached-tls-stable/victoria,,appdirs==1.4.3 certifi==2018.1.18 cffi==1.13.1 chardet==3.0.4 cliff==3.1.0 cmd2==0.8.9 debtcollector==2.1.0 decorator==4.4.2 dogpile.cache==1.0.2 entrypoints==0.3 etcd3gw==0.2.0 extras==1.0.0 fixtures==3.0.0 future==0.18.2 futurist==2.2.0 gitdb2==2.0.3 GitPython==2.1.8 idna==2.6 iso8601==0.1.12 keystoneauth1==3.4.0 linecache2==1.0.0 mock==4.0.2 mox3==0.25.0 msgpack==1.0.0 netaddr==0.7.19 netifaces==0.10.9 os-client-config==1.29.0 oslo.config==8.1.0 oslo.context==3.1.0 oslo.i18n==5.0.0 oslo.log==4.2.1 oslo.serialization==3.2.0 oslo.utils==4.2.0 oslotest==3.2.0 pbr==3.1.1 pifpaf==0.10.0 prettytable==0.7.2 pycparser==2.18 pyinotify==0.9.6 pymongo==3.0.2 pyparsing==2.2.0 pyperclip==1.8.0 python-binary-memcached==0.29.0 python-dateutil==2.8.1 python-memcached==1.56 python-mimeparse==1.6.0 python-subunit==1.2.0 pytz==2020.1 PyYAML==3.12 requests==2.18.4 requestsexceptions==1.4.0 rfc3986==1.4.0 six==1.11.0 smmap2==2.0.3 stestr==2.0.0 stevedore==1.28.0 testrepository==0.0.20 testtools==2.3.0 traceback2==1.4.0 unittest2==1.1.0 urllib3==1.22 voluptuous==0.11.7 wcwidth==0.2.4 wrapt==1.12.1 xattr==0.9.3 ,0,66
openstack%2Fopenstacksdk~master~I11c93de2ba8c6c952394856ab828989346377766,openstack/openstacksdk,master,I11c93de2ba8c6c952394856ab828989346377766,Use OOB inspection to fetch MACs for IB inspection,ABANDONED,2020-11-13 01:58:04.000000000,2021-02-09 12:33:21.000000000,,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 32177}]","[{'number': 1, 'created': '2020-11-13 01:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e3710ec971c75d1b5528a504d80a28267a936032', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 2, 'created': '2020-11-24 01:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9cf251b0fb98875fbe9b0fe42b825bd417d28ed0', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 3, 'created': '2021-01-05 04:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c6cf461a270f697579b90c2ffed0a3e16d43a185', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 4, 'created': '2021-01-06 11:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0f2629bc4c917d29c45fe084a4f1f5de63e9436c', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 5, 'created': '2021-01-06 11:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f1dccb254563763ed4c4512c82c8f91fc29dbaa2', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 6, 'created': '2021-01-07 07:56:14.000000000', 'files': ['releasenotes/notes/releasenote-bf8c1b0db03dadd5.yaml', 'openstack/baremetal_introspection/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cca82ebb09cf9f1bbdc06377e06ae12153a2038a', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}]",7,762603,cca82ebb09cf9f1bbdc06377e06ae12153a2038a,23,6,6,32177,,,0,"Use OOB inspection to fetch MACs for IB inspection

This change adds get_mac_addresses call to the ManagementInterface which will
be used by both out-of-band inspection and in-band inspection with
ironic-inspector. This will remove the necessity of manually defining MAC
addresses for nodes and/or enabling IPMI functionality on Redfish-based
systems.

Change-Id: I11c93de2ba8c6c952394856ab828989346377766
Story: 2008038
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/03/762603/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/baremetal_introspection/v1/_proxy.py'],1,e3710ec971c75d1b5528a504d80a28267a936032,story-2008038," def start_introspection(self, node, manage_boot=None, lookup=None): id=node.id, lookup=lookup) if lookup is not None: kwargs['lookup'] = lookup"," def start_introspection(self, node, manage_boot=None): id=node.id)",5,2
openstack%2Fpuppet-nova~stable%2Fvictoria~I98fe83e0c245388944529cd19b5e2bbed134e855,openstack/puppet-nova,stable/victoria,I98fe83e0c245388944529cd19b5e2bbed134e855,Allow both DEFAULT/dhcp_domain and api/dhcp_domain to be set,MERGED,2021-01-06 01:23:32.000000000,2021-02-09 12:32:29.000000000,2021-01-12 08:30:51.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23811}]","[{'number': 1, 'created': '2021-01-06 01:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f2f90b0e42eb938283ca0e782b82df5445e13a26', 'message': 'Allow both DEFAULT/dhcp_domain and api/dhcp_domain to be set\n\nPartial revert of If6a26527a737a7184ebddd5b4bc346d64827e9e3 to allow\nboth/either config option to be used until it is clear what nova will\ntake.\n\nRelated-bug: #1903908\nChange-Id: I98fe83e0c245388944529cd19b5e2bbed134e855\n'}, {'number': 2, 'created': '2021-01-06 01:40:17.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7301812c9e32cde7ee145a1cbd18e8e76f52be37', 'message': 'Allow both DEFAULT/dhcp_domain and api/dhcp_domain to be set\n\nPartial revert of If6a26527a737a7184ebddd5b4bc346d64827e9e3 to allow\nboth/either config option to be used until it is clear what nova will\ntake.\n\nRelated-bug: #1903908\nChange-Id: I98fe83e0c245388944529cd19b5e2bbed134e855\n'}]",0,769440,7301812c9e32cde7ee145a1cbd18e8e76f52be37,20,7,2,27419,,,0,"Allow both DEFAULT/dhcp_domain and api/dhcp_domain to be set

Partial revert of If6a26527a737a7184ebddd5b4bc346d64827e9e3 to allow
both/either config option to be used until it is clear what nova will
take.

Related-bug: #1903908
Change-Id: I98fe83e0c245388944529cd19b5e2bbed134e855
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/40/769440/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,f2f90b0e42eb938283ca0e782b82df5445e13a26,refactor_nova_db_config, 'DEFAULT/dhcp_domain': value => $dhcp_domain;,,1,0
openstack%2Fironic-inspector~master~I3debcd1f32a2627dafd8456ec73a71fc7c402ebb,openstack/ironic-inspector,master,I3debcd1f32a2627dafd8456ec73a71fc7c402ebb,Use OOB inspection to fetch MACs for IB inspection,ABANDONED,2020-10-21 10:33:40.000000000,2021-02-09 12:32:01.000000000,,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32177}]","[{'number': 1, 'created': '2020-10-21 10:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/99f2376c59d3d17c8876c0ba735240905e3434dc', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 2, 'created': '2020-11-11 11:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/58ebf19340a5c2b9f53789d2d505399a7a83cb0a', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 3, 'created': '2020-11-11 22:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/5062099fe390b3b63e7e97f305525d13f003ed14', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 4, 'created': '2020-11-20 00:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/b7ae9d47be497aa426f0af1451197cfb36de032b', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 5, 'created': '2020-11-23 05:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/436039408a730410d4672026446a0faaf22afbff', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 6, 'created': '2020-11-23 06:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/5ff60762ff040c94cc1acdb910e7061f5c92dfba', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 7, 'created': '2020-11-24 05:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/5c827d1cc4822cd19fcc688df41531ab72709b47', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 8, 'created': '2020-11-24 10:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/625495ad75cb42da2b9c431612238bcc43426e12', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 9, 'created': '2020-11-24 12:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/d9a79c663a1e8ad98f3ac8ba59ca4dfd7ee496ea', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 10, 'created': '2021-01-05 04:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e49cb7d5a9da33c8a3e7373c074f08dd0cf904be', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 11, 'created': '2021-01-05 06:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c9346c4fa7174258179c753f2e84c4c38113f0bd', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 12, 'created': '2021-01-06 07:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/92396dc74ba17742c22458ffa5c4632ab7c7feef', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 13, 'created': '2021-01-07 07:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/9c8ec74a73cfd013cd3492cf2f158af4ece4cc3f', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}, {'number': 14, 'created': '2021-01-07 10:03:08.000000000', 'files': ['ironic_inspector/node_cache.py', 'ironic_inspector/test/unit/test_introspect.py', 'ironic_inspector/introspect.py', 'ironic_inspector/test/unit/test_node_cache.py', 'ironic_inspector/test/unit/test_manager.py', 'ironic_inspector/conductor/manager.py', 'ironic_inspector/main.py', 'api-ref/source/introspection-api-versions.inc', 'ironic_inspector/test/unit/test_main.py', 'releasenotes/notes/releasenote-a561d5e22fe563f3.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/4c8058b841fd28144060fcf83cbbf78d3a9f0742', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb\nStory: 2008038\nTask: 40699\n'}]",21,758994,4c8058b841fd28144060fcf83cbbf78d3a9f0742,53,6,14,32177,,,0,"Use OOB inspection to fetch MACs for IB inspection

This change adds get_mac_addresses call to the ManagementInterface which will
be used by both out-of-band inspection and in-band inspection with
ironic-inspector. This will remove the necessity of manually defining MAC
addresses for nodes and/or enabling IPMI functionality on Redfish-based
systems.

Change-Id: I3debcd1f32a2627dafd8456ec73a71fc7c402ebb
Story: 2008038
Task: 40699
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/94/758994/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/introspect.py', 'ironic_inspector/test/unit/test_manager.py', 'ironic_inspector/conductor/manager.py', 'ironic_inspector/main.py', 'ironic_inspector/test/unit/test_main.py']",5,99f2376c59d3d17c8876c0ba735240905e3434dc,story-2008038," token=None, lookup=None) token=None, lookup=None) token=None, lookup=None) token=None, lookup=None)", token=None) token=None) token=None) token=None),44,16
openstack%2Fironic~master~I11c93de2ba8c6c952394856ab828989346377766,openstack/ironic,master,I11c93de2ba8c6c952394856ab828989346377766,Use OOB inspection to fetch MACs for IB inspection,ABANDONED,2020-09-10 10:00:25.000000000,2021-02-09 12:31:38.000000000,,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 32177}]","[{'number': 1, 'created': '2020-09-10 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d0762c910224ad7483dad44dc365079785fbf941', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 2, 'created': '2020-11-03 12:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/91ce2f2c463645e31a492673d758a532f0bc8516', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 3, 'created': '2020-11-04 00:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/48848cfa84110a530966407f33bb69ede6954839', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 4, 'created': '2020-11-04 04:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/419770833f1092da775f96d274bd91e1fa603e65', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 5, 'created': '2020-11-05 10:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/46d7a93fe56ab215f8ac5197a9a35df4890a6c2c', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 6, 'created': '2020-11-11 10:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5dabef59ee6c010e9407df697a488eae84f6c819', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 7, 'created': '2020-11-11 22:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/be3ff615e3361a654fe1f8613225f155f7375036', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 8, 'created': '2020-11-11 23:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/343fe1ef4e3456351a863fcb2ea7605f4f9a59f7', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 9, 'created': '2020-11-18 04:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/61fdb6cdf7e9ead3112df8d6e5107fbcb0e64e09', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 10, 'created': '2020-11-18 05:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/96097a1ea16c24e9fe4657f5385b55c1c99ae7ed', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 11, 'created': '2020-11-20 04:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/16a71ae9c65c7263c101359bbf33c8d1bc251c95', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 12, 'created': '2020-11-23 04:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c546848729b8743067b5112eb6592479eacb841f', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 13, 'created': '2020-11-24 05:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1aec14d156a69f99db1ab4352ba8c9b72808c017', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 14, 'created': '2020-11-25 02:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9d4f1643f9caeafcf96c015bdf86d80705f96854', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 15, 'created': '2020-11-25 03:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0d244206a24fc8c3070883c75398a009ad55a4e2', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 16, 'created': '2020-11-25 03:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ffbf7f43177dc9637fcd5fc0f9e6e9d1b9aa00b4', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 17, 'created': '2021-01-05 04:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e493c74a33925317a2de2e6501b055382c6785b9', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 18, 'created': '2021-01-05 06:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/68c1a051a9d18119e82af5e73da498a9cf15608a', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 19, 'created': '2021-01-06 07:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c2f9921c86869c5504a3c5f0cf4237b2c72eb7fb', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}, {'number': 20, 'created': '2021-01-07 07:53:32.000000000', 'files': ['ironic/drivers/modules/redfish/utils.py', 'ironic/drivers/base.py', 'ironic/drivers/modules/redfish/management.py', 'ironic/tests/unit/drivers/modules/test_inspector.py', 'ironic/drivers/modules/redfish/inspect.py', 'ironic/drivers/modules/inspector.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8122c660266be70303061535a00887a5d43cf714', 'message': 'Use OOB inspection to fetch MACs for IB inspection\n\nThis change adds get_mac_addresses call to the ManagementInterface which will\nbe used by both out-of-band inspection and in-band inspection with\nironic-inspector. This will remove the necessity of manually defining MAC\naddresses for nodes and/or enabling IPMI functionality on Redfish-based\nsystems.\n\nChange-Id: I11c93de2ba8c6c952394856ab828989346377766\nStory: 2008038\n'}]",17,750943,8122c660266be70303061535a00887a5d43cf714,93,6,20,32177,,,0,"Use OOB inspection to fetch MACs for IB inspection

This change adds get_mac_addresses call to the ManagementInterface which will
be used by both out-of-band inspection and in-band inspection with
ironic-inspector. This will remove the necessity of manually defining MAC
addresses for nodes and/or enabling IPMI functionality on Redfish-based
systems.

Change-Id: I11c93de2ba8c6c952394856ab828989346377766
Story: 2008038
",git fetch https://review.opendev.org/openstack/ironic refs/changes/43/750943/14 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/base.py', 'ironic/drivers/modules/redfish/management.py']",2,d0762c910224ad7483dad44dc365079785fbf941,story-2008038," def get_mac_addresses(self, task): """"""Get MAC address information for the node. :param task: A TaskManager instance containing the node to act on. :raises: UnsupportedDriverExtension :returns: A list of MAC addresses for the node """""" system = redfish_utils.get_system(task.node) mac_addresses = list() try: if system.ethernet_interfaces.summary != """": for mac in system.ethernet_interfaces.summary: if system.ethernet_interfaces.summary[mac] == ""enabled"": mac_addresses.append(mac) return mac_addresses except sushy.exceptions.SushyError as e: error_msg = (_('Failed to fetcg Redfish Ethernet interfaces' ' summary failed for node ' '%(node)s. Error: ' '%(error)s') % {'node': task.node.uuid, 'error': e}) LOG.error(error_msg) raise exception.RedfishError(error=error_msg)",,38,0
openstack%2Fkolla~stable%2Fvictoria~I4d20f23a9b26364943bf967908255d82c8f6621b,openstack/kolla,stable/victoria,I4d20f23a9b26364943bf967908255d82c8f6621b,get rid of traces of CentOS 7 support,MERGED,2021-02-05 09:18:41.000000000,2021-02-09 12:23:17.000000000,2021-02-09 12:19:38.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-05 09:18:41.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/65870d9650ed3141a84f7cf5173371f2f415fbc0', 'message': 'get rid of traces of CentOS 7 support\n\nChange-Id: I4d20f23a9b26364943bf967908255d82c8f6621b\n'}]",0,774122,65870d9650ed3141a84f7cf5173371f2f415fbc0,16,3,1,24072,,,0,"get rid of traces of CentOS 7 support

Change-Id: I4d20f23a9b26364943bf967908255d82c8f6621b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/22/774122/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2']",2,65870d9650ed3141a84f7cf5173371f2f415fbc0,, {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %}, {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'OVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% endif %} {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'AAVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %} {% endif %},18,61
openstack%2Fopenstack-ansible~stable%2Fvictoria~I051539fc3bbd3bfcddc30048348c571dd6a5c7e1,openstack/openstack-ansible,stable/victoria,I051539fc3bbd3bfcddc30048348c571dd6a5c7e1,Add haproxy_*_service variables,MERGED,2021-02-05 10:37:43.000000000,2021-02-09 12:22:02.000000000,2021-02-09 12:17:16.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-05 10:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b3bc5cca17e3d3e7a7cca4ab9d4b41c5013a5566', 'message': 'Add haproxy_*_service variables\n\nThis aims to ease override of the specific service listen port or other\nhaproxy frontend/backend setting without override of all backends.\n\nChange-Id: I051539fc3bbd3bfcddc30048348c571dd6a5c7e1\n(cherry picked from commit 65a8c2413e1e8f91fd6d712cb84af2ab01784299)\n'}, {'number': 2, 'created': '2021-02-05 10:39:57.000000000', 'files': ['releasenotes/notes/haproxy_service_variables-ffd7958b20dfe92e.yaml', 'inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e55defe9f7c9558e86739cd5092e7376bbd8b868', 'message': 'Add haproxy_*_service variables\n\nThis aims to ease override of the specific service listen port or other\nhaproxy frontend/backend setting without override of all backends.\n\nChange-Id: I051539fc3bbd3bfcddc30048348c571dd6a5c7e1\n(cherry picked from commit 65a8c2413e1e8f91fd6d712cb84af2ab01784299)\n'}]",0,774126,e55defe9f7c9558e86739cd5092e7376bbd8b868,10,3,2,28619,,,0,"Add haproxy_*_service variables

This aims to ease override of the specific service listen port or other
haproxy frontend/backend setting without override of all backends.

Change-Id: I051539fc3bbd3bfcddc30048348c571dd6a5c7e1
(cherry picked from commit 65a8c2413e1e8f91fd6d712cb84af2ab01784299)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/26/774126/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/haproxy_service_variables-ffd7958b20dfe92c.yaml', 'inventory/group_vars/haproxy/haproxy.yml']",2,b3bc5cca17e3d3e7a7cca4ab9d4b41c5013a5566,,"haproxy_adjutant_api_service: haproxy_service_name: adjutant_api haproxy_backend_nodes: ""{{ groups['adjutant_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['adjutant_api'] is defined and groups['adjutant_api'] | length > 0 }}"" haproxy_aodh_api_service: haproxy_service_name: aodh_api haproxy_backend_nodes: ""{{ groups['aodh_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8042 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['aodh_api'] is defined and groups['aodh_api'] | length > 0 }}"" haproxy_barbican_service: haproxy_service_name: barbican haproxy_backend_nodes: ""{{ groups['barbican_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9311 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['barbican_api'] is defined and groups['barbican_api'] | length > 0 }}"" haproxy_ceph_rgw_service: haproxy_service_name: ceph-rgw haproxy_backend_nodes: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) | ternary(groups['ceph-rgw'], ceph_rgws) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: ""{{ radosgw_service_port | default(7980) }}"" haproxy_balance_type: http haproxy_backend_options: - httpchk HEAD / haproxy_backend_httpcheck_options: - expect rstatus 200|405 haproxy_service_enabled: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"" haproxy_cinder_api_service: haproxy_service_name: cinder_api haproxy_backend_nodes: ""{{ groups['cinder_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8776 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['cinder_api'] is defined and groups['cinder_api'] | length > 0 }}"" haproxy_designate_api_service: haproxy_service_name: designate_api haproxy_backend_nodes: ""{{ groups['designate_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9001 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['designate_api'] is defined and groups['designate_api'] | length > 0 }}"" haproxy_galera_service: haproxy_service_name: galera haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['galera_all'] | default([]))[1:] }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 3306 haproxy_check_port: 9200 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_galera_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['galera_all'] is defined and groups['galera_all'] | length > 0 }}"" haproxy_glance_api_service: haproxy_service_name: glance_api haproxy_backend_nodes: ""{{ groups['glance_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9292 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['glance_api'] is defined and groups['glance_api'] | length > 0 }}"" haproxy_gnocchi_service: haproxy_service_name: gnocchi haproxy_backend_nodes: ""{{ groups['gnocchi_all'] | default([]) }}"" haproxy_port: 8041 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"" haproxy_heat_api_cfn_service: haproxy_service_name: heat_api_cfn haproxy_backend_nodes: ""{{ groups['heat_api_cfn'] | default([]) }}"" haproxy_port: 8000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api_cfn'] is defined and groups['heat_api_cfn'] | length > 0 }}"" haproxy_heat_api_service: haproxy_service_name: heat_api haproxy_backend_nodes: ""{{ groups['heat_api'] | default([]) }}"" haproxy_port: 8004 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api'] is defined and groups['heat_api'] | length > 0 }}"" haproxy_horizon_service: haproxy_service_name: horizon haproxy_backend_nodes: ""{{ groups['horizon_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: true haproxy_port: ""{{ haproxy_ssl | ternary(443,80) }}"" haproxy_backend_port: 80 haproxy_redirect_http_port: 80 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"" haproxy_redirect_scheme: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary('https if !{ ssl_fc } !{ path_beg /.well-known/acme-challenge/ }', 'https if !{ ssl_fc }') }}"" haproxy_frontend_acls: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary(haproxy_ssl_letsencrypt_acl, {}) }}"" haproxy_acls: ""{{ keystone_security_txt_content is defined | ternary(haproxy_security_txt_acl, {}) }}"" haproxy_ironic_api_service: haproxy_service_name: ironic_api haproxy_backend_nodes: ""{{ groups['ironic_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 6385 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_api'] is defined and groups['ironic_api'] | length > 0 }}"" haproxy_ironic_inspector_service: haproxy_service_name: ironic_inspector haproxy_backend_nodes: ""{{ groups['ironic_inspector'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_inspector'] is defined and groups['ironic_inspector'] | length > 0 }}"" haproxy_keystone_service: haproxy_service_name: keystone_service haproxy_backend_nodes: ""{{ groups['keystone_all'] | default([]) }}"" haproxy_port: 5000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: ""http"" haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['keystone_all'] is defined and groups['keystone_all'] | length > 0 }}"" haproxy_letsencrypt_service: haproxy_service_name: letsencrypt haproxy_backend_nodes: ""{{ groups['haproxy_all'] }}"" backend_rise: 1 backend_fall: 2 haproxy_bind: - 127.0.0.1 haproxy_port: ""{{ haproxy_ssl_letsencrypt_certbot_backend_port }}"" haproxy_balance_type: http haproxy_service_enabled: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) }}"" haproxy_magnum_service: haproxy_service_name: magnum haproxy_backend_nodes: ""{{ groups['magnum_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9511 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['magnum_all'] is defined and groups['magnum_all'] | length > 0 }}"" haproxy_manila_service: haproxy_service_name: manila haproxy_backend_nodes: ""{{ groups['manila_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8786 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['manila_api'] is defined and groups['manila_api'] | length > 0 }}"" haproxy_masakari_api_service: haproxy_service_name: masakari_api haproxy_backend_nodes: ""{{ groups['masakari_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 15868 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['masakari_api'] is defined and groups['masakari_api'] | length > 0 }}"" haproxy_mistral_service: haproxy_service_name: mistral haproxy_backend_nodes: ""{{ groups['mistral_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8989 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['mistral_all'] is defined and groups['mistral_all'] | length > 0 }}"" haproxy_murano_service: haproxy_service_name: murano haproxy_backend_nodes: ""{{ groups['murano_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8082 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 401"" haproxy_service_enabled: ""{{ groups['murano_all'] is defined and groups['murano_all'] | length > 0 }}"" haproxy_neutron_server_service: haproxy_service_name: neutron_server haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_port: 9696 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['neutron_server'] is defined and groups['neutron_server'] | length > 0 }}"" haproxy_nova_api_metadata_service: haproxy_service_name: nova_api_metadata haproxy_backend_nodes: ""{{ groups['nova_api_metadata'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8775 haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_nova_metadata_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['nova_api_metadata'] is defined and groups['nova_api_metadata'] | length > 0 }}"" haproxy_nova_api_compute_service: haproxy_service_name: nova_api_os_compute haproxy_backend_nodes: ""{{ groups['nova_api_os_compute'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8774 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['nova_api_os_compute'] is defined and groups['nova_api_os_compute'] | length > 0 }}"" haproxy_nova_console_service: haproxy_service_name: nova_console haproxy_backend_nodes: ""{{ groups['nova_console'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: ""{{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_port'] | default(6082) }}"" haproxy_balance_type: http haproxy_timeout_client: 60m haproxy_timeout_server: 60m haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD {{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_path'] | default('/spice_auto.html') }} HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['nova_console'] is defined and groups['nova_console'] | length > 0 }}"" haproxy_octavia_service: haproxy_service_name: octavia haproxy_backend_nodes: ""{{ groups['octavia_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9876 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['octavia_all'] is defined and groups['octavia_all'] | length > 0 }}"" haproxy_opendaylight_neutron_service: haproxy_service_name: opendaylight-neutron haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8180 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" haproxy_opendaylight_websocket_service: haproxy_service_name: opendaylight-websocket haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8185 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" haproxy_ovn_northbound_service: haproxy_service_name: neutron_ovn_northd_northbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6641 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_ovn_southbound_service: haproxy_service_name: neutron_ovn_northd_southbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6642 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_ovn_ovsdb_service: haproxy_service_name: neutron_ovn_ovsdb_server haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6640 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" haproxy_panko_api_service: haproxy_service_name: panko_api haproxy_backend_nodes: ""{{ groups['panko_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8777 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['panko_all'] is defined and groups['panko_all'] | length > 0 }}"" haproxy_placement_service: haproxy_service_name: placement haproxy_backend_nodes: ""{{ groups['placement_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8780 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['placement_all'] is defined and groups['placement_all'] | length > 0 }}"" haproxy_rabbitmq_service: haproxy_service_name: rabbitmq_mgmt haproxy_backend_nodes: ""{{ groups['rabbitmq'] | default([]) }}"" haproxy_ssl: False haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 15672 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_rabbitmq_management_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['rabbitmq'] is defined and groups['rabbitmq'] | length > 0 }}"" haproxy_repo_service: haproxy_service_name: repo_all haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8181 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /repo_sync_complete HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" haproxy_sahara_api_service: haproxy_service_name: sahara_api haproxy_backend_nodes: ""{{ groups['sahara_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8386 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['sahara_api'] is defined and groups['sahara_api'] | length > 0 }}"" haproxy_senlin_api_service: haproxy_service_name: senlin_api haproxy_backend_nodes: ""{{ groups['senlin_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8778 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['senlin_api'] is defined and groups['senlin_api'] | length > 0 }}"" haproxy_swift_proxy_service: haproxy_service_name: swift_proxy haproxy_backend_nodes: ""{{ groups['swift_proxy'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8080 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0 }}"" haproxy_tacker_service: haproxy_service_name: tacker haproxy_backend_nodes: ""{{ groups['tacker_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9890 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['tacker_all'] is defined and groups['tacker_all'] | length > 0 }}"" haproxy_trove_service: haproxy_service_name: trove haproxy_backend_nodes: ""{{ groups['trove_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8779 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['trove_api'] is defined and groups['trove_api'] | length > 0 }}"" haproxy_zun_api_service: haproxy_service_name: zun_api haproxy_backend_nodes: ""{{ groups['zun_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9517 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['zun_api'] is defined and groups['zun_api'] | length > 0 }}"" haproxy_default_services: - service: ""{{ haproxy_adjutant_api_service }}"" - service: ""{{ haproxy_aodh_api_service }}"" - service: ""{{ haproxy_barbican_service }}"" - service: ""{{ haproxy_ceph_rgw_service }}"" - service: ""{{ haproxy_cinder_api_service }}"" - service: ""{{ haproxy_designate_api_service }}"" - service: ""{{ haproxy_galera_service }}"" - service: ""{{ haproxy_glance_api_service }}"" - service: ""{{ haproxy_gnocchi_service }}"" - service: ""{{ haproxy_heat_api_cfn_service }}"" - service: ""{{ haproxy_heat_api_service }}"" - service: ""{{ haproxy_horizon_service }}"" - service: ""{{ haproxy_ironic_api_service }}"" - service: ""{{ haproxy_ironic_inspector_service }}"" - service: ""{{ haproxy_keystone_service }}"" - service: ""{{ haproxy_letsencrypt_service }}"" - service: ""{{ haproxy_magnum_service }}"" - service: ""{{ haproxy_manila_service }}"" - service: ""{{ haproxy_masakari_api_service }}"" - service: ""{{ haproxy_mistral_service }}"" - service: ""{{ haproxy_murano_service }}"" - service: ""{{ haproxy_neutron_server_service }}"" - service: ""{{ haproxy_nova_api_metadata_service }}"" - service: ""{{ haproxy_nova_api_compute_service }}"" - service: ""{{ haproxy_nova_console_service }}"" - service: ""{{ haproxy_octavia_service }}"" - service: ""{{ haproxy_opendaylight_neutron_service }}"" - service: ""{{ haproxy_opendaylight_websocket_service }}"" - service: ""{{ haproxy_ovn_northbound_service }}"" - service: ""{{ haproxy_ovn_southbound_service }}"" - service: ""{{ haproxy_ovn_ovsdb_service }}"" - service: ""{{ haproxy_panko_api_service }}"" - service: ""{{ haproxy_placement_service }}"" - service: ""{{ haproxy_rabbitmq_service }}"" - service: ""{{ haproxy_repo_service }}"" - service: ""{{ haproxy_sahara_api_service }}"" - service: ""{{ haproxy_senlin_api_service }}"" - service: ""{{ haproxy_swift_proxy_service }}"" - service: ""{{ haproxy_tacker_service }}"" - service: ""{{ haproxy_trove_service }}"" - service: ""{{ haproxy_zun_api_service }}""","haproxy_default_services: - service: haproxy_service_name: galera haproxy_backend_nodes: ""{{ (groups['galera_all'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['galera_all'] | default([]))[1:] }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 3306 haproxy_check_port: 9200 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_galera_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['galera_all'] is defined and groups['galera_all'] | length > 0 }}"" - service: haproxy_service_name: repo_git haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 9418 haproxy_balance_type: tcp haproxy_backend_options: - tcp-check haproxy_whitelist_networks: ""{{ haproxy_repo_git_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" state: absent - service: haproxy_service_name: repo_all haproxy_backend_nodes: ""{{ groups['repo_all'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8181 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /repo_sync_complete HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"" - service: haproxy_service_name: glance_api haproxy_backend_nodes: ""{{ groups['glance_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9292 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['glance_api'] is defined and groups['glance_api'] | length > 0 }}"" - service: haproxy_service_name: gnocchi haproxy_backend_nodes: ""{{ groups['gnocchi_all'] | default([]) }}"" haproxy_port: 8041 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"" - service: haproxy_service_name: heat_api_cfn haproxy_backend_nodes: ""{{ groups['heat_api_cfn'] | default([]) }}"" haproxy_port: 8000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api_cfn'] is defined and groups['heat_api_cfn'] | length > 0 }}"" - service: haproxy_service_name: heat_api haproxy_backend_nodes: ""{{ groups['heat_api'] | default([]) }}"" haproxy_port: 8004 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['heat_api'] is defined and groups['heat_api'] | length > 0 }}"" - service: haproxy_service_name: keystone_service haproxy_backend_nodes: ""{{ groups['keystone_all'] | default([]) }}"" haproxy_port: 5000 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: ""http"" haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['keystone_all'] is defined and groups['keystone_all'] | length > 0 }}"" - service: haproxy_service_name: neutron_server haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_port: 9696 haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['neutron_server'] is defined and groups['neutron_server'] | length > 0 }}"" - service: haproxy_service_name: nova_api_metadata haproxy_backend_nodes: ""{{ groups['nova_api_metadata'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8775 haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_nova_metadata_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['nova_api_metadata'] is defined and groups['nova_api_metadata'] | length > 0 }}"" - service: haproxy_service_name: nova_api_os_compute haproxy_backend_nodes: ""{{ groups['nova_api_os_compute'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8774 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['nova_api_os_compute'] is defined and groups['nova_api_os_compute'] | length > 0 }}"" - service: haproxy_service_name: placement haproxy_backend_nodes: ""{{ groups['placement_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8780 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['placement_all'] is defined and groups['placement_all'] | length > 0 }}"" - service: haproxy_service_name: nova_console haproxy_backend_nodes: ""{{ groups['nova_console'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: ""{{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_port'] | default(6082) }}"" haproxy_balance_type: http haproxy_timeout_client: 60m haproxy_timeout_server: 60m haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD {{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_path'] | default('/spice_auto.html') }} HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 200"" haproxy_service_enabled: ""{{ groups['nova_console'] is defined and groups['nova_console'] | length > 0 }}"" - service: haproxy_service_name: cinder_api haproxy_backend_nodes: ""{{ groups['cinder_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8776 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['cinder_api'] is defined and groups['cinder_api'] | length > 0 }}"" - service: haproxy_service_name: horizon haproxy_backend_nodes: ""{{ groups['horizon_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: true haproxy_port: ""{{ haproxy_ssl | ternary(443,80) }}"" haproxy_backend_port: 80 haproxy_redirect_http_port: 80 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"" haproxy_redirect_scheme: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary('https if !{ ssl_fc } !{ path_beg /.well-known/acme-challenge/ }', 'https if !{ ssl_fc }') }}"" haproxy_frontend_acls: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) | ternary(haproxy_ssl_letsencrypt_acl, {}) }}"" haproxy_acls: ""{{ keystone_security_txt_content is defined | ternary(haproxy_security_txt_acl, {}) }}"" - service: haproxy_service_name: letsencrypt haproxy_backend_nodes: ""{{ groups['haproxy_all'] }}"" backend_rise: 1 backend_fall: 2 haproxy_bind: - 127.0.0.1 haproxy_port: ""{{ haproxy_ssl_letsencrypt_certbot_backend_port }}"" haproxy_balance_type: http haproxy_service_enabled: ""{{ (haproxy_ssl_letsencrypt_enable | bool and haproxy_ssl | bool) }}"" - service: haproxy_service_name: sahara_api haproxy_backend_nodes: ""{{ groups['sahara_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8386 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['sahara_api'] is defined and groups['sahara_api'] | length > 0 }}"" - service: haproxy_service_name: senlin_api haproxy_backend_nodes: ""{{ groups['senlin_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8778 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['senlin_api'] is defined and groups['senlin_api'] | length > 0 }}"" - service: haproxy_service_name: swift_proxy haproxy_backend_nodes: ""{{ groups['swift_proxy'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: 8080 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0 }}"" - service: haproxy_service_name: adjutant_api haproxy_backend_nodes: ""{{ groups['adjutant_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_balance_alg: source haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['adjutant_api'] is defined and groups['adjutant_api'] | length > 0 }}"" - service: haproxy_service_name: aodh_api haproxy_backend_nodes: ""{{ groups['aodh_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8042 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['aodh_api'] is defined and groups['aodh_api'] | length > 0 }}"" - service: haproxy_service_name: ironic_api haproxy_backend_nodes: ""{{ groups['ironic_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 6385 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_api'] is defined and groups['ironic_api'] | length > 0 }}"" - service: haproxy_service_name: ironic_inspector haproxy_backend_nodes: ""{{ groups['ironic_inspector'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 5050 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['ironic_inspector'] is defined and groups['ironic_inspector'] | length > 0 }}"" - service: haproxy_service_name: rabbitmq_mgmt haproxy_backend_nodes: ""{{ groups['rabbitmq'] | default([]) }}"" haproxy_ssl: False haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 15672 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_whitelist_networks: ""{{ haproxy_rabbitmq_management_whitelist_networks }}"" haproxy_service_enabled: ""{{ groups['rabbitmq'] is defined and groups['rabbitmq'] | length > 0 }}"" - service: haproxy_service_name: magnum haproxy_backend_nodes: ""{{ groups['magnum_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9511 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['magnum_all'] is defined and groups['magnum_all'] | length > 0 }}"" - service: haproxy_service_name: manila haproxy_backend_nodes: ""{{ groups['manila_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8786 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['manila_api'] is defined and groups['manila_api'] | length > 0 }}"" - service: haproxy_service_name: masakari_api haproxy_backend_nodes: ""{{ groups['masakari_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 15868 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['masakari_api'] is defined and groups['masakari_api'] | length > 0 }}"" - service: haproxy_service_name: mistral haproxy_backend_nodes: ""{{ groups['mistral_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8989 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['mistral_all'] is defined and groups['mistral_all'] | length > 0 }}"" - service: haproxy_service_name: murano haproxy_backend_nodes: ""{{ groups['murano_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8082 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_backend_httpcheck_options: - ""expect status 401"" haproxy_service_enabled: ""{{ groups['murano_all'] is defined and groups['murano_all'] | length > 0 }}"" - service: haproxy_service_name: trove haproxy_backend_nodes: ""{{ groups['trove_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8779 haproxy_balance_type: http haproxy_backend_options: - ""httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['trove_api'] is defined and groups['trove_api'] | length > 0 }}"" - service: haproxy_service_name: barbican haproxy_backend_nodes: ""{{ groups['barbican_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9311 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['barbican_api'] is defined and groups['barbican_api'] | length > 0 }}"" - service: haproxy_service_name: designate_api haproxy_backend_nodes: ""{{ groups['designate_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9001 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['designate_api'] is defined and groups['designate_api'] | length > 0 }}"" - service: haproxy_service_name: octavia haproxy_backend_nodes: ""{{ groups['octavia_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9876 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['octavia_all'] is defined and groups['octavia_all'] | length > 0 }}"" - service: haproxy_service_name: tacker haproxy_backend_nodes: ""{{ groups['tacker_all'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9890 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['tacker_all'] is defined and groups['tacker_all'] | length > 0 }}"" - service: haproxy_service_name: opendaylight-neutron haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8180 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" - service: haproxy_service_name: opendaylight-websocket haproxy_backend_nodes: ""{{ groups['neutron_server'] | default([]) }}"" haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_port: 8185 haproxy_balance_type: tcp haproxy_timeout_client: 5000s haproxy_timeout_server: 5000s haproxy_whitelist_networks: ""{{ haproxy_opendaylight_whitelist_networks }}"" haproxy_service_enabled: ""{{ neutron_plugin_type == 'ml2.opendaylight' }}"" - service: haproxy_service_name: ceph-rgw haproxy_backend_nodes: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) | ternary(groups['ceph-rgw'], ceph_rgws) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_balance_alg: source haproxy_port: ""{{ radosgw_service_port | default(7980) }}"" haproxy_balance_type: http haproxy_backend_options: - httpchk HEAD / haproxy_backend_httpcheck_options: - expect rstatus 200|405 haproxy_service_enabled: ""{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_northd_northbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" # list expected haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6641 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_northd_southbound haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6642 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: neutron_ovn_ovsdb_server haproxy_backend_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[:1] }}"" haproxy_backup_nodes: ""{{ (groups['neutron_ovn_northd'] | default([]))[1:] }}"" haproxy_port: 6640 haproxy_bind: ""{{ [internal_lb_vip_address] }}"" haproxy_balance_type: tcp haproxy_timeout_client: 90m haproxy_timeout_server: 90m haproxy_backend_options: - tcpka haproxy_service_enabled: ""{{ (neutron_plugin_type == 'ml2.ovn') and (groups['neutron_ovn_northd'] is defined and groups['neutron_ovn_northd'] | length > 0) }}"" - service: haproxy_service_name: panko_api haproxy_backend_nodes: ""{{ groups['panko_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 8777 haproxy_balance_type: http haproxy_backend_options: - ""forwardfor"" - ""httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" - ""httplog"" haproxy_service_enabled: ""{{ groups['panko_all'] is defined and groups['panko_all'] | length > 0 }}"" - service: haproxy_service_name: zun_api haproxy_backend_nodes: ""{{ groups['zun_api'] | default([]) }}"" haproxy_ssl: ""{{ haproxy_ssl }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}"" haproxy_port: 9517 haproxy_balance_type: http haproxy_backend_options: - ""httpchk GET /v1 HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"" haproxy_service_enabled: ""{{ groups['zun_api'] is defined and groups['zun_api'] | length > 0 }}""",539,461
openstack%2Fopenstack-ansible-os_aodh~master~I73773536938dff9f768381a333c5fa02c98e9d55,openstack/openstack-ansible-os_aodh,master,I73773536938dff9f768381a333c5fa02c98e9d55,Move aodh pip packages from constraints to requirements,MERGED,2021-01-25 08:45:57.000000000,2021-02-09 11:48:08.000000000,2021-02-09 11:45:35.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-25 08:45:57.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/405f551fad8e08b1610459f30baa4101b92d00fe', 'message': 'Move aodh pip packages from constraints to requirements\n\nChange-Id: I73773536938dff9f768381a333c5fa02c98e9d55\n'}]",0,772259,405f551fad8e08b1610459f30baa4101b92d00fe,19,3,1,25023,,,0,"Move aodh pip packages from constraints to requirements

Change-Id: I73773536938dff9f768381a333c5fa02c98e9d55
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/59/772259/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,405f551fad8e08b1610459f30baa4101b92d00fe,osa-new-pip," - ""git+{{ aodh_git_repo }}@{{ aodh_git_install_branch }}#egg=aodh"" - PyMySQL - sqlalchemy"," - ""git+{{ aodh_git_repo }}@{{ aodh_git_install_branch }}#egg=aodh"" # The following constraints are taken from the setup.cfg # file in the aodh project. This is due to the fact that the repo-build # role does not respect constraints specified in setup.cfg files. # https://github.com/openstack/aodh/blob/master/setup.cfg#L35-L38 - alembic>=0.7.2 - PyMySQL>=0.6.2 - sqlalchemy>=0.9.7",3,8
openstack%2Ftempest~master~Icff9d1b0be927c5d3aced4394b42867c553a4e97,openstack/tempest,master,Icff9d1b0be927c5d3aced4394b42867c553a4e97,Set the Nova availability zone different from volume az,ABANDONED,2021-02-01 19:46:17.000000000,2021-02-09 11:29:16.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-02-01 19:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/14bb7bcc43cbf827de406ae1884e397e0410e711', 'message': 'Nova AZ for non-scenario tests\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n'}, {'number': 2, 'created': '2021-02-01 19:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d3e4b8dc062beb736f2042cf3d61973be2b5e49b', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 3, 'created': '2021-02-01 20:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c36d9e13771ce0907d7be62770b2af0ce873b32', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 4, 'created': '2021-02-01 20:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e3329284a0cad0355e8421ceea5cd63ae1308d3', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It's common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 5, 'created': '2021-02-02 20:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4db946af2f3e6897818cb4d33b55b3d411521970', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 6, 'created': '2021-02-03 13:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/81c167746f5ab91edf28391d8d082f3f4b765c9a', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 7, 'created': '2021-02-04 13:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6497621e28f7a0ef98e91a61050c7d95b52ef4a', 'message': ""Set Nova availability zone for non-scenario tests\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. It common configuration\nfor the DCN environment.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}, {'number': 8, 'created': '2021-02-07 10:01:12.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/config.py', 'tempest/common/compute.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dacd6bd1f9bff151bd458a03ad6a8ada98abaa84', 'message': ""Set the Nova availability zone different from volume az\n\nThe review allows related non-scenario tests\nwhen Nova availability zone don't match the\nvolume availability zone. This configuration\nmight be used for the DCN compute-only environment\nwhen edge sites haven't storage.\n\nChange-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97\n""}]",5,773476,dacd6bd1f9bff151bd458a03ad6a8ada98abaa84,32,3,8,32876,,,0,"Set the Nova availability zone different from volume az

The review allows related non-scenario tests
when Nova availability zone don't match the
volume availability zone. This configuration
might be used for the DCN compute-only environment
when edge sites haven't storage.

Change-Id: Icff9d1b0be927c5d3aced4394b42867c553a4e97
",git fetch https://review.opendev.org/openstack/tempest refs/changes/76/773476/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/config.py', 'tempest/common/compute.py']",2,14bb7bcc43cbf827de406ae1884e397e0410e711,multiple_compute_az," if CONF.compute.compute_volume_common_az or CONF.compute.compute_az: if CONF.compute.compute_az: kwargs.setdefault('availability_zone', CONF.compute.compute_az) else: kwargs.setdefault('availability_zone',"," if CONF.compute.compute_volume_common_az: kwargs.setdefault('availability_zone',",13,2
openstack%2Foslo.policy~master~I2837959e8b03f98e8d947787d5c81569fe69acf6,openstack/oslo.policy,master,I2837959e8b03f98e8d947787d5c81569fe69acf6,remove unicode from code,MERGED,2021-01-03 08:20:31.000000000,2021-02-09 11:16:29.000000000,2021-02-09 11:13:53.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-03 08:20:31.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/ca3e551fc38825de5e49b9a9a7cb90b8ee17dbbf', 'message': 'remove unicode from code\n\nChange-Id: I2837959e8b03f98e8d947787d5c81569fe69acf6\n'}]",0,769016,ca3e551fc38825de5e49b9a9a7cb90b8ee17dbbf,11,2,1,30092,,,0,"remove unicode from code

Change-Id: I2837959e8b03f98e8d947787d5c81569fe69acf6
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/16/769016/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,ca3e551fc38825de5e49b9a9a7cb90b8ee17dbbf,,"copyright = '2016, oslo.policy Developers' 'oslo.policy Release Notes Documentation', 'oslo.policy Developers', 'manual'), 'oslo.policy Release Notes Documentation', ['oslo.policy Developers'], 1) 'oslo.policy Release Notes Documentation', 'oslo.policy Developers', 'oslo.policyReleaseNotes',","copyright = u'2016, oslo.policy Developers' u'oslo.policy Release Notes Documentation', u'oslo.policy Developers', 'manual'), u'oslo.policy Release Notes Documentation', [u'oslo.policy Developers'], 1) u'oslo.policy Release Notes Documentation', u'oslo.policy Developers', 'oslo.policyReleaseNotes',",8,8
openstack%2Fopenstack-ansible~master~Ie58167c4bc940eb5b5d2887421212eb2ce97fb8d,openstack/openstack-ansible,master,Ie58167c4bc940eb5b5d2887421212eb2ce97fb8d,Do not prepare upstream repos for distro jobs,MERGED,2021-02-07 08:30:57.000000000,2021-02-09 11:06:34.000000000,2021-02-09 10:57:41.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-07 08:30:57.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cf3f901c528f2c002cf0899e930d3018ab1b79b1', 'message': ""Do not prepare upstream repos for distro jobs\n\nSince we don't build from source, we don't need to clone and prepare\nupstream services' repos for distro jobs.\n\nChange-Id: Ie58167c4bc940eb5b5d2887421212eb2ce97fb8d\n""}]",0,774372,cf3f901c528f2c002cf0899e930d3018ab1b79b1,8,3,1,28619,,,0,"Do not prepare upstream repos for distro jobs

Since we don't build from source, we don't need to clone and prepare
upstream services' repos for distro jobs.

Change-Id: Ie58167c4bc940eb5b5d2887421212eb2ce97fb8d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/72/774372/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,cf3f901c528f2c002cf0899e930d3018ab1b79b1,, name: openstack-ansible-deploy Global parent for integrated OpenStack-Ansible tests pre-run: - zuul.d/playbooks/pre-gate-cleanup.yml - zuul.d/playbooks/pre-gate-scenario.yml - zuul.d/playbooks/pre-osa-aio.yml run: zuul.d/playbooks/run.yml post-run: - zuul.d/playbooks/post.yml timeout: 10800 irrelevant-files: - ^\.git.* - ^.*\.(example|md|rst)$ - ^deploy-guide/.* - ^doc/.* - ^releasenotes/.* - ^setup\.(cfg|py)$ - ^tox.ini$ - ^Vagrantfile - job: name: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy description: | Run integrated tests for an OpenStack-Ansible project. This should be used only for distro based tests. required-projects: # OSA repos - name: openstack/openstack-ansible - name: openstack/ansible-hardening - name: openstack/openstack-ansible-apt_package_pinning - name: openstack/ansible-config_template - name: openstack/openstack-ansible-galera_client - name: openstack/openstack-ansible-galera_server - name: openstack/openstack-ansible-ceph_client - name: openstack/openstack-ansible-haproxy_server - name: openstack/openstack-ansible-lxc_container_create - name: openstack/openstack-ansible-lxc_hosts - name: openstack/openstack-ansible-memcached_server - name: openstack/openstack-ansible-openstack_hosts - name: openstack/openstack-ansible-os_keystone - name: openstack/openstack-ansible-openstack_openrc - name: openstack/openstack-ansible-os_adjutant - name: openstack/openstack-ansible-os_aodh - name: openstack/openstack-ansible-os_barbican - name: openstack/openstack-ansible-os_blazar - name: openstack/openstack-ansible-os_ceilometer - name: openstack/openstack-ansible-os_cinder - name: openstack/openstack-ansible-os_designate - name: openstack/openstack-ansible-os_glance - name: openstack/openstack-ansible-os_gnocchi - name: openstack/openstack-ansible-os_heat - name: openstack/openstack-ansible-os_horizon - name: openstack/openstack-ansible-os_ironic - name: openstack/openstack-ansible-os_magnum - name: openstack/openstack-ansible-os_manila - name: openstack/openstack-ansible-os_masakari - name: openstack/openstack-ansible-os_mistral - name: openstack/openstack-ansible-os_murano - name: openstack/openstack-ansible-os_neutron - name: openstack/openstack-ansible-os_nova - name: openstack/openstack-ansible-os_octavia - name: openstack/openstack-ansible-os_panko - name: openstack/openstack-ansible-os_placement - name: openstack/openstack-ansible-os_rally - name: openstack/openstack-ansible-os_sahara - name: openstack/openstack-ansible-os_senlin - name: openstack/openstack-ansible-os_swift - name: openstack/openstack-ansible-os_tacker - name: openstack/openstack-ansible-os_tempest - name: openstack/openstack-ansible-os_trove - name: openstack/openstack-ansible-plugins - name: openstack/ansible-role-qdrouterd - name: openstack/openstack-ansible-rabbitmq_server - name: openstack/openstack-ansible-repo_server - name: openstack/openstack-ansible-rsyslog_client - name: openstack/openstack-ansible-rsyslog_server - name: openstack/openstack-ansible-nspawn_container_create - name: openstack/openstack-ansible-nspawn_hosts - name: openstack/ansible-role-systemd_service - name: openstack/ansible-role-systemd_mount - name: openstack/ansible-role-systemd_networkd - name: openstack/ansible-role-python_venv_build - name: openstack/ansible-role-uwsgi - job: name: openstack-ansible-deploy-aio parent: openstack-ansible-deploy description: | Run integrated tests for an OpenStack-Ansible project. This should be used only for source based tests. parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro parent: openstack-ansible-deploy-aio-distro," name: openstack-ansible-deploy-aio Run functional tests for an OpenStack-Ansible project. Uses the gate-check-commit.sh script, running a default aio deploy. pre-run: - zuul.d/playbooks/pre-gate-cleanup.yml - zuul.d/playbooks/pre-gate-scenario.yml - zuul.d/playbooks/pre-osa-aio.yml run: zuul.d/playbooks/run.yml post-run: - zuul.d/playbooks/post.yml timeout: 10800 irrelevant-files: - ^\.git.* - ^.*\.(example|md|rst)$ - ^deploy-guide/.* - ^doc/.* - ^releasenotes/.* - ^setup\.(cfg|py)$ - ^tox.ini$ - ^Vagrantfile parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio parent: openstack-ansible-deploy-aio",98,28
openstack%2Fopenstack-ansible-os_zun~master~Ia3782bf272a5970b6992d82e6732854af5e7a561,openstack/openstack-ansible-os_zun,master,Ia3782bf272a5970b6992d82e6732854af5e7a561,Move zun pip packages from constraints to requirements,MERGED,2021-01-25 10:39:47.000000000,2021-02-09 11:05:49.000000000,2021-02-09 10:45:55.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-25 10:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/5f6d16a8cb95a66abd41edb35075d9beb52157ed', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 2, 'created': '2021-01-25 18:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/c0c633e958c62cd127b99a830609419b1a4deed6', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 3, 'created': '2021-01-25 21:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/e156e502c1ee41d5e0712768e68d5aec0d1f640e', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 4, 'created': '2021-01-25 22:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/533adbfd2042b6453eb82093ca8b960b541a7345', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 5, 'created': '2021-01-26 08:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/9afc272e9d92ce03a9845879f57ff687b751814b', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 6, 'created': '2021-01-26 10:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/834f92466615922d1ebce19c0944e71e98613cef', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 7, 'created': '2021-01-28 16:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/0432db2153df3dde309a12e90cd8454882d2e223', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}, {'number': 8, 'created': '2021-02-07 19:39:47.000000000', 'files': ['tasks/main.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/fe94ff67b338428d486033ffadc070fbafbe78ec', 'message': 'Move zun pip packages from constraints to requirements\n\nThis is necessary to use the new pip resolver\n\nChange-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561\n'}]",0,772300,fe94ff67b338428d486033ffadc070fbafbe78ec,24,3,8,25023,,,0,"Move zun pip packages from constraints to requirements

This is necessary to use the new pip resolver

Change-Id: Ia3782bf272a5970b6992d82e6732854af5e7a561
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/00/772300/8 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,5f6d16a8cb95a66abd41edb35075d9beb52157ed,osa-new-pip," - ""git+{{ zun_git_repo }}@{{ zun_git_install_branch }}#egg=zun"" - ""git+{{ zun_kuryr_lib_git_repo }}@{{ zun_kuryr_lib_git_install_branch }}#egg=kuryr-lib"" - ""git+{{ zun_kuryr_git_repo }}@{{ zun_kuryr_git_install_branch }}#egg=kuryr-libnetwork"""," - ""git+{{ zun_git_repo }}@{{ zun_git_install_branch }}#egg=zun"" - ""git+{{ zun_kuryr_lib_git_repo }}@{{ zun_kuryr_lib_git_install_branch }}#egg=kuryr-lib"" - ""git+{{ zun_kuryr_git_repo }}@{{ zun_kuryr_git_install_branch }}#egg=kuryr-libnetwork"" - kuryr-libnetwork - zun",3,5
openstack%2Fironic-python-agent-builder~master~Ifcf9e165e750fd07b11e7bbc18cf9f912b211e23,openstack/ironic-python-agent-builder,master,Ifcf9e165e750fd07b11e7bbc18cf9f912b211e23,Upgrade pip to at least 19.1.1,MERGED,2021-02-08 15:04:39.000000000,2021-02-09 11:05:49.000000000,2021-02-09 10:45:43.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-08 15:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/67abbdfab920642952f33017c2678297af84b710', 'message': 'Upgrade pip to at least 19.1.1\n\nChange-Id: Ifcf9e165e750fd07b11e7bbc18cf9f912b211e23\n'}, {'number': 2, 'created': '2021-02-08 16:57:23.000000000', 'files': ['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/7e2ba37e4a52181c246305985805f320be1c3e03', 'message': 'Upgrade pip to at least 19.1.1\n\nChange-Id: Ifcf9e165e750fd07b11e7bbc18cf9f912b211e23\n'}]",0,774475,7e2ba37e4a52181c246305985805f320be1c3e03,10,3,2,10239,,,0,"Upgrade pip to at least 19.1.1

Change-Id: Ifcf9e165e750fd07b11e7bbc18cf9f912b211e23
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/75/774475/2 && git format-patch -1 --stdout FETCH_HEAD,['dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'],1,67abbdfab920642952f33017c2678297af84b710,gate,"# 19.1.1 is required for cryptography. REQUIRED_PIP_STR=""19.1.1"" REQUIRED_PIP_TUPLE=""(19, 1, 1)""HAS_PIP=$VENVDIR/bin/python -c \ ""import pip; print(tuple(map(int, pip.__version__.split('.'))) >= $REQUIRED_PIP_TUPLE)"" if [ $HAS_PIP == ""False"" ]; then # NOTE(dtantsur): use a fixed version to avoid breakages $VENVDIR/bin/pip install ""pip==$REQUIRED_PIP_STR"" fi","# pip might be an older version which does not support the -c option, therefore # upgrade it first. This is no-op when a new enough version is available. $VENVDIR/bin/pip install 'pip>=7.1'",9,3
openstack%2Foslo.policy~master~I51a7995b0ca372e494f8c620b6c541373614159a,openstack/oslo.policy,master,I51a7995b0ca372e494f8c620b6c541373614159a,Fix lower-constraints job,ABANDONED,2020-12-11 01:21:32.000000000,2021-02-09 10:58:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-11 01:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/2a238cfd086da6823d49eb79000feb9e3c9c363f', 'message': 'Fix lower-constraints job\n\nChange-Id: I51a7995b0ca372e494f8c620b6c541373614159a\n'}, {'number': 2, 'created': '2020-12-11 01:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/2eebde732e65dba49671ab120ea70e00f86d2eff', 'message': 'Fix lower-constraints job\n\nChange-Id: I51a7995b0ca372e494f8c620b6c541373614159a\n'}, {'number': 3, 'created': '2020-12-11 01:45:09.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/0b8892f20bc9d0af0b7cc0f8c6953f1c94de7e17', 'message': 'Fix lower-constraints job\n\nChange-Id: I51a7995b0ca372e494f8c620b6c541373614159a\n'}]",0,766646,0b8892f20bc9d0af0b7cc0f8c6953f1c94de7e17,8,1,3,8556,,,0,"Fix lower-constraints job

Change-Id: I51a7995b0ca372e494f8c620b6c541373614159a
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/46/766646/2 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,2a238cfd086da6823d49eb79000feb9e3c9c363f,fix-lc,bandit==1.6.0,bandit==1.4.0,1,1
openstack%2Ftempest~master~I73cd35e04d72a96d6a3c3f8e85a2754fe16eeef6,openstack/tempest,master,I73cd35e04d72a96d6a3c3f8e85a2754fe16eeef6,Adds additional exception handling to credential provider,ABANDONED,2016-07-13 14:51:26.000000000,2021-02-09 10:49:11.000000000,,"[{'_account_id': 97}, {'_account_id': 1921}, {'_account_id': 6754}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11139}, {'_account_id': 12393}, {'_account_id': 17716}, {'_account_id': 19587}, {'_account_id': 22219}]","[{'number': 1, 'created': '2016-07-13 14:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2564df877cf202368161f5f2b3e5c283c75e93d0', 'message': 'Adds additional exception handling to credential provider\n\nAdds additional handling to the PreProvisionedCredentialProvider\nto handle the case where the os-networks extension is not\nenabled.\n\nChange-Id: I73cd35e04d72a96d6a3c3f8e85a2754fe16eeef6\nCloses-Bug: 1600349\n'}, {'number': 2, 'created': '2016-07-14 16:08:27.000000000', 'files': ['tempest/common/preprov_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/df162b24aa64de1b04cf1933cfa87a0462513d34', 'message': 'Adds additional exception handling to credential provider\n\nAdds additional handling to the PreProvisionedCredentialProvider\nto handle the case where the os-networks extension is not\nenabled.\n\nChange-Id: I73cd35e04d72a96d6a3c3f8e85a2754fe16eeef6\nCloses-Bug: 1600349\n'}]",2,341592,df162b24aa64de1b04cf1933cfa87a0462513d34,24,10,2,97,,,0,"Adds additional exception handling to credential provider

Adds additional handling to the PreProvisionedCredentialProvider
to handle the case where the os-networks extension is not
enabled.

Change-Id: I73cd35e04d72a96d6a3c3f8e85a2754fe16eeef6
Closes-Bug: 1600349
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/341592/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/preprov_creds.py'],1,2564df877cf202368161f5f2b3e5c283c75e93d0,bug/1600349," except exceptions.InvalidTestResource, lib_exc.NotFound:", except exceptions.InvalidTestResource:,1,1
openstack%2Ftempest~master~I39105c47febd11da27945ad690437bd7d2142167,openstack/tempest,master,I39105c47febd11da27945ad690437bd7d2142167,Not delete an external network during tearDown,ABANDONED,2017-04-10 12:58:42.000000000,2021-02-09 10:48:30.000000000,,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 10385}, {'_account_id': 10608}, {'_account_id': 12033}, {'_account_id': 12297}, {'_account_id': 15941}, {'_account_id': 20190}]","[{'number': 1, 'created': '2017-04-10 12:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a8556aebc06fe3680b4b5a98225b962e12b9770', 'message': 'Not delete an external network during tearDown\n\nWhen finished the testcases in test_auto_allocate_network, the\nexternal network will be deleted in tearDown process, this will\nfail if any IP is allocated in the network before. Then the\nerror happens.\n\nChange-Id: I39105c47febd11da27945ad690437bd7d2142167\nCloses-Bug: #1677136\n'}, {'number': 2, 'created': '2017-04-10 13:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9fcf1014b546cc99f73dd1a9d922afa6cefc1bd7', 'message': 'Not delete an external network during tearDown\n\nWhen finished the testcases in test_auto_allocate_network, the\nexternal network will be deleted in tearDown process, this will\nfail if any IP is allocated in the network before. Then the\nerror happens.\n\nChange-Id: I39105c47febd11da27945ad690437bd7d2142167\nCloses-Bug: #1677136\n'}, {'number': 3, 'created': '2017-05-24 03:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d3e8a720cacd3e97cdd9fd150faf28c0522642c9', 'message': 'Not delete an external network during tearDown\n\nWhen finished the testcases in test_auto_allocate_network, the\nexternal network will be deleted in tearDown process, this will\nfail if any IP is allocated in the network before. Then the\nerror happens.\n\nChange-Id: I39105c47febd11da27945ad690437bd7d2142167\nCloses-Bug: #1677136\n'}, {'number': 4, 'created': '2017-05-24 03:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c4fb7d13ec6bd1ed507e1a76618b3491fd50aa2c', 'message': 'Not delete an external network during tearDown\n\nWhen finished the testcases in test_auto_allocate_network, the\nexternal network will be deleted in tearDown process, this will\nfail if any IP is allocated in the network before. Then the\nerror happens.\n\nChange-Id: I39105c47febd11da27945ad690437bd7d2142167\nCloses-Bug: #1677136\n'}, {'number': 5, 'created': '2017-06-14 07:30:55.000000000', 'files': ['tempest/api/compute/admin/test_auto_allocate_network.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/64e4a12326c1ff4ef80d8f506e3e811fa7138468', 'message': 'Not delete an external network during tearDown\n\nWhen finished the testcases in test_auto_allocate_network, an\nexternal network will be deleted in tearDown process, this will\nfail if any IP is allocated in the network before. Then the\nerror happens. This patch make only delete the network owned\nby the current tenant.\n\nChange-Id: I39105c47febd11da27945ad690437bd7d2142167\nCloses-Bug: #1677136\n'}]",2,455310,64e4a12326c1ff4ef80d8f506e3e811fa7138468,37,11,5,12297,,,0,"Not delete an external network during tearDown

When finished the testcases in test_auto_allocate_network, an
external network will be deleted in tearDown process, this will
fail if any IP is allocated in the network before. Then the
error happens. This patch make only delete the network owned
by the current tenant.

Change-Id: I39105c47febd11da27945ad690437bd7d2142167
Closes-Bug: #1677136
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/455310/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_auto_allocate_network.py'],1,8a8556aebc06fe3680b4b5a98225b962e12b9770,bug/1677136, if network['router:external'] == True: continue,,2,0
openstack%2Ftempest~master~Id2318e69708fc7457ca4980340b66a6bad3bc947,openstack/tempest,master,Id2318e69708fc7457ca4980340b66a6bad3bc947,Add verification of show_password to test_change_server_password,ABANDONED,2018-02-09 21:34:27.000000000,2021-02-09 10:47:58.000000000,,"[{'_account_id': 4690}, {'_account_id': 10385}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-02-09 21:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16585b0ea3386159b6db12a17cb5df21464cdf2a', 'message': ""Add verification of show_password to test_change_server_password\n\nWe have a bug in nova where the password is not saved to the metadata\nwhen the server's password is changed via the API. This adds\nverification of the fix and will help catch regressions in the future.\n\nRelated-Bug: #1748544\n\nChange-Id: Id2318e69708fc7457ca4980340b66a6bad3bc947\n""}, {'number': 2, 'created': '2018-02-10 00:45:03.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c3db6a102b2aefb70dddcb918b5582fbe14b3753', 'message': ""Add verification of show_password to test_change_server_password\n\nWe have a bug in nova where the password is not saved to the metadata\nwhen the server's password is changed via the API. This adds\nverification of the fix and will help catch regressions in the future.\n\nRelated-Bug: #1748544\n\nDepends-On: Id5ff7527a687bf285158a70022110863b48b8495\n\nChange-Id: Id2318e69708fc7457ca4980340b66a6bad3bc947\n""}]",2,543029,c3db6a102b2aefb70dddcb918b5582fbe14b3753,11,4,2,4690,,,0,"Add verification of show_password to test_change_server_password

We have a bug in nova where the password is not saved to the metadata
when the server's password is changed via the API. This adds
verification of the fix and will help catch regressions in the future.

Related-Bug: #1748544

Depends-On: Id5ff7527a687bf285158a70022110863b48b8495

Change-Id: Id2318e69708fc7457ca4980340b66a6bad3bc947
",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/543029/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_actions.py'],1,16585b0ea3386159b6db12a17cb5df21464cdf2a,bug/1748544, # Verify we can show the password afterward resp = self.client.show_password(newserver['id']) # Verify the returned encrypted password is not empty self.assertTrue(resp['password']) ,,5,0
openstack%2Ftempest~master~Icd1c0fe5c42738faf37302752fb3b7495efcf416,openstack/tempest,master,Icd1c0fe5c42738faf37302752fb3b7495efcf416,Remove deprecated AMI image file opts,ABANDONED,2016-07-06 16:09:43.000000000,2021-02-09 10:45:45.000000000,,"[{'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9152}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 17716}, {'_account_id': 17920}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2016-07-06 16:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c257c06ccdbf868b69a0ca72c9ec49bf4fe77dd1', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 2, 'created': '2016-07-26 19:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb669df7ab974524ec4572e87dbc9097b2d6fe22', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 3, 'created': '2016-12-21 18:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f7a23d34b3d7149090ba3e98f92dbd4b518d361', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 4, 'created': '2017-02-15 16:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9c5ca6883fc04f62943ad895f7a728f094fd4cfe', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nDepends-On: I6f59dad3a4acb1f993b608ce80df86f763a63f3a\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 5, 'created': '2017-07-31 14:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/29d6b312ea227038120c56680351bdbd5ff93e29', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nDepends-On: I6f59dad3a4acb1f993b608ce80df86f763a63f3a\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 6, 'created': '2018-01-04 16:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e4a9db01331b87b30ce9212dfe39b292e6d13ba', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 7, 'created': '2018-01-04 19:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/76bde22c16412739df7f2a8a715a5227e326aed0', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Id65ebae73b28da7185cb349b714b659af51ef77f\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}, {'number': 8, 'created': '2018-01-04 21:48:46.000000000', 'files': ['tempest/scenario/manager.py', 'doc/source/configuration.rst', 'tempest/config.py', 'releasenotes/notes/remove-deprecated-amazon-img-opts-c9af0faa3481f158.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e20f3367f2d77c1bb3cab2df1fd375ea03807927', 'message': 'Remove deprecated AMI image file opts\n\nThis commit removes the deprecated config options for specifying AMI\nimage file locations. These options were deprecated in change\nI8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using\nthese options is also removed, and the docs are updated to not mention\nthem anymore.\n\nDepends-On: Ic276cbbb91aaf73ba44e588a607338b93d056da8\nChange-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416\nCloses-Bug: #1393881\n'}]",6,338377,e20f3367f2d77c1bb3cab2df1fd375ea03807927,63,12,8,5196,,,0,"Remove deprecated AMI image file opts

This commit removes the deprecated config options for specifying AMI
image file locations. These options were deprecated in change
I8a6ee167384c8a2d17905db3a4061c06398980ad. The fallback mechanism using
these options is also removed, and the docs are updated to not mention
them anymore.

Depends-On: Ic276cbbb91aaf73ba44e588a607338b93d056da8
Change-Id: Icd1c0fe5c42738faf37302752fb3b7495efcf416
Closes-Bug: #1393881
",git fetch https://review.opendev.org/openstack/tempest refs/changes/77/338377/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'doc/source/configuration.rst', 'tempest/config.py', 'releasenotes/notes/remove-deprecated-amazon-img-opts-c9af0faa3481f158.yaml']",4,c257c06ccdbf868b69a0ca72c9ec49bf4fe77dd1,bug/1393881,"--- upgrade: - The deprecated options to specify image files in the AMI triplet format are removed. The fallback mechanism to use these if the regular image upload file can't be found is removed, you must now specify a correct image file for the scenario tests which upload an image to work correctly. ",,17,43
openstack%2Ftempest~master~I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98,openstack/tempest,master,I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98,Add test for glance's tasks API,ABANDONED,2015-08-25 11:14:37.000000000,2021-02-09 10:44:03.000000000,,"[{'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8871}, {'_account_id': 9303}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 10485}, {'_account_id': 11075}, {'_account_id': 12017}]","[{'number': 1, 'created': '2015-08-25 11:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e3ba74d232d34ccb1c48f936eb34c96da6be40cc', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 2, 'created': '2015-10-19 12:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/173d7d0321a83b967fc847aed62c93b7fe9745e3', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 3, 'created': '2015-11-02 10:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/399374e3f81e5fed4b45663a4f2608d35c987600', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 4, 'created': '2015-11-05 10:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c22dffc8dea6db26ee5368de6762f12c8c53a82', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 5, 'created': '2015-11-17 06:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/53b63923d2959882e7d0d1d1c7b815c6f740423b', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 6, 'created': '2015-12-03 13:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a745c352a9d59374b136725407bd0e1625b6e7bb', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 7, 'created': '2015-12-04 13:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3b69556863b1121a12dde2168392813b9f864f33', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCo-Authored-By: Ankit Agrawal <ankit11.agrawal@nttdata.com>\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}, {'number': 8, 'created': '2015-12-04 17:55:40.000000000', 'files': ['tempest/services/image/v2/json/images_client.py', 'tempest/common/waiters.py', 'tempest/exceptions.py', 'tempest/api/image/v2/test_images_tasks.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/47aaadad43c06c2e851b24b3da090a74b031cfba', 'message': ""Add test for glance's tasks API\n\nAdded new test for below glance's tasks APIs,\n\n1. Create task\n2. List task\n3. Get task\n\nCloses-Bug: #1484511\nChange-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98\n""}]",17,216665,47aaadad43c06c2e851b24b3da090a74b031cfba,80,10,8,10300,,,0,"Add test for glance's tasks API

Added new test for below glance's tasks APIs,

1. Create task
2. List task
3. Get task

Closes-Bug: #1484511
Change-Id: I3d40bde5c71447c91e5f6e63de6d5b355e6c5f98
",git fetch https://review.opendev.org/openstack/tempest refs/changes/65/216665/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/image/v2/json/image_client.py', 'tempest/api/image/base.py', 'tempest/common/waiters.py', 'tempest/exceptions.py', 'tempest/api/image/v2/test_images_tasks.py']",5,e3ba74d232d34ccb1c48f936eb34c96da6be40cc,bug/1484511,"# Copyright 2015 OpenStack Foundation # Copyright 2015 NTT DATA. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.image import base from tempest.common.utils import data_utils from tempest.common import waiters from tempest import test class BasicOperationsTaskImportTest(base.BaseV2ImageTest): """"""Here we test the basic operations of tasks"""""" @test.idempotent_id('c1a24094-333f-418a-af43-21825f7ea1c3') def test_create_image_from_task(self): url = ""http://example.com"" image_name = data_utils.rand_name('image') body = self.client.create_task(name=image_name, container_format='bare', disk_format='raw', url=url) waiters.wait_for_task_status(self.client, body['id'], 'success') # Verify image is created correctly by above task params = {""name"": image_name} images_list = self.client.list_images(params=params)['images'] self.assertEqual(1, len(images_list)) image_id = images_list[0]['id'] self.assertEqual('active', images_list[0]['status']) self.addCleanup(self.client.delete_image, image_id) # Verify task is created correctly task_id = body['id'] task = self.client.get_task(task_id) self.assertEqual(task_id, task['id']) self.assertEqual('success', task['status']) # Now check if created task is in the fetched tasks list resp = self.client.list_tasks() tasks_list = map(lambda task: task['id'], resp['tasks']) self.assertIn(task_id, tasks_list) ",,131,0
openstack%2Ftempest~master~I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff,openstack/tempest,master,I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff,Fix cases regarding to DHCP port operation.,ABANDONED,2015-09-14 06:54:54.000000000,2021-02-09 10:41:38.000000000,,"[{'_account_id': 748}, {'_account_id': 6854}, {'_account_id': 9569}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 17958}]","[{'number': 1, 'created': '2015-09-14 06:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/985e377449e3b8231ad9e38fe1ddea3371195d0d', 'message': 'Fix cases regarding to DHCP port operation.\n\nWhen number of dhcp ports excess max_fixed_ips_per_port, a dhcp resync will be triggered.\nDHCP port is not a tenant port. It means DHCP port is not a tenant resource.\nSo that - We should not restrict operations regarding DHCP port with admin user.\n        - Operations of DHCP port from non-admin user should be forbidden.\n\nChange-Id: I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff\nCloses-Bug: #1427015\n'}, {'number': 2, 'created': '2015-09-24 10:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cb7b20ecf4249df582b90d9f8dc4448138753626', 'message': 'Fix cases regarding to DHCP port operation.\n\nWhen number of dhcp ports excess max_fixed_ips_per_port, a dhcp resync will be triggered.\nDHCP port is not a tenant port. It means DHCP port is not a tenant resource.\nSo that - We should not restrict operations regarding DHCP port with admin user.\n        - Operations of DHCP port from non-admin user should be forbidden.\n\nChange-Id: I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff\nCloses-Bug: #1427015\nDepends-On: Iaa9ed6949383ba6a7ce0b3ffd9dcced663126317\n'}, {'number': 3, 'created': '2015-09-30 11:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/56cd57281e26dabc364dd16c0bd282a65e0e6d50', 'message': 'Fix cases regarding to DHCP port operation.\n\nWhen number of dhcp ports excess max_fixed_ips_per_port, a dhcp resync will be triggered.\nDHCP port is not a tenant port. It means DHCP port is not a tenant resource.\nSo that - We should not restrict operations regarding DHCP port with admin user.\n        - Operations of DHCP port from non-admin user should be forbidden.\n\nChange-Id: I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff\nCloses-Bug: #1427015\nDepends-On: Iaa9ed6949383ba6a7ce0b3ffd9dcced663126317\n'}, {'number': 4, 'created': '2015-10-02 09:16:11.000000000', 'files': ['tempest/api/network/test_ports.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c087c06c4cdae350683cd01a85039a18dc5164e0', 'message': 'Fix cases regarding to DHCP port operation.\n\nWhen number of dhcp ports excess max_fixed_ips_per_port, a dhcp resync will be triggered.\nDHCP port is not a tenant port. It means DHCP port is not a tenant resource.\nSo that - We should not restrict operations regarding DHCP port with admin user.\n        - Operations of DHCP port from non-admin user should be forbidden.\n\nChange-Id: I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff\nCloses-Bug: #1427015\nDepends-On: Iaa9ed6949383ba6a7ce0b3ffd9dcced663126317\n'}]",1,222982,c087c06c4cdae350683cd01a85039a18dc5164e0,30,6,4,17958,,,0,"Fix cases regarding to DHCP port operation.

When number of dhcp ports excess max_fixed_ips_per_port, a dhcp resync will be triggered.
DHCP port is not a tenant port. It means DHCP port is not a tenant resource.
So that - We should not restrict operations regarding DHCP port with admin user.
        - Operations of DHCP port from non-admin user should be forbidden.

Change-Id: I3fc3d3f37faf04ea8bfe720019a758326cf6b8ff
Closes-Bug: #1427015
Depends-On: Iaa9ed6949383ba6a7ce0b3ffd9dcced663126317
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/222982/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_networks.py', 'tempest/api/network/test_ports.py', 'tempest/api/network/test_dhcp_ipv6.py']",3,985e377449e3b8231ad9e38fe1ddea3371195d0d,bug/1427015,"import testtools if port['device_owner'] == 'network:dhcp': with testtools.ExpectedException(lib_exc.BadRequest): self.client.delete_port(port['id']) if subnet['enable_dhcp'] is True: with testtools.ExpectedException(lib_exc.BadRequest): self.client.delete_subnet(subnet['id']) else: self.client.delete_subnet(subnet['id']) self._remove_from_list_by_index(self.subnets, subnet)"," self.client.delete_subnet(subnet['id']) self._remove_from_list_by_index(self.subnets, subnet)",79,23
openstack%2Ftempest~master~I5b5849779a5fa5a6422cdeeb704131c292bd64a7,openstack/tempest,master,I5b5849779a5fa5a6422cdeeb704131c292bd64a7,Fixed bug with url building,ABANDONED,2016-02-14 07:45:19.000000000,2021-02-09 10:39:45.000000000,,"[{'_account_id': 8871}, {'_account_id': 9569}, {'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 10385}, {'_account_id': 20354}]","[{'number': 1, 'created': '2016-02-14 07:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e05d2a68cd94cf5d0a9c1ac0d755fe2a0c228c7', 'message': ""Fixed bug with url building\n\nThe requested volume ID contains the hash tag, which makes the request\nURL contain a 'fragment identifier'.\nSome backend WSGI servers might cut this part and pass it in a different\nenvironment variable.\nConceptually this is a bad practice.\n\nRemoving the hash tag from volume get, and volume delete.\n\nChange-Id: I5b5849779a5fa5a6422cdeeb704131c292bd64a7\n""}, {'number': 2, 'created': '2016-02-14 09:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/47ee93b3cdeaf83e11fbf591fd0b0f5c74d4b6e6', 'message': ""Fixed bug with url building\n\nThe requested volume ID contains the hash tag, which makes the request\nURL contain a 'fragment identifier'.\nSome backend WSGI servers might cut this part and pass it in a different\nenvironment variable.\nConceptually this is a bad practice.\n\nRemoving the hash tag from volume get, and volume delete.\n\nChange-Id: I5b5849779a5fa5a6422cdeeb704131c292bd64a7\nCloses-bug: 1545407\n""}, {'number': 3, 'created': '2016-02-29 08:42:08.000000000', 'files': ['tempest/api/compute/volumes/test_volumes_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a73eb55bd613e050403c264ec90122dde5b7dcd', 'message': ""Fixed bug with url building\n\nThe requested volume ID contains special characters such as hash '#' or precent '%'.\n\nThe hash tag makes the request URL contain a 'fragment identifier'.\nSome backend WSGI servers might cut this part and pass it in a different\nenvironment variable.\nConceptually this is a bad practice.\n\nRegarding with RFC3986 percent character '%' must be followed by the two\nhexadecimal digits. In other cases WSGI server can reject such request.\n\nReplacing special characters in volume get, and volume delete with numerical characters.\n\nChange-Id: I5b5849779a5fa5a6422cdeeb704131c292bd64a7\nCloses-bug: 1545407\n""}]",4,279932,7a73eb55bd613e050403c264ec90122dde5b7dcd,24,6,3,20424,,,0,"Fixed bug with url building

The requested volume ID contains special characters such as hash '#' or precent '%'.

The hash tag makes the request URL contain a 'fragment identifier'.
Some backend WSGI servers might cut this part and pass it in a different
environment variable.
Conceptually this is a bad practice.

Regarding with RFC3986 percent character '%' must be followed by the two
hexadecimal digits. In other cases WSGI server can reject such request.

Replacing special characters in volume get, and volume delete with numerical characters.

Change-Id: I5b5849779a5fa5a6422cdeeb704131c292bd64a7
Closes-bug: 1545407
",git fetch https://review.opendev.org/openstack/tempest refs/changes/32/279932/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/volumes/test_volumes_negative.py'],1,5e05d2a68cd94cf5d0a9c1ac0d755fe2a0c228c7,bug/1545407," self.client.show_volume, '$%%&^&^') self.client.delete_volume, '!@$%^&*()')"," self.client.show_volume, '#$%%&^&^') self.client.delete_volume, '!@#$%^&*()')",2,2
openstack%2Ftempest~master~I319e154887566888ac350935fd8529177aa90e90,openstack/tempest,master,I319e154887566888ac350935fd8529177aa90e90,remove order dependency for assert,ABANDONED,2016-06-21 04:29:46.000000000,2021-02-09 10:39:06.000000000,,"[{'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15696}]","[{'number': 1, 'created': '2016-06-21 04:29:46.000000000', 'files': ['tempest/api/network/test_allowed_address_pair.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e99ac01fd869352cbe657976b38d6b1722ff3a7e', 'message': ""remove order dependency for assert\n\nSince the order in which we receive the allowed address pair doesn't matter,\nremoving the order dependency in _update_port_with_address method.\n\nChange-Id: I319e154887566888ac350935fd8529177aa90e90\nCloses-Bug: 1594633\n""}]",0,331935,e99ac01fd869352cbe657976b38d6b1722ff3a7e,8,4,1,15696,,,0,"remove order dependency for assert

Since the order in which we receive the allowed address pair doesn't matter,
removing the order dependency in _update_port_with_address method.

Change-Id: I319e154887566888ac350935fd8529177aa90e90
Closes-Bug: 1594633
",git fetch https://review.opendev.org/openstack/tempest refs/changes/35/331935/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_allowed_address_pair.py'],1,e99ac01fd869352cbe657976b38d6b1722ff3a7e,bug/1594633," self.assertEqual(sorted(allowed_address_pair), sorted(allowed_address_pairs))"," self.assertEqual(allowed_address_pair, allowed_address_pairs)",1,1
openstack%2Ftempest~master~Ia76b7234e0ffce1b00fcc549f12054f84acc36e4,openstack/tempest,master,Ia76b7234e0ffce1b00fcc549f12054f84acc36e4,Add test to verify ironic multitenancy,ABANDONED,2015-12-17 10:35:58.000000000,2021-02-09 10:37:33.000000000,,"[{'_account_id': 2889}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-12-17 10:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b084defa6690fa3c6617ddaaf268725361a22e0', 'message': '[WIP] Add test to verify ironic multitenancy\n\n* Create two tenants with own networks.\n* Boot 2 baremetal instances in the same tenant and\n  check if they are L2-connected.\n* Boot 2 baremetal instance in the different tenants\n  and check if they are L2-isolated.\n\nChange-Id: Ia76b7234e0ffce1b00fcc549f12054f84acc36e4\nCloses-Bug: 1520230\nDepends-On: Iaa787d6f0b643affd4c4666f654a5f7d8b37d2a3\n'}, {'number': 2, 'created': '2015-12-17 10:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a88ffb7080730c7c096303de30cacf1f202f1810', 'message': '[WIP] Add test to verify ironic multitenancy\n\n* Create two tenants with own networks.\n* Boot 2 baremetal instances in the same tenant and\n  check if they are L2-connected.\n* Boot 2 baremetal instance in the different tenants\n  and check if they are L2-isolated.\n\nChange-Id: Ia76b7234e0ffce1b00fcc549f12054f84acc36e4\nCloses-Bug: 1520230\nDepends-On: Iaa787d6f0b643affd4c4666f654a5f7d8b37d2a3\n'}, {'number': 3, 'created': '2015-12-21 13:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1ad9b75f6b5d116dbbafaf585de2a643c32e33ac', 'message': 'Add test to verify ironic multitenancy\n\n* Create two tenants with own networks.\n* Boot 2 baremetal instances in the same network of\n  the first tenant and check if they are L2-connected.\n* Boot 2 baremetal instances in the different tenants\n  and check if they are L2-isolated.\n\nChange-Id: Ia76b7234e0ffce1b00fcc549f12054f84acc36e4\nCloses-Bug: 1520230\nDepends-On: Iaa787d6f0b643affd4c4666f654a5f7d8b37d2a3\n'}, {'number': 4, 'created': '2015-12-21 15:26:23.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/scenario/test_baremetal_multitenancy.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e7b0583444936fe27f0e1b2aaa8a995bcf1de31e', 'message': 'Add test to verify ironic multitenancy\n\n* Create two tenants with own networks.\n* Boot 2 baremetal instances in the same network of\n  the first tenant and check if they are L2-connected.\n* Boot 2 baremetal instances in the different tenants\n  and check if they are L2-isolated.\n\nChange-Id: Ia76b7234e0ffce1b00fcc549f12054f84acc36e4\nCloses-Bug: 1520230\nDepends-On: Iaa787d6f0b643affd4c4666f654a5f7d8b37d2a3\n'}]",0,258934,e7b0583444936fe27f0e1b2aaa8a995bcf1de31e,15,4,4,9068,,,0,"Add test to verify ironic multitenancy

* Create two tenants with own networks.
* Boot 2 baremetal instances in the same network of
  the first tenant and check if they are L2-connected.
* Boot 2 baremetal instances in the different tenants
  and check if they are L2-isolated.

Change-Id: Ia76b7234e0ffce1b00fcc549f12054f84acc36e4
Closes-Bug: 1520230
Depends-On: Iaa787d6f0b643affd4c4666f654a5f7d8b37d2a3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/258934/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_baremetal_basic_ops.py']",2,6b084defa6690fa3c6617ddaaf268725361a22e0,bug/1520230," self.instance, _ = self.boot_instance()", self.boot_instance(),47,17
openstack%2Ftempest~master~I6d8558667e561d77360e2d8043f57acc88594ce6,openstack/tempest,master,I6d8558667e561d77360e2d8043f57acc88594ce6,Add limit and detail optional cases for node list,ABANDONED,2015-01-29 03:23:16.000000000,2021-02-09 10:36:37.000000000,,"[{'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 8106}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 14810}]","[{'number': 1, 'created': '2015-01-29 03:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/04040791a37f842be4a4b48d018761bc3aa7f6a6', 'message': 'Add limit and detail optional cases for node list\n\nAdd limit and detail optional test cases for\nironic node list api.\n\nChange-Id: I6d8558667e561d77360e2d8043f57acc88594ce6\nCloses-Bug: #1415341\n'}, {'number': 2, 'created': '2015-02-04 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/111dd0ae2fabd4a992bc1cd25521093443bb8f03', 'message': 'Add limit and detail optional cases for node list\n\nAdd limit and detail optional test cases for\nironic node list api.\n\nChange-Id: I6d8558667e561d77360e2d8043f57acc88594ce6\nCloses-Bug: #1415341\n'}, {'number': 3, 'created': '2015-02-12 07:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/eb849c5f6a82b6a9967f04e59a963081afdf408a', 'message': 'Add limit and detail optional cases for node list\n\nAdd limit and detail optional test cases for\nironic node list api.\n\nChange-Id: I6d8558667e561d77360e2d8043f57acc88594ce6\nCloses-Bug: #1415341\n'}, {'number': 4, 'created': '2015-02-12 09:11:11.000000000', 'files': ['tempest/api/baremetal/admin/test_nodes.py', 'tempest/services/baremetal/v1/json/baremetal_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cbabf8636cde2bcd46d131794c28e92dd040b282', 'message': 'Add limit and detail optional cases for node list\n\nAdd limit and detail optional test cases for\nironic node list api.\n\nChange-Id: I6d8558667e561d77360e2d8043f57acc88594ce6\nCloses-Bug: #1415341\n'}]",11,151082,cbabf8636cde2bcd46d131794c28e92dd040b282,28,6,4,14810,,,0,"Add limit and detail optional cases for node list

Add limit and detail optional test cases for
ironic node list api.

Change-Id: I6d8558667e561d77360e2d8043f57acc88594ce6
Closes-Bug: #1415341
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/151082/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/baremetal/admin/test_nodes.py', 'tempest/services/baremetal/v1/base_v1.py']",2,04040791a37f842be4a4b48d018761bc3aa7f6a6,bug1415341," def list_nodes_detail(self, **kwargs): """"""Details list all existing nodes."""""" return self._list_request('/nodes/detail', **kwargs) @base.handle_errors",,46,0
openstack%2Ftempest~master~Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a,openstack/tempest,master,Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a,tempest_roles now used as default roles for preprov_creds.,ABANDONED,2016-04-06 15:51:32.000000000,2021-02-09 10:33:34.000000000,,"[{'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 9152}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12393}, {'_account_id': 14394}]","[{'number': 1, 'created': '2016-04-06 15:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1bc7d56fe354c29916bfd7b937e9f20935eea45e', 'message': 'Add config option identity/member_role\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}, {'number': 2, 'created': '2016-04-06 16:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8a79de986685d610e5b342de2508676c6668ef3b', 'message': 'Add config option identity/member_role\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}, {'number': 3, 'created': '2016-04-06 22:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a7b3a5b95c26de1adab7c75b77ea8861433f6f57', 'message': 'Add config option identity/member_role\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}, {'number': 4, 'created': '2016-04-07 10:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f53f1e3540e2f9b0cdf753879c9e6e990e12480c', 'message': 'Add config option identity/member_role\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}, {'number': 5, 'created': '2016-05-24 11:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e23117cd0e77a7ddecaad84b80326c804ca11a2d', 'message': 'Add config option identity/member_role\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}, {'number': 6, 'created': '2016-05-24 15:40:38.000000000', 'files': ['tempest/tests/common/test_preprov_creds.py', 'doc/source/configuration.rst', 'tempest/common/preprov_creds.py', 'tempest/config.py', 'tempest/common/credentials_factory.py', 'tempest/tests/common/test_dynamic_creds.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a018ecbc8c69cf0d324792c3aef124f70e64c8d1', 'message': 'tempest_roles now used as default roles for preprov_creds.\n\nAllows preprov_creds to request primary and alt accounts using\na named role, rather than simply any non-admin account if a test\ndoes not explicitly request a set of roles.\n\nChange-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a\nCloses-Bug: 1565584\n'}]",3,302332,a018ecbc8c69cf0d324792c3aef124f70e64c8d1,35,7,6,14394,,,0,"tempest_roles now used as default roles for preprov_creds.

Allows preprov_creds to request primary and alt accounts using
a named role, rather than simply any non-admin account if a test
does not explicitly request a set of roles.

Change-Id: Ia8d4b18192e09c6abf95bd0fe5a34d640b66336a
Closes-Bug: 1565584
",git fetch https://review.opendev.org/openstack/tempest refs/changes/32/302332/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/preprov_creds.py', 'tempest/config.py', 'tempest/common/credentials_factory.py']",3,1bc7d56fe354c29916bfd7b937e9f20935eea45e,bug/1565584," ('object_storage_reseller_admin_role', reseller_admin_role), ('member_role', CONF.identity.member_role)"," ('object_storage_reseller_admin_role', reseller_admin_role)",13,4
openstack%2Ftempest~master~I894ed29bd0a7d134c0619c05585b03e1ef228cf2,openstack/tempest,master,I894ed29bd0a7d134c0619c05585b03e1ef228cf2,[WIP] Fix a bug of default_domain_id,ABANDONED,2017-08-20 16:58:18.000000000,2021-02-09 10:32:15.000000000,,"[{'_account_id': 10385}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-08-20 16:58:18.000000000', 'files': ['tempest/lib/common/dynamic_creds.py', 'tempest/lib/common/cred_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/94e88bd4324e4f18b49d3a22da515b337961feff', 'message': '[WIP] Fix a bug of default_domain_id\n\nWhen I use tempest verify-config, the console show me a 404 error(\nI can not get the default domain). So I thought we need add the\ndefault_domain_id in create_project() and create_user().\n\nCloses-Bug: #1711891\n\nChange-Id: I894ed29bd0a7d134c0619c05585b03e1ef228cf2\n'}]",0,495569,94e88bd4324e4f18b49d3a22da515b337961feff,6,2,1,22960,,,0,"[WIP] Fix a bug of default_domain_id

When I use tempest verify-config, the console show me a 404 error(
I can not get the default domain). So I thought we need add the
default_domain_id in create_project() and create_user().

Closes-Bug: #1711891

Change-Id: I894ed29bd0a7d134c0619c05585b03e1ef228cf2
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/495569/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/common/dynamic_creds.py', 'tempest/lib/common/cred_client.py']",2,94e88bd4324e4f18b49d3a22da515b337961feff,bug_1711891," def create_user(self, username, password, project, email, domain_id): 'email': email, 'domain_id': domain_id}"," def create_user(self, username, password, project, email): 'email': email}",9,4
openstack%2Ftempest~master~If50b82a48e7449f41f8fb08f63232eb9a21c2cf5,openstack/tempest,master,If50b82a48e7449f41f8fb08f63232eb9a21c2cf5,Cut cinder backend name from host info,ABANDONED,2017-11-26 12:07:16.000000000,2021-02-09 10:30:14.000000000,,"[{'_account_id': 1736}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 15232}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2017-11-26 12:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/064f1b6ddbeea358e130a8fa056f96e46a144029', 'message': 'Cut cinder backend name from host info.\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 2, 'created': '2017-11-27 08:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e4a6c89bcb717ea403c76d3fd21b29e007d21f2', 'message': 'Cut cinder backend name from host info.\n\n bug: 1734636\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 3, 'created': '2017-11-29 10:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e88950867c8991810e2932aec50fda8f64e2087d', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 4, 'created': '2017-11-29 10:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c644fcd4b7e43f60479d04022c4bc16a0b55b142', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 5, 'created': '2017-11-29 10:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9aaf62024d5e91365982ae614dc1f7dd81e534fb', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 6, 'created': '2017-11-29 11:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/65897df37bfa80e2986cc124cc644f201bdf55b3', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 7, 'created': '2017-11-29 15:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b20c9239e4c80160a9da1c6170958a7f8c254632', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 8, 'created': '2017-12-01 09:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7599dbdc66786f27f87085fa74ef70a118b4e72b', 'message': 'Cut cinder backend name from host info\n\n Output of\n ""openstack volume show -f value -c os-vol-host-attr:host <volume>"" command\n includes backend name like ""<host name>#<backend name>"". We need to cut\n excess info.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n'}, {'number': 9, 'created': '2017-12-11 15:10:22.000000000', 'files': ['tempest/api/volume/admin/test_volume_services.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2e8768ac3e455cc611c17ecd87c9d28b76878317', 'message': ""Cut cinder backend name from host info\n\n  Cinder can have hostname with 'host@backend#pool' format where pool\n  info can be present on hostname string.\n  To handle all cases we need to extract the hostname string as per\n  above formatrmat.\n\nCloses-Bug: #1734636\nChange-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5\n""}]",11,522952,2e8768ac3e455cc611c17ecd87c9d28b76878317,37,9,9,15232,,,0,"Cut cinder backend name from host info

  Cinder can have hostname with 'host@backend#pool' format where pool
  info can be present on hostname string.
  To handle all cases we need to extract the hostname string as per
  above formatrmat.

Closes-Bug: #1734636
Change-Id: If50b82a48e7449f41f8fb08f63232eb9a21c2cf5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/522952/8 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/volume/admin/test_volume_services.py'],1,064f1b6ddbeea358e130a8fa056f96e46a144029,bug/1734636, host = host.split('#')[0],,1,0
openstack%2Ftempest~master~I56921d3a4a6c94fa3f0c4879079131e6f5da933c,openstack/tempest,master,I56921d3a4a6c94fa3f0c4879079131e6f5da933c,test_create_token support unspecified user fields,ABANDONED,2016-10-19 20:58:01.000000000,2021-02-09 10:28:12.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6486}, {'_account_id': 9152}, {'_account_id': 10385}, {'_account_id': 11022}, {'_account_id': 12017}, {'_account_id': 12393}]","[{'number': 1, 'created': '2016-10-19 20:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/957f2137e3e629886c12e4a28449efb63c87268a', 'message': ""test_create_token support unspecified user fields\n\nv2.test_tokens.TokensTest.test_create_token would fail if the\nuser ID (or other account field) wasn't specified in\naccounts.yaml because creds.user_id (for example) winds up\nbeing None whereas the ID in the token is whatever the server\nreturns and so doesn't match None.\n\nThe proposed fix is, if there's no creds.user_id (etc.)\nspecified in the accounts.yaml, then only require that it's in\nthe returned token and don't test the value.\n\nChange-Id: I56921d3a4a6c94fa3f0c4879079131e6f5da933c\nCloses-Bug: 1635043\n""}, {'number': 2, 'created': '2016-10-19 20:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a34c3688596484f62a9e15f6cb3a3e0afdabc0f3', 'message': ""test_create_token support unspecified user fields\n\nv2.test_tokens.TokensTest.test_create_token would fail if the\nuser ID (or other account field) wasn't specified in\naccounts.yaml because creds.user_id (for example) winds up\nbeing None whereas the ID in the token is whatever the server\nreturns and so doesn't match None.\n\nThe proposed fix is, if there's no creds.user_id (etc.)\nspecified in the accounts.yaml, then only require that it's in\nthe returned token and don't test the value.\n\nChange-Id: I56921d3a4a6c94fa3f0c4879079131e6f5da933c\nCloses-Bug: 1635043\n""}, {'number': 3, 'created': '2016-11-16 15:08:24.000000000', 'files': ['tempest/api/identity/v2/test_tokens.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c53063b1fea5b7c7a2c608d7d806be9d08a0ff24', 'message': ""test_create_token support unspecified user fields\n\nv2.test_tokens.TokensTest.test_create_token would fail if the\nuser ID (or other account field) wasn't specified in\naccounts.yaml because creds.user_id (for example) winds up\nbeing None whereas the ID in the token is whatever the server\nreturns and so doesn't match None.\n\nThe proposed fix is, if there's no creds.user_id (etc.)\nspecified in the accounts.yaml, then only require that it's in\nthe returned token and don't test the value.\n\nChange-Id: I56921d3a4a6c94fa3f0c4879079131e6f5da933c\nCloses-Bug: 1635043\n""}]",13,388897,c53063b1fea5b7c7a2c608d7d806be9d08a0ff24,20,8,3,6486,,,0,"test_create_token support unspecified user fields

v2.test_tokens.TokensTest.test_create_token would fail if the
user ID (or other account field) wasn't specified in
accounts.yaml because creds.user_id (for example) winds up
being None whereas the ID in the token is whatever the server
returns and so doesn't match None.

The proposed fix is, if there's no creds.user_id (etc.)
specified in the accounts.yaml, then only require that it's in
the returned token and don't test the value.

Change-Id: I56921d3a4a6c94fa3f0c4879079131e6f5da933c
Closes-Bug: 1635043
",git fetch https://review.opendev.org/openstack/tempest refs/changes/97/388897/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/v2/test_tokens.py'],1,957f2137e3e629886c12e4a28449efb63c87268a,bug/1635043," if creds.tenant_id: self.assertEqual(body['token']['tenant']['id'], creds.tenant_id) else: # Expect a project ID, but don't know what it will be. self.assertGreaterEqual(len(body['token']['tenant']['id']), 0, 'Expected tenant ID in token.') if tenant_name: self.assertEqual(body['token']['tenant']['name'], tenant_name) else: # Expect a project name, but don't know what it will be. self.assertGreaterEqual(len(body['token']['tenant']['name']), 0, 'Expected tenant name in token.') if creds.user_id: self.assertEqual(body['user']['id'], creds.user_id) else: # Expect a user ID, but don't know what it will be. self.assertGreaterEqual(len(body['user']['id']), 0, 'Expected user ID in token.') if username: self.assertEqual(body['user']['name'], username) else: # Expect a user name, but don't know what it will be. self.assertGreaterEqual(len(body['user']['name']), 0, 'Expected user name in token.')"," self.assertEqual(body['token']['tenant']['id'], creds.tenant_id) self.assertEqual(body['token']['tenant']['name'], tenant_name) self.assertEqual(body['user']['id'], creds.user_id)",26,6
openstack%2Fcinder~master~Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1,openstack/cinder,master,Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1,[Unity]: Fix failback issue of multiple volumes,NEW,2020-09-09 08:01:01.000000000,2021-02-09 10:11:08.000000000,,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10379}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26114}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 31980}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-09-09 08:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a460826d5035119852cc9b1014bbb041a32d9387', 'message': '[Unity]: Fix failback issue of multiple volumes\n\nFix bug 1894176 to make sure host could be failback\nsuccessfully if there is more than one volume enable\nreplication.\n\nChange-Id: Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1\nCloses-bug: #1894176\n'}, {'number': 2, 'created': '2020-09-24 06:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3161ae07d62982e32f436cf2671ca12336e9883e', 'message': '[Unity]: Fix failback issue of multiple volumes\n\nFix bug 1894176 to make sure host could be failback\nsuccessfully if there is more than one volume enable\nreplication.\n\nChange-Id: Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1\nCloses-bug: #1894176\n'}, {'number': 3, 'created': '2020-09-24 07:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/823061cc1cbccfafd76dd51f82b7409d3b87334c', 'message': '[Unity]: Fix failback issue of multiple volumes\n\nFix bug 1894176 to make sure host could be failback\nsuccessfully if there is more than one volume enable\nreplication.\n\nChange-Id: Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1\nCloses-bug: #1894176\n'}, {'number': 4, 'created': '2020-11-16 02:55:40.000000000', 'files': ['cinder/tests/unit/volume/drivers/dell_emc/unity/test_adapter.py', 'cinder/volume/drivers/dell_emc/unity/adapter.py', 'releasenotes/notes/bug-1894176-dellemc-unity-fix-replication-issue-1894176-d6b78b540bc61997.yaml', 'cinder/volume/drivers/dell_emc/unity/driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a20bf68a490ed82526df15b0f816a517d4b8d76', 'message': '[Unity]: Fix failback issue of multiple volumes\n\nFix bug 1894176 to make sure host could be failback\nsuccessfully if there is more than one volume enable\nreplication.\n\nChange-Id: Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1\nCloses-bug: #1894176\n'}]",2,750590,9a20bf68a490ed82526df15b0f816a517d4b8d76,154,37,4,26114,,,0,"[Unity]: Fix failback issue of multiple volumes

Fix bug 1894176 to make sure host could be failback
successfully if there is more than one volume enable
replication.

Change-Id: Ib1acc8bcfcdd0d6fa92a91690dffea389fc73ba1
Closes-bug: #1894176
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/750590/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/dell_emc/unity/test_adapter.py', 'cinder/volume/drivers/dell_emc/unity/adapter.py', 'cinder/volume/drivers/dell_emc/unity/driver.py', 'releasenotes/notes/unity-fix-replication-issue-1894176-d6b78b540bc61997.yaml']",4,a460826d5035119852cc9b1014bbb041a32d9387,bug/1894176,--- fixes: - | Dell EMC Unity Driver: Make sure host could be failback successfully if there is more than one volume enable replication. ,,187,19
openstack%2Ftacker~master~I825a60ac2261c8d47ca4273318f51221be36bb9e,openstack/tacker,master,I825a60ac2261c8d47ca4273318f51221be36bb9e,Increase timeout value of heat stack creation,MERGED,2021-02-08 03:53:30.000000000,2021-02-09 10:05:39.000000000,2021-02-09 09:45:36.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 26588}, {'_account_id': 32102}]","[{'number': 1, 'created': '2021-02-08 03:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6add91200721d7b281dc5f1425452e275852f582', 'message': '[WIP] test: Increase timeout value of instantiate\n\nSometimes tacker-functional-devstack-multinode-sol-separated-nfvo\nfails because of timeout of instantiate-vnf.\n\nThis patch increases timeout value of instantiate.\n\nChange-Id: I825a60ac2261c8d47ca4273318f51221be36bb9e\n'}, {'number': 2, 'created': '2021-02-08 22:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/a42c80fc109155039002d6f29558df3d38ae9d77', 'message': '[WIP] test: Increase timeout value of instantiate\n\nSometimes tacker-functional-devstack-multinode-sol-separated-nfvo\nfails because of timeout of instantiate-vnf.\n\nThis patch increases timeout value of instantiate.\n\nChange-Id: I825a60ac2261c8d47ca4273318f51221be36bb9e\n'}, {'number': 3, 'created': '2021-02-09 02:35:13.000000000', 'files': ['tacker/tests/functional/sol/vnflcm/base.py', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/06b58b9e004756013e23830f7a7219f8e868c751', 'message': 'Increase timeout value of heat stack creation\n\nSometimes tacker-functional-devstack-multinode-sol-separated-nfvo\nfails because of timeout of heat stack creation.\n\nThis patch increases timeout value of heat stack creation.\n\nChange-Id: I825a60ac2261c8d47ca4273318f51221be36bb9e\n'}]",1,774388,06b58b9e004756013e23830f7a7219f8e868c751,16,6,3,4149,,,0,"Increase timeout value of heat stack creation

Sometimes tacker-functional-devstack-multinode-sol-separated-nfvo
fails because of timeout of heat stack creation.

This patch increases timeout value of heat stack creation.

Change-Id: I825a60ac2261c8d47ca4273318f51221be36bb9e
",git fetch https://review.opendev.org/openstack/tacker refs/changes/88/774388/2 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/sol/vnflcm/base.py', 'tacker/vnfm/infra_drivers/openstack/openstack.py']",2,6add91200721d7b281dc5f1425452e275852f582,ft-sol-separate," default=120,"," default=60,",2,2
openstack%2Ftempest~master~Ie0569b84dd1c397a79d13af609bf23db52a2dfc8,openstack/tempest,master,Ie0569b84dd1c397a79d13af609bf23db52a2dfc8,Make import wait check for store status,MERGED,2021-02-05 20:11:38.000000000,2021-02-09 09:46:08.000000000,2021-02-09 09:23:57.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-02-05 20:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/afe2bb33b7cc68a07bd3846f70513cf7304c8d84', 'message': 'Make import wait check for store status\n\nDuring a glance import, if we fail, we are not going to change the\nstate of the image in all cases, and definitely not to \'active\'.\nThus waiting for active just means we keep polling a broken image\nfor a long time, wasting resources. We should also be checking the\nlist of failed stores, and if something pops in there, abort right\nthen and there.\n\nThis adds that different poll loop for the basic import tests of\nweb-download and glance-direct.\n\nNote that I\'m doing this because sometimes web-download fails in the\ngate due to a timeout trying to pull our http_image and we just keep\nlooping until our own timeout instead of noticing. It also means\nwe just report ""never reached active state"" instead of what we know\nto be true, which is that import failed.\n\nChange-Id: Ie0569b84dd1c397a79d13af609bf23db52a2dfc8\n'}, {'number': 2, 'created': '2021-02-05 20:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9fbab3a8c03527ce1aec40454c5c4840e541cdb3', 'message': 'Make import wait check for store status\n\nDuring a glance import, if we fail, we are not going to change the\nstate of the image in all cases, and definitely not to \'active\'.\nThus waiting for active just means we keep polling a broken image\nfor a long time, wasting resources. We should also be checking the\nlist of failed stores, and if something pops in there, abort right\nthen and there.\n\nThis adds that different poll loop for the basic import tests of\nweb-download and glance-direct.\n\nNote that I\'m doing this because sometimes web-download fails in the\ngate due to a timeout trying to pull our http_image and we just keep\nlooping until our own timeout instead of noticing. It also means\nwe just report ""never reached active state"" instead of what we know\nto be true, which is that import failed.\n\nChange-Id: Ie0569b84dd1c397a79d13af609bf23db52a2dfc8\n'}, {'number': 3, 'created': '2021-02-08 16:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9600a23d2ef8e7da79a3c3f949eb14dfd2bcca26', 'message': 'Make import wait check for store status\n\nDuring a glance import, if we fail, we are not going to change the\nstate of the image in all cases, and definitely not to \'active\'.\nThus waiting for active just means we keep polling a broken image\nfor a long time, wasting resources. We should also be checking the\nlist of failed stores, and if something pops in there, abort right\nthen and there.\n\nThis patch makes us use the wait_for_image_imported_to_stores()\nwaiter, and modifies it to not look at image[\'stores\'] if no\nstores are provided. In the case where we don\'t have multistore\nsupport enabled, we won\'t be able to know that the import failed\nuntil we time out, but otherwise we will (barring a glance bug for\nwhich I also have a fix).\n\nNote that I\'m doing this because sometimes web-download fails in the\ngate due to a timeout trying to pull our http_image and we just keep\nlooping until our own timeout instead of noticing. It also means\nwe just report ""never reached active state"" instead of what we know\nto be true, which is that import failed.\n\nChange-Id: Ie0569b84dd1c397a79d13af609bf23db52a2dfc8\n'}, {'number': 4, 'created': '2021-02-08 17:01:05.000000000', 'files': ['tempest/tests/common/test_waiters.py', 'tempest/api/image/v2/test_images.py', 'tempest/common/waiters.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ef8e054b6b53b393086deb43127195a48107220f', 'message': 'Make import wait check for store status\n\nDuring a glance import, if we fail, we are not going to change the\nstate of the image in all cases, and definitely not to \'active\'.\nThus waiting for active just means we keep polling a broken image\nfor a long time, wasting resources. We should also be checking the\nlist of failed stores, and if something pops in there, abort right\nthen and there.\n\nThis patch makes us use the wait_for_image_imported_to_stores()\nwaiter, and modifies it to not look at image[\'stores\'] if no\nstores are provided. In the case where we don\'t have multistore\nsupport enabled, we won\'t be able to know that the import failed\nuntil we time out, but otherwise we will (barring a glance bug for\nwhich I also have a fix). This also makes the waiter not fail on\nKeyError if os_glance_failed_import is not present on the image,\nas would be the case if used when stores are not enabled.\n\nNote that I\'m doing this because sometimes web-download fails in the\ngate due to a timeout trying to pull our http_image and we just keep\nlooping until our own timeout instead of noticing. It also means\nwe just report ""never reached active state"" instead of what we know\nto be true, which is that import failed.\n\nChange-Id: Ie0569b84dd1c397a79d13af609bf23db52a2dfc8\n'}]",0,774302,ef8e054b6b53b393086deb43127195a48107220f,14,3,4,4393,,,0,"Make import wait check for store status

During a glance import, if we fail, we are not going to change the
state of the image in all cases, and definitely not to 'active'.
Thus waiting for active just means we keep polling a broken image
for a long time, wasting resources. We should also be checking the
list of failed stores, and if something pops in there, abort right
then and there.

This patch makes us use the wait_for_image_imported_to_stores()
waiter, and modifies it to not look at image['stores'] if no
stores are provided. In the case where we don't have multistore
support enabled, we won't be able to know that the import failed
until we time out, but otherwise we will (barring a glance bug for
which I also have a fix). This also makes the waiter not fail on
KeyError if os_glance_failed_import is not present on the image,
as would be the case if used when stores are not enabled.

Note that I'm doing this because sometimes web-download fails in the
gate due to a timeout trying to pull our http_image and we just keep
looping until our own timeout instead of noticing. It also means
we just report ""never reached active state"" instead of what we know
to be true, which is that import failed.

Change-Id: Ie0569b84dd1c397a79d13af609bf23db52a2dfc8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/774302/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/services/image/v2/images_client.py', 'tempest/api/image/v2/test_images.py']",2,afe2bb33b7cc68a07bd3846f70513cf7304c8d84,webdl-nowait, self.client.wait_for_import_termination(image['id']) self.client.wait_for_import_termination(image['id']), self.client.wait_for_resource_activation(image['id']) self.client.wait_for_resource_activation(image['id']),38,2
openstack%2Fcharm-guide~master~I44c02ad28b16caf7aab2dc61ba86280d6aedee89,openstack/charm-guide,master,I44c02ad28b16caf7aab2dc61ba86280d6aedee89,Add known issue to 21.01 - Glance backends,MERGED,2021-02-09 00:27:35.000000000,2021-02-09 09:06:05.000000000,2021-02-09 09:04:43.000000000,"[{'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2021-02-09 00:27:35.000000000', 'files': ['doc/source/2101.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/f813b50575d0c03506bc4ccd50db20ecdd6b45cd', 'message': 'Add known issue to 21.01 - Glance backends\n\nAdd a Glance known issue when adding storage backends\n\nTone down doc update list\n\nFix typo\n\nChange-Id: I44c02ad28b16caf7aab2dc61ba86280d6aedee89\n'}]",0,774568,f813b50575d0c03506bc4ccd50db20ecdd6b45cd,7,2,1,30561,,,0,"Add known issue to 21.01 - Glance backends

Add a Glance known issue when adding storage backends

Tone down doc update list

Fix typo

Change-Id: I44c02ad28b16caf7aab2dc61ba86280d6aedee89
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/68/774568/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/2101.rst'],1,f813b50575d0c03506bc4ccd50db20ecdd6b45cd,2101-docs,"provider will fail due to bug `LP #1896603`_. This bug does not affect loadAdding Glance storage backends ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ When a storage backend is added to Glance a service restart may be necessary in order for the new backend to be registered. This issue is tracked in bug `LP #1914819`_. * Charm READMEs: cinder, glance, keystone, keystone-ldap, and vault... _LP #1914819: https://bugs.launchpad.net/charm-glance/+bug/1914819",provider will fail due to bug `LP #1896603`_. Ths bug does not affect load* Charm READMEs: * cinder * glance * keystone * keystone-ldap * vault,10,8
openstack%2Fdevstack~stable%2Fvictoria~Icfaaefe1aa576733764b393cba96d276c9b1cf68,openstack/devstack,stable/victoria,Icfaaefe1aa576733764b393cba96d276c9b1cf68,Also cap pip in tempest tox venv,ABANDONED,2021-01-24 08:47:32.000000000,2021-02-09 08:27:27.000000000,,"[{'_account_id': 4393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-24 08:47:32.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/195161580a6aac42692dc85be2c12038a4090d79', 'message': 'Also cap pip in tempest tox venv\n\nI am still unable to stack because of pip 20.3, but this time\nbecause of the tempest venv build. This forces it to the same\ncapped pip, which further works around the problem.\n\nChange-Id: Icfaaefe1aa576733764b393cba96d276c9b1cf68\nRelated-Bug: #1906367\n(cherry picked from commit bcd0acf6c0b5d6501e91133c3a937b3fc40f7122)\n'}]",0,772103,195161580a6aac42692dc85be2c12038a4090d79,3,2,1,20363,,,0,"Also cap pip in tempest tox venv

I am still unable to stack because of pip 20.3, but this time
because of the tempest venv build. This forces it to the same
capped pip, which further works around the problem.

Change-Id: Icfaaefe1aa576733764b393cba96d276c9b1cf68
Related-Bug: #1906367
(cherry picked from commit bcd0acf6c0b5d6501e91133c3a937b3fc40f7122)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/772103/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,195161580a6aac42692dc85be2c12038a4090d79,fix-tempest-pip-stable/victoria, # TODO: remove the trailing pip constraint when a proper fix # arrives for bug https://bugs.launchpad.net/devstack/+bug/1906322 $TEMPEST_DIR/.tox/tempest/bin/pip install -U -r $RC_DIR/tools/cap-pip.txt,,3,0
openstack%2Fironic-python-agent~master~I9c6ee475601e8169fa46fccc6717a197af210068,openstack/ironic-python-agent,master,I9c6ee475601e8169fa46fccc6717a197af210068,[WIP] Add support for using NVMe specific cleaning,ABANDONED,2021-01-12 07:03:49.000000000,2021-02-09 08:25:19.000000000,,"[{'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 32177}]","[{'number': 1, 'created': '2021-01-12 07:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/54a94ea2333344f6f411e50234c5893dd558b2b8', 'message': '[WIP] Add support for using NVMe specific cleaning\n\nThis change adds support for utilising NVMe specific cleaning tools\non supported devices. This will remove the neccessity of using shred to\nsecurely delete the contents of a NVMe drive and enable using nvme-cli\ntools instead, improving cleaning performance and reducing wear on the device.\n\nStory: 2008290\nChange-Id: I9c6ee475601e8169fa46fccc6717a197af210068\n'}, {'number': 2, 'created': '2021-01-15 12:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/45d77bfb7608ba6f013ecca34015d37a85742467', 'message': '[WIP] Add support for using NVMe specific cleaning\n\nThis change adds support for utilising NVMe specific cleaning tools\non supported devices. This will remove the neccessity of using shred to\nsecurely delete the contents of a NVMe drive and enable using nvme-cli\ntools instead, improving cleaning performance and reducing wear on the device.\n\nStory: 2008290\nChange-Id: I9c6ee475601e8169fa46fccc6717a197af210068\n'}, {'number': 3, 'created': '2021-01-20 00:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1ee247354a5bbbff64d82514ee94e7c2159c6a4d', 'message': '[WIP] Add support for using NVMe specific cleaning\n\nThis change adds support for utilising NVMe specific cleaning tools\non supported devices. This will remove the neccessity of using shred to\nsecurely delete the contents of a NVMe drive and enable using nvme-cli\ntools instead, improving cleaning performance and reducing wear on the device.\n\nStory: 2008290\nChange-Id: I9c6ee475601e8169fa46fccc6717a197af210068\n'}, {'number': 4, 'created': '2021-01-20 10:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/da41f3c7c541bb3ea974ee4a8c458e534b8e7e0f', 'message': '[WIP] Add support for using NVMe specific cleaning\n\nThis change adds support for utilising NVMe specific cleaning tools\non supported devices. This will remove the neccessity of using shred to\nsecurely delete the contents of a NVMe drive and enable using nvme-cli\ntools instead, improving cleaning performance and reducing wear on the device.\n\nStory: 2008290\nChange-Id: I9c6ee475601e8169fa46fccc6717a197af210068\n'}, {'number': 5, 'created': '2021-01-20 12:00:08.000000000', 'files': ['ironic_python_agent/hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c0b48bea05124efddd7b0a27aeb77c2d38aa00eb', 'message': '[WIP] Add support for using NVMe specific cleaning\n\nThis change adds support for utilising NVMe specific cleaning tools\non supported devices. This will remove the neccessity of using shred to\nsecurely delete the contents of a NVMe drive and enable using nvme-cli\ntools instead, improving cleaning performance and reducing wear on the device.\n\nStory: 2008290\nChange-Id: I9c6ee475601e8169fa46fccc6717a197af210068\n'}]",0,770237,c0b48bea05124efddd7b0a27aeb77c2d38aa00eb,16,3,5,32177,,,0,"[WIP] Add support for using NVMe specific cleaning

This change adds support for utilising NVMe specific cleaning tools
on supported devices. This will remove the neccessity of using shred to
securely delete the contents of a NVMe drive and enable using nvme-cli
tools instead, improving cleaning performance and reducing wear on the device.

Story: 2008290
Change-Id: I9c6ee475601e8169fa46fccc6717a197af210068
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/37/770237/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/hardware.py'],1,54a94ea2333344f6f411e50234c5893dd558b2b8,story-2008290," if 'nvme' in block_device.name: LOG.info(""Attempting NVMe erase of device %s"", block_device.name) if self.nvme_erase(block_device): return else: execute_secure_erase = info.get( 'agent_enable_ata_secure_erase', True) if execute_secure_erase and self._ata_erase(block_device): return "," execute_secure_erase = info.get( 'agent_enable_ata_secure_erase', True) if execute_secure_erase and self._ata_erase(block_device): return",11,4
openstack%2Frequirements~master~I1dcb7d7c25ad61500de0e0c278e366976d7c4ed8,openstack/requirements,master,I1dcb7d7c25ad61500de0e0c278e366976d7c4ed8,Bump cryptography uc to 3.4.2,ABANDONED,2021-02-09 03:31:26.000000000,2021-02-09 07:34:52.000000000,,"[{'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-09 03:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/afdaa98b18ec49cf9f2befe2e756395adfbd6110', 'message': 'Bump cryptography uc to 3.4.2\n\nCryptography 3.4.1 seems broken and has been fixed\nwith 3.4.2.\n\nhttps://github.com/pyca/cryptography/commit/843ada65e816a17e1b3d90b12ab6403c8ff96654\n\nChange-Id: I1dcb7d7c25ad61500de0e0c278e366976d7c4ed8\n'}, {'number': 2, 'created': '2021-02-09 04:53:57.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/239e47ff888be5d678ce3d9424b681eaf7a506a6', 'message': 'Bump cryptography uc to 3.4.2\n\nCryptography 3.4.1 seems broken and has been fixed\nwith 3.4.2.\n\nhttps://github.com/pyca/cryptography/commit/843ada65e816a17e1b3d90b12ab6403c8ff96654\n\nChange-Id: I1dcb7d7c25ad61500de0e0c278e366976d7c4ed8\n'}]",3,774577,239e47ff888be5d678ce3d9424b681eaf7a506a6,13,3,2,8833,,,0,"Bump cryptography uc to 3.4.2

Cryptography 3.4.1 seems broken and has been fixed
with 3.4.2.

https://github.com/pyca/cryptography/commit/843ada65e816a17e1b3d90b12ab6403c8ff96654

Change-Id: I1dcb7d7c25ad61500de0e0c278e366976d7c4ed8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/77/774577/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,afdaa98b18ec49cf9f2befe2e756395adfbd6110,,cryptography===3.4.2,cryptography===3.4.1,2,2
openstack%2Fswift~master~I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef,openstack/swift,master,I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef,Add a read-only role to keystoneauth,MERGED,2021-01-18 04:07:08.000000000,2021-02-09 06:36:10.000000000,2021-02-09 06:34:28.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-18 04:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a106192ce32e674296224cbff91d6536b5bdbca8', 'message': 'WIP: Safe RBAC in Swift\n\nSee the OpenStack popup team for Consistent and Secure Default Policies:\nhttps://wiki.openstack.org/wiki/Consistent_and_Secure_Default_Policies_Popup_Team\n\nChange-Id: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef\n'}, {'number': 2, 'created': '2021-02-04 17:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/78049f0958cbc3538f5c09107cc8d3934d9f681e', 'message': 'WIP: Safe RBAC in Swift\n\nSee the OpenStack popup team for Consistent and Secure Default Policies:\nhttps://wiki.openstack.org/wiki/Consistent_and_Secure_Default_Policies_Popup_Team\n\nChange-Id: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef\n'}, {'number': 3, 'created': '2021-02-05 19:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cfc8a78324db45307f395637715a8befbd81485f', 'message': 'Add a read-only role\n\nAn idea was floated recently of a read-only role that can be used for\ncluster-wide audits, and is otherwise safe. It was also included into\nthe ""Consistent and Secure Default Policies"" effort in OpenStack,\nwhere it implements ""reader"" personas in system, domain, and project\nscopes. This patch implements it for system scope, where it\'s most\nuseful for operators.\n\nChange-Id: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef\n'}, {'number': 4, 'created': '2021-02-09 04:03:36.000000000', 'files': ['test/unit/common/middleware/test_keystoneauth.py', 'etc/proxy-server.conf-sample', 'swift/common/middleware/keystoneauth.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/98a0275a9d3cddb08db2e0f1a8ab20391813adc7', 'message': 'Add a read-only role to keystoneauth\n\nAn idea was floated recently of a read-only role that can be used for\ncluster-wide audits, and is otherwise safe. It was also included into\nthe ""Consistent and Secure Default Policies"" effort in OpenStack,\nwhere it implements ""reader"" personas in system, domain, and project\nscopes. This patch implements it for system scope, where it\'s most\nuseful for operators.\n\nChange-Id: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef\n'}]",5,771158,98a0275a9d3cddb08db2e0f1a8ab20391813adc7,16,2,4,597,,,0,"Add a read-only role to keystoneauth

An idea was floated recently of a read-only role that can be used for
cluster-wide audits, and is otherwise safe. It was also included into
the ""Consistent and Secure Default Policies"" effort in OpenStack,
where it implements ""reader"" personas in system, domain, and project
scopes. This patch implements it for system scope, where it's most
useful for operators.

Change-Id: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef
",git fetch https://review.opendev.org/openstack/swift refs/changes/58/771158/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_keystoneauth.py', 'etc/proxy-server.conf-sample', 'swift/common/middleware/keystoneauth.py']",3,a106192ce32e674296224cbff91d6536b5bdbca8,rbac," service_roles=[], reader_roles=[]))", service_roles=[])),97,2
openstack%2Fpython-cyborgclient~master~I61d5aae4142db71bc7b3e0a28aaaf9a1bfc92bf0,openstack/python-cyborgclient,master,I61d5aae4142db71bc7b3e0a28aaaf9a1bfc92bf0,Update the constraints url,NEW,2019-09-23 08:39:17.000000000,2021-02-09 06:24:17.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-09-23 08:39:17.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/56c86ee5a1f4a27265e33bb6184cfc5fbddaf8bb', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I61d5aae4142db71bc7b3e0a28aaaf9a1bfc92bf0\n'}]",0,683880,56c86ee5a1f4a27265e33bb6184cfc5fbddaf8bb,3,2,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I61d5aae4142db71bc7b3e0a28aaaf9a1bfc92bf0
",git fetch https://review.opendev.org/openstack/python-cyborgclient refs/changes/80/683880/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,56c86ee5a1f4a27265e33bb6184cfc5fbddaf8bb,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Ftosca-parser~master~I35452efb333f7abdb6b7200531e94542fc3877c0,openstack/tosca-parser,master,I35452efb333f7abdb6b7200531e94542fc3877c0,Set tosca.nodes.BlockStorage size required as false,ABANDONED,2019-12-11 10:09:07.000000000,2021-02-09 06:01:28.000000000,,"[{'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26588}, {'_account_id': 32102}]","[{'number': 1, 'created': '2019-12-11 10:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/e534be1cd30a70007f5d72539d43ea8917ee986c', 'message': 'Set tosca.nodes.BlockStorage size required as false\n\nWe can provide already created volume_id for tosca.nodes.BlockStorage,\nin that case no new volume will be created, and no size required.\n\nChange-Id: I35452efb333f7abdb6b7200531e94542fc3877c0\n'}, {'number': 2, 'created': '2019-12-11 13:30:38.000000000', 'files': ['toscaparser/elements/TOSCA_definition_1_0.yaml'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab', 'message': 'Set tosca.nodes.BlockStorage size required as false\n\nWe can provide already created volume_id for tosca.nodes.BlockStorage,\nin that case no new volume will be created, and no size required.\n\nImplements: blueprint attach-existing-volume\n\nChange-Id: I35452efb333f7abdb6b7200531e94542fc3877c0\n'}]",2,698439,c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab,9,4,2,18955,,,0,"Set tosca.nodes.BlockStorage size required as false

We can provide already created volume_id for tosca.nodes.BlockStorage,
in that case no new volume will be created, and no size required.

Implements: blueprint attach-existing-volume

Change-Id: I35452efb333f7abdb6b7200531e94542fc3877c0
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/39/698439/1 && git format-patch -1 --stdout FETCH_HEAD,['toscaparser/elements/TOSCA_definition_1_0.yaml'],1,e534be1cd30a70007f5d72539d43ea8917ee986c,bp/attach-existing-volume, required: false,,1,0
openstack%2Ftacker~master~Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02,openstack/tacker,master,Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02,support to attach already created volumes with VNF,ABANDONED,2019-12-11 13:39:34.000000000,2021-02-09 05:43:58.000000000,,"[{'_account_id': 4149}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26588}, {'_account_id': 31821}, {'_account_id': 32102}, {'_account_id': 32395}]","[{'number': 1, 'created': '2019-12-11 13:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/62958691ae1a10b09d88ea523dcb196353eb5bc1', 'message': 'Add support to attach already created volumes with VNF.\n\nChange-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02\nImplements: blueprint attach-existing-volume\nDepends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab\n'}, {'number': 2, 'created': '2020-09-18 09:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/89c3af56a174c90aa1414f5dc723192c453f47f2', 'message': 'support to attach already created volumes with VNF\n\nChange-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02\nImplements: blueprint attach-existing-volume\nDepends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab\n'}, {'number': 3, 'created': '2020-11-16 02:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/854d7ede7f12c79a939e70ac29d0cb27f4b2587e', 'message': 'support to attach already created volumes with VNF\n\nChange-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02\nImplements: blueprint attach-existing-volume\nDepends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab\n'}, {'number': 4, 'created': '2020-11-16 05:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/f35f7c9379d8d911583966b386b54f1de48e86d0', 'message': 'support to attach already created volumes with VNF\n\nChange-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02\nImplements: blueprint attach-existing-volume\nDepends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab\n'}, {'number': 5, 'created': '2020-11-24 06:52:34.000000000', 'files': ['tacker/tosca/lib/tacker_nfv_defs.yaml', 'tacker/tests/unit/vnfm/tosca/test_utils.py', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/sample-tosca-vnfd-existing-block-storage.yaml', 'doc/source/reference/block_storage_usage_guide.rst', 'tacker/tosca/utils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/7eed467b9ccb3e5e98831c0220b2e7c12e074cea', 'message': 'support to attach already created volumes with VNF\n\nChange-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02\nImplements: blueprint attach-existing-volume\nDepends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab\n'}]",13,698477,7eed467b9ccb3e5e98831c0220b2e7c12e074cea,35,7,5,18955,,,0,"support to attach already created volumes with VNF

Change-Id: Iab5e3eb7891b12df1c442ed117fbf11ac42b1f02
Implements: blueprint attach-existing-volume
Depends-on: c7ffaf7ddaec033e67d73c4e951b1a3da01a4dab
",git fetch https://review.opendev.org/openstack/tacker refs/changes/77/698477/4 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/unit/vnfm/tosca/test_utils.py', 'tacker/tosca/lib/tacker_nfv_defs.yaml', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/sample-tosca-vnfd-existing-block-storage.yaml', 'doc/source/reference/block_storage_usage_guide.rst', 'tacker/tosca/utils.py']",5,62958691ae1a10b09d88ea523dcb196353eb5bc1,bp/attach-existing-volume,"VOLUME_IDs = {} if 'volume_id' in block_properties: global VOLUME_IDs VOLUME_IDs[node_name] = block_properties['volume_id'] volume_dict[node_name]['volume_id'] = block_properties['volume_id'] del node_tpl[node_name] continue if VOLUME_IDs: vol_attach_dict[node_name]['volume_id'] = \ {'get_param': VOLUME_IDs[ req['virtualAttachment']['node']]} else: vol_attach_dict[node_name]['volume_id'] = \ {'get_resource': req['virtualAttachment']['node']} v_dict = get_volumes(template) if v_dict: block_storage_details['volumes'] = v_dict if 'volume_id' not in vol_res['volumes'].values()[0]: for res_name, cinder_vol in vol_res['volumes'].items(): heat_dict['resources'][res_name] = { 'type': 'OS::Cinder::Volume', 'properties': {} } for prop_name, prop_val in cinder_vol.items(): heat_dict['resources'][res_name]['properties'][prop_name] = \ prop_val"," vol_attach_dict[node_name]['volume_id'] = \ {'get_resource': req['virtualAttachment']['node']} block_storage_details['volumes'] = get_volumes(template) for res_name, cinder_vol in vol_res['volumes'].items(): heat_dict['resources'][res_name] = { 'type': 'OS::Cinder::Volume', 'properties': {} } for prop_name, prop_val in cinder_vol.items(): heat_dict['resources'][res_name]['properties'][prop_name] = \ prop_val",129,11
openstack%2Frequirements~stable%2Ftrain~I30658f0da3fa8bc312088eceac1eca574404cf90,openstack/requirements,stable/train,I30658f0da3fa8bc312088eceac1eca574404cf90,update constraint for os-net-config to new release 11.4.0,MERGED,2021-02-08 14:00:43.000000000,2021-02-09 04:55:50.000000000,2021-02-09 04:55:50.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 14:00:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/75757b1324471f7fb9c73d64e463cc90a1759e0b', 'message': 'update constraint for os-net-config to new release 11.4.0\n\nmeta: version: 11.4.0\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Előd Illés <elod.illes@est.tech>\nmeta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I30658f0da3fa8bc312088eceac1eca574404cf90\n'}]",0,774464,75757b1324471f7fb9c73d64e463cc90a1759e0b,13,4,1,11131,,,0,"update constraint for os-net-config to new release 11.4.0

meta: version: 11.4.0
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Előd Illés <elod.illes@est.tech>
meta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I30658f0da3fa8bc312088eceac1eca574404cf90
",git fetch https://review.opendev.org/openstack/requirements refs/changes/64/774464/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,75757b1324471f7fb9c73d64e463cc90a1759e0b,new-release,os-net-config===11.4.0,os-net-config===11.3.1,1,1
openstack%2Fswift~master~Ia5362f850e602667bd63df129f12816d35fc774b,openstack/swift,master,Ia5362f850e602667bd63df129f12816d35fc774b,reader-role cleanup,ABANDONED,2021-02-08 20:38:57.000000000,2021-02-09 04:04:10.000000000,,"[{'_account_id': 597}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 20:38:57.000000000', 'files': ['swift/common/middleware/keystoneauth.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/cb6ded759fe02fee0bedd8343a36bda7a9fec4fc', 'message': 'reader-role cleanup\n\nChange-Id: Ia5362f850e602667bd63df129f12816d35fc774b\nRelated-Change: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef\n'}]",3,774538,cb6ded759fe02fee0bedd8343a36bda7a9fec4fc,4,2,1,15343,,,0,"reader-role cleanup

Change-Id: Ia5362f850e602667bd63df129f12816d35fc774b
Related-Change: I5f5fff2e61a3e5fb4f4464262a8ea558a6e7d7ef
",git fetch https://review.opendev.org/openstack/swift refs/changes/38/774538/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/keystoneauth.py'],1,cb6ded759fe02fee0bedd8343a36bda7a9fec4fc,rbac," self.system_reader_roles = {role.lower() for role in list_from_csv( conf.get('system_reader_roles', ''))} if self.system_reader_roles.intersection(user_roles): if req.method in ('GET', 'HEAD'): # We aren't setting 'swift_owner' nor 'reseller_request'"," system_reader_roles = conf.get('system_reader_roles') if system_reader_roles is None: self.system_reader_roles = None else: self.system_reader_roles = [ role.strip() for role in system_reader_roles.lower().split(',')] if (self.system_reader_roles and user_roles and len(set(self.system_reader_roles) & set(user_roles)) > 0): if (req.environ['REQUEST_METHOD'] == 'GET' or req.environ['REQUEST_METHOD'] == 'HEAD'): # We aren't setting 'swift_owner' nor ''reseller_request'",5,12
openstack%2Ftripleo-common~master~Iaca5c8e149e28dfa7d4862c1b9ac13b8658fa006,openstack/tripleo-common,master,Iaca5c8e149e28dfa7d4862c1b9ac13b8658fa006,Removed broken mocked params,MERGED,2021-02-01 21:14:30.000000000,2021-02-09 03:52:49.000000000,2021-02-09 03:51:21.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2021-02-01 21:14:30.000000000', 'files': ['tripleo_common/tests/utils/test_stack.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bc9529cf70ca7789e28f33826042b492ab7a9777', 'message': ""Removed broken mocked params\n\nWhen building local packages the local params will now assume\ncertificate information that is otherwise irrelevant to the\ntest. Because the underlying functions have changed, there's\nno need to continue with these asserts, so they've been removed.\n\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\nChange-Id: Iaca5c8e149e28dfa7d4862c1b9ac13b8658fa006\n""}]",0,773482,bc9529cf70ca7789e28f33826042b492ab7a9777,10,4,1,7353,,,0,"Removed broken mocked params

When building local packages the local params will now assume
certificate information that is otherwise irrelevant to the
test. Because the underlying functions have changed, there's
no need to continue with these asserts, so they've been removed.

Signed-off-by: Kevin Carter <kecarter@redhat.com>
Change-Id: Iaca5c8e149e28dfa7d4862c1b9ac13b8658fa006
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/82/773482/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/tests/utils/test_stack.py'],1,bc9529cf70ca7789e28f33826042b492ab7a9777,env_merging,," # verify parameters are as expected expected_defaults = {'DeployIdentifier': 1473366264, 'StackAction': 'CREATE', 'random_existing_data': 'a_value'} mock_env_updated = yaml.safe_dump({ 'name': 'overcloud', 'temp_environment': 'temp_environment', 'parameter_defaults': expected_defaults, 'template': 'template', 'environments': [{u'path': u'environments/test.yaml'}] }, default_flow_style=False) swift.put_object.assert_called_once_with( 'overcloud', constants.PLAN_ENVIRONMENT, mock_env_updated ) # verify parameters are as expected mock_env_updated = yaml.safe_dump({ 'name': constants.DEFAULT_CONTAINER_NAME, 'temp_environment': 'temp_environment', 'parameter_defaults': {'StackAction': 'CREATE', 'DeployIdentifier': '', 'random_existing_data': 'a_value'}, 'template': 'template', 'environments': [{u'path': u'environments/test.yaml'}] }, default_flow_style=False) swift.put_object.assert_called_once_with( constants.DEFAULT_CONTAINER_NAME, constants.PLAN_ENVIRONMENT, mock_env_updated ) ",0,36
openstack%2Fneutron~master~Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,openstack/neutron,master,Ib1a95dd41d25f39f3378a6728d752a6589b9b61c,Fix incorrect exception catch when update floating ip port forwarding,MERGED,2021-02-06 02:24:56.000000000,2021-02-09 03:39:39.000000000,2021-02-09 03:38:02.000000000,"[{'_account_id': 5948}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-06 02:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/37ef29c6f0aa511e0214c973e9f9213b79275848', 'message': 'Fix incorrect exception catch when update floating ip port forwarding\n\nChange-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c\n'}, {'number': 2, 'created': '2021-02-06 02:40:28.000000000', 'files': ['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9e4395d578e40bb59272b409c7ca3617ec1e6e3', 'message': 'Fix incorrect exception catch when update floating ip port forwarding\n\nCloses-Bug: #1912596\nChange-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c\n'}]",0,774325,e9e4395d578e40bb59272b409c7ca3617ec1e6e3,19,4,2,28329,,,0,"Fix incorrect exception catch when update floating ip port forwarding

Closes-Bug: #1912596
Change-Id: Ib1a95dd41d25f39f3378a6728d752a6589b9b61c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/774325/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/services/portforwarding/pf_plugin.py']",2,37ef29c6f0aa511e0214c973e9f9213b79275848,bug/1912596,from oslo_db import exception as oslo_db_exc except oslo_db_exc.DBDuplicateEntry:, except obj_exc.NeutronDbObjectDuplicateEntry:,60,1
openstack%2Ftacker~master~I94fc914f58747ae75651480ec11b177140fa849a,openstack/tacker,master,I94fc914f58747ae75651480ec11b177140fa849a,Remove duplication of getting HOT templates,MERGED,2021-02-02 23:46:09.000000000,2021-02-09 02:14:11.000000000,2021-02-09 02:11:52.000000000,"[{'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 27880}, {'_account_id': 32102}, {'_account_id': 32395}]","[{'number': 1, 'created': '2021-02-02 23:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5d3393ec54d3033b98a255f71e75d5e646b84751', 'message': 'Remove duplication of getting HOT templates\n\nPreviously get_base_nest_hot_dict() was called by vnflcm_driver\nand openstack infra_driver redundantly.\n\nThis patch remove calling get_base_nest_hot_dict() from\nvnflcm_driver because HOT is openstack specific.\nbase_hot_dict parameter of infra_driver interface is removed\nat the same time.\nNote that vnf_package_path parameter is passed to infra_driver\nalways since it is used by both openstack and kubernetes.\n\nChange-Id: I94fc914f58747ae75651480ec11b177140fa849a\n'}, {'number': 2, 'created': '2021-02-03 04:58:31.000000000', 'files': ['tacker/tests/unit/vnfm/infra_drivers/openstack/test_openstack_driver.py', 'tacker/vnfm/infra_drivers/kubernetes/kubernetes_driver.py', 'tacker/vnfm/infra_drivers/openstack/openstack.py', 'tacker/vnflcm/vnflcm_driver.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/9204d07e5cc632fda52aee5fc3b9b5885d20d64f', 'message': 'Remove duplication of getting HOT templates\n\nPreviously get_base_nest_hot_dict() was called by vnflcm_driver\nand openstack infra_driver redundantly.\n\nThis patch remove calling get_base_nest_hot_dict() from\nvnflcm_driver because HOT is openstack specific.\nbase_hot_dict parameter of infra_driver interface is removed\nat the same time.\nNote that vnf_package_path parameter is passed to infra_driver\nalways since it is used by both openstack and kubernetes.\n\nChange-Id: I94fc914f58747ae75651480ec11b177140fa849a\n'}]",20,773820,9204d07e5cc632fda52aee5fc3b9b5885d20d64f,11,6,2,4149,,,0,"Remove duplication of getting HOT templates

Previously get_base_nest_hot_dict() was called by vnflcm_driver
and openstack infra_driver redundantly.

This patch remove calling get_base_nest_hot_dict() from
vnflcm_driver because HOT is openstack specific.
base_hot_dict parameter of infra_driver interface is removed
at the same time.
Note that vnf_package_path parameter is passed to infra_driver
always since it is used by both openstack and kubernetes.

Change-Id: I94fc914f58747ae75651480ec11b177140fa849a
",git fetch https://review.opendev.org/openstack/tacker refs/changes/20/773820/2 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/unit/vnfm/infra_drivers/openstack/test_openstack_driver.py', 'tacker/vnfm/infra_drivers/kubernetes/kubernetes_driver.py', 'tacker/vnfm/infra_drivers/openstack/openstack.py', 'tacker/vnflcm/vnflcm_driver.py']",4,5d3393ec54d3033b98a255f71e75d5e646b84751,cleanup, vnf_package_path = vnflcm_utils._get_vnf_package_path(," base_hot_dict, nested_hot_dict = \ vnflcm_utils.get_base_nest_hot_dict( context, instantiate_vnf_req.flavour_id, vnf_instance.vnfd_id) vnf_package_path = None if base_hot_dict is not None: vnf_package_path = vnflcm_utils._get_vnf_package_path( base_hot_dict=base_hot_dict,",17,41
openstack%2Ftacker~master~I6bedc5c8c712c9cf7d95ae5cb7384c4dea187108,openstack/tacker,master,I6bedc5c8c712c9cf7d95ae5cb7384c4dea187108,Workaround for the ControllerRevision FT,MERGED,2021-02-05 10:14:00.000000000,2021-02-09 02:12:50.000000000,2021-02-09 02:11:16.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 26588}, {'_account_id': 32102}]","[{'number': 1, 'created': '2021-02-05 10:14:00.000000000', 'files': ['tacker/tests/functional/sol/vnflcm/test_kubernetes.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/70ec11e11313707ea952591d367d072d7d17e717', 'message': 'Workaround for the ControllerRevision FT\n\nThis patch is provisional workaround for bug [1].\n\nI think possible ways to fix the bug are using the kubernetes\npython client v11.0.0. However, as a other issue, the\nControllerRevision resources is not delete and remain. The\nproblem of resources remaining cannot be solved immediately.\nTherefore, add a skip decorator to skip the Functional Test of\nControllerRevision as a workaround.\n\nThe added skip decorator will be removed after this issue\ncompletely resolved.\n\n[1] https://bugs.launchpad.net/tacker/+bug/1910327\n\nPartial-Bug: #1910327\nChange-Id: I6bedc5c8c712c9cf7d95ae5cb7384c4dea187108\n'}]",0,774215,70ec11e11313707ea952591d367d072d7d17e717,9,6,1,31730,,,0,"Workaround for the ControllerRevision FT

This patch is provisional workaround for bug [1].

I think possible ways to fix the bug are using the kubernetes
python client v11.0.0. However, as a other issue, the
ControllerRevision resources is not delete and remain. The
problem of resources remaining cannot be solved immediately.
Therefore, add a skip decorator to skip the Functional Test of
ControllerRevision as a workaround.

The added skip decorator will be removed after this issue
completely resolved.

[1] https://bugs.launchpad.net/tacker/+bug/1910327

Partial-Bug: #1910327
Change-Id: I6bedc5c8c712c9cf7d95ae5cb7384c4dea187108
",git fetch https://review.opendev.org/openstack/tacker refs/changes/15/774215/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/tests/functional/sol/vnflcm/test_kubernetes.py'],1,70ec11e11313707ea952591d367d072d7d17e717,bug/1910327,"import unittest @unittest.skip(""Until BUG 1910327"")",,2,0
openstack%2Ftacker~master~I6ffdadc196cf2ddcec3625c6bd99b5133e37af4b,openstack/tacker,master,I6ffdadc196cf2ddcec3625c6bd99b5133e37af4b,Close HOT template files after read,MERGED,2021-02-01 05:16:21.000000000,2021-02-09 02:11:20.000000000,2021-02-09 02:11:20.000000000,"[{'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 27880}, {'_account_id': 32102}, {'_account_id': 32395}]","[{'number': 1, 'created': '2021-02-01 05:16:21.000000000', 'files': ['tacker/vnflcm/utils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/54aca142b09b8249531ec558e119e9b7e0db035f', 'message': 'Close HOT template files after read\n\nPreviously get_base_nest_hot_dict() used by tacker-conductor\nopens and reads HOT template files but does not close them.\nAs a result, tacker-conductor will reach the limit of open\nfile descriptor while it is running long time.\n\nThis patch fixes to close HOT template files after read\nthem.\n\nThis patch makes some clean-ups too.\n* use existing method to make path construction and make it easy to\n  understand.\n* remove _get_base_hot_dict() because it was replaced to\n  get_base_nest_hot_dict() and is not used anywhere now.\n  And it is considerd that it will not be used any more.\n* remove meaningless array to tupple translation.\n* same bug fix and clean-ups are applied in the same file.\n\nCloses-Bug: #1913978\n\nChange-Id: I6ffdadc196cf2ddcec3625c6bd99b5133e37af4b\n'}]",0,773286,54aca142b09b8249531ec558e119e9b7e0db035f,11,6,1,4149,,,0,"Close HOT template files after read

Previously get_base_nest_hot_dict() used by tacker-conductor
opens and reads HOT template files but does not close them.
As a result, tacker-conductor will reach the limit of open
file descriptor while it is running long time.

This patch fixes to close HOT template files after read
them.

This patch makes some clean-ups too.
* use existing method to make path construction and make it easy to
  understand.
* remove _get_base_hot_dict() because it was replaced to
  get_base_nest_hot_dict() and is not used anywhere now.
  And it is considerd that it will not be used any more.
* remove meaningless array to tupple translation.
* same bug fix and clean-ups are applied in the same file.

Closes-Bug: #1913978

Change-Id: I6ffdadc196cf2ddcec3625c6bd99b5133e37af4b
",git fetch https://review.opendev.org/openstack/tacker refs/changes/86/773286/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/vnflcm/utils.py'],1,54aca142b09b8249531ec558e119e9b7e0db035f,bug/1913978," vnfd_dict = _get_flavour_based_vnfd( _get_vnf_package_path(context, vnfd_id), flavour_id) vnf_package_path = CONF.vnf_package.vnf_package_csar_path ext = ("".yaml"", "".yml"") if file.endswith(ext): elif src_path.endswith(ext): with open(src_path) as file_obj: file_data = yaml.safe_load(file_obj) return os.path.join(CONF.vnf_package.vnf_package_csar_path, _get_vnf_package_id(context, vnfd_id)) base_hot_path = os.path.join(_get_vnf_package_path(context, vnfd_id), 'BaseHOT', flavour_id) nested_hot_path = os.path.join(base_hot_path, 'nested') ext = ("".yaml"", "".yml"") if file.endswith(ext): with open(os.path.join(base_hot_path, file)) as file_obj: base_hot_dict = yaml.safe_load(file_obj) if file.endswith(ext): with open(os.path.join(nested_hot_path, file)) as file_obj: nested_hot = yaml.safe_load(file_obj) nested_hot_dict[file] = nested_hot","import io vnf_package_id = _get_vnf_package_id(context, vnfd_id) vnf_package_base_path = cfg.CONF.vnf_package.vnf_package_csar_path vnf_package_csar_path = vnf_package_base_path + '/' + vnf_package_id vnfd_dict = _get_flavour_based_vnfd(vnf_package_csar_path, flavour_id) vnf_package_path = cfg.CONF.vnf_package.vnf_package_csar_path ext = ["".yaml"", "".yml""] if file.endswith(tuple(ext)): elif src_path.endswith(tuple(ext)): file_data = yaml.safe_load(io.open(src_path)) vnf_package_id = _get_vnf_package_id(context, vnfd_id) vnf_package_base_path = cfg.CONF.vnf_package.vnf_package_csar_path vnf_package_path = vnf_package_base_path + '/' + vnf_package_id return vnf_package_path def _get_base_hot_dict(context, vnfd_id): vnf_package_id = _get_vnf_package_id(context, vnfd_id) vnf_package_base_path = cfg.CONF.vnf_package.vnf_package_csar_path vnf_package_csar_path = vnf_package_base_path + '/' + vnf_package_id base_hot_dir = 'BaseHOT' ext = ["".yaml"", "".yml""] base_hot_path = vnf_package_csar_path + '/' + base_hot_dir base_hot_dict = None if os.path.exists(base_hot_path): for file in os.listdir(base_hot_path): if file.endswith(tuple(ext)): source_file_path = os.path.join(base_hot_path, file) base_hot_dict = yaml.safe_load(open(source_file_path)) LOG.debug(""Loaded base hot: %s"", base_hot_dict) return base_hot_dict vnf_package_id = _get_vnf_package_id(context, vnfd_id) vnf_package_base_path = cfg.CONF.vnf_package.vnf_package_csar_path vnf_package_csar_path = vnf_package_base_path + '/' + vnf_package_id base_hot_dir = 'BaseHOT' ext = ["".yaml"", "".yml""] base_hot_path = vnf_package_csar_path + '/' + \ base_hot_dir + '/' + flavour_id nested_hot_path = base_hot_path + '/nested' if file.endswith(tuple(ext)): source_file_path = os.path.join(base_hot_path, file) base_hot_dict = yaml.safe_load(open(source_file_path)) if file.endswith(tuple(ext)): source_file_path = os.path.join(nested_hot_path, file) nested_hot = yaml.safe_load(open(source_file_path)) nested_hot_dict[file] = nested_hot",21,47
openstack%2Frequirements~stable%2Ftrain~I0e329f146da5dcc347e232c38d2203269cac7a45,openstack/requirements,stable/train,I0e329f146da5dcc347e232c38d2203269cac7a45,update constraint for paunch to new release 5.4.0,MERGED,2021-02-08 13:48:14.000000000,2021-02-09 02:06:17.000000000,2021-02-09 02:06:17.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:48:14.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a24ebc420a5d2c30317d89ddfcb8da19b171edc4', 'message': 'update constraint for paunch to new release 5.4.0\n\nmeta: version: 5.4.0\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Előd Illés <elod.illes@est.tech>\nmeta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I0e329f146da5dcc347e232c38d2203269cac7a45\n'}]",0,774458,a24ebc420a5d2c30317d89ddfcb8da19b171edc4,11,4,1,11131,,,0,"update constraint for paunch to new release 5.4.0

meta: version: 5.4.0
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Előd Illés <elod.illes@est.tech>
meta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I0e329f146da5dcc347e232c38d2203269cac7a45
",git fetch https://review.opendev.org/openstack/requirements refs/changes/58/774458/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a24ebc420a5d2c30317d89ddfcb8da19b171edc4,new-release,paunch===5.4.0,paunch===5.3.2,1,1
openstack%2Frequirements~stable%2Ftrain~I71f9e9d57a8170a6a6bce28a35a5641e55942c85,openstack/requirements,stable/train,I71f9e9d57a8170a6a6bce28a35a5641e55942c85,update constraint for os-apply-config to new release 10.5.2,MERGED,2021-02-08 13:52:44.000000000,2021-02-09 02:06:13.000000000,2021-02-09 02:06:13.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 13:52:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9da970c58719067ef80e00bce2613bbe097732de', 'message': 'update constraint for os-apply-config to new release 10.5.2\n\nmeta: version: 10.5.2\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Előd Illés <elod.illes@est.tech>\nmeta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I71f9e9d57a8170a6a6bce28a35a5641e55942c85\n'}]",0,774459,9da970c58719067ef80e00bce2613bbe097732de,11,3,1,11131,,,0,"update constraint for os-apply-config to new release 10.5.2

meta: version: 10.5.2
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Előd Illés <elod.illes@est.tech>
meta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I71f9e9d57a8170a6a6bce28a35a5641e55942c85
",git fetch https://review.opendev.org/openstack/requirements refs/changes/59/774459/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,9da970c58719067ef80e00bce2613bbe097732de,new-release,os-apply-config===10.5.2,os-apply-config===10.5.1,1,1
openstack%2Foctavia~master~I48e8882f629886d1b8abadff6e60aad91d1169c7,openstack/octavia,master,I48e8882f629886d1b8abadff6e60aad91d1169c7,Bump oslo.policy version to 2.1.0,MERGED,2020-11-24 04:44:03.000000000,2021-02-09 01:14:06.000000000,2021-02-09 01:12:27.000000000,"[{'_account_id': 1131}, {'_account_id': 7249}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 04:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e9ae51610e1d6b659942b926dcb49ad15f30f530', 'message': ""Bump oslo.policy version to 2.1.0\n\nThe secure RBAC work requires the of oslo.policy's scope_types argument,\nwhich was made available in 1.32.0. This commit updates to version 2.1.0\nso that we're using something more relevant.\n\nChange-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7\n""}, {'number': 2, 'created': '2021-01-28 16:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f1833a49d78db96bb085220be3f565fe31707c95', 'message': ""Bump oslo.policy version to 2.1.0\n\nThe secure RBAC work requires the of oslo.policy's scope_types argument,\nwhich was made available in 1.32.0. This commit updates to version 2.1.0\nso that we're using something more relevant.\n\nChange-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7\n""}, {'number': 3, 'created': '2021-01-28 21:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cfcb0ecfc2af46c7fd485d0b3345929963efd1be', 'message': ""Bump oslo.policy version to 2.1.0\n\nThe secure RBAC work requires the of oslo.policy's scope_types argument,\nwhich was made available in 1.32.0. This commit updates to version 2.1.0\nso that we're using something more relevant.\n\nChange-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7\n""}, {'number': 4, 'created': '2021-01-28 23:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c6dc0878a661d6199a92ed14ecfefc0adf58ab07', 'message': ""Bump oslo.policy version to 2.1.0\n\nThe secure RBAC work requires the of oslo.policy's scope_types argument,\nwhich was made available in 1.32.0. This commit updates to version 2.1.0\nso that we're using something more relevant.\n\nRequired oslo.context bump.\n\nChange-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7\n""}, {'number': 5, 'created': '2021-02-08 17:18:55.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/a822f30eb135b31f1e5fb212810f99f5d5adf477', 'message': ""Bump oslo.policy version to 2.1.0\n\nThe secure RBAC work requires the of oslo.policy's scope_types argument,\nwhich was made available in 1.32.0. This commit updates to version 2.1.0\nso that we're using something more relevant.\n\nRequired oslo.context bump.\n\nChange-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7\n""}]",1,763926,a822f30eb135b31f1e5fb212810f99f5d5adf477,23,5,5,5046,,,0,"Bump oslo.policy version to 2.1.0

The secure RBAC work requires the of oslo.policy's scope_types argument,
which was made available in 1.32.0. This commit updates to version 2.1.0
so that we're using something more relevant.

Required oslo.context bump.

Change-Id: I48e8882f629886d1b8abadff6e60aad91d1169c7
",git fetch https://review.opendev.org/openstack/octavia refs/changes/26/763926/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,e9ae51610e1d6b659942b926dcb49ad15f30f530,secure-rbac,oslo.policy==2.1.0,oslo.policy==1.30.0,2,2
openstack%2Foctavia~master~I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e,openstack/octavia,master,I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e,Bump oslo.log version to 4.3.0,MERGED,2020-11-19 22:23:56.000000000,2021-02-09 00:53:22.000000000,2021-02-09 00:51:30.000000000,"[{'_account_id': 1131}, {'_account_id': 7249}, {'_account_id': 9954}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-19 22:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8302148018213b389e0d84384d802fb2af18ea89', 'message': 'Bump oslo.log version to 4.3.0\n\nThis allows us to use the Wallaby release marker in versionutils for\ndeprecations.\n\nChange-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e\n'}, {'number': 2, 'created': '2021-01-28 15:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/88fa9f1645fd40237cb086cfadb475f0795f2ffa', 'message': 'Bump oslo.log version to 4.3.0\n\nThis allows us to use the Wallaby release marker in versionutils for\ndeprecations.\n\nChange-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e\n'}, {'number': 3, 'created': '2021-01-28 16:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8793b93900e747f5f46c4768d1c278fcb4f73610', 'message': 'Bump oslo.log version to 4.3.0\n\nThis allows us to use the Wallaby release marker in versionutils for\ndeprecations.\n\nRequired some other bumps to satisfy lower-constraints.\n\nChange-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e\n'}, {'number': 4, 'created': '2021-01-28 20:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7fbea7cb1ad336e6a84d27bcc588b961cdffd36f', 'message': 'Bump oslo.log version to 4.3.0\n\nThis allows us to use the Wallaby release marker in versionutils for\ndeprecations.\n\nRequired some other bumps to satisfy lower-constraints.\n\nChange-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e\n'}, {'number': 5, 'created': '2021-02-08 17:17:15.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/7d8b0db3c854d3c452f6072e1a96c3ac5008c5c7', 'message': 'Bump oslo.log version to 4.3.0\n\nThis allows us to use the Wallaby release marker in versionutils for\ndeprecations.\n\nRequired some other bumps to satisfy lower-constraints.\n\nChange-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e\n'}]",0,763477,7d8b0db3c854d3c452f6072e1a96c3ac5008c5c7,22,6,5,5046,,,0,"Bump oslo.log version to 4.3.0

This allows us to use the Wallaby release marker in versionutils for
deprecations.

Required some other bumps to satisfy lower-constraints.

Change-Id: I3c2be8a5189dcda24c42ed7ab4d8fa33a03c5d3e
",git fetch https://review.opendev.org/openstack/octavia refs/changes/77/763477/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,8302148018213b389e0d84384d802fb2af18ea89,secure-rbac,oslo.log==4.3.0,oslo.log==3.36.0,2,2
openstack%2Fproject-config~master~I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3,openstack/project-config,master,I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3,Setup OpenInfra Channels,MERGED,2021-02-08 22:11:06.000000000,2021-02-09 00:52:21.000000000,2021-02-09 00:32:07.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 22:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/83d21ea538d6fd018a5b76e5d586756ee526cc6e', 'message': 'Setup OpenInfra Channels\n\nopenstack-forum, openstack-ptg, openstack-summit and openinfra-summit\nwill now be openinfra-events.\n\nopenstack-diversity will now be openinfra-diversity.\n\nopenstack-board will now be openinfra-board.\n\nopenstack-foundation will now be openinfra.\n\nChange-Id: I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3\n'}, {'number': 2, 'created': '2021-02-08 23:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0610c41995ebdea4654703870b6db4617941de41', 'message': 'Setup OpenInfra Channels\n\nopenstack-forum, openstack-ptg, openstack-summit and openinfra-summit\nwill now be openinfra-events.\n\nopenstack-diversity will now be openinfra-diversity.\n\nopenstack-foundation will now be openinfra.\n\nopenstack-board will come later after we can get op rights and\nregister the channel.\n\nChange-Id: I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3\n'}, {'number': 3, 'created': '2021-02-09 00:03:04.000000000', 'files': ['gerritbot/channels.yaml', 'accessbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f9c31de4c134c880d7ef67c3f074dc4ffcf0a2b8', 'message': 'Setup OpenInfra Channels\n\nopenstack-forum, openstack-ptg, openstack-summit and openinfra-summit\nwill now be openinfra-events.\n\nopenstack-diversity will now be openinfra-diversity.\n\nopenstack-foundation will now be openinfra.\n\nopenstack-board will come later after we can get op rights and\nregister the channel.\n\nChange-Id: I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3\n'}]",1,774550,f9c31de4c134c880d7ef67c3f074dc4ffcf0a2b8,14,2,3,16708,,,0,"Setup OpenInfra Channels

openstack-forum, openstack-ptg, openstack-summit and openinfra-summit
will now be openinfra-events.

openstack-diversity will now be openinfra-diversity.

openstack-foundation will now be openinfra.

openstack-board will come later after we can get op rights and
register the channel.

Change-Id: I4d09979e0c9dac75c7f3d878cde99cdc56b8dbe3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/774550/1 && git format-patch -1 --stdout FETCH_HEAD,"['accessbot/channels.yaml', 'gerritbot/channels.yaml']",2,83d21ea538d6fd018a5b76e5d586756ee526cc6e,openifra-channels,openinfra-events: events: - patchset-created - change-merged projects: - openstack/ptgbot branches: - master ,,13,0
openstack%2Ftripleo-heat-templates~master~Ia0e31c9469033c50a8b65af7fee1adf03b22d4c2,openstack/tripleo-heat-templates,master,Ia0e31c9469033c50a8b65af7fee1adf03b22d4c2,Add service ordering to cleanup service to avoid conflicts with agent startup,MERGED,2021-01-28 17:00:37.000000000,2021-02-09 00:41:32.000000000,2021-02-09 00:41:32.000000000,"[{'_account_id': 6926}, {'_account_id': 11975}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2021-01-28 17:00:37.000000000', 'files': ['deployment/neutron/neutron-cleanup.service'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c20e1e1ac320e30aaedba980270dffbf4528fc3', 'message': 'Add service ordering to cleanup service to avoid conflicts with agent startup\n\nIf the port cleanup takes too long, the neutron agents might begin\noperations on the ovs bridges while cleanup is still ongoing. This can\ncause undefined behavior and errors in the agent.\n\nChange-Id: Ia0e31c9469033c50a8b65af7fee1adf03b22d4c2\nCloses-Bug: #1913623\n'}]",0,772924,0c20e1e1ac320e30aaedba980270dffbf4528fc3,10,6,1,6681,,,0,"Add service ordering to cleanup service to avoid conflicts with agent startup

If the port cleanup takes too long, the neutron agents might begin
operations on the ovs bridges while cleanup is still ongoing. This can
cause undefined behavior and errors in the agent.

Change-Id: Ia0e31c9469033c50a8b65af7fee1adf03b22d4c2
Closes-Bug: #1913623
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/772924/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-cleanup.service'],1,0c20e1e1ac320e30aaedba980270dffbf4528fc3,,Before=tripleo_neutron_ovs_agent.service tripleo_neutron_dhcp.service tripleo_neutron_l3_agent.service tripleo_nova_compute.service,Before=docker.service,1,1
openstack%2Ftrove~master~I6a144fbf5d79c29dc204483bb7403ea850983a73,openstack/trove,master,I6a144fbf5d79c29dc204483bb7403ea850983a73,Doc: custom container image registry,MERGED,2021-02-08 11:00:44.000000000,2021-02-09 00:39:04.000000000,2021-02-09 00:37:44.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 11:00:44.000000000', 'files': ['doc/source/admin/run_trove_in_production.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/6edd3332b68864e69eb6733a71ecb5e827871d8f', 'message': 'Doc: custom container image registry\n\nChange-Id: I6a144fbf5d79c29dc204483bb7403ea850983a73\n'}]",0,774435,6edd3332b68864e69eb6733a71ecb5e827871d8f,7,2,1,6732,,,0,"Doc: custom container image registry

Change-Id: I6a144fbf5d79c29dc204483bb7403ea850983a73
",git fetch https://review.opendev.org/openstack/trove refs/changes/35/774435/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/run_trove_in_production.rst'],1,6edd3332b68864e69eb6733a71ecb5e827871d8f,custom-registry-doc,"Configure Trove Guest Agent """""""""""""""""""""""""""""""""""""""""""""""""""""" The config file of trove guest agent is copied from trove controller node (default file path ``/etc/trove/trove-guestagent.conf``) when creating instance. Some config options specifically for trove guest agent: * Custom container image registry. Trove guest agent pulls container images from docker hub by default, this can be changed by setting: .. code-block:: ini [guest_agent] container_registry = container_registry_username = container_registry_password = Then in the specific database config section, the customized container registry can be used, e.g. .. code-block:: ini [mysql] docker_image = your-registry/your-repo/mysql backup_docker_image = your-registry/your-repo/db-backup-mysql:1.1.0Currently supported databases are: MySQL 5.7.X, MariaDB 10.4.X. PostgreSQL 12.4 is partially supported. ",,31,0
openstack%2Fswift~master~I991806227f18f115646b0549a77326617aa2c8fe,openstack/swift,master,I991806227f18f115646b0549a77326617aa2c8fe,Permit to bind object-server on replication_port,NEW,2016-07-05 20:46:21.000000000,2021-02-09 00:24:20.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 7233}, {'_account_id': 12261}, {'_account_id': 13052}, {'_account_id': 13852}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2016-07-05 20:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e69281d5772561fa3e9b0992274036cd290b4549', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a semicolon.\n\nThe following configuration will create two workers per devices if port\nand replication_port are differents in the ring. One worker for clients\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 2, 'created': '2017-03-02 20:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8851b0c77e93c1a4ddb0496b5422bdee5c223361', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a semicolon.\n\nThe following configuration will create two workers per devices if port\nand replication_port are differents in the ring. One worker for clients\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nCloses-Bug: #1669579\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 3, 'created': '2017-03-09 23:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b1c8fd8723b23e22346a95232e568db8f0847f2', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a semicolon.\n\nThe following configuration will create two workers per devices if port\nand replication_port are differents in the ring. One worker for clients\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 4, 'created': '2017-03-10 08:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/79a8fd7b7d18ac6dc7e58e43aeda963319e29e1e', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a comma.\n\nThe following configuration will create two workers per devices if port\nand replication_port are differents in the ring. One worker for clients\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 5, 'created': '2017-03-10 10:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b72f81b1947991433cac7f15369fffbeb8adb32f', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a comma.\n\nThe following configuration will create two workers per device if port\nand replication_port are different in the ring. One worker for clients'\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 6, 'created': '2019-05-03 16:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbe5031078cb6b268b726b6d11a9f7195efbad20', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a comma.\n\nThe following configuration will create two workers per device if port\nand replication_port are different in the ring. One worker for clients'\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nIf using different ports in the ring for proxy and replication traffic,\nit allows to dedicate processes to replication, which can be\nIO-intensive and sometime hangs the process for many seconds.\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 7, 'created': '2019-12-19 05:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/47060c889736d2a8fd763d0587180b30ce21c1ad', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a comma.\n\nThe following configuration will create two workers per device if port\nand replication_port are different in the ring. One worker for clients'\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nIf using different ports in the ring for proxy and replication traffic,\nit allows to dedicate processes to replication, which can be\nIO-intensive and sometime hangs the process for many seconds.\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}, {'number': 8, 'created': '2021-02-08 23:24:32.000000000', 'files': ['test/unit/common/test_storage_policy.py', 'swift/common/storage_policy.py', 'swift/common/wsgi.py', 'doc/source/config/object_server_config.rst', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/758e53b6ef8432ca66556f237cb86e28d6c6d587', 'message': ""Permit to bind object-server on replication_port\n\nAdd a new configuration option 'servers_per_port_type' to choose on which\nport the object-server must bind when servers_per_port is enabled. It can\nbe 'port' (the default, which does not change the current behavior), or\n'replication_port', or both separated by a comma.\n\nThe following configuration will create two workers per device if port\nand replication_port are different in the ring. One worker for clients'\ntraffic and one worker for replication traffic:\n    servers_per_port = 1\n    servers_per_port_type = port, replication_port\n\nIf using different ports in the ring for proxy and replication traffic,\nit allows to dedicate processes to replication, which can be\nIO-intensive and sometime hangs the process for many seconds.\n\nCloses-Bug: #1669579\n\nChange-Id: I991806227f18f115646b0549a77326617aa2c8fe\n""}]",22,337861,758e53b6ef8432ca66556f237cb86e28d6c6d587,32,8,8,13852,,,0,"Permit to bind object-server on replication_port

Add a new configuration option 'servers_per_port_type' to choose on which
port the object-server must bind when servers_per_port is enabled. It can
be 'port' (the default, which does not change the current behavior), or
'replication_port', or both separated by a comma.

The following configuration will create two workers per device if port
and replication_port are different in the ring. One worker for clients'
traffic and one worker for replication traffic:
    servers_per_port = 1
    servers_per_port_type = port, replication_port

If using different ports in the ring for proxy and replication traffic,
it allows to dedicate processes to replication, which can be
IO-intensive and sometime hangs the process for many seconds.

Closes-Bug: #1669579

Change-Id: I991806227f18f115646b0549a77326617aa2c8fe
",git fetch https://review.opendev.org/openstack/swift refs/changes/61/337861/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/deployment_guide.rst', 'test/unit/common/test_storage_policy.py', 'swift/common/storage_policy.py', 'swift/common/wsgi.py', 'etc/object-server.conf-sample']",5,e69281d5772561fa3e9b0992274036cd290b4549,change-337861-7,"# If servers_per_port is enabled, define for what type of port processes must # be started. Can be 'port', 'replication_port', or both separated by a semi # colon # servers_per_port_type = port #",,78,26
openstack%2Fpython-tripleoclient~stable%2Fussuri~I30b448930f53aef108d9bdb544a6d02b18658b0d,openstack/python-tripleoclient,stable/ussuri,I30b448930f53aef108d9bdb544a6d02b18658b0d,Add --disable-container-prepare flag,MERGED,2021-01-07 16:04:51.000000000,2021-02-09 00:23:31.000000000,2021-02-09 00:21:57.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-07 16:04:51.000000000', 'files': ['tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/undercloud.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/08d9f082eab97dcf42de516c3b7d2a65ed9d325c', 'message': ""Add --disable-container-prepare flag\n\nUsers may want to skip the container prepare process to ensure they\ndon't update their containers. This change adds a\n--disable-container-prepare flag to the following actions which should\nskip the preparation actions.\n - overcloud deploy (and updates)\n - overcloud plan actions\n - undercloud deploy (and upgrades)\n - tripleo deploy (and standalone deploy)\n\nConflicts:\n        tripleoclient/tests/v1/test_overcloud_plan.py\n        tripleoclient/tests/workflows/test_plan_management.py\n        tripleoclient/v1/overcloud_deploy.py\n        tripleoclient/v1/overcloud_plan.py\n        tripleoclient/workflows/plan_management.py\n\nCloses-Bug: #1896757\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/769774\nChange-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d\n(cherry picked from commit 0d84ac9234bf93ca4d1471d5860739bc31a6be80)\n""}]",0,769781,08d9f082eab97dcf42de516c3b7d2a65ed9d325c,17,5,1,14985,,,0,"Add --disable-container-prepare flag

Users may want to skip the container prepare process to ensure they
don't update their containers. This change adds a
--disable-container-prepare flag to the following actions which should
skip the preparation actions.
 - overcloud deploy (and updates)
 - overcloud plan actions
 - undercloud deploy (and upgrades)
 - tripleo deploy (and standalone deploy)

Conflicts:
        tripleoclient/tests/v1/test_overcloud_plan.py
        tripleoclient/tests/workflows/test_plan_management.py
        tripleoclient/v1/overcloud_deploy.py
        tripleoclient/v1/overcloud_plan.py
        tripleoclient/workflows/plan_management.py

Closes-Bug: #1896757
Depends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/769774
Change-Id: I30b448930f53aef108d9bdb544a6d02b18658b0d
(cherry picked from commit 0d84ac9234bf93ca4d1471d5860739bc31a6be80)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/81/769781/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/v1/test_overcloud_plan.py', 'tripleoclient/workflows/plan_management.py', 'tripleoclient/tests/workflows/test_plan_management.py', 'tripleoclient/v1/undercloud.py', 'tripleoclient/v1/overcloud_plan.py', 'tripleoclient/v1/overcloud_deploy.py']",8,08d9f082eab97dcf42de516c3b7d2a65ed9d325c,bug/1896757," disable_prepare = parsed_args.disable_container_prepare verbosity_level=utils.playbook_verbosity(self=self), disable_image_params_prepare=disable_prepare verbosity_level=utils.playbook_verbosity(self=self), disable_image_params_prepare=disable_prepare ""ssh_user_name"": parsed_args.overcloud_ssh_user parser.add_argument( '--disable-container-prepare', action='store_true', default=False, help=_('Disable the container preparation actions to prevent ' 'container tags from being updated and new containers ' 'from being fetched. If you skip this but do not have ' 'the container parameters configured, the deployment ' 'action may fail.') )"," verbosity_level=utils.playbook_verbosity(self=self) verbosity_level=utils.playbook_verbosity(self=self) ""ssh_user_name"": parsed_args.overcloud_ssh_user,",120,40
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I48665379a87e701633be1bcc90bd8be1cc75c513,openstack/tripleo-heat-templates,stable/train,I48665379a87e701633be1bcc90bd8be1cc75c513,Split network validation to it's own play,MERGED,2021-01-29 14:31:50.000000000,2021-02-09 00:22:01.000000000,2021-02-09 00:22:01.000000000,"[{'_account_id': 14985}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-29 14:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80cc64673da84551ad5c4e5b09240fd9558e6cf8', 'message': ""Split network validation to it's own play\n\nWhen we moved the network deployment to free, we can hit a race\ncondition where some nodes are being configured prior to the controllers\nbeing ready. This can lead to the basic network validation failing.  We\ncan deal with this by moving the validation to it's own play so that we\nensure all network configurations have occurred prior to to checking\nthat nodes can ping the controllers.\n\nChange-Id: I48665379a87e701633be1bcc90bd8be1cc75c513\nCloses-Bug: #1913725\n(cherry picked from commit 6b98423dd63d426e9eb2bae33ecebc57df407f7e)\n""}, {'number': 2, 'created': '2021-01-29 14:34:42.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/05c8592732f992790699ee385828b01ca3cad5b1', 'message': ""Split network validation to it's own play\n\nWhen we moved the network deployment to free, we can hit a race\ncondition where some nodes are being configured prior to the controllers\nbeing ready. This can lead to the basic network validation failing.  We\ncan deal with this by moving the validation to it's own play so that we\nensure all network configurations have occurred prior to to checking\nthat nodes can ping the controllers.\n\nChange-Id: I48665379a87e701633be1bcc90bd8be1cc75c513\nCloses-Bug: #1913725\n(cherry picked from commit 64e735898b8fae7643fc092fed840d867a252046)\n""}]",0,773072,05c8592732f992790699ee385828b01ca3cad5b1,17,4,2,14985,,,0,"Split network validation to it's own play

When we moved the network deployment to free, we can hit a race
condition where some nodes are being configured prior to the controllers
being ready. This can lead to the basic network validation failing.  We
can deal with this by moving the validation to it's own play so that we
ensure all network configurations have occurred prior to to checking
that nodes can ping the controllers.

Change-Id: I48665379a87e701633be1bcc90bd8be1cc75c513
Closes-Bug: #1913725
(cherry picked from commit 64e735898b8fae7643fc092fed840d867a252046)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/773072/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,80cc64673da84551ad5c4e5b09240fd9558e6cf8,bug/1913725-stable/train," tags: - overcloud - pre_deploy_steps {% endraw %} - hosts: {{primary_role_name}}:DEPLOY_TARGET_HOST strategy: tripleo_free name: Server deployments gather_facts: ""{% raw %}{{ gather_facts | default(false) }}{% endraw %}"" any_errors_fatal: yes tasks: {% raw %}",,11,0
openstack%2Fkayobe~stable%2Ftrain~I7fa88a203274c3030b3d8e5208f94b2230d43c68,openstack/kayobe,stable/train,I7fa88a203274c3030b3d8e5208f94b2230d43c68,Fix /tmp/swift-rings/backups/ files deletion,MERGED,2021-01-22 17:19:34.000000000,2021-02-08 23:52:24.000000000,2021-02-08 23:50:51.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23871}]","[{'number': 1, 'created': '2021-01-22 17:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/6b38a9032a6a54a5f45ba0ccb0d3fc7216fa3941', 'message': 'Fix /tmp/swift-rings/backups/ files deletion\n\nAdd permission escalation to the swift ring generation playbook\n\nTask: 41256\nStory: 2008354\nChange-Id: I7fa88a203274c3030b3d8e5208f94b2230d43c68\n(cherry picked from commit f811d3148ac542f32b476146ffc791aa4ea72693)\n'}, {'number': 2, 'created': '2021-01-27 09:21:01.000000000', 'files': ['ansible/roles/swift-rings/tasks/main.yml', 'releasenotes/notes/story-2008354-0c34e2ad7aeb7d3d.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/f4a8db8f9d94142979bbf6183062f30e42a3cae8', 'message': 'Fix /tmp/swift-rings/backups/ files deletion\n\nAdd permission escalation to the swift ring generation playbook\n\nTask: 41256\nStory: 2008354\nChange-Id: I7fa88a203274c3030b3d8e5208f94b2230d43c68\n(cherry picked from commit f811d3148ac542f32b476146ffc791aa4ea72693)\n'}]",0,771928,f4a8db8f9d94142979bbf6183062f30e42a3cae8,23,4,2,14826,,,0,"Fix /tmp/swift-rings/backups/ files deletion

Add permission escalation to the swift ring generation playbook

Task: 41256
Story: 2008354
Change-Id: I7fa88a203274c3030b3d8e5208f94b2230d43c68
(cherry picked from commit f811d3148ac542f32b476146ffc791aa4ea72693)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/28/771928/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/swift-rings/tasks/main.yml', 'releasenotes/notes/story-2008354-0c34e2ad7aeb7d3d.yaml']",2,6b38a9032a6a54a5f45ba0ccb0d3fc7216fa3941,,--- fixes: - | Fixes issue with deleting swift ring temporary files. See `story 2008354 <https://storyboard.openstack.org/#!/story/2008354>`__ for details. ,,7,0
openstack%2Fmanila~master~I6a1ada102a40f3e83fe8e5287856d01dd137ea95,openstack/manila,master,I6a1ada102a40f3e83fe8e5287856d01dd137ea95,"[devstack] Setup a ""shared-file-system"" service",MERGED,2021-02-05 07:47:21.000000000,2021-02-08 23:45:15.000000000,2021-02-08 23:42:02.000000000,"[{'_account_id': 6413}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30002}, {'_account_id': 32594}, {'_account_id': 32595}]","[{'number': 1, 'created': '2021-02-05 07:47:21.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/27f01aaa7692614c2e72498418a85545a2aed512', 'message': '[devstack] Setup a ""shared-file-system"" service\n\nA few releases ago, service types were standardized\nacross OpenStack [1] and manila\'s service type was\nrecommended as ""shared-file-system"" [2]. Tools were\nmeant to look at the service-types-authority [3]\nand os-service-types repository [4] to find a list\nof standard service type names for various first\nparty OpenStack services.\n\nThe openstacksdk currently relies on the service\ntype to be ""shared-file-system"" [5], so let\'s set\none up in devstack, to aid contributors working on\nopenstacksdk.\n\nIt is desirable to have all clients to initially\nlook for the standard service type name in the\ncloud\'s service catalog, and fall back to the\nlegacy name (""sharev2"") in environments that\ncall the v2 API that.\n\n[1] https://specs.openstack.org/openstack/service-types-authority/\n[2] https://service-types.openstack.org/service-types.json\n[3] https://opendev.org/openstack/service-types-authority\n[4] https://opendev.org/openstack/os-service-types\n[5] https://opendev.org/openstack/openstacksdk/src/commit/f4dd6fe5fd21fb866b43330ecbbafee5cf553ded/openstack/_services_mixin.py#L71-L72\n\nChange-Id: I6a1ada102a40f3e83fe8e5287856d01dd137ea95\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",0,774202,27f01aaa7692614c2e72498418a85545a2aed512,15,7,1,16643,,,0,"[devstack] Setup a ""shared-file-system"" service

A few releases ago, service types were standardized
across OpenStack [1] and manila's service type was
recommended as ""shared-file-system"" [2]. Tools were
meant to look at the service-types-authority [3]
and os-service-types repository [4] to find a list
of standard service type names for various first
party OpenStack services.

The openstacksdk currently relies on the service
type to be ""shared-file-system"" [5], so let's set
one up in devstack, to aid contributors working on
openstacksdk.

It is desirable to have all clients to initially
look for the standard service type name in the
cloud's service catalog, and fall back to the
legacy name (""sharev2"") in environments that
call the v2 API that.

[1] https://specs.openstack.org/openstack/service-types-authority/
[2] https://service-types.openstack.org/service-types.json
[3] https://opendev.org/openstack/service-types-authority
[4] https://opendev.org/openstack/os-service-types
[5] https://opendev.org/openstack/openstacksdk/src/commit/f4dd6fe5fd21fb866b43330ecbbafee5cf553ded/openstack/_services_mixin.py#L71-L72

Change-Id: I6a1ada102a40f3e83fe8e5287856d01dd137ea95
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/02/774202/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,27f01aaa7692614c2e72498418a85545a2aed512,service-type-standardization," # Set up an endpoint for ""shared-file-system"" - this is necessary to # standardize a naming for the v2 API and for the openstacksdk. # See: https://specs.openstack.org/openstack/service-types-authority/ get_or_create_service ""shared-file-system"" ""shared-file-system"" ""Manila Shared Filesystem Service v2 API (alias of the sharev2 service)"" get_or_create_endpoint ""shared-file-system"" ""$REGION_NAME"" \ ""$MANILA_ENDPOINT_BASE/v2"" ",,9,0
openstack%2Fmanila~master~I47e65d23ebfe310643896e1de3396cd627a3def3,openstack/manila,master,I47e65d23ebfe310643896e1de3396cd627a3def3,Enable healthcheck middleware,MERGED,2021-02-01 09:04:07.000000000,2021-02-08 23:43:37.000000000,2021-02-08 23:41:57.000000000,"[{'_account_id': 6413}, {'_account_id': 9816}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2021-02-01 09:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c7b20fe303ea8055a4f76f34dafbc92edb709999', 'message': 'Enable healthcheck middleware\n\nThis change makes healtcheck middleware enabled by default, so that\noperators can use the middleware to monitor service availability for\nvarious purpose like healthcheck by load balancers.\n\nChange-Id: I47e65d23ebfe310643896e1de3396cd627a3def3\n'}, {'number': 2, 'created': '2021-02-03 22:51:50.000000000', 'files': ['etc/manila/api-paste.ini', 'manila/tests/api/test_middleware.py', 'releasenotes/notes/add-healthcheck-middleware-8f659afb7ee0451c.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/1c17ca43827246d66d47dfbb2766fedaf34847ef', 'message': 'Enable healthcheck middleware\n\nThis change makes healtcheck middleware enabled by default, so that\noperators can use the middleware to monitor service availability for\nvarious purpose like healthcheck by load balancers.\n\nChange-Id: I47e65d23ebfe310643896e1de3396cd627a3def3\n'}]",0,773311,1c17ca43827246d66d47dfbb2766fedaf34847ef,27,5,2,9816,,,0,"Enable healthcheck middleware

This change makes healtcheck middleware enabled by default, so that
operators can use the middleware to monitor service availability for
various purpose like healthcheck by load balancers.

Change-Id: I47e65d23ebfe310643896e1de3396cd627a3def3
",git fetch https://review.opendev.org/openstack/manila refs/changes/11/773311/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/manila/api-paste.ini'],1,c7b20fe303ea8055a4f76f34dafbc92edb709999,healthcheck,/healthcheck: healthcheck [app:healthcheck] paste.app_factory = oslo_middleware:Healthcheck.app_factory backends = disable_by_file disable_by_file_path = /etc/manila/healthcheck_disable,,6,0
openstack%2Fbarbican-tempest-plugin~master~Ie586f8eec68d33d08a07ae9c394dcb5fed520e9c,openstack/barbican-tempest-plugin,master,Ie586f8eec68d33d08a07ae9c394dcb5fed520e9c,DNM: Gate health check,ABANDONED,2020-12-15 21:10:27.000000000,2021-02-08 22:56:26.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-15 21:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/bed4b0a9330fe0b54467c49ee93e607041510ea2', 'message': 'DNM: Gate health check\n\nChange-Id: Ie586f8eec68d33d08a07ae9c394dcb5fed520e9c\n'}, {'number': 2, 'created': '2021-02-08 17:30:21.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/5c72ba3e959ab99e201671a75a88d8c28057a9c3', 'message': 'DNM: Gate health check\n\nChange-Id: Ie586f8eec68d33d08a07ae9c394dcb5fed520e9c\n'}]",0,767220,5c72ba3e959ab99e201671a75a88d8c28057a9c3,5,1,2,7973,,,0,"DNM: Gate health check

Change-Id: Ie586f8eec68d33d08a07ae9c394dcb5fed520e9c
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/20/767220/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,bed4b0a9330fe0b54467c49ee93e607041510ea2,,Please report bugs to: https://storyboard.openstack.org/#!/project/openstack/barbican-tempest-plugin ,Please report bugs to: http://bugs.launchpad.net/barbican,1,1
openstack%2Fopenstack-helm-infra~master~I13506ef0b3979004b2be1aa0f46a23d5cb78d065,openstack/openstack-helm-infra,master,I13506ef0b3979004b2be1aa0f46a23d5cb78d065,feat(tls) [WIP] Add tls feature gate to openstack-helm-infra,ABANDONED,2021-02-08 21:53:59.000000000,2021-02-08 22:53:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-08 21:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4c2800f83c3bc04b6f9714d4447ad96bdaa5852a', 'message': 'feat(tls) [WIP] Add tls feature gate to openstack-helm-infra\n\nThis will serve as a feature gate for the openstack-helm-infra\nrepo by turning on tls for the included charts. When tls is\nadded to a chart a job will need to be added here to turn the\ntls on and test that the chart will still deploy correctly.\n\nChange-Id: I13506ef0b3979004b2be1aa0f46a23d5cb78d065\n'}, {'number': 2, 'created': '2021-02-08 21:59:49.000000000', 'files': ['tools/deployment/tls/000-install-packages.sh', 'tools/deployment/tls/005-deploy-k8s.sh', 'tools/deployment/tls/001-cert-manager.sh', 'tools/deployment/tls/020-ingress.sh', 'tools/deployment/tls/030-nfs-provisioner.sh', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2883f7e4ab99a7dbe8459a43989cdaa85960e406', 'message': 'feat(tls) [WIP] Add tls feature gate to openstack-helm-infra\n\nThis will serve as a feature gate for the openstack-helm-infra\nrepo by turning on tls for the included charts. When tls is\nadded to a chart a job will need to be added here to turn the\ntls on and test that the chart will still deploy correctly.\n\nChange-Id: I13506ef0b3979004b2be1aa0f46a23d5cb78d065\n'}]",0,774546,2883f7e4ab99a7dbe8459a43989cdaa85960e406,4,1,2,28849,,,0,"feat(tls) [WIP] Add tls feature gate to openstack-helm-infra

This will serve as a feature gate for the openstack-helm-infra
repo by turning on tls for the included charts. When tls is
added to a chart a job will need to be added here to turn the
tls on and test that the chart will still deploy correctly.

Change-Id: I13506ef0b3979004b2be1aa0f46a23d5cb78d065
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/46/774546/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/tls/000-install-packages.sh', 'tools/deployment/tls/005-deploy-k8s.sh', 'tools/deployment/tls/001-cert-manager.sh', 'tools/deployment/tls/020-ingress.sh', 'tools/deployment/tls/030-nfs-provisioner.sh', 'zuul.d/jobs.yaml']",6,4c2800f83c3bc04b6f9714d4447ad96bdaa5852a,osh-infra-tls-feature-gate," # internal tls gate for osh-infra - job: name: openstack-helm-infra-tls parent: openstack-helm-infra-functional timeout: 7200 pre-run: playbooks/osh-infra-upgrade-host.yaml required-projects: - openstack/openstack-helm-infra - openstack/openstack-helm post-run: playbooks/osh-infra-collect-logs.yaml nodeset: openstack-helm-single-node vars: osh_params: openstack_release: train container_distro_version: bionic feature_gates: ""tls"" gate_scripts_relative_path: ../openstack-helm-infra gate_scripts: - ./tools/deployment/tls/000-install-packages.sh - ./tools/deployment/tls/005-deploy-k8s.sh - ./tools/deployment/tls/001-cert-manager.sh - ./tools/deployment/tls/020-ingress.sh - ./tools/deployment/tls/030-nfs-provisioner.sh",,200,0
openstack%2Fnova~master~I859be652eb8fff591899a223193bd9efc8830cf3,openstack/nova,master,I859be652eb8fff591899a223193bd9efc8830cf3,fup: Merge duplicate volume attachment checks,MERGED,2021-02-01 12:34:53.000000000,2021-02-08 22:49:04.000000000,2021-02-08 22:45:32.000000000,"[{'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-01 12:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9afcb555ade74bcd1c75eefbe4d7195b7eb950e', 'message': 'fup: Merge duplicate volume attachment checks\n\nThis is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where\nit was noted that we could merge these checks into one using a single db\nquery for all active volume attachments for a given volume. This\nrequires changes to the BlockDeviceMappingList object and was thus left\nas a separate change to allow the original to be backported.\n\nChange-Id: I859be652eb8fff591899a223193bd9efc8830cf3\n'}, {'number': 2, 'created': '2021-02-01 12:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89fcf48b2d625c1c61208b76276aae4b18bd268d', 'message': 'fup: Merge duplicate volume attachment checks\n\nThis is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where\nit was noted that we could merge these checks into one using a single db\nquery for all active volume attachments for a given volume. This\nrequires changes to the BlockDeviceMappingList object and was thus left\nas a separate change to allow the original to be backported.\n\nChange-Id: I859be652eb8fff591899a223193bd9efc8830cf3\n'}, {'number': 3, 'created': '2021-02-01 14:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b172c7027a168304277ae83a35c373165607ef71', 'message': 'fup: Merge duplicate volume attachment checks\n\nThis is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where\nit was noted that we could merge these checks into one using a single db\nquery for all active volume attachments for a given volume. This\nrequires changes to the BlockDeviceMappingList object and was thus left\nas a separate change to allow the original to be backported.\n\nChange-Id: I859be652eb8fff591899a223193bd9efc8830cf3\n'}, {'number': 4, 'created': '2021-02-03 11:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0bad8ba942ff9d5a8f4dd449bf43e92f8363c2a9', 'message': 'fup: Merge duplicate volume attachment checks\n\nThis is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where\nit was noted that we could merge these checks into one using a single db\nquery for all active volume attachments for a given volume. This\nrequires changes to the BlockDeviceMappingList object and was thus left\nas a separate change to allow the original to be backported.\n\nChange-Id: I859be652eb8fff591899a223193bd9efc8830cf3\n'}, {'number': 5, 'created': '2021-02-04 14:05:41.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_block_device.py', 'nova/objects/block_device.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/81b689e5bbae446e0b9da7ad604640aa7abe47e4', 'message': 'fup: Merge duplicate volume attachment checks\n\nThis is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where\nit was noted that we could merge these checks into one using a single db\nquery for all active volume attachments for a given volume. This\nrequires changes to the BlockDeviceMappingList object and was thus left\nas a separate change to allow the original to be backported.\n\nChange-Id: I859be652eb8fff591899a223193bd9efc8830cf3\n'}]",19,773380,81b689e5bbae446e0b9da7ad604640aa7abe47e4,33,4,5,10135,,,0,"fup: Merge duplicate volume attachment checks

This is a follow up to I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a where
it was noted that we could merge these checks into one using a single db
query for all active volume attachments for a given volume. This
requires changes to the BlockDeviceMappingList object and was thus left
as a separate change to allow the original to be backported.

Change-Id: I859be652eb8fff591899a223193bd9efc8830cf3
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/773380/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_block_device.py', 'nova/objects/block_device.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py']",5,a9afcb555ade74bcd1c75eefbe4d7195b7eb950e,," @mock.patch.object(objects.BlockDeviceMappingList, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_reserve, mock_record ): @mock.patch.object(objects.BlockDeviceMappingList, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_reserve, mock_record ): @mock.patch.object(objects.BlockDeviceMappingList, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_reserve ): @mock.patch.object(objects.BlockDeviceMappingList, 'get_by_volume') def test_attach_volume_bdm_exists(self, mock_by_volume): mock_by_volume.return_value = [ mock.Mock( spec=objects.BlockDeviceMapping, volume_id=uuids.volume, instance_uuid=uuids.instance ) ] '_check_volume_already_attached', self.context, instance, volumes[uuids.new_volume]) self.context, instance, volumes[uuids.new_volume]) self.compute_api, '_check_volume_already_attached',"," @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume_and_instance') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve, mock_record ): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume_and_instance') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve, mock_record ): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume_and_instance') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve ): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') @mock.patch.object( objects.BlockDeviceMapping, 'get_by_volume_and_instance') def test_attach_volume_bdm_exists(self, mock_by_instance, mock_by_volume): mock_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id=uuids.volume) mock_by_volume.return_value = mock.Mock( spec=objects.BlockDeviceMapping, volume_id=uuids.volume, instance_uuid=uuids.instance) '_check_volume_already_attached_to_instance', self.context, instance, uuids.new_volume) self.context, instance, uuids.new_volume) self.compute_api, '_check_volume_already_attached_to_instance',",100,80
openstack%2Fnova~master~I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a,openstack/nova,master,I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a,api: Reject volume attach requests when an active bdm exists,MERGED,2020-12-24 13:28:53.000000000,2021-02-08 22:47:51.000000000,2021-02-08 22:45:02.000000000,"[{'_account_id': 4690}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-24 13:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32193531fa5a51155d670a03cac75fd5733d4975', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}, {'number': 2, 'created': '2021-01-04 11:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f1f7d6700e267df5611802880f4ac19cace96b5', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}, {'number': 3, 'created': '2021-01-27 15:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc9e70697d81c997fb251f90e2f26376bc8fce98', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}, {'number': 4, 'created': '2021-02-01 12:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/429f202a64a54ddf89d5cd41b93f9a6328c089da', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}, {'number': 5, 'created': '2021-02-01 14:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54b581c489af72eac6b2580eb176c95ae3196c18', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}, {'number': 6, 'created': '2021-02-04 14:05:41.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1908075.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1252588d4e48da1d3a753639a8a4d937acf3e037', 'message': 'api: Reject volume attach requests when an active bdm exists\n\nWhen attaching volumes to instances Nova has previously relied on checks\ncarried out by c-api to ensure that a single non-multiattach volume is\nnot attached to multiple instances at once. While this works well in\nmost cases it does not handle PEBKAC issues when admins reset the state\nof a volume to available, allowing users to request that Nova attach the\nvolume to another instance.\n\nThis change aims to address this by including a simple check in the\nattach flow for non-multiattach volumes ensuring that there are no\nexisting active block device mapping records for the volume already\npresent within Nova.\n\nCloses-Bug: #1908075\nChange-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a\n'}]",21,768472,1252588d4e48da1d3a753639a8a4d937acf3e037,45,5,6,10135,,,0,"api: Reject volume attach requests when an active bdm exists

When attaching volumes to instances Nova has previously relied on checks
carried out by c-api to ensure that a single non-multiattach volume is
not attached to multiple instances at once. While this works well in
most cases it does not handle PEBKAC issues when admins reset the state
of a volume to available, allowing users to request that Nova attach the
volume to another instance.

This change aims to address this by including a simple check in the
attach flow for non-multiattach volumes ensuring that there are no
existing active block device mapping records for the volume already
present within Nova.

Closes-Bug: #1908075
Change-Id: I2881d77d52bcbde9f3ac6a6ddfb4a22a9bd45c8a
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/768472/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/regressions/test_bug_1908075.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py']",3,32193531fa5a51155d670a03cac75fd5733d4975,bug/1908075," @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') def test_attach_volume_new_flow( self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve, mock_record): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') mock_get_by_volume.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') def test_tagged_volume_attach_new_flow( self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve, mock_record): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') mock_get_by_volume.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') def test_attach_volume_attachment_create_fails( self, mock_attach, mock_get_by_volume, mock_get_by_instance, mock_reserve): mock_get_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') mock_get_by_volume.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume') @mock.patch.object(objects.BlockDeviceMapping, 'get_by_volume_and_instance') def test_attach_volume_bdm_exists(self, mock_by_instance, mock_by_volume): mock_by_instance.side_effect = exception.VolumeBDMNotFound( volume_id=uuids.volume) mock_by_volume.return_value = mock.Mock( spec=objects.BlockDeviceMapping, volume_id=uuids.volume, instance_uuid=uuids.instance) instance = self._create_instance_obj() volume = {'id': uuids.volume, 'multiattach': False} with mock.patch.object( self.compute_api, 'volume_api', mock.MagicMock(spec=cinder.API) ) as mock_v_api: mock_v_api.get.return_value = volume # Assert that we raise InvalidVolume when we find a bdm for the vol self.assertRaises( exception.InvalidVolume, self.compute_api.attach_volume, self.context, instance, uuids.volume ) "," def test_attach_volume_new_flow(self, mock_attach, mock_bdm, mock_reserve, mock_record): mock_bdm.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') def test_tagged_volume_attach_new_flow(self, mock_attach, mock_bdm, mock_reserve, mock_record): mock_bdm.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id') def test_attach_volume_attachment_create_fails(self, mock_attach, mock_bdm, mock_reserve): mock_bdm.side_effect = exception.VolumeBDMNotFound( volume_id='fake-volume-id')",84,28
openstack%2Ftripleo-common~stable%2Fussuri~I96ab407ba50e2183141daec3341dbb29545d5beb,openstack/tripleo-common,stable/ussuri,I96ab407ba50e2183141daec3341dbb29545d5beb,Check existence of expires_in for auth,MERGED,2021-01-27 16:33:11.000000000,2021-02-08 21:42:32.000000000,2021-02-08 21:40:57.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-27 16:33:11.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cefc6250ee754a743037bc9381884aaae84dd3a4', 'message': ""Check existence of expires_in for auth\n\nIf a registries doesn't provide an expires_in with their token, the\ncurrent code fails doing the comparison. If no such header is included,\nlet's assume there is no expire time so we can just use the cached\ntoken.  If the token expires, we'll reauth as usual.\n\nChange-Id: I96ab407ba50e2183141daec3341dbb29545d5beb\nCloses-Bug: #1912645\n(cherry picked from commit e04774948e8cfa8ac4d2a1f57f0e53e2ef0861ee)\n""}]",0,772718,cefc6250ee754a743037bc9381884aaae84dd3a4,15,4,1,14985,,,0,"Check existence of expires_in for auth

If a registries doesn't provide an expires_in with their token, the
current code fails doing the comparison. If no such header is included,
let's assume there is no expire time so we can just use the cached
token.  If the token expires, we'll reauth as usual.

Change-Id: I96ab407ba50e2183141daec3341dbb29545d5beb
Closes-Bug: #1912645
(cherry picked from commit e04774948e8cfa8ac4d2a1f57f0e53e2ef0861ee)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/18/772718/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,cefc6250ee754a743037bc9381884aaae84dd3a4,bug/1912645-stable/ussuri, expires_in = data.get('expires_in') if not expires_in or (now - token_time).seconds < expires_in:, if (now - token_time).seconds < data.get('expires_in'):,2,1
openstack%2Fnova~master~I639dd5af7c039da546eaf9ccce56cbaaa38fa79a,openstack/nova,master,I639dd5af7c039da546eaf9ccce56cbaaa38fa79a,Add regression test for bug #1908075,MERGED,2020-12-14 15:45:01.000000000,2021-02-08 21:40:36.000000000,2021-02-08 21:38:52.000000000,"[{'_account_id': 4690}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27419}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-12-14 15:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26d246129e94e698e2fff99d092be350a4b08358', 'message': 'Add regression test for bug #1908075\n\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\nRelated-Bug: #1908075\n'}, {'number': 2, 'created': '2020-12-24 13:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/831c35589c7a444c2f42230bde1e8221fe722292', 'message': 'Add regression test for bug #1908075\n\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\nRelated-Bug: #1908075\n'}, {'number': 3, 'created': '2021-01-04 11:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66aed6ca07d29328def40f93812cfca2777154f8', 'message': 'Add regression test for bug #1908075\n\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\nRelated-Bug: #1908075\n'}, {'number': 4, 'created': '2021-01-27 15:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0dd9b699c4c883b62bc90f420ed130c974a85465', 'message': 'Add regression test for bug #1908075\n\nRelated-Bug: #1908075\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\n'}, {'number': 5, 'created': '2021-02-01 12:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccc3343f1932d283e366c9723adb17d63177c586', 'message': 'Add regression test for bug #1908075\n\nRelated-Bug: #1908075\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\n'}, {'number': 6, 'created': '2021-02-01 14:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/091dbd07adf39b1d4d3d2fe8015e9c048a0c6024', 'message': 'Add regression test for bug #1908075\n\nRelated-Bug: #1908075\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\n'}, {'number': 7, 'created': '2021-02-04 14:05:41.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1908075.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ee3a8f02253f1f652785c07ea0be6464ab4bcc11', 'message': 'Add regression test for bug #1908075\n\nRelated-Bug: #1908075\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\n'}]",14,766976,ee3a8f02253f1f652785c07ea0be6464ab4bcc11,56,7,7,10135,,,0,"Add regression test for bug #1908075

Related-Bug: #1908075
Change-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/766976/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1908075.py'],1,26d246129e94e698e2fff99d092be350a4b08358,bug/1908075,"# Copyright 2020, Red Hat, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import context from nova.objects import block_device from nova.tests.functional import integrated_helpers class TestVolAttachCinderReset(integrated_helpers._IntegratedTestBase): """"""Regression test for bug 1908075. This regression test aims to assert if n-api allows a non-multiattached volume to be attached to multiple instances after an admin has forcibly reset the state of the volume in Cinder. """""" microversion = 'latest' def setUp(self): super().setUp() self.context = context.get_admin_context() def test_volume_attach_after_cinder_reset_state(self): volume_id = self.cinder.IMAGE_BACKED_VOL # Launch a server and attach a volume server_a = self._create_server(networks='none') self.api.post_server_volume( server_a['id'], dict(volumeAttachment=dict(volumeId=volume_id))) # reset-state of the volume within the cinder fixture, we don't model # the state of the volume within the fixture so this will have to do. del self.cinder.volume_to_attachment[volume_id] self.assertNotIn( volume_id, self.cinder.volume_ids_for_instance(server_a['id'])) # Launch a second server and attempt to attach the same volume again server_b = self._create_server(networks='none') # FIXME(lyarwood): n-api shouldn't accept this request as we already # have an active bdm record for this non-multiattach volume. self.api.post_server_volume( server_b['id'], dict(volumeAttachment=dict(volumeId=volume_id))) # Assert that we have bdms within Nova still for this attachment block_device.BlockDeviceMapping.get_by_volume_and_instance( self.context, volume_id, server_a['id']) block_device.BlockDeviceMapping.get_by_volume_and_instance( self.context, volume_id, server_a['id']) # Assert that the new attachment is the only one in the fixture self.assertIn( volume_id, self.cinder.volume_ids_for_instance(server_b['id'])) def test_volume_attach_after_cinder_reset_state_multiattach_volume(self): volume_id = self.cinder.MULTIATTACH_VOL # Launch a server and attach a volume server_a = self._create_server(networks='none') self.api.post_server_volume( server_a['id'], dict(volumeAttachment=dict(volumeId=volume_id))) # reset-state of the volume within the cinder fixture, we don't model # the state of the volume within the fixture so this will have to do. del self.cinder.volume_to_attachment[volume_id] self.assertNotIn( volume_id, self.cinder.volume_ids_for_instance(server_a['id'])) # Launch a second server and attempt to attach the same volume again server_b = self._create_server(networks='none') # NOTE(lyarwood): Unlike non-multiattach volumes this should always be # allowed as we can have multiple active bdms for multiattached volumes self.api.post_server_volume( server_b['id'], dict(volumeAttachment=dict(volumeId=volume_id))) # Assert that we have bdms within Nova still for this attachment block_device.BlockDeviceMapping.get_by_volume_and_instance( self.context, volume_id, server_a['id']) block_device.BlockDeviceMapping.get_by_volume_and_instance( self.context, volume_id, server_a['id']) # Assert that the new attachment is the only one in the fixture self.assertIn( volume_id, self.cinder.volume_ids_for_instance(server_b['id'])) ",,100,0
openstack%2Fswift~stable%2Fussuri~I952690558486a1d981985eae0fe9d7e07ff30e17,openstack/swift,stable/ussuri,I952690558486a1d981985eae0fe9d7e07ff30e17,Prevent upgrading to pip 21+,MERGED,2021-02-08 15:38:01.000000000,2021-02-08 21:40:26.000000000,2021-02-08 21:38:45.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 15:38:01.000000000', 'files': ['tools/playbooks/common/install_dependencies.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/69a95a52a5a0dc383d30719be6d5c25273ae631d', 'message': 'Prevent upgrading to pip 21+\n\nChange-Id: I952690558486a1d981985eae0fe9d7e07ff30e17\n(cherry picked from commit 0b870eb94dfe9769a07695b296eaa6758820a5f3)\n'}]",0,774482,69a95a52a5a0dc383d30719be6d5c25273ae631d,7,2,1,15343,,,0,"Prevent upgrading to pip 21+

Change-Id: I952690558486a1d981985eae0fe9d7e07ff30e17
(cherry picked from commit 0b870eb94dfe9769a07695b296eaa6758820a5f3)
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/774482/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/playbooks/common/install_dependencies.yaml'],1,69a95a52a5a0dc383d30719be6d5c25273ae631d,," - name: upgrade pip, but not too far pip: # 20.* works on both py2 and py3, and the pip for centos7 in EPEL # isn't smart enough to prevent us upgrading to 21+ name: pip<21", - name: upgrade pip pip: name: pip,4,2
openstack%2Ftripleo-ansible~master~I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1,openstack/tripleo-ansible,master,I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1,Set source IPv4 address from inventory vars,MERGED,2021-01-19 09:54:36.000000000,2021-02-08 21:12:51.000000000,2021-02-08 21:12:51.000000000,"[{'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-19 09:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/5e4f61b7f814124510f1003e14a648f589f4bfcd', 'message': 'WIP: Set source IPv4 address from inventory vars\n\nCurrently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of\nall nodes in the deployment. An example is as follows from THT:\n\n  FrrBgpIpv4LoopbackMap:\n    ctrl-1-0: 99.99.1.1\n    ctrl-2-0: 99.99.2.1\n    ctrl-3-0: 99.99.3.1\n    cmp-1-0: 99.99.1.2\n    cmp-2-0: 99.99.2.2\n    cmp-3-0: 99.99.3.2\n    cmp-1-1: 99.99.1.3\n    cmp-2-1: 99.99.2.3\n    cmp-3-1: 99.99.3.3\n\nThis is rather time consuming, prone to typos and requires updating at\nnode scale up/down. It would be much easier if users could just pass in\nthe network and have tripleo_frr get the IP from given network.\nSnip from tripleo-ansible-inventory.yaml:\n\n  ControllerRack1:\n    hosts:\n      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,\n        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,\n        [...]\n\nChange-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1\n'}, {'number': 2, 'created': '2021-01-19 18:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/83b4861d6306af088e821535eb3f0f7b2bb27055', 'message': 'WIP: Set source IPv4 address from inventory vars\n\nCurrently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of\nall nodes in the deployment. An example is as follows from THT:\n\n  FrrBgpIpv4LoopbackMap:\n    ctrl-1-0: 99.99.1.1\n    ctrl-2-0: 99.99.2.1\n    ctrl-3-0: 99.99.3.1\n    cmp-1-0: 99.99.1.2\n    cmp-2-0: 99.99.2.2\n    cmp-3-0: 99.99.3.2\n    cmp-1-1: 99.99.1.3\n    cmp-2-1: 99.99.2.3\n    cmp-3-1: 99.99.3.3\n\nThis is rather time consuming, prone to typos and requires updating at\nnode scale up/down. It would be much easier if users could just pass in\nthe network and have tripleo_frr get the IP from given network.\nSnip from tripleo-ansible-inventory.yaml:\n\n  ControllerRack1:\n    hosts:\n      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,\n        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,\n        [...]\n\nChange-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1\n'}, {'number': 3, 'created': '2021-01-22 13:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f37416354d6bcb057e91a733acd07d45b274df01', 'message': 'WIP: Set source IPv4 address from inventory vars\n\nCurrently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of\nall nodes in the deployment. An example is as follows from THT:\n\n  FrrBgpIpv4LoopbackMap:\n    ctrl-1-0: 99.99.1.1\n    ctrl-2-0: 99.99.2.1\n    ctrl-3-0: 99.99.3.1\n    cmp-1-0: 99.99.1.2\n    cmp-2-0: 99.99.2.2\n    cmp-3-0: 99.99.3.2\n    cmp-1-1: 99.99.1.3\n    cmp-2-1: 99.99.2.3\n    cmp-3-1: 99.99.3.3\n\nThis is rather time consuming, prone to typos and requires updating at\nnode scale up/down. It would be much easier if users could just pass in\nthe network and have tripleo_frr get the IP from given network.\nSnip from tripleo-ansible-inventory.yaml:\n\n  ControllerRack1:\n    hosts:\n      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,\n        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,\n        [...]\n\nChange-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1\n'}, {'number': 4, 'created': '2021-01-24 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/755b49ec635d42635f294fff968b799ab1f87689', 'message': 'Set source IPv4 address from inventory vars\n\nCurrently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of\nall nodes in the deployment. An example is as follows from THT:\n\n  FrrBgpIpv4LoopbackMap:\n    ctrl-1-0: 99.99.1.1\n    ctrl-2-0: 99.99.2.1\n    ctrl-3-0: 99.99.3.1\n    cmp-1-0: 99.99.1.2\n    cmp-2-0: 99.99.2.2\n    cmp-3-0: 99.99.3.2\n    cmp-1-1: 99.99.1.3\n    cmp-2-1: 99.99.2.3\n    cmp-3-1: 99.99.3.3\n\nThis is rather time consuming, prone to typos and requires updating at\nnode scale up/down. It would be much easier if users could just pass in\nthe network and have tripleo_frr get the IP from given network.\nSnip from tripleo-ansible-inventory.yaml:\n\n  ControllerRack1:\n    hosts:\n      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,\n        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,\n        [...]\n\nChange-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1\n'}, {'number': 5, 'created': '2021-02-08 11:44:35.000000000', 'files': ['tripleo_ansible/roles/tripleo_frr/defaults/main.yml', 'tripleo_ansible/roles/tripleo_frr/templates/frr.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7d89d70342dd8512bc9580d855eb186e4309d691', 'message': 'Set source IPv4 address from inventory vars\n\nCurrently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of\nall nodes in the deployment. An example is as follows from THT:\n\n  FrrBgpIpv4LoopbackMap:\n    ctrl-1-0: 99.99.1.1\n    ctrl-2-0: 99.99.2.1\n    ctrl-3-0: 99.99.3.1\n    cmp-1-0: 99.99.1.2\n    cmp-2-0: 99.99.2.2\n    cmp-3-0: 99.99.3.2\n    cmp-1-1: 99.99.1.3\n    cmp-2-1: 99.99.2.3\n    cmp-3-1: 99.99.3.3\n\nThis is rather time consuming, prone to typos and requires updating at\nnode scale up/down. It would be much easier if users could just pass in\nthe network and have tripleo_frr get the IP from given network.\nSnip from tripleo-ansible-inventory.yaml:\n\n  ControllerRack1:\n    hosts:\n      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,\n        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,\n        [...]\n\nChange-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1\n'}]",0,771393,7d89d70342dd8512bc9580d855eb186e4309d691,21,4,5,6469,,,0,"Set source IPv4 address from inventory vars

Currently users have to pass in a dictionary of HOSTNAME:SOURCE_IPV4 of
all nodes in the deployment. An example is as follows from THT:

  FrrBgpIpv4LoopbackMap:
    ctrl-1-0: 99.99.1.1
    ctrl-2-0: 99.99.2.1
    ctrl-3-0: 99.99.3.1
    cmp-1-0: 99.99.1.2
    cmp-2-0: 99.99.2.2
    cmp-3-0: 99.99.3.2
    cmp-1-1: 99.99.1.3
    cmp-2-1: 99.99.2.3
    cmp-3-1: 99.99.3.3

This is rather time consuming, prone to typos and requires updating at
node scale up/down. It would be much easier if users could just pass in
the network and have tripleo_frr get the IP from given network.
Snip from tripleo-ansible-inventory.yaml:

  ControllerRack1:
    hosts:
      ctrl-1-0: {ansible_host: 192.168.1.101, canonical_hostname: ctrl-1-0.bgp.ftw,
        main_network_hostname: ctrl-1-0.mainnetwork.bgp.ftw, main_network_ip: 99.99.1.1,
        [...]

Change-Id: I43852cb3570b8cb12a35f4bc641a42ddfd8ad7f1
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/93/771393/5 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_frr/defaults/main.yml', 'tripleo_ansible/roles/tripleo_frr/templates/frr.conf.j2']",2,5e4f61b7f814124510f1003e14a648f589f4bfcd,bgpsupport, set src {{ hostvars[host][tripleo_frr_bgp_ipv4_src_network ~ '_ip'] }},{% if tripleo_frr_bgp_ipv4_default_src_map|length > 0 and tripleo_frr_hostname in tripleo_frr_bgp_ipv4_default_src_map %} set src {{ tripleo_frr_bgp_ipv4_default_src_map[tripleo_frr_hostname] }}{% endif %} {# tripleo_frr_bgp_ipv4_default_src_map #},2,4
openstack%2Frequirements~stable%2Ftrain~I4bf84bc29abba99e3e8ac8d68e90bd70bcbeed94,openstack/requirements,stable/train,I4bf84bc29abba99e3e8ac8d68e90bd70bcbeed94,update constraint for tripleo-common to new release 11.5.0,MERGED,2021-02-08 14:05:25.000000000,2021-02-08 20:58:57.000000000,2021-02-08 20:58:57.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 14:05:25.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1a9489aa828ef8a0eb9586367f9694eade30c634', 'message': 'update constraint for tripleo-common to new release 11.5.0\n\nmeta: version: 11.5.0\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Előd Illés <elod.illes@est.tech>\nmeta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I4bf84bc29abba99e3e8ac8d68e90bd70bcbeed94\n'}]",0,774465,1a9489aa828ef8a0eb9586367f9694eade30c634,7,3,1,11131,,,0,"update constraint for tripleo-common to new release 11.5.0

meta: version: 11.5.0
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Előd Illés <elod.illes@est.tech>
meta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I4bf84bc29abba99e3e8ac8d68e90bd70bcbeed94
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/774465/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,1a9489aa828ef8a0eb9586367f9694eade30c634,new-release,tripleo-common===11.5.0,tripleo-common===11.4.0,1,1
openstack%2Fopenstack-ansible~stable%2Fvictoria~I2f77611f9b5f712d017e51fb6751a51d1e985671,openstack/openstack-ansible,stable/victoria,I2f77611f9b5f712d017e51fb6751a51d1e985671,Bump SHAs for stable/victoria,MERGED,2021-01-31 18:09:02.000000000,2021-02-08 20:49:06.000000000,2021-02-08 20:46:31.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-31 18:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3ca111f6d349772bed2af03edd304499929f7e22', 'message': 'Bump SHAs for stable/victoria\n\nChange-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671\n'}, {'number': 2, 'created': '2021-02-04 14:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/05cab97a93c19ab2da6101fb39c0f9d3a30dcc3d', 'message': 'Bump SHAs for stable/victoria\n\nChange-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671\n'}, {'number': 3, 'created': '2021-02-04 20:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/85773556b0e0b4038581048851e8ad8be7dd978c', 'message': 'Bump SHAs for stable/victoria\n\nChange-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671\n'}, {'number': 4, 'created': '2021-02-08 10:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/39b0a85eb0c1b30df948feb6f1b34f29559a1334', 'message': 'Bump SHAs for stable/victoria\n\nChange-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671\n'}, {'number': 5, 'created': '2021-02-08 10:06:11.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e1dc35d8e10d01d8823065cccfb5c8f341be7446', 'message': 'Bump SHAs for stable/victoria\n\nChange-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671\n'}]",0,773264,e1dc35d8e10d01d8823065cccfb5c8f341be7446,29,4,5,28619,,,0,"Bump SHAs for stable/victoria

Change-Id: I2f77611f9b5f712d017e51fb6751a51d1e985671
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/773264/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,3ca111f6d349772bed2af03edd304499929f7e22,bump_osa, version: 9af2d8a58e12e08559fbb970760bb566d0b80140 version: d12a8aa6c5f7af293e6b127795a13becd3d223d0 version: c0a96656f1c38dcf7c4097106c466b4e4ced5f1c version: 36cff3fb06f85d4128603ae062cfe8d0bf5448a5 version: fa9177d2ce9d6259b3ce548f8bc71e4c4a009589 version: 2e32d1a9e07e0bd91446087ae1c5652b779f8a0e, version: 9a5ed4586fdaf3183e583571abc62f20542a6b60 version: 8928157640130ff6c9053f0e34f4f670264b3b1f version: 2b7b2ada9fc0ce7c0ca5508f6432627dc70edbac version: 586f0e9f9e6dd0f0466a2fa686c5c865f69106ac version: 54f7983be281f88714cbc75d393efa637e37ce17 version: 7a08ccfb5410906d5b9291180fc2cfe7ba382e01,61,61
openstack%2Fpython-tripleoclient~stable%2Ftrain~Id94132d23d272d383b65a839a75b08f855fb6be3,openstack/python-tripleoclient,stable/train,Id94132d23d272d383b65a839a75b08f855fb6be3,[Validator Show Run] Display simplified results by default,MERGED,2021-02-01 11:17:04.000000000,2021-02-08 20:41:19.000000000,2021-02-08 20:39:28.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27419}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-02-01 11:17:04.000000000', 'files': ['tripleoclient/v1/tripleo_validator.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8ddfc7d5f1f7a8b20d9c0be8604fba35b464601c', 'message': '[Validator Show Run] Display simplified results by default\n\nThis patch is displaying the content of the validation_output dictionary\nwhich is a simplified output content (the former validation_output)\ninstead of dumping the entire log file in the stdout.\n\nIt also fixes the --full argument which was True forever!\n\nChange-Id: Id94132d23d272d383b65a839a75b08f855fb6be3\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\n(cherry picked from commit 4229bee94016ad5a78dd8455f282a8e7f4a3d28e)\n(cherry picked from commit 7873e6d800d75119730c7cd8ff1152fe08aa1c49)\n(cherry picked from commit 0f91bcce72633ef9f1e006460aca8ce1c3dec83a)\n'}]",0,773367,8ddfc7d5f1f7a8b20d9c0be8604fba35b464601c,17,6,1,11491,,,0,"[Validator Show Run] Display simplified results by default

This patch is displaying the content of the validation_output dictionary
which is a simplified output content (the former validation_output)
instead of dumping the entire log file in the stdout.

It also fixes the --full argument which was True forever!

Change-Id: Id94132d23d272d383b65a839a75b08f855fb6be3
Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
(cherry picked from commit 4229bee94016ad5a78dd8455f282a8e7f4a3d28e)
(cherry picked from commit 7873e6d800d75119730c7cd8ff1152fe08aa1c49)
(cherry picked from commit 0f91bcce72633ef9f1e006460aca8ce1c3dec83a)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/67/773367/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_validator.py'],1,8ddfc7d5f1f7a8b20d9c0be8604fba35b464601c,train," for p in d.get('validation_output', []): print(json.dumps(p['tasks'], indent=4, sort_keys=True))"," default=True, for p in d['plays']: print(json.dumps(p['tasks'], indent=4, sort_keys=True))",4,3
openstack%2Fkayobe~stable%2Ftrain~Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,openstack/kayobe,stable/train,Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,Fix --limit with commas,MERGED,2021-01-15 16:59:59.000000000,2021-02-08 20:39:47.000000000,2021-02-08 20:38:00.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-15 16:59:59.000000000', 'files': ['kayobe/kolla_ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/ansible.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/b3dd061250745f81bfcde292f13464eb8203eba2', 'message': 'Fix --limit with commas\n\nKayobe allows specifying a --limit argument, which is passed through to\nAnsible. In some cases we wish to add an intersection with a group. This\nallows us to reuse playbooks for the seed, overcloud etc.\n\nFor example, the lvm.yml playbook specifies a host list of\nseed-hypervisor:seed:overcloud. When executed as part of a kayobe\novercloud host configure command, Kayobe passes a limit of overcloud. If\nthe user specifies a --limit argument, this gets intersected with the\novercloud limit: host1:&overcloud.\n\nThe problem happens if the user specifies multiple parts to the host\npattern in their limit using a comma, e.g. host1,host2. This results in\nhost1,host2:&overcloud. Ansible ignores the colon, and treats this as\nhost1 or host2:&overcloud.\n\nThe solution is to use a comma to join the patterns if the user has used\na comma: host1,host2,&overcloud\n\nChange-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d\nStory: 2008255\nTask: 41111\n(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)\n'}]",0,770960,b3dd061250745f81bfcde292f13464eb8203eba2,16,3,1,14826,,,0,"Fix --limit with commas

Kayobe allows specifying a --limit argument, which is passed through to
Ansible. In some cases we wish to add an intersection with a group. This
allows us to reuse playbooks for the seed, overcloud etc.

For example, the lvm.yml playbook specifies a host list of
seed-hypervisor:seed:overcloud. When executed as part of a kayobe
overcloud host configure command, Kayobe passes a limit of overcloud. If
the user specifies a --limit argument, this gets intersected with the
overcloud limit: host1:&overcloud.

The problem happens if the user specifies multiple parts to the host
pattern in their limit using a comma, e.g. host1,host2. This results in
host1,host2:&overcloud. Ansible ignores the colon, and treats this as
host1 or host2:&overcloud.

The solution is to use a comma to join the patterns if the user has used
a comma: host1,host2,&overcloud

Change-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d
Story: 2008255
Task: 41111
(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/60/770960/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/kolla_ansible.py', 'kayobe/ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml']",5,b3dd061250745f81bfcde292f13464eb8203eba2,,--- fixes: - | Fixes an issue when using the ``--limit`` argument with a host pattern including commas. See `story 2008255 <https://storyboard.openstack.org/#!/story/2008255>`__ for details. ,,74,4
openstack%2Fopenstack-helm~master~I413f1ea33e1a52919d68a1bdb6208eedca655497,openstack/openstack-helm,master,I413f1ea33e1a52919d68a1bdb6208eedca655497,Update placement release notes to current,MERGED,2021-02-03 20:39:44.000000000,2021-02-08 19:59:15.000000000,2021-02-08 19:56:44.000000000,"[{'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 20:39:44.000000000', 'files': ['releasenotes/notes/placement.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/eab84e55bc25c234a604e8692ef41d5f08b5b88e', 'message': 'Update placement release notes to current\n\nChange-Id: I413f1ea33e1a52919d68a1bdb6208eedca655497\n'}]",0,773998,eab84e55bc25c234a604e8692ef41d5f08b5b88e,11,5,1,24780,,,0,"Update placement release notes to current

Change-Id: I413f1ea33e1a52919d68a1bdb6208eedca655497
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/98/773998/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/placement.yaml'],1,eab84e55bc25c234a604e8692ef41d5f08b5b88e,placement-reno," - 0.1.1 Change helm-toolkit dependency version to "">= 0.1.0"" - 0.1.2 Establish Nova/Placement dependencies - 0.1.3 Use proper default placement image - 0.1.4 Add null check condition in placement deployment manifest - 0.1.5 Change Issuer to ClusterIssuer - 0.1.6 Revert - Change Issuer to ClusterIssuer",,6,0
openstack%2Fironic-tempest-plugin~master~I3f39b25ee0fd44c1bc51f94a7fbee74de8cba65d,openstack/ironic-tempest-plugin,master,I3f39b25ee0fd44c1bc51f94a7fbee74de8cba65d,Reconfigure tox.ini,MERGED,2021-01-23 17:48:00.000000000,2021-02-08 19:51:59.000000000,2021-02-08 19:50:12.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-23 17:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/a6fc025f4ff8dce321c3062109f83d9da9800994', 'message': 'Reconfigure tox.ini\n\nUpdate minversion of tox to 3.9.0 to support inline comments [1]\n\nMove pep8 and coverage requirements to tox.ini\n\nFix typo in coverage job\n\n[1] https://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17\n\nChange-Id: I3f39b25ee0fd44c1bc51f94a7fbee74de8cba65d\n'}, {'number': 2, 'created': '2021-01-25 09:19:48.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/13de53a462ad6f9aa27ed740626f1d5666f5f532', 'message': 'Reconfigure tox.ini\n\nUpdate minversion of tox to 3.9.0 to support inline comments [1]\n\nMove pep8 and coverage requirements to tox.ini\n\nFix typo in coverage job\n\n[1] https://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17\n\nChange-Id: I3f39b25ee0fd44c1bc51f94a7fbee74de8cba65d\n'}]",0,772162,13de53a462ad6f9aa27ed740626f1d5666f5f532,10,3,2,23851,,,0,"Reconfigure tox.ini

Update minversion of tox to 3.9.0 to support inline comments [1]

Move pep8 and coverage requirements to tox.ini

Fix typo in coverage job

[1] https://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17

Change-Id: I3f39b25ee0fd44c1bc51f94a7fbee74de8cba65d
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/62/772162/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,a6fc025f4ff8dce321c3062109f83d9da9800994,tox-min-version-parse-comments,"minversion = 3.9.0deps = hacking>=3.1.0,<4.0.0 # Apache-2.0 flake8-import-order>=0.17.1 # LGPLv3 pycodestyle>=2.0.0,<2.7.0 # MITdeps = {[testenv]deps} coverage!=4.4,>=4.0 # Apache-2.0 coverage html -d cover",minversion = 3.2.1 coverage htlm -d cover,9,8
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~Iaa6fdef24599072f5a31c1fd2da29c276399c83d,openstack/tripleo-heat-templates,stable/victoria,Iaa6fdef24599072f5a31c1fd2da29c276399c83d,Add post delay to reboot,MERGED,2021-02-05 10:02:40.000000000,2021-02-08 19:44:15.000000000,2021-02-08 19:44:15.000000000,"[{'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-05 10:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/93954432adff03d787f580640919731df32cee78', 'message': 'Add post delay to reboot\n\nLeapp may reconfigure network after main upgrade. Also systemd may bring\ndown and up again network unit. This patch adds post_reboot_delay as 2 min to\nmitigate such issues which can be configurable as heat variable in\ncustomers env files for some very specific cases. Also test_command is\nchanged from whoami to systemctl to have better assesment when a system\ncompleted its boot.\n\nCloses-Bug: rhbz#1920293\n\nChange-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d\n(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)\n'}, {'number': 2, 'created': '2021-02-05 10:10:50.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1dc7be85bbeab9e979a3462a89c192e7933836d3', 'message': 'Add post delay to reboot\n\nLeapp may reconfigure network after main upgrade. Also systemd may bring\ndown and up again network unit. This patch adds post_reboot_delay as 2 min to\nmitigate such issues which can be configurable as heat variable in\ncustomers env files for some very specific cases. Also test_command is\nchanged from whoami to systemctl to have better assesment when a system\ncompleted its boot.\n\nCloses-Bug: rhbz#1920293\n\nChange-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d\n(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)\n'}]",0,774124,1dc7be85bbeab9e979a3462a89c192e7933836d3,12,5,2,6816,,,0,"Add post delay to reboot

Leapp may reconfigure network after main upgrade. Also systemd may bring
down and up again network unit. This patch adds post_reboot_delay as 2 min to
mitigate such issues which can be configurable as heat variable in
customers env files for some very specific cases. Also test_command is
changed from whoami to systemctl to have better assesment when a system
completed its boot.

Closes-Bug: rhbz#1920293

Change-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d
(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/774124/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,93954432adff03d787f580640919731df32cee78,fix_reboot-stable/victoria," UpgradeLeappPostRebootDelay: description: | Maximum (seconds) to wait for machine to reboot and respond to a test command. type: number default: 120 pgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout} upgrade_leapp_post_reboot_delay: {get_param: UpgradeLeappPostRebootDelay} test_command: >- systemctl is-system-running | grep -e running -e degraded post_reboot_delay: ""{{ upgrade_leapp_post_reboot_delay }}""", upgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout},11,1
openstack%2Fkolla-ansible~master~I7bcf5039ecb455d5ad73c8d413dbbe89d00da6e9,openstack/kolla-ansible,master,I7bcf5039ecb455d5ad73c8d413dbbe89d00da6e9,Add neutron genericswitch driver,NEW,2020-12-03 11:25:11.000000000,2021-02-08 19:43:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-12-03 11:25:11.000000000', 'files': ['ansible/roles/neutron/tasks/precheck.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/group_vars/all.yml', 'etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/16c46f2ae64550e51475d26a53d714342a7482f0', 'message': 'Add neutron genericswitch driver\n\nWhen ironic use multi-tenancy network need switch vlan.\nneutron-server need the genericswitch driver supported.\n\nChange-Id: I7bcf5039ecb455d5ad73c8d413dbbe89d00da6e9\n'}]",1,765314,16c46f2ae64550e51475d26a53d714342a7482f0,4,2,1,31310,,,0,"Add neutron genericswitch driver

When ironic use multi-tenancy network need switch vlan.
neutron-server need the genericswitch driver supported.

Change-Id: I7bcf5039ecb455d5ad73c8d413dbbe89d00da6e9
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/14/765314/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/neutron/tasks/precheck.yml', 'ansible/group_vars/all.yml', 'ansible/roles/neutron/defaults/main.yml', 'etc/kolla/globals.yml']",4,16c46f2ae64550e51475d26a53d714342a7482f0,neutron_add_networking_generic_switch,"#enable_neutron_genericswitch_driver: ""{{ enable_neutron | bool and enable_ironic | bool }}""",,13,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ie91633c2bcc8011cc62b46452ea5b444cf12029f,openstack/tripleo-heat-templates,stable/ussuri,Ie91633c2bcc8011cc62b46452ea5b444cf12029f,Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware,MERGED,2021-02-08 06:27:44.000000000,2021-02-08 19:26:08.000000000,2021-02-08 19:26:08.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-02-08 06:27:44.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d38c3df912487b35d1c79994cb42032bcb46ee12', 'message': 'Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware\n\nSince multiple types of computes can be deployed, we should allow the\ncustomization of these containers to be role specific.\n\nConflicts:\n      deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: Ie91633c2bcc8011cc62b46452ea5b444cf12029f\n(cherry picked from commit 1471976c6eaf635bc0808dc0f0c6b9cd61654732)\n'}]",0,774395,d38c3df912487b35d1c79994cb42032bcb46ee12,10,8,1,20733,,,0,"Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware

Since multiple types of computes can be deployed, we should allow the
customization of these containers to be role specific.

Conflicts:
      deployment/nova/nova-compute-container-puppet.yaml

Change-Id: Ie91633c2bcc8011cc62b46452ea5b444cf12029f
(cherry picked from commit 1471976c6eaf635bc0808dc0f0c6b9cd61654732)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/95/774395/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,d38c3df912487b35d1c79994cb42032bcb46ee12,," tags: - role_specific tags: - role_specific nova_compute_opt_volumes: NovaComputeOptVolumes nova_compute_opt_env_vars: NovaComputeOptEnvVars NovaComputeOptVolumes: {get_param: NovaComputeOptVolumes} NovaComputeOptEnvVars: {get_param: NovaComputeOptEnvVars} - {get_attr: [RoleParametersValue, value, nova_compute_opt_volumes]} - {get_attr: [RoleParametersValue, value, nova_compute_opt_env_vars]}", - {get_param: NovaComputeOptVolumes} - {get_param: NovaComputeOptEnvVars},10,2
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ie91633c2bcc8011cc62b46452ea5b444cf12029f,openstack/tripleo-heat-templates,stable/train,Ie91633c2bcc8011cc62b46452ea5b444cf12029f,Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware,MERGED,2021-02-08 08:14:56.000000000,2021-02-08 19:26:01.000000000,2021-02-08 19:26:01.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}, {'_account_id': 29268}]","[{'number': 1, 'created': '2021-02-08 08:14:56.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/28cb354c353bef41b2679d49b8c3ae13bcaef626', 'message': 'Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware\n\nSince multiple types of computes can be deployed, we should allow the\ncustomization of these containers to be role specific.\n\nConflicts:\n      deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: Ie91633c2bcc8011cc62b46452ea5b444cf12029f\n(cherry picked from commit 1471976c6eaf635bc0808dc0f0c6b9cd61654732)\n(cherry picked from commit d38c3df912487b35d1c79994cb42032bcb46ee12)\n'}]",0,774417,28cb354c353bef41b2679d49b8c3ae13bcaef626,9,9,1,20733,,,0,"Make NovaComputeOptVolumes and NovaComputeOptEnvVars role aware

Since multiple types of computes can be deployed, we should allow the
customization of these containers to be role specific.

Conflicts:
      deployment/nova/nova-compute-container-puppet.yaml

Change-Id: Ie91633c2bcc8011cc62b46452ea5b444cf12029f
(cherry picked from commit 1471976c6eaf635bc0808dc0f0c6b9cd61654732)
(cherry picked from commit d38c3df912487b35d1c79994cb42032bcb46ee12)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/774417/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,28cb354c353bef41b2679d49b8c3ae13bcaef626,," tags: - role_specific tags: - role_specific nova_compute_opt_volumes: NovaComputeOptVolumes nova_compute_opt_env_vars: NovaComputeOptEnvVars NovaComputeOptVolumes: {get_param: NovaComputeOptVolumes} NovaComputeOptEnvVars: {get_param: NovaComputeOptEnvVars} - {get_attr: [RoleParametersValue, value, nova_compute_opt_volumes]} - {get_attr: [RoleParametersValue, value, nova_compute_opt_env_vars]}", - {get_param: NovaComputeOptVolumes} - {get_param: NovaComputeOptEnvVars},10,2
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I1133c210f35181d44f8ba56f09b52f00589e035c,openstack/tripleo-heat-templates,stable/train,I1133c210f35181d44f8ba56f09b52f00589e035c,Live migration optimization with HP,MERGED,2021-01-26 19:53:48.000000000,2021-02-08 19:23:12.000000000,2021-02-08 19:21:18.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24245}]","[{'number': 1, 'created': '2021-01-26 19:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fcc1fe3faf38027ff7fc0c5ff2ed0b3129bf9ab3', 'message': 'Live migration optimization with HP\n\nWhen a node has hugepages enabled, we can help with live migrations by\nenabling NovaLiveMigrationPermitPostCopy and\nNovaLiveMigrationPermitAutoConverge.\n\nRelated: https://bugzilla.redhat.com/1298201\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: I1133c210f35181d44f8ba56f09b52f00589e035c\n(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)\n(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)\n(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)\n'}, {'number': 2, 'created': '2021-01-27 03:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2fec76e758256f17d44b5d95e05130a144ab8de3', 'message': 'Live migration optimization with HP\n\nWhen a node has hugepages enabled, we can help with live migrations by\nenabling NovaLiveMigrationPermitPostCopy and\nNovaLiveMigrationPermitAutoConverge.\n\nRelated: https://bugzilla.redhat.com/1298201\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: I1133c210f35181d44f8ba56f09b52f00589e035c\n(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)\n(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)\n(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)\n'}, {'number': 3, 'created': '2021-02-03 01:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7b9c3d88bb0a6f34a85e0170cb57c9ed68e97880', 'message': 'Live migration optimization with HP\n\nWhen a node has hugepages enabled, we can help with live migrations by\nenabling NovaLiveMigrationPermitPostCopy and\nNovaLiveMigrationPermitAutoConverge.\n\nRelated: https://bugzilla.redhat.com/1298201\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: I1133c210f35181d44f8ba56f09b52f00589e035c\n(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)\n(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)\n(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)\n'}, {'number': 4, 'created': '2021-02-03 16:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80c83cc24b8fdada450c2c73348d992d915196d3', 'message': 'Live migration optimization with HP\n\nWhen a node has hugepages enabled, we can help with live migrations by\nenabling NovaLiveMigrationPermitPostCopy and\nNovaLiveMigrationPermitAutoConverge.\n\nRelated: https://bugzilla.redhat.com/1298201\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: I1133c210f35181d44f8ba56f09b52f00589e035c\n(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)\n(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)\n(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)\n'}, {'number': 5, 'created': '2021-02-05 17:00:44.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova-live-migration-permit-postcopy-autoconverge-ca1719fd2abed45f.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/43b7188ef524c9eec5ee59faae29ffdf62c2de90', 'message': 'Live migration optimization with HP\n\nWhen a node has hugepages enabled, we can help with live migrations by\nenabling NovaLiveMigrationPermitPostCopy and\nNovaLiveMigrationPermitAutoConverge.\n\nRelated: https://bugzilla.redhat.com/1298201\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: I1133c210f35181d44f8ba56f09b52f00589e035c\n(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)\n(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)\n(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)\n'}]",0,772544,43b7188ef524c9eec5ee59faae29ffdf62c2de90,24,8,5,27419,,,0,"Live migration optimization with HP

When a node has hugepages enabled, we can help with live migrations by
enabling NovaLiveMigrationPermitPostCopy and
NovaLiveMigrationPermitAutoConverge.

Related: https://bugzilla.redhat.com/1298201

Conflicts:
  deployment/nova/nova-compute-container-puppet.yaml

Change-Id: I1133c210f35181d44f8ba56f09b52f00589e035c
(cherry picked from commit df207fd2e94e9604cdf48e82cd1dcafb660eadc8)
(cherry picked from commit d4a3253d9326d0a890feb29794612420506fb866)
(cherry picked from commit aa4382ee83d40070d72785b23a5ff7fa459b6c04)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/772544/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova-live-migration-permit-postcopy-autoconverge-ca1719fd2abed45f.yaml']",2,fcc1fe3faf38027ff7fc0c5ff2ed0b3129bf9ab3,live-migration-optimization,"--- features: - | When a node has hugepages enabled, we can help with live migrations by enabling `NovaLiveMigrationPermitPostCopy` and `NovaLiveMigrationPermitAutoConverge`. These flags are automatically enabled if hugepages are detected, but operators can override these settings. ",,67,1
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I1b4e26fd4a46599985a989441f493a3ed39237bb,openstack/tripleo-heat-templates,stable/victoria,I1b4e26fd4a46599985a989441f493a3ed39237bb,Use include_role for conditional inclusion,MERGED,2021-02-01 12:49:41.000000000,2021-02-08 19:21:24.000000000,2021-02-08 19:21:24.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-01 12:49:41.000000000', 'files': ['deployment/metrics/collectd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9e271664adaed5d5cd3fee03f99e72ba6ab2f1bf', 'message': 'Use include_role for conditional inclusion\n\nWhen import_role is used with a condition, the condition is\napplied to all tasks in the role. This is inefficient. If we\nuse include_role instead, then the role inclusion task is\nskipped and none of the tasks in the role are even evaluated.\n\nRelated-bug: rhbz#1922132\n\nChange-Id: I1b4e26fd4a46599985a989441f493a3ed39237bb\n(cherry picked from commit 46df551a0f00cf143ddd5cd9c651b08a13a79fb0)\n'}]",0,773207,9e271664adaed5d5cd3fee03f99e72ba6ab2f1bf,15,5,1,6816,,,0,"Use include_role for conditional inclusion

When import_role is used with a condition, the condition is
applied to all tasks in the role. This is inefficient. If we
use include_role instead, then the role inclusion task is
skipped and none of the tasks in the role are even evaluated.

Related-bug: rhbz#1922132

Change-Id: I1b4e26fd4a46599985a989441f493a3ed39237bb
(cherry picked from commit 46df551a0f00cf143ddd5cd9c651b08a13a79fb0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/07/773207/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/metrics/collectd-container-puppet.yaml'],1,9e271664adaed5d5cd3fee03f99e72ba6ab2f1bf,, include_role:, import_role:,1,1
openstack%2Fbifrost~master~I764f2b44de62d79fddc0a1d139b9b3f9ee270e5c,openstack/bifrost,master,I764f2b44de62d79fddc0a1d139b9b3f9ee270e5c,Update version of doc8,MERGED,2021-01-18 08:48:16.000000000,2021-02-08 19:11:19.000000000,2021-02-08 19:09:22.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 32102}, {'_account_id': 32231}]","[{'number': 1, 'created': '2021-01-18 08:48:16.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/57a4f1bf2f4b0e896824614b03d2c00ac4353cfe', 'message': 'Update version of doc8\n\nThe doc8 lib supports Py36 starting from version 0.8.1\n\nChange-Id: I764f2b44de62d79fddc0a1d139b9b3f9ee270e5c\n'}]",0,771169,57a4f1bf2f4b0e896824614b03d2c00ac4353cfe,10,5,1,32291,,,0,"Update version of doc8

The doc8 lib supports Py36 starting from version 0.8.1

Change-Id: I764f2b44de62d79fddc0a1d139b9b3f9ee270e5c
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/69/771169/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,57a4f1bf2f4b0e896824614b03d2c00ac4353cfe,, doc8>=0.8.1 # Apache-2.0, doc8>=0.6.0 # Apache-2.0,1,1
openstack%2Frequirements~stable%2Ftrain~Iaac32d3edc938e568b454bc5359da3a6bce234d1,openstack/requirements,stable/train,Iaac32d3edc938e568b454bc5359da3a6bce234d1,update constraint for os-refresh-config to new release 10.4.1,MERGED,2021-02-08 13:56:58.000000000,2021-02-08 18:55:46.000000000,2021-02-08 18:55:46.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:56:58.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ef0b8aca68b279bf5567fe5917bdbf036b514079', 'message': 'update constraint for os-refresh-config to new release 10.4.1\n\nmeta: version: 10.4.1\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Előd Illés <elod.illes@est.tech>\nmeta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: Iaac32d3edc938e568b454bc5359da3a6bce234d1\n'}]",0,774462,ef0b8aca68b279bf5567fe5917bdbf036b514079,7,3,1,11131,,,0,"update constraint for os-refresh-config to new release 10.4.1

meta: version: 10.4.1
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Előd Illés <elod.illes@est.tech>
meta: release:Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: Iaac32d3edc938e568b454bc5359da3a6bce234d1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/62/774462/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ef0b8aca68b279bf5567fe5917bdbf036b514079,new-release,os-refresh-config===10.4.1,os-refresh-config===10.4.0,1,1
openstack%2Foslo.serialization~stable%2Ftrain~I3c416e855cb5f0dc32d14b2749ba92aba8964574,openstack/oslo.serialization,stable/train,I3c416e855cb5f0dc32d14b2749ba92aba8964574,Fix json to_primitive when using IO OBjects,MERGED,2021-02-05 09:26:32.000000000,2021-02-08 18:35:28.000000000,2021-02-08 18:33:37.000000000,"[{'_account_id': 15334}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2021-02-05 09:26:32.000000000', 'files': ['releasenotes/notes/bug-1908607-fix-json-to_primitive-IO-OBjects-04faff4a1b5cf48f.yaml', 'oslo_serialization/tests/test_jsonutils.py', 'oslo_serialization/jsonutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/a9c4bfab354496827ec802f60a46c531107f5de4', 'message': ""Fix json to_primitive when using IO OBjects\n\nCurrently, using Cinder's backup service with RBD the\nbackup-create operation gets stuck when logging\n('use_json=True' must be set in the config file).\n\nThe oslo.log JSONFormatter gets stuck when passing an\nRBDVolumeIOWrapper from os-brick. This happens via os-brick's\nutils.trace() method which passes a connector containing\n{'path': RBDVolumeIOWrapper}.\nThe oslo.log JSONFormatter format() method calls\noslo_serialization's jsonutils.to_primitive and passes in\nthis RBDVolumeIOWrapper object.\n\xa0\nTherefore the to_primitive method eventually calls\nRBDVolumeIOWrapper.read(). In order to fix this the current\npath avoids mapping io.IOBase objects and fallback the wrapper\nRBD volume object.\n\nCo-authored-by: Eric Harney <eharney@redhat.com>\nCloses-Bug: #1908607\nChange-Id: I3c416e855cb5f0dc32d14b2749ba92aba8964574\n(cherry picked from commit 02037330d863ecbe2471b63bff5461dee6a3c024)\n(cherry picked from commit fcd737e2b19a4fee58db79281b336342f0f09d7b)\n(cherry picked from commit ab5c68d301dcd409a1112da6f2f89b0f2fc13183)\n""}]",0,774210,a9c4bfab354496827ec802f60a46c531107f5de4,8,4,1,28522,,,0,"Fix json to_primitive when using IO OBjects

Currently, using Cinder's backup service with RBD the
backup-create operation gets stuck when logging
('use_json=True' must be set in the config file).

The oslo.log JSONFormatter gets stuck when passing an
RBDVolumeIOWrapper from os-brick. This happens via os-brick's
utils.trace() method which passes a connector containing
{'path': RBDVolumeIOWrapper}.
The oslo.log JSONFormatter format() method calls
oslo_serialization's jsonutils.to_primitive and passes in
this RBDVolumeIOWrapper object.
 
Therefore the to_primitive method eventually calls
RBDVolumeIOWrapper.read(). In order to fix this the current
path avoids mapping io.IOBase objects and fallback the wrapper
RBD volume object.

Co-authored-by: Eric Harney <eharney@redhat.com>
Closes-Bug: #1908607
Change-Id: I3c416e855cb5f0dc32d14b2749ba92aba8964574
(cherry picked from commit 02037330d863ecbe2471b63bff5461dee6a3c024)
(cherry picked from commit fcd737e2b19a4fee58db79281b336342f0f09d7b)
(cherry picked from commit ab5c68d301dcd409a1112da6f2f89b0f2fc13183)
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/10/774210/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1908607-fix-json-to_primitive-IO-OBjects-04faff4a1b5cf48f.yaml', 'oslo_serialization/tests/test_jsonutils.py', 'oslo_serialization/jsonutils.py']",3,a9c4bfab354496827ec802f60a46c531107f5de4,fix-json-primitive,"import io elif hasattr(value, '__iter__') and not isinstance(value, io.IOBase):"," elif hasattr(value, '__iter__'):",18,1
openstack%2Fopenstack-helm-infra~master~I18d08eb00c86c1022fdc2599d88ac5429ad661a6,openstack/openstack-helm-infra,master,I18d08eb00c86c1022fdc2599d88ac5429ad661a6,[CEPH] Update release notes for all ceph charts,MERGED,2021-02-08 14:32:04.000000000,2021-02-08 18:27:47.000000000,2021-02-08 18:25:33.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 18511}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}, {'_account_id': 29974}, {'_account_id': 30746}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-08 14:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8e34cf72c7bdea32d17b3b408e29b218469225c6', 'message': '[CEPH] Update ceph-client release notes to current\n\nThis change updates the releasenotes for all ceph charts to current\nchanges as of the date of this commit.\n\nChange-Id: I18d08eb00c86c1022fdc2599d88ac5429ad661a6\n'}, {'number': 2, 'created': '2021-02-08 14:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d5ce57db83c403f415f1ee92c09e9063227e5c87', 'message': '[CEPH] Update release notes for all ceph charts\n\nThis change updates the releasenotes for all ceph charts to current\nchanges as of the date of this commit.\n\nChange-Id: I18d08eb00c86c1022fdc2599d88ac5429ad661a6\n'}, {'number': 3, 'created': '2021-02-08 16:09:31.000000000', 'files': ['releasenotes/notes/ceph-provisioners.yaml', 'releasenotes/notes/ceph-mon.yaml', 'releasenotes/notes/ceph-client.yaml', 'releasenotes/notes/ceph-rgw.yaml', 'releasenotes/notes/ceph-osd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/41b86c1071c9f841e4da0c96af30fafb16811a48', 'message': '[CEPH] Update release notes for all ceph charts\n\nThis change updates the releasenotes for all ceph charts to current\nchanges as of the date of this commit.\n\nChange-Id: I18d08eb00c86c1022fdc2599d88ac5429ad661a6\n'}]",1,774471,41b86c1071c9f841e4da0c96af30fafb16811a48,20,13,3,28372,,,0,"[CEPH] Update release notes for all ceph charts

This change updates the releasenotes for all ceph charts to current
changes as of the date of this commit.

Change-Id: I18d08eb00c86c1022fdc2599d88ac5429ad661a6
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/71/774471/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ceph-provisioners.yaml', 'releasenotes/notes/ceph-client.yaml', 'releasenotes/notes/ceph-mon.yaml', 'releasenotes/notes/ceph-rgw.yaml', 'releasenotes/notes/ceph-osd.yaml']",5,8e34cf72c7bdea32d17b3b408e29b218469225c6,, - 0.1.18 Uplift from Nautilus to Octopus release,,6,0
openstack%2Fpuppet-tripleo~master~Ic2c86e6a890b58ca7703ea3a3147c8d4ecf13953,openstack/puppet-tripleo,master,Ic2c86e6a890b58ca7703ea3a3147c8d4ecf13953,Add parameters for multipath connection in cinder store,MERGED,2021-02-02 16:12:17.000000000,2021-02-08 18:21:12.000000000,2021-02-08 18:21:12.000000000,"[{'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 16:12:17.000000000', 'files': ['spec/classes/tripleo_profile_base_glance_backend_cinder_spec.rb', 'manifests/profile/base/glance/backend/cinder.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/9466c801bc75857334d5b4c8caf0b4175c6fbdc8', 'message': 'Add parameters for multipath connection in cinder store\n\nAdding following 2 parameters for cinder store when multipath usage is\nenabled in volume connection,\n\n - cinder_enforce_multipath\n - cinder_use_multipath\n\nChange-Id: Ic2c86e6a890b58ca7703ea3a3147c8d4ecf13953\n'}]",0,773722,9466c801bc75857334d5b4c8caf0b4175c6fbdc8,8,4,1,19138,,,0,"Add parameters for multipath connection in cinder store

Adding following 2 parameters for cinder store when multipath usage is
enabled in volume connection,

 - cinder_enforce_multipath
 - cinder_use_multipath

Change-Id: Ic2c86e6a890b58ca7703ea3a3147c8d4ecf13953
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/22/773722/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/tripleo_profile_base_glance_backend_cinder_spec.rb', 'manifests/profile/base/glance/backend/cinder.pp']",2,9466c801bc75857334d5b4c8caf0b4175c6fbdc8,cinder-multipath,"# [*cinder_enforce_multipath*] # (Optional) Set to True when multipathd is enabled # Defaults to hiera('glance::backend::cinder::cinder_enforce_multipath', undef) # # [*cinder_use_multipath*] # (Optional) Set to True when multipathd is enabled # Defaults to hiera('glance::backend::cinder::cinder_use_multipath', undef) # $cinder_enforce_multipath = hiera('glance::backend::cinder::cinder_enforce_multipath', undef), $cinder_use_multipath = hiera('glance::backend::cinder::cinder_use_multipath', undef), cinder_enforce_multipath => $cinder_enforce_multipath, cinder_use_multipath => $cinder_use_multipath,",,16,0
openstack%2Fcinder~master~I611855199722a3880e1b18133a8472e1ebe82e6c,openstack/cinder,master,I611855199722a3880e1b18133a8472e1ebe82e6c,Pure Storage: Add IPv6 CIDR support,ABANDONED,2021-01-05 16:02:38.000000000,2021-02-08 18:11:47.000000000,,"[{'_account_id': 13425}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 16:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c4158048f62616dd8bed7e620ff9fd9c4ef1b60b', 'message': 'Pure Storage: Add IPv6 CIDR support\n\nAdd new configuration parameter pure_iscsi_cidr_v6 to allow for\nIPv6 CIDR range support.\n\nChange-Id: I611855199722a3880e1b18133a8472e1ebe82e6c\nCloses-Bug: 1910143\n'}, {'number': 2, 'created': '2021-01-05 16:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4521865652769034fcaca24e553a6c653e5df19a', 'message': 'Pure Storage: Add IPv6 CIDR support\n\nAdd new configuration parameter pure_iscsi_cidr_v6 to allow for\nIPv6 CIDR range support.\n\nChange-Id: I611855199722a3880e1b18133a8472e1ebe82e6c\nCloses-Bug: 1910143\n'}, {'number': 3, 'created': '2021-01-20 14:24:17.000000000', 'files': ['cinder/volume/drivers/pure.py', 'releasenotes/notes/pure-storage-ipv6-26d781a8827ceb5a.yaml', 'cinder/tests/unit/volume/drivers/test_pure.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bf0867110956d4e05fcea099d26bacd886f67b86', 'message': 'Pure Storage: Add IPv6 CIDR support\n\nAdd new configuration parameter pure_iscsi_cidr_v6 to allow for\nIPv6 CIDR range support.\n\nChange-Id: I611855199722a3880e1b18133a8472e1ebe82e6c\nCloses-Bug: 1910143\n'}]",0,769391,bf0867110956d4e05fcea099d26bacd886f67b86,59,2,3,13425,,,0,"Pure Storage: Add IPv6 CIDR support

Add new configuration parameter pure_iscsi_cidr_v6 to allow for
IPv6 CIDR range support.

Change-Id: I611855199722a3880e1b18133a8472e1ebe82e6c
Closes-Bug: 1910143
",git fetch https://review.opendev.org/openstack/cinder refs/changes/91/769391/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/pure.py', 'releasenotes/notes/pure-storage-ipv6-26d781a8827ceb5a.yaml', 'cinder/tests/unit/volume/drivers/test_pure.py']",3,c4158048f62616dd8bed7e620ff9fd9c4ef1b60b,bug/1910143,"ISCSI_CIDR_V6 = ""::/0"" self.mock_config.pure_iscsi_cidr_v6 = ISCSI_CIDR_V6",,38,9
openstack%2Ftripleo-common~master~I259a0d5fcbae8f8a6bbeffa5fdb744d3291315ad,openstack/tripleo-common,master,I259a0d5fcbae8f8a6bbeffa5fdb744d3291315ad,Handle containers without a namespace,MERGED,2021-01-29 18:36:21.000000000,2021-02-08 18:03:50.000000000,2021-02-08 18:02:04.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-29 18:36:21.000000000', 'files': ['tripleo_common/image/image_export.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7e797317a33a5c5881a1e24b9666ae774ca224c0', 'message': 'Handle containers without a namespace\n\nSatellite server does not include a namespace when exposing containers.\nThis change fixes our image-serve metadata creation to understand this\nconcept and build the _catalog we provide correctly. We will only handle\ntwo types of containers path structures with the image-serve.\n\n   * host:port/namespace/container:tag\n   * host:port/container:tag\n\nChange-Id: I259a0d5fcbae8f8a6bbeffa5fdb744d3291315ad\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/773164\nCloses-Bug: #1913782\n'}]",3,773166,7e797317a33a5c5881a1e24b9666ae774ca224c0,13,7,1,14985,,,0,"Handle containers without a namespace

Satellite server does not include a namespace when exposing containers.
This change fixes our image-serve metadata creation to understand this
concept and build the _catalog we provide correctly. We will only handle
two types of containers path structures with the image-serve.

   * host:port/namespace/container:tag
   * host:port/container:tag

Change-Id: I259a0d5fcbae8f8a6bbeffa5fdb744d3291315ad
Depends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/773164
Closes-Bug: #1913782
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/66/773166/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_export.py'],1,7e797317a33a5c5881a1e24b9666ae774ca224c0,bug/1913782," metadata_set = set(['blobs', 'manifests', 'tags']) contents_set = set(os.listdir(namespace_path)) # handle containers with no namespaces if metadata_set.issubset(contents_set): catalog_entries.append(namespace) for image in list(contents_set - metadata_set):", for image in os.listdir(namespace_path):,6,1
openstack%2Ftripleo-quickstart~master~Ifca4714ed189fc57655382325e45b1678b470cdb,openstack/tripleo-quickstart,master,Ifca4714ed189fc57655382325e45b1678b470cdb,Add --disable-validations in extra-args for fs020,MERGED,2021-02-08 06:38:20.000000000,2021-02-08 18:03:38.000000000,2021-02-08 18:02:00.000000000,"[{'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-08 06:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/bd66418847442c6db4e1339e3997e5b4cd668b5e', 'message': 'Add --disable-validations in extra-args for fs020\n\nWe have enabled baremetal provisioning for fs020 with [1]. Because\n--disable-validations is missing we are hitting bug[2].\nfs001 and fs035 already have this option.[3]\n\n[1] https://review.opendev.org/c/openstack/tripleo-quickstart/+/773648\n[2] https://bugs.launchpad.net/tripleo/+bug/1914982\n[3] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L80-L82\n\nCloses-Bug: #1914982\nChange-Id: Ifca4714ed189fc57655382325e45b1678b470cdb\n'}, {'number': 2, 'created': '2021-02-08 07:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d0df8474903c023443a5029b5280af3fc833208d', 'message': ""Add --disable-validations in extra-args for fs020\n\nWe have enabled baremetal provisioning for fs020 with [1]. Because\n--disable-validations is missing for ussuri/victoria we are hitting\nbug[2]. fs001 and fs035 already have disable-validations flag.[3]\n\nIn master we don't need to disable validations anymore with pre-deployed\nOvercloud nodes, details in [4].\n\nOther featureset need update as well to remove --disable-validations for\nmaster branch, but as this option is in multiple places[5] lets do that in\nseparate patch.\n\n[1] https://review.opendev.org/c/openstack/tripleo-quickstart/+/773648\n[2] https://bugs.launchpad.net/tripleo/+bug/1914982\n[3] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L80-L82\n[4] https://review.opendev.org/c/openstack/tripleo-docs/+/771970/4/deploy-guide/source/features/deployed_server.rst\n[5] https://codesearch.opendev.org/?q=--disable-validations&i=nope&files=&excludeFiles=&repos=openstack/tripleo-quickstart\n\nCloses-Bug: #1914982\nChange-Id: Ifca4714ed189fc57655382325e45b1678b470cdb\n""}, {'number': 3, 'created': '2021-02-08 07:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/abd9be85541ad367ad09f5ff3d8af408d039c484', 'message': ""Add --disable-validations in extra-args for fs020\n\nWe have enabled baremetal provisioning for fs020 with [1]. Because\n--disable-validations is missing for ussuri/victoria we are hitting\nbug[2]. fs001 and fs035 already have disable-validations flag.[3]\n\nIn master we don't need to disable validations anymore with\npre-deployed Overcloud nodes, details in [4].\n\nOther featureset need update as well to remove --disable-validations\nfor master branch, but as this option is in multiple places[5] lets\ndo that in separate patch.\n\n[1] https://review.opendev.org/c/openstack/tripleo-quickstart/+/773648\n[2] https://bugs.launchpad.net/tripleo/+bug/1914982\n[3] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L80-L82\n[4] https://review.opendev.org/c/openstack/tripleo-docs/+/771970/4/deploy-guide/source/features/deployed_server.rst\n[5] https://codesearch.opendev.org/?q=--disable-validations&i=nope&files=&excludeFiles=&repos=openstack/tripleo-quickstart\n\nCloses-Bug: #1914982\nChange-Id: Ifca4714ed189fc57655382325e45b1678b470cdb\n""}, {'number': 4, 'created': '2021-02-08 08:28:26.000000000', 'files': ['config/general_config/featureset020.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a75507714623ae42246c65d0f191e3ccabb00009', 'message': ""Add --disable-validations in extra-args for fs020\n\nWe have enabled baremetal provisioning for fs020 with [1]. Because\n--disable-validations is missing for ussuri/victoria we are hitting\nbug[2]. fs001 and fs035 already have disable-validations flag.[3]\n\nIn master we don't need to disable validations anymore with\npre-deployed Overcloud nodes, details in [4].\n\nOther featureset need update as well to remove --disable-validations\nfor master branch, but as this option is in multiple places[5] lets\ndo that in separate patch.\n\n[1] https://review.opendev.org/c/openstack/tripleo-quickstart/+/773648\n[2] https://bugs.launchpad.net/tripleo/+bug/1914982\n[3] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L80-L82\n[4] https://review.opendev.org/c/openstack/tripleo-docs/+/771970/4/deploy-guide/source/features/deployed_server.rst\n[5] https://codesearch.opendev.org/?q=--disable-validations&i=nope&files=&excludeFiles=&repos=openstack/tripleo-quickstart\n\nCloses-Bug: #1914982\nChange-Id: Ifca4714ed189fc57655382325e45b1678b470cdb\n""}]",1,774416,a75507714623ae42246c65d0f191e3ccabb00009,15,4,4,29775,,,0,"Add --disable-validations in extra-args for fs020

We have enabled baremetal provisioning for fs020 with [1]. Because
--disable-validations is missing for ussuri/victoria we are hitting
bug[2]. fs001 and fs035 already have disable-validations flag.[3]

In master we don't need to disable validations anymore with
pre-deployed Overcloud nodes, details in [4].

Other featureset need update as well to remove --disable-validations
for master branch, but as this option is in multiple places[5] lets
do that in separate patch.

[1] https://review.opendev.org/c/openstack/tripleo-quickstart/+/773648
[2] https://bugs.launchpad.net/tripleo/+bug/1914982
[3] https://opendev.org/openstack/tripleo-quickstart/src/branch/master/config/general_config/featureset001.yml#L80-L82
[4] https://review.opendev.org/c/openstack/tripleo-docs/+/771970/4/deploy-guide/source/features/deployed_server.rst
[5] https://codesearch.opendev.org/?q=--disable-validations&i=nope&files=&excludeFiles=&repos=openstack/tripleo-quickstart

Closes-Bug: #1914982
Change-Id: Ifca4714ed189fc57655382325e45b1678b470cdb
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/16/774416/4 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset020.yml'],1,bd66418847442c6db4e1339e3997e5b4cd668b5e,bug/1914982," {% if release not in ['queens','rocky','stein','train'] -%} --disable-validations",,2,0
openstack%2Fpython-magnumclient~master~Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446,openstack/python-magnumclient,master,Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446,Add CT tags argument and field to client,MERGED,2020-06-24 15:55:18.000000000,2021-02-08 17:55:09.000000000,2021-02-08 14:00:49.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-06-24 15:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/6f12552cb15a9c1d50d2669e82bbc7d719b5a301', 'message': 'observations argument for admin CT info\n\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\n'}, {'number': 2, 'created': '2020-06-24 16:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/33c0acfd5b24f689ae856431417d93702e191f4a', 'message': 'Observations argument for admin CT info\n\nA new argument is added to show admin of cluster_templates\nobservations. This field was added with the intention of\nsignaling users the status of the user visible\ncluster_templates with observations like:\n{deprecated, recommended, testing}.\n\nstory: 2004215\ntask: 40161\n\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n'}, {'number': 3, 'created': '2020-06-24 16:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/c50656850958bebfc7b161240eabc35a284f817e', 'message': ""Add CT observations argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--observations <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 4, 'created': '2020-08-27 11:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/9b53bb7e9b56fd23f496e0f7f41ed462ae1761fd', 'message': ""Add CT observations argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--observations <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 5, 'created': '2020-08-27 12:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/1e06377d1d4dd528dde37b78ea71a641ab4f61f4', 'message': ""Add CT observations argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--observations <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 6, 'created': '2020-10-22 14:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/616b753b22a36c94f1cc1500743a13cc915641e8', 'message': ""Add CT observations argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--observations <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 7, 'created': '2020-10-22 14:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/f52cce905980d229034a7e1816746ad5145f3f1f', 'message': ""Add CT tags argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--tags <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 8, 'created': '2021-01-28 18:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/2c2ca23a940636a3194679c76afc6e9a83cb20d5', 'message': ""Add CT tags argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--tags <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 9, 'created': '2021-02-05 09:14:54.000000000', 'files': ['magnumclient/v1/basemodels.py', 'releasenotes/notes/add-ct-tags-argument-3129c5038e95757e.yaml', 'magnumclient/osc/v1/cluster_templates.py', 'magnumclient/tests/osc/unit/v1/test_cluster_templates.py', 'magnumclient/tests/osc/unit/v1/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/201b3527b06a9716338bbc9a5cfa5bb661c76a96', 'message': ""Add CT tags argument and field to client\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch allows the magnumclient to pass the\n--tags <text> when creating a cluster template\nand also shows the observations available when listing\nexistent cluster templates.\n\nstory: 2004215\ntask: 40161\n\nDepends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nChange-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}]",4,737837,201b3527b06a9716338bbc9a5cfa5bb661c76a96,42,5,9,29425,,,0,"Add CT tags argument and field to client

We noticed that from the user perspective it is hard
to know when a cluster_template provided by the cloud
admin is mature enough for a production release.
This field will allow the administrator to add an
annotation to the cluster template like
{deprecated, recommended, testing} giving further
usefull information to the end user about the
template's life cycle

This patch allows the magnumclient to pass the
--tags <text> when creating a cluster template
and also shows the observations available when listing
existent cluster templates.

story: 2004215
task: 40161

Depends-On: I5d1c4221f089bc5cd12b25f620aa01771a029df9
Change-Id: Ibbdc9a9cd7ae4733eb6d38a7db11a68866f0d446
Signed-off-by: Diogo Guerra <dy090.guerra@gmail.com>
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/37/737837/3 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/v1/basemodels.py', 'magnumclient/osc/v1/cluster_templates.py', 'magnumclient/tests/osc/unit/v1/fakes.py']",3,6f12552cb15a9c1d50d2669e82bbc7d719b5a301,observations," 'hidden': False, 'observations': """"", 'hidden': False,15,6
openstack%2Fneutron~master~Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb,openstack/neutron,master,Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb,Stop metadata proxy gracefully,MERGED,2021-02-02 17:31:04.000000000,2021-02-08 17:55:05.000000000,2021-02-08 17:51:49.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 17:31:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b481a61c77e65623c6d4c44d9130129ed82229ee', 'message': 'Stop metadata proxy gracefully\n\nHAProxy supports hard stop [1] via SIGTERM signal. From the\ndocumentation:\n\n  """"""\n  ... when the SIGTERM signal is sent to the haproxy process,\n  it immediately quits and all established connections are\n  closed.\n  """"""\n\nIn case the process does not finish, the SIGKILL signal is sent.\nThe PID file created by the process is deleted.\n\n[1]https://cbonte.github.io/haproxy-dconv/2.0/management.html#4\n\nCloses-Bug: #1910691\n\nChange-Id: Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb\n'}, {'number': 2, 'created': '2021-02-03 17:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/468b31bb638b05608a5f54bb5045a3a272d4a386', 'message': 'Stop metadata proxy gracefully\n\nHAProxy supports hard stop [1] via SIGTERM signal. From the\ndocumentation:\n\n  """"""\n  ... when the SIGTERM signal is sent to the haproxy process,\n  it immediately quits and all established connections are\n  closed.\n  """"""\n\nIn case the process does not finish, the SIGKILL signal is sent.\nThe PID file created by the process is deleted.\n\n[1]https://cbonte.github.io/haproxy-dconv/2.0/management.html#4\n\nCloses-Bug: #1910691\n\nChange-Id: Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb\n'}, {'number': 3, 'created': '2021-02-04 11:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/932e3743cb0f5ff0daaaf603c62eea951f8acbaa', 'message': 'Stop metadata proxy gracefully\n\nHAProxy supports hard stop [1] via SIGTERM signal. From the\ndocumentation:\n\n  """"""\n  ... when the SIGTERM signal is sent to the haproxy process,\n  it immediately quits and all established connections are\n  closed.\n  """"""\n\nIn case the process does not finish, the SIGKILL signal is sent.\nThe PID file created by the process is deleted.\n\n[1]https://cbonte.github.io/haproxy-dconv/2.0/management.html#4\n\nCloses-Bug: #1910691\n\nChange-Id: Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb\n'}, {'number': 4, 'created': '2021-02-06 17:24:56.000000000', 'files': ['neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf14c725bbb6ce710a45c55d1dd00eee2fb53f62', 'message': 'Stop metadata proxy gracefully\n\nHAProxy supports hard stop [1] via SIGTERM signal. From the\ndocumentation:\n\n  """"""\n  ... when the SIGTERM signal is sent to the haproxy process,\n  it immediately quits and all established connections are\n  closed.\n  """"""\n\nIn case the process does not finish, the SIGKILL signal is sent.\nThe PID file created by the process is deleted.\n\n[1]https://cbonte.github.io/haproxy-dconv/2.0/management.html#4\n\nCloses-Bug: #1910691\n\nChange-Id: Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb\n'}]",2,773778,bf14c725bbb6ce710a45c55d1dd00eee2fb53f62,33,5,4,16688,,,0,"Stop metadata proxy gracefully

HAProxy supports hard stop [1] via SIGTERM signal. From the
documentation:

  """"""
  ... when the SIGTERM signal is sent to the haproxy process,
  it immediately quits and all established connections are
  closed.
  """"""

In case the process does not finish, the SIGKILL signal is sent.
The PID file created by the process is deleted.

[1]https://cbonte.github.io/haproxy-dconv/2.0/management.html#4

Closes-Bug: #1910691

Change-Id: Ifa3734e8eb4e52b1a132c3351ecc2e15463298bb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/773778/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py']",2,b481a61c77e65623c6d4c44d9130129ed82229ee,bug/1910691,"import signalfrom neutron.common import utils as common_utilsSIGTERM_TIMEOUT = 5 pm.disable(sig=str(int(signal.SIGTERM))) try: common_utils.wait_until_true(lambda: not pm.active, timeout=SIGTERM_TIMEOUT) except common_utils.WaitTimeout: LOG.warning('Metadata process %s did not finish after SIGTERM ' 'signal in %s seconds, sending SIGKILL signal', pm.pid, SIGTERM_TIMEOUT) pm.disable(sig=str(int(signal.SIGKILL))) # Delete metadata proxy config and PID files. linux_utils.delete_if_exists(pm.get_pid_file_name(), run_as_root=True)", pm.disable() # Delete metadata proxy config file,59,2
openstack%2Frequirements~master~Id3b51761805e3af00c2b7e5f0e90459c3fccdd64,openstack/requirements,master,Id3b51761805e3af00c2b7e5f0e90459c3fccdd64,update constraint for oslo.metrics to new release 0.2.0,MERGED,2021-02-08 13:56:05.000000000,2021-02-08 17:54:29.000000000,2021-02-08 17:52:20.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:56:05.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1379c59249c9940c9582b752463df222ec76dfef', 'message': 'update constraint for oslo.metrics to new release 0.2.0\n\nmeta: version: 0.2.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Ching Kuo <ching.kuo@linecorp.com>\nmeta: release:Commit: Ching Kuo <ching.kuo@linecorp.com>\nmeta: release:Change-Id: I68dbea306109ed25124480348a00fe3830066868\nmeta: release:Code-Review+1: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: Id3b51761805e3af00c2b7e5f0e90459c3fccdd64\n'}]",0,774461,1379c59249c9940c9582b752463df222ec76dfef,9,3,1,11131,,,0,"update constraint for oslo.metrics to new release 0.2.0

meta: version: 0.2.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Ching Kuo <ching.kuo@linecorp.com>
meta: release:Commit: Ching Kuo <ching.kuo@linecorp.com>
meta: release:Change-Id: I68dbea306109ed25124480348a00fe3830066868
meta: release:Code-Review+1: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: Id3b51761805e3af00c2b7e5f0e90459c3fccdd64
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/774461/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,1379c59249c9940c9582b752463df222ec76dfef,new-release,oslo.metrics===0.2.0,oslo.metrics===0.1.0,1,1
openstack%2Ftripleo-common~stable%2Ftrain~If56cd0fa986ef193d036b73e0ab84a88d59147e3,openstack/tripleo-common,stable/train,If56cd0fa986ef193d036b73e0ab84a88d59147e3,Conditionally use python instead of cURL,MERGED,2021-01-26 11:53:02.000000000,2021-02-08 17:31:46.000000000,2021-02-08 17:29:17.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-26 11:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d5546673c394aa7b99aa59f3f85706a21dde2d7a', 'message': 'Conditionally use python instead of cURL\n\nThe healthcheck_curl has always been a bit bonky with the proxies\nmanagement, especially the ""no_proxy"" environment variable: since there\nisn\'t any real RFC describing the content of this variable, there isn\'t\nany unified handling.\n\nThis leads to situation where an Operator puts some CIDR notation inside\nthis variable, while curl doesn\'t handle it.\n\nThis change adds a new python script. Since it uses python-requests, it\nwill have a proper support for the CIDR notation[1].\n\nIt will be called if and only if either NO_PROXY or no_proxy environment\nvariables are set and non-empty.\n\nOne can also force the script usage by passing HEALTHCHECK_CURL_PY=1,\nsuch as:\npodman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck\n\nThe output is 100% iso-compatible, and if someone wants to know what\nhealthcheck is used, they can check the User-Agent on the target logs.\n\nThis change is motivated by, at least, the following existing issues:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1837458\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1883657\n\n[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684\n\nChange-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3\n(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)\n'}, {'number': 2, 'created': '2021-01-27 08:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8f8a98558ac5a824cf30010e4421a9307f71704c', 'message': 'Conditionally use python instead of cURL\n\nThe healthcheck_curl has always been a bit bonky with the proxies\nmanagement, especially the ""no_proxy"" environment variable: since there\nisn\'t any real RFC describing the content of this variable, there isn\'t\nany unified handling.\n\nThis leads to situation where an Operator puts some CIDR notation inside\nthis variable, while curl doesn\'t handle it.\n\nThis change adds a new python script. Since it uses python-requests, it\nwill have a proper support for the CIDR notation[1].\n\nIt will be called if and only if either NO_PROXY or no_proxy environment\nvariables are set and non-empty.\n\nOne can also force the script usage by passing HEALTHCHECK_CURL_PY=1,\nsuch as:\npodman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck\n\nThe output is 100% iso-compatible, and if someone wants to know what\nhealthcheck is used, they can check the User-Agent on the target logs.\n\nThis change is motivated by, at least, the following existing issues:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1837458\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1883657\n\n[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684\n\nNote: stable/train patch has a different shebang than the original one\ndue to the CentOS7 support: we don\'t push any python3 dependencies in\nthe containers for that OS release.\n\nChange-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3\n(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)\n'}, {'number': 3, 'created': '2021-01-29 12:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4e84db43d1e538303c770a9cfb1705a960c571b8', 'message': 'Conditionally use python instead of cURL\n\nThe healthcheck_curl has always been a bit bonky with the proxies\nmanagement, especially the ""no_proxy"" environment variable: since there\nisn\'t any real RFC describing the content of this variable, there isn\'t\nany unified handling.\n\nThis leads to situation where an Operator puts some CIDR notation inside\nthis variable, while curl doesn\'t handle it.\n\nThis change adds a new python script. Since it uses python-requests, it\nwill have a proper support for the CIDR notation[1].\n\nIt will be called if and only if either NO_PROXY or no_proxy environment\nvariables are set and non-empty.\n\nOne can also force the script usage by passing HEALTHCHECK_CURL_PY=1,\nsuch as:\npodman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck\n\nThe output is 100% iso-compatible, and if someone wants to know what\nhealthcheck is used, they can check the User-Agent on the target logs.\n\nThis change is motivated by, at least, the following existing issues:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1837458\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1883657\n\n[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684\n\nNote: stable/train patch has a different shebang than the original one\ndue to the CentOS7 support: we don\'t push any python3 dependencies in\nthe containers for that OS release.\n\nChange-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3\n(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)\n'}, {'number': 4, 'created': '2021-02-01 07:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1da7d370ddf68537088284fbebc339bcddb921e5', 'message': 'Conditionally use python instead of cURL\n\nThe healthcheck_curl has always been a bit bonky with the proxies\nmanagement, especially the ""no_proxy"" environment variable: since there\nisn\'t any real RFC describing the content of this variable, there isn\'t\nany unified handling.\n\nThis leads to situation where an Operator puts some CIDR notation inside\nthis variable, while curl doesn\'t handle it.\n\nThis change adds a new python script. Since it uses python-requests, it\nwill have a proper support for the CIDR notation[1].\n\nIt will be called if and only if either NO_PROXY or no_proxy environment\nvariables are set and non-empty.\n\nOne can also force the script usage by passing HEALTHCHECK_CURL_PY=1,\nsuch as:\npodman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck\n\nThe output is 100% iso-compatible, and if someone wants to know what\nhealthcheck is used, they can check the User-Agent on the target logs.\n\nThis change is motivated by, at least, the following existing issues:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1837458\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1883657\n\n[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684\n\nNote: stable/train patch has a different shebang than the original one\ndue to the CentOS7 support: we don\'t push any python3 dependencies in\nthe containers for that OS release.\n\nChange-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3\n(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)\n'}, {'number': 5, 'created': '2021-02-03 08:50:35.000000000', 'files': ['healthcheck/http-healthcheck.py', 'healthcheck/common.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/74c85faaf0cd5549e0e887672986a3b8f30a4c53', 'message': 'Conditionally use python instead of cURL\n\nThe healthcheck_curl has always been a bit bonky with the proxies\nmanagement, especially the ""no_proxy"" environment variable: since there\nisn\'t any real RFC describing the content of this variable, there isn\'t\nany unified handling.\n\nThis leads to situation where an Operator puts some CIDR notation inside\nthis variable, while curl doesn\'t handle it.\n\nThis change adds a new python script. Since it uses python-requests, it\nwill have a proper support for the CIDR notation[1].\n\nIt will be called if and only if either NO_PROXY or no_proxy environment\nvariables are set and non-empty.\n\nOne can also force the script usage by passing HEALTHCHECK_CURL_PY=1,\nsuch as:\npodman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck\n\nThe output is 100% iso-compatible, and if someone wants to know what\nhealthcheck is used, they can check the User-Agent on the target logs.\n\nThis change is motivated by, at least, the following existing issues:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1837458\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1883657\n\n[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684\n\nNote: stable/train patch has a different shebang than the original one\ndue to the CentOS7 support: we don\'t push any python3 dependencies in\nthe containers for that OS release.\n\nDepends-On: https://review.rdoproject.org/r/#/c/31813/\nChange-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3\n(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)\n'}]",0,772412,74c85faaf0cd5549e0e887672986a3b8f30a4c53,32,3,5,28223,,,0,"Conditionally use python instead of cURL

The healthcheck_curl has always been a bit bonky with the proxies
management, especially the ""no_proxy"" environment variable: since there
isn't any real RFC describing the content of this variable, there isn't
any unified handling.

This leads to situation where an Operator puts some CIDR notation inside
this variable, while curl doesn't handle it.

This change adds a new python script. Since it uses python-requests, it
will have a proper support for the CIDR notation[1].

It will be called if and only if either NO_PROXY or no_proxy environment
variables are set and non-empty.

One can also force the script usage by passing HEALTHCHECK_CURL_PY=1,
such as:
podman exec -e ""HEALTHCHECK_CURL_PY=1"" container /healthchecks/you-healthcheck

The output is 100% iso-compatible, and if someone wants to know what
healthcheck is used, they can check the User-Agent on the target logs.

This change is motivated by, at least, the following existing issues:
https://bugzilla.redhat.com/show_bug.cgi?id=1837458
https://bugzilla.redhat.com/show_bug.cgi?id=1883657

[1] https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L663-L684

Note: stable/train patch has a different shebang than the original one
due to the CentOS7 support: we don't push any python3 dependencies in
the containers for that OS release.

Depends-On: https://review.rdoproject.org/r/#/c/31813/
Change-Id: If56cd0fa986ef193d036b73e0ab84a88d59147e3
(cherry picked from commit 2185d9a8599f4efb79fe38b188bc48e931eba625)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/12/772412/5 && git format-patch -1 --stdout FETCH_HEAD,"['healthcheck/http-healthcheck.py', 'healthcheck/common.sh']",2,d5546673c394aa7b99aa59f3f85706a21dde2d7a,healthcheck/http-stable/train,": ${HEALTHCHECK_CURL_PY_USER_AGENT:=pyrequests-healthcheck} if [ -n ""${HEALTHCHECK_CURL_PY+x}"" ] || [ -n ""${no_proxy+x}"" ] || [ -n ""${NO_PROXY+x}"" ]; then ${HEALTHCHECK_SCRIPTS:-/usr/share/openstack-tripleo-common/healthcheck}/http-healthcheck.py \ --max-time ""${HEALTHCHECK_CURL_MAX_TIME}"" \ --user-agent ""${HEALTHCHECK_CURL_PY_USER_AGENT}"" \ --write-out ""${HEALTHCHECK_CURL_WRITE_OUT}"" \ ""$@"" || return 1 else curl -g -k -q -s -S --fail -o ""${HEALTHCHECK_CURL_OUTPUT}"" \ fi"," curl -g -k -q -s -S --fail -o ""${HEALTHCHECK_CURL_OUTPUT}"" \",54,1
openstack%2Foslo.policy~master~Ibd2503db55739a9b8a3011534a7b51db16282001,openstack/oslo.policy,master,Ibd2503db55739a9b8a3011534a7b51db16282001,Use TOX_CONSTRAINTS_FILE,ABANDONED,2020-11-04 09:49:47.000000000,2021-02-08 17:31:36.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-11-04 09:49:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/0529d84c22acfea957a80cdba2abb5adf0fca2ca', 'message': 'Use TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\nThis allows to use upper-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\n[1] https://review.opendev.org/#/c/722814/\n[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\n\nChange-Id: Ibd2503db55739a9b8a3011534a7b51db16282001\n'}]",0,761349,0529d84c22acfea957a80cdba2abb5adf0fca2ca,15,3,1,28522,,,0,"Use TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
This allows to use upper-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

[1] https://review.opendev.org/#/c/722814/
[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file

Change-Id: Ibd2503db55739a9b8a3011534a7b51db16282001
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/49/761349/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0529d84c22acfea957a80cdba2abb5adf0fca2ca,tox_constraints_file, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},1,1
openstack%2Frequirements~master~If35561726af72c8cf15b493e8099d2fe92bf689f,openstack/requirements,master,If35561726af72c8cf15b493e8099d2fe92bf689f,update constraint for oslo.vmware to new release 3.8.0,MERGED,2021-02-08 13:27:47.000000000,2021-02-08 17:30:45.000000000,2021-02-08 17:26:57.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:27:47.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5d6dbf69fc25c95c70f86c1056cd2c699a6ac925', 'message': 'update constraint for oslo.vmware to new release 3.8.0\n\nmeta: version: 3.8.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: If35561726af72c8cf15b493e8099d2fe92bf689f\n'}]",0,774450,5d6dbf69fc25c95c70f86c1056cd2c699a6ac925,9,3,1,11131,,,0,"update constraint for oslo.vmware to new release 3.8.0

meta: version: 3.8.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: If35561726af72c8cf15b493e8099d2fe92bf689f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/50/774450/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5d6dbf69fc25c95c70f86c1056cd2c699a6ac925,new-release,oslo.vmware===3.8.0,oslo.vmware===3.7.0,1,1
openstack%2Frequirements~master~Ic3f9642248cf4a19f77bdf298549aeaa34798255,openstack/requirements,master,Ic3f9642248cf4a19f77bdf298549aeaa34798255,update constraint for oslo.serialization to new release 4.1.0,MERGED,2021-02-08 13:32:19.000000000,2021-02-08 17:28:56.000000000,2021-02-08 17:26:52.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:32:19.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ff905c551003628ad02d00471da1116e1343c7d6', 'message': 'update constraint for oslo.serialization to new release 4.1.0\n\nmeta: version: 4.1.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: Ic3f9642248cf4a19f77bdf298549aeaa34798255\n'}]",0,774453,ff905c551003628ad02d00471da1116e1343c7d6,9,3,1,11131,,,0,"update constraint for oslo.serialization to new release 4.1.0

meta: version: 4.1.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: Ic3f9642248cf4a19f77bdf298549aeaa34798255
",git fetch https://review.opendev.org/openstack/requirements refs/changes/53/774453/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ff905c551003628ad02d00471da1116e1343c7d6,new-release,oslo.serialization===4.1.0,oslo.serialization===4.0.1,1,1
openstack%2Ftenks~master~Ibd61e090611b3b7a7e0670c854362b512454bf3c,openstack/tenks,master,Ibd61e090611b3b7a7e0670c854362b512454bf3c,Fix virtualbmc installation after release of cryptography 3.4,MERGED,2021-02-08 14:55:10.000000000,2021-02-08 17:06:22.000000000,2021-02-08 17:04:10.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-08 14:55:10.000000000', 'files': ['releasenotes/notes/virtualbmc-cryptography-03d62a3d1e965197.yaml', 'ansible/roles/virtualbmc-daemon/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tenks/commit/f34bb772a018d3ee3a2872358542ad51c22fc06e', 'message': ""Fix virtualbmc installation after release of cryptography 3.4\n\nInstalling virtualbmc system-wide on CentOS 8 fails with:\n\n    ModuleNotFoundError: No module named 'setuptools_rust'\n\nThis error appeared following the release of cryptography 3.4, which now\nincludes Rust code. It can be installed without Rust using a Python\nwheel, but only with more recent pip than version 9.0.3 available as RPM\non CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.\n\nAlso ignore PyYAML when installing system-wide to avoid conflicts with\nan existing RPM package installation.\n\n[1] https://github.com/pyca/cryptography/issues/5753\n\nChange-Id: Ibd61e090611b3b7a7e0670c854362b512454bf3c\nStory: 2008607\nTask: 41788\n""}]",0,774474,f34bb772a018d3ee3a2872358542ad51c22fc06e,8,3,1,15197,,,0,"Fix virtualbmc installation after release of cryptography 3.4

Installing virtualbmc system-wide on CentOS 8 fails with:

    ModuleNotFoundError: No module named 'setuptools_rust'

This error appeared following the release of cryptography 3.4, which now
includes Rust code. It can be installed without Rust using a Python
wheel, but only with more recent pip than version 9.0.3 available as RPM
on CentOS 8. The cryptography bug report [1] recommends pip>=19.1.1.

Also ignore PyYAML when installing system-wide to avoid conflicts with
an existing RPM package installation.

[1] https://github.com/pyca/cryptography/issues/5753

Change-Id: Ibd61e090611b3b7a7e0670c854362b512454bf3c
Story: 2008607
Task: 41788
",git fetch https://review.opendev.org/openstack/tenks refs/changes/74/774474/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/virtualbmc-cryptography-03d62a3d1e965197.yaml', 'ansible/roles/virtualbmc-daemon/tasks/main.yml']",2,f34bb772a018d3ee3a2872358542ad51c22fc06e,,"# NOTE(priteau): We need a recent pip to install the latest cryptography # library. See https://github.com/pyca/cryptography/issues/5753 - name: Ensure a recent version of pip is installed pip: name: ""pip>=19.1.1"" virtualenv: ""{{ vbmcd_virtualenv_path or omit }}"" become: ""{{ not vbmcd_virtualenv_path }}"" # NOTE(priteau): Ignore PyYAML when installing system-wide to avoid the # following error: Cannot uninstall 'PyYAML'. It is a distutils installed # project and thus we cannot accurately determine which files belong to it # which would lead to only a partial uninstall. {% if not vbmcd_virtualenv_path %}--ignore-installed PyYAML{% endif %}",,19,0
openstack%2Ftripleo-heat-templates~master~I269607d43f45f65efcbce33dd776e7eb4f475311,openstack/tripleo-heat-templates,master,I269607d43f45f65efcbce33dd776e7eb4f475311,Use Ceph-NFS for Manila in scenario004,MERGED,2021-01-08 15:00:23.000000000,2021-02-08 17:03:47.000000000,2021-01-27 00:20:41.000000000,"[{'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-01-08 15:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/267ab153f7dc6490d916ea284c5b186b5b598a92', 'message': ""WIP: use Ceph-NFS for Manila in scenario004\n\nWe will likely need more than just the review that this one depends on,\nbut let's start an investigation since overall there is good support\nnowadays with standalone for the pacemaker stuff that we need for CephFS\nthrough NFS.\n\nDepends-on: https://review.opendev.org/c/openstack/puppet-tripleo/+/769906\n\nChange-Id: I269607d43f45f65efcbce33dd776e7eb4f475311\n""}, {'number': 2, 'created': '2021-01-09 15:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/393b230c13384ba0a7152049c80e39b8e6d2e978', 'message': ""WIP: use Ceph-NFS for Manila in scenario004\n\nWe will likely need more than just the review that this one depends on,\nbut let's start an investigation since overall there is good support\nnowadays with standalone for the pacemaker stuff that we need for CephFS\nthrough NFS.\n\nDepends-on: https://review.opendev.org/c/openstack/puppet-tripleo/+/769906\n\nChange-Id: I269607d43f45f65efcbce33dd776e7eb4f475311\n""}, {'number': 3, 'created': '2021-01-09 21:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03dd2caac6258099c44ab1bb9fd4008998d80b9c', 'message': ""WIP: use Ceph-NFS for Manila in scenario004\n\nWe will likely need more than just the review that this one depends on,\nbut let's start an investigation since overall there is good support\nnowadays with standalone for the pacemaker stuff that we need for CephFS\nthrough NFS.\n\nDepends-on: https://review.opendev.org/c/openstack/puppet-tripleo/+/769906\nDepends-on: https://review.opendev.org/c/openstack/tripleo-ci/+/770049\n\nChange-Id: I269607d43f45f65efcbce33dd776e7eb4f475311\n""}, {'number': 4, 'created': '2021-01-11 16:00:24.000000000', 'files': ['roles/Standalone.yaml', 'ci/environments/scenario004-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/63c5a94f83a6d8d9f9cc3e342265002e2e708d81', 'message': 'Use Ceph-NFS for Manila in scenario004\n\nCephFS gatewayed by NFS is more generally suitable for multi-tenant\nOpenStack deployments than native CephFS since the latter requires\nthat VMs belonging to regular members of Keystone projects be exposed\nto the Ceph infrastructure and run client software with capabilities\nthat are not appropriate for untrusted cloud tenants.\n\nDepends-on: https://review.opendev.org/c/openstack/puppet-tripleo/+/769906\nDepends-on: https://review.opendev.org/c/openstack/tripleo-ci/+/770049\n\nChange-Id: I269607d43f45f65efcbce33dd776e7eb4f475311\n'}]",0,769937,63c5a94f83a6d8d9f9cc3e342265002e2e708d81,29,6,4,9003,,,0,"Use Ceph-NFS for Manila in scenario004

CephFS gatewayed by NFS is more generally suitable for multi-tenant
OpenStack deployments than native CephFS since the latter requires
that VMs belonging to regular members of Keystone projects be exposed
to the Ceph infrastructure and run client software with capabilities
that are not appropriate for untrusted cloud tenants.

Depends-on: https://review.opendev.org/c/openstack/puppet-tripleo/+/769906
Depends-on: https://review.opendev.org/c/openstack/tripleo-ci/+/770049

Change-Id: I269607d43f45f65efcbce33dd776e7eb4f475311
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/769937/4 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario004-standalone.yaml'],1,267ab153f7dc6490d916ea284c5b186b5b598a92,, OS::TripleO::Services::CephNfs: ../../deployment/ceph-ansible/ceph-nfs.yaml ManilaCephFSCephFSProtocolHelperType: 'NFS' ExtraConfig: ganesha_vip: 192.168.24.3,,4,0
openstack%2Ftripleo-ansible~master~I0f553f8e7f622b983b6707674c958e211bb83829,openstack/tripleo-ansible,master,I0f553f8e7f622b983b6707674c958e211bb83829,Ignore endpoint not found errors,MERGED,2021-02-05 02:53:50.000000000,2021-02-08 17:01:46.000000000,2021-02-08 17:01:46.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-05 02:53:50.000000000', 'files': ['tripleo_ansible/playbooks/cli-overcloud-delete.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/abda8556f94c2e3a6d9be645a1531c9674d31050', 'message': 'Ignore endpoint not found errors\n\nWhen deleting overcloud ignore endpoint not found\nerror which looks like ``endpoint for object-store\nservice in <regionOne> region not found``, so as not\nto fail when swift is disabled in the undercloud.\n\nChange-Id: I0f553f8e7f622b983b6707674c958e211bb83829\n'}]",0,774185,abda8556f94c2e3a6d9be645a1531c9674d31050,8,3,1,8833,,,0,"Ignore endpoint not found errors

When deleting overcloud ignore endpoint not found
error which looks like ``endpoint for object-store
service in <regionOne> region not found``, so as not
to fail when swift is disabled in the undercloud.

Change-Id: I0f553f8e7f622b983b6707674c958e211bb83829
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/85/774185/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-overcloud-delete.yaml'],1,abda8556f94c2e3a6d9be645a1531c9674d31050,env_merging," - ""'not found' not in container_objects.stderr | lower"" changed_when: - ""'not found' not in container_objects.stderr | lower"""," - ""'Not Found' not in container_objects.stderr"" changed_when: - ""'Not Found' not in container_objects.stderr""",2,2
openstack%2Frequirements~master~Ib3eae193b6c82fdb7fd7940b3eb33e7791f1a2fc,openstack/requirements,master,Ib3eae193b6c82fdb7fd7940b3eb33e7791f1a2fc,update constraint for oslo.service to new release 2.5.0,MERGED,2021-02-08 13:26:59.000000000,2021-02-08 16:49:00.000000000,2021-02-08 16:45:36.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:26:59.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c4632b8e3bded27329fb92f2d5fd5df6f2c8437a', 'message': 'update constraint for oslo.service to new release 2.5.0\n\nmeta: version: 2.5.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: Ib3eae193b6c82fdb7fd7940b3eb33e7791f1a2fc\n'}]",0,774449,c4632b8e3bded27329fb92f2d5fd5df6f2c8437a,9,3,1,11131,,,0,"update constraint for oslo.service to new release 2.5.0

meta: version: 2.5.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: Ib3eae193b6c82fdb7fd7940b3eb33e7791f1a2fc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/49/774449/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c4632b8e3bded27329fb92f2d5fd5df6f2c8437a,new-release,oslo.service===2.5.0,oslo.service===2.4.0,1,1
openstack%2Fneutron~stable%2Fvictoria~Id13ecb68349ca96907c7c1fc959fc89319a10c72,openstack/neutron,stable/victoria,Id13ecb68349ca96907c7c1fc959fc89319a10c72,[stable only] Wait chassis creation before retrieving agent,MERGED,2021-02-05 12:44:22.000000000,2021-02-08 16:48:10.000000000,2021-02-08 16:43:24.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 12:44:22.000000000', 'files': ['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3e95a146288d7c1ad0e43903156af8446449093', 'message': '[stable only] Wait chassis creation before retrieving agent\n\nTo be sure the agent is present, first its needed to create\na chassis with the correct references and wait for the creation\nevent.\n\nThis patch is an extract of [1].\n\n[1]https://review.opendev.org/c/openstack/neutron/+/752795\n\nChange-Id: Id13ecb68349ca96907c7c1fc959fc89319a10c72\nRelated-Bug: #1899004\n'}]",0,774236,d3e95a146288d7c1ad0e43903156af8446449093,9,3,1,16688,,,0,"[stable only] Wait chassis creation before retrieving agent

To be sure the agent is present, first its needed to create
a chassis with the correct references and wait for the creation
event.

This patch is an extract of [1].

[1]https://review.opendev.org/c/openstack/neutron/+/752795

Change-Id: Id13ecb68349ca96907c7c1fc959fc89319a10c72
Related-Bug: #1899004
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/774236/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'],1,d3e95a146288d7c1ad0e43903156af8446449093,bug/1899004,"from ovsdbapp.backend.ovs_idl import eventclass AgentWaitEvent(event.WaitEvent): """"""Wait for a list of Chassis to be created"""""" ONETIME = False def __init__(self, driver, chassis_names): table = driver.agent_chassis_table events = (self.ROW_CREATE,) self.chassis_names = chassis_names super().__init__(events, table, None) self.event_name = 'AgentWaitEvent' def match_fn(self, event, row, old): return row.name in self.chassis_names def run(self, event, row, old): self.chassis_names.remove(row.name) if not self.chassis_names: self.event.set() class TestAgentApi(base.TestOVNFunctionalBase): TEST_AGENT = 'test' def setUp(self, *args): self.host = n_utils.get_rand_name(prefix='testhost-') metadata_agent_id = uuidutils.generate_uuid() # To be *mostly* sure the agent cache has been updated, we need to # wait for the Chassis events to run. So add a new event that should # run afterthey do and wait for it. I've only had to do this when # adding *a bunch* of Chassis at a time, but better safe than sorry. chassis_name = uuidutils.generate_uuid() agent_event = AgentWaitEvent(self.mech_driver, [chassis_name]) self.sb_api.idl.notify_handler.watch_event(agent_event) self.chassis = self.add_fake_chassis( self.host, name=chassis_name, external_ids={ ovn_const.OVN_AGENT_METADATA_ID_KEY: metadata_agent_id}) self.assertTrue(agent_event.wait()) self.agent_types = { self.TEST_AGENT: self._create_test_agent(), ovn_const.OVN_CONTROLLER_AGENT: self.chassis, ovn_const.OVN_METADATA_AGENT: metadata_agent_id, } def _create_test_agent(self): agent = {'agent_type': self.TEST_AGENT, 'binary': '/bin/test', 'host': self.host, 'topic': 'test_topic'} _, status = self.plugin.create_or_update_agent(self.context, agent) return status['id'] def test_agent_show(self): for agent_id in self.agent_types.values(): self.assertTrue(self.plugin.get_agent(self.context, agent_id)) def test_agent_list(self): agent_ids = [a['id'] for a in self.plugin.get_agents( self.context, filters={'host': self.host})] self.assertCountEqual(list(self.agent_types.values()), agent_ids)","class TestAgentApi(base.TestOVNFunctionalBase): def setUp(self): self.host = 'test-host' self.controller_agent = self.add_fake_chassis(self.host) agent = {'agent_type': 'test', 'binary': '/bin/test', 'host': self.host, 'topic': 'test_topic'} _, status = self.plugin.create_or_update_agent(self.context, agent) self.test_agent = status['id'] def test_agent_show_non_ovn(self): self.assertTrue(self.plugin.get_agent(self.context, self.test_agent)) def test_agent_show_ovn_controller(self): self.assertTrue(self.plugin.get_agent(self.context, self.controller_agent))",61,13
openstack%2Frequirements~master~I7cd73f0a3a3e063a3d8a32dd42807d0a67d7d66a,openstack/requirements,master,I7cd73f0a3a3e063a3d8a32dd42807d0a67d7d66a,update constraint for oslo.cache to new release 2.7.0,MERGED,2021-02-08 13:25:40.000000000,2021-02-08 16:47:52.000000000,2021-02-08 16:44:42.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:25:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f8507717b7a6f6a3bfaaa29f2580efcd4526f7cd', 'message': 'update constraint for oslo.cache to new release 2.7.0\n\nmeta: version: 2.7.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I7cd73f0a3a3e063a3d8a32dd42807d0a67d7d66a\n'}]",0,774448,f8507717b7a6f6a3bfaaa29f2580efcd4526f7cd,9,3,1,11131,,,0,"update constraint for oslo.cache to new release 2.7.0

meta: version: 2.7.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I7cd73f0a3a3e063a3d8a32dd42807d0a67d7d66a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/48/774448/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f8507717b7a6f6a3bfaaa29f2580efcd4526f7cd,new-release,oslo.cache===2.7.0,oslo.cache===2.6.1,1,1
openstack%2Frequirements~stable%2Fussuri~I37a4d48f621499b2de238cb9b22afb0528772d74,openstack/requirements,stable/ussuri,I37a4d48f621499b2de238cb9b22afb0528772d74,update constraint for oslo.serialization to new release 3.1.2,MERGED,2021-02-08 13:21:30.000000000,2021-02-08 16:45:09.000000000,2021-02-08 16:45:09.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:21:30.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/007a287c99738cb9ac93d49849ea746a56be8703', 'message': 'update constraint for oslo.serialization to new release 3.1.2\n\nmeta: version: 3.1.2\nmeta: diff-start: -\nmeta: series: ussuri\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I37a4d48f621499b2de238cb9b22afb0528772d74\n'}]",0,774446,007a287c99738cb9ac93d49849ea746a56be8703,7,3,1,11131,,,0,"update constraint for oslo.serialization to new release 3.1.2

meta: version: 3.1.2
meta: diff-start: -
meta: series: ussuri
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I37a4d48f621499b2de238cb9b22afb0528772d74
",git fetch https://review.opendev.org/openstack/requirements refs/changes/46/774446/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,007a287c99738cb9ac93d49849ea746a56be8703,new-release,oslo.serialization===3.1.2;python_version=='3.6' oslo.serialization===3.1.2;python_version=='3.7' oslo.serialization===3.1.2;python_version=='3.8',oslo.serialization===3.1.1;python_version=='3.6' oslo.serialization===3.1.1;python_version=='3.7' oslo.serialization===3.1.1;python_version=='3.8',3,3
openstack%2Frequirements~stable%2Fvictoria~I99c0f51f4f4d7e006d9cd5ab580d4a34033d1c4a,openstack/requirements,stable/victoria,I99c0f51f4f4d7e006d9cd5ab580d4a34033d1c4a,update constraint for oslo.serialization to new release 4.0.2,MERGED,2021-02-08 13:24:04.000000000,2021-02-08 16:44:05.000000000,2021-02-08 16:44:05.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 13:24:04.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5840117b74ac625d4eefaf6a4a73654e0777c06e', 'message': 'update constraint for oslo.serialization to new release 4.0.2\n\nmeta: version: 4.0.2\nmeta: diff-start: -\nmeta: series: victoria\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I99c0f51f4f4d7e006d9cd5ab580d4a34033d1c4a\n'}]",0,774447,5840117b74ac625d4eefaf6a4a73654e0777c06e,8,3,1,11131,,,0,"update constraint for oslo.serialization to new release 4.0.2

meta: version: 4.0.2
meta: diff-start: -
meta: series: victoria
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I99c0f51f4f4d7e006d9cd5ab580d4a34033d1c4a
",git fetch https://review.opendev.org/openstack/requirements refs/changes/47/774447/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5840117b74ac625d4eefaf6a4a73654e0777c06e,new-release,oslo.serialization===4.0.2,oslo.serialization===4.0.1,1,1
openstack%2Ftempest~master~Ia15c501a389c1c7524b1ece912b6d1e2c85ef1b8,openstack/tempest,master,Ia15c501a389c1c7524b1ece912b6d1e2c85ef1b8,[WIP] Add non cirros guest image job in tempest gate,ABANDONED,2021-02-04 20:56:30.000000000,2021-02-08 16:32:39.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-04 20:56:30.000000000', 'files': ['zuul.d/tempest-specific.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c7aa2fd42cb79b2d813b8e095adc8de1de87d13', 'message': '[WIP] Add non cirros guest image job in tempest gate\n\nChange-Id: Ia15c501a389c1c7524b1ece912b6d1e2c85ef1b8\n'}]",0,774158,2c7aa2fd42cb79b2d813b8e095adc8de1de87d13,3,1,1,31239,,,0,"[WIP] Add non cirros guest image job in tempest gate

Change-Id: Ia15c501a389c1c7524b1ece912b6d1e2c85ef1b8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/58/774158/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/tempest-specific.yaml'],1,2c7aa2fd42cb79b2d813b8e095adc8de1de87d13,," - job: name: tempest-plugin-scenario parent: tempest-full-py3 abstract: true description: | Perform setup common to all tempest scenario test jobs. vars: tempest_test_timeout: 2400 tempest_test_regex: ""\ (^tempest..scenario)|\ (^tempest.api.compute.servers.test_attach_interfaces)|\ (^tempest.api.compute.servers.test_multiple_create)"" devstack_localrc: IMAGE_URLS: https://cloud-images.ubuntu.com/releases/bionic/release/ubuntu-18.04-server-cloudimg-amd64.img DEFAULT_IMAGE_NAME: ubuntu-18.04-server-cloudimg-amd64 DEFAULT_INSTANCE_TYPE: ds512M DEFAULT_INSTANCE_USER: ubuntu BUILD_TIMEOUT: 784 tempest_concurrency: 3 # out of 4",,20,0
openstack%2Ftripleo-operator-ansible~master~Idcbc28b107598efec62dd8f4afbb2d404a1a9c14,openstack/tripleo-operator-ansible,master,Idcbc28b107598efec62dd8f4afbb2d404a1a9c14,Ensure undercloud backup role runs with root privileges,MERGED,2021-02-07 22:16:02.000000000,2021-02-08 16:22:22.000000000,2021-02-08 16:22:22.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-02-07 22:16:02.000000000', 'files': ['roles/tripleo_undercloud_backup/tasks/main.yml', 'roles/tripleo_undercloud_backup/defaults/main.yml', 'roles/tripleo_undercloud_backup/molecule/default/converge.yml', 'roles/tripleo_undercloud_backup/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/b12211cf51a6db8de1f6db8162616075d7dd4fb4', 'message': 'Ensure undercloud backup role runs with root privileges\n\nThe undercloud backup command requires root privileges to run,\nas such we need to ensure become is available as a boolean option\nto the operator. By default this value is set to true.\n\nChange-Id: Idcbc28b107598efec62dd8f4afbb2d404a1a9c14\n'}]",3,774383,b12211cf51a6db8de1f6db8162616075d7dd4fb4,11,4,1,29268,,,0,"Ensure undercloud backup role runs with root privileges

The undercloud backup command requires root privileges to run,
as such we need to ensure become is available as a boolean option
to the operator. By default this value is set to true.

Change-Id: Idcbc28b107598efec62dd8f4afbb2d404a1a9c14
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/83/774383/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo_undercloud_backup/tasks/main.yml', 'roles/tripleo_undercloud_backup/defaults/main.yml', 'roles/tripleo_undercloud_backup/molecule/default/converge.yml', 'roles/tripleo_undercloud_backup/README.md']",4,b12211cf51a6db8de1f6db8162616075d7dd4fb4,,* `tripleo_undercloud_backup_become`: (Boolean) Run the command as root. This needs to be true as the commands require root privileges to run. Default: true,,4,0
openstack%2Fpuppet-neutron~stable%2Fqueens~I1d96899de29cdd994f2a45b701923b0177a7edd8,openstack/puppet-neutron,stable/queens,I1d96899de29cdd994f2a45b701923b0177a7edd8,Add ovs/igmp_snooping_enable support,MERGED,2021-02-01 12:20:35.000000000,2021-02-08 16:21:57.000000000,2021-02-08 16:21:57.000000000,"[{'_account_id': 6773}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-01 12:20:35.000000000', 'files': ['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b34137a93ea046b50bae76e10fd00a52c6f74256', 'message': 'Add ovs/igmp_snooping_enable support\n\nThis patch is adding support to the ""ovs/igmp_snooping_enable""\nconfiguration option in the ml2_conf.ini configuration file.\n\nConflicts:\n      manifests/agents/ml2/ovs.pp\n      spec/classes/neutron_agents_ml2_ovs_spec.rb\n\nRelated-Bug: #1868569\n\nChange-Id: I1d96899de29cdd994f2a45b701923b0177a7edd8\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 382352a893c2a693eb10329365357282d68d75e4)\n(cherry picked from commit 4d5fd04844b58c84be7428a5bfcaab1b2f4d7eab)\n(cherry picked from commit 6e4f4e93afe5e13b1e1fd4943397e4efc97737cf)\n'}]",0,773375,b34137a93ea046b50bae76e10fd00a52c6f74256,17,5,1,16688,,,0,"Add ovs/igmp_snooping_enable support

This patch is adding support to the ""ovs/igmp_snooping_enable""
configuration option in the ml2_conf.ini configuration file.

Conflicts:
      manifests/agents/ml2/ovs.pp
      spec/classes/neutron_agents_ml2_ovs_spec.rb

Related-Bug: #1868569

Change-Id: I1d96899de29cdd994f2a45b701923b0177a7edd8
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 382352a893c2a693eb10329365357282d68d75e4)
(cherry picked from commit 4d5fd04844b58c84be7428a5bfcaab1b2f4d7eab)
(cherry picked from commit 6e4f4e93afe5e13b1e1fd4943397e4efc97737cf)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/75/773375/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp']",2,b34137a93ea046b50bae76e10fd00a52c6f74256,bug/1868569,"# [*igmp_snooping_enable*] # (Optional) Enable IGMP snooping for integration bridge. If this # option is set to True, support for Internet Group Management # Protocol (IGMP) is enabled in integration bridge. # Setting this option to True will also enable Open vSwitch # mcast-snooping-disable-flood-unregistered flag. This option will # disable flooding of unregistered multicast packets to all ports. # The switch will send unregistered multicast packets only to ports # connected to multicast routers. This option is used by the ML2/OVS # mechanism driver for Neutron. # Defaults to $::os_service_default $igmp_snooping_enable = $::os_service_default, 'ovs/igmp_snooping_enable': value => $igmp_snooping_enable;",,24,0
openstack%2Fopenstack-helm-infra~master~I4978df1bcdb45ad24e632d976eb407d4129715ad,openstack/openstack-helm-infra,master,I4978df1bcdb45ad24e632d976eb407d4129715ad,Remove snmp_notifier subchart from alertmanager,MERGED,2021-02-04 20:21:45.000000000,2021-02-08 16:18:22.000000000,2021-02-08 16:14:45.000000000,"[{'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 18511}, {'_account_id': 22348}, {'_account_id': 24780}, {'_account_id': 28849}, {'_account_id': 30582}, {'_account_id': 30777}]","[{'number': 1, 'created': '2021-02-04 20:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0f8fb1be757ec5ef85d7db5f9df0a8128aaf112d', 'message': 'Remove snmp_notifier subchart from alertmanager\n\nChange-Id: I4978df1bcdb45ad24e632d976eb407d4129715ad\n'}, {'number': 2, 'created': '2021-02-04 20:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f39b4382f64fff5943edb568edc53099a620fe8b', 'message': 'Remove snmp_notifier subchart from alertmanager\n\nChange-Id: I4978df1bcdb45ad24e632d976eb407d4129715ad\n'}, {'number': 3, 'created': '2021-02-05 14:56:36.000000000', 'files': ['prometheus-alertmanager/values_overrides/apparmor.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-alertmanager/templates/snmp-notifier/snmp-service.yaml', 'prometheus-alertmanager/Chart.yaml', 'prometheus-alertmanager/templates/snmp-notifier/snmp-deployment.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d3bf218250545a54fe71aad1b8177705b2f7ea2f', 'message': 'Remove snmp_notifier subchart from alertmanager\n\nsnmp_notifier lack of features to forward alert labels from Alertmanager.\n\nChange-Id: I4978df1bcdb45ad24e632d976eb407d4129715ad\n'}]",0,774154,d3bf218250545a54fe71aad1b8177705b2f7ea2f,21,8,3,31713,,,0,"Remove snmp_notifier subchart from alertmanager

snmp_notifier lack of features to forward alert labels from Alertmanager.

Change-Id: I4978df1bcdb45ad24e632d976eb407d4129715ad
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/54/774154/2 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus-alertmanager/values_overrides/apparmor.yaml', 'prometheus-alertmanager/values.yaml', 'prometheus-alertmanager/templates/snmp-notifier/snmp-service.yaml', 'prometheus-alertmanager/templates/snmp-notifier/snmp-deployment.yaml']",4,0f8fb1be757ec5ef85d7db5f9df0a8128aaf112d,,,"{{/* Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- if .Values.manifests.snmpnotifier.deployment }} {{- $envAll := . }} {{- $mounts_snmpnotifier := .Values.pod.mounts.snmpnotifier.snmpnotifier }} {{- $mounts_snmpnotifier_init := .Values.pod.mounts.snmpnotifier.init_container }} {{- $serviceAccountName := ""snmpnotifier"" }} {{ tuple $envAll ""snmpnotifier"" $serviceAccountName | include ""helm-toolkit.snippets.kubernetes_pod_rbac_serviceaccount"" }} --- apiVersion: apps/v1 kind: Deployment metadata: name: snmpnotifier annotations: {{ tuple $envAll | include ""helm-toolkit.snippets.release_uuid"" }} labels: {{ tuple $envAll ""snmpnotifier"" ""server"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 4 }} spec: podManagementPolicy: ""Parallel"" replicas: {{ .Values.pod.replicas.snmpnotifier }} selector: matchLabels: {{ tuple $envAll ""snmpnotifier"" ""server"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 6 }} template: metadata: labels: {{ tuple $envAll ""snmpnotifier"" ""server"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 8 }} annotations: {{ dict ""envAll"" $envAll ""podName"" $serviceAccountName ""containerNames"" (list ""snmpnotifier"") | include ""helm-toolkit.snippets.kubernetes_mandatory_access_control_annotation"" | indent 8 }} spec: {{ dict ""envAll"" $envAll ""application"" ""server"" | include ""helm-toolkit.snippets.kubernetes_pod_security_context"" | indent 6 }} serviceAccountName: {{ $serviceAccountName }} affinity: {{ tuple $envAll ""snmpnotifier"" ""server"" | include ""helm-toolkit.snippets.kubernetes_pod_anti_affinity"" | indent 8 }} nodeSelector: {{ .Values.labels.snmpnotifier.node_selector_key }}: {{ .Values.labels.snmpnotifier.node_selector_value | quote }} terminationGracePeriodSeconds: {{ .Values.pod.lifecycle.termination_grace_period.snmpnotifier.timeout | default ""30"" }} containers: - name: snmpnotifier {{ tuple $envAll ""snmpnotifier"" | include ""helm-toolkit.snippets.image"" | indent 10 }} {{ tuple $envAll $envAll.Values.pod.resources.snmpnotifier | include ""helm-toolkit.snippets.kubernetes_resources"" | indent 10 }} {{ dict ""envAll"" $envAll ""application"" ""server"" ""container"" ""snmpnotifier"" | include ""helm-toolkit.snippets.kubernetes_container_security_context"" | indent 10 }} args: - --alert.default-severity={{ .Values.conf.command_flags.snmpnotifier.alert_default_severity}} - --alert.severities={{ .Values.conf.command_flags.snmpnotifier.alert_severities}} - --alert.severity-label={{ .Values.conf.command_flags.snmpnotifier.alert_severity_label}} - --log.level={{ .Values.conf.command_flags.snmpnotifier.log_level}} - --snmp.community={{ .Values.conf.command_flags.snmpnotifier.snmp_community}} - --snmp.destination={{ .Values.conf.command_flags.snmpnotifier.snmp_desination}} - --snmp.trap-default-oid={{ .Values.conf.command_flags.snmpnotifier.snmp_trap_default_oid}} - --snmp.trap-description-template={{ .Values.conf.command_flags.snmpnotifier.snmp_trap_description_template}} - --snmp.version={{ .Values.conf.command_flags.snmpnotifier.snmp_version}} ports: - name: snmp-api containerPort: {{ tuple ""snmpnotifier"" ""internal"" ""api"" . | include ""helm-toolkit.endpoints.endpoint_port_lookup"" }} readinessProbe: httpGet: path: /health port: {{ tuple ""snmpnotifier"" ""internal"" ""api"" . | include ""helm-toolkit.endpoints.endpoint_port_lookup"" }} initialDelaySeconds: 30 timeoutSeconds: 30 {{- end }} ",1,168
openstack%2Fneutron~master~I3d248e9c4fda64e045d1a0f39d90638ea3b21304,openstack/neutron,master,I3d248e9c4fda64e045d1a0f39d90638ea3b21304,Removed unneeded log translation.,ABANDONED,2021-02-04 18:40:42.000000000,2021-02-08 15:59:47.000000000,,"[{'_account_id': 1131}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 18:40:42.000000000', 'files': ['neutron/agent/windows/utils.py', 'neutron/agent/linux/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/61204ad46534e16308330498affa5bd72df2317e', 'message': 'Removed unneeded log translation.\n\nExceptions in the agent side is not user visibile via API,\nso there is no need to mark it as translatable.\n\nPartial-Bug: 1600788\nChange-Id: I3d248e9c4fda64e045d1a0f39d90638ea3b21304\n'}]",2,774143,61204ad46534e16308330498affa5bd72df2317e,8,3,1,32927,,,0,"Removed unneeded log translation.

Exceptions in the agent side is not user visibile via API,
so there is no need to mark it as translatable.

Partial-Bug: 1600788
Change-Id: I3d248e9c4fda64e045d1a0f39d90638ea3b21304
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/774143/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/windows/utils.py', 'neutron/agent/linux/utils.py']",2,61204ad46534e16308330498affa5bd72df2317e,bug/1600788," raise exceptions.ProcessExecutionError(msg,"," raise exceptions.ProcessExecutionError(_(msg),",2,2
openstack%2Freleases~master~I97e2b2c091e0dafcbf03a536704e1613796bb62f,openstack/releases,master,I97e2b2c091e0dafcbf03a536704e1613796bb62f,Create new release of puppet-nova for victoria,MERGED,2021-02-04 06:04:17.000000000,2021-02-08 15:39:00.000000000,2021-02-08 15:39:00.000000000,"[{'_account_id': 308}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16312}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31068}]","[{'number': 1, 'created': '2021-02-04 06:04:17.000000000', 'files': ['deliverables/victoria/puppet-nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6b9cd13d9abcc71d0b4489606350260f3c309813', 'message': 'Create new release of puppet-nova for victoria\n\nIncludes some features and fix needed for CentOS8-stream.\n\nChange-Id: I97e2b2c091e0dafcbf03a536704e1613796bb62f\n'}]",0,774039,6b9cd13d9abcc71d0b4489606350260f3c309813,12,8,1,13861,,,0,"Create new release of puppet-nova for victoria

Includes some features and fix needed for CentOS8-stream.

Change-Id: I97e2b2c091e0dafcbf03a536704e1613796bb62f
",git fetch https://review.opendev.org/openstack/releases refs/changes/39/774039/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/victoria/puppet-nova.yaml'],1,6b9cd13d9abcc71d0b4489606350260f3c309813,tripleo-ocata-eol, - projects: - hash: ae480ddabec91f93440beaef5441f2e31ad7bb41 repo: openstack/puppet-nova version: 17.6.0,,4,0
openstack%2Foslo.cache~master~Icb2b62d7d51cac652f9958ee094fef78a8ac9574,openstack/oslo.cache,master,Icb2b62d7d51cac652f9958ee094fef78a8ac9574,Add bug comment and fix nits,MERGED,2021-01-25 18:20:23.000000000,2021-02-08 15:16:27.000000000,2021-02-08 15:14:36.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-25 18:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/b6345b7ae2a5a73320b16b18e7bb1d4d0ab76d09', 'message': 'Add bug comment and fix nits\n\nChange-Id: Icb2b62d7d51cac652f9958ee094fef78a8ac9574\n'}, {'number': 2, 'created': '2021-02-05 13:35:27.000000000', 'files': ['oslo_cache/core.py', 'releasenotes/notes/bug-1888394-5a53e7a9cb25375b.yaml'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/e5d0b2019e30351e54ee27cbd7597a2114629f39', 'message': 'Add bug comment and fix nits\n\nChange-Id: Icb2b62d7d51cac652f9958ee094fef78a8ac9574\n'}]",6,772418,e5d0b2019e30351e54ee27cbd7597a2114629f39,12,2,2,28522,,,0,"Add bug comment and fix nits

Change-Id: Icb2b62d7d51cac652f9958ee094fef78a8ac9574
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/18/772418/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_cache/core.py', 'releasenotes/notes/bug-1888394-5a53e7a9cb25375b.yaml']",2,b6345b7ae2a5a73320b16b18e7bb1d4d0ab76d09,bug/1888394, But unfortunately this option is causing another issue., But unfortunatelly this option is causing another issue.,6,1
openstack%2Fironic~stable%2Fvictoria~Idba486c98e1e92d35fca2e2d156866566acb9e40,openstack/ironic,stable/victoria,Idba486c98e1e92d35fca2e2d156866566acb9e40,Don't mark an agent as alive if rebooted,MERGED,2021-02-08 10:55:25.000000000,2021-02-08 15:11:48.000000000,2021-02-08 15:09:11.000000000,"[{'_account_id': 1926}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-08 10:55:25.000000000', 'files': ['ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py', 'releasenotes/notes/agent-rebooted-fab20d012fe6cbe8.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cbccfa2a9ffa29ab1f74fb407973d78aedde1034', 'message': ""Don't mark an agent as alive if rebooted\n\nIf 'agent_url' has been cleared from internal_info\nit indicates that the node has been powered off.\n\nChange-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40\nStory: 2008583\nTask: 41736\n(cherry picked from commit 4287951d711b94972abd13bac6dcbd7250e0867e)\n""}]",0,774410,cbccfa2a9ffa29ab1f74fb407973d78aedde1034,9,3,1,10239,,,0,"Don't mark an agent as alive if rebooted

If 'agent_url' has been cleared from internal_info
it indicates that the node has been powered off.

Change-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40
Story: 2008583
Task: 41736
(cherry picked from commit 4287951d711b94972abd13bac6dcbd7250e0867e)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/774410/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py', 'releasenotes/notes/agent-rebooted-fab20d012fe6cbe8.yaml']",3,cbccfa2a9ffa29ab1f74fb407973d78aedde1034,,--- fixes: - | Fixes fast-track to prevent marking the agent as alive if trying to rebuild a node before the fast-track timeout has expired. ,,21,1
openstack%2Fneutron~master~I6340d132ff8e84edef8b7862337c395147a1beb2,openstack/neutron,master,I6340d132ff8e84edef8b7862337c395147a1beb2,[OVN] security group logging support (2 of 3),ABANDONED,2021-02-08 14:05:49.000000000,2021-02-08 15:08:41.000000000,,[],"[{'number': 1, 'created': '2021-02-08 14:05:49.000000000', 'files': ['neutron/services/logapi/drivers/ovn/driver.py', 'neutron/services/logapi/drivers/ovn/__init__.py', 'neutron/common/ovn/constants.py', 'neutron/common/ovn/extensions.py', 'neutron/conf/services/logging.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a8b628032751d3c4fd67f69f33242c43b162a00', 'message': '[OVN] security group logging support (2 of 3)\n\nThis patchset 2 of 3 for OVN driver handling of security-group-logging.\nIt includes the core changes for this feature.\n\nRelated-Bug: 1914757\nRelated-Bug: 1468366\n\nChange-Id: I6340d132ff8e84edef8b7862337c395147a1beb2\n'}]",0,774466,6a8b628032751d3c4fd67f69f33242c43b162a00,3,0,1,11952,,,0,"[OVN] security group logging support (2 of 3)

This patchset 2 of 3 for OVN driver handling of security-group-logging.
It includes the core changes for this feature.

Related-Bug: 1914757
Related-Bug: 1468366

Change-Id: I6340d132ff8e84edef8b7862337c395147a1beb2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/774466/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/logapi/drivers/ovn/driver.py', 'neutron/services/logapi/drivers/ovn/__init__.py', 'neutron/common/ovn/constants.py', 'neutron/common/ovn/extensions.py', 'neutron/conf/services/logging.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",6,6a8b628032751d3c4fd67f69f33242c43b162a00,,from neutron.services.logapi.drivers.ovn import driver as log_driver log_driver.register(self),,341,2
openstack%2Frally-openstack~master~I2e2d6b6f43b958193557aa6bb8d5e3fe06ef73c7,openstack/rally-openstack,master,I2e2d6b6f43b958193557aa6bb8d5e3fe06ef73c7,Remove __unicode__() from RallyCliError,MERGED,2021-01-08 03:09:19.000000000,2021-02-08 14:48:04.000000000,2021-02-08 14:48:04.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-08 03:09:19.000000000', 'files': ['tests/functional/utils.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/934b2a596ee0ff763b59645c99a9ef0843d1134b', 'message': 'Remove __unicode__() from RallyCliError\n\nThis is no longer needed in Python 3.\n\nChange-Id: I2e2d6b6f43b958193557aa6bb8d5e3fe06ef73c7\n'}]",0,769865,934b2a596ee0ff763b59645c99a9ef0843d1134b,18,2,1,30092,,,0,"Remove __unicode__() from RallyCliError

This is no longer needed in Python 3.

Change-Id: I2e2d6b6f43b958193557aa6bb8d5e3fe06ef73c7
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/65/769865/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/functional/utils.py'],1,934b2a596ee0ff763b59645c99a9ef0843d1134b,,, def __unicode__(self): return self.msg ,0,3
openstack%2Fkolla~master~I07490bc3a7809415fe1734aee255143c205d9573,openstack/kolla,master,I07490bc3a7809415fe1734aee255143c205d9573,[docs] Add templates and examples of renos,MERGED,2021-01-31 17:52:54.000000000,2021-02-08 14:39:16.000000000,2021-02-08 14:24:23.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2021-01-31 17:52:54.000000000', 'files': ['releasenotes/templates/feature.yml', 'doc/source/contributor/release-notes.rst', 'releasenotes/templates/fix.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0c3441599671e278031d07f87b318881870c8f10', 'message': ""[docs] Add templates and examples of renos\n\nWith tips and clarifications.\n\nAdapted from Kolla Ansible's patch. [1]\n\n[1] https://review.opendev.org/c/openstack/kolla-ansible/+/759254\n\nChange-Id: I07490bc3a7809415fe1734aee255143c205d9573\n""}]",0,773261,0c3441599671e278031d07f87b318881870c8f10,8,3,1,30491,,,0,"[docs] Add templates and examples of renos

With tips and clarifications.

Adapted from Kolla Ansible's patch. [1]

[1] https://review.opendev.org/c/openstack/kolla-ansible/+/759254

Change-Id: I07490bc3a7809415fe1734aee255143c205d9573
",git fetch https://review.opendev.org/openstack/kolla refs/changes/61/773261/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/release-notes.rst', 'releasenotes/templates/feature.yml', 'releasenotes/templates/fix.yml']",3,0c3441599671e278031d07f87b318881870c8f10,docs-contributor-release-notes,--- fixes: - | Fixes [some bug]. [Can be described using multiple sentences if necessary.] [Possibly also giving the previous behaviour description.] `LP#[bug number] <https://launchpad.net/bugs/[bug number]>`__ ,,143,2
openstack%2Fbifrost~stable%2Fvictoria~I90c7ba15a10faaab24712a8cdc8b6c67457b51a6,openstack/bifrost,stable/victoria,I90c7ba15a10faaab24712a8cdc8b6c67457b51a6,Collect firewalld info if present,MERGED,2021-02-08 11:01:01.000000000,2021-02-08 14:38:51.000000000,2021-02-08 14:27:44.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-08 11:01:01.000000000', 'files': ['scripts/collect-test-info.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e6fde21025af443c3b19fcc851a582969e816d27', 'message': 'Collect firewalld info if present\n\nChange-Id: I90c7ba15a10faaab24712a8cdc8b6c67457b51a6\n(cherry picked from commit 70101f6a2d18d71b98f0ccc2518550cef7a17ecb)\n'}]",0,774412,e6fde21025af443c3b19fcc851a582969e816d27,7,3,1,10239,,,0,"Collect firewalld info if present

Change-Id: I90c7ba15a10faaab24712a8cdc8b6c67457b51a6
(cherry picked from commit 70101f6a2d18d71b98f0ccc2518550cef7a17ecb)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/12/774412/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/collect-test-info.sh'],1,e6fde21025af443c3b19fcc851a582969e816d27,collect-firewalld-info-stable/victoria, if $(sudo firewall-cmd --version &>/dev/null); then sudo firewall-cmd --list-all-zones &> ${LOG_LOCATION}/firewalld-zones.log fi ,,5,0
openstack%2Fkolla~stable%2Fvictoria~I644e072a699dccd8f32a24e484ff6dab7b9b449d,openstack/kolla,stable/victoria,I644e072a699dccd8f32a24e484ff6dab7b9b449d,Horizon: gentler `-o nounset` handling,MERGED,2021-01-29 20:02:51.000000000,2021-02-08 14:38:38.000000000,2021-02-08 14:22:48.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2021-01-29 20:02:51.000000000', 'files': ['docker/horizon/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6e02f95883f31e77793454b7a8c18eeea01fc62f', 'message': ""Horizon: gentler `-o nounset` handling\n\nWhen running with `-o nounset` since [1], the Horizon became quite\nfragile to run as it started requiring all ENABLE_* environment\nvariables to be set upfront. Normally they are - via kolla-ansible.\nHowever, when working with it outside of kolla-ansible or removing\nservices (like it was the case 3 times during the Wallaby cycle),\nit creates needless issues (like having to wait for images to get\npublished for kolla-ansible gate or users bumping into irrelevant\nincompatibilities [2]).\n\nThis patch makes sure all ENABLE_* environment variables default\nto 'no' and are no longer required to be set when there is no\nneed to set them to 'yes'.\n\n[1] 032804e5a0ddf89f7726880d1b57dd492d7d5c07\n[2] https://bugs.launchpad.net/kolla/+bug/1911141\n\nChange-Id: I644e072a699dccd8f32a24e484ff6dab7b9b449d\n(cherry picked from commit 48e6309926f42b46369a7c06cc9f81e9188da802)\n""}]",0,773196,6e02f95883f31e77793454b7a8c18eeea01fc62f,9,3,1,30491,,,0,"Horizon: gentler `-o nounset` handling

When running with `-o nounset` since [1], the Horizon became quite
fragile to run as it started requiring all ENABLE_* environment
variables to be set upfront. Normally they are - via kolla-ansible.
However, when working with it outside of kolla-ansible or removing
services (like it was the case 3 times during the Wallaby cycle),
it creates needless issues (like having to wait for images to get
published for kolla-ansible gate or users bumping into irrelevant
incompatibilities [2]).

This patch makes sure all ENABLE_* environment variables default
to 'no' and are no longer required to be set when there is no
need to set them to 'yes'.

[1] 032804e5a0ddf89f7726880d1b57dd492d7d5c07
[2] https://bugs.launchpad.net/kolla/+bug/1911141

Change-Id: I644e072a699dccd8f32a24e484ff6dab7b9b449d
(cherry picked from commit 48e6309926f42b46369a7c06cc9f81e9188da802)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/96/773196/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/horizon/extend_start.sh'],1,6e02f95883f31e77793454b7a8c18eeea01fc62f,horizon-gentler-nounset-handling-stable/victoria," config_dashboard ""${ENABLE_BLAZAR:-no}"" \ config_dashboard ""${ENABLE_CLOUDKITTY:-no}"" \ config_dashboard ""${ENABLE_DESIGNATE:-no}"" \ config_dashboard ""${ENABLE_FREEZER:-no}"" \ config_dashboard ""${ENABLE_HEAT:-no}"" \ config_dashboard ""${ENABLE_HEAT:-no}"" \ config_dashboard ""${ENABLE_IRONIC:-no}"" \ config_dashboard ""${ENABLE_MAGNUM:-no}"" \ config_dashboard ""${ENABLE_MANILA:-no}"" \ config_dashboard ""${ENABLE_MASAKARI:-no}"" \ config_dashboard ""${ENABLE_MASAKARI:-no}""\ config_dashboard ""${ENABLE_MASAKARI:-no}""\ config_dashboard ""${ENABLE_MONASCA:-no}"" \ config_dashboard ""${ENABLE_MONASCA:-no}"" \ config_dashboard ""${ENABLE_MURANO:-no}"" \ config_dashboard ""${ENABLE_MURANO:-no}""\ config_dashboard ""${ENABLE_MURANO:-no}""\ config_dashboard ""${ENABLE_MISTRAL:-no}"" \ config_dashboard ""${ENABLE_NEUTRON_VPNAAS:-no}"" \ config_dashboard ""${ENABLE_OCTAVIA:-no}"" \ config_dashboard ""${ENABLE_SAHARA:-no}"" \ config_dashboard ""${ENABLE_SENLIN:-no}"" \ config_dashboard ""${ENABLE_SENLIN:-no}"" \ config_dashboard ""${ENABLE_SOLUM:-no}"" \ config_dashboard ""${ENABLE_TACKER:-no}"" \ config_dashboard ""${ENABLE_TROVE:-no}"" \ config_dashboard ""${ENABLE_VITRAGE:-no}"" \ config_dashboard ""${ENABLE_WATCHER:-no}"" \ config_dashboard ""${ENABLE_WATCHER:-no}"" \ config_dashboard ""${ENABLE_ZAQAR:-no}"" \ config_dashboard ""${ENABLE_ZUN:-no}"" \"," config_dashboard ""${ENABLE_BLAZAR}"" \ config_dashboard ""${ENABLE_CLOUDKITTY}"" \ config_dashboard ""${ENABLE_DESIGNATE}"" \ config_dashboard ""${ENABLE_FREEZER}"" \ config_dashboard ""${ENABLE_HEAT}"" \ config_dashboard ""${ENABLE_HEAT}"" \ config_dashboard ""${ENABLE_IRONIC}"" \ config_dashboard ""${ENABLE_MAGNUM}"" \ config_dashboard ""${ENABLE_MANILA}"" \ config_dashboard ""${ENABLE_MASAKARI}"" \ config_dashboard ""${ENABLE_MASAKARI}""\ config_dashboard ""${ENABLE_MASAKARI}""\ config_dashboard ""${ENABLE_MONASCA}"" \ config_dashboard ""${ENABLE_MONASCA}"" \ config_dashboard ""${ENABLE_MURANO}"" \ config_dashboard ""${ENABLE_MURANO}""\ config_dashboard ""${ENABLE_MURANO}""\ config_dashboard ""${ENABLE_MISTRAL}"" \ config_dashboard ""${ENABLE_NEUTRON_VPNAAS}"" \ config_dashboard ""${ENABLE_OCTAVIA}"" \ config_dashboard ""${ENABLE_SAHARA}"" \ config_dashboard ""${ENABLE_SENLIN}"" \ config_dashboard ""${ENABLE_SENLIN}"" \ config_dashboard ""${ENABLE_SOLUM}"" \ config_dashboard ""${ENABLE_TACKER}"" \ config_dashboard ""${ENABLE_TROVE}"" \ config_dashboard ""${ENABLE_VITRAGE}"" \ config_dashboard ""${ENABLE_WATCHER}"" \ config_dashboard ""${ENABLE_WATCHER}"" \ # NOTE(yoctozepto): Kolla-Ansible does not control Zaqar and therefore # does not set ENABLE_ZAQAR; the workaround below ensures it gets set to # `no` in that case to fix this code under `set -o nounset`. ENABLE_ZAQAR=${ENABLE_ZAQAR-no} config_dashboard ""${ENABLE_ZAQAR}"" \ config_dashboard ""${ENABLE_ZUN}"" \",31,36
openstack%2Fopenstack-helm-infra~master~I6a281d354505710007e4e55146a9160e5f52d639,openstack/openstack-helm-infra,master,I6a281d354505710007e4e55146a9160e5f52d639,[ceph-client] Update ceph-client release notes to include 0.1.6,ABANDONED,2021-02-08 14:28:13.000000000,2021-02-08 14:36:42.000000000,,[],"[{'number': 1, 'created': '2021-02-08 14:28:13.000000000', 'files': ['releasenotes/notes/ceph-client.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a02dd1a026d8e19d78b8e1244450a2f07a391134', 'message': ""[ceph-client] Update ceph-client release notes to include 0.1.6\n\nThe previous update was in progress at the same time as the patch\nset for 0.1.6 and 0.1.6 wasn't included when both merged\neffectively simultaneously.\n\nChange-Id: I6a281d354505710007e4e55146a9160e5f52d639\n""}]",0,774470,a02dd1a026d8e19d78b8e1244450a2f07a391134,2,0,1,29974,,,0,"[ceph-client] Update ceph-client release notes to include 0.1.6

The previous update was in progress at the same time as the patch
set for 0.1.6 and 0.1.6 wasn't included when both merged
effectively simultaneously.

Change-Id: I6a281d354505710007e4e55146a9160e5f52d639
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/70/774470/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-client.yaml'],1,a02dd1a026d8e19d78b8e1244450a2f07a391134,, - 0.1.6 Don't wait for premerge PGs in the rbd pool job,,1,0
openstack%2Ftripleo-quickstart~master~I841efd256677ade1ec99520cfe5a1e503d847af0,openstack/tripleo-quickstart,master,I841efd256677ade1ec99520cfe5a1e503d847af0,undercloud-oooq is failing in tempest,ABANDONED,2021-01-29 15:07:52.000000000,2021-02-08 14:17:48.000000000,,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-29 15:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/78ed1dc8b253ca4f50b5a0c71d986a69578bf2d5', 'message': 'undercloud-oooq is failing in tempest\n\nSwitch back to the old tempest execution rather than os_tempest.\n\nChange-Id: I841efd256677ade1ec99520cfe5a1e503d847af0\n'}, {'number': 2, 'created': '2021-02-03 20:37:42.000000000', 'files': ['config/general_config/featureset003.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ed1d36fc7f58386f0a22943e2e0b80f4829fdd87', 'message': 'undercloud-oooq is failing in tempest\n\nSwitch back to the old tempest execution rather than os_tempest.\n\nChange-Id: I841efd256677ade1ec99520cfe5a1e503d847af0\n'}]",2,773092,ed1d36fc7f58386f0a22943e2e0b80f4829fdd87,20,7,2,14985,,,0,"undercloud-oooq is failing in tempest

Switch back to the old tempest execution rather than os_tempest.

Change-Id: I841efd256677ade1ec99520cfe5a1e503d847af0
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/92/773092/2 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset003.yml'],1,78ed1dc8b253ca4f50b5a0c71d986a69578bf2d5,fix-queens,run_tempest: true use_os_tempest: false,,2,0
openstack%2Fcinder~master~I99fb6e41a4448848da7ac45ec518a0700608b140,openstack/cinder,master,I99fb6e41a4448848da7ac45ec518a0700608b140,Zadara multiattach and ipv6 changes for cinder driver,ABANDONED,2020-12-28 04:53:01.000000000,2021-02-08 13:42:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-28 04:53:01.000000000', 'files': ['cinder/volume/drivers/zadara/__init__.py', 'cinder/volume/drivers/zadara/exception.py', 'cinder/volume/drivers/zadara/common.py', 'cinder/volume/drivers/zadara/zadara.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/71e7327f7e961c0f4ce1c37185c2799587fabe79', 'message': 'Zadara multiattach and ipv6 changes for cinder driver\n\nChange-Id: I99fb6e41a4448848da7ac45ec518a0700608b140\n'}]",2,768593,71e7327f7e961c0f4ce1c37185c2799587fabe79,21,1,1,32880,,,0,"Zadara multiattach and ipv6 changes for cinder driver

Change-Id: I99fb6e41a4448848da7ac45ec518a0700608b140
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/768593/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/zadara/__init__.py', 'cinder/volume/drivers/zadara/common.py', 'cinder/volume/drivers/zadara/exception.py', 'cinder/volume/drivers/zadara/zadara.py']",4,71e7327f7e961c0f4ce1c37185c2799587fabe79,TOPIC-BRANCH,"# Copyright (c) 2019 Zadara Storage, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Volume driver for Zadara Virtual Private Storage Array (VPSA). This driver requires VPSA with API version 15.07 or higher. """""" from oslo_config import cfg from oslo_utils import strutils import six from cinder import exception as cinder_exception from cinder.i18n import _ from cinder import interface from cinder.objects import fields from cinder.volume import configuration from cinder.volume import driver from cinder.volume.drivers.zadara.common import common_exception from cinder.volume.drivers.zadara.common import LOG from cinder.volume.drivers.zadara.common import zadara_opts from cinder.volume.drivers.zadara.common import ZadaraVPSAConnection from cinder.volume.drivers.zadara import exception as zadara_exception from cinder.volume import volume_utils CONF = cfg.CONF CONF.register_opts(zadara_opts, group=configuration.SHARED_CONF_GROUP) @interface.volumedriver class ZadaraVPSAISCSIDriver(driver.ISCSIDriver): """"""Zadara VPSA iSCSI/iSER volume driver. .. code-block:: none Version history: 15.07 - Initial driver 16.05 - Move from httplib to requests 19.08 - Add API access key authentication option 20.01 - Move to json format from xml. Provide manage/unmanage volume/snapshot feature 20.12-01 - Merging with the common code for all the openstack drivers 20.12-02 - Common code changed as part of fixing #18723 20.12-03 - Adding the metadata support while creating volume to configure vpsa. 21.04 - IPv6 connectivity support for Cinder driver """""" VERSION = '21.04' # ThirdPartySystems wiki page CI_WIKI_NAME = ""ZadaraStorage_VPSA_CI"" def __init__(self, *args, **kwargs): super(ZadaraVPSAISCSIDriver, self).__init__(*args, **kwargs) self.vpsa = None self.configuration.append_config_values(zadara_opts) # The valid list of volume options that can be specified # as the metadata while creating cinder volume self.vol_options = ['crypt', 'compress', 'dedupe', 'attachpolicies'] @staticmethod def get_driver_options(): return zadara_opts def _check_access_key_validity(self): try: self.vpsa._check_access_key_validity() except common_exception.MalformedResponse as e: raise zadara_exception.MalformedResponse(cmd=e.cmd, reason=e.reason) except common_exception.ZadaraInvalidAccessKey: raise zadara_exception.ZadaraCinderInvalidAccessKey() def do_setup(self, context): """"""Any initialization the volume driver does while starting. Establishes initial connection with VPSA and retrieves access_key. Need to pass driver_ssl_cert_path here (and not fetch it from the config opts directly in common code), because this config option is different for different drivers and so cannot be figured in the common code. """""" driver_ssl_cert_path = self.configuration.driver_ssl_cert_path self.vpsa = ZadaraVPSAConnection(self.configuration, driver_ssl_cert_path, True) self._check_access_key_validity() def check_for_setup_error(self): """"""Returns an error (exception) if prerequisites aren't met."""""" self._check_access_key_validity() def local_path(self, volume): """"""Return local path to existing local volume."""""" raise NotImplementedError() def vpsa_send_cmd(self, cmd, **kwargs): try: response = self.vpsa.send_cmd(cmd, **kwargs) except common_exception.UnknownCmd as e: raise zadara_exception.UnknownCmd(cmd=e.cmd) except common_exception.SessionRequestException as e: raise zadara_exception.SessionRequestException(msg=e.msg) except common_exception.BadHTTPResponseStatus as e: raise zadara_exception.BadHTTPResponseStatus(status=e.status) except common_exception.FailedCmdWithDump as e: raise zadara_exception.FailedCmdWithDump(status=e.status, data=e.data) except common_exception.MalformedResponse as e: raise zadara_exception.MalformedResponse(cmd=e.cmd, reason=e.reason) except common_exception.ZadaraInvalidAccessKey: raise zadara_exception.ZadaraCinderInvalidAccessKey() return response def _validate_existing_ref(self, existing_ref): """"""Validates existing ref"""""" if ""name"" not in existing_ref or not existing_ref[""name""]: raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=_(""manage_existing requires a 'name'"" "" key to identify an existing volume."")) def _get_volume_metadata(self, volume): if 'metadata' in volume: return volume.metadata if 'volume_metadata' in volume: metadata = volume.volume_metadata return {m['key']: m['value'] for m in metadata} return {} def is_valid_metadata(self, metadata): LOG.debug('Metadata while creating volume: %(metadata)s', {'metadata': metadata}) for key, value in metadata.items(): if key in self.vol_options: # Check the values allowed for provided metadata if value in ['YES', 'NO']: continue else: return False return True def create_volume(self, volume): """"""Create volume."""""" vol_name = self.configuration.zadara_vol_name_template % volume['name'] # Collect the volume metadata if any provided and validate it metadata = self._get_volume_metadata(volume) if not self.is_valid_metadata(metadata): msg = (_('Not a valid metadata for Volume %s') % vol_name) LOG.error(msg) raise cinder_exception.VolumeDriverException(message=msg) self.vpsa_send_cmd( 'create_volume', name=vol_name, size=volume['size'], metadata=metadata) vpsa_volume = self.vpsa._get_vpsa_volume(vol_name) if not vpsa_volume: msg = _('VPSA volume %s could not be found.') % vol_name LOG.error(msg) raise cinder_exception.VolumeNotFound(volume_id=volume['id']) def delete_volume(self, volume): """"""Delete volume. Return ok if doesn't exist. Auto detach from all servers. """""" # Get volume name name = self.configuration.zadara_vol_name_template % volume['name'] volume = self.vpsa._get_vpsa_volume(name) if not volume: LOG.warning('Volume %s could not be found. ' 'It might be already deleted', name) return self.vpsa._detach_vpsa_volume(vpsa_vol=volume['name']) # Delete volume self.vpsa_send_cmd('delete_volume', vpsa_vol=volume['name']) def create_snapshot(self, snapshot): """"""Creates a snapshot."""""" LOG.debug('Create snapshot: %s', snapshot['name']) # Retrieve the CG name for the base volume volume_name = (self.configuration.zadara_vol_name_template % snapshot['volume_name']) cg_name = self.vpsa._get_volume_cg_name(volume_name) if not cg_name: msg = _('Volume %(name)s not found') % {'name': volume_name} LOG.error(msg) raise cinder_exception.VolumeDriverException(message=msg) self.vpsa_send_cmd('create_snapshot', cg_name=cg_name, snap_name=snapshot['name']) def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" LOG.debug('Delete snapshot: %s', snapshot['name']) # Retrieve the CG name for the base volume volume_name = (self.configuration.zadara_vol_name_template % snapshot['volume_name']) cg_name = self.vpsa._get_volume_cg_name(volume_name) if not cg_name: # If the volume isn't present, then don't attempt to delete LOG.warning('snapshot: original volume %s not found, ' 'skipping delete operation', volume_name) return snap_id = self.vpsa._get_snap_id(cg_name, snapshot['name']) if not snap_id: # If the snapshot isn't present, then don't attempt to delete LOG.warning('snapshot: snapshot %s not found, ' 'skipping delete operation', snapshot['name']) return self.vpsa_send_cmd('delete_snapshot', snap_id=snap_id) def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug('Creating volume from snapshot: %s', snapshot['name']) # Retrieve the CG name for the base volume volume_name = (self.configuration.zadara_vol_name_template % snapshot['volume_name']) cg_name = self.vpsa._get_volume_cg_name(volume_name) if not cg_name: LOG.error('Volume %(name)s not found', {'name': volume_name}) raise cinder_exception.VolumeNotFound(volume_id=volume['id']) snap_id = self.vpsa._get_snap_id(cg_name, snapshot['name']) if not snap_id: LOG.error('Snapshot %(name)s not found', {'name': snapshot['name']}) raise cinder_exception.SnapshotNotFound(snapshot_id=snapshot['id']) self.vpsa_send_cmd('create_clone_from_snap', cg_name=cg_name, name=self.configuration.zadara_vol_name_template % volume['name'], snap_id=snap_id) if volume['size'] > snapshot['volume_size']: self.extend_volume(volume, volume['size']) def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" LOG.debug('Creating clone of volume: %s', src_vref['name']) # Retrieve the CG name for the base volume volume_name = (self.configuration.zadara_vol_name_template % src_vref['name']) cg_name = self.vpsa._get_volume_cg_name(volume_name) if not cg_name: LOG.error('Volume %(name)s not found', {'name': volume_name}) raise cinder_exception.VolumeNotFound(volume_id=volume['id']) self.vpsa_send_cmd('create_clone', cg_name=cg_name, name=self.configuration.zadara_vol_name_template % volume['name']) if volume['size'] > src_vref['size']: self.extend_volume(volume, volume['size']) def extend_volume(self, volume, new_size): """"""Extend an existing volume."""""" # Get volume name name = self.configuration.zadara_vol_name_template % volume['name'] volume = self.vpsa._get_vpsa_volume(name) if not volume: msg = (_('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name}) LOG.error(msg) raise zadara_exception.ZadaraVolumeNotFound(reason=msg) size = volume['virtual_capacity'] if new_size < size: raise cinder_exception.InvalidInput( reason=_('%(new_size)s < current size %(size)s') % {'new_size': new_size, 'size': size}) expand_size = new_size - size self.vpsa_send_cmd('expand_volume', vpsa_vol=volume['name'], size=expand_size) def create_export(self, context, volume, vg=None): """"""Irrelevant for VPSA volumes. Export created during attachment."""""" pass def ensure_export(self, context, volume): """"""Irrelevant for VPSA volumes. Export created during attachment."""""" pass def remove_export(self, context, volume): """"""Irrelevant for VPSA volumes. Export removed during detach."""""" pass def get_manageable_volumes(self, cinder_volumes, marker, limit, offset, sort_keys, sort_dirs): """"""List volumes on the backend available for management by Cinder"""""" # Get all vpsa volumes all_vpsa_volumes = self.vpsa._get_all_vpsa_volumes() # Create a dictionary of existing volumes existing_vols = {} for cinder_vol in cinder_volumes: cinder_name = (self.configuration.zadara_vol_name_template % cinder_vol['name']) volume = self.vpsa._get_vpsa_volume(cinder_name, volumes=all_vpsa_volumes) if volume: existing_vols[volume['name']] = cinder_vol.name_id # Filter out all volumes already attached to any server volumes_in_use = {} volumes_not_available = {} for volume in all_vpsa_volumes: if existing_vols.get(volume['name']): continue if volume['status'] == 'In-use': volumes_in_use[volume['name']] =\ self.vpsa._get_servers_attached_to_volume(volume['name']) continue if volume['status'] != 'Available': volumes_not_available[volume['name']] = volume['display_name'] continue manageable_vols = [] for vpsa_volume in all_vpsa_volumes: vol_name = vpsa_volume['name'] vol_display_name = vpsa_volume['display_name'] cinder_id = existing_vols.get(vol_name) not_safe_msgs = [] if volumes_in_use.get(vol_name): host_list = volumes_in_use[vol_name] not_safe_msgs.append(_('Volume connected to host(s) %s') % host_list) if volumes_not_available.get(vol_name): not_safe_msgs.append(_('Volume not available')) if cinder_id: not_safe_msgs.append(_('Volume already managed')) is_safe = (len(not_safe_msgs) == 0) reason_not_safe = '' if not is_safe: for i, msg in enumerate(not_safe_msgs): if i > 0: reason_not_safe += ' && ' reason_not_safe += ""%s"" % msg manageable_vols.append({ 'reference': {'name': vol_display_name}, 'size': vpsa_volume['virtual_capacity'], 'safe_to_manage': is_safe, 'reason_not_safe': reason_not_safe, 'cinder_id': cinder_id, }) return volume_utils.paginate_entries_list( manageable_vols, marker, limit, offset, sort_keys, sort_dirs) def manage_existing(self, volume, existing_ref): """"""Bring an existing volume into cinder management"""""" self._validate_existing_ref(existing_ref) # Check if the volume exists in vpsa name = existing_ref['name'] vpsa_volume = self.vpsa._get_vpsa_volume(name) if not vpsa_volume: msg = (_('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name}) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) # Check if the volume is available if vpsa_volume['status'] != 'Available': msg = (_('Existing volume %(name)s is not available') % {'name': name}) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) # Rename the volume to cinder specified name new_name = self.configuration.zadara_vol_name_template % volume['name'] new_vpsa_volume = self.vpsa._get_vpsa_volume(new_name) if new_vpsa_volume: msg = (_('Volume %(new_name)s already exists') % {'new_name': new_name}) LOG.error(msg) raise cinder_exception.VolumeDriverException(message=msg) self.vpsa_send_cmd('rename_volume', vpsa_vol=vpsa_volume['name'], new_name=new_name) def manage_existing_get_size(self, volume, existing_ref): """"""Return size of volume to be managed by manage_existing"""""" # Check if the volume exists in vpsa self._validate_existing_ref(existing_ref) name = existing_ref['name'] vpsa_volume = self.vpsa._get_vpsa_volume(name) if not vpsa_volume: msg = (_('Volume %(name)s could not be found. ' 'It might be already deleted') % {'name': name}) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) # Return the size of the volume return vpsa_volume['virtual_capacity'] def unmanage(self, volume): """"""Removes the specified volume from Cinder management"""""" pass def get_manageable_snapshots(self, cinder_snapshots, marker, limit, offset, sort_keys, sort_dirs): """"""Interface to support listing manageable snapshots and volumes"""""" # Get all volumes all_vpsa_volumes = self.vpsa._get_all_vpsa_volumes() # Get all snapshots of all volumes all_vpsa_snapshots = [] for vpsa_vol in all_vpsa_volumes: if vpsa_vol['has_snapshots'] != 'YES': continue cg_name = vpsa_vol['cg_name'] if not cg_name: continue snapshots = self.vpsa._get_volume_snapshots(cg_name) for snapshot in snapshots: snapshot['volume_name'] = vpsa_vol['display_name'] snapshot['size'] = vpsa_vol['virtual_capacity'] all_vpsa_snapshots += snapshots existing_snapshots = {} for cinder_snapshot in cinder_snapshots: volume_name = (self.configuration.zadara_vol_name_template % cinder_snapshot['volume_name']) cg_name = self.vpsa._get_volume_cg_name(volume_name, all_vpsa_volumes) if not cg_name: continue snap_id = self.vpsa._get_snap_id(cg_name, cinder_snapshot['name']) if not snap_id: continue existing_snapshots[snap_id] = cinder_snapshot.id manageable_snapshots = [] try: unique_snapshots = [] for snapshot in all_vpsa_snapshots: snap_id = snapshot['name'] if snap_id in unique_snapshots: continue cinder_id = existing_snapshots.get(snap_id) is_safe = True reason_not_safe = None if cinder_id: is_safe = False reason_not_safe = _(""Snapshot already managed."") manageable_snapshots.append({ 'reference': {'name': snapshot['display_name']}, 'size': snapshot['size'], 'safe_to_manage': is_safe, 'reason_not_safe': reason_not_safe, 'cinder_id': cinder_id, 'extra_info': None, 'source_reference': {'name': snapshot['volume_name']}, }) unique_snapshots.append(snap_id) return volume_utils.paginate_entries_list( manageable_snapshots, marker, limit, offset, sort_keys, sort_dirs) except Exception as e: msg = (_('Exception: %s') % six.text_type(e)) LOG.error(msg) raise def manage_existing_snapshot(self, snapshot, existing_ref): """"""Brings an existing backend storage object under Cinder management"""""" self._validate_existing_ref(existing_ref) snap_name = existing_ref['name'] volume_name = (self.configuration.zadara_vol_name_template % snapshot['volume_name']) volume = self.vpsa._get_vpsa_volume(volume_name) if not volume: msg = (_('Source volume of snapshot %s could not be found.' ' Invalid data') % snap_name) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) # Check if the snapshot exists snap_id = self.vpsa._get_snap_id(volume['cg_name'], snap_name) if not snap_id: msg = (_('Snapshot %s could not be found. It might be' ' already deleted') % snap_name) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) new_name = snapshot['name'] new_snap_id = self.vpsa._get_snap_id(volume['cg_name'], new_name) if new_snap_id: msg = (_('Snapshot with name %s already exists') % new_name) LOG.debug(msg) return self.vpsa_send_cmd('rename_snapshot', snap_id=snap_id, new_name=new_name) def manage_existing_snapshot_get_size(self, snapshot, existing_ref): """"""Return size of snapshot to be managed by manage_existing"""""" # We do not have any size field for a snapshot. # We only have it on volumes. So, here just figure # out the parent volume of this snapshot and return its size self._validate_existing_ref(existing_ref) snap_name = existing_ref['name'] volume_name = (self.configuration.zadara_vol_name_template % snapshot['volume_name']) volume = self.vpsa._get_vpsa_volume(volume_name) if not volume: msg = (_('Source volume of snapshot %s could not be found.' ' Invalid data') % snap_name) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) snap_id = self.vpsa._get_snap_id(volume['cg_name'], snap_name) if not snap_id: msg = (_('Snapshot %s could not be found. It might be ' 'already deleted') % snap_name) LOG.error(msg) raise cinder_exception.ManageExistingInvalidReference( existing_ref=existing_ref, reason=msg) return volume['virtual_capacity'] def unmanage_snapshot(self, snapshot): """"""Removes the specified snapshot from Cinder management"""""" pass def initialize_connection(self, volume, connector): """"""Attach volume to initiator/host. During this call VPSA exposes volume to particular Initiator. It also creates a 'server' entity for Initiator (if it was not created before) All necessary connection information is returned, including auth data. Connection data (target, LUN) is not stored in the DB. """""" # First: Check Active controller: if not valid, raise exception ctrl = self.vpsa._get_active_controller_details() if not ctrl: raise zadara_exception.ZadaraVPSANoActiveController() # Get/Create server name for IQN initiator_name = connector['initiator'] vpsa_srv = self.vpsa._create_vpsa_server(iqn=initiator_name) if not vpsa_srv: raise zadara_exception.ZadaraServerCreateFailure( name=initiator_name) # Get volume name name = self.configuration.zadara_vol_name_template % volume['name'] vpsa_volume = self.vpsa._get_vpsa_volume(name) if not vpsa_volume: raise cinder_exception.VolumeNotFound(volume_id=volume['id']) data = self.vpsa_send_cmd('list_vol_attachments', vpsa_vol=vpsa_volume['name']) servers = data.get('servers', []) attach = None for server in servers: if server['name'] == vpsa_srv: attach = server break # Attach volume to server if attach is None: self.vpsa_send_cmd('attach_volume', vpsa_srv=vpsa_srv, vpsa_vol=vpsa_volume['name']) data = self.vpsa_send_cmd('list_vol_attachments', vpsa_vol=vpsa_volume['name']) server = None servers = data.get('servers', []) for srv in servers: if srv['iqn'] == initiator_name: server = srv break if server is None: raise zadara_exception.ZadaraAttachmentsNotFound(name=name) target = server['target'] lun = int(server['lun']) if None in [target, lun]: raise zadara_exception.ZadaraInvalidAttachmentInfo( name=name, reason=_('target=%(target)s, lun=%(lun)s') % {'target': target, 'lun': lun}) properties = {'target_discovered': False, 'target_portal': (('%s:%s') % (self.vpsa._get_target_host(ctrl['ip']), '3260')), 'target_iqn': target, 'target_lun': lun, 'volume_id': volume['id'], 'auth_method': 'CHAP', 'auth_username': ctrl['chap_user'], 'auth_password': ctrl['chap_passwd']} LOG.debug('Attach properties: %(properties)s', {'properties': strutils.mask_password(properties)}) return {'driver_volume_type': ('iser' if (self.configuration.safe_get('zadara_use_iser')) else 'iscsi'), 'data': properties} def terminate_connection(self, volume, connector, **kwargs): """"""Detach volume from the initiator."""""" name = self.configuration.zadara_vol_name_template % volume['name'] vpsa_volume = self.vpsa._get_vpsa_volume(name) if connector is None: # Detach volume from all servers # Get volume name if vpsa_volume: self.vpsa._detach_vpsa_volume(vpsa_vol=vpsa_volume['name']) return else: LOG.warning('Volume %s could not be found', name) raise cinder_exception.VolumeNotFound(volume_id=volume['id']) # Check if there are multiple attachments to the volume from the # same host. Terminate connection only for the last attachment from # the corresponding host. count = 0 host = connector.get('host') if connector else None if host and volume.get('multiattach'): attach_list = volume.volume_attachment for attachment in attach_list: if (attachment['attach_status'] != fields.VolumeAttachStatus.ATTACHED): continue if attachment.attached_host == host: count += 1 if count > 1: return # Get server name for IQN initiator_name = connector['initiator'] vpsa_srv = self.vpsa._get_server_name(initiator_name, False) if not vpsa_srv: raise zadara_exception.ZadaraServerNotFound(name=initiator_name) if not vpsa_volume: raise cinder_exception.VolumeNotFound(volume_id=volume['id']) # Detach volume from server self.vpsa._detach_vpsa_volume(vpsa_vol=vpsa_volume['name'], vpsa_srv=vpsa_srv) def get_volume_stats(self, refresh=False): """"""Get volume stats. If 'refresh' is True, run update the stats first. """""" if refresh: self._update_volume_stats() return self._stats def _update_volume_stats(self): """"""Retrieve stats info from volume group."""""" LOG.debug(""Updating volume stats"") data = {} backend_name = self.configuration.safe_get('volume_backend_name') storage_protocol = ('iSER' if (self.configuration.safe_get('zadara_use_iser')) else 'iSCSI') data[""volume_backend_name""] = backend_name or self.__class__.__name__ data[""vendor_name""] = 'Zadara Storage' data[""driver_version""] = self.VERSION data[""storage_protocol""] = storage_protocol data['reserved_percentage'] = self.configuration.reserved_percentage data['QoS_support'] = False data['multiattach'] = True (total, free) = self.vpsa._get_pool_capacity(self.configuration. zadara_vpsa_poolname) data['total_capacity_gb'] = total data['free_capacity_gb'] = free self._stats = data ",,2450,0
openstack%2Fneutron~stable%2Ftrain~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/train,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 12:10:56.000000000,2021-02-08 13:40:08.000000000,2021-02-08 13:34:23.000000000,"[{'_account_id': 11975}, {'_account_id': 13095}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 12:10:56.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/40feff0e468e6575f51bd3295955a1724fdccdf4', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774130,40feff0e468e6575f51bd3295955a1724fdccdf4,14,4,1,16688,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/774130/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,40feff0e468e6575f51bd3295955a1724fdccdf4,bug-1912651-stable/ussuri-stable/train, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Fneutron~stable%2Fstein~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/stein,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 12:11:37.000000000,2021-02-08 13:39:48.000000000,2021-02-08 13:34:32.000000000,"[{'_account_id': 11975}, {'_account_id': 13095}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 12:11:37.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6bb79261a7bfbd2d2c0d79e719a36e1c7e34a8a', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774132,a6bb79261a7bfbd2d2c0d79e719a36e1c7e34a8a,10,4,1,16688,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/774132/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,a6bb79261a7bfbd2d2c0d79e719a36e1c7e34a8a,bug-1912651-stable/stein, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Ftripleo-common~stable%2Fussuri~Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f,openstack/tripleo-common,stable/ussuri,Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f,Use the new IPA-builder element for installing python-hardware,MERGED,2021-01-29 14:53:26.000000000,2021-02-08 13:37:09.000000000,2021-02-08 13:33:07.000000000,"[{'_account_id': 8449}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-29 14:53:26.000000000', 'files': ['image-yaml/overcloud-images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2e2f741ea6dc90157ec92331df3d8fbbf9dc9297', 'message': 'Use the new IPA-builder element for installing python-hardware\n\nChange-Id: Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f\nDepends-On: https://review.opendev.org/#/c/753966/\n(cherry picked from commit be437cb1e341c437ddd8d6901ce107982bb808df)\n'}]",2,773009,2e2f741ea6dc90157ec92331df3d8fbbf9dc9297,21,5,1,13861,,,0,"Use the new IPA-builder element for installing python-hardware

Change-Id: Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f
Depends-On: https://review.opendev.org/#/c/753966/
(cherry picked from commit be437cb1e341c437ddd8d6901ce107982bb808df)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/09/773009/1 && git format-patch -1 --stdout FETCH_HEAD,['image-yaml/overcloud-images.yaml'],1,2e2f741ea6dc90157ec92331df3d8fbbf9dc9297,extra-hardware-stable/ussuri, - extra-hardware DIB_EPEL_DISABLED: 1, packages: - python-hardware-detect,2,2
openstack%2Fneutron~stable%2Fqueens~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/queens,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 12:12:18.000000000,2021-02-08 13:36:06.000000000,2021-02-08 13:36:06.000000000,"[{'_account_id': 11975}, {'_account_id': 13095}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 12:12:18.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e52d3f554240b74ef528f1d6bdf173f9563393a', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774134,2e52d3f554240b74ef528f1d6bdf173f9563393a,9,4,1,16688,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/774134/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,2e52d3f554240b74ef528f1d6bdf173f9563393a,bug-1912651-stable/stein-stable/queens, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Fneutron~stable%2Frocky~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/rocky,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 12:12:00.000000000,2021-02-08 13:35:11.000000000,2021-02-08 13:35:11.000000000,"[{'_account_id': 11975}, {'_account_id': 13095}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 12:12:00.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/36fc4708be6994893d31e8c6bbbb58ec8b7723bc', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774133,36fc4708be6994893d31e8c6bbbb58ec8b7723bc,9,4,1,16688,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/774133/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,36fc4708be6994893d31e8c6bbbb58ec8b7723bc,bug-1912651-stable/stein-stable/rocky, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Freleases~master~I1348f2cb56f7615a9be9a933f74bc487dffb909d,openstack/releases,master,I1348f2cb56f7615a9be9a933f74bc487dffb909d,Release tripleo for stable/train,MERGED,2021-01-29 15:46:35.000000000,2021-02-08 13:32:47.000000000,2021-02-08 13:32:47.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-29 15:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/dc5d7365aeb677656558d778b2eea968ce14192b', 'message': 'Release tripleo-validations for stable/train\n\nThis release picks up new commits to tripleo-validations since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\n'}, {'number': 2, 'created': '2021-02-02 17:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fb14bdc1a32c8dd268cb71d7566afddfb7fcbabd', 'message': 'Release tripleo for stable/train\n\nThis release picks up new commits to tripleo since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\n'}, {'number': 3, 'created': '2021-02-03 17:11:07.000000000', 'files': ['deliverables/train/os-net-config.yaml', 'deliverables/train/paunch.yaml', 'deliverables/train/tripleo-image-elements.yaml', 'deliverables/train/tripleo-ansible.yaml', 'deliverables/train/tripleo-heat-templates.yaml', 'deliverables/train/puppet-tripleo.yaml', 'deliverables/train/tripleo-puppet-elements.yaml', 'deliverables/train/tripleo-validations.yaml', 'deliverables/train/tripleo-common.yaml', 'deliverables/train/os-refresh-config.yaml', 'deliverables/train/os-apply-config.yaml', 'deliverables/train/python-tripleoclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1c3b70b4297b01e15e5bb05a90eb1d32bab21a9f', 'message': 'Release tripleo for stable/train\n\nThis release picks up new commits to tripleo since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d\n'}]",20,773110,1c3b70b4297b01e15e5bb05a90eb1d32bab21a9f,17,5,3,17685,,,0,"Release tripleo for stable/train

This release picks up new commits to tripleo since
the last release from stable/train.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a  stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

Signed-off-by: Elod Illes <elod.illes@est.tech>
Change-Id: I1348f2cb56f7615a9be9a933f74bc487dffb909d
",git fetch https://review.opendev.org/openstack/releases refs/changes/10/773110/3 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/tripleo-validations.yaml'],1,dc5d7365aeb677656558d778b2eea968ce14192b,train-stable, - version: 11.3.2 projects: - repo: openstack/tripleo-validations hash: 5179c2a9f961a4e0e68998588e52cb8660e47289,,4,0
openstack%2Freleases~master~I6e4846676ffde0a5cb86c7a8ed910aac9cc07211,openstack/releases,master,I6e4846676ffde0a5cb86c7a8ed910aac9cc07211,Release murano for stable/train,MERGED,2021-01-29 14:23:26.000000000,2021-02-08 13:31:51.000000000,2021-02-08 13:31:51.000000000,"[{'_account_id': 11904}, {'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-29 14:23:26.000000000', 'files': ['deliverables/train/murano.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/18f35d6f217e2115e61176384c41569a7c4ccff3', 'message': 'Release murano for stable/train\n\nThis release picks up new commits to murano since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I6e4846676ffde0a5cb86c7a8ed910aac9cc07211\n'}]",0,773065,18f35d6f217e2115e61176384c41569a7c4ccff3,9,4,1,17685,,,0,"Release murano for stable/train

This release picks up new commits to murano since
the last release from stable/train.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a  stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

Signed-off-by: Elod Illes <elod.illes@est.tech>
Change-Id: I6e4846676ffde0a5cb86c7a8ed910aac9cc07211
",git fetch https://review.opendev.org/openstack/releases refs/changes/65/773065/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/murano.yaml'],1,18f35d6f217e2115e61176384c41569a7c4ccff3,train-stable, - version: 8.1.1 projects: - repo: openstack/murano hash: 4f698865318df4e72b7521aaad34fc0d2ff22dac,,4,0
openstack%2Fmagnum~master~I5d1c4221f089bc5cd12b25f620aa01771a029df9,openstack/magnum,master,I5d1c4221f089bc5cd12b25f620aa01771a029df9,Add CT tags field to the database and API,MERGED,2020-06-24 16:10:45.000000000,2021-02-08 13:31:34.000000000,2021-02-08 11:01:54.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-06-24 16:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/024be16c5a6c40b01cd2609318c6a30eefcea9a9', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 2, 'created': '2020-06-25 13:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0db89ca57f7999a753daa21efd872a038a0ec4e3', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 3, 'created': '2020-08-14 09:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cfb3517d03994948b8356aa27a1dfec138c140a8', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 4, 'created': '2020-08-26 09:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6384429a7775552205f26c2bfc8fe11f73f7856d', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 5, 'created': '2020-08-26 11:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b7ab7b7a0eb5ddb5f8358b0e7fda1457e2d9dca4', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 6, 'created': '2020-10-22 14:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dd85cd227db681306fb834aa333200400c2ed634', 'message': ""Add CT observations field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 7, 'created': '2020-10-22 14:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f6da0e834ba87a7024805c44f5e1e624741f42a0', 'message': ""Add CT tags field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 8, 'created': '2021-01-28 17:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e80fe36dd32cd89f6ebc1a83448b4ae0d8e9d61f', 'message': ""Add CT tags field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <dy090.guerra@gmail.com>\n""}, {'number': 9, 'created': '2021-01-29 10:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5b0024fcce627dc0f34d24ef154fafeecbc22cd1', 'message': ""Add CT tags field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n""}, {'number': 10, 'created': '2021-02-05 22:46:09.000000000', 'files': ['api-ref/source/parameters.yaml', 'magnum/db/sqlalchemy/api.py', 'magnum/db/sqlalchemy/alembic/versions/f1d8b0ab8b8d_added_observations_to_cluster_template.py', 'magnum/tests/unit/db/utils.py', 'magnum/objects/cluster_template.py', 'magnum/api/controllers/v1/baymodel.py', 'magnum/db/sqlalchemy/models.py', 'magnum/tests/unit/api/controllers/v1/test_cluster_template.py', 'api-ref/source/clustertemplates.inc', 'magnum/api/controllers/v1/cluster_template.py', 'magnum/tests/unit/objects/test_objects.py', 'releasenotes/notes/add_cluster_template_observations_db_and_api_objects-d7350c8193da9470.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/332e2b6fe4069b5348d62273819f16492d1567e0', 'message': ""Add CT tags field to the database and API\n\nWe noticed that from the user perspective it is hard\nto know when a cluster_template provided by the cloud\nadmin is mature enough for a production release.\nThis field will allow the administrator to add an\nannotation to the cluster template like\n{deprecated, recommended, testing} giving further\nusefull information to the end user about the\ntemplate's life cycle\n\nThis patch adds the necessary database column and\nAPI objects to handle the new argument.\n\nstory: 2007857\ntask: 40160\n\nChange-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n""}]",16,737840,332e2b6fe4069b5348d62273819f16492d1567e0,40,4,10,29425,,,0,"Add CT tags field to the database and API

We noticed that from the user perspective it is hard
to know when a cluster_template provided by the cloud
admin is mature enough for a production release.
This field will allow the administrator to add an
annotation to the cluster template like
{deprecated, recommended, testing} giving further
usefull information to the end user about the
template's life cycle

This patch adds the necessary database column and
API objects to handle the new argument.

story: 2007857
task: 40160

Change-Id: I5d1c4221f089bc5cd12b25f620aa01771a029df9
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/40/737840/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'magnum/objects/cluster_template.py', 'magnum/api/controllers/v1/baymodel.py', 'magnum/db/sqlalchemy/models.py', 'magnum/tests/unit/api/controllers/v1/test_cluster_template.py', 'magnum/tests/unit/db/utils.py', 'api-ref/source/clustertemplates.inc', 'magnum/api/controllers/v1/cluster_template.py', 'magnum/tests/unit/objects/test_objects.py', 'magnum/db/sqlalchemy/alembic/versions/230a934f2b6a_added_observations_to_cluster_template_.py']",10,024be16c5a6c40b01cd2609318c6a30eefcea9a9,observations,"""""""Added observations to cluster_template table Revision ID: 230a934f2b6a Revises: c04e925e65c2 Create Date: 2020-06-24 15:09:40.985872 """""" # revision identifiers, used by Alembic. revision = '230a934f2b6a' down_revision = 'c04e925e65c2' from alembic import op import sqlalchemy as sa from sqlalchemy.dialects import mysql def upgrade(): op.add_column('cluster_template', sa.Column('observations', sa.String(length=255), nullable=True)) ",,45,3
openstack%2Fneutron~stable%2Fussuri~I05394e49077a72199bbc80c8cb622ec2b17f2fa7,openstack/neutron,stable/ussuri,I05394e49077a72199bbc80c8cb622ec2b17f2fa7,[OVN] Update metadata port ony for requested subnet,MERGED,2021-02-05 14:29:12.000000000,2021-02-08 13:30:56.000000000,2021-02-08 13:28:31.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 14:29:12.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55a82dacf150246beeade74a47dfbdcf8143063a', 'message': '[OVN] Update metadata port ony for requested subnet\n\nWhen a subnet is updated or created, the metadata port is updated too,\nto add the fixed IP address of the new subnet. In this case, the port\nshould update only the IP address of this specific subnet.\n\nChange-Id: I05394e49077a72199bbc80c8cb622ec2b17f2fa7\nCloses-Bug: #1890432\n(cherry picked from commit 93225e016b4957e9c5635985fe9685269fa2556e)\n'}]",0,774256,55a82dacf150246beeade74a47dfbdcf8143063a,9,3,1,11805,,,0,"[OVN] Update metadata port ony for requested subnet

When a subnet is updated or created, the metadata port is updated too,
to add the fixed IP address of the new subnet. In this case, the port
should update only the IP address of this specific subnet.

Change-Id: I05394e49077a72199bbc80c8cb622ec2b17f2fa7
Closes-Bug: #1890432
(cherry picked from commit 93225e016b4957e9c5635985fe9685269fa2556e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/774256/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py']",2,55a82dacf150246beeade74a47dfbdcf8143063a,bug/1890432-stable/victoria-stable/ussuri," umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') subnet={'enable_dhcp': False, 'id': 'subnet_id', 'ip_version': 4, umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') def test_update_metadata_port_with_subnet_present_in_port(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port( self.context, 'net_id', subnet_id='subnet1') mock_update_port.assert_not_called() def test_update_metadata_port_with_subnet_not_present_in_port(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port( self.context, 'net_id', subnet_id='subnet3') fixed_ips.append({'subnet_id': 'subnet3'}) port = {'id': 'metadata_id', 'port': { 'network_id': 'net_id', 'fixed_ips': fixed_ips}} mock_update_port.assert_called_once_with( mock.ANY, 'metadata_id', port) def test_update_metadata_port_no_subnet(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port(self.context, 'net_id') fixed_ips.append({'subnet_id': 'subnet2'}) port = {'id': 'metadata_id', 'port': { 'network_id': 'net_id', 'fixed_ips': fixed_ips}} mock_update_port.assert_called_once_with( mock.ANY, 'metadata_id', port)"," umd.assert_called_once_with(mock.ANY, 'id') subnet={'enable_dhcp': False, 'id': 'fake_id', 'ip_version': 4, umd.assert_called_once_with(mock.ANY, 'id') umd.assert_called_once_with(mock.ANY, 'id')",91,24
openstack%2Fneutron~stable%2Fvictoria~I05394e49077a72199bbc80c8cb622ec2b17f2fa7,openstack/neutron,stable/victoria,I05394e49077a72199bbc80c8cb622ec2b17f2fa7,[OVN] Update metadata port ony for requested subnet,MERGED,2021-02-05 14:28:43.000000000,2021-02-08 13:30:48.000000000,2021-02-08 13:28:12.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 14:28:43.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c43b4e7a019cccd1c98168ef6042010842753b3', 'message': '[OVN] Update metadata port ony for requested subnet\n\nWhen a subnet is updated or created, the metadata port is updated too,\nto add the fixed IP address of the new subnet. In this case, the port\nshould update only the IP address of this specific subnet.\n\nChange-Id: I05394e49077a72199bbc80c8cb622ec2b17f2fa7\nCloses-Bug: #1890432\n(cherry picked from commit 93225e016b4957e9c5635985fe9685269fa2556e)\n'}]",0,774135,9c43b4e7a019cccd1c98168ef6042010842753b3,9,3,1,11805,,,0,"[OVN] Update metadata port ony for requested subnet

When a subnet is updated or created, the metadata port is updated too,
to add the fixed IP address of the new subnet. In this case, the port
should update only the IP address of this specific subnet.

Change-Id: I05394e49077a72199bbc80c8cb622ec2b17f2fa7
Closes-Bug: #1890432
(cherry picked from commit 93225e016b4957e9c5635985fe9685269fa2556e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/774135/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py']",2,9c43b4e7a019cccd1c98168ef6042010842753b3,bug/1890432-stable/victoria," umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') subnet={'enable_dhcp': False, 'id': 'subnet_id', 'ip_version': 4, umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') umd.assert_called_once_with(mock.ANY, 'id', subnet_id='subnet_id') def test_update_metadata_port_with_subnet_present_in_port(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port( self.context, 'net_id', subnet_id='subnet1') mock_update_port.assert_not_called() def test_update_metadata_port_with_subnet_not_present_in_port(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port( self.context, 'net_id', subnet_id='subnet3') fixed_ips.append({'subnet_id': 'subnet3'}) port = {'id': 'metadata_id', 'port': { 'network_id': 'net_id', 'fixed_ips': fixed_ips}} mock_update_port.assert_called_once_with( mock.ANY, 'metadata_id', port) def test_update_metadata_port_no_subnet(self): ovn_conf.cfg.CONF.set_override('ovn_metadata_enabled', True, group='ovn') fixed_ips = [{'subnet_id': 'subnet1', 'ip_address': 'ip_add1'}] with mock.patch.object( self.mech_driver._ovn_client, '_find_metadata_port', return_value={'fixed_ips': fixed_ips, 'id': 'metadata_id'}), \ mock.patch.object(self.mech_driver._plugin, 'get_subnets', return_value=[{'id': 'subnet1'}, {'id': 'subnet2'}]), \ mock.patch.object(self.mech_driver._plugin, 'update_port') as \ mock_update_port: self.mech_driver._ovn_client.update_metadata_port(self.context, 'net_id') fixed_ips.append({'subnet_id': 'subnet2'}) port = {'id': 'metadata_id', 'port': { 'network_id': 'net_id', 'fixed_ips': fixed_ips}} mock_update_port.assert_called_once_with( mock.ANY, 'metadata_id', port)"," umd.assert_called_once_with(mock.ANY, 'id') subnet={'enable_dhcp': False, 'id': 'fake_id', 'ip_version': 4, umd.assert_called_once_with(mock.ANY, 'id') umd.assert_called_once_with(mock.ANY, 'id')",91,24
openstack%2Freleases~master~I68dbea306109ed25124480348a00fe3830066868,openstack/releases,master,I68dbea306109ed25124480348a00fe3830066868,Release oslo.metrics 0.2.0,MERGED,2021-02-06 08:28:52.000000000,2021-02-08 13:29:50.000000000,2021-02-08 13:29:50.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2021-02-06 08:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3b3b3d840ed779d3cd79953686911028676e978c', 'message': 'Release oslo.metrics 0.1.1\n\nThis commit includes changes for metrics naming that is not compatible\nwith older release. It is required to continue integration with\noslo.messaging.\n\nChange-Id: I68dbea306109ed25124480348a00fe3830066868\n'}, {'number': 2, 'created': '2021-02-06 08:46:06.000000000', 'files': ['deliverables/wallaby/oslo.metrics.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/26523517c54fcb1ac7e2500c048a00ff46bc8061', 'message': 'Release oslo.metrics 0.2.0\n\nThis commit includes changes for metrics naming that is not compatible\nwith older release. It is required to continue integration with\noslo.messaging.\n\nChange-Id: I68dbea306109ed25124480348a00fe3830066868\n'}]",0,774349,26523517c54fcb1ac7e2500c048a00ff46bc8061,11,4,2,32523,,,0,"Release oslo.metrics 0.2.0

This commit includes changes for metrics naming that is not compatible
with older release. It is required to continue integration with
oslo.messaging.

Change-Id: I68dbea306109ed25124480348a00fe3830066868
",git fetch https://review.opendev.org/openstack/releases refs/changes/49/774349/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/oslo.metrics.yaml'],1,3b3b3d840ed779d3cd79953686911028676e978c,oslo-metrics-release, - version: 0.1.1 hash: 0d42ba7ec2f930655cc3f8666a4ada8397c61d24, - version: 0.1.0 hash: 4631e58c56a37c3ab007c1b6de3680dcda83f1b9,2,2
openstack%2Freleases~master~I19cf2b717ad97c7219d5c12ac09550279ee9b4bf,openstack/releases,master,I19cf2b717ad97c7219d5c12ac09550279ee9b4bf,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 18:29:49.000000000,2021-02-08 13:29:45.000000000,2021-02-08 13:29:45.000000000,"[{'_account_id': 7973}, {'_account_id': 11561}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-26 18:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/5c8895db68e73502d61222d7de45078d75d78e66', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf\n'}, {'number': 2, 'created': '2020-12-26 20:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/9c622d83249e1f3295e850a132bbefd866f7d34f', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf\n'}, {'number': 3, 'created': '2020-12-28 21:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/a9545e1c0faf53a721348c01a45df56cdb10db3f', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf\n""}, {'number': 4, 'created': '2021-01-12 22:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/50cb40daa3cf6d89fbfb796a9dcc291cf3ba95ce', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf\n""}, {'number': 5, 'created': '2021-01-12 22:24:50.000000000', 'files': ['deliverables/wallaby/barbican-tempest-plugin.yaml', 'deliverables/stein/barbican-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/bda0d2401ded9df40ba67b39268d21e77c74f0ce', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf\n""}]",0,768537,bda0d2401ded9df40ba67b39268d21e77c74f0ce,19,5,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: I19cf2b717ad97c7219d5c12ac09550279ee9b4bf
",git fetch https://review.opendev.org/openstack/releases refs/changes/37/768537/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/barbican-tempest-plugin.yaml'],1,5c8895db68e73502d61222d7de45078d75d78e66,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/barbican-tempest-plugin hash: 53dcab70f26f8e990fce425ee1005ef3f775d174,,4,0
openstack%2Fnova~master~I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f,openstack/nova,master,I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f,Faults from cell DB missing in GET /servers/detail,NEW,2019-12-16 10:34:51.000000000,2021-02-08 13:21:46.000000000,,"[{'_account_id': 4690}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26250}, {'_account_id': 26515}, {'_account_id': 29125}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-16 10:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11cf5d93897769c666513c839c8f79e0725e0920', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 2, 'created': '2019-12-16 10:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1027124da7f2d7c1c223193e6d8077b2a9d0b717', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 3, 'created': '2020-01-28 13:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06e13fefe480b15be7571b180adf494131d31867', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 4, 'created': '2020-01-28 13:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dbcd1ab623ab82221520ac98ccf94c4543b6c96', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 5, 'created': '2020-01-28 13:41:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa196913eeb98d539c8b6f7c7cd328b157e08609', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 6, 'created': '2020-02-18 15:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1779fd68ed1e93c471d02efcba5ea67d10989cb8', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 7, 'created': '2020-02-18 15:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3063f6c7f1e2a874cff1c89a6cb0e532b9c84ba7', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 8, 'created': '2020-02-20 15:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e98d6710aa133edb484a5d1b2c0719ff7a1ba8e', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 9, 'created': '2020-02-20 18:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1db0c0f36111299af400713b70c7594c944efb25', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 10, 'created': '2020-02-21 14:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8db65319a5dcbe60f501024fd60294b6145433fe', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 11, 'created': '2020-04-15 21:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a5bd6332a4db45c41c73ccb8c035ea506ea8f04', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 12, 'created': '2020-04-16 08:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ffa37724401c0eb196aebfeea0b62fabe5efc41', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 13, 'created': '2020-04-16 09:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f454223dbf2a0d63267f681d494e2d0cb5421b5', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 14, 'created': '2020-05-14 12:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f61a0489a9862e6eb54af6be4e678bb336a0133e', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 15, 'created': '2020-05-19 15:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95aef3bf160d9bd3b5d536fb7ae7cf47302bd3bb', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}, {'number': 16, 'created': '2021-02-08 10:15:22.000000000', 'files': ['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d785c6fe13ae1b1035d006a36a523832c8f07205', 'message': 'Faults from cell DB missing in GET /servers/detail\n\nField  is empty in the response of API GET /servers/detail if the\ninstance (hence instace_faults DB entry) is in nova cell DB.\nUnlike that, for API /servers/:id fault is retrieved correctly no matter\nin which nova cell the instance belongs.\n\nCloses-Bug: #1856329\nChange-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f\n'}]",4,699176,d785c6fe13ae1b1035d006a36a523832c8f07205,120,15,16,29125,,,0,"Faults from cell DB missing in GET /servers/detail

Field  is empty in the response of API GET /servers/detail if the
instance (hence instace_faults DB entry) is in nova cell DB.
Unlike that, for API /servers/:id fault is retrieved correctly no matter
in which nova cell the instance belongs.

Closes-Bug: #1856329
Change-Id: I1726f53cfeac0a67a5dacdddda2af2cc1db0af0f
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/699176/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py']",2,11cf5d93897769c666513c839c8f79e0725e0920,bug/1856329,"from contextlib import contextmanager @mock.patch('nova.objects.InstanceMappingList.get_by_instance_uuids') def test_fill_faults(self, mock_fault_get, mock_get_inst_map_list): mock_get_inst_map_list.return_value = [ mock.Mock(cell_mapping=None, instance_uuid=uuids.db_fault_1), mock.Mock(cell_mapping=None, instance_uuid=uuids.db_fault_2) ] mock_fault_get.assert_called_once_with(mock.ANY, @mock.patch('nova.context.target_cell') @mock.patch('nova.objects.InstanceMappingList.get_by_instance_uuids') @mock.patch.object(db, 'instance_fault_get_by_instance_uuids') def test_fill_faults_multicell(self, mock_fault_get, mock_get_inst_map_list, mock_ctxt_target_cell): # Prepare list with 2 instances inst_list = objects.InstanceList() inst_list._context = self.context inst_list.objects = [ objects.Instance(uuid=uuids.inst_1), objects.Instance(uuid=uuids.inst_2) ] for inst in inst_list.objects: inst.obj_reset_changes() # Define different cell mappings for the 2 instances im1 = mock.Mock(instance_uuid=uuids.inst_1, cell_mapping=mock.Mock( database_connection=self.context.db_connection)) im2 = mock.Mock(instance_uuid=uuids.inst_2) mock_get_inst_map_list.return_value = [im1, im2] # Define faults for the instances in different cell DBs (mocked) def _fake_db_faults(instance_uuid): return { instance_uuid: [{ 'id': 123, 'instance_uuid': instance_uuid, 'code': 456, 'message': 'Fake message %s' % instance_uuid, 'details': 'No details', 'host': 'foo', 'deleted': False, 'deleted_at': None, 'updated_at': None, 'created_at': None }] } db_1_faults = _fake_db_faults(uuids.inst_1) db_2_faults = _fake_db_faults(uuids.inst_2) cell_faults = [ (im1.cell_mapping, db_1_faults), (im2.cell_mapping, db_2_faults) ] def _mock_cell_fault_get(context, instance_uuids, latest=False): for cf in cell_faults: if context.db_connection == cf[0].database_connection: return cf[1] return None mock_fault_get.side_effect = _mock_cell_fault_get @contextmanager def _mock_ctxt_target_cell(context, cell_mapping): yield mock.Mock( db_connection= (cell_mapping.database_connection if cell_mapping and hasattr(cell_mapping, 'database_connection') else None)) mock_ctxt_target_cell.side_effect = _mock_ctxt_target_cell inst_list.fill_faults() # Verify multicell fill_faults by comparing combined list of faults # from different cell DBs to the list of instance faults as filled self.assertEqual([db_1_faults[uuids.inst_1][0]['message'], db_2_faults[uuids.inst_2][0]['message']], [getattr(inst.fault, 'message', None) for inst in inst_list]) "," def test_fill_faults(self, mock_fault_get): mock_fault_get.assert_called_once_with(self.context,",108,5
openstack%2Freleases~master~If117a9da3094e012a308a4a559fcb56a4b815bec,openstack/releases,master,If117a9da3094e012a308a4a559fcb56a4b815bec,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 18:51:06.000000000,2021-02-08 13:17:11.000000000,2021-02-08 13:17:11.000000000,"[{'_account_id': 11904}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-26 18:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7743b83df1a38c54903ed85edcc70d58f279fc42', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If117a9da3094e012a308a4a559fcb56a4b815bec\n'}, {'number': 2, 'created': '2020-12-26 20:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1bfb7377aa68343013803fd010d864c2de5f4e56', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If117a9da3094e012a308a4a559fcb56a4b815bec\n'}, {'number': 3, 'created': '2020-12-28 21:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/feec2c9fecc5ebcd54ba1d4098b4f071031cd943', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If117a9da3094e012a308a4a559fcb56a4b815bec\n""}, {'number': 4, 'created': '2021-01-12 22:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/dfe1140e8785b736c4990868f7e8bbffefdef76b', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If117a9da3094e012a308a4a559fcb56a4b815bec\n""}, {'number': 5, 'created': '2021-01-12 22:18:40.000000000', 'files': ['deliverables/stein/keystone-tempest-plugin.yaml', 'deliverables/wallaby/keystone-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/14fa075f5970daa4e6756932be266e411380d161', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If117a9da3094e012a308a4a559fcb56a4b815bec\n""}]",0,768546,14fa075f5970daa4e6756932be266e411380d161,19,4,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: If117a9da3094e012a308a4a559fcb56a4b815bec
",git fetch https://review.opendev.org/openstack/releases refs/changes/46/768546/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/keystone-tempest-plugin.yaml'],1,7743b83df1a38c54903ed85edcc70d58f279fc42,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/keystone-tempest-plugin hash: 774bb4f905f1626bb30802f5c21205761ccc88d2 tarball-base: keystone_tempest_plugin,,5,0
openstack%2Freleases~master~Idbef25ef2c1d4852f7a040046c3c8b77fe863154,openstack/releases,master,Idbef25ef2c1d4852f7a040046c3c8b77fe863154,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 18:49:48.000000000,2021-02-08 13:16:53.000000000,2021-02-08 13:16:53.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-26 18:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/042b569318b221ebf717a8de2ae5ccce191a4d38', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154\n'}, {'number': 2, 'created': '2020-12-26 20:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d87d3fe88d75bb0c76a7b1568a5d23260fa85318', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154\n'}, {'number': 3, 'created': '2020-12-28 21:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b0d7537a09c6aafe49dfe846572ce35ec8e26254', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154\n""}, {'number': 4, 'created': '2021-01-12 22:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/255632bdca0b240afca8fcca6198063dded0fda2', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154\n""}, {'number': 5, 'created': '2021-01-12 22:16:20.000000000', 'files': ['deliverables/wallaby/ironic-tempest-plugin.yaml', 'deliverables/stein/ironic-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/eceeb5cfbae67b20637be46e28efd3784cabcdd3', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154\n""}]",1,768545,eceeb5cfbae67b20637be46e28efd3784cabcdd3,22,6,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: Idbef25ef2c1d4852f7a040046c3c8b77fe863154
",git fetch https://review.opendev.org/openstack/releases refs/changes/45/768545/4 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/ironic-tempest-plugin.yaml'],1,042b569318b221ebf717a8de2ae5ccce191a4d38,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/ironic-tempest-plugin hash: 5aa5765508fa0b282d60c1ecafddc35f73a046c1,,4,0
openstack%2Freleases~master~I3dedf43f254a745684014bc050ff6ac399144b06,openstack/releases,master,I3dedf43f254a745684014bc050ff6ac399144b06,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 18:48:38.000000000,2021-02-08 13:16:31.000000000,2021-02-08 13:16:31.000000000,"[{'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-12-26 18:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4b424620b9d41a5132aef74ac752496195370a08', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I3dedf43f254a745684014bc050ff6ac399144b06\n'}, {'number': 2, 'created': '2020-12-26 20:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1bbdb4488b3d96cbbd2b96bed22597fa968b8182', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I3dedf43f254a745684014bc050ff6ac399144b06\n'}, {'number': 3, 'created': '2020-12-28 21:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/554904a6317303dc31a5e8726aa311cec7918163', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I3dedf43f254a745684014bc050ff6ac399144b06\n""}, {'number': 4, 'created': '2021-01-12 22:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/9d687ff4cd151671649ad216be64dffb2a3b1bc1', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I3dedf43f254a745684014bc050ff6ac399144b06\n""}, {'number': 5, 'created': '2021-01-12 22:18:48.000000000', 'files': ['deliverables/wallaby/heat-tempest-plugin.yaml', 'deliverables/stein/heat-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6c35d87c0fef8fd141441d9ef421e0eb3bc4e539', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I3dedf43f254a745684014bc050ff6ac399144b06\n""}]",0,768544,6c35d87c0fef8fd141441d9ef421e0eb3bc4e539,20,5,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: I3dedf43f254a745684014bc050ff6ac399144b06
",git fetch https://review.opendev.org/openstack/releases refs/changes/44/768544/5 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/heat-tempest-plugin.yaml'],1,4b424620b9d41a5132aef74ac752496195370a08,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/heat-tempest-plugin hash: c5e1603fb62a8e2e18706c6c084d0fa2a908dad8,,4,0
openstack%2Freleases~master~I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e,openstack/releases,master,I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e,Move os-apply|collect|refresh-config projects to independent,MERGED,2021-01-26 16:39:03.000000000,2021-02-08 13:16:25.000000000,2021-02-08 13:16:25.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 7385}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 9592}, {'_account_id': 11904}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-26 16:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/2d96ef58619755e00a49f377eb825cfe0b84455c', 'message': 'Move os-apply|collect|refresh-config projects to independent\n\nAs discussed at [1] this proposes that the os-apply-config\nos-refresh-config and os-collect-config repos are moved\nto the independent model.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019778.html\n\nChange-Id: I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e\n'}, {'number': 2, 'created': '2021-01-27 15:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/f92837169a3fc8be0694a8415e1091ce6f537925', 'message': 'Move os-apply|collect|refresh-config projects to independent\n\nAs discussed at [1] this proposes that the os-apply-config\nos-refresh-config and os-collect-config repos are moved\nto the independent model. Removes the wallaby release files\nfor these repos.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019778.html\n\nChange-Id: I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e\n'}, {'number': 3, 'created': '2021-01-28 14:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b14f66a2b94fa882083064dc61d7ed8e854f4868', 'message': 'Move os-apply|collect|refresh-config projects to independent\n\nAs discussed at [1] this proposes that the os-apply-config\nos-refresh-config and os-collect-config repos are moved\nto the independent model. Removes the wallaby release files\nfor these repos.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019778.html\n\nChange-Id: I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e\n'}, {'number': 4, 'created': '2021-01-28 17:40:42.000000000', 'files': ['deliverables/_independent/os-collect-config.yaml', 'deliverables/_independent/os-refresh-config.yaml', 'deliverables/wallaby/os-collect-config.yaml', 'deliverables/_independent/os-apply-config.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/78d0577401838b7066341572346f7e7e99640d40', 'message': 'Move os-apply|collect|refresh-config projects to independent\n\nAs discussed at [1] this proposes that the os-apply-config\nos-refresh-config and os-collect-config repos are moved\nto the independent model. Removes the wallaby release files\nfor these repos.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019778.html\n\nChange-Id: I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e\n'}]",3,772570,78d0577401838b7066341572346f7e7e99640d40,31,10,4,8449,,,0,"Move os-apply|collect|refresh-config projects to independent

As discussed at [1] this proposes that the os-apply-config
os-refresh-config and os-collect-config repos are moved
to the independent model. Removes the wallaby release files
for these repos.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019778.html

Change-Id: I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e
",git fetch https://review.opendev.org/openstack/releases refs/changes/70/772570/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/_independent/os-collect-config.yaml', 'deliverables/_independent/os-refresh-config.yaml', 'deliverables/_independent/os-apply-config.yaml']",3,2d96ef58619755e00a49f377eb825cfe0b84455c,I6c4ab66ac71f9e6050b0944f15b9fef7fccfe89e,--- launchpad: os-apply-config release-model: cycle-with-intermediary release-type: python-pypi team: tripleo type: other repository-settings: openstack/os-apply-config: {} branches: - location: 11.2.0 name: stable/ussuri - location: 7.1.0 name: stable/pike - location: 6.0.0.0rc1 name: stable/ocata - name: stable/victoria location: 12.0.0 - location: 8.3.0 name: stable/queens - location: 5.0.0 name: stable/newton - location: 9.1.0 name: stable/rocky - name: stable/train location: 10.5.0 - location: 10.3.0 name: stable/stein releases: - version: 11.0.0 projects: - repo: openstack/os-apply-config hash: 7ced221ab1561e8a184151fba8ae3c7a7627f5e3 - version: 11.1.0 projects: - repo: openstack/os-apply-config hash: 733daffc31fb59e188506f5bd9940fe2e5b3d2f2 - version: 11.2.0 projects: - repo: openstack/os-apply-config hash: 852795d2459cd90cbb9007985fe0a40671dc6000 - version: 11.2.1 projects: - repo: openstack/os-apply-config hash: bc8f0616b3cd63641efdc5eff792552152cc527a - projects: - hash: dcc453a946a98532e5f0b68ebcc52f96a56fb7cb repo: openstack/os-apply-config version: 7.0.0.0b1 - projects: - hash: 89b0ba7bc424e1e10fdf1d269f819a4e612f9358 repo: openstack/os-apply-config version: 7.0.0 - projects: - hash: c2e15c8424de6ee260bc7266f813030d62246945 repo: openstack/os-apply-config version: 7.1.0 - projects: - hash: 1587707645de0fa45e29c0c16f8520175e82b940 repo: openstack/os-apply-config version: 7.2.0 - projects: - hash: 294cd491b585dcdeb199d3d8c3fc0160707ccefe repo: openstack/os-apply-config version: 7.2.1 - projects: - hash: b70958677a775fb4e0c9fa1c22bdfe29e70aabd3 repo: openstack/os-apply-config version: 7.2.2 - projects: - hash: 71f52919f16f4839c0800273e3af6b688f3d0015 repo: openstack/os-apply-config version: 7.2.3 - projects: - hash: e28e90884bf1326299076317334d1a8428fbc747 repo: openstack/os-apply-config version: 7.2.4 - projects: - hash: e28e90884bf1326299076317334d1a8428fbc747 repo: openstack/os-apply-config version: pike-em - projects: - hash: 46d438a8ee70a46ea8ba619a0786d2e37857c301 repo: openstack/os-apply-config version: pike-eol - projects: - hash: 1bd0206930e9af8e91f7eae6878530c6a7968910 repo: openstack/os-apply-config version: 6.0.0.0rc1 - diff-start: 5.0.0 projects: - hash: 1bd0206930e9af8e91f7eae6878530c6a7968910 repo: openstack/os-apply-config version: 6.0.0 - projects: - hash: ed286dcdd0eef0ea6703a73f893c03272b5ab9a5 repo: openstack/os-apply-config version: 6.1.0 - projects: - hash: 92f6066d62eef4282f6b1484c7d47e68f21be243 repo: openstack/os-apply-config version: 6.1.1 - projects: - hash: 9fa6f2dd4fe9a6f0414741d2e5c60ca7518f73e9 repo: openstack/os-apply-config version: 6.1.2 - projects: - hash: 7671343e5b7912bb152ef26e9076589f79a4a341 repo: openstack/os-apply-config version: 6.1.3 - projects: - hash: 7671343e5b7912bb152ef26e9076589f79a4a341 repo: openstack/os-apply-config version: ocata-em - projects: - hash: 919a9c82864aa97faf7c7762f4d2cc93336d38ae repo: openstack/os-apply-config version: ocata-eol - version: 11.3.0 projects: - repo: openstack/os-apply-config hash: 71a69b899efcba4b6b60927ec15fc47ebae421fd - version: 12.0.0 projects: - repo: openstack/os-apply-config hash: 2bf86c4c82404d3e987be23cf85f270a3c46c6e0 - projects: - hash: 8db1c024eee51cc994e19ec44b6d3a141d070ec5 repo: openstack/os-apply-config version: 8.0.0 - projects: - hash: 8dbeb75d798869fe186d1d916314b2362b402c4e repo: openstack/os-apply-config version: 8.1.0 - projects: - hash: 775d6dc6ddc16c31566b18b5054203c79b00e8d1 repo: openstack/os-apply-config version: 8.2.0 - projects: - hash: 81baf73ae89a7dd5a15869986ea3b8adf5187680 repo: openstack/os-apply-config version: 8.3.0 - projects: - hash: be699ba6e0dc29c767ed6d8dc3643950b07da292 repo: openstack/os-apply-config version: 8.3.1 - projects: - hash: ad29f1d44923d12c8c91e6389fda6535653dac2c repo: openstack/os-apply-config version: 8.3.2 - version: queens-em projects: - repo: openstack/os-apply-config hash: ad29f1d44923d12c8c91e6389fda6535653dac2c - projects: - hash: 36f24df3e79e7c0f3621e8231853342b4f89d0e8 repo: openstack/os-apply-config version: 5.0.0.0b1 - projects: - hash: 69879dad8b66933f79c7e06d159ef2e91160aa1e repo: openstack/os-apply-config version: 5.0.0.0b2 - diff-start: 0.1.32 projects: - hash: 69879dad8b66933f79c7e06d159ef2e91160aa1e repo: openstack/os-apply-config version: 5.0.0 - projects: - hash: 13e5cdc7357f0f175a6ea8157032d9e224c5eec1 repo: openstack/os-apply-config version: 5.1.0 - projects: - hash: 5e41fbf013e13777af4be18da3201c24a7b523f5 repo: openstack/os-apply-config version: 5.1.1 - projects: - hash: 59c226b754c5112ab2b803bcac44aa5c69750299 repo: openstack/os-apply-config version: newton-eol - projects: - hash: 9124f56fac1354d63b1dc7759340e34a494c6569 repo: openstack/os-apply-config version: 9.0.0 - projects: - hash: 0522d3ac3da40e3285d91237ea45ffd5f0495916 repo: openstack/os-apply-config version: 9.1.0 - projects: - hash: 4e5dc439e4eabbf0b1f2cc4871e86c914e2645f1 repo: openstack/os-apply-config version: 9.1.1 - projects: - hash: 07165a907a01408485526950739183a6154f6515 repo: openstack/os-apply-config version: 9.1.2 - version: rocky-em projects: - repo: openstack/os-apply-config hash: 07165a907a01408485526950739183a6154f6515 - projects: - hash: 7234780bae671b5fead73c00ff4d76221768ccd6 repo: openstack/os-apply-config version: 10.4.0 - version: 10.4.1 projects: - repo: openstack/os-apply-config hash: d9df1dbd367d42430aa9abfe90d5aec572ec152b - version: 10.5.0 projects: - repo: openstack/os-apply-config hash: 45d999508849137c13eeab63bbec269df232758b - version: 10.5.1 projects: - repo: openstack/os-apply-config hash: 3c6e3cd638f31bce14344e19ac3ff22d74c0c4af - projects: - hash: 21be52c835180cbe138acbfde4e6ec344ded634e repo: openstack/os-apply-config version: 10.0.0 - projects: - hash: 6543fc7498fe3a8dd961a3d755237a3289ae1fc1 repo: openstack/os-apply-config version: 10.1.0 - projects: - hash: b7a2d9e46cac43311a3410902cb74292b0395a05 repo: openstack/os-apply-config version: 10.2.0 - projects: - hash: 9a50e081cb9bc27ec573bda5ad00beff64b23dec repo: openstack/os-apply-config version: 10.3.0 - version: stein-em projects: - repo: openstack/os-apply-config hash: 9a50e081cb9bc27ec573bda5ad00beff64b23dec ,,639,2
openstack%2Freleases~master~I9ba16662f98523a03f5de5712331273916f3ea5a,openstack/releases,master,I9ba16662f98523a03f5de5712331273916f3ea5a,Drop tempest-horizon from wallaby deliverables,MERGED,2021-01-21 08:20:36.000000000,2021-02-08 13:14:51.000000000,2021-02-08 13:14:51.000000000,"[{'_account_id': 1736}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-01-21 08:20:36.000000000', 'files': ['deliverables/wallaby/tempest-horizon.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/82cdebb149705cf4c1d42e495619f7db37ef2122', 'message': 'Drop tempest-horizon from wallaby deliverables\n\ntempest tests in tempest-horizon are merged into the main tempest\nrepo in Wallaby [1][2] as discussed in the wallaby PTG [0].\nQA and horizon teams will complete the effort soon around Wallaby-2.\n\n[0] https://etherpad.opendev.org/p/qa-wallaby-ptg\n[1] https://review.opendev.org/c/openstack/tempest/+/771727\n[2] https://review.opendev.org/q/topic:%22merge-horizon-test%22+(status:open%20OR%20status:merged)\n\nChange-Id: I9ba16662f98523a03f5de5712331273916f3ea5a\n'}]",0,771760,82cdebb149705cf4c1d42e495619f7db37ef2122,10,6,1,841,,,0,"Drop tempest-horizon from wallaby deliverables

tempest tests in tempest-horizon are merged into the main tempest
repo in Wallaby [1][2] as discussed in the wallaby PTG [0].
QA and horizon teams will complete the effort soon around Wallaby-2.

[0] https://etherpad.opendev.org/p/qa-wallaby-ptg
[1] https://review.opendev.org/c/openstack/tempest/+/771727
[2] https://review.opendev.org/q/topic:%22merge-horizon-test%22+(status:open%20OR%20status:merged)

Change-Id: I9ba16662f98523a03f5de5712331273916f3ea5a
",git fetch https://review.opendev.org/openstack/releases refs/changes/60/771760/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/tempest-horizon.yaml'],1,82cdebb149705cf4c1d42e495619f7db37ef2122,merge-horizon-test,,--- include-pypi-link: false launchpad: horizon release-model: cycle-with-intermediary stable-branch-type: none release-type: python-pypi repository-settings: openstack/tempest-horizon: {} team: horizon type: tempest-plugin ,0,10
openstack%2Freleases~master~I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c,openstack/releases,master,I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c,New bugfix and feature releases for oslo.,MERGED,2021-02-08 08:56:31.000000000,2021-02-08 13:11:47.000000000,2021-02-08 13:11:47.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-08 08:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/efa0052be0c48f45bb73b98fe55d369c4d663925', 'message': 'New bugfix release for oslo.serialization.\n\nA new bugfix release for oslo.serialization for ussuri.\n\nChange-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\n'}, {'number': 2, 'created': '2021-02-08 09:27:17.000000000', 'files': ['deliverables/wallaby/oslo.cache.yaml', 'deliverables/wallaby/oslo.service.yaml', 'deliverables/wallaby/oslo.serialization.yaml', 'deliverables/victoria/oslo.serialization.yaml', 'deliverables/ussuri/oslo.serialization.yaml', 'deliverables/wallaby/oslo.vmware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ef3019a11e53c058d6601d569120794aafee1820', 'message': 'New bugfix and feature releases for oslo.\n\nA new releases for oslo for ussuri, victoria and wallaby.\n\nChange-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c\n'}]",0,774422,ef3019a11e53c058d6601d569120794aafee1820,11,3,2,31245,,,0,"New bugfix and feature releases for oslo.

A new releases for oslo for ussuri, victoria and wallaby.

Change-Id: I712e9ad4b4b998b80ca71fe53fea1a6cbf328e3c
",git fetch https://review.opendev.org/openstack/releases refs/changes/22/774422/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ussuri/oslo.serialization.yaml'],1,efa0052be0c48f45bb73b98fe55d369c4d663925,oslo.serialization_wallaby_fix, - version: 3.1.2 projects: - repo: openstack/oslo.serialization hash: ab5c68d301dcd409a1112da6f2f89b0f2fc13183,,4,0
openstack%2Fkuryr-kubernetes~master~I61a05cf2689a5902004358d3b50b1deb2120b8cc,openstack/kuryr-kubernetes,master,I61a05cf2689a5902004358d3b50b1deb2120b8cc,Remove selfLink propagation on K8s feature gates.,ABANDONED,2021-01-12 15:03:09.000000000,2021-02-08 12:53:33.000000000,,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2021-01-12 15:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8fa0dfb915b915c5ab556bc01695212a4b3b561c', 'message': 'Remove selfLink propagation on K8s feature gates.\n\nWIP, either bug on nullable items on k8s 1.18 will be fixed, or we\nmigrate at least to 1.19.\n\nChange-Id: I61a05cf2689a5902004358d3b50b1deb2120b8cc\n'}, {'number': 2, 'created': '2021-01-12 15:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/504c0eb07bdab1515998dc1dd6dd25bc9ca1ee73', 'message': 'Remove selfLink propagation on K8s feature gates.\n\nWIP, either bug on nullable items on k8s 1.18 will be fixed, or we\nmigrate at least to 1.19.\n\nChange-Id: I61a05cf2689a5902004358d3b50b1deb2120b8cc\nDepends-On: Ib0bcc9f5cb6c4cdc27c3393dcb3f665b21cb64ac\n'}, {'number': 3, 'created': '2021-01-14 05:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1a0b89bd2258ba5f630a8065fc5326d67bc560bc', 'message': 'Remove selfLink propagation on K8s feature gates.\n\nWIP, either bug on nullable items on k8s 1.18 will be fixed, or we\nmigrate at least to 1.19.\n\nChange-Id: I61a05cf2689a5902004358d3b50b1deb2120b8cc\nDepends-On: Ib0bcc9f5cb6c4cdc27c3393dcb3f665b21cb64ac\n'}, {'number': 4, 'created': '2021-01-14 05:47:59.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/21b273a82235449af94d435665d9dba9c22939e6', 'message': 'Remove selfLink propagation on K8s feature gates.\n\nWIP, either bug on nullable items on k8s 1.18 will be fixed, or we\nmigrate at least to 1.19.\nEDIT: Turns out, 1.19 share the same behaviour as 1.18. Bug has been\nreported to the Kubernetes project.\n\nChange-Id: I61a05cf2689a5902004358d3b50b1deb2120b8cc\nDepends-On: Ib0bcc9f5cb6c4cdc27c3393dcb3f665b21cb64ac\n'}]",0,770352,21b273a82235449af94d435665d9dba9c22939e6,10,6,4,13692,,,0,"Remove selfLink propagation on K8s feature gates.

WIP, either bug on nullable items on k8s 1.18 will be fixed, or we
migrate at least to 1.19.
EDIT: Turns out, 1.19 share the same behaviour as 1.18. Bug has been
reported to the Kubernetes project.

Change-Id: I61a05cf2689a5902004358d3b50b1deb2120b8cc
Depends-On: Ib0bcc9f5cb6c4cdc27c3393dcb3f665b21cb64ac
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/52/770352/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,8fa0dfb915b915c5ab556bc01695212a4b3b561c,remove-selflink," --feature-gates=""SCTPSupport=true,RemoveSelfLink=true"" \ --feature-gates=""SCTPSupport=true,RemoveSelfLink=true"" \ --feature-gates=""SCTPSupport=true,RemoveSelfLink=true"" \ --feature-gates=""SCTPSupport=true,RemoveSelfLink=true"" \"," --feature-gates=""SCTPSupport=true"" \ --feature-gates=""SCTPSupport=true"" \ --feature-gates=""SCTPSupport=true"" \ --feature-gates=""SCTPSupport=true"" \",4,4
openstack%2Fpython-monascaclient~master~I6deeb7f5205d045e45c70729c87168cc6445534a,openstack/python-monascaclient,master,I6deeb7f5205d045e45c70729c87168cc6445534a,Fix zuul publish docker image job,MERGED,2021-02-08 11:30:20.000000000,2021-02-08 12:48:39.000000000,2021-02-08 12:47:09.000000000,"[{'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2021-02-08 11:30:20.000000000', 'files': ['playbooks/docker-publish.yml'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/952c4c12fc67ff998003b35b75c2c54b4b69f5f2', 'message': 'Fix zuul publish docker image job\n\nAdd tag to docker push command\n\nChange-Id: I6deeb7f5205d045e45c70729c87168cc6445534a\n'}]",0,774437,952c4c12fc67ff998003b35b75c2c54b4b69f5f2,7,2,1,28062,,,0,"Fix zuul publish docker image job

Add tag to docker push command

Change-Id: I6deeb7f5205d045e45c70729c87168cc6445534a
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/37/774437/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/docker-publish.yml'],1,952c4c12fc67ff998003b35b75c2c54b4b69f5f2,fix-zuul-publish," shell: ""docker push monasca/client:{{ zuul.tag if zuul.pipeline == 'release' else zuul.branch }}"""," shell: ""docker push monasca/client""",1,1
openstack%2Fneutron~stable%2Fussuri~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/ussuri,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 11:34:41.000000000,2021-02-08 12:38:23.000000000,2021-02-08 12:36:21.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 11:34:41.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b84dbd68e8416f23575617f9e8e8f14ab014faf6', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774129,b84dbd68e8416f23575617f9e8e8f14ab014faf6,10,3,1,13095,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/774129/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,b84dbd68e8416f23575617f9e8e8f14ab014faf6,bug-1912651-stable/ussuri, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Fneutron~stable%2Fvictoria~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,stable/victoria,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-02-05 11:34:04.000000000,2021-02-08 12:35:57.000000000,2021-02-08 12:33:23.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 11:34:04.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9827eba86690f16818fad1c5684da3fc93c433b', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)\n'}]",0,774128,f9827eba86690f16818fad1c5684da3fc93c433b,14,4,1,13095,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
(cherry picked from commit 412160b97fc398f105c3f7386b928eeec2d9e60a)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/774128/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,f9827eba86690f16818fad1c5684da3fc93c433b,bug-1912651-stable/victoria, self._initialize_sg() self._initialize_sg() def _initialize_sg(self): self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set() , self.sg_port_map = SGPortMap() self.conj_ip_manager = ConjIPFlowManager(self) self.sg_to_delete = set(),7,3
openstack%2Fkolla~stable%2Fussuri~I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec,openstack/kolla,stable/ussuri,I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec,Fix Mistral source images to respect upper-constraints,MERGED,2021-01-29 20:01:21.000000000,2021-02-08 12:35:50.000000000,2021-02-08 12:33:33.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2021-01-29 20:01:21.000000000', 'files': ['releasenotes/notes/mistral-respect-uc-77aea99b5c6506ba.yaml', 'docker/mistral/mistral-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7a4044afb1f063d4d24ce782e546bd71d047c549', 'message': 'Fix Mistral source images to respect upper-constraints\n\nBackport to all supported branches.\n\nChange-Id: I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec\n(cherry picked from commit 004d9eb5d575fcb140b4d90fb30ced0a81dd3e66)\n'}]",0,773013,7a4044afb1f063d4d24ce782e546bd71d047c549,9,3,1,30491,,,0,"Fix Mistral source images to respect upper-constraints

Backport to all supported branches.

Change-Id: I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec
(cherry picked from commit 004d9eb5d575fcb140b4d90fb30ced0a81dd3e66)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/13/773013/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/mistral-respect-uc-77aea99b5c6506ba.yaml', 'docker/mistral/mistral-base/Dockerfile.j2']",2,7a4044afb1f063d4d24ce782e546bd71d047c549,mistral-respect-uc-stable/victoria-stable/ussuri," && {{ macros.install_pip(mistral_base_pip_packages | customizable(""pip_packages"")) }} \"," && {{ macros.install_pip(mistral_base_pip_packages | customizable(""pip_packages""), constraints = false) }} \",5,1
openstack%2Fkolla~stable%2Fvictoria~I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec,openstack/kolla,stable/victoria,I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec,Fix Mistral source images to respect upper-constraints,MERGED,2021-01-29 20:01:04.000000000,2021-02-08 12:30:52.000000000,2021-02-08 12:29:22.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2021-01-29 20:01:04.000000000', 'files': ['releasenotes/notes/mistral-respect-uc-77aea99b5c6506ba.yaml', 'docker/mistral/mistral-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/cf305aaaf0364006185df76be8c0e3e6ab555154', 'message': 'Fix Mistral source images to respect upper-constraints\n\nBackport to all supported branches.\n\nChange-Id: I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec\n(cherry picked from commit 004d9eb5d575fcb140b4d90fb30ced0a81dd3e66)\n'}]",0,773012,cf305aaaf0364006185df76be8c0e3e6ab555154,12,3,1,30491,,,0,"Fix Mistral source images to respect upper-constraints

Backport to all supported branches.

Change-Id: I4a13bbe959e3324f05d5cf78a3be2415eb2ba7ec
(cherry picked from commit 004d9eb5d575fcb140b4d90fb30ced0a81dd3e66)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/12/773012/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/mistral-respect-uc-77aea99b5c6506ba.yaml', 'docker/mistral/mistral-base/Dockerfile.j2']",2,cf305aaaf0364006185df76be8c0e3e6ab555154,mistral-respect-uc-stable/victoria," && {{ macros.install_pip(mistral_base_pip_packages | customizable(""pip_packages"")) }} \"," && {{ macros.install_pip(mistral_base_pip_packages | customizable(""pip_packages""), constraints = false) }} \",5,1
openstack%2Ftripleo-ci~master~I3140b910312ad35b550f69d05311d3ab79adfdb1,openstack/tripleo-ci,master,I3140b910312ad35b550f69d05311d3ab79adfdb1,Log directory workspace/logs do not exists.,MERGED,2021-01-25 16:27:23.000000000,2021-02-08 11:28:30.000000000,2021-02-08 11:28:30.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-25 16:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c897d24636d19ff39d29abfffaede470529ed042', 'message': ""Log directory workspace/logs do not exists.\n\nWhen job fails in pre playbooks and goes to\nlogs collection, it fails because doesn't\nfind logs directory.\n\nCloses-Bug: #1913077\nChange-Id: I3140b910312ad35b550f69d05311d3ab79adfdb1\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n""}, {'number': 2, 'created': '2021-01-29 09:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e28d0b1360d341abd83d617be9da228c99d79abb', 'message': ""Log directory workspace/logs do not exists.\n\nWhen job fails in pre playbooks and goes to\nlogs collection, it fails because doesn't\nfind logs directory.\n\nCloses-Bug: #1913077\nChange-Id: I3140b910312ad35b550f69d05311d3ab79adfdb1\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n""}, {'number': 3, 'created': '2021-02-01 16:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/57dadefcdb671607783dc0e1c8afd9fb9f230b2a', 'message': ""Log directory workspace/logs do not exists.\n\nWhen job fails in pre playbooks and goes to\nlogs collection, it fails because doesn't\nfind logs directory.\n\nCloses-Bug: #1913077\nChange-Id: I3140b910312ad35b550f69d05311d3ab79adfdb1\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n""}, {'number': 4, 'created': '2021-02-02 14:07:21.000000000', 'files': ['playbooks/tripleo-ci/post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1809fd12deb327ba2233ce527ecbf952ec9152cc', 'message': ""Log directory workspace/logs do not exists.\n\nWhen job fails in pre playbooks and goes to\nlogs collection, it fails because doesn't\nfind logs directory.\n\nCloses-Bug: #1913077\nChange-Id: I3140b910312ad35b550f69d05311d3ab79adfdb1\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n""}]",6,772372,1809fd12deb327ba2233ce527ecbf952ec9152cc,26,8,4,30750,,,0,"Log directory workspace/logs do not exists.

When job fails in pre playbooks and goes to
logs collection, it fails because doesn't
find logs directory.

Closes-Bug: #1913077
Change-Id: I3140b910312ad35b550f69d05311d3ab79adfdb1
Signed-off-by: Amol Kahat <amolkahat@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/72/772372/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tripleo-ci/post.yaml'],1,c897d24636d19ff39d29abfffaede470529ed042,bz_1913077," - name: ""Check if {{ ansible_user_dir }}/workspace/log exists"" stat: path: ""{{ ansible_user_dir }}/workspace/log"" register: log_dir_exists - name: ""Create log directory if not exists"" file: path: ""{{ ansible_user_dir }}/workspace/log"" state: directory recurse: yes when: log_dir_exists.stat.exists ",,12,0
openstack%2Ftripleo-quickstart-extras~master~Id57ecea69a3568767f5b4bea101c14ad1335d286,openstack/tripleo-quickstart-extras,master,Id57ecea69a3568767f5b4bea101c14ad1335d286,Don't create redundant heat_stack_owner role,MERGED,2020-12-22 05:40:40.000000000,2021-02-08 11:28:26.000000000,2021-02-08 11:28:26.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}]","[{'number': 1, 'created': '2020-12-22 05:40:40.000000000', 'files': ['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2', 'roles/validate-tempest/files/tempest-undercloud-config.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4cbe54933d785b78175bd4d0c8e60d8926c784f7', 'message': ""Don't create redundant heat_stack_owner role\n\nThis is not required as all the roles of the user are\ndelegated by default to the trustee. Also removes the\ntempest configuration related to that.\n\nChange-Id: Id57ecea69a3568767f5b4bea101c14ad1335d286\n""}]",5,768142,4cbe54933d785b78175bd4d0c8e60d8926c784f7,11,4,1,8833,,,0,"Don't create redundant heat_stack_owner role

This is not required as all the roles of the user are
delegated by default to the trustee. Also removes the
tempest configuration related to that.

Change-Id: Id57ecea69a3568767f5b4bea101c14ad1335d286
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/42/768142/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2', 'roles/validate-tempest/files/tempest-undercloud-config.conf']",2,4cbe54933d785b78175bd4d0c8e60d8926c784f7,,,[orchestration] stack_owner_role = heat_stack_owner ,0,20
openstack%2Fbifrost~stable%2Fvictoria~I01d87177bc6137daa2616b34572303a4185ac914,openstack/bifrost,stable/victoria,I01d87177bc6137daa2616b34572303a4185ac914,docs: explain OS support in terms of two tiers,MERGED,2021-02-08 11:00:06.000000000,2021-02-08 11:25:13.000000000,2021-02-08 11:23:31.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-08 11:00:06.000000000', 'files': ['doc/source/install/index.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/cb3e8104284ea98d508ba124e8d39e7ce5710b17', 'message': ""docs: explain OS support in terms of two tiers\n\n1st tier are OS that we're pretty confident in, 2nd tier are supported\nOS that have some problems or are tested indirectly.\n\nChange-Id: I01d87177bc6137daa2616b34572303a4185ac914\n(cherry picked from commit e0cb590a3f427a13f2c40abac8948382dfb8d01a)\n""}]",0,774411,cb3e8104284ea98d508ba124e8d39e7ce5710b17,7,2,1,10239,,,0,"docs: explain OS support in terms of two tiers

1st tier are OS that we're pretty confident in, 2nd tier are supported
OS that have some problems or are tested indirectly.

Change-Id: I01d87177bc6137daa2616b34572303a4185ac914
(cherry picked from commit e0cb590a3f427a13f2c40abac8948382dfb8d01a)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/11/774411/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/index.rst'],1,cb3e8104284ea98d508ba124e8d39e7ce5710b17,tiers-stable/victoria,"Supported operating systems =========================== 1st tier support (fully tested in the CI, no known or potential issues): * CentOS Stream 8 * Ubuntu 20.04 ""Focal"" * Debian 9 ""Buster"" 2nd tier support (limited testing or known issues): * Ubuntu 18.04 ""Bionic"" Tested in the Bifrost CI, but no longer tested in the ironic upstream CI. * RHEL 8 and regular CentOS 8 Only tested indirectly via CentOS Stream 8. * openSUSE Leap 15.2 Tested in the CI but has frequent issues. Only the latest Fedora is tested in the CI. .. note:: Operating systems evolve and so does the support for them, even on stable branches. This especially concerns Fedora, which is evolving faster than other distributions.","Requirements ============ Supported operating systems: * Ubuntu 18.04, 20.04 * CentOS 8 Stream (normal CentOS 8 and RHEL 8 should work but are not tested) * openSUSE Leap 15.2 (15.1 is supported but not recommended)* Debian Buster",28,7
openstack%2Fmagnum~master~I8e266e49b6d3cfe5a0920bf2346fd743e0365281,openstack/magnum,master,I8e266e49b6d3cfe5a0920bf2346fd743e0365281,Update API version history doc,MERGED,2020-11-30 23:17:24.000000000,2021-02-08 11:04:59.000000000,2021-02-08 11:02:03.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-11-30 23:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4209756d26383ba69e88e2913bdb95830d398fd2', 'message': 'Update API version history doc\n\nInfo copied from magnum/api/controllers/versions.py\n\nChange-Id: I8e266e49b6d3cfe5a0920bf2346fd743e0365281\n'}, {'number': 2, 'created': '2021-02-05 14:28:23.000000000', 'files': ['magnum/api/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d21d7d50896343ad442b723d2769b3d870db41e6', 'message': 'Update API version history doc\n\nInfo copied from magnum/api/controllers/versions.py\n\nChange-Id: I8e266e49b6d3cfe5a0920bf2346fd743e0365281\n'}]",0,764860,d21d7d50896343ad442b723d2769b3d870db41e6,11,4,2,8064,,,0,"Update API version history doc

Info copied from magnum/api/controllers/versions.py

Change-Id: I8e266e49b6d3cfe5a0920bf2346fd743e0365281
",git fetch https://review.opendev.org/openstack/magnum refs/changes/60/764860/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/api/rest_api_version_history.rst'],1,4209756d26383ba69e88e2913bdb95830d398fd2,, 1.7 --- Add resize API 1.8 --- Add upgrade API 1.9 --- Add nodegroup API,,18,0
openstack%2Fvalidations-common~master~Ide7ef784e254b705748135e315a23dab4a35f9ec,openstack/validations-common,master,Ide7ef784e254b705748135e315a23dab4a35f9ec,Simple tests for validation_output callback.,ABANDONED,2021-02-08 10:48:27.000000000,2021-02-08 10:49:26.000000000,,[],"[{'number': 1, 'created': '2021-02-08 10:48:27.000000000', 'files': ['validations_common/tests/callback_plugins/test_validation_output.py'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/1e5e74c97237299cde97bb246ccef49467ed12a3', 'message': 'Simple tests for validation_output callback.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Ide7ef784e254b705748135e315a23dab4a35f9ec\n'}]",0,774432,1e5e74c97237299cde97bb246ccef49467ed12a3,2,0,1,32926,,,0,"Simple tests for validation_output callback.

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: Ide7ef784e254b705748135e315a23dab4a35f9ec
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/32/774432/1 && git format-patch -1 --stdout FETCH_HEAD,['validations_common/tests/callback_plugins/test_validation_output.py'],1,1e5e74c97237299cde97bb246ccef49467ed12a3,unittests/validationoutput," """""" MockStats mimics some behavior of the ansible.executor.stats.AggregateStats. Othewise it behaves like an ordinary MagicMock """"""class DummyResults(dict): """""" DummyResults is used in tests as a substitute, mimicking the behavior of the ansible.executor.task_results.TaskResults class. """""" def __init__(self): self.task_fields = {} @mock.patch('ansible.constants.COLOR_WARN') @mock.patch('pprint.pprint') @mock.patch( 'validations_common.callback_plugins.validation_output.FAILURE_TEMPLATE', create=True) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_print_failure_message_script(self, mock_display, mock_failure_template, mock_pprint, mock_color_warn, mock_color_error): """""" The test places assertions on the values of arguments passed to the format method of the FAILURE_TEMPLATE obj, and the display method of the ansible.utils.display.Display class. As such it mostly deals with string manipulation, and is therefore sensitive to localisation and formatting changes, including the color of the output text. """""" mock_abridged_result = mock.MagicMock() mock_results = DummyResults() mock_results._task_fields = { 'action': 'script', 'args': '_raw_params' } host_name = 'foo' task_name = 'bar' mock_results['results'] = [ { 'foo': 'bar', 'failed': 5 } ] mock_results['rc'] = 'fizz' mock_results['invocation'] = { 'module_args': { '_raw_params': 'buzz' }, } callback = validation_output.CallbackModule() callback.print_failure_message( host_name, task_name, mock_results, mock_abridged_result ) mock_failure_template.format.assert_called_once_with( task_name, host_name, 'Script `buzz` exited with code: fizz' ) mock_display.assert_called_once_with( mock_failure_template.format(), color=mock_color_error ) @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_WARN') @mock.patch('pprint.pprint') @mock.patch( 'validations_common.callback_plugins.validation_output.FAILURE_TEMPLATE', create=True) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_print_failure_message_rc_and_cmd(self, mock_display, mock_failure_template, mock_pprint, mock_color_warn, mock_color_error): """""" The test places assertions on the values of arguments passed to the format method of the FAILURE_TEMPLATE obj, and the display method of the ansible.utils.display.Display class. As such it mostly deals with string manipulation, and is therefore sensitive to localisation and formatting changes, including the color of the output text. The test assumes that both 'rc' and 'cmd' keys are present within the results object. """""" mock_abridged_result = mock.MagicMock() host_name = 'foo' task_name = 'bar' result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ], 'cmd': 'fizz', 'rc': 'buzz' } callback = validation_output.CallbackModule() callback.print_failure_message( host_name, task_name, result_dict, mock_abridged_result ) mock_failure_template.format.assert_called_once_with( task_name, host_name, ""Command `fizz` exited with code: buzz"" ) mock_display.assert_called_once_with( mock_failure_template.format(), color=mock_color_error ) @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_WARN') @mock.patch('pprint.pprint') @mock.patch( 'validations_common.callback_plugins.validation_output.FAILURE_TEMPLATE', create=True) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_print_failure_message_unknown_error_no_warn(self, mock_display, mock_failure_template, mock_pprint, mock_color_warn, mock_color_error): """""" The test places assertions on the values of arguments passed to the format method of the FAILURE_TEMPLATE obj, the display method of the ansible.utils.display.Display class and the pprint method. As such it mostly deals with string manipulation, and is therefore sensitive to localisation and formatting changes, including the color of the output text. Test assumes that neither pair of 'rc' and 'cmd' keys, nor the 'msg' key, exists within the results object. Therefore an Unknown error is assumed to have occured and output is adjusted accordignly. Furthermore, the test assumes that in absence of 'warnings' key, no warnings will be passed to the display method. """""" mock_abridged_result = mock.MagicMock() host_name = 'foo' task_name = 'bar' result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ] } callback = validation_output.CallbackModule() callback.print_failure_message( host_name, task_name, result_dict, mock_abridged_result ) mock_failure_template.format.assert_called_once_with( task_name, host_name, ""Unknown error"" ) mock_display.assert_called_once_with( mock_failure_template.format(), color=mock_color_error ) mock_pprint.assert_called_once_with( mock_abridged_result, indent=4) @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_WARN') @mock.patch('pprint.pprint') @mock.patch( 'validations_common.callback_plugins.validation_output.FAILURE_TEMPLATE', create=True) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_print_failure_message_unknown_error_warn(self, mock_display, mock_failure_template, mock_pprint, mock_color_warn, mock_color_error): """""" The test places assertions on the values of arguments passed to the format method of the FAILURE_TEMPLATE obj, the display method of the ansible.utils.display.Display class and the pprint method. As such it mostly deals with string manipulation, and is therefore sensitive to localisation and formatting changes, including the color of the output text. Test assumes that neither pair of 'rc' and 'cmd' keys, nor the 'msg' key, exists within the results object. Therefore an Unknown error is assumed to have occured and output is adjusted accordignly. Furthermore, the test assumes that when the 'warnings' key is present, the display method will be called with list entries as arguments. """""" mock_abridged_result = mock.MagicMock() host_name = 'foo' task_name = 'bar' result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ], 'warnings': [ 'foo' ] } callback = validation_output.CallbackModule() callback.print_failure_message( host_name, task_name, result_dict, mock_abridged_result) mock_failure_template.format.assert_called_once_with( task_name, host_name, ""Unknown error"") mock_display.assert_has_calls( [ mock.call( mock_failure_template.format(), color=mock_color_error ), mock.call( ""* foo "", color=mock_color_warn ) ] ) mock_pprint.assert_called_once_with( mock_abridged_result, indent=4) @mock.patch('ansible.constants.COLOR_WARN') @mock.patch( 'validations_common.callback_plugins.validation_output.WARNING_TEMPLATE', create=True) @mock.patch( 'validations_common.callback_plugins.validation_output.CallbackModule._dump_results', return_value={'foo': 'bar'}) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_v2_runner_on_ok_warnings(self, mock_display, mock_dump_results, mock_warn_template, mock_error_color): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ], 'warnings': [ 'foo' ] } mock_results._result = result_dict mock_results._host() mock_results._task.get_name() mock_results._task_fields() callback = validation_output.CallbackModule() callback.v2_runner_on_ok(mock_results) mock_dump_results.assert_called_once_with(result_dict) mock_warn_template.format.assert_called_once_with( mock_results._task.get_name(), mock_results._host, 'foo\n') mock_display.assert_called_once_with( mock_warn_template.format(), color=mock_error_color) @mock.patch('ansible.constants.COLOR_OK') @mock.patch( 'validations_common.callback_plugins.validation_output.DEBUG_TEMPLATE', create=True) @mock.patch( 'validations_common.callback_plugins.validation_output.CallbackModule._dump_results', return_value={'foo': 'bar'}) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_v2_runner_on_ok_debug_vars(self, mock_display, mock_dump_results, mock_debug_template, mock_ok_color): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ], 'fizz': 'buzz' } mock_results._result = result_dict mock_results._host() mock_results._task.get_name() mock_results._task_fields = { 'action': 'debug', 'args': {'var': 'fizz'} } callback = validation_output.CallbackModule() callback.v2_runner_on_ok(mock_results) mock_dump_results.assert_called_once_with(result_dict) mock_debug_template.format.assert_called_once_with( mock_results._host, ""fizz: buzz"" ) mock_display.assert_called_once_with( mock_debug_template.format(), color=mock_ok_color) @mock.patch('ansible.constants.COLOR_OK') @mock.patch( 'validations_common.callback_plugins.validation_output.DEBUG_TEMPLATE', create=True) @mock.patch( 'validations_common.callback_plugins.validation_output.CallbackModule._dump_results', return_value={'foo': 'bar'}) @mock.patch( 'ansible.utils.display.Display.display', create=True) def test_v2_runner_on_ok_debug_msg(self, mock_display, mock_dump_results, mock_debug_template, mock_ok_color): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ] } mock_results._result = result_dict mock_results._host() mock_results._task.get_name() mock_results._task_fields = { 'action': 'debug', 'args': {'msg': 'fizz'} } callback = validation_output.CallbackModule() callback.v2_runner_on_ok(mock_results) mock_dump_results.assert_called_once_with(result_dict) mock_debug_template.format.assert_called_once_with( mock_results._host, ""Message: fizz"" ) mock_display.assert_called_once_with( mock_debug_template.format(), color=mock_ok_color) @mock.patch( 'validations_common.callback_plugins.validation_output.CallbackModule._dump_results', return_value={'foo': 'bar'}) @mock.patch('validations_common.callback_plugins.validation_output.CallbackModule.print_failure_message') def test_v2_runner_on_failed_one_result(self, mock_print, mock_dump_results): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() result_dict = { 'results': [ { 'foo': 'bar', 'failed': 5 } ] } mock_results._result = result_dict mock_results._host() mock_results._task.get_name() callback = validation_output.CallbackModule() callback.v2_runner_on_failed(mock_results) mock_print.assert_called_once_with( mock_results._host, mock_results._task.get_name(), { 'foo': 'bar', 'failed': 5 }, { 'foo': 'bar', 'failed': 5 } ) @mock.patch( 'validations_common.callback_plugins.validation_output.CallbackModule._dump_results', return_value={'foo': 'bar'}) @mock.patch('validations_common.callback_plugins.validation_output.CallbackModule.print_failure_message') def test_v2_runner_on_failed_no_result(self, mock_print, mock_dump_results): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() result_dict = {} mock_results._result = result_dict mock_results._host() mock_results._task.get_name() callback = validation_output.CallbackModule() callback.v2_runner_on_failed(mock_results) mock_print.assert_called_once_with( mock_results._host, mock_results._task.get_name(), {}, { 'foo': 'bar' } ) @mock.patch('validations_common.callback_plugins.validation_output.CallbackModule.print_failure_message') def test_v2_runner_on_unreachable(self, mock_print): """""" The test asserts on argumets passed to print_failure_message method. In order to check the call arguments we need initialize them before passing the mock_results to the tested method. It is a bit hacky, but the most simple way I know how to make sure the relevant mocks ids don't change. If you know how to improve it, go for it. """""" mock_results = mock.MagicMock() results_dict = {'msg': 'The host is unreachable.'} mock_results._host() mock_results._task.get_name() callback = validation_output.CallbackModule() callback.v2_runner_on_unreachable(mock_results) mock_print.assert_called_once_with( mock_results._host, mock_results._task.get_name(), results_dict, results_dict) @mock.patch('ansible.constants.COLOR_ERROR')"," def _set_summary(self, dummy_summary): """""" Arguments: dummy_summary: should be dict """""" self.summary = dummy_summary ",539,7
openstack%2Fvalidations-common~master~Ib548898cbdbbe7c94e09b053f83a9e7245e2d744,openstack/validations-common,master,Ib548898cbdbbe7c94e09b053f83a9e7245e2d744,Simple tests for validation_output callback.,ABANDONED,2021-02-08 10:48:27.000000000,2021-02-08 10:49:16.000000000,,[],"[{'number': 1, 'created': '2021-02-08 10:48:27.000000000', 'files': ['validations_common/tests/callback_plugins/test_validation_output.py'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/6fbe3ecf17bd0f0f6cba3e782524488494c07289', 'message': 'Simple tests for validation_output callback.\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Ib548898cbdbbe7c94e09b053f83a9e7245e2d744\n'}]",0,774431,6fbe3ecf17bd0f0f6cba3e782524488494c07289,2,0,1,32926,,,0,"Simple tests for validation_output callback.

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: Ib548898cbdbbe7c94e09b053f83a9e7245e2d744
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/31/774431/1 && git format-patch -1 --stdout FETCH_HEAD,['validations_common/tests/callback_plugins/test_validation_output.py'],1,6fbe3ecf17bd0f0f6cba3e782524488494c07289,unittests/validationoutput,"from unittest import mock from ansible.executor.stats import AggregateStats from ansible.parsing.ajson import AnsibleJSONEncoder from ansible.playbook import Playbook from ansible.plugins.callback import CallbackBasefrom validations_common.callback_plugins import validation_output class MockStats(mock.MagicMock): summary = {} def _set_summary(self, dummy_summary): """""" Arguments: dummy_summary: should be dict """""" self.summary = dummy_summary def summarize(self, anything): return self.summary.get(anything, self.summary) def test_callback_instantiation(self): """""" Verifying that the CallbackModule is instantiated properly. Test checks presence of CallbackBase in the inheritance chain, in order to ensure that folowing tests are performed with the correct assumptions. """""" callback = validation_output.CallbackModule() self.assertEqual(type(callback).__mro__[1], CallbackBase) """""" Every ansible callback needs to define variable with name and version. The validation_output plugin also defines CALLBACK_TYPE, so we need to check it too. """""" self.assertIn('CALLBACK_NAME', dir(callback)) self.assertIn('CALLBACK_VERSION', dir(callback)) self.assertIn('CALLBACK_TYPE', dir(callback)) self.assertEqual(callback.CALLBACK_NAME, 'validation_output') self.assertIsInstance(callback.CALLBACK_VERSION, float) self.assertEqual(callback.CALLBACK_TYPE, 'stdout') @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_OK') @mock.patch('validations_common.callback_plugins.validation_output.print') @mock.patch.object(CallbackBase, '_display.display', create=True) def test_v2_playbook_on_stats_no_hosts(self, mock_display, mock_print, mock_color_ok, mock_color_error): """""" In case we don't supply any hosts, we expect the method not to call display or related methods and attributes even once. The final call to print function is not an ideal place for assertion, as the string might get localised and/or adjusted in the future. """""" callback = validation_output.CallbackModule() dummy_stats = mock.MagicMock() callback.v2_playbook_on_stats(dummy_stats) mock_color_ok.assert_not_called() mock_color_error.assert_not_called() mock_display.assert_not_called() mock_print.assert_called_once() @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_OK') @mock.patch('validations_common.callback_plugins.validation_output.print') @mock.patch( 'validations_common.callback_plugins.validation_output.sorted', return_value=['bar', 'foo']) @mock.patch('ansible.utils.display.Display.display') @mock.patch('ansible.plugins.callback.CallbackBase') def test_v2_playbook_on_stats_no_fail(self, mock_callback_base, mock_display, mock_sorted, mock_print, mock_color_ok, mock_color_error): """""" When we have hosts and their state is not specified, we expect them to be considered a `pass` and the display method to be called with appropriate arguments. The final call to print function is not an ideal place for assertion, as the string might get localised and/or adjusted in the future. """""" callback = validation_output.CallbackModule() dummy_stats = MockStats() callback.v2_playbook_on_stats(dummy_stats) mock_display.assert_called_with('* foo', color=mock_color_ok) mock_print.assert_called_once() @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_OK') @mock.patch('validations_common.callback_plugins.validation_output.print') @mock.patch( 'validations_common.callback_plugins.validation_output.sorted', return_value=['bar', 'buzz', 'fizz', 'foo']) @mock.patch('ansible.utils.display.Display.display') @mock.patch('ansible.plugins.callback.CallbackBase') def test_v2_playbook_on_stats_some_fail(self, mock_callback_base, mock_display, mock_sorted, mock_print, mock_color_ok, mock_color_error): """""" When at least one host is specified as failure and/or unreachable we expect it to be considered a `failure` and the display method to be called with the appropriate arguments in the proper order. The final call to print function is not an ideal place for assertion, as the string might get localised and/or adjusted in the future. """""" callback = validation_output.CallbackModule() dummy_stats = MockStats() dummy_stats.summary = { 'fizz': { 'failures': 5 } } expected_calls = [ mock.call('* fizz', color=mock_color_error), mock.call('* bar', color=mock_color_ok), mock.call('* buzz', color=mock_color_ok), mock.call('* foo', color=mock_color_ok) ] callback.v2_playbook_on_stats(dummy_stats) mock_display.assert_has_calls(expected_calls) mock_print.assert_called() @mock.patch('ansible.constants.COLOR_ERROR') @mock.patch('ansible.constants.COLOR_OK') @mock.patch('validations_common.callback_plugins.validation_output.print') @mock.patch( 'validations_common.callback_plugins.validation_output.sorted', return_value=['bar', 'buzz', 'fizz', 'foo']) @mock.patch('ansible.utils.display.Display.display') @mock.patch('ansible.plugins.callback.CallbackBase') def test_v2_playbook_on_stats_all_fail(self, mock_callback_base, mock_display, mock_sorted, mock_print, mock_color_ok, mock_color_error): """""" When at all hosts are specified as failure and/or unreachable we expect them to be considered a `failure` and the display method to be called with the appropriate arguments in the proper order. The final call to print function is not an ideal place for assertion, as the string might get localised and/or adjusted in the future. """""" callback = validation_output.CallbackModule() dummy_stats = MockStats() dummy_stats.summary = { 'fizz': { 'failures': 5 }, 'foo': { 'failures': 5 }, 'bar': { 'failures': 5 }, 'buzz': { 'failures': 5 } } expected_calls = [ mock.call('* bar', color=mock_color_error), mock.call('* buzz', color=mock_color_error), mock.call('* fizz', color=mock_color_error), mock.call('* foo', color=mock_color_error) ] callback.v2_playbook_on_stats(dummy_stats) mock_display.assert_has_calls(expected_calls) mock_print.assert_called()",from unittest import mock,178,1
openstack%2Fbifrost~master~I01d87177bc6137daa2616b34572303a4185ac914,openstack/bifrost,master,I01d87177bc6137daa2616b34572303a4185ac914,docs: explain OS support in terms of two tiers,MERGED,2021-02-03 11:27:05.000000000,2021-02-08 10:31:27.000000000,2021-02-08 10:29:46.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-03 11:27:05.000000000', 'files': ['doc/source/install/index.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e0cb590a3f427a13f2c40abac8948382dfb8d01a', 'message': ""docs: explain OS support in terms of two tiers\n\n1st tier are OS that we're pretty confident in, 2nd tier are supported\nOS that have some problems or are tested indirectly.\n\nChange-Id: I01d87177bc6137daa2616b34572303a4185ac914\n""}]",1,773875,e0cb590a3f427a13f2c40abac8948382dfb8d01a,8,3,1,10239,,,0,"docs: explain OS support in terms of two tiers

1st tier are OS that we're pretty confident in, 2nd tier are supported
OS that have some problems or are tested indirectly.

Change-Id: I01d87177bc6137daa2616b34572303a4185ac914
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/75/773875/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/index.rst'],1,e0cb590a3f427a13f2c40abac8948382dfb8d01a,tiers,"Supported operating systems =========================== 1st tier support (fully tested in the CI, no known or potential issues): * CentOS Stream 8 * Ubuntu 20.04 ""Focal"" * Debian 9 ""Buster"" 2nd tier support (limited testing or known issues): * Ubuntu 18.04 ""Bionic"" Tested in the Bifrost CI, but no longer tested in the ironic upstream CI. * RHEL 8 and regular CentOS 8 Only tested indirectly via CentOS Stream 8. * openSUSE Leap 15.2 Tested in the CI but has frequent issues. Only the latest Fedora is tested in the CI. .. note:: Operating systems evolve and so does the support for them, even on stable branches. This especially concerns Fedora, which is evolving faster than other distributions.","Requirements ============ Supported operating systems: * Ubuntu 18.04, 20.04 * CentOS 8 Stream (normal CentOS 8 and RHEL 8 should work but are not tested) * openSUSE Leap 15.2 (15.1 is supported but not recommended)* Debian Buster",28,7
openstack%2Ftripleo-ci~master~I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d,openstack/tripleo-ci,master,I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d,Update tempest whitelist for scenario004,MERGED,2021-01-20 15:52:47.000000000,2021-02-08 10:23:49.000000000,2021-02-08 10:23:49.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 9003}, {'_account_id': 9592}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-01-20 15:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/433eac1c4bfcb282ab95f4cfc5616f1f54fedfbe', 'message': 'Update tempest whitelist for scenario004\n\nIn https://review.opendev.org/c/openstack/tripleo-ci/+/770049 we\nupdated scenrio004 to use CephFS gatewayed by NFS rather than native\nCephFS but we did not enable the NFS test case via the tempest whitelist\nsince these also require the THT changes in dependent review\nhttps://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937.\n\nHere we enable the NFS test case, dependent on the just-mentioned\nTHT patch.\n\nDepends-on: https: //review.opendev.org/c/openstack/tripleo-heat-templates/+/769937\n\nChange-Id: I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d\n'}, {'number': 2, 'created': '2021-01-21 15:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b84db7bf8debfd663fb53738582a2c85edc88024', 'message': 'Update tempest whitelist for scenario004\n\nIn https://review.opendev.org/c/openstack/tripleo-ci/+/770049 we\nupdated scenrio004 to use CephFS gatewayed by NFS rather than native\nCephFS but we did not enable the NFS test case via the tempest whitelist\nsince these also require the THT changes in dependent review\nhttps://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937.\n\nHere we enable the NFS test case, dependent on the just-mentioned\nTHT patch.\n\nDepends-on: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937\n\nChange-Id: I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d\n'}, {'number': 3, 'created': '2021-02-05 17:51:59.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65dc8bde15297874baa98c7779f3cea75e1057f8', 'message': 'Update tempest whitelist for scenario004\n\nIn https://review.opendev.org/c/openstack/tripleo-ci/+/770049 we\nupdated scenrio004 to use CephFS gatewayed by NFS rather than native\nCephFS but we did not enable the NFS test case via the tempest whitelist\nsince these also require the THT changes in dependent review\nhttps://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937.\n\nHere we enable the NFS test case, dependent on the just-mentioned\nTHT patch.\n\nDepends-on: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937\n\nChange-Id: I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d\n'}]",1,771664,65dc8bde15297874baa98c7779f3cea75e1057f8,19,8,3,9003,,,0,"Update tempest whitelist for scenario004

In https://review.opendev.org/c/openstack/tripleo-ci/+/770049 we
updated scenrio004 to use CephFS gatewayed by NFS rather than native
CephFS but we did not enable the NFS test case via the tempest whitelist
since these also require the THT changes in dependent review
https://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937.

Here we enable the NFS test case, dependent on the just-mentioned
THT patch.

Depends-on: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937

Change-Id: I9c848ce6e0bf7fa07c94ca714d3a5d739f79f85d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/64/771664/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,433eac1c4bfcb282ab95f4cfc5616f1f54fedfbe,, - 'manila_tempest_tests.tests.api.test_shares.SharesNFSTest.test_create_get_delete_share', # Add the following back after # https://review.opendev.org/c/openstack/tripleo-heat-templates/+/769937 merges # - 'manila_tempest_tests.tests.api.test_shares.SharesNFSTest.test_create_get_delete_share',1,3
openstack%2Fnova~master~I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7,openstack/nova,master,I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7,api: Reject requests to reset the state of SHELVE_OFFLOADED servers,NEW,2021-01-30 14:36:30.000000000,2021-02-08 10:18:29.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 29307}]","[{'number': 1, 'created': '2021-01-30 14:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d057dda7f46a16c5210de413ac8fab1a0375bc2', 'message': 'Adding a validation on os-resetState so that when vm is shelved offload,\nreseting the VM state is blocked. In shelved state VM doesnt existed physically\non compute nodes.\n\nSigned-off-by: Khomesh Thakre <khomeshthakre24@gmail.com>\nCloses-Bug: 1913016\nChange-Id: I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7\n'}, {'number': 2, 'created': '2021-01-30 14:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/769b12fb8e1d3a427b418691703a40f93a7e0bcf', 'message': 'Adding a validation on os-resetState so that when vm is shelved offload,\nreseting the VM state is blocked. In shelved state VM does not existed\nphysically on compute nodes.\n\nSigned-off-by: Khomesh Thakre <khomeshthakre24@gmail.com>\nCloses-Bug: 1913016\nChange-Id: I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7\n'}, {'number': 3, 'created': '2021-01-30 16:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70999bf3c7919306bbefe65371f9423ba3a02fe9', 'message': 'Adding a validation on os-resetState so that when vm is shelved offload,\nreseting the VM state is blocked. In shelved state VM doesnt existed physically\non compute nodes.\n\nSigned-off-by: Khomesh Thakre <khomeshthakre24@gmail.com>\nCloses-Bug: 1913016\nChange-Id: I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7\n'}, {'number': 4, 'created': '2021-02-05 06:00:34.000000000', 'files': ['nova/api/openstack/compute/admin_actions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e1877be3270fd6446c5970ee0443b4843d6adb1e', 'message': 'api: Reject requests to reset the state of SHELVE_OFFLOADED servers\n\nAdding a validation on os-resetState so that when vm is shelved offload,\nreseting the VM state is blocked. In shelved state VM doesnt existed\nphysically on compute nodes.\n\nSigned-off-by: Khomesh Thakre <khomeshthakre24@gmail.com>\nCloses-Bug: 1913016\nChange-Id: I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7\n'}]",10,773238,e1877be3270fd6446c5970ee0443b4843d6adb1e,34,3,4,29307,,,0,"api: Reject requests to reset the state of SHELVE_OFFLOADED servers

Adding a validation on os-resetState so that when vm is shelved offload,
reseting the VM state is blocked. In shelved state VM doesnt existed
physically on compute nodes.

Signed-off-by: Khomesh Thakre <khomeshthakre24@gmail.com>
Closes-Bug: 1913016
Change-Id: I7d3d6d88ddbf530e0547e4122f4274ecf037a7c7
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/773238/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/admin_actions.py'],1,0d057dda7f46a16c5210de413ac8fab1a0375bc2,,"from oslo_log import log as loggingfrom nova.i18n import _ LOG = logging.getLogger(__name__) # If VM is shelved offload, setting the state is blocked # As vm doesnt exist physically on compute node if instance.vm_state == 'shelved_offloaded': msg = _('Action not allowed as Instance is %(instance)s ' 'shelved' ) % { 'instance':instance.display_name } raise exc.HTTPBadRequest(explanation=msg) else: instance.vm_state = state instance.task_state = None instance.save(admin_state_reset=True) instance_action.finish()", instance.vm_state = state instance.task_state = None instance.save(admin_state_reset=True) instance_action.finish(),16,4
openstack%2Fbifrost~master~I90c7ba15a10faaab24712a8cdc8b6c67457b51a6,openstack/bifrost,master,I90c7ba15a10faaab24712a8cdc8b6c67457b51a6,Collect firewalld info if present,MERGED,2021-02-03 17:40:46.000000000,2021-02-08 10:15:36.000000000,2021-02-08 10:14:07.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 17:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/4ba9b015d950776af994eefebfbe0573ee006872', 'message': '[WIP] Collect firewalld info if present\n\nChange-Id: I90c7ba15a10faaab24712a8cdc8b6c67457b51a6\n'}, {'number': 2, 'created': '2021-02-04 08:22:50.000000000', 'files': ['scripts/collect-test-info.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/70101f6a2d18d71b98f0ccc2518550cef7a17ecb', 'message': 'Collect firewalld info if present\n\nChange-Id: I90c7ba15a10faaab24712a8cdc8b6c67457b51a6\n'}]",0,773953,70101f6a2d18d71b98f0ccc2518550cef7a17ecb,10,3,2,23851,,,0,"Collect firewalld info if present

Change-Id: I90c7ba15a10faaab24712a8cdc8b6c67457b51a6
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/53/773953/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/collect-test-info.sh'],1,4ba9b015d950776af994eefebfbe0573ee006872,collect-firewalld-info, if $(sudo firewall-cmd --version &>/dev/null); then sudo firewall-cmd --list-all-zones &> ${LOG_LOCATION}/firewalld-zones.log fi ,,5,0
openstack%2Fneutron~master~Iff47cf1646fc99fd5a1bf4ff5498d4a15f9d9d68,openstack/neutron,master,Iff47cf1646fc99fd5a1bf4ff5498d4a15f9d9d68,Remove duplicated assignement of the device_owner in UT,MERGED,2021-02-03 20:12:38.000000000,2021-02-08 10:14:00.000000000,2021-02-08 10:09:03.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 22348}, {'_account_id': 32231}]","[{'number': 1, 'created': '2021-02-03 20:12:38.000000000', 'files': ['neutron/tests/unit/agent/linux/test_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc322a6e7de7404c05889b1539803103748dadf3', 'message': ""Remove duplicated assignement of the device_owner in UT\n\nIn the unit tests of the dhcp linux driver module there are some\nfake port classes defined.\nSome of them had duplicate assignement of the device_owner, once\nit was set to some constant value and later it was assignment with\nsome value given as an __init__'s argument.\nThis patch removes setting constant value. We can always accept\nvalue given as input argument.\n\nTrivialFix\n\nChange-Id: Iff47cf1646fc99fd5a1bf4ff5498d4a15f9d9d68\n""}]",0,773995,dc322a6e7de7404c05889b1539803103748dadf3,11,4,1,11975,,,0,"Remove duplicated assignement of the device_owner in UT

In the unit tests of the dhcp linux driver module there are some
fake port classes defined.
Some of them had duplicate assignement of the device_owner, once
it was set to some constant value and later it was assignment with
some value given as an __init__'s argument.
This patch removes setting constant value. We can always accept
value given as input argument.

TrivialFix

Change-Id: Iff47cf1646fc99fd5a1bf4ff5498d4a15f9d9d68
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/773995/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/agent/linux/test_dhcp.py'],1,dc322a6e7de7404c05889b1539803103748dadf3,fix-dhcp-ut,, self.device_owner = constants.DEVICE_OWNER_ROUTER_INTF self.device_owner = constants.DEVICE_OWNER_ROUTER_INTF,0,2
openstack%2Fneutron~master~Ib73babdd563e3e8c21ce6f63456cc87af414c5aa,openstack/neutron,master,Ib73babdd563e3e8c21ce6f63456cc87af414c5aa,Don't try to create default SG when security groups are disabled,MERGED,2021-01-26 13:56:47.000000000,2021-02-08 10:12:15.000000000,2021-02-08 10:06:49.000000000,"[{'_account_id': 841}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-26 13:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe806d460e6dce1bf6f490d528bb3f5e50b39ce9', 'message': ""Don't try to create default SG when security groups are disabled\n\nIf security group API is disabled, there is no point to create default\nsecurity group for tenant when e.g. network is created.\n\nCloses-Bug: #1913297\nChange-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa\n""}, {'number': 2, 'created': '2021-01-27 10:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b622b40445ca71e55b0ece502ae1a2062e9bcec', 'message': ""Don't try to create default SG when security groups are disabled\n\nIf security group API is disabled, there is no point to create default\nsecurity group for tenant when e.g. network is created.\n\nCloses-Bug: #1913297\nChange-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa\n""}, {'number': 3, 'created': '2021-01-27 15:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/82eca8f7129c51e7e4f9086878f3ce19e7ce5dac', 'message': ""Don't try to create default SG when security groups are disabled\n\nIf security group API is disabled, there is no point to create default\nsecurity group for tenant when e.g. network is created.\n\nCloses-Bug: #1913297\nChange-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa\n""}, {'number': 4, 'created': '2021-02-03 09:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4dc3d6289688cb445c3177e966743cfccaef27fe', 'message': ""Don't try to create default SG when security groups are disabled\n\nIf security group API is disabled, there is no point to create default\nsecurity group for tenant when e.g. network is created.\n\nCloses-Bug: #1913297\nChange-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa\n""}, {'number': 5, 'created': '2021-02-05 15:08:33.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/db/test_securitygroups_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/013c183d7c1a16d07f5acae9e29b157b0ffd8fae', 'message': ""Don't try to create default SG when security groups are disabled\n\nIf security group API is disabled, there is no point to create default\nsecurity group for tenant when e.g. network is created.\n\nCloses-Bug: #1913297\nChange-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa\n""}]",18,772526,013c183d7c1a16d07f5acae9e29b157b0ffd8fae,39,8,5,11975,,,0,"Don't try to create default SG when security groups are disabled

If security group API is disabled, there is no point to create default
security group for tenant when e.g. network is created.

Closes-Bug: #1913297
Change-Id: Ib73babdd563e3e8c21ce6f63456cc87af414c5aa
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/772526/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/tests/unit/db/test_securitygroups_db.py']",2,fe806d460e6dce1bf6f490d528bb3f5e50b39ce9,bug/1913297," is_ext_supported = mock.patch( 'neutron_lib.api.extensions.is_extension_supported') self.is_ext_supported = is_ext_supported.start() self.mixin, '_get_default_sg_id') as get_default_sg_id,\ self.mixin, '_get_default_sg_id') as get_default_sg_id,\ self.mixin, 'create_security_group') as create_sg: def test__ensure_default_security_group_when_disabled(self): with mock.patch( 'neutron_lib.api.extensions.is_extension_supported', return_value=False),\ mock.patch.object( self.mixin, '_get_default_sg_id') as get_default_sg_id,\ mock.patch.object( self.mixin, 'create_security_group') as create_sg: get_default_sg_id.return_value = None self.mixin._ensure_default_security_group(self.ctx, 'tenant_1') create_sg.assert_not_called() get_default_sg_id.assert_not_called()"," self.mixin, '_get_default_sg_id') as get_default_sg_id,\ self.mixin, '_get_default_sg_id') as get_default_sg_id,\ self.mixin, 'create_security_group') as create_sg:",22,3
openstack%2Frequirements~master~I3b451a13d0af993f36c7664a0609920933e2744f,openstack/requirements,master,I3b451a13d0af993f36c7664a0609920933e2744f,Updated from generate-constraints,MERGED,2021-02-07 06:25:47.000000000,2021-02-08 10:10:43.000000000,2021-02-08 10:07:29.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 06:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/836bf8fd5c4a7898985c159fbac4790e070f2245', 'message': 'Updated from generate-constraints\n\nChange-Id: I3b451a13d0af993f36c7664a0609920933e2744f\n'}, {'number': 2, 'created': '2021-02-08 06:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/79376c67e058e4ac852b9f891f04076039fc8a21', 'message': 'Updated from generate-constraints\n\nChange-Id: I3b451a13d0af993f36c7664a0609920933e2744f\n'}, {'number': 3, 'created': '2021-02-08 06:36:16.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ed019e17dfc136092fe55ff41e2570f566e320e9', 'message': 'Updated from generate-constraints\n\nChange-Id: I3b451a13d0af993f36c7664a0609920933e2744f\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,774366,ed019e17dfc136092fe55ff41e2570f566e320e9,13,2,3,11131,,,0,"Updated from generate-constraints

Change-Id: I3b451a13d0af993f36c7664a0609920933e2744f
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/66/774366/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,836bf8fd5c4a7898985c159fbac4790e070f2245,openstack/requirements/constraints/noclob,mock===4.0.3construct===2.10.59oslo.db===8.5.0oslo.policy===3.6.2pkg-resources===0.0.0fasteners===0.16virtualenv===20.4.2,mock===3.0.5construct===2.10.58oslo.db===8.4.0oslo.policy===3.6.0fasteners===0.14.1virtualenv===20.2.1setuptools===53.0.0,7,7
openstack%2Fneutron~master~I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8,openstack/neutron,master,I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8,Add extension unit tests for conntrack_helper plugin,MERGED,2021-02-06 02:36:33.000000000,2021-02-08 10:08:29.000000000,2021-02-08 10:08:29.000000000,"[{'_account_id': 5948}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-06 02:36:33.000000000', 'files': ['neutron/tests/unit/extensions/test_l3_conntrack_helper.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbfac6b7a849a5b7344c525d8fd070e48bdbe6b2', 'message': 'Add extension unit tests for conntrack_helper plugin\n\nChange-Id: I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8\n'}]",0,774344,cbfac6b7a849a5b7344c525d8fd070e48bdbe6b2,10,4,1,28329,,,0,"Add extension unit tests for conntrack_helper plugin

Change-Id: I2e89bcb183a75f39ba6aeeef6f1ea355fca59fc8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/774344/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/extensions/test_l3_conntrack_helper.py'],1,cbfac6b7a849a5b7344c525d8fd070e48bdbe6b2,add-conntrack-helper-extension-unit-test,"# Copyright 2021 Troila # All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from unittest import mock from webob import exc from neutron_lib.api.definitions import l3 as l3_apidef from neutron_lib.api.definitions import l3_conntrack_helper as l3_ct from neutron_lib import context from oslo_utils import uuidutils from neutron.extensions import l3 from neutron.extensions import l3_conntrack_helper from neutron.tests.unit.api import test_extensions from neutron.tests.unit.extensions import test_l3 _uuid = uuidutils.generate_uuid class TestL3ConntrackHelperServicePlugin(test_l3.TestL3NatServicePlugin): supported_extension_aliases = [l3_apidef.ALIAS, l3_ct.ALIAS] class ExtendL3ConntrackHelperExtensionManager(object): def get_resources(self): return (l3.L3.get_resources() + l3_conntrack_helper.L3_conntrack_helper.get_resources()) def get_actions(self): return [] def get_request_extensions(self): return [] class L3NConntrackHelperTestCase(test_l3.L3BaseForIntTests, test_l3.L3NatTestCaseMixin): tenant_id = _uuid() fmt = ""json"" def setUp(self): mock.patch('neutron.api.rpc.handlers.resources_rpc.' 'ResourcesPushRpcApi').start() svc_plugins = ('neutron.services.conntrack_helper.plugin.Plugin', 'neutron.tests.unit.extensions.' 'test_l3_conntrack_helper.' 'TestL3ConntrackHelperServicePlugin') plugin = ('neutron.tests.unit.extensions.test_l3.TestL3NatIntPlugin') ext_mgr = ExtendL3ConntrackHelperExtensionManager() super(L3NConntrackHelperTestCase, self).setUp( ext_mgr=ext_mgr, service_plugins=svc_plugins, plugin=plugin) self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr) def _create_router_conntrack_helper(self, fmt, router_id, protocol, port, helper): tenant_id = self.tenant_id or _uuid() data = {'conntrack_helper': { ""protocol"": protocol, ""port"": port, ""helper"": helper} } router_ct_req = self._req( 'POST', 'routers', data, fmt or self.fmt, id=router_id, subresource='conntrack_helpers') router_ct_req.environ['neutron.context'] = context.Context( '', tenant_id, is_admin=True) return router_ct_req.get_response(self.ext_api) def _update_router_conntrack_helper(self, fmt, router_id, conntrack_helper_id, **kwargs): conntrack_helper = {} for k, v in kwargs.items(): conntrack_helper[k] = v data = {'conntrack_helper': conntrack_helper} router_ct_req = self._req( 'PUT', 'routers', data, fmt or self.fmt, id=router_id, sub_id=conntrack_helper_id, subresource='conntrack_helpers') return router_ct_req.get_response(self.ext_api) def test_create_ct_with_duplicate_entry(self): with self.router() as router: ct1 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct1.status_code) ct2 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPBadRequest.code, ct2.status_code) expect_msg = (""Bad conntrack_helper request: A duplicate "" ""conntrack helper entry with same attributes "" ""already exists, conflicting values are "" ""{'router_id': '%s', 'protocol': 'udp', "" ""'port': 69, 'helper': "" ""'tftp'}."") % router['router']['id'] self.assertEqual( expect_msg, ct2.json_body['NeutronError']['message']) def test_update_ct_with_duplicate_entry(self): with self.router() as router: ct1 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 69, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct1.status_code) ct2 = self._create_router_conntrack_helper( self.fmt, router['router']['id'], ""udp"", 68, ""tftp"") self.assertEqual(exc.HTTPCreated.code, ct2.status_code) result = self._update_router_conntrack_helper( self.fmt, router['router']['id'], ct1.json['conntrack_helper']['id'], **{'port': 68}) self.assertEqual(exc.HTTPBadRequest.code, result.status_code) expect_msg = (""Bad conntrack_helper request: A duplicate "" ""conntrack helper entry with same attributes "" ""already exists, conflicting values are "" ""{'router_id': '%s', 'protocol': 'udp', "" ""'port': 68, 'helper': "" ""'tftp'}."") % router['router']['id'] self.assertEqual( expect_msg, result.json_body['NeutronError']['message']) ",,141,0
openstack%2Ftacker~master~Icb0f8066de783372305c45c464ce1619b4b8fa02,openstack/tacker,master,Icb0f8066de783372305c45c464ce1619b4b8fa02,[DNM] Add new test for zuul-install,NEW,2021-02-05 04:30:47.000000000,2021-02-08 09:38:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-05 04:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/d11ea87afb00f3353d41c5570092d4030aeba9f7', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 2, 'created': '2021-02-05 06:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/fe87f060a530609db69a899ccdb46b526f660a22', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 3, 'created': '2021-02-05 08:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3a8f974f72652eb8c42c6a12af1f7cd08e191e4f', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 4, 'created': '2021-02-05 09:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/666585fa0d7ab8569ddf3c08fe18b8b20382e333', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 5, 'created': '2021-02-05 09:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/f88280fe252bc3b6a42da12e3a87f420c928cee1', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 6, 'created': '2021-02-08 01:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/e0766779ccec9b03c7e66649810930b556f27604', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}, {'number': 7, 'created': '2021-02-08 06:50:45.000000000', 'files': ['tacker/common/exceptions.py', 'test-requirements.txt', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Scripts/kubernetes_mgmt_cluster.py', 'playbooks/devstack/run_cluster.yaml', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Scripts/install_k8s_cluster.sh', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/TOSCA-Metadata/TOSCA.meta', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Files/images/ubuntu-20.04-server-cloudimg-amd64.img', 'requirements.txt', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Files/kubernetes/deployment.yaml', 'tacker/tests/unit/vnflcm/fakes.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_top.vnfd.yaml', 'tacker/tests/functional/k8s_cluster/vnfm/test_kubernetes_mgmt.py', 'tacker/api/validation/parameter_types.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_a_SOL/Definitions/helloworld3_df_simple.yaml', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Definitions/helloworld3_types.yaml', 'tacker/vnfm/mgmt_drivers/vnflcm_abstract_driver.py', 'playbooks/devstack/pre_cluster.yaml', 'tacker/tests/functional/k8s_cluster/__init__.py', 'tacker/vnfm/mgmt_drivers/vnflcm_noop.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_a_SOL/TOSCA-Metadata/TOSCA.meta', '.zuul.yaml', 'tacker/tests/functional/k8s_cluster/vnfm/__init__.py', 'tacker/tests/unit/vnflcm/test_vnflcm_driver.py', 'lower-constraints.txt', 'tacker/vnfm/mgmt_drivers/kubernetes_mgmt_cluster.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_types.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_df_simple.yaml', 'roles/setup-default-vim/tasks/main.yaml', 'tools/test-setup-k8s-cluster-env.sh', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Definitions/helloworld3_top.vnfd.yaml', 'setup.cfg', 'tools/modify-local-conf.sh', 'tox.ini', 'tacker/vnflcm/vnflcm_driver.py', 'roles/modify-local-conf/tasks/main.yaml', 'tacker/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/d035e35a945fef79deedaf17fa2578eff9677e76', 'message': '[DNM] Add new test for zuul-install\n\nChange-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02\n'}]",0,774193,d035e35a945fef79deedaf17fa2578eff9677e76,14,1,7,31821,,,0,"[DNM] Add new test for zuul-install

Change-Id: Icb0f8066de783372305c45c464ce1619b4b8fa02
",git fetch https://review.opendev.org/openstack/tacker refs/changes/93/774193/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/common/exceptions.py', 'test-requirements.txt', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Scripts/kubernetes_mgmt_cluster.py', 'playbooks/devstack/run_cluster.yaml', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Scripts/install_k8s_cluster.sh', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/TOSCA-Metadata/TOSCA.meta', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Files/images/ubuntu-20.04-server-cloudimg-amd64.img', 'requirements.txt', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Files/kubernetes/deployment.yaml', 'tacker/tests/unit/vnflcm/fakes.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_top.vnfd.yaml', 'tacker/tests/functional/k8s_cluster/vnfm/test_kubernetes_mgmt.py', 'tacker/api/validation/parameter_types.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_a_SOL/Definitions/helloworld3_df_simple.yaml', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Definitions/helloworld3_types.yaml', 'tacker/vnfm/mgmt_drivers/vnflcm_abstract_driver.py', 'tacker/tests/functional/k8s_cluster/__init__.py', 'tacker/vnfm/mgmt_drivers/vnflcm_noop.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_a_SOL/TOSCA-Metadata/TOSCA.meta', '.zuul.yaml', 'tacker/tests/functional/k8s_cluster/vnfm/__init__.py', 'tacker/tests/unit/vnflcm/test_vnflcm_driver.py', 'lower-constraints.txt', 'tacker/vnfm/mgmt_drivers/kubernetes_mgmt_cluster.py', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_types.yaml', 'tacker/tests/etc/samples/etsi/nfv/test_scenario_b/Definitions/helloworld3_df_simple.yaml', 'roles/setup-default-vim/tasks/main.yaml', 'tools/test-setup-k8s-cluster-env.sh', 'tacker/tests/etc/samples/etsi/nfv/common_mgmt_cluster/Definitions/helloworld3_top.vnfd.yaml', 'setup.cfg', 'tox.ini', 'tacker/vnflcm/vnflcm_driver.py', 'tacker/tests/utils.py']",33,d11ea87afb00f3353d41c5570092d4030aeba9f7,zuul-install-test,"import hashlibdef _update_image_hash(data): try: prop1 = data['topology_template']['node_templates']['masterNode'] prop2 = data['topology_template']['node_templates']['workerNode'] except KeyError: # Let's check for 'node_types' pass if prop1 and prop2: hash_obj = hashlib.sha512() path = os.path.abspath(os.path.join( os.path.dirname(__file__), 'etc/samples/etsi/nfv/common_mgmt_cluster/Files/images/' 'ubuntu-20.04-server-cloudimg-amd64.img')) f = open(path, 'rb') hash_obj.update(f.read()) hash_value = hash_obj.hexdigest() f.close() prop1['properties']['sw_image_data']['checksum']['hash'] = hash_value prop2['properties']['sw_image_data']['checksum']['hash'] = hash_value else: pass def create_csar_with_unique_mgmt_cluster(csar_dir): unique_id = uuidutils.generate_uuid() tempfd, tempname = tempfile.mkstemp(suffix="".zip"", dir=os.path.dirname(csar_dir)) os.close(tempfd) common_mgmt_cluster_dir = os.path.join( csar_dir, '../common_mgmt_cluster') common_dir = os.path.join(csar_dir, '../common') zcsar = zipfile.ZipFile(tempname, 'w') mgmt_cluster_files = [] for (dpath, _, fnames) in os.walk(csar_dir): if not fnames: continue for fname in fnames: if fname == 'TOSCA.meta' or fname.endswith('.mf'): src_file = os.path.join(dpath, fname) with open(src_file, 'rb') as f: artifacts_data = f.read() artifacts_data_split = re.split(b'\n\n+', artifacts_data) for data in artifacts_data_split: if re.findall(b"".?Algorithm:.?"", data) and\ re.findall(b"".?Hash:.?"", data): artifact_data_dict = yaml.safe_load(data) mgmt_cluster_files.append( artifact_data_dict['Source'] if 'Source' in artifact_data_dict.keys() else artifact_data_dict['Name']) mgmt_cluster_files = list(set(mgmt_cluster_files)) for (dpath, _, fnames) in os.walk(common_mgmt_cluster_dir): if not fnames: continue for fname in fnames: src_file = os.path.join(dpath, fname) dst_file = os.path.relpath( os.path.join(dpath, fname), common_mgmt_cluster_dir) if fname.endswith('.yaml') or fname.endswith('.yml'): if dst_file not in mgmt_cluster_files: with open(src_file, 'rb') as yfile: data = yaml.safe_load(yfile) _update_unique_id_in_yaml(data, unique_id) zcsar.writestr(dst_file, yaml.dump( data, default_flow_style=False, allow_unicode=True)) else: zcsar.write(src_file, dst_file) else: zcsar.write(src_file, dst_file) for (dpath, _, fnames) in os.walk(csar_dir): if not fnames: continue for fname in fnames: src_file = os.path.join(dpath, fname) dst_file = os.path.relpath(os.path.join(dpath, fname), csar_dir) if 'Definitions' in src_file and \ (fname.endswith('.yaml') or fname.endswith('.yml')): if dst_file not in mgmt_cluster_files: with open(src_file, 'rb') as yfile: data = yaml.safe_load(yfile) _update_image_hash(data) zcsar.writestr(dst_file, yaml.dump( data, default_flow_style=False, allow_unicode=True)) else: zcsar.write(src_file, dst_file) else: zcsar.write(src_file, dst_file) for (dpath, _, fnames) in os.walk(common_dir): if not fnames: continue if 'Files' in dpath or 'Scripts' in dpath: continue for fname in fnames: src_file = os.path.join(dpath, fname) dst_file = os.path.relpath(os.path.join(dpath, fname), common_dir) zcsar.write(src_file, dst_file) zcsar.close() return tempname, unique_id ",,4476,189
openstack%2Fironic~master~Idba486c98e1e92d35fca2e2d156866566acb9e40,openstack/ironic,master,Idba486c98e1e92d35fca2e2d156866566acb9e40,Don't mark an agent as alive if rebooted,MERGED,2021-02-03 17:06:41.000000000,2021-02-08 09:26:57.000000000,2021-02-08 09:24:47.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 17:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9cc617f462288f31ef6e8577d6804449dba54af1', 'message': ""Don't mark an agent as alive if rebooted\n\nIf the last power state change is more recent\nthen the last agent heartbeat then don't mark\nthe agent as alive.\n\nChange-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40\nStory: 2008583\nTask: 41736\n""}, {'number': 2, 'created': '2021-02-04 11:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/08c2d09da8ce3cd07bce3b4785d5413d84b97898', 'message': ""Don't mark an agent as alive if rebooted\n\nIf 'agent_url' has been cleared from internal_info\nit indicates that the node has been powered off.\n\nChange-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40\nStory: 2008583\nTask: 41736\n""}, {'number': 3, 'created': '2021-02-04 13:02:09.000000000', 'files': ['ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py', 'releasenotes/notes/agent-rebooted-fab20d012fe6cbe8.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4287951d711b94972abd13bac6dcbd7250e0867e', 'message': ""Don't mark an agent as alive if rebooted\n\nIf 'agent_url' has been cleared from internal_info\nit indicates that the node has been powered off.\n\nChange-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40\nStory: 2008583\nTask: 41736\n""}]",3,773949,4287951d711b94972abd13bac6dcbd7250e0867e,27,4,3,1926,,,0,"Don't mark an agent as alive if rebooted

If 'agent_url' has been cleared from internal_info
it indicates that the node has been powered off.

Change-Id: Idba486c98e1e92d35fca2e2d156866566acb9e40
Story: 2008583
Task: 41736
",git fetch https://review.opendev.org/openstack/ironic refs/changes/49/773949/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py', 'releasenotes/notes/agent-rebooted-fab20d012fe6cbe8.yaml']",3,9cc617f462288f31ef6e8577d6804449dba54af1,,--- fixes: - | Fixes Fastrack to prevent marking the agent as alive if trying to rebuild a node befor the Fast track timeout has expired. ,,28,0
openstack%2Freleases~master~I4f8aca952fae44a737cab10f56d2dac0648d4503,openstack/releases,master,I4f8aca952fae44a737cab10f56d2dac0648d4503,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 19:01:20.000000000,2021-02-08 09:22:14.000000000,2021-02-08 09:22:14.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-26 19:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1185ac90100c211b456fd7d6019c0b38e708d6d8', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503\n'}, {'number': 2, 'created': '2020-12-26 20:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4f2f0ea5cb2a44cab4750223ed79c1d08aab9054', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503\n'}, {'number': 3, 'created': '2020-12-28 21:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/92b73c27bca89a2df1eed9e472a025581ff38686', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503\n""}, {'number': 4, 'created': '2021-01-12 22:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1b8bd98e059e6df82c4b8d937455c058db945d7c', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503\n""}, {'number': 5, 'created': '2021-01-12 22:17:44.000000000', 'files': ['deliverables/stein/solum-tempest-plugin.yaml', 'deliverables/wallaby/solum-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f320b5a4032c11365f8d7c504dab7e84786b5825', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503\n""}]",0,768558,f320b5a4032c11365f8d7c504dab7e84786b5825,21,3,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: I4f8aca952fae44a737cab10f56d2dac0648d4503
",git fetch https://review.opendev.org/openstack/releases refs/changes/58/768558/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/solum-tempest-plugin.yaml'],1,1185ac90100c211b456fd7d6019c0b38e708d6d8,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/solum-tempest-plugin hash: 80e23bb97926308505bc0ac206974468b38efe4e,,4,0
openstack%2Freleases~master~If5360db5adcefc8bce0b38c21172e725e0a5d3f1,openstack/releases,master,If5360db5adcefc8bce0b38c21172e725e0a5d3f1,[Tempest Plugins] Tag stein-last,MERGED,2020-12-26 18:45:35.000000000,2021-02-08 09:19:24.000000000,2021-02-08 09:19:24.000000000,"[{'_account_id': 8099}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-12-26 18:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0f418b3cdb234937edeb6f408b28bfd556ef5bb4', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1\n'}, {'number': 2, 'created': '2020-12-26 20:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/32a726b5e746a9c89c4bcb7aa8b6c444fd55d9f8', 'message': '[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1\n'}, {'number': 3, 'created': '2020-12-28 21:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8ab50df74fd53d2d4c20fba4f43ca12a6ba70ec7', 'message': ""[Tempest Plugins] Tag stein EM\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-em' as well as a new version also with same hash.\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1\n""}, {'number': 4, 'created': '2021-01-12 22:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0280bfaa8106f153e2643b98299fa9b39d2dc018', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1\n""}, {'number': 5, 'created': '2021-01-12 22:24:55.000000000', 'files': ['deliverables/stein/designate-tempest-plugin.yaml', 'deliverables/wallaby/designate-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e4e4f1a5bcf5188e643ef6a544ec827337cb2b09', 'message': ""[Tempest Plugins] Tag stein-last\n\nStein branch is in Extended Maintenance now[1]. All Tempest\nplugins are branchless which means master version of Tempest\nand its plugins is used to test the supported stable branches.\n\nOnce stable branch is moved to EM state then, Tempest and its\nplugins compatible tag needs to be released so that we can\nkeep testing the EM stable branches with this tag once master\nTempest and its plugins are not compatible[2].\n\nThis tag will help for testing the stable/stein with single\ncompatible tag of Tempest and its plugins.\n\nTagging 'stein-last' as well as a new version also with same hash.\nDocumenting this new tag name here\n- https://review.opendev.org/c/openstack/project-team-guide/+/769821\n\nMore detail on compatible version policy for Tempest and its\nplugins is here\n- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\n[1] https://releases.openstack.org/stein/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n\nChange-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1\n""}]",0,768541,e4e4f1a5bcf5188e643ef6a544ec827337cb2b09,22,5,5,8556,,,0,"[Tempest Plugins] Tag stein-last

Stein branch is in Extended Maintenance now[1]. All Tempest
plugins are branchless which means master version of Tempest
and its plugins is used to test the supported stable branches.

Once stable branch is moved to EM state then, Tempest and its
plugins compatible tag needs to be released so that we can
keep testing the EM stable branches with this tag once master
Tempest and its plugins are not compatible[2].

This tag will help for testing the stable/stein with single
compatible tag of Tempest and its plugins.

Tagging 'stein-last' as well as a new version also with same hash.
Documenting this new tag name here
- https://review.opendev.org/c/openstack/project-team-guide/+/769821

More detail on compatible version policy for Tempest and its
plugins is here
- https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

[1] https://releases.openstack.org/stein/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html

Change-Id: If5360db5adcefc8bce0b38c21172e725e0a5d3f1
",git fetch https://review.opendev.org/openstack/releases refs/changes/41/768541/5 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/designate-tempest-plugin.yaml'],1,0f418b3cdb234937edeb6f408b28bfd556ef5bb4,tempest-plugin-stein-last, - version: stein-em projects: - repo: openstack/designate-tempest-plugin hash: 5da3047851aae36f09e0b52f79523426fec6a104,,4,0
openstack%2Ftripleo-quickstart~master~I78508d1f8058896c244b40a8a06940221a810a58,openstack/tripleo-quickstart,master,I78508d1f8058896c244b40a8a06940221a810a58,Add openvswitch dependency pipeline repo config,MERGED,2021-01-13 13:50:03.000000000,2021-02-08 09:10:14.000000000,2021-02-08 09:08:24.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-01-13 13:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/35f62e9effb750c5ad067e1dd1de69026330acd8', 'message': 'WIP add openvswitch dependency repo config\n\nChange-Id: I78508d1f8058896c244b40a8a06940221a810a58\n'}, {'number': 2, 'created': '2021-01-28 10:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/9460aa588e28a0c094c7dafb3f911d01b3f82431', 'message': 'WIP add openvswitch dependency repo config\n\nChange-Id: I78508d1f8058896c244b40a8a06940221a810a58\n'}, {'number': 3, 'created': '2021-01-28 11:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/27663937b619f2c9286df8f0f126716bf80da861', 'message': 'WIP add openvswitch dependency repo config\n\nNeeded by https://review.rdoproject.org/r/#/c/31539/\n\nChange-Id: I78508d1f8058896c244b40a8a06940221a810a58\n'}, {'number': 4, 'created': '2021-02-02 10:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/89ef48f4aa922a935c4afc18fe21619ea19a5500', 'message': 'WIP add openvswitch dependency repo config\n\nNeeded by https://review.rdoproject.org/r/#/c/31539/\n\nChange-Id: I78508d1f8058896c244b40a8a06940221a810a58\n'}, {'number': 5, 'created': '2021-02-03 10:57:16.000000000', 'files': ['config/release/dependency_ci/openvswitch/repo_config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5440c9171cc194d1465cccce1bf3f03bf2e488f9', 'message': 'Add openvswitch dependency pipeline repo config\n\nAdds the repo config used by the openvswitch dependency\npipeline jobs defined in [1] which depends-on this patch.\n\n[1] https://review.rdoproject.org/r/#/c/31539/\n\nChange-Id: I78508d1f8058896c244b40a8a06940221a810a58\n'}]",0,770620,5440c9171cc194d1465cccce1bf3f03bf2e488f9,19,6,5,8449,,,0,"Add openvswitch dependency pipeline repo config

Adds the repo config used by the openvswitch dependency
pipeline jobs defined in [1] which depends-on this patch.

[1] https://review.rdoproject.org/r/#/c/31539/

Change-Id: I78508d1f8058896c244b40a8a06940221a810a58
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/20/770620/5 && git format-patch -1 --stdout FETCH_HEAD,['config/release/dependency_ci/openvswitch/repo_config.yaml'],1,35f62e9effb750c5ad067e1dd1de69026330acd8,I78508d1f8058896c244b40a8a06940221a810a58,"--- add_repos: - type: generic reponame: quickstart-centos-openvswitch filename: ""quickstart-centos-openvswitch.repo"" baseurl: ""https://buildlogs.centos.org/centos/8/nfv/x86_64/openvswitch-2/"" update_container: false dep_repo_cmd_after: | # enable conatiner tools rhel8 sudo dnf repolist; sudo dnf module list; sudo dnf module disable container-tools:2.0 -y; sudo dnf module enable container-tools:rhel8 -y; sudo dnf clean metadata; sudo dnf clean all; sudo dnf update -y; ",,16,0
openstack%2Fmanila-ui~master~I239e5aeb5296ef0534688ae10059cff57a269ea5,openstack/manila-ui,master,I239e5aeb5296ef0534688ae10059cff57a269ea5,DNM: testing manila-ui integration tests,ABANDONED,2021-01-29 05:53:38.000000000,2021-02-08 08:54:50.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-29 05:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/f80486e19353f99a9952e7e5e4317fe5487be08c', 'message': 'test\n\nthis patch is to test failing manila-ui integration tests.\n\nChange-Id: I239e5aeb5296ef0534688ae10059cff57a269ea5\n'}, {'number': 2, 'created': '2021-01-29 06:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/8c5045d07feb1134b58311af35b5f7ac787b1ef1', 'message': 'test\n\nthis patch is to test failing manila-ui integration tests.\n\nChange-Id: I239e5aeb5296ef0534688ae10059cff57a269ea5\n'}, {'number': 3, 'created': '2021-01-29 06:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/b9a3148cd8f4464a786f34f477185d0a27e4e344', 'message': 'test\n\nthis patch is to test failing manila-ui integration tests.\n\nChange-Id: I239e5aeb5296ef0534688ae10059cff57a269ea5\n'}, {'number': 4, 'created': '2021-01-29 06:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/a158f8284af1004194e6624512d1072830d40250', 'message': 'DNM: testing manila-ui integration tests\n\nthis patch is to test failing manila-ui integration tests.\n\nChange-Id: I239e5aeb5296ef0534688ae10059cff57a269ea5\n'}]",0,772972,a158f8284af1004194e6624512d1072830d40250,8,1,4,32531,,,0,"DNM: testing manila-ui integration tests

this patch is to test failing manila-ui integration tests.

Change-Id: I239e5aeb5296ef0534688ae10059cff57a269ea5
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/72/772972/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_ui/api/manila.py'],1,f80486e19353f99a9952e7e5e4317fe5487be08c,test,#test,,1,1
openstack%2Fkolla-ansible~master~Ie8d82010bf8d5b8af2c039f285744e5ae67316dc,openstack/kolla-ansible,master,Ie8d82010bf8d5b8af2c039f285744e5ae67316dc,docs: improve external Ceph docs,MERGED,2020-11-20 08:53:41.000000000,2021-02-08 08:44:07.000000000,2021-02-07 15:32:38.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-11-20 08:53:41.000000000', 'files': ['doc/source/reference/storage/external-ceph-guide.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8e47f6b8335b8003952f6e8e33f1f2f43aaaa3bc', 'message': 'docs: improve external Ceph docs\n\n* make each section independent\n* move enable flags to specific sections\n* move inventory changes to Cinder section\n* move Nova config that is actually for Cinder volumes to Cinder section\n* add an introduction about each integration\n\nChange-Id: Ie8d82010bf8d5b8af2c039f285744e5ae67316dc\n'}]",0,763529,8e47f6b8335b8003952f6e8e33f1f2f43aaaa3bc,11,5,1,14826,,,0,"docs: improve external Ceph docs

* make each section independent
* move enable flags to specific sections
* move inventory changes to Cinder section
* move Nova config that is actually for Cinder volumes to Cinder section
* add an introduction about each integration

Change-Id: Ie8d82010bf8d5b8af2c039f285744e5ae67316dc
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/29/763529/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/storage/external-ceph-guide.rst'],1,8e47f6b8335b8003952f6e8e33f1f2f43aaaa3bc,,"Ceph integration is configured for different OpenStack services independently. Ceph RBD can be used as a storage backend for Glance images. Configuring Glance for Ceph includes the following steps: #. Enable Glance Ceph backend in ``globals.yml``: .. code-block:: yaml glance_backend_ceph: ""yes""Ceph RBD can be used as a storage backend for Cinder volumes. Configuring Cinder for Ceph includes following steps: #. When using external Ceph, there may be no nodes defined in the storage group. This will cause Cinder and related services relying on this group to fail. In this case, operator should add some nodes to the storage group, all the nodes where ``cinder-volume`` and ``cinder-backup`` will run: .. code-block:: ini [storage] control01 #. Enable Cinder Ceph backend in ``globals.yml``: .. code-block:: yaml cinder_backend_ceph: ""yes""Nova must also be configured to allow access to Cinder volumes: #. Copy Ceph keyring file(s) to: * ``/etc/kolla/config/nova/<ceph_cinder_keyring>`` Nova ---- Ceph RBD can be used as a storage backend for Nova instance ephemeral disks. This avoids the requirement for local storage for instances on compute nodes. It improves the performance of migration, since instances' ephemeral disks do not need to be copied between hypervisors. Configuring Nova for Ceph includes following steps: #. Enable Nova Ceph backend in ``globals.yml``: .. code-block:: yaml nova_backend_ceph: ""yes"" #. Configure Ceph authentication details in ``/etc/kolla/globals.yml``: * ``ceph_nova_keyring`` (by default it's the same as ``ceph_cinder_keyring``)Ceph object storage can be used as a storage backend for Gnocchi metrics.#. Enable Gnocchi Ceph backend in ``globals.yml``: .. code-block:: yaml gnocchi_backend_storage: ""ceph"" CephFS can be used as a storage backend for Manila shares. Configuring Manila for Ceph includes following steps: #. Enable Manila Ceph backend in ``globals.yml``: .. code-block:: yaml enable_manila_backend_cephfs_native: ""yes"" ","Enabling External Ceph ~~~~~~~~~~~~~~~~~~~~~~ To activate external Ceph integration you need to enable Ceph backend. This can be done individually per service in ``/etc/kolla/globals.yml``: .. code-block:: yaml glance_backend_ceph: ""yes"" cinder_backend_ceph: ""yes"" nova_backend_ceph: ""yes"" gnocchi_backend_storage: ""ceph"" enable_manila_backend_cephfs_native: ""yes"" Edit the Inventory File ~~~~~~~~~~~~~~~~~~~~~~~ When using external Ceph, there may be no nodes defined in the storage group. This will cause Cinder and related services relying on this group to fail. In this case, operator should add some nodes to the storage group, all the nodes where ``cinder-volume`` and ``cinder-backup`` will run: .. code-block:: ini [storage] compute01 Configuring Glance for Ceph includes the following steps:Configuring Cinder for Ceph includes following steps:Nova ---- Configuring Nova for Ceph includes following steps: * ``ceph_nova_keyring`` (by default it's the same as ceph_cinder_keyring) * ``/etc/kolla/config/nova/<ceph_cinder_keyring>``Configuring Manila for Ceph includes following steps: #. Configure CephFS backend by setting ``enable_manila_backend_cephfs_native`` to ``true``",69,38
openstack%2Foctavia-tempest-plugin~master~I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f,openstack/octavia-tempest-plugin,master,I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f,Fix copy output in two-node jobs,ABANDONED,2020-09-21 12:54:15.000000000,2021-02-08 08:27:09.000000000,,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2020-09-21 12:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/dcf5bd449ae64218c0554873bb89820f3db9d64c', 'message': 'Fix copy output in two-node jobs\n\nThe ""zuul_copy_output"" option under host-vars overrides base\n""zuul_copy_output"". This means only barely a handful of log files are\ncopied. Fix this by using ""host_copy_output"" option to combine both log\nfile lists.\n\nChange-Id: I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f\n'}, {'number': 2, 'created': '2021-01-29 11:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/daf597707433412027052d9e2f8a0fa49d457b37', 'message': 'Fix copy output in two-node jobs\n\nThe ""zuul_copy_output"" option under host-vars overrides base\n""zuul_copy_output"". This means only barely a handful of log files are\ncopied. Fix this by using ""host_copy_output"" option to combine both log\nfile lists.\n\nChange-Id: I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f\n'}, {'number': 3, 'created': '2021-02-05 07:37:31.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/4f899f87bae81d2d391117f58d2b3d31a22df7bf', 'message': 'Fix copy output in two-node jobs\n\nThe ""zuul_copy_output"" option under host-vars overrides base\n""zuul_copy_output"". This means only barely a handful of log files are\ncopied. Fix this by using ""host_copy_output"" option to combine both log\nfile lists.\n\nChange-Id: I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f\n'}]",5,752936,4f899f87bae81d2d391117f58d2b3d31a22df7bf,17,5,3,6469,,,0,"Fix copy output in two-node jobs

The ""zuul_copy_output"" option under host-vars overrides base
""zuul_copy_output"". This means only barely a handful of log files are
copied. Fix this by using ""host_copy_output"" option to combine both log
file lists.

Change-Id: I523eb5d13fe5b5d1a3c55b28b5e0e0870b9bb95f
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/36/752936/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,dcf5bd449ae64218c0554873bb89820f3db9d64c,octavia-availability-zones, host_copy_output: host_copy_output:, zuul_copy_output: zuul_copy_output:,2,2
openstack%2Fkolla-ansible~master~I0790830e1c21520df2534d2f3b1ea96010064355,openstack/kolla-ansible,master,I0790830e1c21520df2534d2f3b1ea96010064355,docs: Improve multinode Docker registry setup,MERGED,2020-10-29 10:11:07.000000000,2021-02-08 08:22:52.000000000,2021-02-07 15:27:41.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-10-29 10:11:07.000000000', 'files': ['doc/source/user/multinode.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/34cce4c57e9a609899f2922db83878500495f825', 'message': 'docs: Improve multinode Docker registry setup\n\nThe multinode guide hints at how to setup the registry as a registry\nmirror, however it does not provide all information necessary. This\nchange fixes that, and separates the local registry and registry mirror\ncases.\n\nChange-Id: I0790830e1c21520df2534d2f3b1ea96010064355\nCloses-Bug: #1901768\n'}]",0,760318,34cce4c57e9a609899f2922db83878500495f825,12,5,1,14826,,,0,"docs: Improve multinode Docker registry setup

The multinode guide hints at how to setup the registry as a registry
mirror, however it does not provide all information necessary. This
change fixes that, and separates the local registry and registry mirror
cases.

Change-Id: I0790830e1c21520df2534d2f3b1ea96010064355
Closes-Bug: #1901768
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/18/760318/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/multinode.rst'],1,34cce4c57e9a609899f2922db83878500495f825,bug/1901768,"`pokey registry <https://github.com/docker/docker/issues/14018>`__. The Kolla community recommends using registry 2.3 or later. The registry may be configured either as a local registry with support for storing images, or as a pull-through cache for Docker hub. Option 1: local registry ------------------------ .. code-block:: console docker run -d \ --name registry \ --restart=always \ -p 4000:5000 \ -v registry:/var/lib/registry \ registry:2 Here we are using port 4000 to avoid a conflict with Keystone. If the registry is not running on the same host as Keystone, the ``-p`` argument may be omitted. Edit ``globals.yml`` and add the following, where ``192.168.1.100:4000`` is the IP address and port on which the registry is listening: docker_registry: 192.168.1.100:4000 Option 2: registry mirror -------------------------registry as a pull through cache, pass the environment variable ``REGISTRY_PROXY_REMOTEURL`` through to the registry container. Pushing to a registry configured as a pull-through cache is unsupported. For more information, Reference the `Docker Documentation <https://docs.docker.com/registry/configuration/>`__. docker run -d \ --name registry \ --restart=always \ -p 4000:5000 \ -v registry:/var/lib/registry \ -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io \ registry:2 Edit ``globals.yml`` and add the following, where ``192.168.1.100:4000`` is the IP address and port on which the registry is listening: .. code-block:: yaml docker_custom_config: registry-mirrors: - 192.168.1.100:4000","`pokey registry <https://github.com/docker/docker/issues/14018>`__. Edit the ``/etc/kolla/globals.yml`` and add the following where 192.168.1.100 is the IP address of the machine and 5000 is the port where the registry is currently running: docker_registry: 192.168.1.100:5000 The Kolla community recommends using registry 2.3 or later. To deploy registry with version 2.3 or later, do the following: .. code-block:: console cd kolla tools/start-registryregistry as a pull through cache, in the host machine set the environment variable ``REGISTRY_PROXY_REMOTEURL`` to the URL for the repository on Docker Hub. export REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io .. note:: Pushing to a registry configured as a pull-through cache is unsupported. For more information, Reference the `Docker Documentation <https://docs.docker.com/registry/configuration/>`__. .. _configure_docker_all_nodes: Configure Docker on all nodes ============================= .. note:: As the subtitle for this section implies, these steps should be applied to all nodes, not just the deployment node. After starting the registry, it is necessary to instruct Docker that it will be communicating with an insecure registry. For example, To enable insecure registry communication, modify the ``/etc/docker/daemon.json`` file to contain the following where ``192.168.1.100`` is the IP address of the machine where the registry is currently running: .. path /etc/docker/daemon.json .. code-block:: json { ""insecure-registries"" : [""192.168.1.100:5000""] } Restart Docker by executing the following commands: For CentOS or Ubuntu with systemd: .. code-block:: console systemctl restart docker For Ubuntu with upstart or sysvinit: .. code-block:: console service docker restart",44,57
openstack%2Fironic~master~I3b6ced6dcf03580903f5ea7237fc057f372999f9,openstack/ironic,master,I3b6ced6dcf03580903f5ea7237fc057f372999f9,Prevent redfish-virtual-media from being used with Dell nodes,MERGED,2021-01-20 11:53:56.000000000,2021-02-08 07:49:17.000000000,2021-02-08 07:47:40.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 27909}]","[{'number': 1, 'created': '2021-01-20 11:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/689f10266292ac0f4647e1aeba1d68d9efe40304', 'message': '[WIP] Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n'}, {'number': 2, 'created': '2021-01-20 17:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ddb065cb36cc111117ff076ecd54cf0f700b5285', 'message': ""Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen. Do the reverse with\nthe iDRAC implementation: make sure it's not use for non-Dell\nnodes.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n""}, {'number': 3, 'created': '2021-01-28 13:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/99d1de6a2a257e1542480ea2eab1a8ca53462ec5', 'message': ""Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen. Do the reverse with\nthe iDRAC implementation: make sure it's not use for non-Dell\nnodes.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n""}, {'number': 4, 'created': '2021-01-28 15:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a2c0de3ab47fcc5dde221e7c136b58a244560a5', 'message': ""Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen. Do the reverse with\nthe iDRAC implementation: make sure it's not use for non-Dell\nnodes.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n""}, {'number': 5, 'created': '2021-02-03 15:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6ac7ba6b4b37ffe13442b4d3d676373c75a8fbfa', 'message': ""Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen. Do the reverse with\nthe iDRAC implementation: make sure it's not use for non-Dell\nnodes.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n""}, {'number': 6, 'created': '2021-02-05 11:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/41354289cc16abf7b947a92411a43e944b7c82d9', 'message': ""Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen. Do the reverse with\nthe iDRAC implementation: make sure it's not use for non-Dell\nnodes.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n""}, {'number': 7, 'created': '2021-02-05 11:09:17.000000000', 'files': ['ironic/drivers/modules/drac/boot.py', 'doc/source/admin/drivers/redfish.rst', 'ironic/tests/unit/drivers/modules/drac/test_boot.py', 'ironic/tests/unit/drivers/modules/redfish/test_boot.py', 'ironic/drivers/modules/redfish/boot.py', 'releasenotes/notes/redfish-vmedia-vendor-fc76086893d99415.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cf22604c5863920b56e0b16dbf30894cbb544130', 'message': 'Prevent redfish-virtual-media from being used with Dell nodes\n\nIndicate that idrac-redfish-virtual-media must be used instead,\notherwise a confusing failure will happen.\n\nChange-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9\n'}]",15,771619,cf22604c5863920b56e0b16dbf30894cbb544130,43,6,7,10239,,,0,"Prevent redfish-virtual-media from being used with Dell nodes

Indicate that idrac-redfish-virtual-media must be used instead,
otherwise a confusing failure will happen.

Change-Id: I3b6ced6dcf03580903f5ea7237fc057f372999f9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/19/771619/7 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/drac/boot.py', 'ironic/drivers/modules/redfish/management.py', 'ironic/drivers/modules/redfish/boot.py']",3,689f10266292ac0f4647e1aeba1d68d9efe40304,redfish-vendor," def _validate_vendor(self, task): vendor = task.node.properties.get('vendor') if not vendor: return if 'Dell' in vendor.split(): raise exception.InvalidParameterValue( _(""The %(iface)s boot interface is not suitable for node "" ""%(node)s with vendor %(vendor)s, use "" ""idrac-redfish-virtual-media instead"") % {'iface': task.node.boot_interface, 'node': task.node.uuid, 'vendor': vendor}) self._validate_vendor(task)",,40,0
openstack%2Fheat~stable%2Ftrain~I93abdbf8a9532af1aec7ad15a6f384beb9fc3ff9,openstack/heat,stable/train,I93abdbf8a9532af1aec7ad15a6f384beb9fc3ff9,Use random exponential delay,MERGED,2021-02-06 06:17:00.000000000,2021-02-08 04:49:11.000000000,2021-02-08 04:47:29.000000000,"[{'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-06 06:17:00.000000000', 'files': ['heat/objects/resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/069c4db8fed218702c9cd08d773c5ea9a0807fb0', 'message': 'Use random exponential delay\n\nthis is much more suited for resolving contention when\naccessing a (lockable) shared resource.\n\nChange-Id: I93abdbf8a9532af1aec7ad15a6f384beb9fc3ff9\n(cherry picked from commit 56f6e583d19ef4dd0c1462bfece677a6ec2fa756)\n'}]",0,774270,069c4db8fed218702c9cd08d773c5ea9a0807fb0,10,3,1,8833,,,0,"Use random exponential delay

this is much more suited for resolving contention when
accessing a (lockable) shared resource.

Change-Id: I93abdbf8a9532af1aec7ad15a6f384beb9fc3ff9
(cherry picked from commit 56f6e583d19ef4dd0c1462bfece677a6ec2fa756)
",git fetch https://review.opendev.org/openstack/heat refs/changes/70/774270/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/objects/resource.py'],1,069c4db8fed218702c9cd08d773c5ea9a0807fb0,wait-exp-stable/train," wait=tenacity.wait_random_exponential(multiplier=0.5, max=60),"," wait=tenacity.wait_random(max=2),",1,1
openstack%2Fswift~master~I5d48b67217f705ac30bb427ef8d969a90eaad2e5,openstack/swift,master,I5d48b67217f705ac30bb427ef8d969a90eaad2e5,Enable shard ranges to be manually shrunk to root container,MERGED,2021-01-21 20:58:47.000000000,2021-02-08 03:03:11.000000000,2021-02-08 03:01:39.000000000,"[{'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-21 20:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2711a92643cbd37af871a60e827d6228b267e9c4', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch enables the root container to include its own shard range\nin responses to shard containers when the root determines that it\nshould be an acceptor for the shard. This is only the case when all\nshard ranges in the root db are either deleted or shrinking.  A new\ncontainer GET request param 'include_own_acceptor' is used to indicate\nthat a particular GET request is from the sharder during shard audit;\nthe root shoud not otherwise include its own shard range in GET\nresponses.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 2, 'created': '2021-01-22 10:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0bd9706e42e95a430e6de691ec058fe5c6d1afc4', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch enables the root container to include its own shard range\nin responses to shard containers when the root determines that it\nshould be an acceptor for the shard. This is only the case when all\nshard ranges in the root db are either deleted or shrinking.  A new\ncontainer GET request param 'include_own_acceptor' is used to indicate\nthat a particular GET request is from the sharder during shard audit;\nthe root shoud not otherwise include its own shard range in GET\nresponses.\n\nAlso fix some unit tests that could fail intermittently due to timing.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 3, 'created': '2021-01-25 12:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bc7a92d87847c7342605e0bbf711e3e4d239df4d', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch enables the root container to include its own shard range\nin responses to shard containers when the root determines that it\nshould be an acceptor for the shard. This is only the case when all\nshard ranges in the root db are either deleted or shrinking.  A new\ncontainer GET request param 'include_own_acceptor' is used to indicate\nthat a particular GET request is from the sharder during shard audit;\nthe root shoud not otherwise include its own shard range in GET\nresponses.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 4, 'created': '2021-01-28 18:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/88d67ed2c091fe9afa980b60edf7bce07d53ed62', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nTODO:\n- unit test cleaving ignores non-active root shard range\n- unit test shard audit with root shard range in shard db\n- unit test for resolve_states with 'auditing'\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch modifies the root container behaviour to include its own\nshard range in responses to shard containers when the container GET\nrequest param 'states' has value 'auditing'. This parameter is used to\nindicate that a particular GET request is from the sharder during\nshard audit; the root does not otherwise include its own shard range\nin GET responses.\n\nThe shard only merges the root's shard range (and any other shard\nranges) when the shard is shrinking. If the root shard range is ACTIVE\nthen it is the acceptor and will be used when the shard cleaves.  If\nthe root shard range is in any other state then it will be ignored\nwhen the shard cleaves to other acceptors.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 5, 'created': '2021-01-28 18:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7509cbbd7a477a78051090b8891237a2f7437e91', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nTODO:\n- unit test cleaving ignores non-active root shard range\n- unit test shard audit with root shard range in shard db\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch modifies the root container behaviour to include its own\nshard range in responses to shard containers when the container GET\nrequest param 'states' has value 'auditing'. This parameter is used to\nindicate that a particular GET request is from the sharder during\nshard audit; the root does not otherwise include its own shard range\nin GET responses.\n\nThe shard only merges the root's shard range (and any other shard\nranges) when the shard is shrinking. If the root shard range is ACTIVE\nthen it is the acceptor and will be used when the shard cleaves.  If\nthe root shard range is in any other state then it will be ignored\nwhen the shard cleaves to other acceptors.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 6, 'created': '2021-01-29 19:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f6e3683e201cbd836d96ce427822bb5655efd0fc', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch modifies the root container behaviour to include its own\nshard range in responses to shard containers when the container GET\nrequest param 'states' has value 'auditing'. This parameter is used to\nindicate that a particular GET request is from the sharder during\nshard audit; the root does not otherwise include its own shard range\nin GET responses.\n\nThe shard only merges the root's shard range (and any other shard\nranges) when the shard is shrinking. If the root shard range is ACTIVE\nthen it is the acceptor and will be used when the shard cleaves.  If\nthe root shard range is in any other state then it will be ignored\nwhen the shard cleaves to other acceptors.\n\nThe sharder cleave loop is modified to break as soon as cleaving is\ndone i.e. cleaving has been completed up to the shard's upper bound.\nThis prevents misleading logging that cleaving has stopped when\nin fact cleaving to a non-root acceptor has completed but the shard\nrange list still contains an irrelevant root shard range in SHARDED\nstate. This also prevents cleaving to more than one acceptor in the\nunexpected case that multiple active acceptors overlap the shrinking\nshard - cleaving will now complete once the first acceptor has\ncleaved.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 7, 'created': '2021-02-04 14:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/79a9e7459f4d9bdf621e8f075134f395aed8706c', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch modifies the root container behaviour to include its own\nshard range in responses to shard containers when the container GET\nrequest param 'states' has value 'auditing'. This parameter is used to\nindicate that a particular GET request is from the sharder during\nshard audit; the root does not otherwise include its own shard range\nin GET responses.\n\nThe shard only merges the root's shard range (and any other shard\nranges) when the shard is shrinking. If the root shard range is ACTIVE\nthen it is the acceptor and will be used when the shard cleaves.  If\nthe root shard range is in any other state then it will be ignored\nwhen the shard cleaves to other acceptors.\n\nThe sharder cleave loop is modified to break as soon as cleaving is\ndone i.e. cleaving has been completed up to the shard's upper bound.\nThis prevents misleading logging that cleaving has stopped when\nin fact cleaving to a non-root acceptor has completed but the shard\nrange list still contains an irrelevant root shard range in SHARDED\nstate. This also prevents cleaving to more than one acceptor in the\nunexpected case that multiple active acceptors overlap the shrinking\nshard - cleaving will now complete once the first acceptor has\ncleaved.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}, {'number': 8, 'created': '2021-02-05 15:59:13.000000000', 'files': ['swift/container/server.py', 'test/unit/container/test_sharder.py', 'test/probe/test_sharder.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/sharder.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b0c8de699e43dffa4800564ea44a049ebab1a7ac', 'message': ""Enable shard ranges to be manually shrunk to root container\n\nShard containers learn about their own shard range by fetching shard\nranges from the root container during the sharder audit phase. Since\n[1], if the shard is shrinking, it may also learn about acceptor\nshards in the shard ranges fetched from the root.  However, the\nfetched shard ranges do not currently include the root's own shard\nrange, even when the root is to be the acceptor for a shrinking shard.\nThis prevents the mechanism being used to perform shrinking to root.\n\nThis patch modifies the root container behaviour to include its own\nshard range in responses to shard containers when the container GET\nrequest param 'states' has value 'auditing'. This parameter is used to\nindicate that a particular GET request is from the sharder during\nshard audit; the root does not otherwise include its own shard range\nin GET responses.\n\nWhen the 'states=auditing' parameter is used with a container GET\nrequest the response includes all shard ranges except those in the\nFOUND state. The shard ranges of relevance to a shard are its own\nshard range and any overlapping shard ranges that may be acceptors if\nthe shard is shrinking. None of these relevant shard ranges should be\nin state FOUND: the shard itself cannot be in FOUND state since it has\nbeen created; acceptor ranges should not be in FOUND state. The FOUND\nstate is therefore excluded from the 'auditing' states to prevent an\nunintended overlapping FOUND shard range that has not yet been\nresolved at the root container being fetched by a shrinking shard,\nwhich might then proceed to create and cleave to it.\n\nThe shard only merges the root's shard range (and any other shard\nranges) when the shard is shrinking. If the root shard range is ACTIVE\nthen it is the acceptor and will be used when the shard cleaves.  If\nthe root shard range is in any other state then it will be ignored\nwhen the shard cleaves to other acceptors.\n\nThe sharder cleave loop is modified to break as soon as cleaving is\ndone i.e. cleaving has been completed up to the shard's upper bound.\nThis prevents misleading logging that cleaving has stopped when\nin fact cleaving to a non-root acceptor has completed but the shard\nrange list still contains an irrelevant root shard range in SHARDED\nstate. This also prevents cleaving to more than one acceptor in the\nunexpected case that multiple active acceptors overlap the shrinking\nshard - cleaving will now complete once the first acceptor has\ncleaved.\n\n[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6\n\nChange-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5\n""}]",42,771885,b0c8de699e43dffa4800564ea44a049ebab1a7ac,47,5,8,7847,,,0,"Enable shard ranges to be manually shrunk to root container

Shard containers learn about their own shard range by fetching shard
ranges from the root container during the sharder audit phase. Since
[1], if the shard is shrinking, it may also learn about acceptor
shards in the shard ranges fetched from the root.  However, the
fetched shard ranges do not currently include the root's own shard
range, even when the root is to be the acceptor for a shrinking shard.
This prevents the mechanism being used to perform shrinking to root.

This patch modifies the root container behaviour to include its own
shard range in responses to shard containers when the container GET
request param 'states' has value 'auditing'. This parameter is used to
indicate that a particular GET request is from the sharder during
shard audit; the root does not otherwise include its own shard range
in GET responses.

When the 'states=auditing' parameter is used with a container GET
request the response includes all shard ranges except those in the
FOUND state. The shard ranges of relevance to a shard are its own
shard range and any overlapping shard ranges that may be acceptors if
the shard is shrinking. None of these relevant shard ranges should be
in state FOUND: the shard itself cannot be in FOUND state since it has
been created; acceptor ranges should not be in FOUND state. The FOUND
state is therefore excluded from the 'auditing' states to prevent an
unintended overlapping FOUND shard range that has not yet been
resolved at the root container being fetched by a shrinking shard,
which might then proceed to create and cleave to it.

The shard only merges the root's shard range (and any other shard
ranges) when the shard is shrinking. If the root shard range is ACTIVE
then it is the acceptor and will be used when the shard cleaves.  If
the root shard range is in any other state then it will be ignored
when the shard cleaves to other acceptors.

The sharder cleave loop is modified to break as soon as cleaving is
done i.e. cleaving has been completed up to the shard's upper bound.
This prevents misleading logging that cleaving has stopped when
in fact cleaving to a non-root acceptor has completed but the shard
range list still contains an irrelevant root shard range in SHARDED
state. This also prevents cleaving to more than one acceptor in the
unexpected case that multiple active acceptors overlap the shrinking
shard - cleaving will now complete once the first acceptor has
cleaved.

[1] Related-Change: I9034a5715406b310c7282f1bec9625fe7acd57b6

Change-Id: I5d48b67217f705ac30bb427ef8d969a90eaad2e5
",git fetch https://review.opendev.org/openstack/swift refs/changes/85/771885/6 && git format-patch -1 --stdout FETCH_HEAD,"['swift/container/server.py', 'test/unit/container/test_sharder.py', 'test/probe/test_sharder.py', 'test/unit/container/test_server.py', 'swift/container/sharder.py', 'test/unit/container/test_backend.py', 'swift/common/request_helpers.py', 'swift/container/backend.py']",8,2711a92643cbd37af871a60e827d6228b267e9c4,p-shard-compact," exclude_others=False, fill_gaps=False, include_own_acceptor=False): :param include_own_acceptor: if True then the returned list will include the row whose name matches the broker's path if and only if all other shard ranges are deleted or in SHRINKING state. if (include_own_acceptor and not include_own and all(((sr.state == ShardRange.SHRINKING or sr.deleted) for sr in shard_ranges))): # special case to facilitate shrinking of shard ranges to root: # all shard ranges are either shrinking or deleted so include own # shard range as the default acceptor; note that we deliberately # test that all shard ranges in the list are shrinking *before* # applying 'marker', 'end_marker' and 'includes' filtering, because # the root should only become acceptor when *all* remaining shards # are shrinking. own_acceptor = self._own_shard_range() own_acceptor.update_state(ShardRange.ACTIVE, state_timestamp=Timestamp.now()) shard_ranges.append(own_acceptor) self.logger.debug( 'Container %s including own shard range as acceptor' % self.path) shard_ranges.sort(key=ShardRange.sort_key)"," exclude_others=False, fill_gaps=False): shard_ranges.sort(key=ShardRange.sort_key) ",267,26
openstack%2Fironic-python-agent-builder~master~Ic24cd265db05acd23675a453632d4488fa83507c,openstack/ironic-python-agent-builder,master,Ic24cd265db05acd23675a453632d4488fa83507c,Update version of tgt to 1.0.80,MERGED,2021-02-02 08:31:15.000000000,2021-02-08 02:39:48.000000000,2021-02-08 02:38:39.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 08:31:15.000000000', 'files': ['tinyipa/build-tinyipa.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/1bb81e130daa830d1a66e6871814e416eae78b94', 'message': 'Update version of tgt to 1.0.80\n\nChange-Id: Ic24cd265db05acd23675a453632d4488fa83507c\n'}]",0,773604,1bb81e130daa830d1a66e6871814e416eae78b94,8,3,1,23851,,,0,"Update version of tgt to 1.0.80

Change-Id: Ic24cd265db05acd23675a453632d4488fa83507c
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/04/773604/1 && git format-patch -1 --stdout FETCH_HEAD,['tinyipa/build-tinyipa.sh'],1,1bb81e130daa830d1a66e6871814e416eae78b94,update-tgt-version,"TGT_RELEASE=""v1.0.80""","TGT_RELEASE=""v1.0.79""",1,1
openstack%2Ffreezer~master~Ia39021e543fea24f686caeacd8dcef964c80f431,openstack/freezer,master,Ia39021e543fea24f686caeacd8dcef964c80f431,add test_job_start_session unit test cases,MERGED,2021-02-08 01:30:58.000000000,2021-02-08 02:29:18.000000000,2021-02-08 02:28:01.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 01:30:58.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/9773f99febb853ca9fc44756428ce1874ffdf0f5', 'message': 'add test_job_start_session unit test cases\n\nChange-Id: Ia39021e543fea24f686caeacd8dcef964c80f431\n'}]",0,774387,9773f99febb853ca9fc44756428ce1874ffdf0f5,7,2,1,21387,,,0,"add test_job_start_session unit test cases

Change-Id: Ia39021e543fea24f686caeacd8dcef964c80f431
",git fetch https://review.opendev.org/openstack/freezer refs/changes/87/774387/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,9773f99febb853ca9fc44756428ce1874ffdf0f5,," def test_job_finish(self): scheduler = mock.MagicMock() freezer_action = {""backup_name"": ""freezer"", 'action': 'exec', ""remove_from_date"": ""2020-11-10T10:10:10""} jobdoc = {'job_id': 'test', 'job_schedule': {""event"": ""remove""}, 'job_actions': [{'freezer_action': freezer_action, 'max_retries_interval': 1, 'max_retries': 1}]} job = scheduler_job.Job(scheduler, None, jobdoc) result = job.finish() self.assertIsNone(result) self.assertEqual(job.job_doc_status, 'removed') scheduler.is_scheduled.return_value = False jobdoc = {'job_id': 'test', 'job_schedule': {""event"": ""start""}, 'job_actions': [{'freezer_action': freezer_action, 'max_retries_interval': 1, 'max_retries': 1}]} job = scheduler_job.Job(scheduler, None, jobdoc) result = job.finish() self.assertIsNone(result) self.assertEqual(job.job_doc_status, 'completed') scheduler.is_scheduled.return_value = True jobdoc = {'job_id': 'test', 'job_schedule': {""event"": ""stop""}, 'job_actions': [{'freezer_action': freezer_action, 'max_retries_interval': 1, 'max_retries': 1}]} job = scheduler_job.Job(scheduler, None, jobdoc) result = job.finish() self.assertIsNone(result) self.assertEqual(job.job_doc_status, 'completed') def test_job_start_session(self): scheduler = mock.MagicMock() scheduler.start_session.side_effect = [Exception('error'), {'result': 'success', 'session_tag': 1024}] job = scheduler_job.Job(scheduler, None, self.jobdoc) job.session_id = 'test' result = job.start_session() self.assertIsNone(result) self.assertEqual(job.session_tag, 1024) scheduler.start_session.side_effect = [Exception('error'), Exception('error'), Exception('error'), Exception('error'), Exception('error')] job = scheduler_job.Job(scheduler, None, self.jobdoc) job.session_id = 'test' result = job.start_session() self.assertIsNone(result) self.assertEqual(job.session_tag, 1024) def test_job_end_session(self): scheduler = mock.MagicMock() scheduler.end_session.side_effect = [Exception('error'), {'result': 'success'}] job = scheduler_job.Job(scheduler, None, self.jobdoc) job.session_id = 'test' result = job.end_session('test') self.assertIsNone(result) self.assertEqual(job.session_tag, 0) scheduler.end_session.side_effect = [Exception('error'), Exception('error'), Exception('error'), Exception('error'), Exception('error')] job = scheduler_job.Job(scheduler, None, self.jobdoc) job.session_id = 'test' result = job.end_session('test') self.assertIsNone(result) self.assertEqual(job.session_tag, 0) def test_job_schedule(self): scheduler = mock.MagicMock() scheduler.is_scheduled.return_value = False scheduler.add_job.side_effect = Exception('error') job = scheduler_job.Job(scheduler, None, self.jobdoc) result = job.schedule() self.assertIsNone(result) self.assertEqual(job.job_doc_status, 'completed') def test_job_unschedule(self): scheduler = mock.MagicMock() scheduler.remove_job.side_effect = Exception('error') job = scheduler_job.Job(scheduler, None, self.jobdoc) result = job.unschedule() self.assertIsNone(result) def test_job_terminate_kill(self): process = mock.MagicMock() self.job.process = process self.assertIsNone(self.job.terminate()) self.assertIsNone(self.job.kill())",,99,0
openstack%2Fironic-python-agent~master~I8e2cac5172f009d5204f83bd83e1f27cfd721f09,openstack/ironic-python-agent,master,I8e2cac5172f009d5204f83bd83e1f27cfd721f09,Use variable for lsblk columns device info,MERGED,2021-02-03 11:02:11.000000000,2021-02-08 02:26:19.000000000,2021-02-08 02:25:10.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 21909}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 11:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0db9bea9b75aa9379a6a3eea462cc4da99ba8e75', 'message': '[WIP] Use variable for lsblk columns device info\n\nChange-Id: I8e2cac5172f009d5204f83bd83e1f27cfd721f09\n'}, {'number': 2, 'created': '2021-02-03 14:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b973195e70b03dec973edb6a4cc036107de4c7ec', 'message': 'Use variable for lsblk columns device info\n\nAdjusted unit tests accordingly.\n\nAlso removed redundant parenthesis.\n\nChange-Id: I8e2cac5172f009d5204f83bd83e1f27cfd721f09\n'}, {'number': 3, 'created': '2021-02-03 14:31:45.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fc1f2c73c665222d4a9ff32a763d4588978d9987', 'message': 'Use variable for lsblk columns device info\n\nAdjusted unit tests accordingly.\n\nAlso removed redundant parenthesis.\n\nChange-Id: I8e2cac5172f009d5204f83bd83e1f27cfd721f09\n'}]",0,773871,fc1f2c73c665222d4a9ff32a763d4588978d9987,12,4,3,23851,,,0,"Use variable for lsblk columns device info

Adjusted unit tests accordingly.

Also removed redundant parenthesis.

Change-Id: I8e2cac5172f009d5204f83bd83e1f27cfd721f09
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/71/773871/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/hardware.py'],1,0db9bea9b75aa9379a6a3eea462cc4da99ba8e75,lsblk-columns, columns = utils.LSBLK_COLUMNS," columns = ['KNAME', 'MODEL', 'SIZE', 'ROTA', 'TYPE', 'UUID']",1,1
openstack%2Fmurano~master~Ib42e368cfda2b148a07df0bd74046739f40f7018,openstack/murano,master,Ib42e368cfda2b148a07df0bd74046739f40f7018,Use common rpc pattern for all services,MERGED,2021-01-19 05:05:43.000000000,2021-02-08 01:36:34.000000000,2021-02-08 01:35:08.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-19 05:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/fc46a67200c5bcc668f7219cfdd75bf21b7895eb', 'message': '[WIP] Use common rpc pattern for all services\n\nChange-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018\n'}, {'number': 2, 'created': '2021-01-19 08:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/661cbf45d8b279cafa54d28039970e897b7e4f28', 'message': 'Use common rpc pattern for all services\n\nThis patch introduces a common rpc pattern to ensure\nthat the rpc transport is shared where possible. This\nhelps prevent rpc connection leaks and should ensure\nthat we are making the best possible use of all\navailable rpc connections.\n\nChange-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018\n'}, {'number': 3, 'created': '2021-01-19 08:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a7ee4dfd31109715bbd863a4fd8655f9e80ea823', 'message': 'Use common rpc pattern for all services\n\nThis patch introduces a common rpc pattern to ensure\nthat the rpc transport is shared where possible. This\nhelps prevent rpc connection leaks and should ensure\nthat we are making the best possible use of all\navailable rpc connections.\n\nChange-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018\n'}, {'number': 4, 'created': '2021-01-19 09:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7c3fecaad71d0fe32dabe8d4992c16feb543618f', 'message': 'Use common rpc pattern for all services\n\nThis patch introduces a common rpc pattern to ensure\nthat the rpc transport is shared where possible. This\nhelps prevent rpc connection leaks and should ensure\nthat we are making the best possible use of all\navailable rpc connections.\n\nChange-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018\n'}, {'number': 5, 'created': '2021-01-19 20:24:21.000000000', 'files': ['murano/tests/unit/common/test_engine.py', 'murano/common/rpc.py', 'murano/common/engine.py', 'murano/engine/system/status_reporter.py', 'murano/tests/unit/common/test_server.py', 'murano/engine/system/instance_reporter.py', 'murano/common/server.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/e5d9d1b74fec1bcf0d93361670a1ffcc22d2bdaa', 'message': 'Use common rpc pattern for all services\n\nThis patch introduces a common rpc pattern to ensure\nthat the rpc transport is shared where possible. This\nhelps prevent rpc connection leaks and should ensure\nthat we are making the best possible use of all\navailable rpc connections.\n\nChange-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018\n'}]",2,771341,e5d9d1b74fec1bcf0d93361670a1ffcc22d2bdaa,15,2,5,22623,,,0,"Use common rpc pattern for all services

This patch introduces a common rpc pattern to ensure
that the rpc transport is shared where possible. This
helps prevent rpc connection leaks and should ensure
that we are making the best possible use of all
available rpc connections.

Change-Id: Ib42e368cfda2b148a07df0bd74046739f40f7018
",git fetch https://review.opendev.org/openstack/murano refs/changes/41/771341/3 && git format-patch -1 --stdout FETCH_HEAD,"['murano/common/rpc.py', 'murano/tests/unit/base.py', 'murano/tests/unit/common/test_engine.py', 'murano/common/engine.py', 'murano/engine/system/status_reporter.py', 'murano/tests/unit/common/test_server.py', 'murano/engine/system/instance_reporter.py', 'murano/common/server.py']",8,fc46a67200c5bcc668f7219cfdd75bf21b7895eb,reuse,"from murano.common import rpc listener = rpc.get_notification_listener( [s_target], endpoints, executor='threading' ) server = rpc.get_server(s_target, endpoints, executor='threading') self.server = rpc.get_notification_listener( [s_target], endpoints, executor='eventlet' ) self.server = rpc.get_server( s_target, endpoints, executor='eventlet' )","import oslo_messaging as messaging from oslo_messaging.rpc import dispatcher transport = messaging.get_notification_transport(CONF) listener = messaging.get_notification_listener( transport, [s_target], endpoints, executor='threading') transport = messaging.get_rpc_transport(CONF) access_policy = dispatcher.DefaultRPCAccessPolicy server = messaging.get_rpc_server( transport, s_target, endpoints, 'threading', access_policy=access_policy) transport = messaging.get_notification_transport(CONF) self.server = messaging.get_notification_listener( transport, [s_target], endpoints, executor='eventlet') transport = messaging.get_rpc_transport(CONF) access_policy = dispatcher.DefaultRPCAccessPolicy self.server = messaging.get_rpc_server( transport, s_target, endpoints, 'eventlet', access_policy=access_policy)",96,68
openstack%2Fsolum~master~Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1,openstack/solum,master,Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1,Re-use rpc transport,MERGED,2021-01-16 21:23:50.000000000,2021-02-08 01:29:39.000000000,2021-02-08 01:28:17.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-16 21:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7a5121ec2532b4a19c069770034aa70973bdb7e4', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 2, 'created': '2021-01-16 21:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/917288c859426116400b9765d0519930d5036f11', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 3, 'created': '2021-01-16 21:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4d9bdc64c244de0f58bc467b0d24393cdd807d0c', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 4, 'created': '2021-01-16 23:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0c35b5b1fec804ca93c44895b952b3890addf4f9', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 5, 'created': '2021-01-16 23:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/aacd1b11d5407e6af8080a2f6434b38ca1e9e7ec', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 6, 'created': '2021-01-16 23:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0591e7d5c6e33ad1c626c5773760b81bbeef864b', 'message': 'Re-use rpc transport\n\nBlazar is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}, {'number': 7, 'created': '2021-01-19 08:37:02.000000000', 'files': ['solum/deployer/api.py', 'solum/worker/api.py', 'solum/common/rpc/service.py', 'solum/conductor/api.py', 'solum/rpc.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/956079ed2511b6f3317d03837a3f919139307acb', 'message': 'Re-use rpc transport\n\nSolum is currently not re-using the rpc transport, this\nwill cause connections to leak. This patch introduces\na commonly shared rpc pattern for openstack services\nthat ensures that the transport is always re-used.\n\nChange-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1\n'}]",0,771111,956079ed2511b6f3317d03837a3f919139307acb,16,2,7,22623,,,0,"Re-use rpc transport

Solum is currently not re-using the rpc transport, this
will cause connections to leak. This patch introduces
a commonly shared rpc pattern for openstack services
that ensures that the transport is always re-used.

Change-Id: Ibdfb4fa4711b10f66ae4c01b2a10b850d0c42ca1
",git fetch https://review.opendev.org/openstack/solum refs/changes/11/771111/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/deployer/api.py', 'solum/worker/api.py', 'solum/common/rpc/service.py', 'solum/conductor/api.py', 'solum/rpc.py']",5,7a5121ec2532b4a19c069770034aa70973bdb7e4,reuse,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_config import cfg import oslo_messaging as messaging from oslo_messaging.rpc import dispatcher CONF = cfg.CONF TRANSPORT = None def init(): global TRANSPORT if TRANSPORT is None: TRANSPORT = create_transport(get_transport_url()) def get_transport_url(url_str=None): return messaging.TransportURL.parse(CONF, url_str) def get_client(target, serializer): if TRANSPORT is None: raise AssertionError(""'TRANSPORT' must not be None"") return messaging.RPCClient( TRANSPORT, target, serializer=serializer, ) def get_server(target, endpoints, serializer): if TRANSPORT is None: raise AssertionError(""'TRANSPORT' must not be None"") access_policy = dispatcher.DefaultRPCAccessPolicy return messaging.get_rpc_server( TRANSPORT, target, endpoints, executor='threading', serializer=serializer, access_policy=access_policy, ) def create_transport(url): return messaging.get_rpc_transport(CONF, url=url) ",,67,19
openstack%2Ffreezer~master~Icf6a719bc71d1a478d0a232e65d01a3b6617e7e6,openstack/freezer,master,Icf6a719bc71d1a478d0a232e65d01a3b6617e7e6,add test_job_execute unit test cases,MERGED,2021-02-08 00:10:11.000000000,2021-02-08 01:23:10.000000000,2021-02-08 01:21:59.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-08 00:10:11.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/71f04ce289871e69fcaa4c69ab9b7de17bd9faf9', 'message': 'add test_job_execute unit test cases\n\nChange-Id: Icf6a719bc71d1a478d0a232e65d01a3b6617e7e6\n'}]",0,774385,71f04ce289871e69fcaa4c69ab9b7de17bd9faf9,7,2,1,21387,,,0,"add test_job_execute unit test cases

Change-Id: Icf6a719bc71d1a478d0a232e65d01a3b6617e7e6
",git fetch https://review.opendev.org/openstack/freezer refs/changes/85/774385/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,71f04ce289871e69fcaa4c69ab9b7de17bd9faf9,,"from oslo_config import cfgCONF = cfg.CONF def test_job_contains_exec(self): jobdoc = {'job_actions': [{'freezer_action': {'action': 'exec'}}]} job = scheduler_job.Job(None, None, jobdoc) result = job.contains_exec() self.assertTrue(result) jobdoc = {'job_actions': [{'freezer_action': {'action': 'stop'}}]} job = scheduler_job.Job(None, None, jobdoc) result = job.contains_exec() self.assertFalse(result) def test_job_update_job_schedule_doc(self): jobdoc = {'job_actions': [{'freezer_action': {'action': 'exec'}}]} self.job.update_job_schedule_doc(**jobdoc) self.assertEqual(self.job.job_doc['job_schedule']['job_actions'], [{'freezer_action': {'action': 'exec'}}]) @mock.patch('subprocess.Popen') def test_job_execute(self, mock_process): CONF.disable_exec = True scheduler = mock.MagicMock() freezer_action = {""backup_name"": ""freezer"", 'action': 'exec', ""remove_from_date"": ""2020-11-10T10:10:10""} jobdoc = {'job_id': 'test', 'job_schedule': {}, 'job_actions': [{'freezer_action': freezer_action, 'max_retries_interval': 1, 'max_retries': 1}]} job = scheduler_job.Job(scheduler, None, jobdoc) result = job.execute() self.assertIsNone(result) self.assertEqual(job.result, 'fail') CONF.disable_exec = False process = mock.MagicMock() process.pid = 123 process.communicate.return_value = (b'test', 0) process.returncode = -15 mock_process.return_value = process result = job.execute() self.assertIsNone(result) self.assertEqual(job.result, 'aborted') process.communicate.return_value = ('test', 'test') process.returncode = 1 mock_process.return_value = process result = job.execute() self.assertIsNone(result) self.assertEqual(job.result, 'fail')",,53,0
openstack%2Fsolum-dashboard~master~I58231c2cd2f11d9002961f3105a989c37a58bc75,openstack/solum-dashboard,master,I58231c2cd2f11d9002961f3105a989c37a58bc75,Add doc/requirements,MERGED,2021-01-07 16:05:36.000000000,2021-02-08 00:53:30.000000000,2021-02-08 00:53:30.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-07 16:05:36.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/8a7461367ba520cffbe3ff4e9b21e6538f32c4ea', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoving specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I58231c2cd2f11d9002961f3105a989c37a58bc75\n""}]",0,769782,8a7461367ba520cffbe3ff4e9b21e6538f32c4ea,10,2,1,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removing specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I58231c2cd2f11d9002961f3105a989c37a58bc75
",git fetch https://review.opendev.org/openstack/solum-dashboard refs/changes/82/769782/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,8a7461367ba520cffbe3ff4e9b21e6538f32c4ea,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,,4,3
openstack%2Fnova~master~Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38,openstack/nova,master,Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38,db: Compact Ocata database migrations,MERGED,2020-10-21 15:52:33.000000000,2021-02-08 00:34:00.000000000,2021-02-08 00:31:55.000000000,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-10-21 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3950624c44275e321015eedca022f64ecc9420bf', 'message': ""db: Compact Ocata database migrations\n\nCompact Ocata database migrations into a single migration,\n'347_ocata.py'.\n\nUsers will now need to update to Ocata before updating to Pike or later.\n\nSpecific changes include:\n\n- Drop 'scheduled_at' column from 'instances' table\n- Add indexes on 'instances' table covering the 'project_id' column,\n  and the 'updated_at' and 'project_id' columns\n\nChange-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-10-22 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3df30c8c51a880527b3c608e42a103d5c0474d50', 'message': ""db: Compact Ocata database migrations\n\nCompact Ocata database migrations into a single migration,\n'347_ocata.py'.\n\nUsers will now need to update to Ocata before updating to Pike or later.\n\nSpecific changes include:\n\n- Drop 'scheduled_at' column from 'instances' table\n- Add indexes on 'instances' table covering the 'project_id' column,\n  and the 'updated_at' and 'project_id' columns\n\nChange-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-10-23 10:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/792d9e87b5abd641e8733d4fd5057b33cc93e40a', 'message': ""db: Compact Ocata database migrations\n\nCompact Ocata database migrations into a single migration,\n'347_ocata.py'.\n\nUsers will now need to update to Ocata before updating to Pike or later.\n\nSpecific changes include:\n\n- Drop 'scheduled_at' column from 'instances' table\n- Add indexes on 'instances' table covering the 'project_id' column,\n  and the 'updated_at' and 'project_id' columns\n\nChange-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-10-28 11:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93742d81e80adc34eb966728b1894491f3bcd5f6', 'message': ""db: Compact Ocata database migrations\n\nCompact Ocata database migrations into a single migration,\n'347_ocata.py'.\n\nUsers will now need to update to Ocata before updating to Pike or later.\n\nSpecific changes include:\n\n- Drop 'scheduled_at' column from 'instances' table\n- Add indexes on 'instances' table covering the 'project_id' column,\n  and the 'updated_at' and 'project_id' columns\n\nChange-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2021-01-07 11:47:59.000000000', 'files': ['nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/339_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/337_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/347_ocata.py', 'nova/db/sqlalchemy/migrate_repo/versions/341_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/343_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/338_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/336_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/335_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/342_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/345_require_online_migration_completion.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/340_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/346_remove_scheduled_at_column.py', 'nova/db/sqlalchemy/migrate_repo/versions/344_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/347_add_updated_at_index.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/eb5a1e4d721a2c2dc01932b87ecb88db9e37013c', 'message': ""db: Compact Ocata database migrations\n\nCompact Ocata database migrations into a single migration,\n'347_ocata.py'.\n\nUsers will now need to update to Ocata before updating to Pike or later.\n\nSpecific changes include:\n\n- Drop 'scheduled_at' column from 'instances' table\n- Add indexes on 'instances' table covering the 'project_id' column,\n  and the 'updated_at' and 'project_id' columns\n\nChange-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,759086,eb5a1e4d721a2c2dc01932b87ecb88db9e37013c,82,13,5,15334,,,0,"db: Compact Ocata database migrations

Compact Ocata database migrations into a single migration,
'347_ocata.py'.

Users will now need to update to Ocata before updating to Pike or later.

Specific changes include:

- Drop 'scheduled_at' column from 'instances' table
- Add indexes on 'instances' table covering the 'project_id' column,
  and the 'updated_at' and 'project_id' columns

Change-Id: Ia9fa4b206b247ff2f52e107b2e31b20a21a58f38
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/759086/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/339_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/337_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/347_ocata.py', 'nova/db/sqlalchemy/migrate_repo/versions/341_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/343_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/338_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/336_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/335_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/342_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/345_require_online_migration_completion.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/340_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/346_remove_scheduled_at_column.py', 'nova/db/sqlalchemy/migrate_repo/versions/344_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/347_add_updated_at_index.py']",17,3950624c44275e321015eedca022f64ecc9420bf,bp/compact-db-migrations-wallaby,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from sqlalchemy import MetaData, Table, Index from sqlalchemy.engine import reflection LOG = logging.getLogger(__name__) INDEX_COLUMNS_1 = ['project_id'] INDEX_NAME_1 = 'instances_project_id_idx' INDEX_COLUMNS_2 = ['updated_at', 'project_id'] INDEX_NAME_2 = 'instances_updated_at_project_id_idx' TABLE_NAME = 'instances' def _get_table_index(migrate_engine, table_name, index_columns): inspector = reflection.Inspector.from_engine(migrate_engine) for idx in inspector.get_indexes(table_name): if idx['column_names'] == index_columns: break else: idx = None return idx def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine table = Table(TABLE_NAME, meta, autoload=True) if _get_table_index(migrate_engine, TABLE_NAME, INDEX_COLUMNS_1): LOG.info('Skipped adding %s because an equivalent index' ' already exists.', INDEX_NAME_1) else: columns = [getattr(table.c, col_name) for col_name in INDEX_COLUMNS_1] index = Index(INDEX_NAME_1, *columns) index.create(migrate_engine) if _get_table_index(migrate_engine, TABLE_NAME, INDEX_COLUMNS_2): LOG.info('Skipped adding %s because an equivalent index' ' already exists.', INDEX_NAME_2) else: columns = [getattr(table.c, col_name) for col_name in INDEX_COLUMNS_2] index = Index(INDEX_NAME_2, *columns) index.create(migrate_engine) ",4,483
openstack%2Fopenstack-ansible~master~I0a99b37281fed49a10a5f1482e573ab5cac7bb89,openstack/openstack-ansible,master,I0a99b37281fed49a10a5f1482e573ab5cac7bb89,Add barbican-ui repo package and zuul repo,MERGED,2021-02-04 08:57:41.000000000,2021-02-07 23:52:46.000000000,2021-02-07 23:47:18.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 08:57:41.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ea1e97941aa9197773d0ee4b92d8815e09a75389', 'message': 'Add barbican-ui repo package and zuul repo\n\nAdd these so we can enable the barbican panels in horizon\n\nChange-Id: I0a99b37281fed49a10a5f1482e573ab5cac7bb89\n'}]",0,774053,ea1e97941aa9197773d0ee4b92d8815e09a75389,18,3,1,25023,,,0,"Add barbican-ui repo package and zuul repo

Add these so we can enable the barbican panels in horizon

Change-Id: I0a99b37281fed49a10a5f1482e573ab5cac7bb89
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/53/774053/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'zuul.d/jobs.yaml']",2,ea1e97941aa9197773d0ee4b92d8815e09a75389,, - name: openstack/barbican-ui,,7,0
openstack%2Fkayobe~stable%2Fussuri~Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,openstack/kayobe,stable/ussuri,Ibe42fa372c6fa0c539d2c2b0e238601286dc213d,Fix --limit with commas,MERGED,2021-01-15 16:59:38.000000000,2021-02-07 17:23:08.000000000,2021-02-07 17:21:43.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 23871}]","[{'number': 1, 'created': '2021-01-15 16:59:38.000000000', 'files': ['kayobe/kolla_ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/ansible.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/783d0f2e3626bab169d6f2268b0bc1e97514dbed', 'message': 'Fix --limit with commas\n\nKayobe allows specifying a --limit argument, which is passed through to\nAnsible. In some cases we wish to add an intersection with a group. This\nallows us to reuse playbooks for the seed, overcloud etc.\n\nFor example, the lvm.yml playbook specifies a host list of\nseed-hypervisor:seed:overcloud. When executed as part of a kayobe\novercloud host configure command, Kayobe passes a limit of overcloud. If\nthe user specifies a --limit argument, this gets intersected with the\novercloud limit: host1:&overcloud.\n\nThe problem happens if the user specifies multiple parts to the host\npattern in their limit using a comma, e.g. host1,host2. This results in\nhost1,host2:&overcloud. Ansible ignores the colon, and treats this as\nhost1 or host2:&overcloud.\n\nThe solution is to use a comma to join the patterns if the user has used\na comma: host1,host2,&overcloud\n\nChange-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d\nStory: 2008255\nTask: 41111\n(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)\n'}]",0,770959,783d0f2e3626bab169d6f2268b0bc1e97514dbed,13,4,1,14826,,,0,"Fix --limit with commas

Kayobe allows specifying a --limit argument, which is passed through to
Ansible. In some cases we wish to add an intersection with a group. This
allows us to reuse playbooks for the seed, overcloud etc.

For example, the lvm.yml playbook specifies a host list of
seed-hypervisor:seed:overcloud. When executed as part of a kayobe
overcloud host configure command, Kayobe passes a limit of overcloud. If
the user specifies a --limit argument, this gets intersected with the
overcloud limit: host1:&overcloud.

The problem happens if the user specifies multiple parts to the host
pattern in their limit using a comma, e.g. host1,host2. This results in
host1,host2:&overcloud. Ansible ignores the colon, and treats this as
host1 or host2:&overcloud.

The solution is to use a comma to join the patterns if the user has used
a comma: host1,host2,&overcloud

Change-Id: Ibe42fa372c6fa0c539d2c2b0e238601286dc213d
Story: 2008255
Task: 41111
(cherry picked from commit 017b092df70706177c542c3a3cab3f9d0a75e5c2)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/59/770959/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/kolla_ansible.py', 'kayobe/ansible.py', 'kayobe/tests/unit/test_utils.py', 'kayobe/utils.py', 'releasenotes/notes/fix-limit-with-commas-04a357b0b7ef0371.yaml']",5,783d0f2e3626bab169d6f2268b0bc1e97514dbed,,--- fixes: - | Fixes an issue when using the ``--limit`` argument with a host pattern including commas. See `story 2008255 <https://storyboard.openstack.org/#!/story/2008255>`__ for details. ,,74,4
openstack%2Fopenstack-ansible~master~I151a6635c4db76a597d0412eee9d039eb4383ddb,openstack/openstack-ansible,master,I151a6635c4db76a597d0412eee9d039eb4383ddb,Add a note about stale env.d files,ABANDONED,2018-12-12 11:22:23.000000000,2021-02-07 15:15:29.000000000,,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-12 11:22:23.000000000', 'files': ['doc/source/admin/upgrades/major-upgrades.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca67b323384c168b8f89bfefa2928396499a9836', 'message': 'Add a note about stale env.d files\n\nbackport: rocky queens\n\nChange-Id: I151a6635c4db76a597d0412eee9d039eb4383ddb\nCloses-Bug: #1808041\n'}]",0,624667,ca67b323384c168b8f89bfefa2928396499a9836,4,2,1,16523,,,0,"Add a note about stale env.d files

backport: rocky queens

Change-Id: I151a6635c4db76a597d0412eee9d039eb4383ddb
Closes-Bug: #1808041
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/67/624667/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/upgrades/major-upgrades.rst'],1,ca67b323384c168b8f89bfefa2928396499a9836,bug/1808041, .. note:: Merge any changes from ``/opt/openstack-ansible/inventory/env.d`` into ``/etc/openstack_deploy/env.d`` before upgrading. ,,6,0
openstack%2Fopenstack-ansible-os_masakari~master~I320abfca4946ccd5683722890dfdd054e56d9f49,openstack/openstack-ansible-os_masakari,master,I320abfca4946ccd5683722890dfdd054e56d9f49,Add doc for installing masakari role,ABANDONED,2018-06-05 06:41:48.000000000,2021-02-07 15:13:48.000000000,,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-05 06:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/27bc36a59febc6744be0c3465caa6dcfec84dd4f', 'message': 'Add doc for installing masakari role\n\nThis change adds an installation guide for the masakari role.\n\nChange-Id: I320abfca4946ccd5683722890dfdd054e56d9f49\n'}, {'number': 2, 'created': '2018-09-09 11:47:23.000000000', 'files': ['doc/source/index.rst', 'doc/source/configure-masakari.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/fd5e620f2096bb513517549ebc394fb00b1d6603', 'message': 'Add doc for installing masakari role\n\nThis change adds an installation guide for the masakari role.\n\nChange-Id: I320abfca4946ccd5683722890dfdd054e56d9f49\n'}]",2,572264,fd5e620f2096bb513517549ebc394fb00b1d6603,7,2,2,26463,,,0,"Add doc for installing masakari role

This change adds an installation guide for the masakari role.

Change-Id: I320abfca4946ccd5683722890dfdd054e56d9f49
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/64/572264/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'README.rst', 'doc/source/configure-masakari.rst']",3,27bc36a59febc6744be0c3465caa6dcfec84dd4f,masakari-documentation,"=============================================================== Configuring the high availability (masakari) service (optional) =============================================================== .. note:: This feature is experimental at this time and it has not been fully production tested yet. Masakari provides a Virtual Machines High Availability(VMHA), and rescues a KVM-based Virtual Machines(VM) from a failure events of the following: * VM process down - restart vm (use nova stop API, and nova start API). Libvirt events will be also emitted by other failures. * Provisioning process down - restarts process, changes nova-compute service status to maintenance mode (use nova service-disable). * nova-compute host failure - evacuate all the VMs from failure host to reserved host (use nova evacuate API). Masakari is configured using the ``/etc/openstack_deploy/conf.d/masakari.yml`` file Configuring target hosts ~~~~~~~~~~~~~~~~~~~~~~~~ Modify ``/etc/openstack_deploy/conf.d/masakari.yml`` by adding a list containing the infrastructure target hosts in the masakari_hosts section: In ``masakari.yml``: .. code-block:: yaml masakari_hosts: infra01: ip: INFRA01_IP_ADDRESS Replace ``*_IP_ADDRESS`` with the IP address of the br-mgmt container management bridge on each target host. This hosts will be used to deploy the containers where masakari will be installed. Setting up Masakari ~~~~~~~~~~~~~~~~~~~ Run the setup-hosts playbook, to create the masakari containers, and the repo-build playbook to update the repository with the masakari packages. .. code-block:: console # cd /opt/openstack-ansible/playbooks # openstack-ansible setup-hosts.yml # openstack-ansible repo-build.yml Run the masakari playbook to install masakari: .. code-block:: console # cd /opt/openstack-ansible/playbooks # openstack-ansible os-masakari-install.yml",<TODO> ,108,18
openstack%2Fopenstack-ansible~master~I1d6d1edb4f2968438de6add6846ebf88b1664c4b,openstack/openstack-ansible,master,I1d6d1edb4f2968438de6add6846ebf88b1664c4b,fix inventory path,ABANDONED,2018-02-14 16:25:00.000000000,2021-02-07 15:11:33.000000000,,"[{'_account_id': 10068}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 24468}]","[{'number': 1, 'created': '2018-02-14 16:25:00.000000000', 'files': ['doc/source/admin/maintenance-tasks/scale-environment.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d448076536fc423d41279d3ffbac54f65d6d3d66', 'message': 'fix inventory path\n\nChange-Id: I1d6d1edb4f2968438de6add6846ebf88b1664c4b\n'}]",1,544523,d448076536fc423d41279d3ffbac54f65d6d3d66,7,4,1,20494,,,0,"fix inventory path

Change-Id: I1d6d1edb4f2968438de6add6846ebf88b1664c4b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/23/544523/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/maintenance-tasks/scale-environment.rst'],1,d448076536fc423d41279d3ffbac54f65d6d3d66,fix_inventories_path, # /opt/openstack-ansible/playbooks/inventory/dynamic_inventory.py > /dev/null, # /opt/openstack-ansible/inventory/dynamic_inventory.py > /dev/null,1,1
openstack%2Fopenstack-ansible-tests~master~Ifca0af018c074fe0371a5fe0f15106bea817299d,openstack/openstack-ansible-tests,master,Ifca0af018c074fe0371a5fe0f15106bea817299d,Cope with disappearing files when compressing,ABANDONED,2017-12-19 16:37:28.000000000,2021-02-07 15:10:21.000000000,,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-12-19 16:37:28.000000000', 'files': ['test-log-collect.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/9092c1f5fe0cc5f28e646be7257e30d8b28c828d', 'message': 'Cope with disappearing files when compressing\n\nGzip fails if a file is not present. So instead of zipping every file\nwith a single invocation of gzip, we zip them with an invocation per\nfile. That way if a file is removed after the file list is generated,\nonly one invocation of gzip will fail and the rest of the files will be\nsuccessfully compressed.\n\nChange-Id: Ifca0af018c074fe0371a5fe0f15106bea817299d\n'}]",3,529109,9092c1f5fe0cc5f28e646be7257e30d8b28c828d,6,3,1,7217,,,0,"Cope with disappearing files when compressing

Gzip fails if a file is not present. So instead of zipping every file
with a single invocation of gzip, we zip them with an invocation per
file. That way if a file is removed after the file list is generated,
only one invocation of gzip will fail and the rest of the files will be
successfully compressed.

Change-Id: Ifca0af018c074fe0371a5fe0f15106bea817299d
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/09/529109/1 && git format-patch -1 --stdout FETCH_HEAD,['test-log-collect.sh'],1,9092c1f5fe0cc5f28e646be7257e30d8b28c828d,log_collection_removed_file,"# Gzip fails if a file is not present. So instead of zipping every file # with a single invocation of gzip, we zip them with an invocation per file # that way if a file is removed after find is executed, only one invocation of # gzip will fail and the rest of the files will be successfully compressed. find ""${WORKING_DIR}/logs/"" -type f \ | while read f; do command gzip --force --best ""${f}"" \ || echo ""Warning: Failed to compress ${f}, file removed?""; done","command gzip --force --best --recursive ""${WORKING_DIR}/logs/""",7,1
openstack%2Fopenstack-ansible-os_keystone~stable%2Fussuri~I68c0b138955693c8d1992f986878862ea12f5149,openstack/openstack-ansible-os_keystone,stable/ussuri,I68c0b138955693c8d1992f986878862ea12f5149,Allow OIDCClaimDelimiter to be set in the apache config file,MERGED,2021-02-04 15:06:24.000000000,2021-02-07 14:49:17.000000000,2021-02-07 14:48:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 15:06:24.000000000', 'files': ['templates/keystone-httpd.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/9b75e5071520533bd0e5083029dd344d16beafcc', 'message': ""Allow OIDCClaimDelimiter to be set in the apache config file\n\nThis may be necessary for federation where there are multiple\nOIDC groups that are separate by a ';'. See [1].\n\n[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html\n\nChange-Id: I68c0b138955693c8d1992f986878862ea12f5149\n(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)\n""}]",0,773965,9b75e5071520533bd0e5083029dd344d16beafcc,14,4,1,28619,,,0,"Allow OIDCClaimDelimiter to be set in the apache config file

This may be necessary for federation where there are multiple
OIDC groups that are separate by a ';'. See [1].

[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html

Change-Id: I68c0b138955693c8d1992f986878862ea12f5149
(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/65/773965/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone-httpd.conf.j2'],1,9b75e5071520533bd0e5083029dd344d16beafcc,," {% if keystone_sp.trusted_idp_list.0.oidc_claim_delimiter is defined -%} OIDCClaimDelimiter ""{{ keystone_sp.trusted_idp_list.0.oidc_claim_delimiter }}"" {% endif %}",,3,0
openstack%2Fopenstack-ansible-os_neutron~stable%2Fussuri~I5a2cfa40dbcd8116065892e5994898914fd0480b,openstack/openstack-ansible-os_neutron,stable/ussuri,I5a2cfa40dbcd8116065892e5994898914fd0480b,Fix neutron_keepalived_no_track default logic,MERGED,2021-02-04 16:38:42.000000000,2021-02-07 14:35:47.000000000,2021-02-07 14:34:29.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 16:38:42.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/bd74c76dfb5ed5e0d1a01ee6e1efd1bdc7871371', 'message': ""Fix neutron_keepalived_no_track default logic\n\nCurrent logic didn't make sense and made condition to be always true\nfor ubuntu/debian regardless OS version. While for bionic it should have\nremained as false.\n\nChange-Id: I5a2cfa40dbcd8116065892e5994898914fd0480b\n(cherry picked from commit f441b212f5786f07472c103b36aa6224b19bbf25)\n""}]",0,773975,bd74c76dfb5ed5e0d1a01ee6e1efd1bdc7871371,14,3,1,28619,,,0,"Fix neutron_keepalived_no_track default logic

Current logic didn't make sense and made condition to be always true
for ubuntu/debian regardless OS version. While for bionic it should have
remained as false.

Change-Id: I5a2cfa40dbcd8116065892e5994898914fd0480b
(cherry picked from commit f441b212f5786f07472c103b36aa6224b19bbf25)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/75/773975/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,bd74c76dfb5ed5e0d1a01ee6e1efd1bdc7871371,,"_neutron_keepalived_no_track: ""{{ (ansible_distribution_major_version is version('20', '>=') or ansible_distribution | lower == 'debian') }}""","_neutron_keepalived_no_track: ""{{ (ansible_distribution_major_version is version('20', '>=') or ansible_os_family | lower == 'debian') }}""",1,1
openstack%2Fnova~master~Id49a4e400159130fbc676800aeca6b9746071a2e,openstack/nova,master,Id49a4e400159130fbc676800aeca6b9746071a2e,docs: Move the LibvirtDistroSupportMatrix wiki page into our docs,MERGED,2021-01-22 13:57:22.000000000,2021-02-07 13:41:16.000000000,2021-02-06 01:09:38.000000000,"[{'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-22 13:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/568bc65d6d6fdfda915a14c9f06249362afe40f4', 'message': 'docs: Move the LibvirtDistroSupportMatrix wiki page into our docs\n\nThis change moves the LibvirtDistroSupportMatrix [1] wiki page into the\ntree as a reference doc. The wiki page will be decommissioned once this\nchange lands and is published.\n\nSome older distro information is removed to keep the table readable and\na note is added to driver.py to ensure it updated with each version\nbump.\n\n[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix\n\nChange-Id: Id49a4e400159130fbc676800aeca6b9746071a2e\n'}, {'number': 2, 'created': '2021-01-25 08:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6c4832ece8889e80f790283046535b7822c6014', 'message': 'docs: Move the LibvirtDistroSupportMatrix wiki page into our docs\n\nThis change moves the LibvirtDistroSupportMatrix [1] wiki page into the\ntree as a reference doc. The wiki page will be decommissioned once this\nchange lands and is published.\n\nSome older distro information is removed to keep the table readable and\na note is added to driver.py to ensure it updated with each version\nbump.\n\n[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix\n\nChange-Id: Id49a4e400159130fbc676800aeca6b9746071a2e\n'}, {'number': 3, 'created': '2021-01-27 14:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff40be909ec852a6703a1dcb342abfe401038382', 'message': 'docs: Move the LibvirtDistroSupportMatrix wiki page into our docs\n\nThis change moves the LibvirtDistroSupportMatrix [1] wiki page into the\ntree as a reference doc. The wiki page will be decommissioned once this\nchange lands and is published.\n\nSome older distro information is removed to keep the table readable and\na note is added to driver.py to ensure it updated with each version\nbump.\n\n[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix\n\nChange-Id: Id49a4e400159130fbc676800aeca6b9746071a2e\n'}, {'number': 4, 'created': '2021-01-28 15:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c54b9f19eb7bbc044a044e90b03c4b5017ef0c7', 'message': 'docs: Move the LibvirtDistroSupportMatrix wiki page into our docs\n\nThis change moves the LibvirtDistroSupportMatrix [1] wiki page into the\ntree as a reference doc. The wiki page will be decommissioned once this\nchange lands and is published.\n\nSome older distro information is removed to keep the table readable and\na note is added to driver.py to ensure it updated with each version\nbump.\n\n[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix\n\nChange-Id: Id49a4e400159130fbc676800aeca6b9746071a2e\n'}, {'number': 5, 'created': '2021-02-01 14:34:27.000000000', 'files': ['nova/virt/libvirt/driver.py', 'doc/source/reference/index.rst', 'doc/source/reference/libvirt-distro-support-matrix.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/a19d25b67fb524aca83d6ad4e24a16bbd1c65433', 'message': 'docs: Move the LibvirtDistroSupportMatrix wiki page into our docs\n\nThis change moves the LibvirtDistroSupportMatrix [1] wiki page into the\ntree as a reference doc. The wiki page will be decommissioned once this\nchange lands and is published.\n\nSome older distro information is removed to keep the table readable and\na note is added to driver.py to ensure it updated with each version\nbump.\n\n[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix\n\nChange-Id: Id49a4e400159130fbc676800aeca6b9746071a2e\n'}]",35,771981,a19d25b67fb524aca83d6ad4e24a16bbd1c65433,73,4,5,10135,,,0,"docs: Move the LibvirtDistroSupportMatrix wiki page into our docs

This change moves the LibvirtDistroSupportMatrix [1] wiki page into the
tree as a reference doc. The wiki page will be decommissioned once this
change lands and is published.

Some older distro information is removed to keep the table readable and
a note is added to driver.py to ensure it updated with each version
bump.

[1] https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix

Change-Id: Id49a4e400159130fbc676800aeca6b9746071a2e
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/771981/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'doc/source/reference/index.rst', 'doc/source/reference/libvirt-distro-support-matrix.rst']",3,568bc65d6d6fdfda915a14c9f06249362afe40f4,,"libvirt virt driver OS distribution support matrix ================================================== .. note:: This document was previously hosted on the OpenStack wiki: https://wiki.openstack.org/wiki/LibvirtDistroSupportMatrix This page documents the libvirt versions present in the various distro versions that OpenStack Nova aims to be deployable with. libvirt min version change policy --------------------------------- At the start of each Nova development cycle this matrix will be consulted to determine if it is viable to drop support for any end-of-life or otherwise undesired distro versions. Based on this distro evaluation, it may be possible to increase the min required version of libvirt in Nova, and thus drop some compatibility code for older versions. When a decision to update the minimum required libvirt version is made, there must be a warning issued for one cycle. This is achieved by editting ``nova/virt/libvirt/driver.py`` to set .. code:: NEXT_MIN_LIBVIRT_VESION = (X, Y, Z) This causes a deprecation warning to be printed when Nova starts up warning the admin that the version of libvirt they are on will be dropped in the subsequent release. After a version has been listed in ``NEXT_MIN_LIBVIRT_VERSION`` for one release cycle, the corresponding actual min required libvirt can be updated by setting .. code:: MIN_LIBVIRT_VESION = (X, Y, Z) At this point of course, an even newer version might be set in ``NEXT_MIN_LIBVIRT_VERSION`` to repeat the process.... An email should also be sent to the ``openstack-discuss@lists.openstack.org`` mailing list as a courtesy at this point raising awareness of the change in minimum version requirements in the upcoming release, for example: http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019849.html There is more background on the rationale used for picking minimum versions in the operators mailing list thread here: http://lists.openstack.org/pipermail/openstack-operators/2015-May/007012.html QEMU min version change policy ------------------------------ After deciding the minimum libvirt version, the minimum QEMU version is determined by looking for the lowest QEMU version from all the distros that support the decided libvirt version. ``MIN_{LIBVIRT,QEMU}_VESION`` and ``NEXT_MIN_{LIBVIRT,QEMU}_VESION`` table -------------------------------------------------------------------------- .. list-table:: * - OpenStack Release - Nova Release - ``MIN_LIBVIRT_VESION`` - ``NEXT_MIN_LIBVIRT_VESION`` - ``MIN_QEMU_VESION`` - ``NEXT_MIN_QEMU_VESION`` * - Havana - 2013.2.0 - 0.9.6 - 0.9.6 - - * - Icehouse - 2014.1 - 0.9.6 - 0.9.11 - - * - Juno - 2014.2.0 - 0.9.11 - 0.9.11 - - * - Kilo - 2015.1.0 - 0.9.11 - 0.9.11 - - * - Liberty - 12.0.0 - 0.9.11 - 0.10.2 - - * - Mitaka - 13.0.0 - 0.10.2 - 1.2.1 - - * - Newton - 14.0.0 - 1.2.1 - 1.2.1 - 1.5.3 - 1.5.3 * - Ocata - 15.0.0 - 1.2.1 - 1.2.9 - 1.5.3 - 2.1.0 * - Pike - 16.0.0 - 1.2.9 - 1.3.1 - 2.1.0 - 2.5.0 * - Queens - 17.0.0 - 1.2.9 - 1.3.1 - 2.1.0 - 2.5.0 * - Rocky - 18.0.0 - 1.3.1 - 3.0.0 - 2.5.0 - 2.8.0 * - Stein - 19.0.0 - 3.0.0 - 4.0.0 - 2.8.0 - 2.11.0 * - Train - 20.0.0 - 3.0.0 - 4.0.0 - 2.8.0 - 2.11.0 * - Ussuri - 21.0.0 - 4.0.0 - 5.0.0 - 2.11.0 - 4.0.0 * - Victoria - 22.0.0 - 5.0.0 - 6.0.0 - 4.0.0 - 4.2.0 * - Wallaby - 23.0.0 - 6.0.0 - 7.0.0 - 4.2.0 - 5.2.0 OS distribution versions ------------------------ This table provides information on a representative sample of OS distros and the version of libirt/QEMU/libguestfs that they ship. This is **NOT** intended to be an exhaustive list of distros where OpenStack Nova can run - it is intended to run on any Linux distro which can satisfy the minimum required software versions. This table merely aims to help identify when min required versions can be reasonably updated without losing support for important OS distros. .. list-table:: Distro support table * - OS Distro - GA date - Libvirt - QEMU/KVM - libguestfs * - **Debian** - - - - * - 10.x (Buster) (""stable"") - as of 2020-05-15 - 5.0.0 - 3.1 - 1.40 * - 11.x (Bullseye) (""sid"" - unstable) - No GA date as of 2020-05-15 - 6.0.0 - 5.0 - 1.42.0 * - **Fedora** - - - - * - 32 - 2020-04-28 - 6.1.0 - 4.2.0 - 1.42.0 * - 33 - 2020-10-27 - 6.6.0 - 5.1.0 - 1.43.0 * - **SUSE** - - - - * - Leap 15.0 - 2018-05 - 4.0.0 - 2.11.1 - 1.38.0 * - Leap 15.1 - 2019-05-22 - 5.1.0 - 3.1.1 - 1.38.0 * - Leap 15.2 - 2020-07-02 (scheduled) - 6.0.0 - 4.2.0 - 1.38.0 * - **RHEL** - - - - * - 7.7 - 2019-08-06 - 4.5.0-23 - 2.12.0-33 - 1.40.2-5 * - 7.8 - 2020-03-31 - - - * - 8.2 - 2020-04-28 - 6.0.0-17.2 - 4.2.0-19 - 1.40.2-22 * - 8.3 - 2020-10-29 - - - * - **SLES** - - - - * - 15 - 2018-07 - 4.0.0 - 2.11.1 - 1.38.0 * - 15.1 - 2019 - 5.1.0 - 3.1.1 - 1.38.0 * - 15.2 - 2020 - 6.0.0 - 4.2.1 - 1.38.0 * - **Ubuntu** - - - - * - 18.04 (Bionic LTS - Cloud Archive) - as of 2019-11-18 - 5.4 - 4.0 - 1.36 * - 20.04 (Focal Fossa) - 2020-04-23 - 6.0.0 - 4.2 - 1.40.2 NB: maintain alphabetical ordering of distros, followed by oldest released versions first NB2: RHEL versions of QEMU refer to the qemu-kvm-rhev RPM, not the qemu-kvm RPM, since the former is what is intended for use with OpenStack ",,308,6
openstack%2Fnova~master~Idd58298a6b01775f962b9bf0a0835f762c8e0ed2,openstack/nova,master,Idd58298a6b01775f962b9bf0a0835f762c8e0ed2,Refactor ResourceRequest constructor,MERGED,2021-01-07 12:41:14.000000000,2021-02-07 13:04:52.000000000,2021-02-07 06:36:58.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2021-01-07 12:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3fe52daf7885744d04763e441d9c83be3fa6310', 'message': 'Refactor ResourceRequest constructor\n\nThis refactor changes ResourceRequest __init__ to make only an empty\nrequest and moves the ResourceReqeust creation from a RequestSpec to a\nstatic factory method. This is a preparation to introduce another\nfactory method later that will generate aResourceRequest from a single\nResourceGroup instead of a full RequestSpec.\n\nBlueprint: support-interface-attach-with-qos-ports\n\nChange-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2\n'}, {'number': 2, 'created': '2021-01-07 13:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abc6b72f512184d43ec8b80e1be4b0d0e92c862e', 'message': 'Refactor ResourceRequest constructor\n\nThis refactor changes ResourceRequest __init__ to make only an empty\nrequest and moves the ResourceReqeust creation from a RequestSpec to a\nstatic factory method. This is a preparation to introduce another\nfactory method later that will generate aResourceRequest from a single\nResourceGroup instead of a full RequestSpec.\n\nBlueprint: support-interface-attach-with-qos-ports\n\nChange-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2\n'}, {'number': 3, 'created': '2021-01-08 15:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/039bcf8569ea22a899f1c6d1a2bae1e491d2cf3e', 'message': 'Refactor ResourceRequest constructor\n\nThis refactor changes ResourceRequest __init__ to make only an empty\nrequest and moves the ResourceReqeust creation from a RequestSpec to a\nstatic factory method. This is a preparation to introduce another\nfactory method later that will generate aResourceRequest from a single\nResourceGroup instead of a full RequestSpec.\n\nBlueprint: support-interface-attach-with-qos-ports\n\nChange-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2\n'}, {'number': 4, 'created': '2021-01-11 13:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/438393d9da3f81f67b62ed6475a2573d33d23c86', 'message': 'Refactor ResourceRequest constructor\n\nThis refactor changes ResourceRequest __init__ to make only an empty\nrequest and moves the ResourceReqeust creation from a RequestSpec to a\nstatic factory method. This is a preparation to introduce another\nfactory method later that will generate a ResourceRequest from a single\nResourceGroup instead of a full RequestSpec.\n\nBlueprint: support-interface-attach-with-qos-ports\n\nChange-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2\n'}, {'number': 5, 'created': '2021-01-18 15:10:48.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/functional/test_report_client.py', 'nova/tests/unit/scheduler/test_utils.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/request_filter.py', 'nova/virt/libvirt/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c3804efd42f2d735ad48455705dfaa34e10f4cdf', 'message': 'Refactor ResourceRequest constructor\n\nThis refactor changes ResourceRequest __init__ to make only an empty\nrequest and moves the ResourceReqeust creation from a RequestSpec to a\nstatic factory method. This is a preparation to introduce another\nfactory method later that will generate a ResourceRequest from a single\nResourceGroup instead of a full RequestSpec.\n\nBlueprint: support-interface-attach-with-qos-ports\n\nChange-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2\n'}]",41,769720,c3804efd42f2d735ad48455705dfaa34e10f4cdf,108,6,5,9708,,,0,"Refactor ResourceRequest constructor

This refactor changes ResourceRequest __init__ to make only an empty
request and moves the ResourceReqeust creation from a RequestSpec to a
static factory method. This is a preparation to introduce another
factory method later that will generate a ResourceRequest from a single
ResourceGroup instead of a full RequestSpec.

Blueprint: support-interface-attach-with-qos-ports

Change-Id: Idd58298a6b01775f962b9bf0a0835f762c8e0ed2
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/769720/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/functional/test_report_client.py', 'nova/tests/unit/scheduler/test_utils.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/request_filter.py', 'nova/virt/libvirt/utils.py']",6,e3fe52daf7885744d04763e441d9c83be3fa6310,bp/support-interface-attach-with-qos-ports, resource_request = scheduler_utils.ResourceRequest.from_request_spec( req_spec), resource_request = scheduler_utils.ResourceRequest(req_spec),53,28
openstack%2Fnova~master~Id854a6a516eb8467d29d186a2b7bc9e9ce70db33,openstack/nova,master,Id854a6a516eb8467d29d186a2b7bc9e9ce70db33,db: Compact Newton database migrations,MERGED,2020-10-21 15:52:33.000000000,2021-02-07 12:04:07.000000000,2021-02-07 12:02:26.000000000,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32291}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-10-21 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccab5eadccdcc0d2474ec373993a37567728d224', 'message': ""db: Compact Newton database migrations\n\nCompact Newton database migrations into a single migration,\n'334_newton.py'.\n\nUsers will now need to update to Newton before updating to Ocata or\nlater.\n\nSpecific changes include:\n\n- Add 'tag' column to 'virtual_interfaces' table\n- Add 'tag' column to 'block_device_mapping' table\n- Add 'keypairs' column to 'instance_extra' table\n- Add 'console_auth_tokens' table\n- Add 'device_metadata' column to 'instance_extra' table\n\nChange-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-10-22 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccc09333a89edb7e12869b4fa2b4553e11c4f8e6', 'message': ""db: Compact Newton database migrations\n\nCompact Newton database migrations into a single migration,\n'334_newton.py'.\n\nUsers will now need to update to Newton before updating to Ocata or\nlater.\n\nSpecific changes include:\n\n- Add 'tag' column to 'virtual_interfaces' table\n- Add 'tag' column to 'block_device_mapping' table\n- Add 'keypairs' column to 'instance_extra' table\n- Add 'console_auth_tokens' table\n- Add 'device_metadata' column to 'instance_extra' table\n\nChange-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-10-23 10:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c82bb1ceddc53a880c5f1e74f9a57c18b257b178', 'message': ""db: Compact Newton database migrations\n\nCompact Newton database migrations into a single migration,\n'334_newton.py'.\n\nUsers will now need to update to Newton before updating to Ocata or\nlater.\n\nSpecific changes include:\n\n- Add 'tag' column to 'virtual_interfaces' table\n- Add 'tag' column to 'block_device_mapping' table\n- Add 'keypairs' column to 'instance_extra' table\n- Add 'console_auth_tokens' table\n- Add 'device_metadata' column to 'instance_extra' table\n\nChange-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-10-28 11:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/626a4dddcd0d7c7bb3733cf4fd31c8a141343d7d', 'message': ""db: Compact Newton database migrations\n\nCompact Newton database migrations into a single migration,\n'334_newton.py'.\n\nUsers will now need to update to Newton before updating to Ocata or\nlater.\n\nSpecific changes include:\n\n- Add 'tag' column to 'virtual_interfaces' table\n- Add 'tag' column to 'block_device_mapping' table\n- Add 'keypairs' column to 'instance_extra' table\n- Add 'console_auth_tokens' table\n- Add 'device_metadata' column to 'instance_extra' table\n\nChange-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2021-01-07 11:47:59.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/326_placeholder.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/321_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/324_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/332_keypair_in_extra.py', 'nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/328_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/322_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/334_device_metadata_in_extra.py', 'nova/db/sqlalchemy/migrate_repo/versions/325_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/320_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/333_add_console_auth_tokens_table.py', 'nova/db/sqlalchemy/migrate_repo/versions/334_newton.py', 'nova/db/sqlalchemy/migrate_repo/versions/323_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/331_add_tag_to_vifs_and_bdm.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/327_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/329_placeholder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c57cc047ee7c2df1ed508eee1faaf9104c5198ae', 'message': ""db: Compact Newton database migrations\n\nCompact Newton database migrations into a single migration,\n'334_newton.py'.\n\nUsers will now need to update to Newton before updating to Ocata or\nlater.\n\nSpecific changes include:\n\n- Add 'tag' column to 'virtual_interfaces' table\n- Add 'tag' column to 'block_device_mapping' table\n- Add 'keypairs' column to 'instance_extra' table\n- Add 'console_auth_tokens' table\n- Add 'device_metadata' column to 'instance_extra' table\n\nChange-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,759085,c57cc047ee7c2df1ed508eee1faaf9104c5198ae,90,14,5,15334,,,0,"db: Compact Newton database migrations

Compact Newton database migrations into a single migration,
'334_newton.py'.

Users will now need to update to Newton before updating to Ocata or
later.

Specific changes include:

- Add 'tag' column to 'virtual_interfaces' table
- Add 'tag' column to 'block_device_mapping' table
- Add 'keypairs' column to 'instance_extra' table
- Add 'console_auth_tokens' table
- Add 'device_metadata' column to 'instance_extra' table

Change-Id: Id854a6a516eb8467d29d186a2b7bc9e9ce70db33
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/759085/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/326_placeholder.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/321_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/324_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/332_keypair_in_extra.py', 'nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/328_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/322_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/334_device_metadata_in_extra.py', 'nova/db/sqlalchemy/migrate_repo/versions/325_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/320_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/333_add_console_auth_tokens_table.py', 'nova/db/sqlalchemy/migrate_repo/versions/334_newton.py', 'nova/db/sqlalchemy/migrate_repo/versions/323_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/331_add_tag_to_vifs_and_bdm.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/327_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/329_placeholder.py']",19,ccab5eadccdcc0d2474ec373993a37567728d224,bp/compact-db-migrations-wallaby,," # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # This is a placeholder for backports. # Do not use this number for new work. New work starts after # all the placeholders. # # See this for more information: # http://lists.openstack.org/pipermail/openstack-dev/2013-March/006827.html def upgrade(migrate_engine): pass ",28,529
openstack%2Fopenstack-ansible-os_neutron~stable%2Fvictoria~I5a2cfa40dbcd8116065892e5994898914fd0480b,openstack/openstack-ansible-os_neutron,stable/victoria,I5a2cfa40dbcd8116065892e5994898914fd0480b,Fix neutron_keepalived_no_track default logic,MERGED,2021-02-04 16:37:48.000000000,2021-02-07 10:46:51.000000000,2021-02-07 10:45:43.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 16:37:48.000000000', 'files': ['vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/f3eb23c7fa8a3fde67535cd8e36f15047cf22e4a', 'message': ""Fix neutron_keepalived_no_track default logic\n\nCurrent logic didn't make sense and made condition to be always true\nfor ubuntu/debian regardless OS version. While for bionic it should have\nremained as false.\n\nChange-Id: I5a2cfa40dbcd8116065892e5994898914fd0480b\n(cherry picked from commit f441b212f5786f07472c103b36aa6224b19bbf25)\n""}]",0,773974,f3eb23c7fa8a3fde67535cd8e36f15047cf22e4a,12,3,1,28619,,,0,"Fix neutron_keepalived_no_track default logic

Current logic didn't make sense and made condition to be always true
for ubuntu/debian regardless OS version. While for bionic it should have
remained as false.

Change-Id: I5a2cfa40dbcd8116065892e5994898914fd0480b
(cherry picked from commit f441b212f5786f07472c103b36aa6224b19bbf25)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/74/773974/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/debian.yml'],1,f3eb23c7fa8a3fde67535cd8e36f15047cf22e4a,,"_neutron_keepalived_no_track: ""{{ (ansible_distribution_major_version is version('20', '>=') or ansible_distribution | lower == 'debian') }}""","_neutron_keepalived_no_track: ""{{ (ansible_distribution_major_version is version('20', '>=') or ansible_os_family | lower == 'debian') }}""",1,1
openstack%2Ffreezer~master~Ifcef7876c3b1930ebd1237e9c1264db8278e332e,openstack/freezer,master,Ifcef7876c3b1930ebd1237e9c1264db8278e332e,add test_job_process_event unit test cases,MERGED,2021-02-07 08:51:17.000000000,2021-02-07 09:55:54.000000000,2021-02-07 09:54:27.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 08:51:17.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/98b12b02e0ae653fda3034993afa6eaca42a3113', 'message': 'add test_job_process_event unit test cases\n\nChange-Id: Ifcef7876c3b1930ebd1237e9c1264db8278e332e\n'}]",0,774374,98b12b02e0ae653fda3034993afa6eaca42a3113,7,2,1,21387,,,0,"add test_job_process_event unit test cases

Change-Id: Ifcef7876c3b1930ebd1237e9c1264db8278e332e
",git fetch https://review.opendev.org/openstack/freezer refs/changes/74/774374/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,98b12b02e0ae653fda3034993afa6eaca42a3113,," def test_job_process_event(self): jobdoc1 = {""job_id"": ""test"", ""job_schedule"": {""event"": ""start"", ""status"": ""start""}} result = self.job.process_event(jobdoc1) self.assertIsNone(result) jobdoc1 = {""job_id"": ""test"", ""job_schedule"": {""event"": ""stop"", ""status"": ""start""}} result = self.job.process_event(jobdoc1) self.assertIsNone(result) jobdoc1 = {""job_id"": ""test"", ""job_schedule"": {""event"": ""abort"", ""status"": ""start""}} result = self.job.process_event(jobdoc1) self.assertIsNone(result) jobdoc1 = {""job_id"": ""test"", ""job_schedule"": {""event"": ""aborted"", ""status"": ""start""}} result = self.job.process_event(jobdoc1) self.assertIsNone(result) def test_job_upload_metadata(self): metatring = '{""test"": ""freezer""}' self.job.upload_metadata(metatring) self.assertTrue(self.scheduler.upload_metadata.called) metatring = '' result = self.job.upload_metadata(metatring) self.assertIsNone(result)",,26,0
openstack%2Fneutron~master~I2ffee0c8dcfd9911681ba5dd0e16b6d3505a9271,openstack/neutron,master,I2ffee0c8dcfd9911681ba5dd0e16b6d3505a9271,Add OVN mechanism driver to the ML2 config document,MERGED,2021-02-02 22:12:12.000000000,2021-02-07 09:19:26.000000000,2021-02-07 09:17:59.000000000,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 22:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15c4e52c50339b40445fe748b69812999a65a8fe', 'message': 'Add OVN mechanism driver to the ML2 config document\n\nChange-Id: I2ffee0c8dcfd9911681ba5dd0e16b6d3505a9271\n'}, {'number': 2, 'created': '2021-02-02 22:32:31.000000000', 'files': ['doc/source/admin/config-ml2.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0db771dcfe5e2fb6c9c4964cc4769bb13416cf80', 'message': 'Add OVN mechanism driver to the ML2 config document\n\nChange-Id: I2ffee0c8dcfd9911681ba5dd0e16b6d3505a9271\n'}]",6,773811,0db771dcfe5e2fb6c9c4964cc4769bb13416cf80,12,3,2,11975,,,0,"Add OVN mechanism driver to the ML2 config document

Change-Id: I2ffee0c8dcfd9911681ba5dd0e16b6d3505a9271
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/773811/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-ml2.rst'],1,15c4e52c50339b40445fe748b69812999a65a8fe,improve-ml2-docs," - Geneve - yes - no * - OVN - yes - yes - yes (requires OVN 20.09+) - no - yes - no - no - yes VXLAN, GRE and Geneve. It needs to be used in conjunction with either the* OVN The administrator has to configure some additional configuration options for this driver. When this driver is used, architecture of the Neutron application in the cluster is different from what is with other drivers like e.g. Open vSwitch or Linuxbridge. For details, see :ref:`OVN reference architecture<refarch-refarch>`. * - OVN - normal, direct, direct_macvtap, direct_physical - no * - OVN - No (there is ovn-controller running on nodes) * - OVN - no (own L3 implementation) - no (DHCP provided by OVN, fully distributed) - yes (running on compute nodes, fully distributed) - no* OVN mechanism driver Can be used for instance network attachments as well as for attachments of other network resources like routers, metadata ports, and so on. ", VXLAN and GRE. It needs to be used in conjunction with either the,36,1
openstack%2Fnova~master~I9933a9e9087868f1cd92100b3e82c35fe02cab09,openstack/nova,master,I9933a9e9087868f1cd92100b3e82c35fe02cab09,db: Compact Liberty database migrations,MERGED,2020-10-15 11:17:29.000000000,2021-02-07 09:14:06.000000000,2021-02-06 06:20:13.000000000,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-10-15 11:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/738841016485e3cff705794389d63d5f3c936f10', 'message': ""TODO: Compact pre-Mitaka database migrations\n\nCompact pre-Mitaka database migrations into a single migration,\n'302_liberty.py'.\n\nPre-Mitaka users will now need to update to Liberty before updating to\nMitaka or later.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\nTODO: What to do with 298?\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-10-21 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e4f68fbbc6a0858fefdf867098287f7bc408698', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nOur diff is once again because of SQLAlchemy bug #652 [1] and can be\nignored:\n\n  --- nova_before.sql     2020-10-20 16:56:16.805785140 +0100\n  +++ nova_after.sql      2020-10-20 17:04:58.918037517 +0100\n  @@ -714,7 +714,8 @@\n     KEY `migrations_by_host_nodes_and_status_idx` (`deleted`,`source_compute`(100),`dest_compute`(100),`source_node`(100),`dest_node`(100),`status`),\n     KEY `migrations_instance_uuid_and_status_idx` (`deleted`,`instance_uuid`,`status`),\n     KEY `fk_migrations_instance_uuid` (`instance_uuid`),\n  -  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`)\n  +  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`),\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`hidden` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `networks`;\n  @@ -1015,7 +1016,8 @@\n     PRIMARY KEY (`id`),\n     UNIQUE KEY `uniq_services0host0topic0deleted` (`host`,`topic`,`deleted`),\n     UNIQUE KEY `uniq_services0host0binary0deleted` (`host`,`binary`,`deleted`),\n  -  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1))\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1)),\n  +  CONSTRAINT `CONSTRAINT_2` CHECK (`forced_down` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `shadow_agent_builds`;\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-10-22 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdea3141733b17aeb304962e9dfef1e50f9e0890', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nOur diff is once again because of SQLAlchemy bug #652 [1] and can be\nignored:\n\n  --- nova_before.sql     2020-10-20 16:56:16.805785140 +0100\n  +++ nova_after.sql      2020-10-20 17:04:58.918037517 +0100\n  @@ -714,7 +714,8 @@\n     KEY `migrations_by_host_nodes_and_status_idx` (`deleted`,`source_compute`(100),`dest_compute`(100),`source_node`(100),`dest_node`(100),`status`),\n     KEY `migrations_instance_uuid_and_status_idx` (`deleted`,`instance_uuid`,`status`),\n     KEY `fk_migrations_instance_uuid` (`instance_uuid`),\n  -  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`)\n  +  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`),\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`hidden` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `networks`;\n  @@ -1015,7 +1016,8 @@\n     PRIMARY KEY (`id`),\n     UNIQUE KEY `uniq_services0host0topic0deleted` (`host`,`topic`,`deleted`),\n     UNIQUE KEY `uniq_services0host0binary0deleted` (`host`,`binary`,`deleted`),\n  -  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1))\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1)),\n  +  CONSTRAINT `CONSTRAINT_2` CHECK (`forced_down` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `shadow_agent_builds`;\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-10-23 10:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd3c9fff232997349ed8d495db97dc8f9f24bd98', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nOur diff is once again because of SQLAlchemy bug #652 [1] and can be\nignored:\n\n  --- nova_before.sql     2020-10-20 16:56:16.805785140 +0100\n  +++ nova_after.sql      2020-10-20 17:04:58.918037517 +0100\n  @@ -714,7 +714,8 @@\n     KEY `migrations_by_host_nodes_and_status_idx` (`deleted`,`source_compute`(100),`dest_compute`(100),`source_node`(100),`dest_node`(100),`status`),\n     KEY `migrations_instance_uuid_and_status_idx` (`deleted`,`instance_uuid`,`status`),\n     KEY `fk_migrations_instance_uuid` (`instance_uuid`),\n  -  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`)\n  +  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`),\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`hidden` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `networks`;\n  @@ -1015,7 +1016,8 @@\n     PRIMARY KEY (`id`),\n     UNIQUE KEY `uniq_services0host0topic0deleted` (`host`,`topic`,`deleted`),\n     UNIQUE KEY `uniq_services0host0binary0deleted` (`host`,`binary`,`deleted`),\n  -  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1))\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1)),\n  +  CONSTRAINT `CONSTRAINT_2` CHECK (`forced_down` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `shadow_agent_builds`;\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2020-10-23 13:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c92f9f0aceb69e1ef3115a7d174135d6d394b71', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nOur diff is once again because of SQLAlchemy bug #652 [1] and can be\nignored:\n\n  --- nova_before.sql     2020-10-20 16:56:16.805785140 +0100\n  +++ nova_after.sql      2020-10-20 17:04:58.918037517 +0100\n  @@ -714,7 +714,8 @@\n     KEY `migrations_by_host_nodes_and_status_idx` (`deleted`,`source_compute`(100),`dest_compute`(100),`source_node`(100),`dest_node`(100),`status`),\n     KEY `migrations_instance_uuid_and_status_idx` (`deleted`,`instance_uuid`,`status`),\n     KEY `fk_migrations_instance_uuid` (`instance_uuid`),\n  -  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`)\n  +  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`),\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`hidden` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `networks`;\n  @@ -1015,7 +1016,8 @@\n     PRIMARY KEY (`id`),\n     UNIQUE KEY `uniq_services0host0topic0deleted` (`host`,`topic`,`deleted`),\n     UNIQUE KEY `uniq_services0host0binary0deleted` (`host`,`binary`,`deleted`),\n  -  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1))\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1)),\n  +  CONSTRAINT `CONSTRAINT_2` CHECK (`forced_down` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `shadow_agent_builds`;\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2020-10-28 11:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec52f9428668873f1ae4d1dddec09339d95b2ab2', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nOur diff is once again because of SQLAlchemy bug #652 [1] and can be\nignored:\n\n  --- nova_before.sql     2020-10-20 16:56:16.805785140 +0100\n  +++ nova_after.sql      2020-10-20 17:04:58.918037517 +0100\n  @@ -714,7 +714,8 @@\n     KEY `migrations_by_host_nodes_and_status_idx` (`deleted`,`source_compute`(100),`dest_compute`(100),`source_node`(100),`dest_node`(100),`status`),\n     KEY `migrations_instance_uuid_and_status_idx` (`deleted`,`instance_uuid`,`status`),\n     KEY `fk_migrations_instance_uuid` (`instance_uuid`),\n  -  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`)\n  +  CONSTRAINT `fk_migrations_instance_uuid` FOREIGN KEY (`instance_uuid`) REFERENCES `instances` (`uuid`),\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`hidden` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `networks`;\n  @@ -1015,7 +1016,8 @@\n     PRIMARY KEY (`id`),\n     UNIQUE KEY `uniq_services0host0topic0deleted` (`host`,`topic`,`deleted`),\n     UNIQUE KEY `uniq_services0host0binary0deleted` (`host`,`binary`,`deleted`),\n  -  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1))\n  +  CONSTRAINT `CONSTRAINT_1` CHECK (`disabled` in (0,1)),\n  +  CONSTRAINT `CONSTRAINT_2` CHECK (`forced_down` in (0,1))\n   ) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n   /*!40101 SET character_set_client = @saved_cs_client */;\n   DROP TABLE IF EXISTS `shadow_agent_builds`;\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 7, 'created': '2021-01-07 11:47:59.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/294_add_service_heartbeat.py', 'nova/db/sqlalchemy/migrate_repo/versions/300_migration_context.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/281_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/302_liberty.py', 'nova/db/sqlalchemy/migrate_repo/versions/287_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/293_add_migration_type.py', 'nova/db/sqlalchemy/migrate_repo/versions/285_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/282_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/286_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/290_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/298_mysql_extra_specs_binary_collation.py', 'nova/db/sqlalchemy/migrate_repo/versions/284_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/291_enforce_flavors_migrated.py', 'nova/db/sqlalchemy/migrate_repo/versions/295_add_virtual_interfaces_uuid_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/292_drop_nova_volumes_tables.py', 'nova/db/sqlalchemy/migrate_repo/versions/297_add_forced_down_for_services.py', 'nova/db/sqlalchemy/migrate_repo/versions/289_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/283_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/302_pgsql_add_instance_system_metadata_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/296_add_missing_db2_fkeys.py', 'nova/db/sqlalchemy/migrate_repo/versions/301_add_cpu_and_ram_ratios_for_compute_nodes.py', 'nova/db/sqlalchemy/migrate_repo/versions/288_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/299_service_version_number.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1da542ff7a9ebf4cb86ec607bb35b4d69d848f73', 'message': ""db: Compact Liberty database migrations\n\nCompact Liberty database migrations into a single migration,\n'302_liberty.py'.\n\nUsers will now need to update to Liberty before updating to Mitaka or\nlater.\n\nSpecific changes include:\n\n- Drop 'volumes', 'iscsi_targets' tables\n- Add 'migration_type', 'hidden' columns to 'migrations' table\n- Add 'last_seen_up' column to 'services' table\n- Add index for 'uuid' column of 'virtual_interfaces' table\n- Add 'forced_down' column to 'services' table\n- Add 'version' column to 'services' table\n- Add 'migration_context' column to 'migration_context' table\n- Add index for 'instance_uuid' column of 'instance_system_metadata'\n  table for PostgreSQL and SQLite; this was already present for MySQL\n\nThis hits the same issue seen previously of a constraint being added to\na boolean field in a shadow table on SQLite, despite this being disabled\nfor the main table. As before, we can ignore this given SQLite is not a\nproduction DB.\n\nWe also hit another case of doing something to a main table but not its\nshadow table, which will have to be resolved later.\n\nNow that we can rely on flavor records having been migrated, we can\nremove the 'db migrate_flavor_data' nova-manage command. This will be\ndone separately.\n\nWhen testing, the previous base version was 279. It is now 301.\n\n[1] https://github.com/sqlalchemy/alembic/issues/652\n\nChange-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",14,758397,1da542ff7a9ebf4cb86ec607bb35b4d69d848f73,122,13,7,15334,,,0,"db: Compact Liberty database migrations

Compact Liberty database migrations into a single migration,
'302_liberty.py'.

Users will now need to update to Liberty before updating to Mitaka or
later.

Specific changes include:

- Drop 'volumes', 'iscsi_targets' tables
- Add 'migration_type', 'hidden' columns to 'migrations' table
- Add 'last_seen_up' column to 'services' table
- Add index for 'uuid' column of 'virtual_interfaces' table
- Add 'forced_down' column to 'services' table
- Add 'version' column to 'services' table
- Add 'migration_context' column to 'migration_context' table
- Add index for 'instance_uuid' column of 'instance_system_metadata'
  table for PostgreSQL and SQLite; this was already present for MySQL

This hits the same issue seen previously of a constraint being added to
a boolean field in a shadow table on SQLite, despite this being disabled
for the main table. As before, we can ignore this given SQLite is not a
production DB.

We also hit another case of doing something to a main table but not its
shadow table, which will have to be resolved later.

Now that we can rely on flavor records having been migrated, we can
remove the 'db migrate_flavor_data' nova-manage command. This will be
done separately.

When testing, the previous base version was 279. It is now 301.

[1] https://github.com/sqlalchemy/alembic/issues/652

Change-Id: I9933a9e9087868f1cd92100b3e82c35fe02cab09
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/758397/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/294_add_service_heartbeat.py', 'nova/db/sqlalchemy/migrate_repo/versions/300_migration_context.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/281_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/302_liberty.py', 'nova/db/sqlalchemy/migrate_repo/versions/287_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/293_add_migration_type.py', 'nova/db/sqlalchemy/migrate_repo/versions/285_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/282_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/286_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/290_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/298_mysql_extra_specs_binary_collation.py', 'nova/db/sqlalchemy/migrate_repo/versions/284_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/291_enforce_flavors_migrated.py', 'nova/db/sqlalchemy/migrate_repo/versions/295_add_virtual_interfaces_uuid_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/292_drop_nova_volumes_tables.py', 'nova/db/sqlalchemy/migrate_repo/versions/297_add_forced_down_for_services.py', 'nova/db/sqlalchemy/migrate_repo/versions/289_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/283_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/302_pgsql_add_instance_system_metadata_index.py', 'nova/db/sqlalchemy/migrate_repo/versions/296_add_missing_db2_fkeys.py', 'nova/db/sqlalchemy/migrate_repo/versions/301_add_cpu_and_ram_ratios_for_compute_nodes.py', 'nova/db/sqlalchemy/migrate_repo/versions/288_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/299_service_version_number.py']",25,738841016485e3cff705794389d63d5f3c936f10,bp/compact-db-migrations-wallaby,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Integer, Column, MetaData, Table def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine services = Table('services', meta, autoload=True) shadow_services = Table('shadow_services', meta, autoload=True) services.create_column(Column('version', Integer, default=0)) shadow_services.create_column(Column('version', Integer, default=0)) ",22,771
openstack%2Ffreezer~master~I3459d776df233dbe8c36495db3cc113984b44e94,openstack/freezer,master,I3459d776df233dbe8c36495db3cc113984b44e94,add test_save_action_to_file unit test cases,MERGED,2021-02-07 07:47:06.000000000,2021-02-07 08:47:56.000000000,2021-02-07 08:46:46.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 07:47:06.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/ca74ddf145f92db30fc1ec9cc507d5b96b788cbb', 'message': 'add test_save_action_to_file unit test cases\n\nChange-Id: I3459d776df233dbe8c36495db3cc113984b44e94\n'}]",0,774369,ca74ddf145f92db30fc1ec9cc507d5b96b788cbb,7,2,1,21387,,,0,"add test_save_action_to_file unit test cases

Change-Id: I3459d776df233dbe8c36495db3cc113984b44e94
",git fetch https://review.opendev.org/openstack/freezer refs/changes/69/774369/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,ca74ddf145f92db30fc1ec9cc507d5b96b788cbb,,"import shutil def test_save_action_to_file(self): action = {'start': ""test""} temp = tempfile.mkdtemp() filename = '/'.join([temp, ""test.conf""]) f = mock.MagicMock() f.name = filename result = self.job.save_action_to_file(action, f) self.assertIsNone(result) shutil.rmtree(temp) def test_job_schedule_end_date(self): self.assertEqual(self.job.schedule_end_date, '') def test_job_schedule_cron_fields(self): result = self.job.schedule_cron_fields self.assertEqual(result, {""day"": ""1""}) def test_get_schedule_args(self): jobdoc1 = {""job_schedule"": {""schedule_start_date"": ""2020-01-10T10:10:10"", ""schedule_end_date"": ""2020-11-10T10:10:10"", ""schedule_date"": ""2020-09-10T10:10:10""}} job1 = scheduler_job.Job(self.scheduler, None, jobdoc1) result = job1.get_schedule_args() self.assertEqual(result, {'trigger': 'date', 'run_date': ""2020-09-10T10:10:10""}) jobdoc1 = {""job_schedule"": {""schedule_start_date"": ""2020-10-10T10:10:10"", ""schedule_end_date"": ""2020-11-10T10:10:10"", ""schedule_interval"": ""continuous""}} job1 = scheduler_job.Job(self.scheduler, None, jobdoc1) result = job1.get_schedule_args() self.assertEqual(result.get('seconds'), 1) jobdoc1 = {""job_schedule"": {""schedule_start_date"": ""2020-10-10T10:10:10"", ""schedule_end_date"": ""2020-11-10T10:10:10"", ""schedule_interval"": ""5 days""}} job1 = scheduler_job.Job(self.scheduler, None, jobdoc1) result = job1.get_schedule_args() self.assertEqual(result.get('days'), 5) jobdoc1 = {""job_schedule"": {}} job1 = scheduler_job.Job(self.scheduler, None, jobdoc1) result = job1.get_schedule_args() self.assertEqual(result.get('trigger'), 'date')",,46,0
openstack%2Fcyborg~master~Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5,openstack/cyborg,master,Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5,Add intel NIC driver,MERGED,2020-10-21 05:54:16.000000000,2021-02-07 08:46:57.000000000,2021-02-07 08:45:36.000000000,"[{'_account_id': 7543}, {'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 28748}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-10-21 05:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/cd68665dc3fa28ae3250bbadcb612dd11112b4ea', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 2, 'created': '2021-01-05 12:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f055708fa41d2e617928cd5197274830590a7a1c', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 3, 'created': '2021-01-08 11:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f4c735f744e2b3cbc3f1d0a75089bca2fcb66c9d', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 4, 'created': '2021-01-14 06:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/cd05f70b20fa35735b24d84e420d4a0cb71ddec0', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 5, 'created': '2021-01-14 07:18:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/d1ab2695069e001cfb9a6fc568771359fa0097c6', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 6, 'created': '2021-01-25 07:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/4a97355ca3a0636297294f2970e93a7279398d1b', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 7, 'created': '2021-01-26 08:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/485e603eb29b49b5c8adea0b85ce9f5fd9d019d4', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 8, 'created': '2021-02-02 05:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/914c0be301a44cf3090c31da21792bfb61f82bbf', 'message': ""Add 710 driver\n\nThis patch implements a new driver for Intel X710 Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that X710's driver can read the info from this\nfile.\n\nPlease check the test report in the following link:\nhttps://wiki.openstack.org/wiki/Cyborg/TestReport/IntelNic\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 9, 'created': '2021-02-03 11:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f0e860a5cd8191d9b11d77ceea5a4c8b1014f394', 'message': ""Add intel NIC driver\n\nThis patch implements a new driver for Intel Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that nic's driver can read the info from this\nfile.\n\nPlease check the test report in the following link:\nhttps://wiki.openstack.org/wiki/Cyborg/TestReport/IntelNic\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}, {'number': 10, 'created': '2021-02-04 08:45:23.000000000', 'files': ['cyborg/tests/unit/accelerator/drivers/nic/intel/__init__.py', 'cyborg/accelerator/drivers/nic/intel/__init__.py', 'cyborg/accelerator/drivers/nic/intel/driver.py', 'cyborg/common/constants.py', 'cyborg/tests/unit/accelerator/drivers/fpga/intel/prepare_test_data.py', 'cyborg/tests/unit/accelerator/drivers/nic/intel/test_driver.py', 'cyborg/accelerator/common/utils.py', 'cyborg/accelerator/drivers/nic/base.py', 'cyborg/tests/unit/accelerator/drivers/nic/__init__.py', 'cyborg/accelerator/drivers/fpga/intel/driver.py', 'cyborg/accelerator/drivers/nic/intel/sysinfo.py', 'cyborg/common/exception.py', 'cyborg/tests/unit/accelerator/drivers/nic/intel/prepare_test_data.py', 'cyborg/db/sqlalchemy/models.py', 'cyborg/accelerator/drivers/nic/__init__.py', 'cyborg.conf.intelnic.sample', 'cyborg/db/sqlalchemy/alembic/versions/899cead40bc9_add_nic_type.py', 'cyborg/conf/devices.py', 'cyborg/tests/unit/accelerator/drivers/nic/test_base.py', 'cyborg/conf/__init__.py', 'doc/source/reference/driver-table.rst', 'releasenotes/notes/intel-nic-driver-f93adad86a23ceb9.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/e3caf5cb0a5d5fe44e2409c7712d3d911508a27b', 'message': ""Add intel NIC driver\n\nThis patch implements a new driver for Intel Nic Card. It\ncan discover the device and report it to Placement service with\nCUSTOM_NIC resource class and specific traits.\n\nOperator should specify the device and correspond profile in a\nconfig file so that nic's driver can read the info from this\nfile.\n\nPlease check the test report in the following link:\nhttps://wiki.openstack.org/wiki/Cyborg/TestReport/IntelNic\n\nChange-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5\nImplements: blueprint sriov-smartnic-support\n""}]",94,758942,e3caf5cb0a5d5fe44e2409c7712d3d911508a27b,51,7,10,25738,,,0,"Add intel NIC driver

This patch implements a new driver for Intel Nic Card. It
can discover the device and report it to Placement service with
CUSTOM_NIC resource class and specific traits.

Operator should specify the device and correspond profile in a
config file so that nic's driver can read the info from this
file.

Please check the test report in the following link:
https://wiki.openstack.org/wiki/Cyborg/TestReport/IntelNic

Change-Id: Ida0ba8f24b9e226da7f3d7a85fc372247e5281a5
Implements: blueprint sriov-smartnic-support
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/42/758942/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg/accelerator/drivers/nic/intel/__init__.py', 'cyborg/accelerator/drivers/nic/intel/driver.py', 'cyborg/common/constants.py', 'x710-driver-setup', 'cyborg/accelerator/drivers/nic/intel/nic.conf', 'cyborg/accelerator/common/utils.py', 'cyborg/accelerator/drivers/nic/base.py', 'cyborg/accelerator/drivers/nic/intel/sysinfo.py', 'cyborg/db/sqlalchemy/models.py', 'cyborg/accelerator/drivers/nic/__init__.py', 'cyborg/db/sqlalchemy/alembic/versions/899cead40bc9_add_nic_type.py', '0001-Enable-Intel-710-driver.patch', 'setup.cfg']",13,cd68665dc3fa28ae3250bbadcb612dd11112b4ea,bp/sriov-smartnic-support, intel_nic_driver = cyborg.accelerator.drivers.nic.intel.driver:IntelNICDriver,,897,6
openstack%2Fpython-manilaclient~master~I39afab6c844972a1c97c15055dbc1f07ed90a68b,openstack/python-manilaclient,master,I39afab6c844972a1c97c15055dbc1f07ed90a68b,"Add ""--wait"" option for force-deleting a share/snapshot/share-instance",ABANDONED,2021-01-28 10:41:59.000000000,2021-02-07 08:02:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 31213}]","[{'number': 1, 'created': '2021-01-28 10:41:59.000000000', 'files': ['manilaclient/tests/unit/v2/test_shell.py', 'manilaclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/9e37a49f7ef60074745f354d52d33ea68f8ac8c0', 'message': 'Add ""--wait"" option for force-deleting a share/snapshot/share-instance\n\nChange-Id: I39afab6c844972a1c97c15055dbc1f07ed90a68b\n'}]",7,772849,9e37a49f7ef60074745f354d52d33ea68f8ac8c0,6,2,1,32493,,,0,"Add ""--wait"" option for force-deleting a share/snapshot/share-instance

Change-Id: I39afab6c844972a1c97c15055dbc1f07ed90a68b
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/49/772849/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/tests/unit/v2/test_shell.py', 'manilaclient/v2/shell.py']",2,9e37a49f7ef60074745f354d52d33ea68f8ac8c0,Bug-#1898317,"@cliutils.arg( '--wait', action='store_true', help='Wait for share to delete') @cliutils.service_type('sharev2') if args.wait: try: _wait_for_share_status(cs, share, expected_status='deleted') except exceptions.CommandError as e: print(e, file=sys.stderr)@cliutils.arg( '--wait', action='store_true', help='Wait for share instance deletion') @cliutils.service_type('sharev2') if args.wait: try: _wait_for_share_status(cs, instance, expected_status='deleted') except exceptions.CommandError as e: print(e, file=sys.stderr)@cliutils.arg( '--wait', action='store_true', help='Wait for snapshot to delete') @cliutils.service_type('sharev2') if args.wait: try: snapshot_ref = _wait_for_share_status( cs, snapshot, expected_status='deleted') except exceptions.CommandError as e: print(e, file=sys.stderr)",,48,0
openstack%2Fneutron~stable%2Fussuri~Ib840e7c51f7b918b5e17ce9deff9ceafacf063cc,openstack/neutron,stable/ussuri,Ib840e7c51f7b918b5e17ce9deff9ceafacf063cc,Make test_agent_show only look for its own agents,MERGED,2021-02-03 08:52:20.000000000,2021-02-07 07:52:49.000000000,2021-02-07 07:51:24.000000000,"[{'_account_id': 5756}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 08:52:20.000000000', 'files': ['neutron/db/agents_db.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f78ff515a5a926ab3f8208b0980585e8ab89ae7', 'message': ""Make test_agent_show only look for its own agents\n\nSince plugin agents are a global resource, relying just on the\n'type' field for test_agent_show may end up finding an agent that\nwe don't know about, and that agent could be deleted by another\ntest. This reworks test_agent_show to sepecifically look for its\nown OVN controller agent and test agent.\n\nThis also adds the 'id' field to the returned agent_status from\ncreate_or_update_agent() to make it possible to look for the agent\nthat was just created.\n\nChange-Id: Ib840e7c51f7b918b5e17ce9deff9ceafacf063cc\nCloses-Bug: #1899004\n(cherry picked from commit df2c7baa23b814ccd118fb69d16427b2bf59cecc)\n""}]",0,773851,5f78ff515a5a926ab3f8208b0980585e8ab89ae7,19,4,1,16688,,,0,"Make test_agent_show only look for its own agents

Since plugin agents are a global resource, relying just on the
'type' field for test_agent_show may end up finding an agent that
we don't know about, and that agent could be deleted by another
test. This reworks test_agent_show to sepecifically look for its
own OVN controller agent and test agent.

This also adds the 'id' field to the returned agent_status from
create_or_update_agent() to make it possible to look for the agent
that was just created.

Change-Id: Ib840e7c51f7b918b5e17ce9deff9ceafacf063cc
Closes-Bug: #1899004
(cherry picked from commit df2c7baa23b814ccd118fb69d16427b2bf59cecc)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/773851/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/agents_db.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py']",2,5f78ff515a5a926ab3f8208b0980585e8ab89ae7,bug/1899004," self.controller_agent = self.add_fake_chassis(self.host) _, status = self.plugin.create_or_update_agent(self.context, agent) self.test_agent = status['id'] def test_agent_show_non_ovn(self): self.assertTrue(self.plugin.get_agent(self.context, self.test_agent)) def test_agent_show_ovn_controller(self): self.assertTrue(self.plugin.get_agent(self.context, self.controller_agent))"," self.add_fake_chassis(self.host) self.plugin.create_or_update_agent(self.context, agent) def get_agent(self, agent_type): return next(iter(self.plugin.get_agents( self.context, filters={'agent_type': agent_type}))) def test_agent_show(self): for agent_type in ('test', ovn_const.OVN_CONTROLLER_AGENT): agent = self.get_agent(agent_type) self.assertTrue(self.plugin.get_agent(self.context, agent['id']))",9,9
openstack%2Ffreezer~master~If11616c358681b2363ea5ff37c1aba726e4d9091,openstack/freezer,master,If11616c358681b2363ea5ff37c1aba726e4d9091,add test_job_session_id unit testcases,MERGED,2021-02-07 06:05:16.000000000,2021-02-07 07:43:02.000000000,2021-02-07 07:41:47.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 06:05:16.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/d8b96ff91cbdb41a0495f6e7d6214470d3a964ae', 'message': 'add test_job_session_id unit testcases\n\nChange-Id: If11616c358681b2363ea5ff37c1aba726e4d9091\n'}]",0,774365,d8b96ff91cbdb41a0495f6e7d6214470d3a964ae,7,2,1,21387,,,0,"add test_job_session_id unit testcases

Change-Id: If11616c358681b2363ea5ff37c1aba726e4d9091
",git fetch https://review.opendev.org/openstack/freezer refs/changes/65/774365/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,d8b96ff91cbdb41a0495f6e7d6214470d3a964ae,," def test_job_session_id(self): self.assertEqual(self.job.session_id, '') self.job.session_id = 'test' self.assertEqual(self.job.session_id, 'test') def test_job_session_tag(self): self.assertEqual(self.job.session_tag, 0) self.job.session_tag = 1 self.assertEqual(self.job.session_tag, 1) def test_job_result(self): self.assertEqual(self.job.result, '') self.job.result = 'test' self.assertEqual(self.job.result, 'test') def test_job_can_be_removed(self): result = self.job.can_be_removed() self.assertFalse(result)",,19,0
openstack%2Fneutron~stable%2Fussuri~Ied5bdca2a3b3832f11d42614d609d0849111ae1a,openstack/neutron,stable/ussuri,Ied5bdca2a3b3832f11d42614d609d0849111ae1a,"Do not update agents ""alive"" state in TestAgentApi",MERGED,2021-02-03 08:50:54.000000000,2021-02-07 07:31:10.000000000,2021-02-07 07:29:33.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 08:50:54.000000000', 'files': ['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c825921dc73f065d4984895d7b1dadf35f505596', 'message': 'Do not update agents ""alive"" state in TestAgentApi\n\nDuring the execution of FT TestAgentApi, we should not update the\nchassis agents ""alive"" state; during the FT execution, some of the\nagents returned by ""agents_from_chassis"" do not really exist (not\nrelevant for the test case).\n\nChange-Id: Ied5bdca2a3b3832f11d42614d609d0849111ae1a\nCloses-Bug: #1897921\n(cherry picked from commit be7882be27237e7803c0b8411335f66594729175)\n(cherry picked from commit 3ca5b3a5de44af57024a67f7f6abc0a09711c232)\n'}]",0,773850,c825921dc73f065d4984895d7b1dadf35f505596,31,3,1,16688,,,0,"Do not update agents ""alive"" state in TestAgentApi

During the execution of FT TestAgentApi, we should not update the
chassis agents ""alive"" state; during the FT execution, some of the
agents returned by ""agents_from_chassis"" do not really exist (not
relevant for the test case).

Change-Id: Ied5bdca2a3b3832f11d42614d609d0849111ae1a
Closes-Bug: #1897921
(cherry picked from commit be7882be27237e7803c0b8411335f66594729175)
(cherry picked from commit 3ca5b3a5de44af57024a67f7f6abc0a09711c232)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/773850/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py'],1,c825921dc73f065d4984895d7b1dadf35f505596,bug/1897921," mock.patch.object(self.mech_driver, 'ping_all_chassis', return_value=False).start()",,2,0
openstack%2Fglance~master~I2a3a99bd27db1c72d49b36b87e073e0b97fc874d,openstack/glance,master,I2a3a99bd27db1c72d49b36b87e073e0b97fc874d,Add functional tests for cinder multiple store,MERGED,2020-09-07 09:44:56.000000000,2021-02-07 07:28:32.000000000,2021-02-05 16:20:47.000000000,"[{'_account_id': 4393}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2020-09-07 09:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a7bd346303fac9f702ac6491e26c794e62c552b1', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}, {'number': 2, 'created': '2020-09-07 10:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0bd736c00c2dbba881b8985990f018efbd5600cd', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}, {'number': 3, 'created': '2021-01-21 05:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3b2d886db1bd985eb5f547bf4c649d3a6b552da9', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}, {'number': 4, 'created': '2021-01-27 13:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/735e654908b6c04fc4d3e795fc46fa61e82fdfac', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}, {'number': 5, 'created': '2021-02-04 11:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1aacda6cb2cef4fd1beefa6017eaea95c19bd073', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}, {'number': 6, 'created': '2021-02-05 13:11:01.000000000', 'files': ['test-requirements.txt', 'glance/tests/functional/v2/test_legacy_update_cinder_store.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/glance/commit/09b924c9bcdfd4d750f285f60cfd02f5504908fb', 'message': 'Add functional tests for cinder multiple store\n\nThis patch adds functional tests for cinder multiple stores[1] legacy\nimage migration and new image create.\nNOTE: This has been proposed separately as it has a dependency on a\nglance-store change[2] which will require a new release of glance-store\nto reflect changes on the gate.\n\n[1] https://review.opendev.org/#/c/748039\n[2] https://review.opendev.org/#/c/750131\n\nDepends-On: https://review.opendev.org/#/c/750131\nChange-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d\n'}]",15,750144,09b924c9bcdfd4d750f285f60cfd02f5504908fb,42,6,6,27615,,,0,"Add functional tests for cinder multiple store

This patch adds functional tests for cinder multiple stores[1] legacy
image migration and new image create.
NOTE: This has been proposed separately as it has a dependency on a
glance-store change[2] which will require a new release of glance-store
to reflect changes on the gate.

[1] https://review.opendev.org/#/c/748039
[2] https://review.opendev.org/#/c/750131

Depends-On: https://review.opendev.org/#/c/750131
Change-Id: I2a3a99bd27db1c72d49b36b87e073e0b97fc874d
",git fetch https://review.opendev.org/openstack/glance refs/changes/44/750144/3 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'glance/tests/functional/v2/test_legacy_update_cinder_store.py', 'lower-constraints.txt']",3,a7bd346303fac9f702ac6491e26c794e62c552b1,multiple-cinder-backend-support,os-brick==3.1.0oslo.privsep==1.32.0python-cinderclient>=4.1.0,,243,0
openstack%2Ffreezer~master~I8955f673b968c34b9b27f6e305f17ab3b6fcfac2,openstack/freezer,master,I8955f673b968c34b9b27f6e305f17ab3b6fcfac2,add test_job_create unit testcases,MERGED,2021-02-07 03:14:21.000000000,2021-02-07 05:59:35.000000000,2021-02-07 05:58:21.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 03:14:21.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/bf49fb0dfc8bf2ab35921db46bf9e4878c5bad78', 'message': 'add test_job_create unit testcases\n\nChange-Id: I8955f673b968c34b9b27f6e305f17ab3b6fcfac2\n'}]",0,774364,bf49fb0dfc8bf2ab35921db46bf9e4878c5bad78,7,2,1,21387,,,0,"add test_job_create unit testcases

Change-Id: I8955f673b968c34b9b27f6e305f17ab3b6fcfac2
",git fetch https://review.opendev.org/openstack/freezer refs/changes/64/774364/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,bf49fb0dfc8bf2ab35921db46bf9e4878c5bad78,improveUTC5," def test_job_create(self): jobdoc = {""job_id"": ""test"", ""job_schedule"": {""status"": ""running""}} result = scheduler_job.Job.create(None, None, jobdoc) self.assertEqual(result.job_doc_status, 'running') jobdoc = {""job_id"": ""test"", ""job_schedule"": {""status"": ""stop""}} result = scheduler_job.Job.create(None, None, jobdoc) self.assertEqual(result.event, 'stop') jobdoc = {""job_id"": ""test"", ""job_schedule"": {}} result = scheduler_job.Job.create(None, None, jobdoc) self.assertEqual(result.event, 'start') def test_job_remove(self): result = self.job.remove() self.assertIsNone(result)",,15,0
openstack%2Fcinder~master~I7325307d58e93f219e9a24529d90680141b165a4,openstack/cinder,master,I7325307d58e93f219e9a24529d90680141b165a4,volume list query optimization,NEW,2020-07-09 03:49:11.000000000,2021-02-07 04:34:20.000000000,,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12988}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26458}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30407}, {'_account_id': 30555}, {'_account_id': 30615}, {'_account_id': 30688}, {'_account_id': 30754}, {'_account_id': 32029}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-07-09 03:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6515daabddd9a008c16d9a8debb48762143accf3', 'message': 'volume list query optimization\n\nWhen we fail to manage a volume, we use cinder list to view the volume\nlist, or use cinder show to view the volume details, We can see that the\nvolume state is error.\nBut when we filter the list of volumes by specifying the status as\nerror,We found that there were no manage failed volumes in the\nscreening results,this will confuse the user.\nso what needs to be fixed?\n\n(A) when a user filters on status=error, volumes in (internal) status\nerror_managing should also be included\n(B) when a user filters on status=creating, volumes in (internal) status\nmanaging should also be included\n(C) when a user filters on status=deleting, volumes in (internal) status\nerror_managing_deleting should also be included\n(D) when a user filters on any status that\'s not in the official list,\nthey should get an empty list of volumes (need to verify that\'s the\ncurrent behavior, but I\'m pretty sure that if you GET\n/v3/v3/{project_id}/volumes/detail?status=not-a-status you get the\nresponse { ""volumes"": [] }, not a 400). Currently we rely on the\ndatabase for this, but we may need to handle it in the REST API layer.\n(E) fixing the ""like"" operator from microversion 3.34 is going to be\ntricky. ?status~=error should include volumes in statuses error,\nerror_deleting, error_backing-up, error_restoring, and error_extending\n(and error_managing), but NOT include volumes with status\nerror_managing_deleting. ?status~=creating should include volumes with\n(internal) status \'managing\'. ?status~=deleting should include volumes\nwith internal status \'error_managing_deleting\', but not include error_deleting.\n\nPartially-Implements: blueprint volume-list-query-optimization\n\nChange-Id: I7325307d58e93f219e9a24529d90680141b165a4\n'}, {'number': 2, 'created': '2020-07-09 12:46:04.000000000', 'files': ['cinder/api/v2/volumes.py', 'cinder/objects/fields.py', 'releasenotes/notes/bp-volume-list-query-optimization-ddebc9df5919e887.yaml', 'cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c79b672806cd9854070784bdad533933d95f6cc6', 'message': 'volume list query optimization\n\nWhen we fail to manage a volume, we use cinder list to view the volume\nlist, or use cinder show to view the volume details, We can see that the\nvolume state is error.\nBut when we filter the list of volumes by specifying the status as\nerror,We found that there were no manage failed volumes in the\nscreening results,this will confuse the user.\nso what needs to be fixed?\n\n(A) when a user filters on status=error, volumes in (internal) status\nerror_managing should also be included\n(B) when a user filters on status=creating, volumes in (internal) status\nmanaging should also be included\n(C) when a user filters on status=deleting, volumes in (internal) status\nerror_managing_deleting should also be included\n(D) when a user filters on any status that\'s not in the official list,\nthey should get an empty list of volumes (need to verify that\'s the\ncurrent behavior, but I\'m pretty sure that if you GET\n/v3/v3/{project_id}/volumes/detail?status=not-a-status you get the\nresponse { ""volumes"": [] }, not a 400). Currently we rely on the\ndatabase for this, but we may need to handle it in the REST API layer.\n(E) fixing the ""like"" operator from microversion 3.34 is going to be\ntricky. ?status~=error should include volumes in statuses error,\nerror_deleting, error_backing-up, error_restoring, and error_extending\n(and error_managing), but NOT include volumes with status\nerror_managing_deleting. ?status~=creating should include volumes with\n(internal) status \'managing\'. ?status~=deleting should include volumes\nwith internal status \'error_managing_deleting\', but not include error_deleting.\n\nPartially-Implements: blueprint volume-list-query-optimization\n\nChange-Id: I7325307d58e93f219e9a24529d90680141b165a4\n'}]",1,740152,c79b672806cd9854070784bdad533933d95f6cc6,179,42,2,30407,,,0,"volume list query optimization

When we fail to manage a volume, we use cinder list to view the volume
list, or use cinder show to view the volume details, We can see that the
volume state is error.
But when we filter the list of volumes by specifying the status as
error,We found that there were no manage failed volumes in the
screening results,this will confuse the user.
so what needs to be fixed?

(A) when a user filters on status=error, volumes in (internal) status
error_managing should also be included
(B) when a user filters on status=creating, volumes in (internal) status
managing should also be included
(C) when a user filters on status=deleting, volumes in (internal) status
error_managing_deleting should also be included
(D) when a user filters on any status that's not in the official list,
they should get an empty list of volumes (need to verify that's the
current behavior, but I'm pretty sure that if you GET
/v3/v3/{project_id}/volumes/detail?status=not-a-status you get the
response { ""volumes"": [] }, not a 400). Currently we rely on the
database for this, but we may need to handle it in the REST API layer.
(E) fixing the ""like"" operator from microversion 3.34 is going to be
tricky. ?status~=error should include volumes in statuses error,
error_deleting, error_backing-up, error_restoring, and error_extending
(and error_managing), but NOT include volumes with status
error_managing_deleting. ?status~=creating should include volumes with
(internal) status 'managing'. ?status~=deleting should include volumes
with internal status 'error_managing_deleting', but not include error_deleting.

Partially-Implements: blueprint volume-list-query-optimization

Change-Id: I7325307d58e93f219e9a24529d90680141b165a4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/740152/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v2/volumes.py', 'cinder/objects/fields.py', 'releasenotes/notes/bp-volume-list-query-optimization-ddebc9df5919e887.yaml', 'cinder/db/sqlalchemy/api.py']",4,6515daabddd9a008c16d9a8debb48762143accf3,bp/volume-list-query-optimization," original_query = query if model == models.Volume: if key == 'status': if value == 'error': # should not include error_managing_deleting query = query.filter( model.status != 'error_managing_deleting') if value == 'creating': query = original_query.filter(or_( models.Volume.status == 'creating', models.Volume.status == 'managing')) if value == 'deleting': # should not include error_deleting query = original_query.filter(or_( models.Volume.status == 'deleting', models.Volume.status == 'error_managing_deleting')) elif key == 'status' and value == 'error': # we need to include error_managing here. query = query.filter(or_(models.Volume.status == 'error', models.Volume.status == 'error_managing')) elif key == 'status' and value == 'creating': # we need to include managing here. query = query.filter(or_(models.Volume.status == 'creating', models.Volume.status == 'managing')) elif key == 'status' and value == 'deleting': # we need to include error_managing_deleting here. query = query.filter(or_( models.Volume.status == 'deleting', models.Volume.status == 'error_managing_deleting'))",,90,2
openstack%2Fceilometer~master~I52455c85b5cb50e9c4f1fdf5538965dc200065aa,openstack/ceilometer,master,I52455c85b5cb50e9c4f1fdf5538965dc200065aa,Using Iterable was deprecated in python 3.3,MERGED,2021-02-02 12:34:46.000000000,2021-02-07 03:44:19.000000000,2021-02-07 03:42:49.000000000,"[{'_account_id': 14107}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 12:34:46.000000000', 'files': ['ceilometer/compute/pollsters/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ec08228a1b0fb09b0d75b2ca41459558c6ec0a71', 'message': 'Using Iterable was deprecated in python 3.3\n\nand one should use collections.abc.Iterable\n\nChange-Id: I52455c85b5cb50e9c4f1fdf5538965dc200065aa\n'}]",0,773652,ec08228a1b0fb09b0d75b2ca41459558c6ec0a71,8,3,1,4264,,,0,"Using Iterable was deprecated in python 3.3

and one should use collections.abc.Iterable

Change-Id: I52455c85b5cb50e9c4f1fdf5538965dc200065aa
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/52/773652/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/compute/pollsters/__init__.py'],1,ec08228a1b0fb09b0d75b2ca41459558c6ec0a71,iterable," if isinstance(result, collections.abc.Iterable):"," if isinstance(result, collections.Iterable):",1,1
openstack%2Fmurano~master~Id2364b046080c50e122f89d0a7b2d914b1bedbfd,openstack/murano,master,Id2364b046080c50e122f89d0a7b2d914b1bedbfd,Fix lower-constraints,MERGED,2021-01-19 07:51:24.000000000,2021-02-07 03:33:00.000000000,2021-02-07 03:31:41.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-19 07:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/93f5c96c46d37e34832fb0b63cf4b34f5e5d4d26', 'message': 'Fix lower-constraints\n\nThe lower-constraints job is currently broken since the new\nrelease of pip. This patch resolves all of the issues uncovered\nby the new version of pip.\n\nChange-Id: Id2364b046080c50e122f89d0a7b2d914b1bedbfd\n'}, {'number': 2, 'created': '2021-01-19 08:01:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/7dd31ad63b4ad5d86d747dbc0e3de18f4a768199', 'message': 'Fix lower-constraints\n\nThe lower-constraints job is currently broken since the new\nrelease of pip. This patch resolves all of the issues uncovered\nby the new version of pip.\n\nWe also add new constraints to fix slow installations\ndue to pip trying to resolve the ideal candidates.\n\nChange-Id: Id2364b046080c50e122f89d0a7b2d914b1bedbfd\n'}]",0,771374,7dd31ad63b4ad5d86d747dbc0e3de18f4a768199,10,2,2,22623,,,0,"Fix lower-constraints

The lower-constraints job is currently broken since the new
release of pip. This patch resolves all of the issues uncovered
by the new version of pip.

We also add new constraints to fix slow installations
due to pip trying to resolve the ideal candidates.

Change-Id: Id2364b046080c50e122f89d0a7b2d914b1bedbfd
",git fetch https://review.opendev.org/openstack/murano refs/changes/74/771374/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,93f5c96c46d37e34832fb0b63cf4b34f5e5d4d26,fix_gate,alembic==0.9.6 amqp==2.5.2attrs==17.4.0flake8==3.7.9httplib2==0.9.1 hacking==3.0.1keystoneauth1==3.8.0mccabe==0.6.0msgpack-python==0.5.6openstacksdk==0.17.0osc-lib==1.14.0oslo.service==1.31.0positional==1.2.1pyflakes==2.1.0pyrsistent==0.15.7python-cinderclient==3.3.0python-keystoneclient==3.17.0python-novaclient==15.0.0 python-openstackclient==4.0.0warlock==1.3.1,alembic==0.8.10 amqp==2.2.2flake8==2.5.5hacking==0.12.0keystoneauth1==3.4.0mccabe==0.2.1msgpack==0.5.6openstacksdk==0.12.0stestr==1.0.0 osc-lib==1.10.0oslo.service==1.24.0pyflakes==0.8.1python-keystoneclient==3.8.0warlock==1.3.0,24,18
openstack%2Fsolum~master~Ie325affdb24ba01e762f0832db80e0c46e635f60,openstack/solum,master,Ie325affdb24ba01e762f0832db80e0c46e635f60,Fix broken CI and lower-constraints,MERGED,2021-01-16 21:52:17.000000000,2021-02-07 03:26:58.000000000,2021-02-07 03:25:32.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-16 21:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8e644d0affb9638f1c74c03ac25ae319ed22b61b', 'message': 'Fix broken CI\n\nWe need to monkey patch the tests to make sure\nwe get the same order of operations as we would\nwhen running the service.\n\nChange-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60\n'}, {'number': 2, 'created': '2021-01-16 22:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d49e3381e6a956de8b17ded86ca8a6ad032bbd3b', 'message': 'Fix broken CI and lower-constraints\n\nWe need to monkey patch the tests to make sure\nwe get the same order of operations as we would\nwhen running the service.\n\nThis patch also fixes issues with lower-constraints. I based\nthe fix on the same fix as I did for Designate and Senlin.\n\nChange-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60\n'}, {'number': 3, 'created': '2021-01-16 23:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/46ab8ce6d3a244465ff40db6544ba786659d53d9', 'message': 'Fix broken CI and lower-constraints\n\nWe need to monkey patch the tests to make sure\nwe get the same order of operations as we would\nwhen running the service.\n\nThis patch also fixes issues with lower-constraints. I based\nthe fix on the same fix as I did for Designate and Senlin.\n\nChange-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60\n'}, {'number': 4, 'created': '2021-01-16 23:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2780a964f7ae15cbb0c1efd610ef3b67c1acd137', 'message': 'Fix broken CI and lower-constraints\n\nWe need to monkey patch the tests to make sure\nwe get the same order of operations as we would\nwhen running the service.\n\nThis patch also fixes issues with lower-constraints. I based\nthe fix on the same fix as I did for Designate and Senlin.\n\nChange-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60\n'}, {'number': 5, 'created': '2021-01-16 23:07:45.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'solum/tests/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/solum/commit/e70179000dcef97af1378ad01b8c38d44b8a2742', 'message': 'Fix broken CI and lower-constraints\n\nWe need to monkey patch the tests to make sure\nwe get the same order of operations as we would\nwhen running the service.\n\nThis patch also fixes issues with lower-constraints. I based\nthe fix on the same fix as I did for Designate and Senlin.\n\nChange-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60\n'}]",0,771112,e70179000dcef97af1378ad01b8c38d44b8a2742,13,2,5,22623,,,0,"Fix broken CI and lower-constraints

We need to monkey patch the tests to make sure
we get the same order of operations as we would
when running the service.

This patch also fixes issues with lower-constraints. I based
the fix on the same fix as I did for Designate and Senlin.

Change-Id: Ie325affdb24ba01e762f0832db80e0c46e635f60
",git fetch https://review.opendev.org/openstack/solum refs/changes/12/771112/4 && git format-patch -1 --stdout FETCH_HEAD,['solum/tests/__init__.py'],1,8e644d0affb9638f1c74c03ac25ae319ed22b61b,fix_gate,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet eventlet.monkey_patch(os=False) ",,14,0
openstack%2Ffreezer~master~I3db2a946d0950c9b01ee8912c43f7704ffd97c5d,openstack/freezer,master,I3db2a946d0950c9b01ee8912c43f7704ffd97c5d,add test_runningstate_remove for unit test,MERGED,2021-02-07 01:48:42.000000000,2021-02-07 03:08:23.000000000,2021-02-07 03:07:10.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 01:48:42.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/97236a160994f139ca1302bb7cd5d68bacc7c15f', 'message': 'add test_runningstate_remove for unit test\n\nChange-Id: I3db2a946d0950c9b01ee8912c43f7704ffd97c5d\n'}]",0,774363,97236a160994f139ca1302bb7cd5d68bacc7c15f,7,2,1,21387,,,0,"add test_runningstate_remove for unit test

Change-Id: I3db2a946d0950c9b01ee8912c43f7704ffd97c5d
",git fetch https://review.opendev.org/openstack/freezer refs/changes/63/774363/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,97236a160994f139ca1302bb7cd5d68bacc7c15f,improveUTC4," def test_runningstate_abort(self): result = scheduler_job.RunningState.abort(self.job, self.jobdoc) self.assertEqual(result, 'aborted') def test_runningstate_start(self): result = scheduler_job.RunningState.start(self.job, self.jobdoc) self.assertEqual(result, '') def test_runningstate_remove(self): result = scheduler_job.RunningState.remove(self.job) self.assertEqual(result, '')",,12,0
openstack%2Fyaql~master~Ib07d778a01275d7c985e059156e95abc112e81c8,openstack/yaql,master,Ib07d778a01275d7c985e059156e95abc112e81c8,Switch to collections.abc.*,MERGED,2021-02-01 10:34:25.000000000,2021-02-07 02:47:11.000000000,2021-02-07 02:47:11.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-01 10:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/01af8f37e18fafa3456831609aaa98ebe70bae61', 'message': ""Switch to collections.abc.*\n\nThe abstract base classes previously defined in 'collections' were moved\nto 'collections.abc' in 3.3. The aliases will be removed in 3.10.\nPreempt this change now with a simple find-replace:\n\n  $ ag -l 'collections.($TYPES)' | \\\n      xargs sed -i 's/\\(collections\\)\\.\\($TYPES\\)/\\1.abc.\\2/g'\n\nWhere $TYPES is the list of moved ABCs from [1].\n\n[1] https://docs.python.org/3/library/collections.abc.html\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib07d778a01275d7c985e059156e95abc112e81c8\n""}, {'number': 2, 'created': '2021-02-01 10:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/d4285cae091f0620aeec194e3ee89f330251006b', 'message': ""Switch to collections.abc.*\n\nThe abstract base classes previously defined in 'collections' were moved\nto 'collections.abc' in 3.3. The aliases will be removed in 3.10.\nPreempt this change now with a simple find-replace:\n\n  $ ag -l 'collections.($TYPES)' | \\\n      xargs sed -i 's/\\(collections\\)\\.\\($TYPES\\)/\\1.abc.\\2/g'\n\nWhere $TYPES is the list of moved ABCs from [1].\n\n[1] https://docs.python.org/3/library/collections.abc.html\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib07d778a01275d7c985e059156e95abc112e81c8\n""}, {'number': 3, 'created': '2021-02-01 11:11:35.000000000', 'files': ['yaql/language/utils.py', 'yaql/language/yaqltypes.py', 'yaql/standard_library/queries.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/c3bda9eeb1d802cd95b3120925d3786a4f060025', 'message': ""Switch to collections.abc.*\n\nThe abstract base classes previously defined in 'collections' were moved\nto 'collections.abc' in 3.3. The aliases will be removed in 3.10.\nPreempt this change now with a simple find-replace:\n\n  $ ag -l 'collections.($TYPES)' | \\\n      xargs sed -i 's/\\(collections\\)\\.\\($TYPES\\)/\\1.abc.\\2/g'\n\nWhere $TYPES is the list of moved ABCs from [1].\n\n[1] https://docs.python.org/3/library/collections.abc.html\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib07d778a01275d7c985e059156e95abc112e81c8\n""}]",1,773350,c3bda9eeb1d802cd95b3120925d3786a4f060025,10,2,3,15334,,,0,"Switch to collections.abc.*

The abstract base classes previously defined in 'collections' were moved
to 'collections.abc' in 3.3. The aliases will be removed in 3.10.
Preempt this change now with a simple find-replace:

  $ ag -l 'collections.($TYPES)' | \
      xargs sed -i 's/\(collections\)\.\($TYPES\)/\1.abc.\2/g'

Where $TYPES is the list of moved ABCs from [1].

[1] https://docs.python.org/3/library/collections.abc.html

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: Ib07d778a01275d7c985e059156e95abc112e81c8
",git fetch https://review.opendev.org/openstack/yaql refs/changes/50/773350/1 && git format-patch -1 --stdout FETCH_HEAD,"['yaql/language/utils.py', 'yaql/language/yaqltypes.py', 'yaql/standard_library/queries.py']",3,01af8f37e18fafa3456831609aaa98ebe70bae61,collections.abc," isinstance(result, collections.abc.Sequence) and"," isinstance(result, collections.Sequence) and",19,19
openstack%2Fyaql~master~I2f37e055838ea50627562d3585d6951f8d8d46aa,openstack/yaql,master,I2f37e055838ea50627562d3585d6951f8d8d46aa,Remove six,MERGED,2021-02-01 10:34:25.000000000,2021-02-07 02:47:07.000000000,2021-02-07 02:47:07.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-01 10:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/6bba3de4024495bdc3cf1e25bba0ab171b38132d', 'message': 'Remove six\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I2f37e055838ea50627562d3585d6951f8d8d46aa\n'}, {'number': 2, 'created': '2021-02-01 10:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/2d3046b47bde0615e261d00feb58475cc663343f', 'message': 'Remove six\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I2f37e055838ea50627562d3585d6951f8d8d46aa\n'}, {'number': 3, 'created': '2021-02-01 11:11:35.000000000', 'files': ['yaql/standard_library/regex.py', 'yaql/language/lexer.py', 'requirements.txt', 'yaql/language/specs.py', 'yaql/language/utils.py', 'yaql/standard_library/math.py', 'yaql/standard_library/yaqlized.py', 'doc/source/_exts/yaqlautodoc.py', 'yaql/standard_library/queries.py', 'yaql/language/parser.out', 'yaql/standard_library/collections.py', 'yaql/standard_library/legacy.py', 'yaql/yaql_interface.py', 'yaql/cli/cli_functions.py', 'yaql/language/parser.py', 'yaql/tests/test_type_aggregation.py', 'yaql/language/expressions.py', 'yaql/language/runner.py', 'yaql/standard_library/strings.py', 'yaql/language/conventions.py', 'yaql/standard_library/system.py', 'yaql/tests/test_engine.py', 'yaql/language/contexts.py', 'yaql/language/yaqltypes.py', 'yaql/yaqlization.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/4670f0949c349a162cf48b0aad30a98eabbaff7f', 'message': 'Remove six\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I2f37e055838ea50627562d3585d6951f8d8d46aa\n'}]",3,773349,4670f0949c349a162cf48b0aad30a98eabbaff7f,10,2,3,15334,,,0,"Remove six

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: I2f37e055838ea50627562d3585d6951f8d8d46aa
",git fetch https://review.opendev.org/openstack/yaql refs/changes/49/773349/3 && git format-patch -1 --stdout FETCH_HEAD,"['yaql/standard_library/regex.py', 'yaql/language/lexer.py', 'requirements.txt', 'yaql/language/specs.py', 'yaql/language/utils.py', 'yaql/standard_library/math.py', 'yaql/standard_library/yaqlized.py', 'doc/source/_exts/yaqlautodoc.py', 'yaql/standard_library/queries.py', 'yaql/standard_library/collections.py', 'yaql/standard_library/legacy.py', 'yaql/yaql_interface.py', 'yaql/cli/cli_functions.py', 'yaql/language/parser.py', 'yaql/tests/test_type_aggregation.py', 'yaql/language/expressions.py', 'yaql/language/runner.py', 'yaql/standard_library/strings.py', 'yaql/language/conventions.py', 'yaql/standard_library/system.py', 'yaql/tests/test_engine.py', 'yaql/language/contexts.py', 'yaql/language/yaqltypes.py', 'yaql/yaqlization.py']",24,6bba3de4024495bdc3cf1e25bba0ab171b38132d,collections.abc," for value in attribute_remapping.values: if not isinstance(value, str):","import six for value in six.itervalues(attribute_remapping): if not isinstance(value, six.string_types):",173,273
openstack%2Fyaql~master~I450c062eed1185e7e4c49a156307abb4320f6cb6,openstack/yaql,master,I450c062eed1185e7e4c49a156307abb4320f6cb6,tox: Set 'ignore_basepython_conflict',MERGED,2021-02-01 10:55:54.000000000,2021-02-07 02:45:51.000000000,2021-02-07 02:45:51.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-01 10:55:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/yaql/commit/8fcac72fd36724aecaa2557332852fbfa67773dd', 'message': ""tox: Set 'ignore_basepython_conflict'\n\nEnsure we run with the versions of Python we expect to. Some other\ncruft is removed.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: I450c062eed1185e7e4c49a156307abb4320f6cb6\n""}]",0,773356,8fcac72fd36724aecaa2557332852fbfa67773dd,6,2,1,15334,,,0,"tox: Set 'ignore_basepython_conflict'

Ensure we run with the versions of Python we expect to. Some other
cruft is removed.

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: I450c062eed1185e7e4c49a156307abb4320f6cb6
",git fetch https://review.opendev.org/openstack/yaql refs/changes/56/773356/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8fcac72fd36724aecaa2557332852fbfa67773dd,collections.abc,minversion = 3.1ignore_basepython_conflict = True,minversion = 2.0install_command = pip install -U {opts} {packages} setenv = VIRTUAL_ENV={envdir},2,4
openstack%2Fmurano-dashboard~master~I425e9b4cfcf86e67c6288796e3da95b07769c6dc,openstack/murano-dashboard,master,I425e9b4cfcf86e67c6288796e3da95b07769c6dc,Add doc/requirements,MERGED,2021-01-07 14:32:45.000000000,2021-02-07 02:42:46.000000000,2021-02-07 02:40:56.000000000,"[{'_account_id': 841}, {'_account_id': 14107}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-01-07 14:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/fa15e6959d44a635c56c6ddb70766335b4133b11', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoving specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I425e9b4cfcf86e67c6288796e3da95b07769c6dc\n""}, {'number': 2, 'created': '2021-02-03 12:22:37.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7d710044b6d89600fcec73e5b48b146689cca255', 'message': ""Add doc/requirements\n\nWe need to specify doc requirements in doc/requirements.txt\nto avoid problems with the pip resolver [1] for the release team [2][3].\nRemoving specific doc requirements from test-requirements.txt.\n\nThe problem here is that this repos haven't doc/requirements.txt file\nand by default in this case zuul will use the test-requirements.txt file\nto pull requirements [4].\n\nThis requirements file contains extra requirements like flake8 that\ncollided with those allowed in our job environment and so the new pip\nresolver fails to install these requirements and the job exits in error.\nIt also update horizon version in requirements.txt to match the horizon\nversion in  lower-constriants.txt to fix requirements-check job.\n\nThis project meet the conditions leading to the bug.\n\n[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html\n[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36\n\nChange-Id: I425e9b4cfcf86e67c6288796e3da95b07769c6dc\n""}]",0,769756,7d710044b6d89600fcec73e5b48b146689cca255,18,4,2,28522,,,0,"Add doc/requirements

We need to specify doc requirements in doc/requirements.txt
to avoid problems with the pip resolver [1] for the release team [2][3].
Removing specific doc requirements from test-requirements.txt.

The problem here is that this repos haven't doc/requirements.txt file
and by default in this case zuul will use the test-requirements.txt file
to pull requirements [4].

This requirements file contains extra requirements like flake8 that
collided with those allowed in our job environment and so the new pip
resolver fails to install these requirements and the job exits in error.
It also update horizon version in requirements.txt to match the horizon
version in  lower-constriants.txt to fix requirements-check job.

This project meet the conditions leading to the bug.

[1] http://lists.openstack.org/pipermail/release-job-failures/2021-January/001500.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019611.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019612.html
[4] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-sphinx/tasks/main.yaml#L36

Change-Id: I425e9b4cfcf86e67c6288796e3da95b07769c6dc
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/56/769756/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'tox.ini']",3,fa15e6959d44a635c56c6ddb70766335b4133b11,fix-relmgt-pip-doc,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt[testenv:releasenotes] deps = {[testenv:docs]deps} commands = sphinx-build -a -E -W -d releasenotes/build/doctrees -b html releasenotes/source releasenotes/build/html ,[testenv:releasenotes] commands = sphinx-build -a -E -W -d releasenotes/build/doctrees -b html releasenotes/source releasenotes/build/html ,9,9
openstack%2Fsolum-dashboard~master~Ided45f20b4d30f9c655d1745bbcc8f57e875ff9f,openstack/solum-dashboard,master,Ided45f20b4d30f9c655d1745bbcc8f57e875ff9f,Fix lower-constraints job,MERGED,2021-02-03 13:25:22.000000000,2021-02-07 02:40:37.000000000,2021-02-07 02:40:37.000000000,"[{'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 13:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/8a072f2cb41b3ded82ba65acce4801dd0096d58f', 'message': '[DNR] Test lower-constraints job\n\nChange-Id: Ided45f20b4d30f9c655d1745bbcc8f57e875ff9f\n'}, {'number': 2, 'created': '2021-02-03 14:36:27.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/a9330963c82dd78585e03b79db79165d1c3124d3', 'message': ""Fix lower-constraints job\n\nThis patch bump few packages version in 'lower-constraints.txt'\nto fix the CI.\n\nChange-Id: Ided45f20b4d30f9c655d1745bbcc8f57e875ff9f\n""}]",0,773887,a9330963c82dd78585e03b79db79165d1c3124d3,8,2,2,29313,,,0,"Fix lower-constraints job

This patch bump few packages version in 'lower-constraints.txt'
to fix the CI.

Change-Id: Ided45f20b4d30f9c655d1745bbcc8f57e875ff9f
",git fetch https://review.opendev.org/openstack/solum-dashboard refs/changes/87/773887/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,8a072f2cb41b3ded82ba65acce4801dd0096d58f,,decorator==4.4.1keystoneauth1==3.18.0mccabe==0.6.0os-service-types==1.7.0pyflakes==2.1.0,decorator==4.2.1keystoneauth1==3.4.0mccabe==0.2.1os-service-types==1.2.0pyflakes==0.8.1,5,5
openstack%2Fnova~master~I9335ddb2d72909a110c313d5b609f2be279b18ef,openstack/nova,master,I9335ddb2d72909a110c313d5b609f2be279b18ef,Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API,MERGED,2021-01-08 22:55:39.000000000,2021-02-07 01:46:03.000000000,2021-02-05 04:12:43.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2021-01-08 22:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d174dcec366ed98bf20ecd6a015f561f088008d', 'message': 'Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API\n\nForbiddenWithAccelerators is not converted to HTTPForbidden unless\nthat is explicitly converted in API controller. For example:\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/compute/migrate_server.py#L154\n\nOtherwise it end up raising 500 because ForbiddenWithAccelerators is\nnot inherrited from nova.exception.Forbidden\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/exception.py#L158\n\nand expected_errors() decorator convert it to 500.\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/wsgi.py#L689\n\nExcept shelve API, all other APIs which can get\nForbiddenWithAccelerators via block_accelerators decorator convert it\nexplicitly.\n\nIf we inherit ForbiddenWithAccelerators from nova.exception.Forbidden\nthen expected_errors() decorator will take care of convertion to\nHTTPForbidden automatically for all APIs.\n\nAlso adding tests for APIs can get ForbiddenWithAccelerators.\n\nChange-Id: I9335ddb2d72909a110c313d5b609f2be279b18ef\n'}, {'number': 2, 'created': '2021-01-10 17:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47c7d7f910dee3cc171b3e09e89d27f8cdfd47d1', 'message': 'Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API\n\nForbiddenWithAccelerators is not converted to HTTPForbidden unless\nthat is explicitly converted in API controller. For example:\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/compute/migrate_server.py#L154\n\nOtherwise it end up raising 500 because ForbiddenWithAccelerators is\nnot inherrited from nova.exception.Forbidden\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/exception.py#L158\n\nand expected_errors() decorator convert it to 500.\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/wsgi.py#L689\n\nExcept shelve API, all other APIs which can get\nForbiddenWithAccelerators via block_accelerators decorator convert it\nexplicitly.\n\nIf we inherit ForbiddenWithAccelerators from nova.exception.Forbidden\nthen expected_errors() decorator will take care of convertion to\nHTTPForbidden automatically for all APIs.\n\nAlso adding tests for APIs can get ForbiddenWithAccelerators.\n\nChange-Id: I9335ddb2d72909a110c313d5b609f2be279b18ef\n'}, {'number': 3, 'created': '2021-01-10 17:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2237bac6c3db71ca8e4508458b35ab0a9831275', 'message': 'Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API\n\nForbiddenWithAccelerators is not converted to HTTPForbidden unless\nthat is explicitly converted in API controller. For example:\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/compute/migrate_server.py#L154\n\nOtherwise it end up raising 500 because ForbiddenWithAccelerators is\nnot inherrited from nova.exception.Forbidden\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/exception.py#L158\n\nand expected_errors() decorator convert it to 500.\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/wsgi.py#L689\n\nExcept shelve API, all other APIs which can get\nForbiddenWithAccelerators via block_accelerators decorator convert it\nexplicitly.\n\nIf we inherit ForbiddenWithAccelerators from nova.exception.Forbidden\nthen expected_errors() decorator will take care of convertion to\nHTTPForbidden automatically for all APIs.\n\nAlso adding tests for APIs can get ForbiddenWithAccelerators.\n\nChange-Id: I9335ddb2d72909a110c313d5b609f2be279b18ef\n'}, {'number': 4, 'created': '2021-01-26 00:51:27.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/tests/unit/api/openstack/compute/test_suspend_server.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cb56ae6aad274ba0cef8b97dcc2130e114260db2', 'message': 'Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API\n\nForbiddenWithAccelerators is not converted to HTTPForbidden unless\nthat is explicitly converted in API controller. For example:\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/compute/migrate_server.py#L154\n\nOtherwise it end up raising 500 because ForbiddenWithAccelerators is\nnot inherrited from nova.exception.Forbidden\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/exception.py#L158\n\nand expected_errors() decorator convert it to 500.\n- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/wsgi.py#L689\n\nExcept shelve API, all other APIs which can get\nForbiddenWithAccelerators via block_accelerators decorator convert it\nexplicitly.\n\nIf we inherit ForbiddenWithAccelerators from nova.exception.Forbidden\nthen expected_errors() decorator will take care of convertion to\nHTTPForbidden automatically for all APIs.\n\nAlso adding tests for APIs can get ForbiddenWithAccelerators.\n\nChange-Id: I9335ddb2d72909a110c313d5b609f2be279b18ef\n'}]",6,770007,cb56ae6aad274ba0cef8b97dcc2130e114260db2,37,7,4,8556,,,0,"Fix ForbiddenWithAccelerators to HTTPForbidden for shelve API

ForbiddenWithAccelerators is not converted to HTTPForbidden unless
that is explicitly converted in API controller. For example:
- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/compute/migrate_server.py#L154

Otherwise it end up raising 500 because ForbiddenWithAccelerators is
not inherrited from nova.exception.Forbidden
- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/exception.py#L158

and expected_errors() decorator convert it to 500.
- https://github.com/openstack/nova/blob/46899968619e4ea0ff2ab380977619bb29578d43/nova/api/openstack/wsgi.py#L689

Except shelve API, all other APIs which can get
ForbiddenWithAccelerators via block_accelerators decorator convert it
explicitly.

If we inherit ForbiddenWithAccelerators from nova.exception.Forbidden
then expected_errors() decorator will take care of convertion to
HTTPForbidden automatically for all APIs.

Also adding tests for APIs can get ForbiddenWithAccelerators.

Change-Id: I9335ddb2d72909a110c313d5b609f2be279b18ef
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/770007/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/tests/unit/api/openstack/compute/test_suspend_server.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py']",4,8d174dcec366ed98bf20ecd6a015f561f088008d,," @mock.patch('nova.compute.api.API.live_migrate', side_effect=exception.ForbiddenWithAccelerators) def test_live_migration_raises_http_forbidden(self, mock_migrate): body = self._get_migration_body(host='hostname') self.assertRaises(webob.exc.HTTPForbidden, self.controller._migrate_live, self.req, fakes.FAKE_UUID, body=body) ",,38,0
openstack%2Ffreezer~master~I33388d127121cc8e017f9db7209ad03773098929,openstack/freezer,master,I33388d127121cc8e017f9db7209ad03773098929,add test_runningstate_stop for unit test,MERGED,2021-02-07 00:11:10.000000000,2021-02-07 01:44:37.000000000,2021-02-07 01:43:09.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-07 00:11:10.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/8b26e2738bf7abac57497af896dcac896caf3b16', 'message': 'add test_runningstate_stop for unit test\n\nChange-Id: I33388d127121cc8e017f9db7209ad03773098929\n'}]",0,774361,8b26e2738bf7abac57497af896dcac896caf3b16,7,2,1,21387,,,0,"add test_runningstate_stop for unit test

Change-Id: I33388d127121cc8e017f9db7209ad03773098929
",git fetch https://review.opendev.org/openstack/freezer refs/changes/61/774361/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,8b26e2738bf7abac57497af896dcac896caf3b16,improveUTC3," def test_scheduledstate_remove(self): result = scheduler_job.ScheduledState.remove(self.job) self.assertEqual(result, '') def test_runningstate_stop(self): result = scheduler_job.RunningState.stop(self.job, {}) self.assertEqual(result, '')",,8,0
openstack%2Fnova~master~I51f6da50ac349c78c5bf3d7847b0b34526872cd4,openstack/nova,master,I51f6da50ac349c78c5bf3d7847b0b34526872cd4,pci: Improve testing of 'nova.pci.request' module,MERGED,2020-11-27 11:35:19.000000000,2021-02-06 20:41:17.000000000,2021-02-05 04:14:02.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 11:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f2e2914b3a04929f5be0328bcde648f2fa9a274', 'message': ""pci: Improve testing of 'nova.pci.request' module\n\nThe tests for this were a bit of a mess and fairly indecipherable.\nImprove them by reducing duplication, using better test function names\nand closing some small coverage gaps.\n\nChange-Id: I51f6da50ac349c78c5bf3d7847b0b34526872cd4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-11-27 17:56:31.000000000', 'files': ['nova/pci/request.py', 'nova/tests/unit/pci/test_request.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/671dc5bfe8ae09788e4c7b301b9a069e869b9f7b', 'message': ""pci: Improve testing of 'nova.pci.request' module\n\nThe tests for this were a bit of a mess and fairly indecipherable.\nImprove them by reducing duplication, using better test function names\nand closing some small coverage gaps.\n\nChange-Id: I51f6da50ac349c78c5bf3d7847b0b34526872cd4\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,764446,671dc5bfe8ae09788e4c7b301b9a069e869b9f7b,24,4,2,15334,,,0,"pci: Improve testing of 'nova.pci.request' module

The tests for this were a bit of a mess and fairly indecipherable.
Improve them by reducing duplication, using better test function names
and closing some small coverage gaps.

Change-Id: I51f6da50ac349c78c5bf3d7847b0b34526872cd4
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/764446/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/request.py', 'nova/tests/unit/pci/test_request.py']",2,0f2e2914b3a04929f5be0328bcde648f2fa9a274,bug/1852727,"from oslo_serialization import jsonutils_fake_alias1 = jsonutils.dumps({ ""name"": ""QuickAssist"", ""capability_type"": ""pci"", ""product_id"": ""4443"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"", ""numa_policy"": ""legacy"", }) _fake_alias2 = jsonutils.dumps({ ""name"": ""IntelNIC"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""type-PF"", }) def test_get_alias_from_config_valid(self): self.assertEqual(expected_result, result['QuickAssist']) def test_get_alias_from_config_valid_multispec(self): _fake_alias = jsonutils.dumps({ ""name"": ""QuickAssist"", ""capability_type"": ""pci"", ""product_id"": ""4444"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"", }) self.flags(alias=[_fake_alias1, _fake_alias], group='pci') self.assertEqual(expected_result, result['QuickAssist']) def _test_get_alias_from_config_invalid(self, alias): self.flags(alias=[alias], group='pci') self.assertRaises( exception.PciInvalidAlias, def test_get_alias_from_config_invalid_device_type(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""device_type"": ""N"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_invalid_product_id(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""product_id"": ""g111"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_invalid_vendor_id(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""vendor_id"": ""0xg111"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_invalid_capability_type(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""capability_type"": ""usb"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_invalid_numa_policy(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""numa_policy"": ""derp"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_invalid_arbitrary_field(self): fake_alias = jsonutils.dumps({ ""name"": ""xxx"", ""foo"": ""bar"", }) self._test_get_alias_from_config_invalid(fake_alias) def test_get_alias_from_config_valid_numa_policy(self): for policy in fields.PCINUMAAffinityPolicy.ALL: fake_alias = jsonutils.dumps({ ""numa_policy"": policy, }) self.flags(alias=[fake_alias], group='pci') def test_get_alias_from_config_conflicting_device_type(self): fake_alias_a = jsonutils.dumps({ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""type-PF"" }) fake_alias_b = jsonutils.dumps({ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"" }) self.flags(alias=[fake_alias_a, fake_alias_b], group='pci') def test_get_alias_from_config_conflicting_numa_policy(self): fake_alias_a = jsonutils.dumps({ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""numa_policy"": ""required"", }) fake_alias_b = jsonutils.dumps({ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""numa_policy"": ""legacy"", }) self.flags(alias=[fake_alias_a, fake_alias_b], group='pci') def test_translate_alias_to_requests(self): self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') 'alias_name': 'QuickAssist'}, ""QuickAssist : 3, IntelNIC: 1"") def test_translate_alias_to_requests_invalid(self): self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') ""QuickAssistX : 3"") def test_translate_alias_to_requests_affinity_policy(self): # _fake_alias1 requests the legacy policy and _fake_alias2 self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') 'alias_name': 'QuickAssist', ""QuickAssist : 3, IntelNIC: 1"", affinity_policy=policy) mock_inst_cn = mock.Mock() mock_inst_cn.id = 1 cn_get_by_host_and_node.return_value = mock_inst_cn mock_inst_cn = mock.Mock() mock_inst_cn.id = 1 cn_get_by_host_and_node.return_value = mock_inst_cn mock_inst_cn.id = 2 self.flags(alias=[_fake_alias1], group='pci') expect_request = [ { 'count': 3, 'spec': [ { 'vendor_id': '8086', 'product_id': '4443', 'dev_type': ""type-PCI"", 'capability_type': 'pci', } ], 'alias_name': 'QuickAssist' }, ] flavor = {'extra_specs': {'pci_passthrough:alias': 'QuickAssist:3'}} requests = request.get_pci_requests_from_flavor(flavor) self.assertEqual(1, len(requests.requests)) self.assertEqual({3, }, {p.count for p in requests.requests}) self._verify_result(expect_request, requests.requests) def test_get_pci_requests_from_flavor_multiple(self): self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') 'alias_name': 'QuickAssist'}, ""QuickAssist:3, IntelNIC: 1""}} self.assertEqual(2, len(requests.requests)) self.assertEqual({3, 1}, {p.count for p in requests.requests}) _fake_alias4 = jsonutils.dumps({ ""name"": "" Cirrus Logic "", ""capability_type"": ""pci"", ""product_id"": ""0ff2"", ""vendor_id"": ""10de"", ""device_type"": ""type-PCI"", }) self.flags(alias=[_fake_alias2, _fake_alias4], group='pci') self.assertEqual(2, len(requests.requests)) self.assertEqual({3, 4}, {p.count for p in requests.requests}) self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') self.flags(alias=[_fake_alias1, _fake_alias2], group='pci') flavor = {'extra_specs': {""pci_passthrough:alias"": ""QuickAssist:3, IntelNIC: 1""}}","_fake_alias1 = """"""{ ""name"": ""QuicAssist"", ""capability_type"": ""pci"", ""product_id"": ""4443"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"", ""numa_policy"": ""legacy"" }"""""" _fake_alias11 = """"""{ ""name"": ""QuicAssist"", ""capability_type"": ""pci"", ""product_id"": ""4444"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"" }"""""" _fake_alias2 = """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""1111"", ""device_type"": ""N"" }"""""" _fake_alias3 = """"""{ ""name"": ""IntelNIC"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""type-PF"" }"""""" _fake_alias4 = """"""{ ""name"": "" Cirrus Logic "", ""capability_type"": ""pci"", ""product_id"": ""0ff2"", ""vendor_id"": ""10de"", ""device_type"": ""type-PCI"" }"""""" self.mock_inst_cn = mock.Mock() def test_valid_alias(self): self.assertEqual(expected_result, result['QuicAssist']) def test_valid_multispec_alias(self): self.flags(alias=[_fake_alias1, _fake_alias11], group='pci') self.assertEqual(expected_result, result['QuicAssist']) def test_invalid_type_alias(self): self.flags(alias=[_fake_alias2], group='pci') self.assertRaises(exception.PciInvalidAlias, def test_invalid_product_id_alias(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""g111"", ""vendor_id"": ""1111"", ""device_type"": ""NIC"" }""""""], group='pci') self.assertRaises(exception.PciInvalidAlias, request._get_alias_from_config) def test_invalid_vendor_id_alias(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""0xg111"", ""device_type"": ""NIC"" }""""""], group='pci') self.assertRaises(exception.PciInvalidAlias, request._get_alias_from_config) def test_invalid_cap_type_alias(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""usb"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""NIC"" }""""""], group='pci') self.assertRaises(exception.PciInvalidAlias, request._get_alias_from_config) def test_invalid_numa_policy(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""NIC"", ""numa_policy"": ""derp"" }""""""], group='pci') self.assertRaises(exception.PciInvalidAlias, request._get_alias_from_config) def test_valid_numa_policy(self): for policy in fields.PCINUMAAffinityPolicy.ALL: self.flags(alias=[ """"""{ ""numa_policy"": ""%s"" }"""""" % policy], group='pci') def test_conflicting_device_type(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""NIC"" }"""""", """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""device_type"": ""type-PCI"" }""""""], group='pci') def test_conflicting_numa_policy(self): self.flags(alias=[ """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""numa_policy"": ""required"", }"""""", """"""{ ""name"": ""xxx"", ""capability_type"": ""pci"", ""product_id"": ""1111"", ""vendor_id"": ""8086"", ""numa_policy"": ""legacy"", }""""""], group='pci') def test_alias_2_request(self): self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') 'alias_name': 'QuicAssist'}, ""QuicAssist : 3, IntelNIC: 1"") def test_alias_2_request_invalid(self): self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') ""QuicAssistX : 3"") def test_alias_2_request_affinity_policy(self): # _fake_alias1 requests the legacy policy and _fake_alias3 self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') 'alias_name': 'QuicAssist', ""QuicAssist : 3, IntelNIC: 1"", affinity_policy=policy) self.mock_inst_cn.id = 1 cn_get_by_host_and_node.return_value = self.mock_inst_cn self.mock_inst_cn.id = 1 cn_get_by_host_and_node.return_value = self.mock_inst_cn self.mock_inst_cn.id = 2 self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') 'alias_name': 'QuicAssist'}, ""QuicAssist:3, IntelNIC: 1""}} self.assertEqual(set([1, 3]), set([p.count for p in requests.requests])) self.flags(alias=[_fake_alias3, _fake_alias4], group='pci') self.assertEqual(set([3, 4]), set([p.count for p in requests.requests])) self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') self.flags(alias=[_fake_alias1, _fake_alias3], group='pci') flavor = {'extra_specs': {""pci_passthrough:alias"": ""QuicAssist:3, IntelNIC: 1""}}",171,168
openstack%2Fnova~master~Ib0c9229899e9a83992757270503e0e1a988f2402,openstack/nova,master,Ib0c9229899e9a83992757270503e0e1a988f2402,db: Compact Mitaka database migrations,MERGED,2020-10-15 11:17:29.000000000,2021-02-06 16:39:46.000000000,2021-02-06 16:38:08.000000000,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-10-15 11:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3d4538bcdfc0c7871fe661e76c29c11611f03ec', 'message': ""WIP: Compact pre-Newton database migrations\n\nCompact pre-Newton database migrations into a single migration,\n'319_mitaka.py'.\n\nPre-Newton users will now need to update to Mitaka before updating to\nNewton or later.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- TODO\n\nTODO: Still need to handle 318, 319\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-10-21 15:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9729c3a6b66356c5df3127781770a40b164c734', 'message': ""db: Compact Mitaka database migrations\n\nCompact Mitaka database migrations into a single migration,\n'319_mitaka.py'.\n\nUsers will now need to update to Mitaka before updating to Newton or\nlater.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- Add 'name', 'generation' and 'can_host' columns to\n  'resource_providers' table\n- Add unique constraint on 'name' column of 'resource_providers' table\n- Add index on 'name' column of 'resource_providers' table\n- Add 'resource_provider_aggregates' table\n\nSome tests that depended on some of these migrations are removed.\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-10-22 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a52032a6bc6a595fe71051be82e73424ade07197', 'message': ""db: Compact Mitaka database migrations\n\nCompact Mitaka database migrations into a single migration,\n'319_mitaka.py'.\n\nUsers will now need to update to Mitaka before updating to Newton or\nlater.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- Add 'name', 'generation' and 'can_host' columns to\n  'resource_providers' table\n- Add unique constraint on 'name' column of 'resource_providers' table\n- Add index on 'name' column of 'resource_providers' table\n- Add 'resource_provider_aggregates' table\n\nSome tests that depended on some of these migrations are removed.\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2020-10-23 10:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ead050328fce8c14831b973f5b3c122040cc7813', 'message': ""db: Compact Mitaka database migrations\n\nCompact Mitaka database migrations into a single migration,\n'319_mitaka.py'.\n\nUsers will now need to update to Mitaka before updating to Newton or\nlater.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- Add 'name', 'generation' and 'can_host' columns to\n  'resource_providers' table\n- Add unique constraint on 'name' column of 'resource_providers' table\n- Add index on 'name' column of 'resource_providers' table\n- Add 'resource_provider_aggregates' table\n\nSome tests that depended on some of these migrations are removed.\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2020-10-28 11:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc81e1ee059763875527a84ee6935d58ad5b4d55', 'message': ""db: Compact Mitaka database migrations\n\nCompact Mitaka database migrations into a single migration,\n'319_mitaka.py'.\n\nUsers will now need to update to Mitaka before updating to Newton or\nlater.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- Add 'name', 'generation' and 'can_host' columns to\n  'resource_providers' table\n- Add unique constraint on 'name' column of 'resource_providers' table\n- Add index on 'name' column of 'resource_providers' table\n- Add 'resource_provider_aggregates' table\n\nSome tests that depended on some of these migrations are removed.\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2021-01-07 11:47:59.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/319_add_instances_deleted_created_at_index.py', 'nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/305_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/307_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/313_add_parent_id_column.py', 'nova/tests/unit/test_fixtures.py', 'nova/db/sqlalchemy/migrate_repo/versions/309_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/317_add_aggregate_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/311_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/318_resource_provider_name_aggregates.py', 'nova/db/sqlalchemy/migrate_repo/versions/306_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/315_add_migration_progresss_detail.py', 'nova/db/sqlalchemy/migrate_repo/versions/319_mitaka.py', 'nova/db/sqlalchemy/migrate_repo/versions/304_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/308_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/303_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/310_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/316_add_disk_ratio_for_compute_nodes.py', 'nova/db/sqlalchemy/migrate_repo/versions/312_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/314_add_resource_provider_tables.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/76e8653ba1ec62656274ee8b28aa7b7cd34b307a', 'message': ""db: Compact Mitaka database migrations\n\nCompact Mitaka database migrations into a single migration,\n'319_mitaka.py'.\n\nUsers will now need to update to Mitaka before updating to Newton or\nlater.\n\nSpecific changes include:\n\n- Add 'parent_addr' column to 'pci_devices' table\n- Add 'resource_providers', 'inventories', and 'allocations' tables\n- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',\n  'disk_processed', and 'disk_remaining' columns to 'migrations' table\n- Add 'disk_allocation_ratio' column to 'compute_nodes' table\n- Add 'uuid' column and corresponding index to 'aggregates' table\n- Add 'name', 'generation' and 'can_host' columns to\n  'resource_providers' table\n- Add unique constraint on 'name' column of 'resource_providers' table\n- Add index on 'name' column of 'resource_providers' table\n- Add 'resource_provider_aggregates' table\n\nSome tests that depended on some of these migrations are removed.\n\nWhen testing, the previous base version was 301. It is now 318.\n\nChange-Id: Ib0c9229899e9a83992757270503e0e1a988f2402\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",1,758398,76e8653ba1ec62656274ee8b28aa7b7cd34b307a,101,14,6,15334,,,0,"db: Compact Mitaka database migrations

Compact Mitaka database migrations into a single migration,
'319_mitaka.py'.

Users will now need to update to Mitaka before updating to Newton or
later.

Specific changes include:

- Add 'parent_addr' column to 'pci_devices' table
- Add 'resource_providers', 'inventories', and 'allocations' tables
- Add 'memory_total', 'memory_processed', 'memory_remaining', 'disk_total',
  'disk_processed', and 'disk_remaining' columns to 'migrations' table
- Add 'disk_allocation_ratio' column to 'compute_nodes' table
- Add 'uuid' column and corresponding index to 'aggregates' table
- Add 'name', 'generation' and 'can_host' columns to
  'resource_providers' table
- Add unique constraint on 'name' column of 'resource_providers' table
- Add index on 'name' column of 'resource_providers' table
- Add 'resource_provider_aggregates' table

Some tests that depended on some of these migrations are removed.

When testing, the previous base version was 301. It is now 318.

Change-Id: Ib0c9229899e9a83992757270503e0e1a988f2402
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/758398/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_migrations.py', 'nova/db/sqlalchemy/migrate_repo/versions/305_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/307_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/313_add_parent_id_column.py', 'nova/db/sqlalchemy/migrate_repo/versions/309_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/317_add_aggregate_uuid.py', 'nova/db/sqlalchemy/migrate_repo/versions/311_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/306_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/315_add_migration_progresss_detail.py', 'nova/db/sqlalchemy/migrate_repo/versions/319_mitaka.py', 'nova/db/sqlalchemy/migrate_repo/versions/304_placeholder.py', 'nova/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/migrate_repo/versions/308_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/303_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/310_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/316_add_disk_ratio_for_compute_nodes.py', 'nova/db/sqlalchemy/migrate_repo/versions/312_placeholder.py', 'nova/db/sqlalchemy/migrate_repo/versions/314_add_resource_provider_tables.py']",18,d3d4538bcdfc0c7871fe661e76c29c11611f03ec,bp/compact-db-migrations-wallaby,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Database migrations for resource-providers."""""" from migrate import UniqueConstraint from sqlalchemy import Column from sqlalchemy import Float from sqlalchemy import Index from sqlalchemy import Integer from sqlalchemy import MetaData from sqlalchemy import String from sqlalchemy import Table def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine resource_providers = Table( 'resource_providers', meta, Column('id', Integer, primary_key=True, nullable=False), Column('uuid', String(36), nullable=False), UniqueConstraint('uuid', name='uniq_resource_providers0uuid'), mysql_engine='InnoDB', mysql_charset='latin1' ) Index('resource_providers_uuid_idx', resource_providers.c.uuid) inventories = Table( 'inventories', meta, Column('id', Integer, primary_key=True, nullable=False), Column('resource_provider_id', Integer, nullable=False), Column('resource_class_id', Integer, nullable=False), Column('total', Integer, nullable=False), Column('reserved', Integer, nullable=False), Column('min_unit', Integer, nullable=False), Column('max_unit', Integer, nullable=False), Column('step_size', Integer, nullable=False), Column('allocation_ratio', Float, nullable=False), mysql_engine='InnoDB', mysql_charset='latin1' ) Index('inventories_resource_provider_id_idx', inventories.c.resource_provider_id) Index('inventories_resource_class_id_idx', inventories.c.resource_class_id) allocations = Table( 'allocations', meta, Column('id', Integer, primary_key=True, nullable=False), Column('resource_provider_id', Integer, nullable=False), Column('consumer_id', String(36), nullable=False), Column('resource_class_id', Integer, nullable=False), Column('used', Integer, nullable=False), mysql_engine='InnoDB', mysql_charset='latin1' ) Index('allocations_resource_provider_class_id_idx', allocations.c.resource_provider_id, allocations.c.resource_class_id) Index('allocations_consumer_id_idx', allocations.c.consumer_id) Index('allocations_resource_class_id_idx', allocations.c.resource_class_id) for table in [resource_providers, inventories, allocations]: table.create(checkfirst=True) for table_name in ('', 'shadow_'): uuid_column = Column('uuid', String(36)) compute_nodes = Table('%scompute_nodes' % table_name, meta) compute_nodes.create_column(uuid_column) ",63,518
openstack%2Fcharm-mysql-innodb-cluster~master~I573ac3519687f48790809bd3c1c61fba1f5a54da,openstack/charm-mysql-innodb-cluster,master,I573ac3519687f48790809bd3c1c61fba1f5a54da,Clear ssl_ca when certificates relation departs,MERGED,2021-02-04 02:22:04.000000000,2021-02-06 15:05:13.000000000,2021-02-06 15:05:13.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2021-02-04 02:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/2d861253e642bb67840ee3b29561b6bb36a4e024', 'message': 'Clear ssl_ca when certificates relation departs\n\nCloses Bug: #1914299\nDepends-On: 1e66aca79df83b41072bb5df2cfb1708c8259cb4\nChange-Id: I573ac3519687f48790809bd3c1c61fba1f5a54da\n'}, {'number': 2, 'created': '2021-02-04 23:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/ad539cff7b3262aa53ab5dbb6f2bdc25759543d7', 'message': 'Clear ssl_ca when certificates relation departs\n\nCloses Bug: #1914299\nDepends-On: 1e66aca79df83b41072bb5df2cfb1708c8259cb4\nChange-Id: I573ac3519687f48790809bd3c1c61fba1f5a54da\n'}, {'number': 3, 'created': '2021-02-05 10:26:17.000000000', 'files': ['src/lib/charm/openstack/mysql_innodb_cluster.py', 'src/reactive/mysql_innodb_cluster_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/ee2aff9278c5d903cb892241e7c90bd6fa8e65b3', 'message': 'Clear ssl_ca when certificates relation departs\n\nCloses-Bug: #1914299\nChange-Id: I573ac3519687f48790809bd3c1c61fba1f5a54da\n'}]",0,774033,ee2aff9278c5d903cb892241e7c90bd6fa8e65b3,28,4,3,20805,,,0,"Clear ssl_ca when certificates relation departs

Closes-Bug: #1914299
Change-Id: I573ac3519687f48790809bd3c1c61fba1f5a54da
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/33/774033/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/mysql_innodb_cluster.py', 'src/reactive/mysql_innodb_cluster_handlers.py']",2,2d861253e642bb67840ee3b29561b6bb36a4e024,bug/1914299," 'certificates.certs.changed', 'endpoint.certificates.departed')", 'certificates.certs.changed'),10,1
openstack%2Fnova~master~I5e8bbc078266d81d64c2073a828b6ff394e4f0e1,openstack/nova,master,I5e8bbc078266d81d64c2073a828b6ff394e4f0e1,glance: Remove [glance]/allowed_direct_url_schemes,MERGED,2021-01-28 12:47:18.000000000,2021-02-06 14:43:18.000000000,2021-02-06 01:10:07.000000000,"[{'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-28 12:47:18.000000000', 'files': ['nova/image/glance.py', 'nova/conf/glance.py', 'nova/tests/unit/image/test_glance.py', 'releasenotes/notes/remove-glance-allowed_direct_url_schemes-93d34d95dd84d2c8.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/f9901ca92770a879a28c17f28814f6c93204f2fc', 'message': 'glance: Remove [glance]/allowed_direct_url_schemes\n\nThis option was deprecated during Queens and can be removed now.\n\nA single test is fully removed as it is no longer possible to hit the\nusecase while an additional two tests are modified to test the recently\nintroduced rbd direct download usecase.\n\nChange-Id: I5e8bbc078266d81d64c2073a828b6ff394e4f0e1\n'}]",0,772874,f9901ca92770a879a28c17f28814f6c93204f2fc,35,4,1,10135,,,0,"glance: Remove [glance]/allowed_direct_url_schemes

This option was deprecated during Queens and can be removed now.

A single test is fully removed as it is no longer possible to hit the
usecase while an additional two tests are modified to test the recently
introduced rbd direct download usecase.

Change-Id: I5e8bbc078266d81d64c2073a828b6ff394e4f0e1
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/772874/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/image/glance.py', 'nova/conf/glance.py', 'nova/tests/unit/image/test_glance.py', 'releasenotes/notes/remove-glance-allowed_direct_url_schemes-93d34d95dd84d2c8.yaml']",4,f9901ca92770a879a28c17f28814f6c93204f2fc,,"--- upgrade: - | The ``[glance]/allowed_direct_url_schemes`` config option, which was first deprecated in the 17.0.0 (Queens) release has now been removed. ",,12,71
openstack%2Ftripleo-quickstart~master~Ia30d28237c744644e5b8a435458a65fdbcfea4ae,openstack/tripleo-quickstart,master,Ia30d28237c744644e5b8a435458a65fdbcfea4ae,Enable swift for fs039,MERGED,2021-02-02 02:53:33.000000000,2021-02-06 11:07:16.000000000,2021-02-06 11:06:06.000000000,"[{'_account_id': 8449}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-02 02:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/9e02494b08684129bfa43303c8553d1df04c068b', 'message': ""Enable swift for fs039\n\nNova/Ironic require swift for certain use cases. Let's enable\nit for fs039 where we use nova for node provisioning.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/773559\nChange-Id: Ia30d28237c744644e5b8a435458a65fdbcfea4ae\n""}, {'number': 2, 'created': '2021-02-02 08:59:11.000000000', 'files': ['config/general_config/featureset039.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5dcdeb202078b6adc864b4e60db104eaab731535', 'message': ""Enable swift for fs039\n\nNova/Ironic require swift for certain use cases. Let's enable\nit for fs039 where we use nova for node provisioning.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/773559\nChange-Id: Ia30d28237c744644e5b8a435458a65fdbcfea4ae\n""}]",2,773560,5dcdeb202078b6adc864b4e60db104eaab731535,34,4,2,8833,,,0,"Enable swift for fs039

Nova/Ironic require swift for certain use cases. Let's enable
it for fs039 where we use nova for node provisioning.

Depends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/773559
Change-Id: Ia30d28237c744644e5b8a435458a65fdbcfea4ae
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/60/773560/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset039.yml'],1,9e02494b08684129bfa43303c8553d1df04c068b,env_merging,undercloud_enable_swift: true,,1,0
openstack%2Frequirements~master~I5cf25fcba050b07cf0818278484636f5715a424d,openstack/requirements,master,I5cf25fcba050b07cf0818278484636f5715a424d,Updated from generate-constraints,MERGED,2021-02-06 06:19:39.000000000,2021-02-06 09:34:03.000000000,2021-02-06 09:32:32.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-06 06:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6031b995cc31ba68d92bac8ab07ea9ba8e98e6fc', 'message': 'Updated from generate-constraints\n\nChange-Id: I5cf25fcba050b07cf0818278484636f5715a424d\n'}, {'number': 2, 'created': '2021-02-06 06:40:36.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/32a1a608513986a0c346eea125b92552feb87296', 'message': 'Updated from generate-constraints\n\nChange-Id: I5cf25fcba050b07cf0818278484636f5715a424d\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,774347,32a1a608513986a0c346eea125b92552feb87296,11,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: I5cf25fcba050b07cf0818278484636f5715a424d
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/47/774347/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,6031b995cc31ba68d92bac8ab07ea9ba8e98e6fc,openstack/requirements/constraints/noclob,pymongo===3.11.3pyghmi===1.5.22google-auth===1.25.0eventlet===0.30.1mock===4.0.3pylxd===2.3.0autobahn===21.1.1boto3===1.17.3iso8601===0.1.14cfn-lint===0.44.6pika===1.2.0uhashring===2.0botocore===1.20.3dulwich===0.20.18oslo.db===8.5.0oslo.policy===3.6.2pkg-resources===0.0.0xmlschema===1.5.0diskimage-builder===3.7.0python-cyborgclient===1.3.0alembic===1.5.4confluent-kafka===1.6.0fasteners===0.16virtualenv===20.4.2 sshpubkeys===3.3.1,pymongo===3.11.2pyghmi===1.5.21google-auth===1.24.0eventlet===0.30.0mock===3.0.5pylxd===2.2.11autobahn===20.12.3boto3===1.16.63python-cyborgclient===1.2.1iso8601===0.1.13cfn-lint===0.44.5pika===1.1.0uhashring===1.2botocore===1.19.63dulwich===0.20.15oslo.db===8.4.0oslo.policy===3.6.0xmlschema===1.4.2diskimage-builder===3.6.0alembic===1.5.3confluent-kafka===1.5.0fasteners===0.14.1virtualenv===20.2.1 sshpubkeys===3.3.0setuptools===52.0.0,25,25
openstack%2Fmanila~master~Ia58fc523e17d6f4c4efdae3e3fd070012c12d341,openstack/manila,master,Ia58fc523e17d6f4c4efdae3e3fd070012c12d341,WIP - Add missing features to driver support mapping,NEW,2020-10-08 22:08:25.000000000,2021-02-06 09:17:24.000000000,,"[{'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-08 22:08:25.000000000', 'files': ['doc/source/admin/share_back_ends_feature_support_mapping.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/8d04691c3115c5b1f1de62da0dbfd82355aa3822', 'message': 'WIP - Add missing features to driver support mapping\n\nChange-Id: Ia58fc523e17d6f4c4efdae3e3fd070012c12d341\nSigned-off-by: Douglas Viroel <viroel@gmail.com>\n'}]",0,756928,8d04691c3115c5b1f1de62da0dbfd82355aa3822,5,3,1,30002,,,0,"WIP - Add missing features to driver support mapping

Change-Id: Ia58fc523e17d6f4c4efdae3e3fd070012c12d341
Signed-off-by: Douglas Viroel <viroel@gmail.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/28/756928/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/share_back_ends_feature_support_mapping.rst'],1,8d04691c3115c5b1f1de62da0dbfd82355aa3822,update_support_mapping," Mapping of share drivers and advanced share features support ------------------------------------------------------------ +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Driver name | share replica | share group | share group snapshot | share group from group snapshot | manage unmanage share server | share migration | share server migration | +========================================+===============================+=======================+==========================+===================================+================================+========================+============================+ | ZFSonLinux | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Container | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Generic (Cinder as back-end) | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | NetApp Clustered Data ONTAP | DHSS=False (M), DHSS=True (T) | P | P | P | S | O | V | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | EMC VMAX | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | EMC VNX | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | EMC Unity | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | EMC Isilon | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | GlusterFS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | GlusterFS-Native | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | HDFS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Hitachi HNAS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Hitachi HSP | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | HPE 3PAR | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Huawei | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | IBM GPFS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | INFINIDAT | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | INSPUR AS13000 | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | INSPUR InStorage | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Infortrend | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | LVM | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Quobyte | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Windows SMB | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Oracle ZFSSA | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | CephFS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | Tegile | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | NexentaStor4 | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | NexentaStor5 | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | MapRFS | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ | QNAP | ? | ? | ? | ? | ? | ? | ? | +----------------------------------------+-------------------------------+-----------------------+--------------------------+-----------------------------------+--------------------------------+------------------------+----------------------------+ ",,69,0
openstack%2Fmanila~master~I23342d056d5a2167c8140e50b22397904e169e10,openstack/manila,master,I23342d056d5a2167c8140e50b22397904e169e10,Manila share driver for ZTE CloveStorage series.,NEW,2020-10-12 08:31:37.000000000,2021-02-06 08:28:20.000000000,,"[{'_account_id': 10068}, {'_account_id': 12016}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 16643}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 32527}]","[{'number': 1, 'created': '2020-10-12 08:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4047cf2e148ed41fad22aa37e39f1441edccc4b1', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 2, 'created': '2020-10-12 08:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/34785c5c867c6a1feda40f287a9d0a6604649ab5', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 3, 'created': '2020-10-13 02:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/82ec47f6a0d1306a0b40784c80753780199d13ce', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 4, 'created': '2020-10-13 05:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ac221384a23ed75c79c2f672b7a230d2c7131e78', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 5, 'created': '2020-10-13 08:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5107efbea41598ae06e25057d9d1295053edca44', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 6, 'created': '2020-10-15 08:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/327ec9cb871a5b3fb9297c287d614823fc419053', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 7, 'created': '2020-11-06 02:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3d96f90dce9e9b075a162150251cff1bf1b58bec', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 8, 'created': '2020-11-06 05:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8f161eb8d62eda5fe4cb29d291f1b31890538f47', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 9, 'created': '2020-11-06 08:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/69a72294a0aa7e031ccbc58e7d447876e0bfce91', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 10, 'created': '2020-11-06 09:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/78e42def1c59d6e8d0873efc5ecb922a3d61548a', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 11, 'created': '2020-11-06 09:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4919e37495cc75fb7882ff3c0956fccc297f0ea8', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 12, 'created': '2020-11-13 09:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/399aae778dff4e8fb5866cd8b23cd20bef236a6a', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 13, 'created': '2020-11-16 06:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6ab8140f6fa04194717da2b5c3ed05ffba1528b4', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nrevert_to_snapshot_support,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 14, 'created': '2020-12-09 02:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/834471f467ff52ba91d20962f76e1941cab7a87f', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nrevert_to_snapshot_support,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}, {'number': 15, 'created': '2020-12-09 05:39:54.000000000', 'files': ['manila/share/drivers/zte/__init__.py', 'manila/tests/share/drivers/zte/__init__.py', 'manila/tests/share/drivers/zte/clovestorage/test_clovestorage_nas.py', 'manila/share/drivers/zte/clovestorage/clovestorage_nas.py', 'releasenotes/notes/zte-clovestorage-driver-49022da9deaf0118.yaml', 'manila/share/drivers/zte/clovestorage/__init__.py', 'manila/tests/share/drivers/zte/clovestorage/__init__.py', 'manila/opts.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/cb2db32cf81c552087251c27ec6a1a27c599ecfe', 'message': 'Manila share driver for ZTE CloveStorage series.\n\nFeatures that ZTE CloveStorage Driver support:\nshare create/delete,\nsnapshot create/delete,\nextend size,\ncreate_share_from_snapshot,\nrevert_to_snapshot_support,\nupdate_access.\nprotocol: nfs/cifs\n\nChange-Id: I23342d056d5a2167c8140e50b22397904e169e10\nImplements: Blueprint zte-clovestorage-manila-driver\nSigned-off-by: luomuyao <luo.muyao@zte.com.cn>\n'}]",151,757473,cb2db32cf81c552087251c27ec6a1a27c599ecfe,59,9,15,32527,,,0,"Manila share driver for ZTE CloveStorage series.

Features that ZTE CloveStorage Driver support:
share create/delete,
snapshot create/delete,
extend size,
create_share_from_snapshot,
revert_to_snapshot_support,
update_access.
protocol: nfs/cifs

Change-Id: I23342d056d5a2167c8140e50b22397904e169e10
Implements: Blueprint zte-clovestorage-manila-driver
Signed-off-by: luomuyao <luo.muyao@zte.com.cn>
",git fetch https://review.opendev.org/openstack/manila refs/changes/73/757473/8 && git format-patch -1 --stdout FETCH_HEAD,['manila/opts.py'],1,4047cf2e148ed41fad22aa37e39f1441edccc4b1,,"import manila.share.drivers.zte.clovestorage.clovestorage_nas manila.share.drivers.zte.clovestorage.clovestorage_nas.zte_clovestorage_opts,",,2,0
openstack%2Fmanila~master~I0287a8a2c93b307fe2b55103e081245900ecfa46,openstack/manila,master,I0287a8a2c93b307fe2b55103e081245900ecfa46,Add share group replica support,NEW,2020-12-17 09:31:16.000000000,2021-02-06 06:44:59.000000000,,"[{'_account_id': 18742}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-17 09:31:16.000000000', 'files': ['api-ref/source/parameters.yaml', 'manila/policies/share_group_instance.py', 'manila/api/v2/share_networks.py', 'manila/policies/share_group_snapshot_instance.py', 'manila/share/drivers/dell_emc/plugins/unity/connection.py', 'manila/api/views/share_group_replicas.py', 'manila/api/openstack/api_version_request.py', 'manila/share_group/api.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/message/message_field.py', 'manila/scheduler/manager.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_replicas.py', 'manila/share/rpcapi.py', 'manila/api/v2/share_group_snapshots.py', 'manila/db/sqlalchemy/api.py', 'manila/api/views/share_groups.py', 'manila/share/manager.py', 'manila/api/views/share_group_snapshot_instances.py', 'manila/common/constants.py', 'manila/scheduler/filters/share_group_filters/share_group_replication.py', 'manila/api/v2/share_group_replicas.py', 'manila/scheduler/utils.py', 'manila/api/common.py', 'manila/api/v2/router.py', 'manila/api/views/share_replicas.py', 'manila/db/sqlalchemy/models.py', 'manila/share/driver.py', 'manila/scheduler/drivers/filter.py', 'manila/policies/share_group_replica.py', 'manila/share/drivers/dell_emc/driver.py', 'manila/db/api.py', 'manila/api/views/share_group_instances.py', 'manila/share/api.py', 'manila/api/v2/share_group_instances.py', 'manila/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/api/v2/share_group_snapshot_instances.py', 'manila/api/v2/share_groups.py', 'manila/scheduler/drivers/base.py', 'manila/scheduler/rpcapi.py', 'manila/db/migrations/alembic/versions/d34c9e9098fa_add_share_group_instances.py', 'manila/quota.py', 'setup.cfg', 'manila/exception.py', 'manila/policies/__init__.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/668a4e2be42a0ee9bf4b248cd6ebdb3b52f5bce8', 'message': 'Add share group replica support\n\nImplements: blueprint support-share-group-replica\nChange-Id: I0287a8a2c93b307fe2b55103e081245900ecfa46\n'}]",2,767504,668a4e2be42a0ee9bf4b248cd6ebdb3b52f5bce8,9,2,1,18742,,,0,"Add share group replica support

Implements: blueprint support-share-group-replica
Change-Id: I0287a8a2c93b307fe2b55103e081245900ecfa46
",git fetch https://review.opendev.org/openstack/manila refs/changes/04/767504/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'manila/policies/share_group_instance.py', 'manila/api/v2/share_networks.py', 'manila/policies/share_group_snapshot_instance.py', 'manila/share/drivers/dell_emc/plugins/unity/connection.py', 'manila/api/views/share_group_replicas.py', 'manila/api/openstack/api_version_request.py', 'manila/share_group/api.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/message/message_field.py', 'manila/scheduler/manager.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_replicas.py', 'manila/share/rpcapi.py', 'manila/api/v2/share_group_snapshots.py', 'manila/db/sqlalchemy/api.py', 'manila/api/views/share_groups.py', 'manila/share/manager.py', 'manila/api/views/share_group_snapshot_instances.py', 'manila/common/constants.py', 'manila/scheduler/filters/share_group_filters/share_group_replication.py', 'manila/api/v2/share_group_replicas.py', 'manila/scheduler/utils.py', 'manila/api/common.py', 'manila/api/v2/router.py', 'manila/api/views/share_replicas.py', 'manila/db/sqlalchemy/models.py', 'manila/share/driver.py', 'manila/scheduler/drivers/filter.py', 'manila/policies/share_group_replica.py', 'manila/share/drivers/dell_emc/driver.py', 'manila/db/api.py', 'manila/api/views/share_group_instances.py', 'manila/share/api.py', 'manila/api/v2/share_group_instances.py', 'manila/share/drivers/dell_emc/plugins/unity/utils.py', 'manila/api/v2/share_group_snapshot_instances.py', 'manila/api/v2/share_groups.py', 'manila/scheduler/drivers/base.py', 'manila/scheduler/rpcapi.py', 'manila/db/migrations/alembic/versions/d34c9e9098fa_add_share_group_instances.py', 'manila/quota.py', 'setup.cfg', 'manila/exception.py', 'manila/policies/__init__.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py']",46,668a4e2be42a0ee9bf4b248cd6ebdb3b52f5bce8,bp/support-share-group-replica,"from distutils import versionfrom manila import utils as manila_utils# TODO(RyanLiang): delete it. NAME_PREFIX_DR_NAS_SERVER = 'OS-DR_' self.unity_host = host def delete_filesystem(filesystem, force_snap_delete=False): try: filesystem.delete(force_snap_delete=force_snap_delete) @manila_utils.retry(storops_ex.UnityDeleteResourceInReplicationError, interval=3, retries=6) def delete_filesystem_wait_replication_deletion(self, filesystem): self.delete_filesystem(filesystem, force_snap_delete=True) @manila_utils.retry(storops_ex.UnityDeleteResourceInReplicationError, interval=3, retries=6) def delete_nas_server_wait_replication_deletion(self, name): self.delete_nas_server(name) def create_snapshot(filesystem, name, replicated_to=None): return filesystem.create_snap(name, fs_access_type=access_type, replicated_to=replicated_to) def get_snapshot(self, name=None): def _get_nas_server_with_rep_role(self, name, role): """"""Gets nas server with specified replication role. :param name: could be xxx or OS-DR_xxx. :param role: could be `active` or `dr`. """""" # TODO(RyanLiang): delete it if name.startswith(NAME_PREFIX_DR_NAS_SERVER): dr_name = name active_name = name[len(NAME_PREFIX_DR_NAS_SERVER):] else: dr_name = NAME_PREFIX_DR_NAS_SERVER + name active_name = name def _is_role_match(s): if role == 'active': return not s.is_replication_destination else: return s.is_replication_destination nas_server = None for name in [active_name, dr_name]: try: nas_server = self.get_nas_server(name) if _is_role_match(nas_server): break else: LOG.debug('Nas server with name %(name)s found but not ' '%(role)s.', {'name': name, 'role': role}) nas_server = None except storops_ex.UnityResourceNotFoundError: LOG.debug( 'Nas server with name %(name)s not found. Will try ' 'another name %(alt)s.', {'name': name, 'alt': dr_name if name == active_name else active_name}) if not nas_server: raise exception.EMCUnityError( err='No %(role)s nas server found with any name in ' '%(names)s.' % {'role': role, 'names': (active_name, name)} ) LOG.debug('Nas server: name=%(name)s,role=%(role)s returned.', {'name': nas_server.name, 'role': role}) return nas_server def get_active_nas_server(self, name): """"""Returns the active nas server. For the nas server involved in a local replication, the name of the active nas server could be xxx or OS-DR_xxx. """""" # TODO(RyanLiang): delete it # return self._get_nas_server_with_rep_role(name, 'active') def get_dr_nas_server(self, name): """"""Returns the dr nas server. For the nas server involved in a local replication, the name of the dr nas server could be xxx or OS-DR_xxx. Try OS-DR_xxx first. """""" # TODO(RyanLiang): delete it # return self._get_nas_server_with_rep_role(name, 'dr') def get_serial_number(self): return self.system.serial_number def get_remote_system(self, name): return self.system.get_remote_system(name=name) def is_local_replication(self, dr_client): return self.get_serial_number() == dr_client.get_serial_number() @staticmethod def _zip_active_dr_filesystems(active_filesystems, dr_filesystems): return zip(sorted(active_filesystems or [], key=lambda fs: fs.name), sorted(dr_filesystems or [], key=lambda fs: fs.name)) @staticmethod def _get_fs_replications(active_nas_server, dr_nas_server, remote_system): fs_reps = {} for active_fs, dr_fs in UnityClient._zip_active_dr_filesystems( active_nas_server.filesystems, dr_nas_server.filesystems): try: fs_reps[active_fs.name] = active_fs.get_replications( remote_system=remote_system, dst_filesystem=dr_fs)[0] except IndexError: LOG.info('Replication session not exist from fs %(src)s to ' 'fs %(dst)s on unity %(remote)s.', {'src': active_fs.name, 'dst': dr_fs.name, 'remote': remote_system.name}) return fs_reps def _get_dr_nas_server_name(self, dr_client, active_nas_server_name): # 1) For nas server in local replication, if source's name is xxx, then # destination's name is OS-DR_xxx, otherwise, source's name is # OS-DR_xxx, and destination's name is xxx. # 2) For nas server in remote replication, the name of source and # destination is the same. # TODO(RyanLiang): delete it if self.is_local_replication(dr_client): prefix = NAME_PREFIX_DR_NAS_SERVER return (active_nas_server_name[len(prefix):] if active_nas_server_name.startswith(prefix) else (prefix + active_nas_server_name)) return active_nas_server_name def enable_replication(self, dr_client, active_nas_server_name, dr_nas_server_name, max_out_of_sync_minutes, dr_pool_name=None, dr_new_ip_addr=None, replicate_existing_snaps=False, reuse_dr_resources=False): """"""Enables the nas server replication from this client to dr_client. dr_pool_name could be None only when reuse_dr_resources=True and there is an existing nas server and/or filesystem usable. dr_client could connect to the same Unity for local replications. reuse_dr_resources will be ignored by storops when Unity OE is prior to 5.1.0. """""" active_nas_server = self.get_nas_server(active_nas_server_name) dr_pool_id = None if dr_pool_name: dr_pool_id = dr_client.get_pool(name=dr_pool_name).get_id() remote_system = None dst_sp = None if not self.is_local_replication(dr_client): remote_system = self.get_remote_system( dr_client.get_serial_number()) # Required for remote replications. dst_sp = active_nas_server.home_sp.to_node_enum() active_filesystems = active_nas_server.filesystems or [] nas_rep = active_nas_server.replicate_with_dst_resource_provisioning( max_out_of_sync_minutes, dst_pool_id=dr_pool_id, dst_nas_server_name=dr_nas_server_name, remote_system=remote_system, dst_sp=dst_sp, filesystems=active_filesystems, replicate_existing_snaps=replicate_existing_snaps, reuse_dst_resource=reuse_dr_resources, ) # Manual sync the nas server replication session to make sure the share # is created on the destination system. nas_rep.sync() dr_nas_server = dr_client.get_nas_server(dr_nas_server_name) # The file interface on the destination nas server will be the same as # the source's. Need to override it using its expected ip address. if dr_new_ip_addr: dr_nas_server.file_interface[0].modify(ip=dr_new_ip_addr) return nas_rep, self._get_fs_replications(active_nas_server, dr_nas_server, remote_system) def disable_replication(self, dr_client, active_nas_server_name, dr_nas_server_name, keep_dr_resources=False): """"""Disables the nas server replication."""""" try: dr_nas_server = dr_client.get_nas_server(dr_nas_server_name) except storops_ex.UnityResourceNotFoundError: LOG.warning('DR side nas server %s not found. Skipping ' 'deleting this replication and all related filesystem ' 'replications, nas server, filesystems, shares ' 'from DR Unity.', dr_nas_server_name) return except storops_ex.StoropsConnectTimeoutError: LOG.warning('DR Unity %s is down. Skipping deleting this ' 'replication and all related filesystem replications, ' 'nas server, filesystems shares from DR Unity.', dr_client.unity_host) return try: active_nas_server = self.get_nas_server(active_nas_server_name) remote_system = self.get_remote_system( dr_client.get_serial_number()) # Delete the replication sessions on filesystems. for active_fs, dr_fs in self._zip_active_dr_filesystems( active_nas_server.filesystems, dr_nas_server.filesystems): active_fs.delete_replications(remote_system=remote_system, dst_filesystem=dr_fs) # Delete the replication session on nas server. active_nas_server.delete_replications(remote_system=remote_system, dst_nas_server=dr_nas_server) except storops_ex.StoropsConnectTimeoutError: LOG.info('Active Unity %s is down. Unable to disable the ' 'replication from the active side. Deleting the ' 'replication and all related filesystem replications, ' 'nas server, filesystems shares from DR Unity.', 'without sync', self.unity_host) for dr_fs in (dr_nas_server.filesystems or []): # It's safe because there must be only one replications to the # dr filesystem. dr_fs.delete_replications() # It's safe because there must be only one replications to the # dr nas server. dr_nas_server.delete_replications() if not keep_dr_resources: # Delete dr side filesystems then nas server. No need to delete the # shares on the dr destination nas server. They will be deleted # together with filesystems. for fs in (dr_nas_server.filesystems or []): dr_client.delete_filesystem_wait_replication_deletion(fs) dr_client.delete_nas_server_wait_replication_deletion( dr_nas_server_name) # Return this information for replication rebuild. return {'dr_pool': dr_nas_server.pool, 'dr_file_interface': dr_nas_server.file_interface[0]} def failover_replication(self, dr_client, active_nas_server_name, dr_nas_server_name): try: # Planned fail over which fails over with sync from active side. active_nas_server = self.get_nas_server(active_nas_server_name) remote_system = self.get_remote_system( dr_client.get_serial_number()) dr_nas_server = dr_client.get_nas_server(dr_nas_server_name) rep_session = active_nas_server.get_replications( remote_system=remote_system, dst_nas_server=dr_nas_server)[0] rep_session.failover(sync=True) # Resume can only be done on the original dr side. rep_session = dr_client.system.get_replication_sessions( _id=rep_session.get_id()) rep_session.resume() except storops_ex.StoropsConnectTimeoutError: # Unplanned fail over which fails over without sync from dr side. # Because the active side is down. LOG.info('Active Unity %s is down. Unable to fail over the ' 'replication with sync. Using unplanned fail over ' 'without sync', self.unity_host) # Cannot use active_nas_server or other resources of active side # which is down. dr_nas_server = dr_client.get_nas_server(dr_nas_server_name) rep_session = dr_client.system.get_replication_sessions( dst_resource_id=dr_nas_server.get_id())[0] rep_session.failover(sync=False) rep_session.resume() def rebuild_replication(self, new_active_nas_name, dr_client, dr_nas_server_name, orig_active_client, orig_active_nas_name, max_out_of_sync_minutes, only_tear_down=False): """"""Rebuilds the replication for DR nas server. The DR nas server with name=`dr_nas_server_name` is with replication from the original active nas server with name=`orig_active_nas_name` on the Unity to which `orig_active_client` is connecting before rebuilding. The rebuild will tear down the original replication and build up a new one from the nas server with name=`new_active_nas_name` on the Unity to which `self` is connecting. """""" dr_resource = orig_active_client.disable_replication( dr_client, orig_active_nas_name, dr_nas_server_name, keep_dr_resources=self.is_unity_version('5.1.0')) if only_tear_down: return if self.is_unity_version('5.1.0'): self.enable_replication( dr_client, new_active_nas_name, dr_nas_server_name, max_out_of_sync_minutes, replicate_existing_snaps=True, reuse_dr_resources=True) else: self.enable_replication( dr_client, new_active_nas_name, dr_nas_server_name, max_out_of_sync_minutes, dr_pool_name=dr_resource['dr_pool'].name, dr_new_ip_addr=dr_resource['dr_file_interface'].ip_address, replicate_existing_snaps=True) def get_nas_server_and_fs_replications(self, dr_client, active_nas_server_name, dr_nas_server_name): try: active_nas_server = self.get_nas_server(active_nas_server_name) except storops_ex.StoropsConnectTimeoutError: LOG.info('Active Unity %s is down. Cannot get the replication ' 'sessions.', self.unity_host) return None, None dr_nas_server = dr_client.get_nas_server(dr_nas_server_name) remote_system = self.get_remote_system(dr_client.get_serial_number()) try: nas_server_rep = active_nas_server.get_replications( remote_system=remote_system, dst_nas_server=dr_nas_server)[0] except IndexError: LOG.info('Replication session not exist from nas server ' '%(active)s to nas server %(dr)s on unity %(remote)s.', {'active': active_nas_server.name, 'dr': dr_nas_server_name, 'remote': remote_system.name}) return None, None return nas_server_rep, self._get_fs_replications(active_nas_server, dr_nas_server, remote_system) def get_replicated_snapshot(self, name, is_local_replication): """"""Gets the replicated filesystem snapshot. :param name: the replicated snapshot's name is the same as the source's for remote replicated filesystems. But the replicated snapshot's name could be <fake-uuid>_20200907020101 while the source's is <fake-uuid> for local replicated filesystems. This parameter `name` is <fake-uuid> part. It's safe because it's UUID. :return: the replicated snapshot with name <fake-uuid> or <fake-uuid>_20200907020101. """""" @manila_utils.retry(storops_ex.UnityResourceNotFoundError, interval=3, retries=3) def _get_with_retry(name): # Could raise `UnityResourceNotFoundError` when the replicated # snapshot doesn't appear. if is_local_replication: name = name + '_' snaps = [snap for snap in self.get_snapshot() if snap.name.startswith(name)] if len(snaps) != 1: raise exception.EMCUnityError( err='There should be only one snapshot starting with ' 'name %(name)s, but %(count)s ' 'found.' % {'name': name, 'count': len(snaps)}) return snaps[0] else: return self.get_snapshot(name) return _get_with_retry(name) def is_unity_version(self, min_version, max_version=None): """"""Returns True if min_version <= Unity OE version < max_version."""""" curr_version = self.system.system_version return (version.LooseVersion(min_version) <= version.LooseVersion(curr_version) and (not max_version or version.LooseVersion(curr_version) < version.LooseVersion(max_version)))"," def delete_filesystem(filesystem): try: filesystem.delete() def create_snapshot(filesystem, name): return filesystem.create_snap(name, fs_access_type=access_type) def get_snapshot(self, name):",8167,455
openstack%2Fneutron~master~Ie1d837d17bf50a4675bec4fe48ab13dde22ebdc2,openstack/neutron,master,Ie1d837d17bf50a4675bec4fe48ab13dde22ebdc2,Drop meaningless translation marker,MERGED,2021-02-04 07:04:11.000000000,2021-02-06 04:08:38.000000000,2021-02-05 14:50:34.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 07:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cebc980fee12ea3b231a017dda2e8b54f1ecb026', 'message': ""Drop meaningless translation marker\n\nThe translation marker _(..) wrapping a variable is meaningless\nas no string is extracted and there is no way to translate them.\nOnly rare exception is the same string is defined in somewhere else\nbut I've never seen such situations so far.\n\nIn addition, we now only support translations in user-visible messages\nused in API, so we can safely drop translation markers in exceptions\nin the agent side.\n\nChange-Id: Ie1d837d17bf50a4675bec4fe48ab13dde22ebdc2\nRelated-Bug: #1600788\n""}, {'number': 2, 'created': '2021-02-05 10:15:09.000000000', 'files': ['neutron/agent/windows/utils.py', 'neutron/agent/linux/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/257a51769bb070600ca3d6bc169cf530bd33f1a3', 'message': ""Drop meaningless translation marker\n\nThe translation marker _(..) wrapping a variable is meaningless\nas no string is extracted and there is no way to translate them.\nOnly rare exception is the same string is defined in somewhere else\nbut I've never seen such situations so far.\n\nIn addition, we now only support translations in user-visible messages\nused in API, so we can safely drop translation markers in exceptions\nin the agent side.\n\nChange-Id: Ie1d837d17bf50a4675bec4fe48ab13dde22ebdc2\nRelated-Bug: #1600788\n""}]",2,774045,257a51769bb070600ca3d6bc169cf530bd33f1a3,17,5,2,841,,,0,"Drop meaningless translation marker

The translation marker _(..) wrapping a variable is meaningless
as no string is extracted and there is no way to translate them.
Only rare exception is the same string is defined in somewhere else
but I've never seen such situations so far.

In addition, we now only support translations in user-visible messages
used in API, so we can safely drop translation markers in exceptions
in the agent side.

Change-Id: Ie1d837d17bf50a4675bec4fe48ab13dde22ebdc2
Related-Bug: #1600788
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/774045/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/windows/utils.py', 'neutron/agent/linux/utils.py']",2,cebc980fee12ea3b231a017dda2e8b54f1ecb026,bug/1600788," raise exceptions.ProcessExecutionError(msg,"," raise exceptions.ProcessExecutionError(_(msg),",2,2
openstack%2Frequirements~master~Ifd770cc8f35c7ebf97f831ff9e2f1d92444b5061,openstack/requirements,master,Ifd770cc8f35c7ebf97f831ff9e2f1d92444b5061,Updated from generate-constraints,MERGED,2021-02-02 06:22:33.000000000,2021-02-06 03:59:17.000000000,2021-02-06 03:58:12.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 06:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d57c723d4768b36693ffd6836406e73c90552a79', 'message': 'Updated from generate-constraints\n\nChange-Id: Ifd770cc8f35c7ebf97f831ff9e2f1d92444b5061\n'}, {'number': 2, 'created': '2021-02-02 06:26:52.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6a05820984972d2540ae229f8771c33a67e72336', 'message': 'Updated from generate-constraints\n\nChange-Id: Ifd770cc8f35c7ebf97f831ff9e2f1d92444b5061\nSigned-off-by: Matthew Thode <mthode@mthode.org>\n'}]",0,773573,6a05820984972d2540ae229f8771c33a67e72336,27,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: Ifd770cc8f35c7ebf97f831ff9e2f1d92444b5061
Signed-off-by: Matthew Thode <mthode@mthode.org>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/73/773573/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d57c723d4768b36693ffd6836406e73c90552a79,openstack/requirements/constraints/noclob,netmiko===3.3.3croniter===1.0.6SQLAlchemy===1.3.23mock===4.0.3Jinja2===2.11.3pifpaf===3.1.5Django===2.2.18cmd2===1.5.0oslo.db===8.5.0hvac===0.10.7pkg-resources===0.0.0fasteners===0.16virtualenv===20.4.2pytz===2021.1,netmiko===3.3.2croniter===1.0.5SQLAlchemy===1.3.22mock===3.0.5Jinja2===2.11.2pifpaf===3.1.4Django===2.2.17cmd2===1.4.0oslo.db===8.4.0hvac===0.10.6fasteners===0.14.1virtualenv===20.2.1pytz===2020.5setuptools===52.0.0,14,14
openstack%2Frequirements~stable%2Ftrain~I4a05bca2e71ecbf761c76115f95a8a706fe37d33,openstack/requirements,stable/train,I4a05bca2e71ecbf761c76115f95a8a706fe37d33,update constraint for ceilometer to new release 13.1.2,MERGED,2021-02-01 19:05:41.000000000,2021-02-06 03:57:18.000000000,2021-02-06 03:57:18.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-01 19:05:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5fac0f723e9c5a71e593b84250cc9a988231b0a3', 'message': 'update constraint for ceilometer to new release 13.1.2\n\nmeta: version: 13.1.2\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: I1220d32320eab262625c1c4a9a276bc077d113a1\nmeta: release:Code-Review+1: Matthias Runge <mrunge@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Hervé Beraud <hberaud@redhat.com>\nChange-Id: I4a05bca2e71ecbf761c76115f95a8a706fe37d33\n'}]",0,773472,5fac0f723e9c5a71e593b84250cc9a988231b0a3,17,3,1,11131,,,0,"update constraint for ceilometer to new release 13.1.2

meta: version: 13.1.2
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: I1220d32320eab262625c1c4a9a276bc077d113a1
meta: release:Code-Review+1: Matthias Runge <mrunge@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Hervé Beraud <hberaud@redhat.com>
Change-Id: I4a05bca2e71ecbf761c76115f95a8a706fe37d33
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/773472/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5fac0f723e9c5a71e593b84250cc9a988231b0a3,new-release,ceilometer===13.1.2,ceilometer===13.1.1,1,1
openstack%2Fansible-collections-openstack~master~Iabadd94f990c49ba078aa02e2d801c40985f85b8,openstack/ansible-collections-openstack,master,Iabadd94f990c49ba078aa02e2d801c40985f85b8,Add modules for roles information,MERGED,2021-01-04 18:29:56.000000000,2021-02-06 03:28:01.000000000,2021-02-06 03:28:01.000000000,"[{'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32458}]","[{'number': 1, 'created': '2021-01-04 18:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6db18991406f20997c583d1cbf1310e2b4cf3165', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}, {'number': 2, 'created': '2021-01-05 00:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/626bc98e4f08d167fd878c2fef82db200d406094', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}, {'number': 3, 'created': '2021-01-05 01:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/85fd77b04e42a6b142532785f270eb84ce4e7bf7', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}, {'number': 4, 'created': '2021-01-05 02:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b6a9553ea40cfebe09c7ce808e9c8e516019484b', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}, {'number': 5, 'created': '2021-02-04 01:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f44e2fa6a6180b23d323cdd7e621cfc13bd457e8', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}, {'number': 6, 'created': '2021-02-04 02:30:18.000000000', 'files': ['ci/roles/keystone_role/tasks/main.yml', 'plugins/modules/identity_role_info.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c39c8f9d744248d1fb8ea3d9cff864f5cebe1caa', 'message': 'Add modules for roles information\n\nAdd module that retrieves list of roles for a Openstack cloud.\nChange-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8\n'}]",2,769202,c39c8f9d744248d1fb8ea3d9cff864f5cebe1caa,19,5,6,10969,,,0,"Add modules for roles information

Add module that retrieves list of roles for a Openstack cloud.
Change-Id: Iabadd94f990c49ba078aa02e2d801c40985f85b8
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/02/769202/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/keystone_role/tasks/main.yml', 'plugins/modules/identity_role_info.py']",2,6db18991406f20997c583d1cbf1310e2b4cf3165,new_roles_info,"#!/usr/bin/python # coding: utf-8 -*- # Copyright (c) 2020, Sagi Shnaidman <sshnaidm@redhat.com> # GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt) DOCUMENTATION = ''' --- module: identity_role_info short_description: Retrive information about roles author: OpenStack Ansible SIG description: - Get information about identity roles in Openstack options: domain_id: description: - List roles in specified domain only type: str required: false requirements: - ""python >= 3.6"" - ""openstacksdk"" extends_documentation_fragment: - openstack.cloud.openstack ''' RETURN = ''' openstack_roles: description: List of identity roles returned: always type: list elements: dict sample: - domain_id: None id: 19bf514fdda84f808ccee8463bd85c1a location: cloud: mycloud project: domain_id: None domain_name: None id: None name: None region_name: None zone: None name: member properties: ''' EXAMPLES = ''' # Retrieve info about all roles - openstack.cloud.identity_role_info: cloud: mycloud # Retrieve info about all roles in specific domain - openstack.cloud.identity_role_info: cloud: mycloud domain_id: some_domain_id ''' from ansible_collections.openstack.cloud.plugins.module_utils.openstack import OpenStackModule class IdentityRoleInfoModule(OpenStackModule): argument_spec = dict( domain_id=dict(type='str', required=False), ) module_kwargs = dict( supports_check_mode=True, ) def run(self): roles = self.conn.list_roles(domain_id=self.params['domain_id']) self.results.update({'openstack_roles': roles}) def main(): module = IdentityRoleInfoModule() module() if __name__ == '__main__': main() ",,98,0
openstack%2Fansible-collections-openstack~master~Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e,openstack/ansible-collections-openstack,master,Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e,Add security_group_info module,MERGED,2020-11-13 09:54:54.000000000,2021-02-06 03:27:58.000000000,2021-02-06 03:27:58.000000000,"[{'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32673}]","[{'number': 1, 'created': '2020-11-13 09:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d0b2e1516f0eb3d544b9f7fb3208197852b62ecd', 'message': ""WIP: Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 2, 'created': '2020-12-04 12:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0db137620cc5fe6a959adf6a8d29f590b856b2ae', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 3, 'created': '2021-01-20 14:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/769182ed6a1a12df204e24a56ea0b451de882fb9', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 4, 'created': '2021-01-20 15:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/eb6accc611aaaffda83a9e895a764af60dae5498', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nThis PR is depend from another PR for OS SDK\nhttps://review.opendev.org/c/openstack/openstacksdk/+/765980 .\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 5, 'created': '2021-01-22 12:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c99bb1c9eb75540c81e4046b3d32c26c519c53f7', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nThis PR is depend from another PR for OS SDK\nhttps://review.opendev.org/c/openstack/openstacksdk/+/765980 .\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 6, 'created': '2021-01-27 18:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e267e1d2487fac6e426eff1ac3095d6eb71767be', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\n\nThis PR is depend from another PR for OS SDK\nhttps://review.opendev.org/c/openstack/openstacksdk/+/765980 .\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 7, 'created': '2021-02-01 19:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f7c92551dd90036332ccd5585f620080f8084e98', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\nAdd tests.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 8, 'created': '2021-02-02 13:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/dc0d31c22a14ec85c0966391935d59d545a4c584', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\nAdd tests.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}, {'number': 9, 'created': '2021-02-04 00:22:45.000000000', 'files': ['meta/runtime.yml', 'ci/roles/security_group/tasks/main.yml', 'plugins/modules/security_group_info.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e4c7bd3df831832cbb1cc59c4565aeeac930d2fd', 'message': ""Add security_group_info module\n\nLet's add a new missing module for getting info about security groups.\nAdd tests.\n\nChange-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e\n""}]",18,762626,e4c7bd3df831832cbb1cc59c4565aeeac930d2fd,36,5,9,27900,,,0,"Add security_group_info module

Let's add a new missing module for getting info about security groups.
Add tests.

Change-Id: Ib032c8d14444cea1fcbfd98d252cc56b9f5f383e
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/26/762626/6 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/security_group_info.py'],1,d0b2e1516f0eb3d544b9f7fb3208197852b62ecd,,"#!/usr/bin/python # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. DOCUMENTATION = ''' module: security_group_info short_description: Lists security groups extends_documentation_fragment: openstack.cloud.openstack author: OpenStack Ansible SIG description: - List security groups options: description: description: - Description of the security group type: str project_id: description: - Specifies the project id as filter criteria type: str name: description: - Name or id of the security group. type: str requirements: [""openstacksdk""] ''' RETURN = ''' security_groups: description: List of dictionaries describing security groups. type: complex returned: On Success. contains: created_at: description: Creation time of the security group type: str sample: ""yyyy-mm-dd hh:mm:ss"" description: description: Description of the security group type: str sample: ""My security group"" id: description: ID of the security group type: str sample: ""d90e55ba-23bd-4d97-b722-8cb6fb485d69"" name: description: Name of the security group. type: str sample: ""my-sg"" project_id: description: Project ID where the security group is located in. type: str sample: ""25d24fc8-d019-4a34-9fff-0a09fde6a567"" security_group_rules: description: Specifies the security group rule list type: list sample: [ { ""id"": ""d90e55ba-23bd-4d97-b722-8cb6fb485d69"", ""direction"": ""ingress"", ""protocol"": null, ""ethertype"": ""IPv4"", ""description"": null, ""remote_group_id"": ""0431c9c5-1660-42e0-8a00-134bec7f03e2"", ""remote_ip_prefix"": null, ""tenant_id"": ""bbfe8c41dd034a07bebd592bf03b4b0c"", ""port_range_max"": null, ""port_range_min"": null, ""security_group_id"": ""0431c9c5-1660-42e0-8a00-134bec7f03e2"" }, { ""id"": ""aecff4d4-9ce9-489c-86a3-803aedec65f7"", ""direction"": ""egress"", ""protocol"": null, ""ethertype"": ""IPv4"", ""description"": null, ""remote_group_id"": null, ""remote_ip_prefix"": null, ""tenant_id"": ""bbfe8c41dd034a07bebd592bf03b4b0c"", ""port_range_max"": null, ""port_range_min"": null, ""security_group_id"": ""0431c9c5-1660-42e0-8a00-134bec7f03e2"" } ] updated_at: description: Update time of the security group type: str sample: ""yyyy-mm-dd hh:mm:ss"" ''' EXAMPLES = ''' # Get specific security group - openstack.cloud.security_group_info: name: ""{{ my_sg }}"" register: sg # Get all security groups - openstack.cloud.security_group_info: register: sg ''' from ansible_collections.openstack.cloud.plugins.module_utils.openstack import ( OpenStackModule) class SecurityGroupInfoModule(OpenStackModule): argument_spec = dict( description=dict(required=False), name=dict(required=False), project_id=dict(required=False) ) def run(self): data = [] query = {} if self.params['name']: sg = self.conn.network.find_security_group( name_or_id=self.params['name'], ignore_missing=True) if sg: query['id'] = sg.id else: self.exit( changed=False, security_groups=[], message=('No security group found with name or id: %s' % self.params['name']) ) if self.params['description']: query['description'] = self.params['description'] if self.params['project_id']: query['project_id'] = self.params['project_id'] for raw in self.conn.network.security_groups(**query): dt = raw.to_dict() dt.pop('location') data.append(dt) self.exit( changed=False, security_groups=data ) def main(): module = SecurityGroupInfoModule() module() if __name__ == ""__main__"": main() ",,162,0
openstack%2Fmanila~master~I25aeb1b6dd1a4150c6e542e29b7d43e18d9ad94c,openstack/manila,master,I25aeb1b6dd1a4150c6e542e29b7d43e18d9ad94c,[devstack] create endpoint without project_id,MERGED,2021-02-03 19:25:11.000000000,2021-02-06 01:07:47.000000000,2021-02-06 01:06:03.000000000,"[{'_account_id': 9003}, {'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2021-02-03 19:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/aa67f18adeb5a4355d00db7f0d5d772fca8d0b33', 'message': '[devstack] create endpoint without project_id\n\nAs of API version 2.60, a project_id is no\nlonger needed in the API URLs. We can stop\ndevstack from setting up an endpoint with\nproject_id in it.\n\nCreate a ""sharev2_legacy"" endpoint that\ncontains the project_id for testing the\ncompatibility with the older style of URLs.\n\nChange-Id: I25aeb1b6dd1a4150c6e542e29b7d43e18d9ad94c\nImplements: bp remove-project-id-from-urls\nDepends-On: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 2, 'created': '2021-02-05 07:25:31.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/9efcb475cff6dd99363a239424a3febccb76374a', 'message': '[devstack] create endpoint without project_id\n\nAs of API version 2.60, a project_id is no\nlonger needed in the API URLs. We can stop\ndevstack from setting up an endpoint with\nproject_id in it.\n\nCreate a ""sharev2_legacy"" endpoint that\ncontains the project_id for testing the\ncompatibility with the older style of URLs.\n\nChange-Id: I25aeb1b6dd1a4150c6e542e29b7d43e18d9ad94c\nImplements: bp remove-project-id-from-urls\nDepends-On: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",0,773986,9efcb475cff6dd99363a239424a3febccb76374a,24,3,2,16643,,,0,"[devstack] create endpoint without project_id

As of API version 2.60, a project_id is no
longer needed in the API URLs. We can stop
devstack from setting up an endpoint with
project_id in it.

Create a ""sharev2_legacy"" endpoint that
contains the project_id for testing the
compatibility with the older style of URLs.

Change-Id: I25aeb1b6dd1a4150c6e542e29b7d43e18d9ad94c
Implements: bp remove-project-id-from-urls
Depends-On: I5127e150e8a71e621890f30dba6720b3932cf583
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/86/773986/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,aa67f18adeb5a4355d00db7f0d5d772fca8d0b33,bp/remove-project-id-from-urls," # Set up Manila v2 service and endpoint - as of microversion 2.60, # project_id is no longer necessary in the v2 endpoint ""$MANILA_ENDPOINT_BASE/v2"" # Set up Manila legacy v2 service and endpoint - as of microversion 2.60, # project_id is no longer necessary in the v2 endpoint get_or_create_service ""manilav2_legacy"" ""sharev2_legacy"" ""Manila Shared Filesystem Service V2 (Legacy 2.0)"" get_or_create_endpoint ""sharev2_legacy"" ""$REGION_NAME"" \", # Set up Manila v2 service and endpoint,9,1
openstack%2Foslo.utils~master~I10fed16dad77ac17691a5d175c42b25916dc8bc4,openstack/oslo.utils,master,I10fed16dad77ac17691a5d175c42b25916dc8bc4,Add a ``strict`` flag allowing users to restrict validation of IPv4 format,MERGED,2021-02-03 10:01:44.000000000,2021-02-06 00:50:03.000000000,2021-02-06 00:48:46.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2021-02-03 10:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/6fabbc69e50079b604e1417725959a5e6a5e1c7c', 'message': 'Allow to convert IPV4 addresses from text to binary form.\n\nAdd flags to `netutils.is_valid_ipv4` and define inet_pton to\nallow users to convert IPv4 addresses from text to binary form.\n\nhttps://github.com/netaddr/netaddr/issues/186\nhttps://man7.org/linux/man-pages/man3/inet_pton.3.html\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1924436\n\nChange-Id: I10fed16dad77ac17691a5d175c42b25916dc8bc4\nCloses-Bug: #1914386\n'}, {'number': 2, 'created': '2021-02-05 12:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/4be15882bdeab91d82dd74381998916c352defe5', 'message': 'Add a ``strict`` flag allowing users to restrict validation to IP addresses\n\nAdd a ``strict`` flag allowing users to restrict validation to IP\naddresses in presentation format (``a.b.c.d``) as opposed to address\nformat (``a.b.c.d``, ``a.b.c``, ``a.b``, ``a``).\n\nhttps://github.com/netaddr/netaddr/issues/186\nhttps://man7.org/linux/man-pages/man3/inet_pton.3.html\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1924436\n\nChange-Id: I10fed16dad77ac17691a5d175c42b25916dc8bc4\nCloses-Bug: #1914386\n'}, {'number': 3, 'created': '2021-02-05 12:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/b2ea807c6de231ae3baf8299d5a5b3a119aea1f5', 'message': 'Add a ``strict`` flag allowing users to restrict validation of IP format\n\nAdd a ``strict`` flag allowing users to restrict validation to IP\naddresses in presentation format (``a.b.c.d``) as opposed to address\nformat (``a.b.c.d``, ``a.b.c``, ``a.b``, ``a``).\n\nhttps://github.com/netaddr/netaddr/issues/186\nhttps://man7.org/linux/man-pages/man3/inet_pton.3.html\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1924436\n\nChange-Id: I10fed16dad77ac17691a5d175c42b25916dc8bc4\nCloses-Bug: #1914386\n'}, {'number': 4, 'created': '2021-02-05 13:08:02.000000000', 'files': ['oslo_utils/tests/test_netutils.py', 'releasenotes/notes/allow-to-convert-ipv4-address-from-text-to-binary-8c46ad2d9989e8c5.yaml', 'oslo_utils/netutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/3288539a0b3be6b69efd2630b79133b918bb079b', 'message': 'Add a ``strict`` flag allowing users to restrict validation of IPv4 format\n\nAdd a ``strict`` flag allowing users to restrict validation to IP\naddresses in presentation format (``a.b.c.d``) as opposed to address\nformat (``a.b.c.d``, ``a.b.c``, ``a.b``, ``a``).\n\nhttps://github.com/netaddr/netaddr/issues/186\nhttps://man7.org/linux/man-pages/man3/inet_pton.3.html\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1924436\n\nChange-Id: I10fed16dad77ac17691a5d175c42b25916dc8bc4\nCloses-Bug: #1914386\n'}]",16,773863,3288539a0b3be6b69efd2630b79133b918bb079b,20,3,4,28522,,,0,"Add a ``strict`` flag allowing users to restrict validation of IPv4 format

Add a ``strict`` flag allowing users to restrict validation to IP
addresses in presentation format (``a.b.c.d``) as opposed to address
format (``a.b.c.d``, ``a.b.c``, ``a.b``, ``a``).

https://github.com/netaddr/netaddr/issues/186
https://man7.org/linux/man-pages/man3/inet_pton.3.html
https://bugzilla.redhat.com/show_bug.cgi?id=1924436

Change-Id: I10fed16dad77ac17691a5d175c42b25916dc8bc4
Closes-Bug: #1914386
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/63/773863/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/tests/test_netutils.py', 'releasenotes/notes/allow-to-convert-ipv4-address-from-text-to-binary-8c46ad2d9989e8c5.yaml', 'oslo_utils/netutils.py']",3,6fabbc69e50079b604e1417725959a5e6a5e1c7c,aton-flag,"# NOTE(hberaud) import INET_PTON to allow user to import it and # to use it as a flag with is_valid_ipv4 # https://github.com/netaddr/netaddr/issues/186#issuecomment-533291576 from netaddr.core import INET_PTON # noqadef is_valid_ipv4(address, flags=0): :param flags: Convert IPv4 addresses from text to binary form. If netutils.INET_PTON is passed addressed will be converted. :type flags: integer return netaddr.valid_ipv4(address, flags=flags)",def is_valid_ipv4(address): return netaddr.valid_ipv4(address),19,2
openstack%2Ftripleo-heat-templates~master~If9ecd82640b1419090bf169d2f00d02151082cd8,openstack/tripleo-heat-templates,master,If9ecd82640b1419090bf169d2f00d02151082cd8,[trivial] Fix mistaken variable rename,MERGED,2021-02-05 10:21:26.000000000,2021-02-05 23:46:55.000000000,2021-02-05 23:46:55.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-05 10:21:26.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a01784dc38cc4964905ba694c748b5d18f0d5e6d', 'message': ""[trivial] Fix mistaken variable rename\n\nIn https://review.opendev.org/772459 the leading 'u' was\nremoved from the variable name, resulting in the variable\nbeing renamed by mistake.\n\nThis patch corrects it.\n\nRelated-Bug: rhbz#1920293\n\nChange-Id: If9ecd82640b1419090bf169d2f00d02151082cd8\n""}]",0,774218,a01784dc38cc4964905ba694c748b5d18f0d5e6d,10,7,1,6816,,,0,"[trivial] Fix mistaken variable rename

In https://review.opendev.org/772459 the leading 'u' was
removed from the variable name, resulting in the variable
being renamed by mistake.

This patch corrects it.

Related-Bug: rhbz#1920293

Change-Id: If9ecd82640b1419090bf169d2f00d02151082cd8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/774218/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,a01784dc38cc4964905ba694c748b5d18f0d5e6d,, upgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout}, pgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout},1,1
openstack%2Fmanila~master~I5127e150e8a71e621890f30dba6720b3932cf583,openstack/manila,master,I5127e150e8a71e621890f30dba6720b3932cf583,Advertise v2 API routes without project_id,MERGED,2021-02-02 15:23:18.000000000,2021-02-05 23:39:24.000000000,2021-02-05 22:26:55.000000000,"[{'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2021-02-02 15:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a046ce98d204e948eb2017d3f1e188505d2b6e81', 'message': 'WIP: Advertise routes without project_id\n\nChange-Id: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 2, 'created': '2021-02-03 17:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b990234dc6891ef74459ab1f5829b7eda661eccc', 'message': 'Advertise v2 API routes without project_id\n\nManila APIs have had the requirement to include\nproject_id in the URLs since the very beginning.\nThis comes from an old assumption that our APIs\nwould be differentiated per-tenant on the cloud,\nand we would allow different kinds of API endpoints\n(public, admin, internal, etc). We don\'t _need_\nthe project_id information that we receive in\nthe URL for any of our APIs to function. We rather\nauthorize tenants by gathering information from\nthe Identity service (Keystone) and wrapping that\ninto a RequestContext object that we then rely on\nto ensure namespace isolation.\n\nRemoving the requirement for ""project_id"" simplifies\nour API endpoint structure in the service catalog\nas well as provides a way for system scoped users\nto interact with manila without having to declare\ntheir project.\n\nIn order to make project_id optional in urls, the\npossible values of project_id have to be constrained.\nThis change introduces a new configuration option\nso deployers may control that. This configuration\noption defaults to accepting UUIDs with and without\ndashes.\n\nSince manila can be used in standalone deployments\nwithout the need for Keystone, this change introduces\na noauth middleware that can work without project_id\nin the URL paths.\n\nThe API version has been incremented to signal this\nchange to end users. When 2.60 is available, deployments\nmay drop ""project_id"" in the service catalog endpoint\nfor Manila and end users applications can stop needing\nit as well (if they don\'t already rely on the service\ncatalog for this data).\n\nAPIImpact\nDocImpact\nImplements: bp remove-project-id-from-urls\nChange-Id: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 3, 'created': '2021-02-03 17:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/bb413c16f58841352ad9816ec6da0f46fd516489', 'message': 'Advertise v2 API routes without project_id\n\nManila APIs have had the requirement to include\nproject_id in the URLs since the very beginning.\nThis comes from an old assumption that our APIs\nwould be differentiated per-tenant on the cloud,\nand we would allow different kinds of API endpoints\n(public, admin, internal, etc). We don\'t _need_\nthe project_id information that we receive in\nthe URL for any of our APIs to function. We rather\nauthorize tenants by gathering information from\nthe Identity service (Keystone) and wrapping that\ninto a RequestContext object that we then rely on\nto ensure namespace isolation.\n\nRemoving the requirement for ""project_id"" simplifies\nour API endpoint structure in the service catalog\nas well as provides a way for system scoped users\nto interact with manila without having to declare\ntheir project.\n\nIn order to make project_id optional in urls, the\npossible values of project_id have to be constrained.\nThis change introduces a new configuration option\nso deployers may control that. This configuration\noption defaults to accepting UUIDs with and without\ndashes.\n\nSince manila can be used in standalone deployments\nwithout the need for Keystone, this change introduces\na noauth middleware that can work without project_id\nin the URL paths.\n\nThe API version has been incremented to signal this\nchange to end users. When 2.60 is available, deployments\nmay drop ""project_id"" in the service catalog endpoint\nfor Manila and end users applications can stop needing\nit as well (if they don\'t already rely on the service\ncatalog for this data).\n\nAPIImpact\nDocImpact\nImplements: bp remove-project-id-from-urls\nChange-Id: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 4, 'created': '2021-02-05 07:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/218c948812b5421faf709ea8eea659f9440d5885', 'message': 'Advertise v2 API routes without project_id\n\nManila APIs have had the requirement to include\nproject_id in the URLs since the very beginning.\nThis comes from an old assumption that our APIs\nwould be differentiated per-tenant on the cloud,\nand we would allow different kinds of API endpoints\n(public, admin, internal, etc). While it is possible\nto set up different endpoints against the API\nservice, the same and complete API is exposed at\neach of these endpoints.\n\nWe don\'t _need_ the project_id information that\nwe receive in the URL for any of our APIs to\nfunction. We rather authorize tenants by gathering\ninformation from the Identity service (Keystone)\nand wrapping that into a RequestContext object\nthat we then rely on to ensure namespace isolation.\n\nRemoving the requirement for ""project_id"" simplifies\nour API endpoint structure in the service catalog\nas well as provides a way for system scoped users\nto interact with manila without having to declare\ntheir project.\n\nIn order to make project_id optional in urls, the\npossible values of project_id have to be constrained.\nThis change introduces a new configuration option\nso deployers may control that. This configuration\noption defaults to accepting UUIDs with and without\ndashes.\n\nSince manila can be used in standalone deployments\nwithout the need for Keystone, this change introduces\na noauth middleware that can work without project_id\nin the URL paths.\n\nThe API version has been incremented to signal this\nchange to end users. When 2.60 is available, deployments\nmay drop ""project_id"" in the service catalog endpoint\nfor Manila and end users applications can stop needing\nit as well (if they don\'t already rely on the service\ncatalog for this data).\n\nAPIImpact\nImplements: bp remove-project-id-from-urls\nChange-Id: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 5, 'created': '2021-02-05 07:21:03.000000000', 'files': ['manila/tests/api/v1/test_share_snapshots.py', 'manila/tests/api/v1/test_shares.py', 'manila/api/common.py', 'manila/api/openstack/__init__.py', 'manila/api/v2/router.py', 'manila/tests/integrated/integrated_helpers.py', 'manila/tests/api/v2/test_share_snapshot_instance_export_locations.py', 'manila/tests/conf_fixture.py', 'manila/common/config.py', 'manila/tests/api/v2/test_messages.py', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/tests/api/v2/test_share_snapshot_export_locations.py', 'manila/tests/api/v2/test_share_instances.py', 'manila/tests/fake_share.py', 'manila/api/middleware/auth.py', 'manila/tests/api/v2/test_share_snapshots.py', 'releasenotes/notes/bp-remove-project-id-from-urls-9f338371b8ffa203.yaml', 'etc/manila/api-paste.ini', 'manila/tests/api/v2/test_shares.py', 'manila/tests/integrated/api/client.py', 'manila/tests/api/fakes.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/263d5438f0df0a13bb71a154034aa8d071609b65', 'message': 'Advertise v2 API routes without project_id\n\nManila APIs have had the requirement to include\nproject_id in the URLs since the very beginning.\nThis comes from an old assumption that our APIs\nwould be differentiated per-tenant on the cloud,\nand we would allow different kinds of API endpoints\n(public, admin, internal, etc). While it is possible\nto set up different endpoints against the API\nservice, the same and complete API is exposed at\neach of these endpoints.\n\nWe don\'t _need_ the project_id information that\nwe receive in the URL for any of our APIs to\nfunction. We rather authorize tenants by gathering\ninformation from the Identity service (Keystone)\nand wrapping that into a RequestContext object\nthat we then rely on to ensure namespace isolation.\n\nRemoving the requirement for ""project_id"" simplifies\nour API endpoint structure in the service catalog\nas well as provides a way for system scoped users\nto interact with manila without having to declare\ntheir project.\n\nIn order to make project_id optional in urls, the\npossible values of project_id have to be constrained.\nThis change introduces a new configuration option\nso deployers may control that. This configuration\noption defaults to accepting UUIDs with and without\ndashes.\n\nSince manila can be used in standalone deployments\nwithout the need for Keystone, this change introduces\na noauth middleware that can work without project_id\nin the URL paths.\n\nThe API version has been incremented to signal this\nchange to end users. When 2.60 is available, deployments\nmay drop ""project_id"" in the service catalog endpoint\nfor Manila and end users applications can stop needing\nit as well (if they don\'t already rely on the service\ncatalog for this data).\n\nAPIImpact\nImplements: bp remove-project-id-from-urls\nChange-Id: I5127e150e8a71e621890f30dba6720b3932cf583\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",16,773709,263d5438f0df0a13bb71a154034aa8d071609b65,50,4,5,16643,,,0,"Advertise v2 API routes without project_id

Manila APIs have had the requirement to include
project_id in the URLs since the very beginning.
This comes from an old assumption that our APIs
would be differentiated per-tenant on the cloud,
and we would allow different kinds of API endpoints
(public, admin, internal, etc). While it is possible
to set up different endpoints against the API
service, the same and complete API is exposed at
each of these endpoints.

We don't _need_ the project_id information that
we receive in the URL for any of our APIs to
function. We rather authorize tenants by gathering
information from the Identity service (Keystone)
and wrapping that into a RequestContext object
that we then rely on to ensure namespace isolation.

Removing the requirement for ""project_id"" simplifies
our API endpoint structure in the service catalog
as well as provides a way for system scoped users
to interact with manila without having to declare
their project.

In order to make project_id optional in urls, the
possible values of project_id have to be constrained.
This change introduces a new configuration option
so deployers may control that. This configuration
option defaults to accepting UUIDs with and without
dashes.

Since manila can be used in standalone deployments
without the need for Keystone, this change introduces
a noauth middleware that can work without project_id
in the URL paths.

The API version has been incremented to signal this
change to end users. When 2.60 is available, deployments
may drop ""project_id"" in the service catalog endpoint
for Manila and end users applications can stop needing
it as well (if they don't already rely on the service
catalog for this data).

APIImpact
Implements: bp remove-project-id-from-urls
Change-Id: I5127e150e8a71e621890f30dba6720b3932cf583
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/773709/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/common.py', 'manila/api/openstack/__init__.py', 'manila/api/v2/router.py', 'etc/manila/api-paste.ini', 'manila/tests/conf_fixture.py', 'manila/tests/api/fakes.py', 'manila/common/config.py', 'manila/api/openstack/api_version_request.py', 'manila/api/openstack/rest_api_version_history.rst', 'manila/api/middleware/auth.py']",10,a046ce98d204e948eb2017d3f1e188505d2b6e81,bp/remove-project-id-from-urls,"class NoAuthMiddlewareBase(base_wsgi.Middleware): def base_call(self, req, project_id_in_path=False): if project_id_in_path: os_url = os.path.join([req.url.rstrip('/'), project_id]) else: os_url = req.url.rstrip('/') class NoAuthMiddleware(NoAuthMiddlewareBase): """"""Return a fake token if one isn't specified. Sets project_id in URLs. """""" @webob.dec.wsgify(RequestClass=wsgi.Request) def __call__(self, req): return self.base_call(req, project_id_in_path=True) class NoAuthMiddlewarev2_60(NoAuthMiddlewareBase): """"""Return a fake token if one isn't specified. Does not set project_id in URLs. """""" @webob.dec.wsgify(RequestClass=wsgi.Request) def __call__(self, req): return self.base_call(req)","class NoAuthMiddleware(base_wsgi.Middleware): @webob.dec.wsgify(RequestClass=wsgi.Request) def __call__(self, req): os_url = os.path.join(req.url, project_id)",352,216
openstack%2Fopenstack-ansible-os_tempest~master~If53aca6f16324d305b150466b94d3f18c8a1096a,openstack/openstack-ansible-os_tempest,master,If53aca6f16324d305b150466b94d3f18c8a1096a,Move tempest pip package from a constraint to a requirement,MERGED,2021-01-12 12:09:07.000000000,2021-02-05 23:29:50.000000000,2021-02-05 23:28:37.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-12 12:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/4c82d9c80708936773d3ac5d9f26c6783efb3426', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}, {'number': 2, 'created': '2021-01-13 08:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/4586aff01b52f7b7372b2899de5fae5c92514ac8', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}, {'number': 3, 'created': '2021-01-13 16:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/11caa027e9f01294fa9688f788fff9781930804d', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}, {'number': 4, 'created': '2021-01-13 20:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ffc89f5aab0be4ed992f663406424370bffe1c1d', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}, {'number': 5, 'created': '2021-01-14 16:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/ad9cb528bb357bc2a79a989cc02287792096a0f6', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}, {'number': 6, 'created': '2021-01-18 16:38:16.000000000', 'files': ['tasks/tempest_install_source.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/1fd23f2aede8a5a48621ccad808579c69212f845', 'message': 'Move tempest pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: If53aca6f16324d305b150466b94d3f18c8a1096a\n'}]",0,770281,1fd23f2aede8a5a48621ccad808579c69212f845,25,3,6,25023,,,0,"Move tempest pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: If53aca6f16324d305b150466b94d3f18c8a1096a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/81/770281/5 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,4c82d9c80708936773d3ac5d9f26c6783efb3426,osa-new-pip," - ""{{ (tempest_git_repo is defined) | ternary('git+' ~ (tempest_git_repo | default('https://opendev.org/openstack/tempest.git')) ~ '@' ~ tempest_git_install_branch ~ '#egg=tempest', 'tempest') }}"""," - ""{{ (tempest_git_repo is defined) | ternary('git+' ~ (tempest_git_repo | default('https://opendev.org/openstack/tempest.git')) ~ '@' ~ tempest_git_install_branch ~ '#egg=tempest', '') }}"" - tempest",1,2
openstack%2Ftripleo-upgrade~stable%2Fvictoria~Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,openstack/tripleo-upgrade,stable/victoria,Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,[live-migration] Count all hosts from all tenants for migration timeout,MERGED,2021-02-04 09:59:27.000000000,2021-02-05 22:55:31.000000000,2021-02-05 22:55:31.000000000,"[{'_account_id': 11166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 09:59:27.000000000', 'files': ['templates/node_upgrade_pre.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/4e7aa848d6cd7a8dc0b97f77a803ddb738799121', 'message': '[live-migration] Count all hosts from all tenants for migration timeout\n\nChange-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9\n(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)\n'}]",0,773959,4e7aa848d6cd7a8dc0b97f77a803ddb738799121,12,2,1,6816,,,0,"[live-migration] Count all hosts from all tenants for migration timeout

Change-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9
(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/59/773959/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/node_upgrade_pre.sh.j2'],1,4e7aa848d6cd7a8dc0b97f77a803ddb738799121,,"INSTANCE_COUNT=$(openstack server list --all --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')","INSTANCE_COUNT=$(openstack server list --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')",1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I82cc708deb4400b7191b4f706e12f817bc28f0bb,openstack/tripleo-heat-templates,stable/train,I82cc708deb4400b7191b4f706e12f817bc28f0bb,Make ExternalSwift*Url parameters optional,MERGED,2021-02-03 21:58:23.000000000,2021-02-05 22:55:26.000000000,2021-02-05 22:55:26.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-02-03 21:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c8b1dda38769a4be30dab87c3f71f9b4df5f505', 'message': ""Make ExternalSwift*Url parameters optional\n\nFor backward compatibility reasons, ExternalPublicUrl prevail on ExternalSwiftPublicUrl\nyet the templates force setting ExternalSwiftPublicUrl because it does not have a\ndefault when that isn't necessary and won't be honored if ExternalPublisUrl is set\n\nChange-Id: I82cc708deb4400b7191b4f706e12f817bc28f0bb\nCloses-Bug: 1914471\n""}, {'number': 2, 'created': '2021-02-03 22:01:12.000000000', 'files': ['deployment/swift/external-swift-proxy-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cf605138f2ee38cf6b224e5f4f956a31996d2b2c', 'message': ""Make ExternalSwift*Url parameters optional\n\nFor backward compatibility reasons, ExternalPublicUrl prevail on\nExternalSwiftPublicUrl yet the templates force setting it\nbecause it does not have a default; that is not necessary instead\nand in fact ExternalSwiftPublicUrl won't be honored if\nExternalPublicUrl is set.\n\nChange-Id: I82cc708deb4400b7191b4f706e12f817bc28f0bb\nCloses-Bug: 1914471\n""}]",0,774003,cf605138f2ee38cf6b224e5f4f956a31996d2b2c,15,3,2,6796,,,0,"Make ExternalSwift*Url parameters optional

For backward compatibility reasons, ExternalPublicUrl prevail on
ExternalSwiftPublicUrl yet the templates force setting it
because it does not have a default; that is not necessary instead
and in fact ExternalSwiftPublicUrl won't be honored if
ExternalPublicUrl is set.

Change-Id: I82cc708deb4400b7191b4f706e12f817bc28f0bb
Closes-Bug: 1914471
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/774003/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/swift/external-swift-proxy-baremetal-puppet.yaml'],1,0c8b1dda38769a4be30dab87c3f71f9b4df5f505,, default: '' default: '' default: '',,3,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I0e041c6a95a7f53019967f9263df2326b1408c6f,openstack/tripleo-heat-templates,stable/train,I0e041c6a95a7f53019967f9263df2326b1408c6f,Serialize shutdown of pacemaker nodes,MERGED,2020-10-28 13:28:31.000000000,2021-02-05 22:53:32.000000000,2021-02-05 22:53:32.000000000,"[{'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-10-28 13:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e946e3566ca134a0ca5d5a8c4a57727b7bc2ab6d', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 2, 'created': '2020-10-28 19:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/685dba661d21c869a631e830f9df0ded13c57eb1', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 3, 'created': '2020-11-25 22:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c90e649d6890d8fc75b2e6d8ecd8c634218f2440', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 4, 'created': '2020-11-27 11:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/93835b3730c0375965b0cbabc4f398fbd76cf5e9', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 5, 'created': '2020-12-14 15:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5c71fdee78a72c9946d908a0618072394f61d46', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 6, 'created': '2020-12-14 20:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a20bc0baa03271e92e175fbf202eb11ad277cb40', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 7, 'created': '2020-12-14 20:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a2d26be1c58b65b1b86c314fa472ed57323bd902', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 8, 'created': '2020-12-17 14:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d0b7adabe89bbbe2ead549ea9c2b115f84a91363', 'message': 'DNR test backport of https://review.opendev.org/#/c/759242/\n\nWIP Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit adf83cfe26160ebe80ff44e8402d3fa2a51d51e5)\n'}, {'number': 9, 'created': '2021-02-04 10:20:19.000000000', 'files': ['deployment/containers-common.yaml', 'container_config_scripts/pacemaker_mutex_shutdown.sh', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml', 'container_config_scripts/pacemaker_resource_lock.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6733d14f11e4a15597ba9cbcf4df5e92ce2e914c', 'message': 'Serialize shutdown of pacemaker nodes\n\nWhen running minor update in a composable HA, different\nroles could run ansible tasks concurrently. However,\nthere is currently a race when pacemaker nodes are\nstopped in parallel [1,2], that could cause nodes to\nincorrectly stop themselves once they reconnect to the\ncluster.\n\nTo prevent concurrent shutdown, use a cluster-wide lock\nto signals that one node is about to shutdown, and block\nthe others until the node disconnects from the cluster.\n\nTested the minor update in a composable HA environment:\n  . when run with ""openstack update run"", every role\n    is updated sequentially, and the shutdown lock\n    doesn\'t interfere.\n  . when running multiple ansible tasks in parallel\n    ""openstack update run --limit role<X>"", pacemaker\n    nodes are correctly stopped sequentially thanks\n    to the shutdown lock.\n  . when updating an existing overcloud, the new\n    locking script used in the review is correctly\n    injected on the overcloud, thanks to [3].\n\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404\n[3] I2ac6bb98e1d4183327e888240fc8d5a70e0d6fcb\n\nCloses-Bug: #1904193\nChange-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f\n(cherry picked from commit cb55cc8ce538f3e075754b0328872ec075f4cde9)\n(cherry picked from commit 8e9798caf65296e3849afad3a5dbed12f23c735a)\n(cherry picked from commit 83ba65e3ae3259e74186eb3db8bce1a2ba546e90)\n'}]",0,760133,6733d14f11e4a15597ba9cbcf4df5e92ce2e914c,32,4,9,20778,,,0,"Serialize shutdown of pacemaker nodes

When running minor update in a composable HA, different
roles could run ansible tasks concurrently. However,
there is currently a race when pacemaker nodes are
stopped in parallel [1,2], that could cause nodes to
incorrectly stop themselves once they reconnect to the
cluster.

To prevent concurrent shutdown, use a cluster-wide lock
to signals that one node is about to shutdown, and block
the others until the node disconnects from the cluster.

Tested the minor update in a composable HA environment:
  . when run with ""openstack update run"", every role
    is updated sequentially, and the shutdown lock
    doesn't interfere.
  . when running multiple ansible tasks in parallel
    ""openstack update run --limit role<X>"", pacemaker
    nodes are correctly stopped sequentially thanks
    to the shutdown lock.
  . when updating an existing overcloud, the new
    locking script used in the review is correctly
    injected on the overcloud, thanks to [3].

[1] https://bugzilla.redhat.com/show_bug.cgi?id=1791841
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1872404
[3] I2ac6bb98e1d4183327e888240fc8d5a70e0d6fcb

Closes-Bug: #1904193
Change-Id: I0e041c6a95a7f53019967f9263df2326b1408c6f
(cherry picked from commit cb55cc8ce538f3e075754b0328872ec075f4cde9)
(cherry picked from commit 8e9798caf65296e3849afad3a5dbed12f23c735a)
(cherry picked from commit 83ba65e3ae3259e74186eb3db8bce1a2ba546e90)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/33/760133/8 && git format-patch -1 --stdout FETCH_HEAD,"['container_config_scripts/pacemaker_mutex_shutdown.sh', 'deployment/pacemaker/pacemaker-baremetal-puppet.yaml', 'container_config_scripts/pacemaker_resource_lock.sh']",3,e946e3566ca134a0ca5d5a8c4a57727b7bc2ab6d,pcmk-shutdown-lock-stable/train,"# Retrieve the owner of a lock from the CIB # this is a read-only operation, so no need to log debug info lock_get_owner() { local lockname=$1 local rc local lock local owner pcs cluster cib > $TMP_CIB rc=$? if [ $rc -ne 0 ]; then return 2 fi lock=$(lock_get $TMP_CIB $lockname) rc=$? if [ $rc -ne 0 ]; then return 2 fi if [ -z ""$lock"" ]; then return 1 else lock_owner $lock return 0 fi } if [ -z ""$LOCKNAME"" ]; then error ""You must specific a lock name"" fi if [ $ACTION != ""--owner"" ] && [ $ACTION != ""-o"" ]; then if [ -z ""$REQUESTER"" ]; then error ""You must specific a lock requester"" fi --acquire-once|-A) lock_acquire $LOCKNAME $REQUESTER $TTL;; --owner|-o) lock_get_owner $LOCKNAME;;"," if [ -z ""$LOCKNAME"" ] || [ -z ""$REQUESTER"" ]; then error ""You must specific a lock name and a requester""",164,3
openstack%2Fopenstack-helm-infra~master~I4e8746f428da383759884fbadacd6a50a847a19b,openstack/openstack-helm-infra,master,I4e8746f428da383759884fbadacd6a50a847a19b,[ceph-client] Update ceph-client release notes to current,MERGED,2021-02-04 23:07:52.000000000,2021-02-05 22:38:17.000000000,2021-02-05 22:36:43.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-04 23:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/29218543f4753b9ec1cb655b505d70a551ecdb96', 'message': '[ceph-client] Update ceph-client release notes to current\n\nThis change updates the releasenotes for ceph-client to all current\nchanges as of the date of this commit.\n\nChange-Id: I4e8746f428da383759884fbadacd6a50a847a19b\n'}, {'number': 2, 'created': '2021-02-05 22:12:22.000000000', 'files': ['releasenotes/notes/ceph-client.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f4f072c2a75c4c35c7a40cfda6cb6fa9c1a2b792', 'message': '[ceph-client] Update ceph-client release notes to current\n\nThis change updates the releasenotes for ceph-client to all current\nchanges as of the date of this commit.\n\nChange-Id: I4e8746f428da383759884fbadacd6a50a847a19b\n'}]",0,774169,f4f072c2a75c4c35c7a40cfda6cb6fa9c1a2b792,15,11,2,28372,,,0,"[ceph-client] Update ceph-client release notes to current

This change updates the releasenotes for ceph-client to all current
changes as of the date of this commit.

Change-Id: I4e8746f428da383759884fbadacd6a50a847a19b
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/69/774169/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-client.yaml'],1,29218543f4753b9ec1cb655b505d70a551ecdb96,ceph-charts-release-notes," - 0.1.0 Change helm-toolkit dependency version to "">= 0.1.0"" - 0.1.2 fix the logic to disable the autoscaler on pools - 0.1.3 Run as ceph user and disallow privilege escalation - 0.1.4 Improvements for ceph-client helm tests - 0.1.5 Fix Helm test check_pgs() check for inactive PGs",,5,0
openstack%2Fopenstack-helm-infra~master~I9a2985855a25cdb98ef6fe011ba473587ea7a4c9,openstack/openstack-helm-infra,master,I9a2985855a25cdb98ef6fe011ba473587ea7a4c9,[ceph-client] Don't wait for premerge PGs in the rbd pool job,MERGED,2021-02-05 15:57:49.000000000,2021-02-05 22:12:37.000000000,2021-02-05 22:11:04.000000000,"[{'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-05 15:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7dcfb8bc5a5de478f1ff9d96378a8b435a5973e7', 'message': '[ceph-client] Don\'t wait for premerge PGs in the rbd pool job\n\nThe wait_for_pgs() function in the rbd pool job waits for all PGs\nto become active before proceeding, but in the event of an upgrade\nthat decreases pg_num values on one or more pools it sees PGs in\nthe clean+premerge+peered state as peering and waits for ""peering""\nto complete. Since these PGs are in the process of merging into\nactive PGs, waiting for the merge to complete is unnecessary. This\nchange will reduce the wait time in this job significantly in\nthese cases.\n\nChange-Id: I9a2985855a25cdb98ef6fe011ba473587ea7a4c9\n'}, {'number': 2, 'created': '2021-02-05 16:55:37.000000000', 'files': ['ceph-client/templates/bin/pool/_init.sh.tpl', 'ceph-client/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1dcaffdf7043ddaca0511de4ec6aac214be4dca0', 'message': '[ceph-client] Don\'t wait for premerge PGs in the rbd pool job\n\nThe wait_for_pgs() function in the rbd pool job waits for all PGs\nto become active before proceeding, but in the event of an upgrade\nthat decreases pg_num values on one or more pools it sees PGs in\nthe clean+premerge+peered state as peering and waits for ""peering""\nto complete. Since these PGs are in the process of merging into\nactive PGs, waiting for the merge to complete is unnecessary. This\nchange will reduce the wait time in this job significantly in\nthese cases.\n\nChange-Id: I9a2985855a25cdb98ef6fe011ba473587ea7a4c9\n'}]",0,774276,1dcaffdf7043ddaca0511de4ec6aac214be4dca0,19,11,2,29974,,,0,"[ceph-client] Don't wait for premerge PGs in the rbd pool job

The wait_for_pgs() function in the rbd pool job waits for all PGs
to become active before proceeding, but in the event of an upgrade
that decreases pg_num values on one or more pools it sees PGs in
the clean+premerge+peered state as peering and waits for ""peering""
to complete. Since these PGs are in the process of merging into
active PGs, waiting for the merge to complete is unnecessary. This
change will reduce the wait time in this job significantly in
these cases.

Change-Id: I9a2985855a25cdb98ef6fe011ba473587ea7a4c9
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/76/774276/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-client/templates/bin/pool/_init.sh.tpl'],1,7dcfb8bc5a5de478f1ff9d96378a8b435a5973e7,," query='map({state: .state}) | group_by(.state) | map({state: .[0].state, count: length}) | .[] | select(.state | contains(""active"") or contains(""premerge"") | not)'"," query='map({state: .state}) | group_by(.state) | map({state: .[0].state, count: length}) | .[] | select(.state | contains(""active"") | not)'",1,1
openstack%2Ftripleo-docs~master~Ie671804966a5c579ceab0f06f18d9814addc6751,openstack/tripleo-docs,master,Ie671804966a5c579ceab0f06f18d9814addc6751,Update DCN documentation for rename of dcn-hci to dcn-storage,MERGED,2021-01-26 20:52:38.000000000,2021-02-05 22:12:27.000000000,2021-02-05 22:10:50.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-26 20:52:38.000000000', 'files': ['deploy-guide/source/features/distributed_compute_node.rst', 'deploy-guide/source/features/distributed_multibackend_storage.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/b765122851ef49334cac82b2017374c99b717434', 'message': 'Update DCN documentation for rename of dcn-hci to dcn-storage\n\nIf Ice5e1cfbc158eb6705988706c8625bedb80d7de2 merges, then the\ndocumentation should be renamed accordingly.\n\nDepends-On: Ice5e1cfbc158eb6705988706c8625bedb80d7de2\nChange-Id: Ie671804966a5c579ceab0f06f18d9814addc6751\n'}]",0,772600,b765122851ef49334cac82b2017374c99b717434,13,5,1,18002,,,0,"Update DCN documentation for rename of dcn-hci to dcn-storage

If Ice5e1cfbc158eb6705988706c8625bedb80d7de2 merges, then the
documentation should be renamed accordingly.

Depends-On: Ice5e1cfbc158eb6705988706c8625bedb80d7de2
Change-Id: Ie671804966a5c579ceab0f06f18d9814addc6751
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/00/772600/1 && git format-patch -1 --stdout FETCH_HEAD,"['deploy-guide/source/features/distributed_compute_node.rst', 'deploy-guide/source/features/distributed_multibackend_storage.rst']",2,b765122851ef49334cac82b2017374c99b717434,dcn-storage,"the `environments/dcn-storage.yaml` environment file is included in the -e /usr/share/openstack-tripleo-heat-templates/environments/dcn-storage.yaml \``environments/dcn-storage.yaml`` contains the same parameters. The ``environments/dcn-storage.yaml`` file is also used to configure theBoth ``environments/dcn-storage.yaml`` and ``environments/dcn.yaml`` usedefault of ""dcn"" to ""dcn0"" found in `environments/dcn-storage.yaml`. Seeconfigured by deploying with `environments/dcn-storage.yaml`. If the","the `environments/dcn-hci.yaml` environment file is included in the -e /usr/share/openstack-tripleo-heat-templates/environments/dcn-hci.yaml \``environments/dcn-hci.yaml`` contains the same parameters. The ``environments/dcn-hci.yaml`` file is also used to configure theBoth ``environments/dcn-hci.yaml`` and ``environments/dcn.yaml`` usedefault of ""dcn"" to ""dcn0"" found in `environments/dcn-hci.yaml`. Seeconfigured by deploying with `environments/dcn-hci.yaml`. If the",8,8
openstack%2Fkolla~stable%2Fussuri~I0cfde46c29eedce77c70c1c677220814a801ff3a,openstack/kolla,stable/ussuri,I0cfde46c29eedce77c70c1c677220814a801ff3a,Remove sensu images,MERGED,2021-02-05 11:00:26.000000000,2021-02-05 22:04:46.000000000,2021-02-05 22:03:29.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 26285}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2021-02-05 11:00:26.000000000', 'files': ['docker/sensu/sensu-base/extend_start.sh', 'kolla/template/repos.yaml', 'docker/sensu/sensu-api/Dockerfile.j2', 'kolla/common/config.py', 'docker/base/sources.list.ubuntu', 'kolla/image/build.py', 'doc/source/matrix_x86.csv', 'doc/source/matrix_aarch64.csv', 'tools/validate-binary-build.sh', 'docker/sensu/sensu-base/Dockerfile.j2', 'releasenotes/notes/remove-sensu-a20b01d025385aa1.yaml', 'docker/sensu/sensu-server/Dockerfile.j2', 'docker/sensu/sensu-client/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/27b2914b43afe64d1e7c218aa8b6876851e9d9d6', 'message': 'Remove sensu images\n\nThey have been deprecated in Ussuri [1].\n\n[1]: https://review.opendev.org/#/c/711636/\n\nUpstream dropped it:\n\nIMPORTANT: Sensu Core reached end-of-life (EOL) on December 31, 2019, and we permanently removed the Sensu EOL repository on February 1, 2021.\n\nChange-Id: I0cfde46c29eedce77c70c1c677220814a801ff3a\n(cherry picked from commit 0cfd36292cccb8d3af9c65a1dff9696f50870df6)\n'}]",0,774127,27b2914b43afe64d1e7c218aa8b6876851e9d9d6,16,7,1,24072,,,0,"Remove sensu images

They have been deprecated in Ussuri [1].

[1]: https://review.opendev.org/#/c/711636/

Upstream dropped it:

IMPORTANT: Sensu Core reached end-of-life (EOL) on December 31, 2019, and we permanently removed the Sensu EOL repository on February 1, 2021.

Change-Id: I0cfde46c29eedce77c70c1c677220814a801ff3a
(cherry picked from commit 0cfd36292cccb8d3af9c65a1dff9696f50870df6)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/27/774127/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/sensu/sensu-base/extend_start.sh', 'kolla/template/repos.yaml', 'docker/sensu/sensu-api/Dockerfile.j2', 'kolla/common/config.py', 'docker/base/sources.list.ubuntu', 'kolla/image/build.py', 'doc/source/matrix_x86.csv', 'doc/source/matrix_aarch64.csv', 'tools/validate-binary-build.sh', 'docker/sensu/sensu-base/Dockerfile.j2', 'releasenotes/notes/remove-sensu-a20b01d025385aa1.yaml', 'docker/sensu/sensu-server/Dockerfile.j2', 'docker/sensu/sensu-client/Dockerfile.j2']",13,27b2914b43afe64d1e7c218aa8b6876851e9d9d6,remove_sensu-stable/ussuri,,"FROM {{ namespace }}/{{ image_prefix }}sensu-base:{{ tag }} {% block labels %} LABEL maintainer=""{{ maintainer }}"" name=""{{ image_name }}"" build-date=""{{ build_date }}"" {% endblock %} {% block sensu_client_header %}{% endblock %} {% import ""macros.j2"" as macros with context %} {{ macros.enable_extra_repos(['ceph']) }} {% if base_package_type == 'rpm' %} {% set sensu_client_packages = [ 'ceph-common', 'cyrus-sasl-devel', 'docker-client', 'gcc-c++', 'make', 'mariadb', 'ntp', 'python3-pymongo', 'ruby-devel' ] %} {% elif base_package_type == 'deb' %} {% set sensu_client_packages = [ 'build-essential', 'ceph-common', 'docker.io', 'inetutils-ping', 'libsasl2-dev', 'mysql-client', 'ntp', 'python3-cephfs', 'python3-pymongo', 'python3-rados', 'python3-rbd' ] %} {% else %} RUN echo '{{ image_name }} not yet available for {{ base_distro }}' \ && /bin/false {% endif %} {{ macros.install_packages(sensu_client_packages | customizable(""packages"")) }} {% block sensu_clients_install %} # Sensu plugins are all using semantic versioning. # Let's cap them to the known major version that works with the ruby shipped on # rhel/centos (currently 2.0) {% set sensu_plugins = [ 'cpu-checks:""~>1""', 'disk-checks:""~>2""', 'dns:""~>1""', 'docker:""~>3""', 'elasticsearch:""~>1""', 'filesystem-checks:""~>1""', 'haproxy:""~>1""', 'http:""~>1""', 'io-checks:""~>1""', 'load-checks:""~>3""', 'memcached:""~>0""', 'memory-checks:""~>1""', 'mongodb:""~>0""', 'mysql:""~>2""', 'network-checks:""~>2""', 'ntp:""~>1""', 'openstack:""~>1""', 'rabbitmq:""~>3""', 'redis:""~>2""', 'uptime-checks:""~>1""', 'vmstats:""~>1""' ] %} # TODO(mandre) Use packaged sensu plugins from centos-opstools for binary distro # http://cbs.centos.org/koji/search?match=glob&type=package&terms=*sensu* # NOTE(hrw): whois 5.0.0 requires Ruby 2.4+ while CentOS has 2.0 # NOTE(yoctozepto): pinning minitest for the same reason RUN {%if base_package_type == 'rpm' %} gem install whois:""<5"" minitest:""~>5.11.3"" && {% endif %} sensu-install --plugins {{ sensu_plugins | customizable('plugins') | join (',') }} {% endblock %} {% block sensu_client_footer %}{% endblock %} {% block footer %}{% endblock %} ",6,189
openstack%2Fcharm-glance~master~Ic54fbe28736c8923b90d868d5c91ac926e78e59e,openstack/charm-glance,master,Ic54fbe28736c8923b90d868d5c91ac926e78e59e,[DO NOT MERGE] no-op for testing,ABANDONED,2021-01-28 23:50:38.000000000,2021-02-05 22:00:21.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-28 23:50:38.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/e197d2c0e0f0e026e86607b3666891a881ed3f6f', 'message': '[DO NOT MERGE] no-op for testing\n\nThis is a no-op PR meant to test a Zaza change\n\nFunc-Test-Pr: https://github.com/openstack-charmers/zaza/pull/412\nChange-Id: Ic54fbe28736c8923b90d868d5c91ac926e78e59e\n'}]",0,772957,e197d2c0e0f0e026e86607b3666891a881ed3f6f,10,2,1,32803,,,0,"[DO NOT MERGE] no-op for testing

This is a no-op PR meant to test a Zaza change

Func-Test-Pr: https://github.com/openstack-charmers/zaza/pull/412
Change-Id: Ic54fbe28736c8923b90d868d5c91ac926e78e59e
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/57/772957/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,e197d2c0e0f0e026e86607b3666891a881ed3f6f,,,,1,0
openstack%2Fcharm-designate~master~I46fb4fe2c853154f11ea0c8b86cb682b21d1a5c7,openstack/charm-designate,master,I46fb4fe2c853154f11ea0c8b86cb682b21d1a5c7,[DO NOT MERGE] no-op for testing,ABANDONED,2021-01-28 23:33:21.000000000,2021-02-05 22:00:00.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-28 23:33:21.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/b363a23349566af038b42b8579d1d009c53157bc', 'message': '[DO NOT MERGE] no-op for testing\n\nThis is a no-op PR meant to test a Zaza change\n\nFunc-Test-Pr: https://github.com/openstack-charmers/zaza/pull/412\nChange-Id: I46fb4fe2c853154f11ea0c8b86cb682b21d1a5c7\n'}]",0,772956,b363a23349566af038b42b8579d1d009c53157bc,10,2,1,32803,,,0,"[DO NOT MERGE] no-op for testing

This is a no-op PR meant to test a Zaza change

Func-Test-Pr: https://github.com/openstack-charmers/zaza/pull/412
Change-Id: I46fb4fe2c853154f11ea0c8b86cb682b21d1a5c7
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/56/772956/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,b363a23349566af038b42b8579d1d009c53157bc,,,,1,0
openstack%2Fneutron~master~I89438feae3c0244f6da5e6a2a035d45b956ac247,openstack/neutron,master,I89438feae3c0244f6da5e6a2a035d45b956ac247,Process DHCP events in order if related,MERGED,2021-01-29 17:22:05.000000000,2021-02-05 21:34:30.000000000,2021-02-05 21:32:31.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-29 17:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/21641f7aa91b4abae641f923aba730af167cb081', 'message': '[WIP] Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 2, 'created': '2021-02-01 11:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30ae562a0bbdd92cc25c7560105b0492c69ed407', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 3, 'created': '2021-02-01 11:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3815e66623a82098da7800b8b581dc0955504601', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 4, 'created': '2021-02-01 15:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8904d0a1894f65e1076e1ec599b29bae361a61f', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 5, 'created': '2021-02-03 14:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a473d52c32018a83f67f26b46515a26f9210527f', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 6, 'created': '2021-02-04 12:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c6d25cae9fa0d375823f8ae1f92d5dfcb66668e', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}, {'number': 7, 'created': '2021-02-04 15:39:28.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3c229b9cc5c293b4d512f269d5ddb3708fd303a', 'message': 'Process DHCP events in order if related\n\nWhen processing port events (create, update, delete), the port\nprovisioning (port creation) has priority over the other events [1].\nAs reported in the related bug, if a port deletion with an IP\naddress and another port creation with the same IP address arrive\nto the DHCP agent, those events can be processed in the same queue.\n\nBecause of the creation event priority, even when this event arrived\nafter the deletion event, it will be processed first. That will\nclash with the DHCP agent cache, that contains a port (not deleted\nyet) with the same IP address. That will trigger an unwanted resync.\n\nThis patch implements a specific logic to store the events in\n""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When\na port event arrives, the event comparison method checks the\n(subnet, fixed_ips) tuple set of both elements. If there is a\ncoincidence, that means those ports are the same or are using\nthe same IP addreses (the race condition explained in the bug).\nIn this case, the priority is defined only by the timestamp;\nthat means the events are processed in order of arrival.\n\nBecause the Neutron server do not allow to have two ports in the\nsame subnet with the same IP address, the order of the events is\nguaranteed. In the case explained in the bug, the deletion event\nwill be processed first.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/626830\n[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue\n\nCloses-Bug: #1913723\n\nChange-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247\n'}]",25,773160,f3c229b9cc5c293b4d512f269d5ddb3708fd303a,68,6,7,16688,,,0,"Process DHCP events in order if related

When processing port events (create, update, delete), the port
provisioning (port creation) has priority over the other events [1].
As reported in the related bug, if a port deletion with an IP
address and another port creation with the same IP address arrive
to the DHCP agent, those events can be processed in the same queue.

Because of the creation event priority, even when this event arrived
after the deletion event, it will be processed first. That will
clash with the DHCP agent cache, that contains a port (not deleted
yet) with the same IP address. That will trigger an unwanted resync.

This patch implements a specific logic to store the events in
""ResourceProcessingQueue"" (that uses ""PriorityQueue"" [2]). When
a port event arrives, the event comparison method checks the
(subnet, fixed_ips) tuple set of both elements. If there is a
coincidence, that means those ports are the same or are using
the same IP addreses (the race condition explained in the bug).
In this case, the priority is defined only by the timestamp;
that means the events are processed in order of arrival.

Because the Neutron server do not allow to have two ports in the
same subnet with the same IP address, the order of the events is
guaranteed. In the case explained in the bug, the deletion event
will be processed first.

[1]https://review.opendev.org/c/openstack/neutron/+/626830
[2]https://docs.python.org/3/library/queue.html#queue.PriorityQueue

Closes-Bug: #1913723

Change-Id: I89438feae3c0244f6da5e6a2a035d45b956ac247
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/773160/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py']",2,21641f7aa91b4abae641f923aba730af167cb081,bug/1913723," def _notify_agents(self, context, method, payload, network_id, obj_type): payload['obj_type'] = obj_type kwargs['port']['network_id'], 'port') {'port_id': kwargs['port']['id'], 'fixed_ips': kwargs['port']['fixed_ips']}, kwargs['port']['network_id'], 'port') if obj_type == 'port': payload['fixed_ips'] = obj_value['fixed_ips'] self._notify_agents(context, method_name, payload, network_id, obj_type) else: self._notify_agents(context, method_name, data, network_id, obj_type)"," def _notify_agents(self, context, method, payload, network_id): kwargs['port']['network_id']) {'port_id': kwargs['port']['id']}, kwargs['port']['network_id']) self._notify_agents(context, method_name, payload, network_id) else: self._notify_agents(context, method_name, data, network_id)",75,46
openstack%2Fpython-tripleoclient~master~I70469b29b71746fcfdb6382c080baf836c61f2ef,openstack/python-tripleoclient,master,I70469b29b71746fcfdb6382c080baf836c61f2ef,Allow enabling swift on undercloud,MERGED,2021-01-29 03:17:31.000000000,2021-02-05 21:29:18.000000000,2021-02-05 21:27:39.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-01-29 03:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/27f52d9ec03a7f15a8e6f02fb889d17f72f05726', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}, {'number': 2, 'created': '2021-01-29 03:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6f2e9ea6b23612ab5ca448cc93cb8c3dc4ce185c', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}, {'number': 3, 'created': '2021-02-01 04:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fdc983672fb94cdc7f69e67f9513671db26e70ae', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}, {'number': 4, 'created': '2021-02-01 05:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4667854bce0191b7520b18f1de4009bb1d93feb8', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}, {'number': 5, 'created': '2021-02-02 11:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/56524a4a955e3056bcdbaba3b4cc41a64545940d', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}, {'number': 6, 'created': '2021-02-05 02:47:03.000000000', 'files': ['tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/v1/undercloud/test_install_upgrade.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3739872bcdc1177c6eb648b45c270cf344f0ee67', 'message': 'Allow enabling swift on undercloud\n\nIf swift is needed on the undercloud, specifically for missing\nuse case, it can be enabled.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967\nChange-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef\n'}]",0,772968,3739872bcdc1177c6eb648b45c270cf344f0ee67,25,4,6,8833,,,0,"Allow enabling swift on undercloud

If swift is needed on the undercloud, specifically for missing
use case, it can be enabled.

Depends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772967
Change-Id: I70469b29b71746fcfdb6382c080baf836c61f2ef
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/68/772968/6 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/undercloud_config.py'],1,27f52d9ec03a7f15a8e6f02fb889d17f72f05726,env_merging," if CONF.get('enable_swift'): tht_templates, ""environments/enable-undercloud-swift.yaml"")]"," if not CONF.get('enable_swift'): tht_templates, ""environments/disable-swift.yaml"")]",2,2
openstack%2Ftripleo-quickstart~master~Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa,openstack/tripleo-quickstart,master,Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa,Added container-tools repo config,MERGED,2021-02-01 04:25:48.000000000,2021-02-05 21:29:15.000000000,2021-02-05 21:27:20.000000000,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-01 04:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/9fb0bc7ba8d80822a5c605f5e015e22a8503fa4b', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:2.0 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}, {'number': 2, 'created': '2021-02-01 08:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f61d8fd5d3b97bbcad762f4246a4fc1b38561560', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:2.0 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}, {'number': 3, 'created': '2021-02-02 10:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4a2b9e92e51d054afce31075f59b200240503fe3', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:rhel8 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}, {'number': 4, 'created': '2021-02-03 08:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/76f5ddd3bba4501710de472c5ca98c64e19489fc', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:rhel8 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}, {'number': 5, 'created': '2021-02-03 10:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7621550d21e6c6601d5915bdf5229624ed4da99f', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:rhel8 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}, {'number': 6, 'created': '2021-02-05 10:36:22.000000000', 'files': ['config/release/dependency_ci/container-tools/repo_config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a28941350797e4740b3c7df1d57215350535ebb4', 'message': 'Added container-tools repo config\n\nIn order to test latest podman and buildah, we need to\nenable container-tools:rhel8 on the centos-8-stream\ndependency pipeline job.\n\nIt adds the config and will be used in container tools\ndependency pipeline.\n\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\nChange-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa\n'}]",8,773285,a28941350797e4740b3c7df1d57215350535ebb4,33,4,6,12393,,,0,"Added container-tools repo config

In order to test latest podman and buildah, we need to
enable container-tools:rhel8 on the centos-8-stream
dependency pipeline job.

It adds the config and will be used in container tools
dependency pipeline.

Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
Change-Id: Ibee0e195e3ac0557a4e30134ab6b5ce1b43a6afa
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/85/773285/3 && git format-patch -1 --stdout FETCH_HEAD,['config/release/dependency_ci/container-tools/repo_config.yaml'],1,9fb0bc7ba8d80822a5c605f5e015e22a8503fa4b,containertools_depspipeline,"--- # For testing container-tools on centos-8-stream, # we need to enable container-tools 2:0 module # and disable container-tools rhel8 module. # It will fetch latest podman and buildah dependency_modules: - module_name: container-tools control_version: rhel8 test_version: 2.0 dep_repo_cmd_after: | sudo dnf repolist; sudo dnf module list; {% for item in dependency_modules %} sudo dnf module disable {{ item.module_name }}:{{ item.control_version }} -y; sudo dnf module enable {{ item.module_name }}:{{ item.test_version }} -y; {% endfor %} sudo dnf clean metadata sudo dnf clean all; sudo dnf update -y; dependency_params: 'container-tools:rhel8' ",,21,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I1b4e26fd4a46599985a989441f493a3ed39237bb,openstack/tripleo-heat-templates,stable/train,I1b4e26fd4a46599985a989441f493a3ed39237bb,Use include_role for conditional inclusion,MERGED,2021-02-01 12:50:23.000000000,2021-02-05 21:27:15.000000000,2021-02-05 21:27:15.000000000,"[{'_account_id': 7353}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-01 12:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a1fd9340ff8ab1587da12fc283a7fa57bc5cb084', 'message': 'Use include_role for conditional inclusion\n\nWhen import_role is used with a condition, the condition is\napplied to all tasks in the role. This is inefficient. If we\nuse include_role instead, then the role inclusion task is\nskipped and none of the tasks in the role are even evaluated.\n\nRelated-bug: rhbz#1922132\n\nChange-Id: I1b4e26fd4a46599985a989441f493a3ed39237bb\n(cherry picked from commit 46df551a0f00cf143ddd5cd9c651b08a13a79fb0)\n'}, {'number': 2, 'created': '2021-02-02 17:20:20.000000000', 'files': ['deployment/metrics/collectd-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c5a2a9ce50f316370a1f90db358692e9999e6b99', 'message': 'Use include_role for conditional inclusion\n\nWhen import_role is used with a condition, the condition is\napplied to all tasks in the role. This is inefficient. If we\nuse include_role instead, then the role inclusion task is\nskipped and none of the tasks in the role are even evaluated.\n\nRelated-bug: rhbz#1922132\n\nChange-Id: I1b4e26fd4a46599985a989441f493a3ed39237bb\n(cherry picked from commit 46df551a0f00cf143ddd5cd9c651b08a13a79fb0)\n'}]",0,773209,c5a2a9ce50f316370a1f90db358692e9999e6b99,20,6,2,6816,,,0,"Use include_role for conditional inclusion

When import_role is used with a condition, the condition is
applied to all tasks in the role. This is inefficient. If we
use include_role instead, then the role inclusion task is
skipped and none of the tasks in the role are even evaluated.

Related-bug: rhbz#1922132

Change-Id: I1b4e26fd4a46599985a989441f493a3ed39237bb
(cherry picked from commit 46df551a0f00cf143ddd5cd9c651b08a13a79fb0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/09/773209/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/metrics/collectd-container-puppet.yaml'],1,a1fd9340ff8ab1587da12fc283a7fa57bc5cb084,, include_role:, import_role:,1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Iaa6fdef24599072f5a31c1fd2da29c276399c83d,openstack/tripleo-heat-templates,stable/train,Iaa6fdef24599072f5a31c1fd2da29c276399c83d,Add post delay to reboot,MERGED,2021-02-05 10:09:11.000000000,2021-02-05 21:26:42.000000000,2021-02-05 21:26:42.000000000,"[{'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-05 10:09:11.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/678186027f5addad4fd69ee68986ef4500f17ac2', 'message': 'Add post delay to reboot\n\nLeapp may reconfigure network after main upgrade. Also systemd may bring\ndown and up again network unit. This patch adds post_reboot_delay as 2 min to\nmitigate such issues which can be configurable as heat variable in\ncustomers env files for some very specific cases. Also test_command is\nchanged from whoami to systemctl to have better assesment when a system\ncompleted its boot.\n\nCloses-Bug: rhbz#1920293\n\nChange-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d\n(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)\n'}]",0,774214,678186027f5addad4fd69ee68986ef4500f17ac2,9,5,1,6816,,,0,"Add post delay to reboot

Leapp may reconfigure network after main upgrade. Also systemd may bring
down and up again network unit. This patch adds post_reboot_delay as 2 min to
mitigate such issues which can be configurable as heat variable in
customers env files for some very specific cases. Also test_command is
changed from whoami to systemctl to have better assesment when a system
completed its boot.

Closes-Bug: rhbz#1920293

Change-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d
(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/774214/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,678186027f5addad4fd69ee68986ef4500f17ac2,fix_reboot-stable/train," UpgradeLeappPostRebootDelay: description: | Maximum (seconds) to wait for machine to reboot and respond to a test command. type: number default: 120 upgrade_leapp_post_reboot_delay: {get_param: UpgradeLeappPostRebootDelay} test_command: >- systemctl is-system-running | grep -e running -e degraded post_reboot_delay: ""{{ upgrade_leapp_post_reboot_delay }}""",,10,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Iaa6fdef24599072f5a31c1fd2da29c276399c83d,openstack/tripleo-heat-templates,stable/ussuri,Iaa6fdef24599072f5a31c1fd2da29c276399c83d,Add post delay to reboot,MERGED,2021-02-05 10:04:08.000000000,2021-02-05 21:26:37.000000000,2021-02-05 21:26:37.000000000,"[{'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-05 10:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06d3a6f53755a2d343bc3e9bc525e26c85a370a5', 'message': 'Add post delay to reboot\n\nLeapp may reconfigure network after main upgrade. Also systemd may bring\ndown and up again network unit. This patch adds post_reboot_delay as 2 min to\nmitigate such issues which can be configurable as heat variable in\ncustomers env files for some very specific cases. Also test_command is\nchanged from whoami to systemctl to have better assesment when a system\ncompleted its boot.\n\nCloses-Bug: rhbz#1920293\n\nChange-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d\n(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)\n'}, {'number': 2, 'created': '2021-02-05 10:10:22.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/43c02ebc95393b729db93e5503011f566d3fbe06', 'message': 'Add post delay to reboot\n\nLeapp may reconfigure network after main upgrade. Also systemd may bring\ndown and up again network unit. This patch adds post_reboot_delay as 2 min to\nmitigate such issues which can be configurable as heat variable in\ncustomers env files for some very specific cases. Also test_command is\nchanged from whoami to systemctl to have better assesment when a system\ncompleted its boot.\n\nCloses-Bug: rhbz#1920293\n\nChange-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d\n(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)\n'}]",0,774125,43c02ebc95393b729db93e5503011f566d3fbe06,9,5,2,6816,,,0,"Add post delay to reboot

Leapp may reconfigure network after main upgrade. Also systemd may bring
down and up again network unit. This patch adds post_reboot_delay as 2 min to
mitigate such issues which can be configurable as heat variable in
customers env files for some very specific cases. Also test_command is
changed from whoami to systemctl to have better assesment when a system
completed its boot.

Closes-Bug: rhbz#1920293

Change-Id: Iaa6fdef24599072f5a31c1fd2da29c276399c83d
(cherry picked from commit a9bf1c1285ebb54844018b9f18ed8089fbc30a3f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/774125/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,06d3a6f53755a2d343bc3e9bc525e26c85a370a5,fix_reboot-stable/ussuri," UpgradeLeappPostRebootDelay: description: | Maximum (seconds) to wait for machine to reboot and respond to a test command. type: number default: 120 pgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout} upgrade_leapp_post_reboot_delay: {get_param: UpgradeLeappPostRebootDelay} test_command: >- systemctl is-system-running | grep -e running -e degraded post_reboot_delay: ""{{ upgrade_leapp_post_reboot_delay }}""", upgrade_leapp_reboot_timeout: {get_param: UpgradeLeappRebootTimeout},11,1
openstack%2Fopenstack-ansible-os_glance~master~I41fc05409433b4e22307ad604c15d30bcea32abd,openstack/openstack-ansible-os_glance,master,I41fc05409433b4e22307ad604c15d30bcea32abd,Move glance pip package from a constraint to a requirement,MERGED,2021-01-13 09:04:19.000000000,2021-02-05 21:21:42.000000000,2021-02-05 21:18:37.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-13 09:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/1c2e256680adbb97263d71c4f4f0474ec48d843f', 'message': 'Move glance pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I41fc05409433b4e22307ad604c15d30bcea32abd\n'}, {'number': 2, 'created': '2021-01-18 16:38:40.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/a6b1bc17d542e25b3f8a9eeea29b6d81a5373ab3', 'message': 'Move glance pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I41fc05409433b4e22307ad604c15d30bcea32abd\n'}]",0,770546,a6b1bc17d542e25b3f8a9eeea29b6d81a5373ab3,21,4,2,25023,,,0,"Move glance pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: I41fc05409433b4e22307ad604c15d30bcea32abd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/46/770546/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,1c2e256680adbb97263d71c4f4f0474ec48d843f,osa-new-pip," - ""git+{{ glance_git_repo }}@{{ glance_git_install_branch }}#egg=glance"""," - ""git+{{ glance_git_repo }}@{{ glance_git_install_branch }}#egg=glance"" - glance",1,2
openstack%2Fopenstack-ansible-os_placement~master~I00b42c61d03c83bfbfec69ad3bd47d940bb449d2,openstack/openstack-ansible-os_placement,master,I00b42c61d03c83bfbfec69ad3bd47d940bb449d2,Move placement pip package from a constraint to a requirement,MERGED,2021-01-12 12:05:06.000000000,2021-02-05 21:09:41.000000000,2021-02-05 21:08:14.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-12 12:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/1e1a12207114aa9246adc070e216141c7bffb4b9', 'message': 'Move placement pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: I00b42c61d03c83bfbfec69ad3bd47d940bb449d2\n'}, {'number': 2, 'created': '2021-01-12 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/b653b812f6ca276c6c35009998a2d5bf9f559fe7', 'message': 'Move placement pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: I00b42c61d03c83bfbfec69ad3bd47d940bb449d2\n'}, {'number': 3, 'created': '2021-01-13 08:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/bf09857c9ce34a1d0e6c07fa54d2c8d1a8882f45', 'message': 'Move placement pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I00b42c61d03c83bfbfec69ad3bd47d940bb449d2\n'}, {'number': 4, 'created': '2021-01-18 16:39:08.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/044852c1be35d11debbab981062e8f4a2ae6231e', 'message': 'Move placement pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I00b42c61d03c83bfbfec69ad3bd47d940bb449d2\n'}]",0,770280,044852c1be35d11debbab981062e8f4a2ae6231e,26,4,4,25023,,,0,"Move placement pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: I00b42c61d03c83bfbfec69ad3bd47d940bb449d2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_placement refs/changes/80/770280/4 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,1e1a12207114aa9246adc070e216141c7bffb4b9,osa-new-pip,"Move keystone pip package from a constraint to a requirement This is necessary to support the new pip resolver. - ""git+{{ placement_git_repo }}@{{ placement_git_install_branch }}#egg=openstack-placement"""," - ""git+{{ placement_git_repo }}@{{ placement_git_install_branch }}#egg=openstack-placement"" - openstack-placement",4,2
openstack%2Fopenstack-ansible-os_keystone~master~I599f9de82a6350599444096e98a0e25a417e18ef,openstack/openstack-ansible-os_keystone,master,I599f9de82a6350599444096e98a0e25a417e18ef,Move keystone pip package from a constraint to a requirement,MERGED,2021-01-12 11:34:23.000000000,2021-02-05 21:09:16.000000000,2021-02-05 21:07:49.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-12 11:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/1fb3ab7cb608cf686b919308bd8b38be8cb698d9', 'message': 'Move keystone pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: I599f9de82a6350599444096e98a0e25a417e18ef\n'}, {'number': 2, 'created': '2021-01-13 08:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/45bc102abacd77720ac967bae887ee748e6d24e2', 'message': 'Move keystone pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I599f9de82a6350599444096e98a0e25a417e18ef\n'}, {'number': 3, 'created': '2021-01-18 16:40:53.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/05c7f80711c6e267a2a7f9f30d7bffcd90c6271e', 'message': 'Move keystone pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I599f9de82a6350599444096e98a0e25a417e18ef\n'}]",0,770271,05c7f80711c6e267a2a7f9f30d7bffcd90c6271e,29,4,3,25023,,,0,"Move keystone pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: I599f9de82a6350599444096e98a0e25a417e18ef
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/71/770271/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,1fb3ab7cb608cf686b919308bd8b38be8cb698d9,osa-new-pip," - ""git+{{ keystone_git_repo }}@{{ keystone_git_install_branch }}#egg=keystone"""," - ""git+{{ keystone_git_repo }}@{{ keystone_git_install_branch }}#egg=keystone"" - keystone",1,2
openstack%2Fopenstack-ansible-os_cinder~master~I2c4009fbdf524f2d54adf1d4a730604c123f72fd,openstack/openstack-ansible-os_cinder,master,I2c4009fbdf524f2d54adf1d4a730604c123f72fd,Move cinder pip package from a constraint to a requirement,MERGED,2021-01-12 11:36:04.000000000,2021-02-05 21:06:49.000000000,2021-02-05 21:05:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-12 11:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/bd40395cfe1b11503734f3d094c93d5c457a47fe', 'message': 'Move cinder pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: I2c4009fbdf524f2d54adf1d4a730604c123f72fd\n'}, {'number': 2, 'created': '2021-01-13 08:51:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/f8b5bd0e12086f8929d4c3af03bd5abfc694bf77', 'message': 'Move cinder pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I2c4009fbdf524f2d54adf1d4a730604c123f72fd\n'}, {'number': 3, 'created': '2021-01-18 16:40:04.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/6958079640b89d637b4c40abb1d857e12f99adfb', 'message': 'Move cinder pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: I2c4009fbdf524f2d54adf1d4a730604c123f72fd\n'}]",0,770272,6958079640b89d637b4c40abb1d857e12f99adfb,25,4,3,25023,,,0,"Move cinder pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: I2c4009fbdf524f2d54adf1d4a730604c123f72fd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/72/770272/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,bd40395cfe1b11503734f3d094c93d5c457a47fe,osa-new-pip," - ""git+{{ cinder_git_repo }}@{{ cinder_git_install_branch }}#egg=cinder"""," - ""git+{{ cinder_git_repo }}@{{ cinder_git_install_branch }}#egg=cinder"" - cinder",1,2
openstack%2Fopenstack-helm-infra~master~Ibaa817a2178e38f18cb6e16f4e9d65e8ae2e7b0a,openstack/openstack-helm-infra,master,Ibaa817a2178e38f18cb6e16f4e9d65e8ae2e7b0a,[ceph-rgw] Update ceph-rgw release notes to current,MERGED,2021-02-04 23:15:10.000000000,2021-02-05 20:59:14.000000000,2021-02-05 20:57:01.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-04 23:15:10.000000000', 'files': ['releasenotes/notes/ceph-rgw.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e3e6db5acdf2a043da156943f41c28574a2e74c8', 'message': '[ceph-rgw] Update ceph-rgw release notes to current\n\nThis change updates the releasenotes for ceph-rgw to all current\nchanges as of the date of this commit.\n\nChange-Id: Ibaa817a2178e38f18cb6e16f4e9d65e8ae2e7b0a\n'}]",0,774171,e3e6db5acdf2a043da156943f41c28574a2e74c8,11,10,1,28372,,,0,"[ceph-rgw] Update ceph-rgw release notes to current

This change updates the releasenotes for ceph-rgw to all current
changes as of the date of this commit.

Change-Id: Ibaa817a2178e38f18cb6e16f4e9d65e8ae2e7b0a
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/71/774171/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-rgw.yaml'],1,e3e6db5acdf2a043da156943f41c28574a2e74c8,ceph-charts-release-notes," - 0.1.1 Change helm-toolkit dependency version to "">= 0.1.0""",,1,0
openstack%2Fopenstack-helm-infra~master~I48a0e10fcae8920396658499321dede9ed026eff,openstack/openstack-helm-infra,master,I48a0e10fcae8920396658499321dede9ed026eff,[ceph-provisioners] Update ceph-provisioners release notes to current,MERGED,2021-02-04 23:11:44.000000000,2021-02-05 20:58:15.000000000,2021-02-05 20:56:52.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-04 23:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3be74f410a7aeedb64cd03f12b63fe93c076952d', 'message': '[ceph-provisioners] Update ceph-provisioners release notes to current\n\nThis change updates the releasenotes for ceph-provisioners to all current\nchanges as of the date of this commit.\n\nChange-Id: I48a0e10fcae8920396658499321dede9ed026eff\n'}, {'number': 2, 'created': '2021-02-05 01:03:39.000000000', 'files': ['releasenotes/notes/ceph-provisioners.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/acf0054aa421dcef811b4c73dcbe4af2656552d5', 'message': '[ceph-provisioners] Update ceph-provisioners release notes to current\n\nThis change updates the releasenotes for ceph-provisioners to all current\nchanges as of the date of this commit.\n\nChange-Id: I48a0e10fcae8920396658499321dede9ed026eff\n'}]",0,774170,acf0054aa421dcef811b4c73dcbe4af2656552d5,13,10,2,28372,,,0,"[ceph-provisioners] Update ceph-provisioners release notes to current

This change updates the releasenotes for ceph-provisioners to all current
changes as of the date of this commit.

Change-Id: I48a0e10fcae8920396658499321dede9ed026eff
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/70/774170/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-provisioners.yaml'],1,3be74f410a7aeedb64cd03f12b63fe93c076952d,ceph-charts-release-notes," - 0.1.1 Change helm-toolkit dependency version to "">= 0.1.0"" - 0.1.2 Validate each storageclass created",,2,0
openstack%2Fopenstack-helm~master~I19f4e24ad6e55d917c7e656f78edfa9364bf721b,openstack/openstack-helm,master,I19f4e24ad6e55d917c7e656f78edfa9364bf721b,Update cinder release notes to current,MERGED,2021-02-04 16:56:10.000000000,2021-02-05 20:57:59.000000000,2021-02-05 20:56:18.000000000,"[{'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 16:56:10.000000000', 'files': ['releasenotes/notes/cinder.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/45cde69b17c44fe8cb0afc54519cbaad8ebcee9b', 'message': 'Update cinder release notes to current\n\nChange-Id: I19f4e24ad6e55d917c7e656f78edfa9364bf721b\n'}]",0,774104,45cde69b17c44fe8cb0afc54519cbaad8ebcee9b,9,4,1,24780,,,0,"Update cinder release notes to current

Change-Id: I19f4e24ad6e55d917c7e656f78edfa9364bf721b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/04/774104/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/cinder.yaml'],1,45cde69b17c44fe8cb0afc54519cbaad8ebcee9b,," - 0.1.1 Change helm-toolkit dependency version to "">= 0.1.0"" - 0.1.2 Support service tokens to prevent long-running job failures - 0.1.3 Support of external ceph backend - 0.1.4 Enable iscsi to work correctly in cinder volume - 0.1.5 Resolves mount issue with termination-log - 0.1.6 Enable volume backup for iSCSI based volumes - 0.1.7 Change Issuer to ClusterIssuer - 0.1.8 Revert - Change Issuer to ClusterIssuer - 0.1.9 Use HostToContainer mount propagation",,9,0
openstack%2Fopenstack-ansible-os_nova~master~Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3,openstack/openstack-ansible-os_nova,master,Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3,Move nova pip package from a constraint to a requirement,MERGED,2021-01-12 12:03:37.000000000,2021-02-05 20:57:49.000000000,2021-02-05 20:56:32.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-12 12:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/f3ad7bd6c25dad8eb49fb6a5015976f69a56c372', 'message': 'Move nova pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nChange-Id: Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3\n'}, {'number': 2, 'created': '2021-01-13 08:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/6e03afdd71f7edf765d207bbc0015985bd580676', 'message': 'Move nova pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3\n'}, {'number': 3, 'created': '2021-01-18 16:39:42.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/dd93f405e3beacbfe4b3e7a2a257844796f8b811', 'message': 'Move nova pip package from a constraint to a requirement\n\nThis is necessary to support the new pip resolver.\n\nDepends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281\nDepends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd\nChange-Id: Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3\n'}]",0,770279,dd93f405e3beacbfe4b3e7a2a257844796f8b811,25,4,3,25023,,,0,"Move nova pip package from a constraint to a requirement

This is necessary to support the new pip resolver.

Depends-On: I9be6bbf4a29a4da2ddf96dc0336bc2a7d8ec9281
Depends-On: I49c75dd11d6c4e8d37fe013b7ffdfd56ff193fcd
Change-Id: Ie2c30984b9ad7fc2cc55900f49b2300e2bdaa1e3
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/79/770279/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,f3ad7bd6c25dad8eb49fb6a5015976f69a56c372,osa-new-pip," - ""git+{{ nova_git_repo }}@{{ nova_git_install_branch }}#egg=nova"""," - ""git+{{ nova_git_repo }}@{{ nova_git_install_branch }}#egg=nova"" - nova",1,2
openstack%2Fopenstack-helm-infra~master~I9a29ed9b6d8e17de19c6e929f3c673107ebd7912,openstack/openstack-helm-infra,master,I9a29ed9b6d8e17de19c6e929f3c673107ebd7912,[ceph-mon] Update ceph-mon release notes to current,MERGED,2021-02-04 22:37:42.000000000,2021-02-05 20:56:56.000000000,2021-02-05 20:56:56.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 24780}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-04 22:37:42.000000000', 'files': ['releasenotes/notes/ceph-mon.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/57f70a54b61c3a67fa4ee43e646b1c0d28464026', 'message': '[ceph-mon] Update ceph-mon release notes to current\n\nThis change updates the releasenotes for ceph-mon to all current\nchanges as of the date of this commit.\n\nChange-Id: I9a29ed9b6d8e17de19c6e929f3c673107ebd7912\n'}]",0,774165,57f70a54b61c3a67fa4ee43e646b1c0d28464026,12,11,1,28372,,,0,"[ceph-mon] Update ceph-mon release notes to current

This change updates the releasenotes for ceph-mon to all current
changes as of the date of this commit.

Change-Id: I9a29ed9b6d8e17de19c6e929f3c673107ebd7912
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/65/774165/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-mon.yaml'],1,57f70a54b61c3a67fa4ee43e646b1c0d28464026,ceph-charts-release-notes, - 0.1.1 Change helm-toolkit dependency to >= 0.1.0 - 0.1.2 Enable shareProcessNamespace in mon daemonset - 0.1.3 Run mon container as ceph user,,3,0
openstack%2Fopenstack-helm-infra~master~Ib2f1ae712d81ccc3d35e334b15ad71b602ebd87f,openstack/openstack-helm-infra,master,Ib2f1ae712d81ccc3d35e334b15ad71b602ebd87f,[ceph-osd] Update ceph-osd release notes to current,MERGED,2021-02-04 23:01:45.000000000,2021-02-05 20:55:54.000000000,2021-02-05 20:54:32.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-02-04 23:01:45.000000000', 'files': ['releasenotes/notes/ceph-osd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8c0343d68c646b0bdd4ce6516629c4c3acbb0166', 'message': '[ceph-osd] Update ceph-osd release notes to current\n\nThis change updates the releasenotes for ceph-osd to all current\nchanges as of the date of this commit.\n\nChange-Id: Ib2f1ae712d81ccc3d35e334b15ad71b602ebd87f\n'}]",0,774167,8c0343d68c646b0bdd4ce6516629c4c3acbb0166,11,10,1,28372,,,0,"[ceph-osd] Update ceph-osd release notes to current

This change updates the releasenotes for ceph-osd to all current
changes as of the date of this commit.

Change-Id: Ib2f1ae712d81ccc3d35e334b15ad71b602ebd87f
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/67/774167/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceph-osd.yaml'],1,8c0343d68c646b0bdd4ce6516629c4c3acbb0166,ceph-charts-release-notes, - 0.1.1 Change helm-toolkit dependency to >= 0.1.0 - 0.1.2 wait for only osd pods from post apply job - 0.1.3 Search for complete logical volume name for OSD data volumes - 0.1.4 Don't try to prepare OSD disks that are already deployed - 0.1.5 Fix the sync issue between osds when using shared disk for metadata - 0.1.6 Logic improvement for used osd disk detection - 0.1.7 Synchronization audit for the ceph-volume osd-init script - 0.1.8 Update post apply job - 0.1.9 Check inactive PGs multiple times - 0.1.10 Fix typo in check inactive PGs logic - 0.1.11 Fix post-apply job failure related to fault tolerance - 0.1.12 Add a check for misplaced objects to the post-apply job - 0.1.13 Remove default OSD configuration - 0.1.14 Alias synchronized commands and fix descriptor leak - 0.1.15 Correct naming convention for logical volumes in disk_zap() - 0.1.16 dmsetup remove logical devices using correct device names - 0.1.17 Fix a bug with DB orphan volume removal,,17,0
openstack%2Fopenstack-helm~master~I75c888a3401cf2cdf4b889d70d5feb5fc54898a3,openstack/openstack-helm,master,I75c888a3401cf2cdf4b889d70d5feb5fc54898a3,Update ceilometer release notes to current,MERGED,2021-02-04 15:52:49.000000000,2021-02-05 20:53:59.000000000,2021-02-05 20:51:52.000000000,"[{'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 15:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b9a72ec8a31779ffc4869e1522f42fd971f8e8fd', 'message': 'Update ceilometer release notes to current\n\nChange-Id: I75c888a3401cf2cdf4b889d70d5feb5fc54898a3\n'}, {'number': 2, 'created': '2021-02-04 16:55:01.000000000', 'files': ['releasenotes/notes/ceilometer.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d3256726a1fb3855f9b3996241aca7c3f73551e6', 'message': 'Update ceilometer release notes to current\n\nChange-Id: I75c888a3401cf2cdf4b889d70d5feb5fc54898a3\n'}]",1,774095,d3256726a1fb3855f9b3996241aca7c3f73551e6,15,4,2,24780,,,0,"Update ceilometer release notes to current

Change-Id: I75c888a3401cf2cdf4b889d70d5feb5fc54898a3
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/95/774095/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/ceilometer.yaml'],1,b9a72ec8a31779ffc4869e1522f42fd971f8e8fd,ceilometer-reno," - 0.1.1 Change helm-toolkit dependency version to "">= 0.1.0"" ",,1,0
openstack%2Fkolla~master~I4d20f23a9b26364943bf967908255d82c8f6621b,openstack/kolla,master,I4d20f23a9b26364943bf967908255d82c8f6621b,get rid of traces of CentOS 7 support,MERGED,2021-02-04 16:06:54.000000000,2021-02-05 20:50:19.000000000,2021-02-05 20:48:45.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}]","[{'number': 1, 'created': '2021-02-04 16:06:54.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/fc89e57c1cad910dc9f2f01a2ec3c6c36051c8bc', 'message': 'get rid of traces of CentOS 7 support\n\nChange-Id: I4d20f23a9b26364943bf967908255d82c8f6621b\n'}]",0,774098,fc89e57c1cad910dc9f2f01a2ec3c6c36051c8bc,14,3,1,24072,,,0,"get rid of traces of CentOS 7 support

Change-Id: I4d20f23a9b26364943bf967908255d82c8f6621b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/98/774098/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2']",2,fc89e57c1cad910dc9f2f01a2ec3c6c36051c8bc,, {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %}, {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'OVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-ovmf' ] %} {% endif %} {% if base_distro_tag.startswith('7') %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'AAVMF' ] %} {% else %} {% set nova_libvirt_packages = nova_libvirt_packages + [ 'edk2-aarch64' ] %} {% endif %},18,61
openstack%2Fnova~master~I598a1f36d197188b9f891f14dd5d0514ed71f2b1,openstack/nova,master,I598a1f36d197188b9f891f14dd5d0514ed71f2b1,Remove __unicode__() from nova unit test Exception,MERGED,2021-01-08 09:21:24.000000000,2021-02-05 20:19:55.000000000,2021-02-04 21:03:11.000000000,"[{'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-08 09:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cb1fbafbefaea4021133e9f1e1bd4e72b696be8', 'message': 'Remove __unicode__() from nova unit test Exception\n\nThis is no longer needed in Python 3.\n\nChange-Id: I598a1f36d197188b9f891f14dd5d0514ed71f2b1\n'}, {'number': 2, 'created': '2021-02-04 13:26:41.000000000', 'files': ['nova/tests/unit/test_exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cea5bf3d93b1f414b6612225235edae517cbb774', 'message': 'Remove __unicode__() from nova unit test Exception\n\nThis is no longer needed in Python 3.\n\nChange-Id: I598a1f36d197188b9f891f14dd5d0514ed71f2b1\n'}]",1,769894,cea5bf3d93b1f414b6612225235edae517cbb774,17,3,2,30384,,,0,"Remove __unicode__() from nova unit test Exception

This is no longer needed in Python 3.

Change-Id: I598a1f36d197188b9f891f14dd5d0514ed71f2b1
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/769894/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_exception.py'],1,8cb1fbafbefaea4021133e9f1e1bd4e72b696be8,,," def __unicode__(self): return u""print the whole trace""",0,2
openstack%2Fcinder~stable%2Fussuri~Ib80e04512ec34a390e9e17af2f3544e18cad8598,openstack/cinder,stable/ussuri,Ib80e04512ec34a390e9e17af2f3544e18cad8598,RBD: Retry delete if VolumeIsBusy in _copy_image_to_volume,MERGED,2021-01-06 16:58:07.000000000,2021-02-05 20:01:43.000000000,2021-02-05 19:59:43.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2021-01-06 16:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cbcde484b01168727ec2d7a96d3c57d02f2105ee', 'message': 'RBD: Retry delete if VolumeIsBusy in _copy_image_to_volume\n\nCinder can fail to create an image-based volume if RBD mirroring\nis enabled. With the journaling-based approach to RBD mirroring,\nceph will still create a snapshot as a result of volume creation.\nThe volume create in _create_from_image_download() results in\na snapshot getting created, resulting in a race where delete_volume()\ngets a VolumeIsBusy exception.\n\nChange-Id: Ib80e04512ec34a390e9e17af2f3544e18cad8598\nCloses-Bug: #1900775\n(cherry picked from commit 6231d26667508e34eb0a985f1f7ced1dbe623e1a)\n'}, {'number': 2, 'created': '2021-01-27 14:03:29.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4f40f059f81ac27c92e4238f78ba649b69b09dd0', 'message': 'RBD: Retry delete if VolumeIsBusy in _copy_image_to_volume\n\nCinder can fail to create an image-based volume if RBD mirroring\nis enabled. With the journaling-based approach to RBD mirroring,\nceph will still create a snapshot as a result of volume creation.\nThe volume create in _create_from_image_download() results in\na snapshot getting created, resulting in a race where delete_volume()\ngets a VolumeIsBusy exception.\n\nChange-Id: Ib80e04512ec34a390e9e17af2f3544e18cad8598\nCloses-Bug: #1900775\n(cherry picked from commit 6231d26667508e34eb0a985f1f7ced1dbe623e1a)\n(cherry picked from commit e1ed30838c3d72e70e3e06d5e7bc6f18d6bc4aad)\n'}]",1,769577,4f40f059f81ac27c92e4238f78ba649b69b09dd0,29,4,2,11805,,,0,"RBD: Retry delete if VolumeIsBusy in _copy_image_to_volume

Cinder can fail to create an image-based volume if RBD mirroring
is enabled. With the journaling-based approach to RBD mirroring,
ceph will still create a snapshot as a result of volume creation.
The volume create in _create_from_image_download() results in
a snapshot getting created, resulting in a race where delete_volume()
gets a VolumeIsBusy exception.

Change-Id: Ib80e04512ec34a390e9e17af2f3544e18cad8598
Closes-Bug: #1900775
(cherry picked from commit 6231d26667508e34eb0a985f1f7ced1dbe623e1a)
(cherry picked from commit e1ed30838c3d72e70e3e06d5e7bc6f18d6bc4aad)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/769577/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py']",2,cbcde484b01168727ec2d7a96d3c57d02f2105ee,bug/1900775-stable/victoria-stable/ussuri," def _copy_image(self, volume_busy=False): with mock.patch.object(self.driver, 'delete_volume') \ as mock_dv: if volume_busy: mock_dv.side_effect = ( exception.VolumeIsBusy(""doh"")) self.assertRaises( exception.VolumeIsBusy, self.driver.copy_image_to_volume, *args) self.assertEqual( self.cfg.rados_connection_retries, mock_dv.call_count) else: self.driver.copy_image_to_volume(*args) @common_mocks def test_copy_image_busy_volume(self): self.cfg.image_conversion_dir = '/var/run/cinder/tmp' self._copy_image(volume_busy=True) "," def _copy_image(self): with mock.patch.object(self.driver, 'delete_volume'): self.driver.copy_image_to_volume(*args)",27,4
openstack%2Fcinder~stable%2Fvictoria~I00f1bd46bc8715591016f59c32651fc2c9cddf35,openstack/cinder,stable/victoria,I00f1bd46bc8715591016f59c32651fc2c9cddf35,[SVF]:Reduce slowness by caching pool information,MERGED,2020-12-17 08:25:48.000000000,2021-02-05 20:01:38.000000000,2021-02-05 19:59:35.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30615}, {'_account_id': 32036}]","[{'number': 1, 'created': '2020-12-17 08:25:48.000000000', 'files': ['cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/bug-1890591-Pool-information-is-not-saved-in-stats-22f302d941cd9fe2.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2cddc108b174895b3575e9a2640d3cd8afc21ab', 'message': '[SVF]:Reduce slowness by caching pool information\n\n[Spectrum Virtualize Family] Data_reduction is a pool specific property,\nthis property should be saved for a specific pool during initialisation.\n\nWith this, calls to get_pool_attrs can be reduced everytime create_vdisk\nis called, in order to check if pool is a data_reduction_pool.\n\ncloses bug: #1890591\n\nChange-Id: I00f1bd46bc8715591016f59c32651fc2c9cddf35\n(cherry picked from commit 7d89890704ef2ed9265a5dec9cbe47cb1ffc5aaa)\n'}]",0,767477,e2cddc108b174895b3575e9a2640d3cd8afc21ab,34,6,1,32171,,,0,"[SVF]:Reduce slowness by caching pool information

[Spectrum Virtualize Family] Data_reduction is a pool specific property,
this property should be saved for a specific pool during initialisation.

With this, calls to get_pool_attrs can be reduced everytime create_vdisk
is called, in order to check if pool is a data_reduction_pool.

closes bug: #1890591

Change-Id: I00f1bd46bc8715591016f59c32651fc2c9cddf35
(cherry picked from commit 7d89890704ef2ed9265a5dec9cbe47cb1ffc5aaa)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/767477/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/bug-1890591-Pool-information-is-not-saved-in-stats-22f302d941cd9fe2.yaml']",3,e2cddc108b174895b3575e9a2640d3cd8afc21ab,bug/1890591-stable/victoria,--- fixes: - | `Bug #1890591 <https://bugs.launchpad.net/cinder/+bug/1890591>`_: IBM Spectrum Virtualize Family: Fixed issue in do_setup of StorwizeSVCCommonDriver to save pool information in stats during initialisation. ,,69,1
openstack%2Ftripleo-common~master~Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241,openstack/tripleo-common,master,Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241,Bump Ceph containers to octopus,MERGED,2021-01-19 11:11:18.000000000,2021-02-05 19:29:09.000000000,2021-02-05 19:26:56.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 14270}, {'_account_id': 15205}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 31896}]","[{'number': 1, 'created': '2021-01-19 11:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7715ea18b90964e9edc33a4c5859a24a46f04f9c', 'message': 'Bump Ceph containers to octopus\n\nWallaby+ is going to use the Ceph Octopus/Pacific releases.\nThe purpose of this review is to make the ceph 5 containers\navailable to the cephadm provisioning process.\n\nChange-Id: Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241\n'}, {'number': 2, 'created': '2021-01-20 08:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b17bb98ba94f0c223f1cc2fc60f8e19074d44f5a', 'message': 'Bump Ceph containers to octopus\n\nWallaby+ is going to use the Ceph Octopus/Pacific releases.\nThe purpose of this review is to make the ceph 5 containers\navailable to the cephadm provisioning process.\n\nChange-Id: Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241\n'}, {'number': 3, 'created': '2021-01-22 06:01:54.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/tripleo_containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/97bb49e97c97ba9922b2e0e69150c9e8be806021', 'message': 'Bump Ceph containers to octopus\n\nWallaby+ is going to use the Ceph Octopus/Pacific releases.\nThe purpose of this review is to make the ceph 5 containers\navailable to the cephadm provisioning process.\n\nChange-Id: Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241\n'}]",1,771424,97bb49e97c97ba9922b2e0e69150c9e8be806021,32,10,3,25402,,,0,"Bump Ceph containers to octopus

Wallaby+ is going to use the Ceph Octopus/Pacific releases.
The purpose of this review is to make the ceph 5 containers
available to the cephadm provisioning process.

Change-Id: Ic42055f642312f9e7a6fead1ac72d3a9e2b7a241
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/24/771424/3 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/tripleo_containers.yaml']",2,7715ea18b90964e9edc33a4c5859a24a46f04f9c,cephadm_integration,- imagename: quay.ceph.io/ceph-ci/daemon:v5.0.6-stable-5.0-octopus-centos-8-x86_64,- imagename: quay.ceph.io/ceph-ci/daemon:v4.0.13-stable-4.0-nautilus-centos-7-x86_64,2,2
openstack%2Fswift~master~I191307967813ed77d41d12900aa641a2d7735069,openstack/swift,master,I191307967813ed77d41d12900aa641a2d7735069,Make CORS tests tolerate quoted or unquoted Etag,ABANDONED,2021-02-03 16:05:05.000000000,2021-02-05 19:04:18.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 16:05:05.000000000', 'files': ['test/cors/harness.js'], 'web_link': 'https://opendev.org/openstack/swift/commit/53e40785bcb32b75f5d882d993005cc663e75c94', 'message': 'Make CORS tests tolerate quoted or unquoted Etag\n\nMake the CORS tests match expected Etag against quoted or unquoted\nresponse values in order to tolerate the etag-quoter being in the\nproxy pipeline or not.\n\nChange-Id: I191307967813ed77d41d12900aa641a2d7735069\n'}]",0,773935,53e40785bcb32b75f5d882d993005cc663e75c94,4,2,1,7847,,,0,"Make CORS tests tolerate quoted or unquoted Etag

Make the CORS tests match expected Etag against quoted or unquoted
response values in order to tolerate the etag-quoter being in the
proxy pipeline or not.

Change-Id: I191307967813ed77d41d12900aa641a2d7735069
",git fetch https://review.opendev.org/openstack/swift refs/changes/35/773935/1 && git format-patch -1 --stdout FETCH_HEAD,['test/cors/harness.js'],1,53e40785bcb32b75f5d882d993005cc663e75c94,p-cors-test-random-query-string," const value = resp.getResponseHeader(name) if (name === 'Etag') { // special case for Etag which may or may not be quoted if ((value !== headers[name]) && (value !== ""\"""" + headers[name] + ""\"""")) { throw new Error('Expected header ' + name + ' to have value ' + headers[name] + ', got ' + value) } } else if (value !== headers[name]) { throw new Error('Expected header ' + name + ' to have value ' + headers[name] + ', got ' + value)"," if (resp.getResponseHeader(name) !== headers[name]) { throw new Error('Expected header ' + name + ' to have value ' + headers[name] + ', got ' + resp.getResponseHeader(name))",9,2
openstack%2Fswift~master~I74cbb8bed2d1fe46cb2a7d7fd851bb4454518045,openstack/swift,master,I74cbb8bed2d1fe46cb2a7d7fd851bb4454518045,Add random query string to CORS test requests,ABANDONED,2021-02-03 15:59:59.000000000,2021-02-05 19:04:09.000000000,,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 15:59:59.000000000', 'files': ['test/cors/test-container.js', 'test/cors/harness.js'], 'web_link': 'https://opendev.org/openstack/swift/commit/04574c8fe4ac3ebc0415c482b90dcad4d2ba9279', 'message': 'Add random query string to CORS test requests\n\nAdd random and date params to CORS test query strings\nto avoid the request being served from browser cache.\n\nChange-Id: I74cbb8bed2d1fe46cb2a7d7fd851bb4454518045\n'}]",3,773934,04574c8fe4ac3ebc0415c482b90dcad4d2ba9279,5,3,1,7847,,,0,"Add random query string to CORS test requests

Add random and date params to CORS test query strings
to avoid the request being served from browser cache.

Change-Id: I74cbb8bed2d1fe46cb2a7d7fd851bb4454518045
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/773934/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/cors/test-container.js', 'test/cors/harness.js']",2,04574c8fe4ac3ebc0415c482b90dcad4d2ba9279,p-cors-test-random-query-string,"export function MakeRequest (method, path, headers, body, params) { // give each request a unique query string to avoid ever fetching from cache params = params || {} params['cors-test-time'] = Date.now().toString() params['cors-test-random'] = Math.random().toString() const qs_parts = [] for (const key of Object.keys(params)) { qs_parts.push(key + '=' + params[key]) } path = path + '?' + qs_parts.join('&') ","export function MakeRequest (method, path, headers, body) {",18,8
openstack%2Fswift~master~I17ef7c2d1a71479b7dca68a3a5c83b5a0e296e09,openstack/swift,master,I17ef7c2d1a71479b7dca68a3a5c83b5a0e296e09,use some javascript builtins,ABANDONED,2021-02-03 18:40:39.000000000,2021-02-05 19:04:03.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 18:40:39.000000000', 'files': ['test/cors/harness.js'], 'web_link': 'https://opendev.org/openstack/swift/commit/0f09c00fcebfc722a69259e7a036a8c3a39aac48', 'message': 'use some javascript builtins\n\nChange-Id: I17ef7c2d1a71479b7dca68a3a5c83b5a0e296e09\n'}]",0,773982,0f09c00fcebfc722a69259e7a036a8c3a39aac48,4,2,1,1179,,,0,"use some javascript builtins

Change-Id: I17ef7c2d1a71479b7dca68a3a5c83b5a0e296e09
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/773982/1 && git format-patch -1 --stdout FETCH_HEAD,['test/cors/harness.js'],1,0f09c00fcebfc722a69259e7a036a8c3a39aac48,p-cors-test-random-query-string," var url = new URL(makeUrl(path)) // give each request a unique query string to avoid ever fetching from cache for (var key in params) { url.searchParams.append(key, params[key]) } req.open(method, url.toString())"," // give each request a unique query string to avoid ever fetching from cache const qs_parts = [] for (const key of Object.keys(params)) { qs_parts.push(key + '=' + params[key]) } path = path + '?' + qs_parts.join('&') req.open(method, makeUrl(path))",5,7
openstack%2Fpython-brick-cinderclient-ext~stable%2Fvictoria~I742cf8ee70ba427a12ece164f29cf46acaee3c8a,openstack/python-brick-cinderclient-ext,stable/victoria,I742cf8ee70ba427a12ece164f29cf46acaee3c8a,Update requirements and lower-constraints,MERGED,2021-01-09 02:26:55.000000000,2021-02-05 18:58:11.000000000,2021-02-05 18:56:22.000000000,"[{'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-09 02:26:55.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/b2e33001c5cdd2ce28c89bdb14e7c169d016915d', 'message': 'Update requirements and lower-constraints\n\nMajor changes:\n- python-cinderclient 3.3.0 -> 7.2.0 (update to victoria client)\n- os-brick 2.5.0 -> 4.0.0 (update to victoria official release)\n\nOther changes to satisfy dependencies for the above.\n\nChange-Id: I742cf8ee70ba427a12ece164f29cf46acaee3c8a\n'}]",0,770010,b2e33001c5cdd2ce28c89bdb14e7c169d016915d,8,3,1,5314,,,0,"Update requirements and lower-constraints

Major changes:
- python-cinderclient 3.3.0 -> 7.2.0 (update to victoria client)
- os-brick 2.5.0 -> 4.0.0 (update to victoria official release)

Other changes to satisfy dependencies for the above.

Change-Id: I742cf8ee70ba427a12ece164f29cf46acaee3c8a
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/10/770010/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,b2e33001c5cdd2ce28c89bdb14e7c169d016915d,update-l-c,cffi==1.14.2doc8==0.8.1eventlet==0.26.1greenlet==0.4.16msgpack==1.0.0os-brick==4.0.0os-win==5.1.0oslo.context==3.1.1 oslo.i18n==5.0.1 oslo.log==4.4.0 oslo.privsep==2.4.0 oslo.serialization==4.0.1 oslo.service==2.4.0 oslo.utils==4.7.0pbr==5.5.0python-cinderclient==7.2.0,cffi==1.13.2doc8==0.6.0eventlet==0.25.1greenlet==0.4.13msgpack==0.5.6os-brick==2.5.0os-win==4.0.0oslo.context==2.20.0 oslo.i18n==3.20.0 oslo.log==3.37.0 oslo.privsep==1.28.0 oslo.serialization==2.25.0 oslo.service==1.30.0 oslo.utils==3.36.0pbr==2.0.0python-cinderclient==3.3.0,20,21
openstack%2Fpython-brick-cinderclient-ext~stable%2Fussuri~Idde52d9d2797fa00af117e428fcb81f6fdb88e1c,openstack/python-brick-cinderclient-ext,stable/ussuri,Idde52d9d2797fa00af117e428fcb81f6fdb88e1c,Update requirements and lower-constraints,MERGED,2021-01-09 02:38:07.000000000,2021-02-05 18:57:55.000000000,2021-02-05 18:56:27.000000000,"[{'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-09 02:38:07.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/17dc36a20a9ccad7af6129e8171ee2c9c263a40f', 'message': 'Update requirements and lower-constraints\n\nMajor changes:\n- python-cinderclient 3.3.0 -> 7.0.0 (update to ussuri client)\n- os-brick 2.5.0 -> 3.0.1 (update to ussuri official release)\n\nOther changes to satisfy dependencies for the above.\n\nChange-Id: Idde52d9d2797fa00af117e428fcb81f6fdb88e1c\n'}]",0,770011,17dc36a20a9ccad7af6129e8171ee2c9c263a40f,10,3,1,5314,,,0,"Update requirements and lower-constraints

Major changes:
- python-cinderclient 3.3.0 -> 7.0.0 (update to ussuri client)
- os-brick 2.5.0 -> 3.0.1 (update to ussuri official release)

Other changes to satisfy dependencies for the above.

Change-Id: Idde52d9d2797fa00af117e428fcb81f6fdb88e1c
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/11/770011/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,17dc36a20a9ccad7af6129e8171ee2c9c263a40f,update-l-c,flake8==3.6.0hacking==3.0.1mccabe==0.6.0os-brick==3.0.1oslo.privsep==1.32.0pyflakes==2.0.0python-cinderclient==7.0.0,flake8==2.2.4hacking==2.0.0mccabe==0.2.1os-brick==2.5.0oslo.privsep==1.28.0pyflakes==0.8.1python-cinderclient==3.3.0,9,10
openstack%2Fopenstack-ansible-os_keystone~stable%2Fvictoria~I68c0b138955693c8d1992f986878862ea12f5149,openstack/openstack-ansible-os_keystone,stable/victoria,I68c0b138955693c8d1992f986878862ea12f5149,Allow OIDCClaimDelimiter to be set in the apache config file,MERGED,2021-02-04 15:05:56.000000000,2021-02-05 18:51:31.000000000,2021-02-05 18:50:16.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 15:05:56.000000000', 'files': ['templates/keystone-httpd.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/8b4b2251f9b4fc61650188084b7071fbfe1d44de', 'message': ""Allow OIDCClaimDelimiter to be set in the apache config file\n\nThis may be necessary for federation where there are multiple\nOIDC groups that are separate by a ';'. See [1].\n\n[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html\n\nChange-Id: I68c0b138955693c8d1992f986878862ea12f5149\n(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)\n""}]",0,773964,8b4b2251f9b4fc61650188084b7071fbfe1d44de,12,4,1,28619,,,0,"Allow OIDCClaimDelimiter to be set in the apache config file

This may be necessary for federation where there are multiple
OIDC groups that are separate by a ';'. See [1].

[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html

Change-Id: I68c0b138955693c8d1992f986878862ea12f5149
(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/64/773964/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone-httpd.conf.j2'],1,8b4b2251f9b4fc61650188084b7071fbfe1d44de,," {% if keystone_sp.trusted_idp_list.0.oidc_claim_delimiter is defined -%} OIDCClaimDelimiter ""{{ keystone_sp.trusted_idp_list.0.oidc_claim_delimiter }}"" {% endif %}",,3,0
openstack%2Fopenstack-helm-images~master~I1ac031106d487d61688207c714911fd91d1a717f,openstack/openstack-helm-images,master,I1ac031106d487d61688207c714911fd91d1a717f,Fix logic for critical_threshold to match the documentation,MERGED,2021-02-04 19:54:58.000000000,2021-02-05 18:41:08.000000000,2021-02-05 18:39:34.000000000,"[{'_account_id': 8863}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 19:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/6cea1c36703f4681a9d6f891c0392fc1717b7695', 'message': 'Fix logic for critical_threshold to match the documentation\n\nChange-Id: I1ac031106d487d61688207c714911fd91d1a717f\n'}, {'number': 2, 'created': '2021-02-04 22:53:18.000000000', 'files': ['nagios/plugins/query_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/a262c243d2942372b44479d5d02ad3a6680e6086', 'message': 'Fix logic for critical_threshold to match the documentation\n\nChange-Id: I1ac031106d487d61688207c714911fd91d1a717f\n'}]",0,774152,a262c243d2942372b44479d5d02ad3a6680e6086,13,4,2,27499,,,0,"Fix logic for critical_threshold to match the documentation

Change-Id: I1ac031106d487d61688207c714911fd91d1a717f
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/52/774152/1 && git format-patch -1 --stdout FETCH_HEAD,['nagios/plugins/query_elasticsearch.py'],1,6cea1c36703f4681a9d6f891c0392fc1717b7695,, if hits >= args.critical_threshold:, if hits > args.critical_threshold:,1,1
openstack%2Fopenstack-helm-images~master~I15df1b940c80d756685e58341f5a40c94db1a4a6,openstack/openstack-helm-images,master,I15df1b940c80d756685e58341f5a40c94db1a4a6,Limit pip for nagios xenial image,MERGED,2021-02-03 22:24:20.000000000,2021-02-05 18:34:44.000000000,2021-02-05 18:33:24.000000000,"[{'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27499}]","[{'number': 1, 'created': '2021-02-03 22:24:20.000000000', 'files': ['nagios/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/6f41c6ee840f48c2231a32b9830b09249acb362a', 'message': 'Limit pip for nagios xenial image\n\nStarting pip 21 python2 is not supported.\n\nChange-Id: I15df1b940c80d756685e58341f5a40c94db1a4a6\nSigned-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>\n'}]",0,774010,6f41c6ee840f48c2231a32b9830b09249acb362a,13,7,1,8863,,,0,"Limit pip for nagios xenial image

Starting pip 21 python2 is not supported.

Change-Id: I15df1b940c80d756685e58341f5a40c94db1a4a6
Signed-off-by: Andrii Ostapenko <andrii.ostapenko@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/10/774010/1 && git format-patch -1 --stdout FETCH_HEAD,['nagios/Dockerfile.ubuntu_xenial'],1,6f41c6ee840f48c2231a32b9830b09249acb362a,,"RUN pip --no-cache-dir install --upgrade ""pip<21"" \",RUN pip --no-cache-dir install --upgrade pip \,1,1
openstack%2Fopenstack-ansible-os_keystone~stable%2Ftrain~I68c0b138955693c8d1992f986878862ea12f5149,openstack/openstack-ansible-os_keystone,stable/train,I68c0b138955693c8d1992f986878862ea12f5149,Allow OIDCClaimDelimiter to be set in the apache config file,MERGED,2021-02-04 15:06:51.000000000,2021-02-05 18:21:16.000000000,2021-02-05 18:19:17.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-04 15:06:51.000000000', 'files': ['templates/keystone-httpd.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/60f7f7f2851106fbfa42956814ed8265187396ac', 'message': ""Allow OIDCClaimDelimiter to be set in the apache config file\n\nThis may be necessary for federation where there are multiple\nOIDC groups that are separate by a ';'. See [1].\n\n[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html\n\nChange-Id: I68c0b138955693c8d1992f986878862ea12f5149\n(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)\n""}]",0,773966,60f7f7f2851106fbfa42956814ed8265187396ac,8,4,1,28619,,,0,"Allow OIDCClaimDelimiter to be set in the apache config file

This may be necessary for federation where there are multiple
OIDC groups that are separate by a ';'. See [1].

[1] https://docs.openstack.org/keystone/ussuri/admin/federation/mapping_combinations.html

Change-Id: I68c0b138955693c8d1992f986878862ea12f5149
(cherry picked from commit b71f4853e3749169f8d8e23c78c4dc3846c026dd)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/66/773966/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone-httpd.conf.j2'],1,60f7f7f2851106fbfa42956814ed8265187396ac,," {% if keystone_sp.trusted_idp_list.0.oidc_claim_delimiter is defined -%} OIDCClaimDelimiter ""{{ keystone_sp.trusted_idp_list.0.oidc_claim_delimiter }}"" {% endif %}",,3,0
openstack%2Fetcd3gw~master~I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6,openstack/etcd3gw,master,I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6,Drop py2 support and clean things up,MERGED,2021-02-04 13:14:16.000000000,2021-02-05 18:20:02.000000000,2021-02-05 18:15:41.000000000,"[{'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-04 13:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/eb09579d5ad66c6ae1ca0ae81ef9468dcf3bfcb7', 'message': 'Drop py2 support and clean things up\n\nChange-Id: I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6\n'}, {'number': 2, 'created': '2021-02-04 13:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/37dbefe1232c92f768cd0e713f0d9a0260983ada', 'message': 'Drop py2 support and clean things up\n\nChange-Id: I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6\n'}, {'number': 3, 'created': '2021-02-04 14:11:31.000000000', 'files': ['requirements.txt', 'test-requirements.txt', '.travis.yml', '.zuul.yaml', 'doc/source/conf.py', 'doc/requirements.txt', 'setup.cfg', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/etcd3gw/commit/4f299a62c2b3e0188e371c5ce50f40948510c1e6', 'message': 'Drop py2 support and clean things up\n\nChange-Id: I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6\n'}]",0,774082,4f299a62c2b3e0188e371c5ce50f40948510c1e6,14,4,3,30491,,,0,"Drop py2 support and clean things up

Change-Id: I0b2afbb3f8ba1da18e2c10e713e5374a3131a7a6
",git fetch https://review.opendev.org/openstack/etcd3gw refs/changes/82/774082/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', '.travis.yml', '.zuul.yaml', 'doc/source/conf.py', 'doc/requirements.txt', 'setup.cfg', 'tox.ini', 'releasenotes/source/conf.py']",9,eb09579d5ad66c6ae1ca0ae81ef9468dcf3bfcb7,drop-py2-support," 'openstackdocstheme',pygments_style = 'native'html_theme = 'openstackdocs' # openstackdocstheme options openstackdocs_repo_name = 'openstack/etcd3gw'"," 'oslosphinx',pygments_style = 'sphinx'html_theme = 'default'",38,121
openstack%2Foslo.policy~master~Iae1846215b29c07788acd47bc018b4cb97da8df2,openstack/oslo.policy,master,Iae1846215b29c07788acd47bc018b4cb97da8df2,DNM: More debugging,ABANDONED,2021-01-29 16:22:22.000000000,2021-02-05 18:19:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-29 16:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/769554d9de0da0c8a11fe99bf785a280a4dc0c4a', 'message': 'DNM: More debugging\n\nChange-Id: Iae1846215b29c07788acd47bc018b4cb97da8df2\n'}, {'number': 2, 'created': '2021-01-29 19:41:30.000000000', 'files': ['oslo_policy/policy.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/89893b9d1aa32e209cf6ad580a30e6e2f08f2d35', 'message': 'DNM: More debugging\n\nChange-Id: Iae1846215b29c07788acd47bc018b4cb97da8df2\n'}]",2,773143,89893b9d1aa32e209cf6ad580a30e6e2f08f2d35,5,1,2,4393,,,0,"DNM: More debugging

Change-Id: Iae1846215b29c07788acd47bc018b4cb97da8df2
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/43/773143/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_policy/policy.py'],1,769554d9de0da0c8a11fe99bf785a280a4dc0c4a,," LOG.debug('Looking for policy file in %s' % location) LOG.debug('Exist check %s: %s' % ( os.path.join(location, old_default_policy_file), os.path.exists(os.path.join(location, old_default_policy_file)))) try: LOG.debug('Contents of location %s: %s' % (location, os.listdir(location))) except Exception as e: LOG.debug('Location does not exist, no contents: %s' % location) ",,12,0
openstack%2Foslo.config~master~Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3,openstack/oslo.config,master,Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3,DNM: for debugging,ABANDONED,2021-01-29 16:24:13.000000000,2021-02-05 18:19:29.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-29 16:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/089dc438b406f92394655443278242cfc2fc09d6', 'message': 'DNM: for debugging\n\nChange-Id: Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3\n'}, {'number': 2, 'created': '2021-01-29 16:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/bb48d1366c4209021c0162d98da9f74240185263', 'message': 'DNM: for debugging\n\nChange-Id: Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3\n'}, {'number': 3, 'created': '2021-01-29 18:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/3f4e2dffac3642c87833e31025e3c37b4f4888b6', 'message': 'DNM: for debugging\n\nChange-Id: Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3\n'}, {'number': 4, 'created': '2021-01-29 21:02:58.000000000', 'files': ['oslo_config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/ac2fbff8edc51ebe3b9e116292d14ba9733c3f48', 'message': 'DNM: for debugging\n\nChange-Id: Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3\n'}]",3,773146,ac2fbff8edc51ebe3b9e116292d14ba9733c3f48,8,2,4,4393,,,0,"DNM: for debugging

Change-Id: Ie4aa68222bfb0bd4d71f3b579d048b775601f0c3
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/46/773146/4 && git format-patch -1 --stdout FETCH_HEAD,['oslo_config/cfg.py'],1,089dc438b406f92394655443278242cfc2fc09d6,," LOG.debug('Checking for %s: %s' % (path, os.path.exists(path))) LOG.debug('searching file %s in project: %s directories: %s.', name, self.project, dirs)",,2,1
openstack%2Fmanila~master~I54063d4876a956723ac479c83d924c1efdd98a46,openstack/manila,master,I54063d4876a956723ac479c83d924c1efdd98a46,DNM (yet) - Gracefully handle ceph backends w/o mode capability,NEW,2019-02-01 15:14:07.000000000,2021-02-05 18:17:44.000000000,,"[{'_account_id': 2417}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-02-01 15:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/88647aa400119b3df3e398d60a4777dc9695c090', 'message': 'DNM - gracefully handle ceph backends w/o mode capability\n\nI\'m not sure that we should do this, but in light of downstream\nCI failures, we could gracefully handle the situation where an\nold version of ceph is deployed that cannot handle setting mode\non volume and snapshot creates, and on group operations.\n\nWe\'d have to inspect logs downstream in RDO CI to see that packages\nneed updating and containers rebuilt.  And it\'s not clear that the\nright semantics when one can\'t fulfill a user\'s request to create\na share with a given mode is to say ""I can\'t do exactly that, but\nI created one with the default mode -- hope you like it.""\n\nPutting this up for discussion.  If we were to go ahead we\'d\nmake corresponding changes for the other operations than volume\ncreation and add some unit tests that throw the TypeError.\n\nChange-Id: I54063d4876a956723ac479c83d924c1efdd98a46\n'}, {'number': 2, 'created': '2019-03-22 16:44:45.000000000', 'files': ['manila/share/drivers/cephfs/driver.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f288329b443bf73f3265bcefabab8b281f311859', 'message': ""DNM (yet) - Gracefully handle ceph backends w/o mode capability\n\nDownstream packages (e.g. ubuntu) of ceph are not yet all up-to-date\neven though the requisite changes in ceph git repos have been\nbackported all the way to luminous, the earliest ceph version supported\nin manila.\n\nSo gracefully handle the situation where an old version of ceph is\ndeployed that cannot handle setting mode on volume and snapshot\ncreates, and on group operations.\n\nNote that CentOS and RHOSP and SUSE packages have been updated and\nKevin Carter is raising a LP issue for ubuntu so we may not have a\nneed for this one.  Ceph community would like to encourage customers\nto update if they hit the issue.\n\nIf we do go ahad then we'd need to make corresponding changes for the\nother operations than volume creation, add some unit tests that throw,\nthe TypeError, and of course add a release note.\n\nChange-Id: I54063d4876a956723ac479c83d924c1efdd98a46\n""}]",2,634430,f288329b443bf73f3265bcefabab8b281f311859,30,14,2,9003,,,0,"DNM (yet) - Gracefully handle ceph backends w/o mode capability

Downstream packages (e.g. ubuntu) of ceph are not yet all up-to-date
even though the requisite changes in ceph git repos have been
backported all the way to luminous, the earliest ceph version supported
in manila.

So gracefully handle the situation where an old version of ceph is
deployed that cannot handle setting mode on volume and snapshot
creates, and on group operations.

Note that CentOS and RHOSP and SUSE packages have been updated and
Kevin Carter is raising a LP issue for ubuntu so we may not have a
need for this one.  Ceph community would like to encourage customers
to update if they hit the issue.

If we do go ahad then we'd need to make corresponding changes for the
other operations than volume creation, add some unit tests that throw,
the TypeError, and of course add a release note.

Change-Id: I54063d4876a956723ac479c83d924c1efdd98a46
",git fetch https://review.opendev.org/openstack/manila refs/changes/30/634430/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/cephfs/driver.py'],1,88647aa400119b3df3e398d60a4777dc9695c090,,"DEFAULT_VOLUME_MODE = '0755' try: cephfs_volume = self.volume_client.create_volume( cephfs_share_path(share), size=size, data_isolated=data_isolated, mode=self._cephfs_volume_mode) except TypeError: cephfs_volume = self.volume_client.create_volume( cephfs_share_path(share), size=size, data_isolated=data_isolated) LOG.info(""[%(be)s] Ceph backend does not support setting "" ""volume mode."", {""be"": self.backend_name}) if self._cephfs_volume_mode != int(DEFAULT_VOLUME_MODE, 8): LOG.warning(""mode requested: %(mr)s, "" ""mode used: %(mu)s."", {""mr"": oct(self._cephfs_volume_mode), ""mu"": DEFAULT_VOLUME_MODE})","DEFAULT_VOLUME_MODE = '755' cephfs_volume = self.volume_client.create_volume( cephfs_share_path(share), size=size, data_isolated=data_isolated, mode=self._cephfs_volume_mode)",17,4
openstack%2Fswift~master~I1d573ee45e597668032b438e2d50ce96d2639871,openstack/swift,master,I1d573ee45e597668032b438e2d50ce96d2639871,Change default -max-shrinking to 1,ABANDONED,2021-02-05 15:59:13.000000000,2021-02-05 18:08:04.000000000,,[{'_account_id': 15343}],"[{'number': 1, 'created': '2021-02-05 15:59:13.000000000', 'files': ['swift/cli/manage_shard_ranges.py', 'test/unit/cli/test_manage_shard_ranges.py', 'test/probe/test_sharder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/75461c757f043b13be57a0cda7f7c590c1024e6e', 'message': 'Change default -max-shrinking to 1\n\nChange-Id: I1d573ee45e597668032b438e2d50ce96d2639871\n'}]",0,774277,75461c757f043b13be57a0cda7f7c590c1024e6e,3,1,1,7847,,,0,"Change default -max-shrinking to 1

Change-Id: I1d573ee45e597668032b438e2d50ce96d2639871
",git fetch https://review.opendev.org/openstack/swift refs/changes/77/774277/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/cli/manage_shard_ranges.py', 'test/unit/cli/test_manage_shard_ranges.py', 'test/probe/test_sharder.py']",3,75461c757f043b13be57a0cda7f7c590c1024e6e,p-shard-compact," # now compact some ranges; use --max-shrinking to allow 2 shrinking # shards # now compact the final two shard ranges to the root; use # --max-shrinking to allow 2 shrinking shards 'compact', '--yes', '--max-shrinking', '2'],"," # now compact some ranges; use --max-shrinking to limit the number of # shrinking shards to 2 # now compact the final two shard ranges to the root 'compact', '--yes'],",67,12
openstack%2Fkuryr-kubernetes~master~I3257e263b53bb9f38946ca9cff6a1be5448dec00,openstack/kuryr-kubernetes,master,I3257e263b53bb9f38946ca9cff6a1be5448dec00,Get trunks more diligently,MERGED,2021-02-04 17:15:13.000000000,2021-02-05 17:50:11.000000000,2021-02-05 17:48:28.000000000,"[{'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2021-02-04 17:15:13.000000000', 'files': ['kuryr_kubernetes/controller/handlers/kuryrnetwork_population.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_kuryrnetwork_population.py', 'kuryr_kubernetes/utils.py', 'kuryr_kubernetes/tests/unit/test_utils.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/229a990b57ecb74f4019e81f6758db3ead7c7423', 'message': ""Get trunks more diligently\n\nWe mostly assumed that trunk ports are only used by Kuryr in an\nOpenStack env but sometimes it's not true. This commit adds some checks\nto make sure we list trunk ports in a smarter way (checking if they\nmatch the worker_nodes_subnets) and operate on them in a safer way\n(checking if they even have IPs).\n\nChange-Id: I3257e263b53bb9f38946ca9cff6a1be5448dec00\nCloses-Bug: 1914631\n""}]",0,774108,229a990b57ecb74f4019e81f6758db3ead7c7423,9,4,1,11600,,,0,"Get trunks more diligently

We mostly assumed that trunk ports are only used by Kuryr in an
OpenStack env but sometimes it's not true. This commit adds some checks
to make sure we list trunk ports in a smarter way (checking if they
match the worker_nodes_subnets) and operate on them in a safer way
(checking if they even have IPs).

Change-Id: I3257e263b53bb9f38946ca9cff6a1be5448dec00
Closes-Bug: 1914631
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/08/774108/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/handlers/kuryrnetwork_population.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_kuryrnetwork_population.py', 'kuryr_kubernetes/utils.py', 'kuryr_kubernetes/tests/unit/test_utils.py']",5,229a990b57ecb74f4019e81f6758db3ead7c7423,bug/1914631," ip1 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.1', 'subnet_id': 'foo'}], ip2 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.2', 'subnet_id': 'bar'}], ip3 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.3', 'subnet_id': 'baz'}], ip4 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.4', 'subnet_id': 'zab'}], 'trunk_details': True}) ports = (p for p in [ip1, ip2, ip3, ip4]) trunk_ips = utils.get_nodes_ips(['foo', 'bar']) ip1 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.1', 'subnet_id': 'foo'}], ip2 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.2', 'subnet_id': 'bar'}], trunk_ips = utils.get_nodes_ips(['foo'])"," ip1 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.1'}], ip2 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.2'}], ip3 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.3'}], ports = (p for p in [ip1, ip2, ip3]) trunk_ips = utils.get_nodes_ips() ip1 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.1'}], ip2 = munch.Munch({'fixed_ips': [{'ip_address': '10.0.0.2'}], trunk_ips = utils.get_nodes_ips()",30,12
openstack%2Fcinder~master~Ic50c5b59b7dfc9a5e594b892398702f1341c25d3,openstack/cinder,master,Ic50c5b59b7dfc9a5e594b892398702f1341c25d3,squash image_utils,ABANDONED,2021-02-05 17:04:04.000000000,2021-02-05 17:08:45.000000000,,[],"[{'number': 1, 'created': '2021-02-05 17:04:04.000000000', 'files': ['cinder/image/image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/70560c18d52d00db15915c6de1e6a1bbafed9c3b', 'message': 'squash image_utils\n\nChange-Id: Ic50c5b59b7dfc9a5e594b892398702f1341c25d3\n'}]",0,774289,70560c18d52d00db15915c6de1e6a1bbafed9c3b,3,0,1,4523,,,0,"squash image_utils

Change-Id: Ic50c5b59b7dfc9a5e594b892398702f1341c25d3
",git fetch https://review.opendev.org/openstack/cinder refs/changes/89/774289/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/image/image_utils.py'],1,70560c18d52d00db15915c6de1e6a1bbafed9c3b,mypy,"def qemu_img_info(path: str, run_as_root: bool = True, force_share: bool = False) -> imageutils.QemuImgInfo:def get_qemu_data(image_id: str, has_meta: bool, disk_format_raw: bool, dest: str, run_as_root: bool, force_share: bool = False):","def qemu_img_info(path: str, run_as_root: bool = True, force_share: bool = False) -> imageutils.QemuImgInfo:def get_qemu_data(image_id, has_meta, disk_format_raw, dest, run_as_root, force_share=False):",5,3
openstack%2Freleases~master~I73528c3ca8a9f3b9fcec6326129d04efa78615fb,openstack/releases,master,I73528c3ca8a9f3b9fcec6326129d04efa78615fb,Release oslo.policy 3.6.2,MERGED,2021-02-05 15:13:51.000000000,2021-02-05 17:05:17.000000000,2021-02-05 17:05:17.000000000,"[{'_account_id': 308}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-05 15:13:51.000000000', 'files': ['deliverables/wallaby/oslo.policy.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a612add3f5209d04b60f9f253dea2af5daafe95f', 'message': 'Release oslo.policy 3.6.2\n\nThis release includes an important fix ensuring the oslo.policy Enforcer\nsafely handles data it modifies:\n\n  https://review.opendev.org/c/openstack/oslo.policy/+/773950/5\n\nChange-Id: I73528c3ca8a9f3b9fcec6326129d04efa78615fb\n'}]",0,774250,a612add3f5209d04b60f9f253dea2af5daafe95f,8,6,1,5046,,,0,"Release oslo.policy 3.6.2

This release includes an important fix ensuring the oslo.policy Enforcer
safely handles data it modifies:

  https://review.opendev.org/c/openstack/oslo.policy/+/773950/5

Change-Id: I73528c3ca8a9f3b9fcec6326129d04efa78615fb
",git fetch https://review.opendev.org/openstack/releases refs/changes/50/774250/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/oslo.policy.yaml'],1,a612add3f5209d04b60f9f253dea2af5daafe95f,, - version: 3.6.2 projects: - repo: openstack/oslo.policy hash: de243e7a72097246a1c9be9072a4322df38927b2,,4,0
openstack%2Fopenstack-manuals~master~I6f8da8772bef24057970cda8cbed7838b3125645,openstack/openstack-manuals,master,I6f8da8772bef24057970cda8cbed7838b3125645,Redirect bindep docs to opendev,MERGED,2021-02-04 19:10:28.000000000,2021-02-05 16:36:54.000000000,2021-02-05 16:08:56.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2021-02-04 19:10:28.000000000', 'files': ['www/.htaccess', 'www/redirect-tests.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8556867e6f5aaa3d132631dece3c67bdfb1c8ced', 'message': 'Redirect bindep docs to opendev\n\nThe opendev/bindep projects has started publishing its documentation\non the docs.opendev.org site now, so install a redirect from the\nformer location for the sake of user continuity.\n\nChange-Id: I6f8da8772bef24057970cda8cbed7838b3125645\nDepends-On: https://review.opendev.org/773796\n'}]",0,774147,8556867e6f5aaa3d132631dece3c67bdfb1c8ced,10,3,1,5263,,,0,"Redirect bindep docs to opendev

The opendev/bindep projects has started publishing its documentation
on the docs.opendev.org site now, so install a redirect from the
former location for the sake of user continuity.

Change-Id: I6f8da8772bef24057970cda8cbed7838b3125645
Depends-On: https://review.opendev.org/773796
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/774147/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/.htaccess', 'www/redirect-tests.txt']",2,8556867e6f5aaa3d132631dece3c67bdfb1c8ced,bindep-2.9,"# Redirect https://docs.openstack.org/infra/bindep to # https://docs.opendev.org/opendev/bindep {{ deep_links('/infra/bindep', 'https://docs.opendev.org/opendev/bindep/latest') }} # End redirect bindep ",,10,0
openstack%2Fglance~master~I28c2d4701750bbd94c3f0ed106569091bea020b3,openstack/glance,master,I28c2d4701750bbd94c3f0ed106569091bea020b3,Add devstack plugin script,MERGED,2021-02-02 04:25:56.000000000,2021-02-05 16:35:44.000000000,2021-02-05 16:34:09.000000000,"[{'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 04:25:56.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/glance/commit/2a120055c657258f6e5e8dcd804c1274d1df692d', 'message': 'Add devstack plugin script\n\nThis commit adds a devstack/plugin.sh script so that we can invoke it\nfrom devstack. This is useful for deploying glance in particular ways we\nneed to test, like with new policy defaults for API protection testing.\n\nChange-Id: I28c2d4701750bbd94c3f0ed106569091bea020b3\n'}]",0,773566,2a120055c657258f6e5e8dcd804c1274d1df692d,13,3,1,5046,,,0,"Add devstack plugin script

This commit adds a devstack/plugin.sh script so that we can invoke it
from devstack. This is useful for deploying glance in particular ways we
need to test, like with new policy defaults for API protection testing.

Change-Id: I28c2d4701750bbd94c3f0ed106569091bea020b3
",git fetch https://review.opendev.org/openstack/glance refs/changes/66/773566/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,2a120055c657258f6e5e8dcd804c1274d1df692d,secure-rbac,"#!/usr/bin/env bash # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. function configure_enforce_scope { iniset $GLANCE_CONF_DIR/glance-api.conf oslo_policy enforce_scope true iniset $GLANCE_CONF_DIR/glance-api.conf oslo_policy enforce_new_defaults true sudo systemctl restart devstack@keystone } function configure_protection_tests { iniset $TEMPEST_CONFIG image-feature-enabled enforce_scope true iniset $TEMPEST_CONFIG auth admin_system true iniset $TEMPEST_CONFIG auth admin_project_name '' } # For more information on Devstack plugins, including a more detailed # explanation on when the different steps are executed please see: # https://docs.openstack.org/devstack/latest/plugins.html if [[ ""$1"" == ""stack"" && ""$2"" == ""test-config"" ]]; then # This phase is executed after Tempest was configured echo ""Glance plugin - Test-config phase"" if [[ ""$(trueorfalse False GLANCE_ENFORCE_SCOPE)"" == ""True"" ]] ; then # devstack and tempest assume enforce_scope is false, so need to wait # until the final phase to turn it on configure_enforce_scope configure_protection_tests fi fi ",,40,0
openstack%2Fblazar~master~I89fccf38451b19c4af25558834cf919bd772fdca,openstack/blazar,master,I89fccf38451b19c4af25558834cf919bd772fdca,Remove misplaced return statement,MERGED,2020-11-27 07:04:15.000000000,2021-02-05 16:31:14.000000000,2021-02-05 16:29:37.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 07:04:15.000000000', 'files': ['blazar/tests/api/v1/test_validation.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/a1ecf0d98b15f8f0f4dd44037fea79121dee5f2b', 'message': 'Remove misplaced return statement\n\nThis is to remove the misplaced return statement which makes the\nstatement after it unreachable.\n\nChange-Id: I89fccf38451b19c4af25558834cf919bd772fdca\n'}]",0,764417,a1ecf0d98b15f8f0f4dd44037fea79121dee5f2b,7,2,1,20190,,,0,"Remove misplaced return statement

This is to remove the misplaced return statement which makes the
statement after it unreachable.

Change-Id: I89fccf38451b19c4af25558834cf919bd772fdca
",git fetch https://review.opendev.org/openstack/blazar refs/changes/17/764417/1 && git format-patch -1 --stdout FETCH_HEAD,['blazar/tests/api/v1/test_validation.py'],1,a1ecf0d98b15f8f0f4dd44037fea79121dee5f2b,false_return, self.u_api.render(lease_id=self.fake_id), return self.u_api.render(lease_id=self.fake_id),1,1
openstack%2Fcharm-trilio-wlm~master~I4e32dab8e4eccbd20269004d3f79905196ed0732,openstack/charm-trilio-wlm,master,I4e32dab8e4eccbd20269004d3f79905196ed0732,Add support for Ussuri,MERGED,2021-02-05 10:17:51.000000000,2021-02-05 16:24:12.000000000,2021-02-05 16:24:12.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 10:17:51.000000000', 'files': ['src/lib/charm/openstack/trilio_wlm.py'], 'web_link': 'https://opendev.org/openstack/charm-trilio-wlm/commit/2598bff3ca0d3d61b2f6d64c009b6ca4e6fefafa', 'message': 'Add support for Ussuri\n\nThis adds support for\n\nTrilio 4.0 + Bionic + Ussuri\nTrilio 4.1 + Bionic + Ussuri\nTrilio 4.1 + Focal + Ussuri\n\nBundles to follow when the rest of the Trilio charms are fixed.\n\nChange-Id: I4e32dab8e4eccbd20269004d3f79905196ed0732\n'}]",0,774216,2598bff3ca0d3d61b2f6d64c009b6ca4e6fefafa,7,3,1,12549,,,0,"Add support for Ussuri

This adds support for

Trilio 4.0 + Bionic + Ussuri
Trilio 4.1 + Bionic + Ussuri
Trilio 4.1 + Focal + Ussuri

Bundles to follow when the rest of the Trilio charms are fixed.

Change-Id: I4e32dab8e4eccbd20269004d3f79905196ed0732
",git fetch https://review.opendev.org/openstack/charm-trilio-wlm refs/changes/16/774216/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/trilio_wlm.py'],1,2598bff3ca0d3d61b2f6d64c009b6ca4e6fefafa,ussuri-support," class TrilioWLMCharmUssuri40(TrilioWLMCharm): # First release supported release = ""ussuri"" trilio_release = ""4.0"" python_version = 3 packages = [ ""linux-image-virtual"", # Used for libguestfs supermin appliance ""nova-common"", ""workloadmgr"", ""python3-workloadmgrclient"", ""python3-contegoclient"", ""python3-glanceclient"", ""python3-neutronclient"", ""python3-apt"", ""python3-retrying"", ] class TrilioWLMCharmUssuri41(TrilioWLMCharmUssuri40): # First release supported release = ""ussuri"" trilio_release = ""4.1""",,27,0
openstack%2Fcharm-trilio-dm-api~master~I3ced39cb3ab5bf678ac57ed95e2c5cb8e82b3525,openstack/charm-trilio-dm-api,master,I3ced39cb3ab5bf678ac57ed95e2c5cb8e82b3525,Add support for Ussuri,MERGED,2021-02-05 10:23:03.000000000,2021-02-05 16:23:32.000000000,2021-02-05 16:23:32.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 10:23:03.000000000', 'files': ['src/lib/charm/openstack/dmapi.py'], 'web_link': 'https://opendev.org/openstack/charm-trilio-dm-api/commit/10cd6cd2b8e97db73c2105fd3dabfd02d75c4d63', 'message': 'Add support for Ussuri\n\nThis adds support for\n\nTrilio 4.0 + Bionic + Ussuri\nTrilio 4.1 + Bionic + Ussuri\nTrilio 4.1 + Focal + Ussuri\n\nBundles to follow when the rest of the Trilio charms are fixed.\n\nChange-Id: I3ced39cb3ab5bf678ac57ed95e2c5cb8e82b3525\n'}]",0,774219,10cd6cd2b8e97db73c2105fd3dabfd02d75c4d63,7,3,1,12549,,,0,"Add support for Ussuri

This adds support for

Trilio 4.0 + Bionic + Ussuri
Trilio 4.1 + Bionic + Ussuri
Trilio 4.1 + Focal + Ussuri

Bundles to follow when the rest of the Trilio charms are fixed.

Change-Id: I3ced39cb3ab5bf678ac57ed95e2c5cb8e82b3525
",git fetch https://review.opendev.org/openstack/charm-trilio-dm-api refs/changes/19/774219/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/dmapi.py'],1,10cd6cd2b8e97db73c2105fd3dabfd02d75c4d63,focal-support," @property def python_version(self): return hookenv.config(""python-version"") if self.python_version == 3:class DmapiCharmiUssur40(DmapiCharm): # First release supported release = ""ussuri"" trilio_release = ""4.0"" @property def packages(self): if self.python_version == 3: return [""python3-nova"", ""python3-dmapi"", ""python3-retrying""] return [""python-nova"", ""dmapi"", ""python-retrying""] class DmapiCharmUssuri41(DmapiCharmQueens41): # First release supported release = ""ussuri"" trilio_release = ""4.1"""," if hookenv.config(""python-version"") == 3:",26,1
openstack%2Fcinderlib~stable%2Fussuri~I86ccab516108615d6f718c6fdc9d3e4fad67ee05,openstack/cinderlib,stable/ussuri,I86ccab516108615d6f718c6fdc9d3e4fad67ee05,Update requirements and lower-constraints,MERGED,2021-01-15 20:42:22.000000000,2021-02-05 16:22:50.000000000,2021-02-05 16:20:44.000000000,"[{'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-15 20:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinderlib/commit/0f655c5f2487b671d348b43cdc3be4020cd0237b', 'message': 'Update requirements and lower-constraints\n\nChanges prompted by the new pip resolver doing stricter dependency\nchecking:\n- req, lc: cinder to 16.0.0 (ussuri official release)\n- lc: os-brick: 2.7.0 -> 3.0.1 (ussuri official release)\n- update test-req to match cinder stable/ussuri versions\n- added some indirect dependencies to test-requirements.txt to help\n  speed up dependency resolution\n- doc/req: openstackdocstheme, reno exceeded ussuri upper constraint\n\nChange-Id: I86ccab516108615d6f718c6fdc9d3e4fad67ee05\n'}, {'number': 2, 'created': '2021-01-26 13:20:54.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinderlib/commit/7fdbadddaf300497f0fad52396d3e167322b91b1', 'message': 'Update requirements and lower-constraints\n\nChanges prompted by the new pip resolver doing stricter dependency\nchecking:\n- req, lc: cinder to 16.0.0 (ussuri official release)\n- req: restrict cinder to < 17.0.0 (victoria) because cinder is not\n  in upper-constraints\n- req, lc: os-brick: to 3.0.1 (ussuri official release)\n- update test-req to match cinder stable/ussuri versions\n- added some indirect dependencies to test-requirements.txt to help\n  speed up dependency resolution\n- doc/req: openstackdocstheme, reno exceeded ussuri upper constraint\n- tox.ini: base testenv: added upper-constraints and changed it to\n  use cinder and os-brick from pypi instead of master\n\nChange-Id: I86ccab516108615d6f718c6fdc9d3e4fad67ee05\n'}]",0,771079,7fdbadddaf300497f0fad52396d3e167322b91b1,14,3,2,5314,,,0,"Update requirements and lower-constraints

Changes prompted by the new pip resolver doing stricter dependency
checking:
- req, lc: cinder to 16.0.0 (ussuri official release)
- req: restrict cinder to < 17.0.0 (victoria) because cinder is not
  in upper-constraints
- req, lc: os-brick: to 3.0.1 (ussuri official release)
- update test-req to match cinder stable/ussuri versions
- added some indirect dependencies to test-requirements.txt to help
  speed up dependency resolution
- doc/req: openstackdocstheme, reno exceeded ussuri upper constraint
- tox.ini: base testenv: added upper-constraints and changed it to
  use cinder and os-brick from pypi instead of master

Change-Id: I86ccab516108615d6f718c6fdc9d3e4fad67ee05
",git fetch https://review.opendev.org/openstack/cinderlib refs/changes/79/771079/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt']",4,0f655c5f2487b671d348b43cdc3be4020cd0237b,update-l-c,openstackdocstheme>=2.0.0 # Apache-2.0 reno>=2.5.0 # Apache-2.0,openstackdocstheme>=2.2.1 # Apache-2.0 reno>=3.1.0 # Apache-2.0,18,8
openstack%2Fcinderlib~stable%2Fvictoria~I59a2dd3cd2e56a83702e75086bec75569060167f,openstack/cinderlib,stable/victoria,I59a2dd3cd2e56a83702e75086bec75569060167f,Update requirements,MERGED,2021-01-26 13:51:43.000000000,2021-02-05 16:22:46.000000000,2021-02-05 16:20:41.000000000,"[{'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 10459}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-26 13:51:43.000000000', 'files': ['requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinderlib/commit/ef98ec2aee205d82c5eeb79b99e2dce74ef0cefe', 'message': ""Update requirements\n\n- cap cinder at < 18.0.0 (wallaby) in requirements.txt because cinder\n  isn't in upper-constraints\n- add os-brick>=4.0.1 (victoria official release) to requirements\n- tox.ini: base testenv: add upper-constraints and change to use\n  cinder and os-brick from pypi instead of master\n\nChange-Id: I59a2dd3cd2e56a83702e75086bec75569060167f\n""}]",0,772522,ef98ec2aee205d82c5eeb79b99e2dce74ef0cefe,9,5,1,5314,,,0,"Update requirements

- cap cinder at < 18.0.0 (wallaby) in requirements.txt because cinder
  isn't in upper-constraints
- add os-brick>=4.0.1 (victoria official release) to requirements
- tox.ini: base testenv: add upper-constraints and change to use
  cinder and os-brick from pypi instead of master

Change-Id: I59a2dd3cd2e56a83702e75086bec75569060167f
",git fetch https://review.opendev.org/openstack/cinderlib refs/changes/22/772522/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,ef98ec2aee205d82c5eeb79b99e2dce74ef0cefe,update-l-c,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/victoria} -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt,# Use cinder from master instead of from PyPi. Defining the egg name we won't # overwrite the package installed by Zuul on jobs supporting cross-project # dependencies (include Cinder in required-projects). This allows us to also # run local tests against master. # NOTE: Functional tests may fail if host is missing bindeps from deps projects deps= -r{toxinidir}/test-requirements.txt git+https://opendev.org/openstack/os-brick#egg=os-brick git+https://opendev.org/openstack/cinder#egg=cinder,5,9
openstack%2Ftripleo-heat-templates~master~I020da468d909bd98819f1e3618bf905260791d9b,openstack/tripleo-heat-templates,master,I020da468d909bd98819f1e3618bf905260791d9b,Add new parameters to configure nova-compute direct rbd image download,MERGED,2021-01-23 22:47:29.000000000,2021-02-05 16:13:45.000000000,2021-02-05 16:10:00.000000000,"[{'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 25402}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-01-23 22:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e950ba44fd8e32b1f41bfc052c7e3c514ca09a7f', 'message': 'Add new parameters to configure nova-compute direct rbd image download\n\nIntroduce new compute role based parameters to enable direct download if\nrbd is used. If GlanceBackend is rbd, nova::glance::enable_rbd_download\nis automatically set to true. This can be customized using role parameter\nNovaGlanceEnableRbdDownload. Also GlanceRbdPoolName is set as the default\nrbd pool, but can be customized via role parameter NovaGlanceRbdPoolName.\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687\nChange-Id: I020da468d909bd98819f1e3618bf905260791d9b\n'}, {'number': 2, 'created': '2021-01-27 10:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/909de73bba8ad6676bbe0b2a0c6bbce187bb211d', 'message': 'Add new parameters to configure nova-compute direct rbd image download\n\nIntroduce new compute role based parameters to enable direct download if\nrbd is used. If GlanceBackend is rbd, nova::glance::enable_rbd_download\nis automatically set to true. This can be customized using role parameter\nNovaGlanceEnableRbdDownload. Also GlanceRbdPoolName is set as the default\nrbd pool, but can be customized via role parameter NovaGlanceRbdPoolName.\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687\nChange-Id: I020da468d909bd98819f1e3618bf905260791d9b\n'}, {'number': 3, 'created': '2021-02-01 07:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/69075220c9a7f8b6b1333feb96c247fa88dbe8e8', 'message': 'Add new parameters to configure nova-compute direct rbd image download\n\nIf rbd is used for glance, but compute is using local ephemeral storage,\nnova-compute can direct download the images in this scenario from the\nglance ceph pool via rbd, instead going through glance api.\n\nThis change introduce new compute role based parameters to enable direct\ndownload of glance images via rbd. If NovaGlanceEnableRbdDownload is set,\nper default the global RBD glance parameters are used, CephClientUserName\nGlanceRbdPoolName and CephClusterName for the used ceph.conf.\n\nGlance also support multi storage backends which can be configured using\nGlanceMultistoreConfig. If additional RBD glance backends are configured,\nthe NovaGlanceRbdDownloadMultistoreConfig can be used to pointing to the\nhash key (backend ID) of GlanceMultistoreConfig to use.\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687\nChange-Id: I020da468d909bd98819f1e3618bf905260791d9b\n'}, {'number': 4, 'created': '2021-02-01 12:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ed2247a3c70c4abd53f65b389ae2edde8c1e1ecb', 'message': 'Add new parameters to configure nova-compute direct rbd image download\n\nIf rbd is used for glance, but compute is using local ephemeral storage,\nnova-compute can direct download the images in this scenario from the\nglance ceph pool via rbd, instead going through glance api.\n\nThis change introduce new compute role based parameters to enable direct\ndownload of glance images via rbd. If NovaGlanceEnableRbdDownload is set,\nper default the global RBD glance parameters are used, CephClientUserName\nGlanceRbdPoolName and CephClusterName for the used ceph.conf.\n\nGlance also support multi storage backends which can be configured using\nGlanceMultistoreConfig. If additional RBD glance backends are configured,\nthe NovaGlanceRbdDownloadMultistoreConfig can be used to pointing to the\nhash key (backend ID) of GlanceMultistoreConfig to use.\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687\nChange-Id: I020da468d909bd98819f1e3618bf905260791d9b\n'}, {'number': 5, 'created': '2021-02-04 12:25:22.000000000', 'files': ['releasenotes/notes/nova_direct_glance_rbd_download-e945933da26f10f0.yaml', 'deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/91837d4fa7325e909b5f5a655336015688edb47c', 'message': 'Add new parameters to configure nova-compute direct rbd image download\n\nIf rbd is used for glance, but compute is using local ephemeral storage,\nnova-compute can direct download the images in this scenario from the\nglance ceph pool via rbd, instead going through glance api.\n\nThis change introduce new compute role based parameters to enable direct\ndownload of glance images via rbd. If NovaGlanceEnableRbdDownload is set,\nper default the global RBD glance parameters are used, CephClientUserName\nGlanceRbdPoolName and CephClusterName for the used ceph.conf.\n\nGlance also support multi storage backends which can be configured using\nGlanceMultistoreConfig. If additional RBD glance backends are configured,\nthe NovaGlanceRbdDownloadMultistoreID can be used to pointing to the\nhash key (backend ID) of GlanceMultistoreConfig to use.\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687\nChange-Id: I020da468d909bd98819f1e3618bf905260791d9b\n'}]",15,772169,91837d4fa7325e909b5f5a655336015688edb47c,39,11,5,17216,,,0,"Add new parameters to configure nova-compute direct rbd image download

If rbd is used for glance, but compute is using local ephemeral storage,
nova-compute can direct download the images in this scenario from the
glance ceph pool via rbd, instead going through glance api.

This change introduce new compute role based parameters to enable direct
download of glance images via rbd. If NovaGlanceEnableRbdDownload is set,
per default the global RBD glance parameters are used, CephClientUserName
GlanceRbdPoolName and CephClusterName for the used ceph.conf.

Glance also support multi storage backends which can be configured using
GlanceMultistoreConfig. If additional RBD glance backends are configured,
the NovaGlanceRbdDownloadMultistoreID can be used to pointing to the
hash key (backend ID) of GlanceMultistoreConfig to use.

Depends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/772168
Depends-On: https://review.opendev.org/c/openstack/puppet-nova/+/770687
Change-Id: I020da468d909bd98819f1e3618bf905260791d9b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/69/772169/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nova_direct_glance_rbd_download-e945933da26f10f0.yaml', 'deployment/nova/nova-compute-container-puppet.yaml']",2,e950ba44fd8e32b1f41bfc052c7e3c514ca09a7f,rbd-download," NovaGlanceEnableRbdDownload: type: string description: > Enable download of Glance images directly via RBD. default: '' constraints: - allowed_values: [ '', 'true', 'True', 'TRUE', 'false', 'False', 'FALSE'] tags: - role_specific GlanceBackend: default: swift description: The short name of the Glance backend to use. Should be one of swift, rbd, cinder, or file type: string constraints: - allowed_values: ['swift', 'file', 'rbd', 'cinder'] GlanceRbdPoolName: default: images type: string NovaGlanceRbdPoolName: type: string description: > Per default GlanceRbdPoolName is set as rbd pool name. This parameter can can be used to overwrite GlanceRbdPoolName. default: '' tags: - role_specific nova_glance_enable_rbd_download: NovaGlanceEnableRbdDownload nova_glance_rbd_pool_name: NovaGlanceRbdPoolName NovaGlanceEnableRbdDownload: {get_param: NovaGlanceEnableRbdDownload} NovaGlanceRbdPoolName: {get_param: NovaGlanceRbdPoolName} glance_enable_rbd_download_set: not: and: - equals: [{get_param: [RoleParameters, NovaGlanceEnableRbdDownload]}, ''] - equals: [{get_param: NovaGlanceEnableRbdDownload}, ''] nova_glance_rbd_pool_name_set: not: and: - equals: [{get_param: [RoleParameters, NovaGlanceRbdPoolName]}, ''] - equals: [{get_param: NovaGlanceRbdPoolName}, ''] glance_rbd_backend_enabled: {equals: [{get_param: GlanceBackend}, ""rbd""]} nova::glance::enable_rbd_download: if: - glance_enable_rbd_download_set - contains: - {get_attr: [RoleParametersValue, value, nova_glance_enable_rbd_download]} - [""TRUE"", ""true"", ""True""] - if: - glance_rbd_backend_enabled - true - false nova::glance::rbd_user: {get_param: CephClientUserName} nova::glance::rbd_pool: if: - nova_glance_rbd_pool_name_set - {get_attr: [RoleParametersValue, value, nova_glance_rbd_pool_name]} - {get_param: GlanceRbdPoolName} nova::glance::rbd_ceph_conf: list_join: - '' - - '/etc/ceph/' - {get_param: CephClusterName} - '.conf'",,75,0
openstack%2Fnova~master~I4d3193d8401614311010ed0e055fcb3aaeeebaed,openstack/nova,master,I4d3193d8401614311010ed0e055fcb3aaeeebaed,Avoid allocation leak when deleting instance stuck in BUILD,MERGED,2020-01-14 08:20:04.000000000,2021-02-05 16:10:01.000000000,2020-02-28 01:02:51.000000000,"[{'_account_id': 9008}, {'_account_id': 9373}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28332}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-14 08:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c03ff8a10b6b707ca9ce6a8d3bfb5640ca44fafd', 'message': 'Avoid allocation leak when deleting instance stuck in BUILD\n\nDuring instance build, conductor claim resources to scheduler\nand create instance entry in cells.\n\nIf for any reason conductor is not able to get scheduler response\n(ex: AMQP issues) and in the mean time user requests deletion of\nits stuck instance in BUILD state, nova api will delete build_request\nbut let allocation in place resulting in a leak.\n\nThe change proposes that nova api ensure allocation cleanup is made\nif there is no instance entry in nova cells.\n\nChange-Id: I4d3193d8401614311010ed0e055fcb3aaeeebaed\nCloses-Bug: #1859496\n'}, {'number': 2, 'created': '2020-01-21 14:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/178a2353585303b7423784cf5892eb913bd12be8', 'message': 'Avoid allocation leak when deleting instance stuck in BUILD\n\nDuring instance build, conductor claim resources to scheduler\nand create instance entry in cells.\n\nIf for any reason conductor is not able to get scheduler response\n(ex: AMQP issues) and in the mean time user requests deletion of\nits stuck instance in BUILD state, nova api will delete build_request\nbut let allocation in place resulting in a leak.\n\nThe change proposes that nova api ensure allocation cleanup is made\nif there is no instance entry in nova cells.\n\nChange-Id: I4d3193d8401614311010ed0e055fcb3aaeeebaed\nCloses-Bug: #1859496\n'}, {'number': 3, 'created': '2020-02-14 15:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d26b55f22caf7d5b7c28f793dbe4cf34bf7fc6db', 'message': 'Avoid allocation leak when deleting instance stuck in BUILD\n\nDuring instance build, conductor claim resources to scheduler\nand create instance DB entry in cell.\n\nIf for any reason conductor is not able to complete a build after\ninstance claim (ex: AMQP issues, conductor restart before build completes)\nand in the mean time user requests deletion of its stuck instance in BUILD,\nnova api will delete build_request but let allocation in place resulting\nin a leak.\n\nThe change proposes that nova api ensures allocation cleanup is made\nin case of ongoing/incomplete build.\nNote that because build did not reach a cell, compute is not able to heal\nallocation during its periodic update_available_resource task.\nFurthermore, it ensures that instance mapping is also queued for deletion.\n\nChange-Id: I4d3193d8401614311010ed0e055fcb3aaeeebaed\nCloses-Bug: #1859496\n'}, {'number': 4, 'created': '2020-02-24 13:30:15.000000000', 'files': ['nova/tests/functional/integrated_helpers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f35930eef8fa27ee972e87366abb38596839fdba', 'message': 'Avoid allocation leak when deleting instance stuck in BUILD\n\nDuring instance build, conductor claim resources to scheduler\nand create instance DB entry in cell.\n\nIf for any reason conductor is not able to complete a build after\ninstance claim (ex: AMQP issues, conductor restart before build completes)\nand in the mean time user requests deletion of its stuck instance in BUILD,\nnova api will delete build_request but let allocation in place resulting\nin a leak.\n\nThe change proposes that nova api ensures allocation cleanup is made\nin case of ongoing/incomplete build.\nNote that because build did not reach a cell, compute is not able to heal\nallocation during its periodic update_available_resource task.\nFurthermore, it ensures that instance mapping is also queued for deletion.\n\nChange-Id: I4d3193d8401614311010ed0e055fcb3aaeeebaed\nCloses-Bug: #1859496\n'}]",16,702368,f35930eef8fa27ee972e87366abb38596839fdba,59,14,4,28332,,,0,"Avoid allocation leak when deleting instance stuck in BUILD

During instance build, conductor claim resources to scheduler
and create instance DB entry in cell.

If for any reason conductor is not able to complete a build after
instance claim (ex: AMQP issues, conductor restart before build completes)
and in the mean time user requests deletion of its stuck instance in BUILD,
nova api will delete build_request but let allocation in place resulting
in a leak.

The change proposes that nova api ensures allocation cleanup is made
in case of ongoing/incomplete build.
Note that because build did not reach a cell, compute is not able to heal
allocation during its periodic update_available_resource task.
Furthermore, it ensures that instance mapping is also queued for deletion.

Change-Id: I4d3193d8401614311010ed0e055fcb3aaeeebaed
Closes-Bug: #1859496
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/702368/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",2,c03ff8a10b6b707ca9ce6a8d3bfb5640ca44fafd,bug/1859496," else: # NOTE(aarents) In most cases instance is properly deleted # here, but if conductor handles build request, # asks allocation, but for any reason never gets or treats # scheduler response, the only chance to cleanup allocation # is here. self.placementclient.delete_allocation_for_instance( context, instance_uuid)",,12,1
openstack%2Fswift~master~I9edd6a78c5720c0aad4eed5cfb9f6311bb6b2512,openstack/swift,master,I9edd6a78c5720c0aad4eed5cfb9f6311bb6b2512,Exclude FOUND state from shard 'auditing' states,ABANDONED,2021-02-04 15:14:01.000000000,2021-02-05 16:01:34.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 15:14:01.000000000', 'files': ['test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/5aea1ea7975c6194ae8a599f9b7bfc2951f62957', 'message': ""Exclude FOUND state from shard 'auditing' states\n\nThe 'states=auditing' param on a container GET request is used\nto indicate that the returned shard ranges are to be used for shard\nauditing. Currently all shard range states are included.\n\nThe shard ranges of relevance to a shard are its own shard range and\nany overlapping shard ranges that may be acceptors if the shard is\nshrinking. None of these relevant shard ranges should be in state\nFOUND: the shard itself cannot be in FOUND state since it has been\ncreated; acceptor ranges should not be in FOUND state. This patch\ntherefore excludes FOUND from the 'auditing' states to prevent an\nunintended overlapping FOUND shard range that has not yet been\nresolved at the root container being fetched by a shrinking shard,\nwhich might then proceed to create and cleave to it.\n\nChange-Id: I9edd6a78c5720c0aad4eed5cfb9f6311bb6b2512\n""}]",1,774088,5aea1ea7975c6194ae8a599f9b7bfc2951f62957,4,2,1,7847,,,0,"Exclude FOUND state from shard 'auditing' states

The 'states=auditing' param on a container GET request is used
to indicate that the returned shard ranges are to be used for shard
auditing. Currently all shard range states are included.

The shard ranges of relevance to a shard are its own shard range and
any overlapping shard ranges that may be acceptors if the shard is
shrinking. None of these relevant shard ranges should be in state
FOUND: the shard itself cannot be in FOUND state since it has been
created; acceptor ranges should not be in FOUND state. This patch
therefore excludes FOUND from the 'auditing' states to prevent an
unintended overlapping FOUND shard range that has not yet been
resolved at the root container being fetched by a shrinking shard,
which might then proceed to create and cleave to it.

Change-Id: I9edd6a78c5720c0aad4eed5cfb9f6311bb6b2512
",git fetch https://review.opendev.org/openstack/swift refs/changes/88/774088/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py']",3,5aea1ea7975c6194ae8a599f9b7bfc2951f62957,p-shard-auditing-states-excludes-found,"# when auditing a shard gets its own shard range, which could be in any state # except FOUND, and any potential acceptors excluding FOUND ranges that may be # unwanted overlaps SHARD_AUDITING_STATES = [ShardRange.CREATED, ShardRange.CLEAVED, ShardRange.ACTIVE, ShardRange.SHARDING, ShardRange.SHARDED, ShardRange.SHRINKING, ShardRange.SHRUNK] currently maps to all states except FOUND). resolved_states.update(SHARD_AUDITING_STATES)", currently maps to all states). resolved_states.update(ShardRange.STATES.keys()),17,9
openstack%2Fopenstack-helm-images~master~Icda8443c66778ba86fbb415e16a8d509e231c2e4,openstack/openstack-helm-images,master,Icda8443c66778ba86fbb415e16a8d509e231c2e4,[ceph] Upgrade sudo for CVE fixes,ABANDONED,2021-02-03 22:04:57.000000000,2021-02-05 15:55:38.000000000,,"[{'_account_id': 18511}, {'_account_id': 22348}, {'_account_id': 22636}]","[{'number': 1, 'created': '2021-02-03 22:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c7f16812fcde2151f03603644774e6e2a78ef331', 'message': '[ceph] remove dist upgrade\n\nChange-Id: Icda8443c66778ba86fbb415e16a8d509e231c2e4\n'}, {'number': 2, 'created': '2021-02-04 17:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/aeb50040392722de10c4f8ba4b6dd65d76b4b5ab', 'message': '[ceph] Upgrade sudo for CVE fixes\n\nChange-Id: Icda8443c66778ba86fbb415e16a8d509e231c2e4\n'}, {'number': 3, 'created': '2021-02-04 17:53:29.000000000', 'files': ['ceph-config-helper/Dockerfile.ubuntu_bionic', 'ceph-daemon/Dockerfile.ubuntu_bionic'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b800c2a7ef35e96ce5163136da70121748d1c315', 'message': '[ceph] Upgrade sudo for CVE fixes\n\nThis is to make sure to install high CVE free sudo package\nas few of ceph packages depends on sudo.\n\nChange-Id: Icda8443c66778ba86fbb415e16a8d509e231c2e4\n'}]",1,774007,b800c2a7ef35e96ce5163136da70121748d1c315,10,3,3,28372,,,0,"[ceph] Upgrade sudo for CVE fixes

This is to make sure to install high CVE free sudo package
as few of ceph packages depends on sudo.

Change-Id: Icda8443c66778ba86fbb415e16a8d509e231c2e4
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/07/774007/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_bionic'],1,c7f16812fcde2151f03603644774e6e2a78ef331,,, apt-get dist-upgrade -y ;\,0,1
openstack%2Fswift~master~I3a5e05b91b29247eeb52ee88bb0a822f45f0523c,openstack/swift,master,I3a5e05b91b29247eeb52ee88bb0a822f45f0523c,Make fill_gaps fill all gaps with own_SR,NEW,2021-02-05 06:20:08.000000000,2021-02-05 15:37:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-05 06:20:08.000000000', 'files': ['swift/common/utils.py', 'test/probe/test_sharder.py', 'test/unit/container/test_server.py', 'test/unit/container/test_backend.py', 'swift/container/sharder.py', 'swift/container/backend.py', 'test/unit/common/test_utils.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8c5dfd49ff00c87a80346d982d0722e26d85bd90', 'message': 'Make fill_gaps fill all gaps with own_SR\n\nThere is a bug where we could mark everything to collapse back into the root\ncontainer and until all sharder have run any shrinking shard that runs\nbefore the rest will collapse and cause a momentary hole in the object\nlisting for the sharded container.\n\nWe currently have code in get_shard_ranges that when listing will\nfill_gaps with the root SR to plug holes. This is used when we are in\nthe sharding state and we need to still build full listings.\n\nThis patch makes this fill_gaps code work for all gaps in a returning\nlisting, if the own_sr is in a LISTING state, ie SHARDING, CLEAVED,\nACTIVE, SHRINKING. This way if a shard is collapsed back to the root\nbefore any others, the root will already respond to listing for it.\n\nChange-Id: I3a5e05b91b29247eeb52ee88bb0a822f45f0523c\n'}]",1,774195,8c5dfd49ff00c87a80346d982d0722e26d85bd90,4,1,1,7233,,,0,"Make fill_gaps fill all gaps with own_SR

There is a bug where we could mark everything to collapse back into the root
container and until all sharder have run any shrinking shard that runs
before the rest will collapse and cause a momentary hole in the object
listing for the sharded container.

We currently have code in get_shard_ranges that when listing will
fill_gaps with the root SR to plug holes. This is used when we are in
the sharding state and we need to still build full listings.

This patch makes this fill_gaps code work for all gaps in a returning
listing, if the own_sr is in a LISTING state, ie SHARDING, CLEAVED,
ACTIVE, SHRINKING. This way if a shard is collapsed back to the root
before any others, the root will already respond to listing for it.

Change-Id: I3a5e05b91b29247eeb52ee88bb0a822f45f0523c
",git fetch https://review.opendev.org/openstack/swift refs/changes/95/774195/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/probe/test_sharder.py', 'test/unit/container/test_server.py', 'swift/container/sharder.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py', 'test/unit/common/test_utils.py']",7,8c5dfd49ff00c87a80346d982d0722e26d85bd90,fill_all_gaps," def test_find_missing_ranges(self): def do_test(bounds, expected, minimum=None, maximum=None): if not minimum: minimum = utils.ShardRange.MIN if not maximum: maximum = utils.ShardRange.MAX shard_ranges = [utils.ShardRange('a/c', next(self.ts_iter), lower, upper) for lower, upper in bounds] missing_bounds = utils.find_missing_ranges( shard_ranges, minimum, maximum) self.assertEqual(missing_bounds, expected) shard_bounds = [(utils.ShardRange.MIN, 'd'), ('d', 'i'), ('i', 'o'), ('o', 'x'), ('x', utils.ShardRange.MAX)] for i in range(len(shard_bounds)): tmp_bounds = list(shard_bounds) expected = tmp_bounds.pop(i) do_test(tmp_bounds, [expected]) # now do more targeted tests expected = [] tmp_bounds = list(shard_bounds) expected.append(tmp_bounds.pop(0)) expected.append(tmp_bounds.pop(-1)) do_test(tmp_bounds, expected) expected = [] tmp_bounds = list(shard_bounds) expected.append(tmp_bounds.pop(1)) expected.append(tmp_bounds.pop(2)) do_test(tmp_bounds, expected) expected = [] tmp_bounds = list(shard_bounds) expected.append(tmp_bounds.pop(1)) expected.append(tmp_bounds.pop(3)) do_test(tmp_bounds, expected) expected = [('x', 'y')] tmp_bounds = list(shard_bounds) tmp_bounds.pop(-1) do_test(tmp_bounds, expected, maximum='y') expected = [('c', 'd')] tmp_bounds = list(shard_bounds) tmp_bounds.pop(0) do_test(tmp_bounds, expected, minimum='c') do_test(shard_bounds, [], minimum='m', maximum='c') do_test(shard_bounds, [], minimum='m', maximum='m') ",,182,35
openstack%2Fmagnum~master~I9b3ca7cd63a2eceef1a0a2bd54cd9b9f550285b0,openstack/magnum,master,I9b3ca7cd63a2eceef1a0a2bd54cd9b9f550285b0,Add image prefix for grafana images,MERGED,2020-11-25 00:42:55.000000000,2021-02-05 15:21:57.000000000,2021-02-05 15:20:23.000000000,"[{'_account_id': 1004}, {'_account_id': 6484}, {'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-11-25 00:42:55.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/327c12fc8400c6cb6e29230f81a1735ba5f6d45b', 'message': 'Add image prefix for grafana images\n\n- grafana image\n- k8s-sidecar image\n\nChange-Id: I9b3ca7cd63a2eceef1a0a2bd54cd9b9f550285b0\n'}]",1,764105,327c12fc8400c6cb6e29230f81a1735ba5f6d45b,16,5,1,31746,,,0,"Add image prefix for grafana images

- grafana image
- k8s-sidecar image

Change-Id: I9b3ca7cd63a2eceef1a0a2bd54cd9b9f550285b0
",git fetch https://review.opendev.org/openstack/magnum refs/changes/05/764105/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh'],1,327c12fc8400c6cb6e29230f81a1735ba5f6d45b,, image: repository: ${CONTAINER_INFRA_PREFIX:-grafana/}grafana sidecar: image: ${CONTAINER_INFRA_PREFIX:-kiwigrid/}k8s-sidecar:0.1.99,,4,1
openstack%2Fopenstack-ansible~master~I464799a1c2e488ea6e7ca9f4d38b3e93ddb30e87,openstack/openstack-ansible,master,I464799a1c2e488ea6e7ca9f4d38b3e93ddb30e87,Conform cinder management address to pattern used for nova,ABANDONED,2020-07-15 13:05:27.000000000,2021-02-05 14:56:35.000000000,,"[{'_account_id': 22348}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-07-15 13:05:27.000000000', 'files': ['inventory/group_vars/cinder_all.yml', 'playbooks/common-playbooks/cinder.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/16f59a2566e4b7e15b377360e8424cef7d81e545', 'message': 'Conform cinder management address to pattern used for nova\n\nThis ensures that the correct address is used when cinder is\ndeployed to a physical host which uses different networks for\ndeployment and management\n\nChange-Id: I464799a1c2e488ea6e7ca9f4d38b3e93ddb30e87\n'}]",0,741180,16f59a2566e4b7e15b377360e8424cef7d81e545,6,2,1,31542,,,0,"Conform cinder management address to pattern used for nova

This ensures that the correct address is used when cinder is
deployed to a physical host which uses different networks for
deployment and management

Change-Id: I464799a1c2e488ea6e7ca9f4d38b3e93ddb30e87
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/80/741180/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/cinder_all.yml', 'playbooks/common-playbooks/cinder.yml']",2,16f59a2566e4b7e15b377360e8424cef7d81e545,cinder-mgmt-address," - name: Determine management bridge IP address include_tasks: ../common-tasks/dynamic-address-fact.yml vars: network_address: ""container_address"" tags: - always cinder_management_address: ""{{ container_address }}""",,8,3
openstack%2Fopenstack-ansible-lxc_container_create~master~I55b928bc21232f70f37c9c7a9f8e2d60c9fcb5b5,openstack/openstack-ansible-lxc_container_create,master,I55b928bc21232f70f37c9c7a9f8e2d60c9fcb5b5,Avoid delegation to the target container,ABANDONED,2021-02-02 14:25:24.000000000,2021-02-05 14:56:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-02-02 14:25:24.000000000', 'files': ['tasks/lxc_container_config.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/695e8dc8ecb457452a2ad961684975539948a540', 'message': 'Avoid delegation to the target container\n\nThis task creates a matching named directory in both the container\nand on its physical host. Up to now this has been done with a loop\nwith delegation to the physical host and then to the container via\ninventory_hostname.\n\nIt appears that https://github.com/ansible/ansible/issues/72776\nmay be causing the inventory hostname to be only partially\nresolved, resulting in the SSH command targeting the physical host\nby hostname rather than by IP address.\n\nThis patch splits the task to avoid delegating to the same host\nwhich is being targeted initially by the task.\n\nChange-Id: I55b928bc21232f70f37c9c7a9f8e2d60c9fcb5b5\n'}]",0,773690,695e8dc8ecb457452a2ad961684975539948a540,4,2,1,31542,,,0,"Avoid delegation to the target container

This task creates a matching named directory in both the container
and on its physical host. Up to now this has been done with a loop
with delegation to the physical host and then to the container via
inventory_hostname.

It appears that https://github.com/ansible/ansible/issues/72776
may be causing the inventory hostname to be only partially
resolved, resulting in the SSH command targeting the physical host
by hostname rather than by IP address.

This patch splits the task to avoid delegating to the same host
which is being targeted initially by the task.

Change-Id: I55b928bc21232f70f37c9c7a9f8e2d60c9fcb5b5
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/90/773690/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_container_config.yml'],1,695e8dc8ecb457452a2ad961684975539948a540,," - name: Ensure journal directory exists in container - name: Ensure journal directory exists on physical host file: path: ""{{ lxc_container_journal_path }}"" state: ""directory"" group: ""systemd-journal"" owner: ""root"" mode: ""02755"" delegate_to: ""{{ physical_host }}"""," - name: Ensure journal directory exists delegate_to: ""{{ item }}"" with_items: - ""{{ physical_host }}"" - ""{{ inventory_hostname }}""",10,5
openstack%2Fdevstack~master~I2b108be7386971cc02577d61a97a51bcb388951a,openstack/devstack,master,I2b108be7386971cc02577d61a97a51bcb388951a,DNM: Test just on vexxhost,ABANDONED,2021-02-02 15:47:57.000000000,2021-02-05 14:43:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-02-02 15:47:57.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/eebac2a80c040ea3607e9f397a49b2ea8e28c277', 'message': 'DNM: Test just on vexxhost\n\nChange-Id: I2b108be7386971cc02577d61a97a51bcb388951a\n'}]",1,773714,eebac2a80c040ea3607e9f397a49b2ea8e28c277,3,1,1,4393,,,0,"DNM: Test just on vexxhost

Change-Id: I2b108be7386971cc02577d61a97a51bcb388951a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/14/773714/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,eebac2a80c040ea3607e9f397a49b2ea8e28c277,async, name: vexx-bionic nodes: - name: ubuntu-bionic label: ubuntu-bionic-vexxhost - nodeset: name: devstack-platform-centos8-async nodeset: vexx-centos8 vars: devstack_localrc: DEVSTACK_PARALLEL: True nodeset: vexx-bionic - devstack-platform-centos8-async,"- job: name: devstack-base parent: multinode abstract: true description: | Base abstract Devstack job. Defines plays and base variables, but it does not include any project and it does not run any service by default. This is a common base for all single Devstack jobs, single or multinode. Variables are defined in job.vars, which is what is then used by single node jobs and by multi node jobs for the controller, as well as in job.group-vars.peers, which is what is used by multi node jobs for subnode nodes (everything but the controller). required-projects: - opendev.org/openstack/devstack roles: - zuul: opendev.org/openstack/devstack-gate - zuul: opendev.org/openstack/openstack-zuul-jobs vars: devstack_localrc: DATABASE_PASSWORD: secretdatabase RABBIT_PASSWORD: secretrabbit ADMIN_PASSWORD: secretadmin SERVICE_PASSWORD: secretservice NETWORK_GATEWAY: 10.1.0.1 FIXED_RANGE: 10.1.0.0/20 IPV4_ADDRS_SAFE_TO_USE: 10.1.0.0/20 FLOATING_RANGE: 172.24.5.0/24 PUBLIC_NETWORK_GATEWAY: 172.24.5.1 LOGFILE: /opt/stack/logs/devstacklog.txt LOG_COLOR: false VERBOSE: true VERBOSE_NO_TIMESTAMP: true NOVNC_FROM_PACKAGE: true ERROR_ON_CLONE: true # Gate jobs can't deal with nested virt. Disable it by default. LIBVIRT_TYPE: '{{ devstack_libvirt_type | default(""qemu"") }}' devstack_services: # Ignore any default set by devstack. Emit a ""disable_all_services"". base: false zuul_copy_output: '{{ devstack_conf_dir }}/local.conf': logs '{{ devstack_conf_dir }}/localrc': logs '{{ devstack_conf_dir }}/.localrc.auto': logs '{{ devstack_conf_dir }}/.stackenv': logs '{{ devstack_log_dir }}/dstat-csv.log': logs '{{ devstack_log_dir }}/devstacklog.txt': logs '{{ devstack_log_dir }}/devstacklog.txt.summary': logs '{{ devstack_log_dir }}/tcpdump.pcap': logs '{{ devstack_log_dir }}/worlddump-latest.txt': logs '{{ devstack_full_log}}': logs '{{ stage_dir }}/verify_tempest_conf.log': logs '{{ stage_dir }}/apache': logs '{{ stage_dir }}/apache_config': logs '{{ stage_dir }}/etc': logs /var/log/rabbitmq: logs /var/log/postgresql: logs /var/log/mysql: logs /var/log/libvirt: logs /etc/sudoers: logs /etc/sudoers.d: logs '{{ stage_dir }}/iptables.txt': logs '{{ stage_dir }}/df.txt': logs '{{ stage_dir }}/pip2-freeze.txt': logs '{{ stage_dir }}/pip3-freeze.txt': logs '{{ stage_dir }}/dpkg-l.txt': logs '{{ stage_dir }}/rpm-qa.txt': logs '{{ stage_dir }}/core': logs '{{ stage_dir }}/listen53.txt': logs '{{ stage_dir }}/deprecations.log': logs '{{ stage_dir }}/audit.log': logs /etc/ceph: logs /var/log/ceph: logs /var/log/openvswitch: logs /var/log/glusterfs: logs /etc/glusterfs/glusterd.vol: logs /etc/resolv.conf: logs /var/log/unbound.log: logs extensions_to_txt: conf: true log: true localrc: true stackenv: true auto: true group-vars: subnode: devstack_localrc: DATABASE_PASSWORD: secretdatabase RABBIT_PASSWORD: secretrabbit ADMIN_PASSWORD: secretadmin SERVICE_PASSWORD: secretservice NETWORK_GATEWAY: 10.1.0.1 FIXED_RANGE: 10.1.0.0/20 IPV4_ADDRS_SAFE_TO_USE: 10.1.0.0/20 FLOATING_RANGE: 172.24.5.0/24 PUBLIC_NETWORK_GATEWAY: 172.24.5.1 LOGFILE: /opt/stack/logs/devstacklog.txt LOG_COLOR: false VERBOSE: true VERBOSE_NO_TIMESTAMP: true NOVNC_FROM_PACKAGE: true ERROR_ON_CLONE: true LIBVIRT_TYPE: qemu devstack_services: base: false pre-run: playbooks/pre.yaml run: playbooks/devstack.yaml post-run: playbooks/post.yaml irrelevant-files: # Documentation related - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^releasenotes/.*$ # Translations - ^.*/locale/.*po$ - job: name: devstack-minimal parent: devstack-base description: | Minimal devstack base job, intended for use by jobs that need less than the normal minimum set of required-projects. nodeset: openstack-single-node-focal required-projects: - opendev.org/openstack/requirements vars: devstack_localrc: # Multinode specific settings SERVICE_HOST: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" HOST_IP: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" PUBLIC_BRIDGE_MTU: '{{ external_bridge_mtu }}' devstack_services: # Shared services dstat: true etcd3: true memory_tracker: true mysql: true rabbit: true group-vars: subnode: devstack_services: # Shared services dstat: true memory_tracker: true devstack_localrc: # Multinode specific settings HOST_IP: ""{{ hostvars[inventory_hostname]['nodepool']['private_ipv4'] }}"" SERVICE_HOST: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" PUBLIC_BRIDGE_MTU: '{{ external_bridge_mtu }}' # Subnode specific settings DATABASE_TYPE: mysql RABBIT_HOST: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" DATABASE_HOST: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" - job: name: devstack parent: devstack-minimal description: | Base devstack job for integration gate. This base job can be used for single node and multinode devstack jobs. With a single node nodeset, this job sets up an ""all-in-one"" (aio) devstack with the seven OpenStack services included in the devstack tree: keystone, glance, cinder, neutron, nova, placement, and swift. With a two node nodeset, this job sets up an aio + compute node. The controller can be customised using host-vars.controller, the sub-nodes can be customised using group-vars.subnode. Descendent jobs can enable / disable services, add devstack configuration options, enable devstack plugins, configure log files or directories to be transferred to the log server. The job assumes that there is only one controller node. The number of subnodes can be scaled up seamlessly by setting a custom nodeset in job.nodeset. The run playbook consists of a single role, so it can be easily rewritten and extended. required-projects: - opendev.org/openstack/cinder - opendev.org/openstack/glance - opendev.org/openstack/keystone - opendev.org/openstack/neutron - opendev.org/openstack/nova - opendev.org/openstack/placement - opendev.org/openstack/swift timeout: 7200 vars: devstack_localrc: # Common OpenStack services settings SWIFT_REPLICAS: 1 SWIFT_START_ALL_SERVICES: false SWIFT_HASH: 1234123412341234 DEBUG_LIBVIRT_COREDUMPS: true NOVA_VNC_ENABLED: true devstack_local_conf: post-config: $NEUTRON_CONF: DEFAULT: global_physnet_mtu: '{{ external_bridge_mtu }}' devstack_services: # Core services enabled for this branch. # This list replaces the test-matrix. # Shared services dstat: true etcd3: true memory_tracker: true mysql: true rabbit: true tls-proxy: true # Keystone services key: true # Glance services g-api: true # Nova services n-api: true n-api-meta: true n-cond: true n-cpu: true n-novnc: true n-sch: true # Placement service placement-api: true # Neutron services q-agt: true q-dhcp: true q-l3: true q-meta: true q-metering: true q-svc: true # Swift services s-account: true s-container: true s-object: true s-proxy: true # Cinder services c-api: true c-bak: true c-sch: true c-vol: true cinder: true # Services we don't need. # This section is not really needed, it's for readability. horizon: false tempest: false # Test matrix emits ceilometer but ceilomenter is not installed in the # integrated gate, so specifying the services has not effect. # ceilometer-*: false group-vars: subnode: devstack_services: # Core services enabled for this branch. # This list replaces the test-matrix. # Shared services dstat: true memory_tracker: true tls-proxy: true # Nova services n-cpu: true # Placement services placement-client: true # Neutron services q-agt: true # Cinder services c-bak: true c-vol: true # Services we don't run at all on subnode. # This section is not really needed, it's for readability. # keystone: false # s-*: false horizon: false tempest: false # Test matrix emits ceilometer but ceilometer is not installed in the # integrated gate, so specifying the services has not effect. # ceilometer-*: false devstack_localrc: # Subnode specific settings GLANCE_HOSTPORT: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}:9292"" Q_HOST: ""{{ hostvars['controller']['nodepool']['private_ipv4'] }}"" NOVA_VNC_ENABLED: true - job: name: devstack-ipv6 parent: devstack description: | Devstack single node job for integration gate with IPv6. vars: devstack_localrc: SERVICE_IP_VERSION: 6 SERVICE_HOST: """" - job: name: devstack-multinode parent: devstack nodeset: openstack-two-node-focal description: | Simple multinode test to verify multinode functionality on devstack side. This is not meant to be used as a parent job. name: devstack-platform-centos-8 nodeset: devstack-single-node-centos-8 - job: name: devstack-platform-opensuse-15 parent: tempest-full-py3 description: openSUSE 15.x platform test nodeset: devstack-single-node-opensuse-15 voting: false - job: name: devstack-platform-bionic parent: tempest-full-py3 description: Ubuntu Bionic platform test nodeset: openstack-single-node-bionic voting: false- job: name: devstack-platform-fedora-latest parent: tempest-full-py3 description: Fedora latest platform test nodeset: devstack-single-node-fedora-latest voting: false - job: name: devstack-platform-fedora-latest-virt-preview parent: tempest-full-py3 description: Fedora latest platform test using the virt-preview repo. nodeset: devstack-single-node-fedora-latest voting: false vars: devstack_localrc: ENABLE_FEDORA_VIRT_PREVIEW_REPO: true - job: name: devstack-tox-base parent: devstack description: | Base job for devstack-based functional tests that use tox. This job is not intended to be run directly. It's just here for organizational purposes for devstack-tox-functional and devstack-tox-functional-consumer. post-run: playbooks/tox/post.yaml vars: tox_envlist: functional tox_install_siblings: false - job: name: devstack-tox-functional parent: devstack-tox-base description: | Base job for devstack-based functional tests that use tox. Runs devstack, then runs the tox ``functional`` environment, then collects tox/testr build output like normal tox jobs. Turns off tox sibling installation. Projects may be involved in the devstack deployment and so may be in the required-projects list, but may not want to test against master of the other projects in their tox env. Child jobs can set tox_install_siblings to True to re-enable sibling processing. run: playbooks/tox/run-both.yaml - job: name: devstack-tox-functional-consumer parent: devstack description: | Base job for devstack-based functional tests for projects that consume the devstack cloud. This base job should only be used by projects that are not involved in the devstack deployment step, but are instead projects that are using devstack to get a cloud against which they can test things. Runs devstack in pre-run, then runs the tox ``functional`` environment, then collects tox/testr build output like normal tox jobs. Turns off tox sibling installation. Projects may be involved in the devstack deployment and so may be in the required-projects list, but may not want to test against master of the other projects in their tox env. Child jobs can set tox_install_siblings to True to re-enable sibling processing. pre-run: - playbooks/devstack.yaml - playbooks/tox/pre.yaml run: playbooks/tox/run.yaml - job: name: devstack-unit-tests description: | Runs unit tests on devstack project. It runs ``run_tests.sh``. pre-run: playbooks/unit-tests/pre.yaml run: playbooks/unit-tests/run.yaml - devstack - devstack-ipv6 - devstack-platform-opensuse-15 - devstack-platform-fedora-latest - devstack-platform-centos-8 - devstack-platform-bionic - devstack-multinode - devstack-unit-tests - openstack-tox-bashate - devstack - devstack-ipv6 - devstack-multinode - devstack-unit-tests - openstack-tox-bashate",13,414
openstack%2Fpython-brick-cinderclient-ext~stable%2Ftrain~Ic8fbf3c3eb0eaa83b79f9a2a9b630734054314ee,openstack/python-brick-cinderclient-ext,stable/train,Ic8fbf3c3eb0eaa83b79f9a2a9b630734054314ee,Update requirements and lower-constraints,MERGED,2021-01-09 02:51:31.000000000,2021-02-05 14:42:33.000000000,2021-02-05 14:41:03.000000000,"[{'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-09 02:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/b8cd79c3a745207389db6512f1498989976c1e1a', 'message': 'Update requirements and lower-constraints\n\nchanges:\n- python-cinderclient 3.3.0 -> 5.0.0 (update to train client)\n- os-brick 2.5.0 -> 2.10.0 (update to train official release)\n\nChange-Id: Ic8fbf3c3eb0eaa83b79f9a2a9b630734054314ee\n'}, {'number': 2, 'created': '2021-01-15 14:53:46.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/8951feb3feed09ee687470e621adaac0dcd9e8e1', 'message': 'Update requirements and lower-constraints\n\nchanges:\n- python-cinderclient 3.3.0 -> 5.0.0 (update to train client)\n- os-brick 2.5.0 -> 2.10.0 (update to train official release)\n- raised Sphinx to 1.8.0 and added py2,py3 classifiers\n\nChange-Id: Ic8fbf3c3eb0eaa83b79f9a2a9b630734054314ee\n'}]",2,770012,8951feb3feed09ee687470e621adaac0dcd9e8e1,14,3,2,5314,,,0,"Update requirements and lower-constraints

changes:
- python-cinderclient 3.3.0 -> 5.0.0 (update to train client)
- os-brick 2.5.0 -> 2.10.0 (update to train official release)
- raised Sphinx to 1.8.0 and added py2,py3 classifiers

Change-Id: Ic8fbf3c3eb0eaa83b79f9a2a9b630734054314ee
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/12/770012/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,b8cd79c3a745207389db6512f1498989976c1e1a,update-l-c,os-brick==2.10.0python-cinderclient==5.0.0,os-brick==2.5.0python-cinderclient==3.3.0,4,5
openstack%2Fironic~master~I12b4bc0d4599ccf5ef6fdca91f54f4294b127f9d,openstack/ironic,master,I12b4bc0d4599ccf5ef6fdca91f54f4294b127f9d,ilo: do not change deploy_boot_mode in instance_info,MERGED,2021-02-02 10:41:32.000000000,2021-02-05 14:33:05.000000000,2021-02-05 14:30:27.000000000,"[{'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-02-02 10:41:32.000000000', 'files': ['ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/ilo/boot.py', 'ironic/tests/unit/drivers/modules/ilo/test_boot.py', 'ironic/tests/unit/drivers/modules/ilo/test_common.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6c8dad9465af138eb8c8c387af1f42e723310e26', 'message': 'ilo: do not change deploy_boot_mode in instance_info\n\ninstance_info is the input from an operator, we should not change that.\nUse driver_internal_info instead.\n\nChange-Id: I12b4bc0d4599ccf5ef6fdca91f54f4294b127f9d\n'}]",0,773631,6c8dad9465af138eb8c8c387af1f42e723310e26,28,3,1,10239,,,0,"ilo: do not change deploy_boot_mode in instance_info

instance_info is the input from an operator, we should not change that.
Use driver_internal_info instead.

Change-Id: I12b4bc0d4599ccf5ef6fdca91f54f4294b127f9d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/31/773631/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/ilo/boot.py', 'ironic/tests/unit/drivers/modules/ilo/test_boot.py', 'ironic/tests/unit/drivers/modules/ilo/test_common.py']",4,6c8dad9465af138eb8c8c387af1f42e723310e26,ilo-deploy-boot-mode," task.node.driver_internal_info['deploy_boot_mode'] = 'bios' self.assertEqual( 'bios', task.node.driver_internal_info['deploy_boot_mode']) self.assertEqual( 'bios', task.node.driver_internal_info['deploy_boot_mode']) self.assertEqual( 'uefi', task.node.driver_internal_info['deploy_boot_mode']) self.assertEqual( 'bios', task.node.driver_internal_info['deploy_boot_mode'])"," task.node.instance_info['deploy_boot_mode'] = 'bios' self.assertEqual('bios', task.node.instance_info['deploy_boot_mode']) self.assertEqual('bios', task.node.instance_info['deploy_boot_mode']) self.assertEqual('uefi', task.node.instance_info['deploy_boot_mode']) self.assertEqual('bios', task.node.instance_info['deploy_boot_mode'])",23,21
openstack%2Fgovernance~master~If4bdd357fea98df9ae7bb94889a5e75c68c9913f,openstack/governance,master,If4bdd357fea98df9ae7bb94889a5e75c68c9913f,Remove Karbor project team,MERGED,2020-12-15 00:21:15.000000000,2021-02-05 13:58:07.000000000,2021-02-04 16:01:47.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 2033}, {'_account_id': 4393}, {'_account_id': 7198}, {'_account_id': 8556}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-15 00:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/d5657dbc0d921d8867b0c472fa4df8f1b688eccd', 'message': 'Remove Karbor project team\n\nKarbor did not have any PTL candidates for the Wallaby\ncycle. As per its activities in Victoria cycle and no\nmaintainers, the TC decided to retire Karbor deliverables in\nthe Wallaby cycle. The retirement was announced on the ML[1].\n\nAs per retirement process this commit proposes to remove\nthe Karbor project from the official OpenStack projects.\n\nIf there are any maintainers who would like to continue the\ndevelopment of this projects then they can continue under\nopendev in x namespace or repropose it to OpenStack governance.\n\nThank you to all the contributors of Karbor for your hard work!\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nChange-Id: If4bdd357fea98df9ae7bb94889a5e75c68c9913f\n'}, {'number': 2, 'created': '2020-12-15 00:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/5c6b32faab7e16db8b273116a557298e42818ec9', 'message': 'Remove Karbor project team\n\nKarbor did not have any PTL candidates for the Wallaby\ncycle. As per its activities in Victoria cycle and no\nmaintainers, the TC decided to retire Karbor deliverables in\nthe Wallaby cycle. The retirement was announced on the ML[1].\n\nAs per retirement process this commit proposes to remove\nthe Karbor project from the official OpenStack projects.\n\nIf there are any maintainers who would like to continue the\ndevelopment of this projects then they can continue under\nopendev in x namespace or repropose it to OpenStack governance.\n\nThank you to all the contributors of Karbor for your hard work!\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nDepends-on: https://review.opendev.org/c/openstack/project-config/+/767030\n\nChange-Id: If4bdd357fea98df9ae7bb94889a5e75c68c9913f\n'}, {'number': 3, 'created': '2020-12-15 23:41:28.000000000', 'files': ['reference/legacy.yaml', 'reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/9945807de256f81347c6268f452ccf6824f8f2bc', 'message': 'Remove Karbor project team\n\nKarbor did not have any PTL candidates for the Wallaby\ncycle. As per its activities in Victoria cycle and no\nmaintainers, the TC decided to retire Karbor deliverables in\nthe Wallaby cycle. The retirement was announced on the ML[1].\n\nAs per retirement process this commit proposes to remove\nthe Karbor project from the official OpenStack projects.\n\nIf there are any maintainers who would like to continue the\ndevelopment of this projects then they can continue under\nopendev in x namespace or repropose it to OpenStack governance.\n\nThank you to all the contributors of Karbor for your hard work!\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nDepends-on: https://review.opendev.org/c/openstack/project-config/+/767057\n\nChange-Id: If4bdd357fea98df9ae7bb94889a5e75c68c9913f\n'}]",4,767056,9945807de256f81347c6268f452ccf6824f8f2bc,30,8,3,16708,,,0,"Remove Karbor project team

Karbor did not have any PTL candidates for the Wallaby
cycle. As per its activities in Victoria cycle and no
maintainers, the TC decided to retire Karbor deliverables in
the Wallaby cycle. The retirement was announced on the ML[1].

As per retirement process this commit proposes to remove
the Karbor project from the official OpenStack projects.

If there are any maintainers who would like to continue the
development of this projects then they can continue under
opendev in x namespace or repropose it to OpenStack governance.

Thank you to all the contributors of Karbor for your hard work!

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html

Depends-on: https://review.opendev.org/c/openstack/project-config/+/767057

Change-Id: If4bdd357fea98df9ae7bb94889a5e75c68c9913f
",git fetch https://review.opendev.org/openstack/governance refs/changes/56/767056/1 && git format-patch -1 --stdout FETCH_HEAD,"['reference/legacy.yaml', 'reference/projects.yaml']",2,d5657dbc0d921d8867b0c472fa4df8f1b688eccd,project-update,,karbor: ptl: name: APPOINTMENT NEEDED irc: No nick supplied email: example@example.org irc-channel: openstack-karbor service: Data Protection Orchestration service mission: > To implement services and libraries to provide project aware data-protection orchestration of existing vendor solutions. url: https://wiki.openstack.org/wiki/Karbor deliverables: karbor: repos: - openstack/karbor karbor-dashboard: repos: - openstack/karbor-dashboard python-karborclient: repos: - openstack/python-karborclient liaisons: tc_members: - diablo_rojo - knikolla,20,26
openstack%2Fpuppet-openstack-integration~master~Icb07742d328827a41132cdd6a6c2bcfa3cde11ec,openstack/puppet-openstack-integration,master,Icb07742d328827a41132cdd6a6c2bcfa3cde11ec,Retry sealert command on failure,MERGED,2021-02-04 15:32:39.000000000,2021-02-05 13:35:10.000000000,2021-02-05 13:35:10.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 15:32:39.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/425f454bdcb264eb80b305b67a5d4bcd4e04aadb', 'message': 'Retry sealert command on failure\n\nWe randomly see issues while running sealert\nin RDO puppet promotion pipeline, sealert fails with:-\n""SELinux is disabled or we can\'t open a policy file""\nAs per logs selinux is enabled and selinuxfs is mounted\nso seems it\'s some filesystem issue.\n\nLocally was able to reproduce only with selinux disabled\nor umount /sys/fs/selinux. Adding retries in hope to\nfix these random failures.\n\nChange-Id: Icb07742d328827a41132cdd6a6c2bcfa3cde11ec\n'}]",0,774093,425f454bdcb264eb80b305b67a5d4bcd4e04aadb,7,5,1,13861,,,0,"Retry sealert command on failure

We randomly see issues while running sealert
in RDO puppet promotion pipeline, sealert fails with:-
""SELinux is disabled or we can't open a policy file""
As per logs selinux is enabled and selinuxfs is mounted
so seems it's some filesystem issue.

Locally was able to reproduce only with selinux disabled
or umount /sys/fs/selinux. Adding retries in hope to
fix these random failures.

Change-Id: Icb07742d328827a41132cdd6a6c2bcfa3cde11ec
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/93/774093/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,425f454bdcb264eb80b305b67a5d4bcd4e04aadb,," sealert_cmd=""$SUDO sealert -a /var/log/audit/audit.log"" retry_cmd ""$sealert_cmd""", $SUDO sealert -a /var/log/audit/audit.log,2,1
openstack%2Fpuppet-openstack-integration~master~Ia33ff3dbb88317171143a43e5b1c674038187254,openstack/puppet-openstack-integration,master,Ia33ff3dbb88317171143a43e5b1c674038187254,Improve retry_cmd function to handle set -e,MERGED,2021-02-05 08:37:19.000000000,2021-02-05 13:35:07.000000000,2021-02-05 13:35:07.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 08:37:19.000000000', 'files': ['functions'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/ec57a35931babc9698a8399ca5c76773f069e377', 'message': ""Improve retry_cmd function to handle set -e\n\nIn run_tests.sh we use 'set -e' which makes\nscript fail as soon as error hit but we don't\nwant to fail in case of retries, this patch fixes it.\n\nChange-Id: Ia33ff3dbb88317171143a43e5b1c674038187254\n""}]",0,774204,ec57a35931babc9698a8399ca5c76773f069e377,7,5,1,13861,,,0,"Improve retry_cmd function to handle set -e

In run_tests.sh we use 'set -e' which makes
script fail as soon as error hit but we don't
want to fail in case of retries, this patch fixes it.

Change-Id: Ia33ff3dbb88317171143a43e5b1c674038187254
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/04/774204/1 && git format-patch -1 --stdout FETCH_HEAD,['functions'],1,ec57a35931babc9698a8399ca5c76773f069e377,test-rdo-repo-updates," set +e set -e if [ ${ret_code} -ne 0 ]; then echo Failed even after ${total_tries} retries, Exiting exit ${ret_code} fi",,6,0
openstack%2Freleases~master~I26feae1e85ce2f6dae499441d3984ac3094170a5,openstack/releases,master,I26feae1e85ce2f6dae499441d3984ac3094170a5,Release panko for stable/train,MERGED,2021-01-29 14:46:18.000000000,2021-02-05 13:24:46.000000000,2021-02-05 13:24:46.000000000,"[{'_account_id': 308}, {'_account_id': 4264}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-01-29 14:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3daa375e05a4d7319481c76d47c4bf99a21f311c', 'message': 'Release panko for stable/train\n\nThis release picks up new commits to panko since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I26feae1e85ce2f6dae499441d3984ac3094170a5\n'}, {'number': 2, 'created': '2021-02-01 17:41:07.000000000', 'files': ['deliverables/train/panko.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a9a56c080c6be596cb7e9a167d4d7cbe5d2af8c6', 'message': 'Release panko for stable/train\n\nThis release picks up new commits to panko since\nthe last release from stable/train.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a  stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\nSigned-off-by: Elod Illes <elod.illes@est.tech>\nChange-Id: I26feae1e85ce2f6dae499441d3984ac3094170a5\n'}]",0,773085,a9a56c080c6be596cb7e9a167d4d7cbe5d2af8c6,18,4,2,17685,,,0,"Release panko for stable/train

This release picks up new commits to panko since
the last release from stable/train.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a  stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

Signed-off-by: Elod Illes <elod.illes@est.tech>
Change-Id: I26feae1e85ce2f6dae499441d3984ac3094170a5
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/773085/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/panko.yaml'],1,3daa375e05a4d7319481c76d47c4bf99a21f311c,train-stable, - version: 7.0.1 projects: - repo: openstack/panko hash: d2ba20f241ec0fdc8f31462dbe3646117e91f736,,4,0
openstack%2Fkuryr-kubernetes~master~Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba,openstack/kuryr-kubernetes,master,Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba,Update documentation for svc and ep annotation to KuryrLoadBalancer,MERGED,2020-12-02 19:35:36.000000000,2021-02-05 12:41:26.000000000,2021-02-05 12:39:30.000000000,"[{'_account_id': 11600}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-12-02 19:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/072af5de3aac87cfa431e6802f5c186d0a34ff0c', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 2, 'created': '2020-12-21 16:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/706ab0d9ce10574723ee2db5a281e6b6ba8fb5f3', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 3, 'created': '2021-01-22 16:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8e6a3a65061782c7e6db30bf6ba03a160bc8e693', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 4, 'created': '2021-02-03 16:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c5769b3b99653bcf9c2002dd26a7b56bdff1df2c', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 5, 'created': '2021-02-03 17:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/197427cbe1579833766dece04d18054c85d92e55', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 6, 'created': '2021-02-03 19:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f4085caf8cd0872ebfba0a02aab22723c0073873', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 7, 'created': '2021-02-03 19:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/537999d6e4b9fbe5f418a7954e42f351bde1312a', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 8, 'created': '2021-02-03 19:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9385bd9e491b5aa7c19a560ab603a7ae04c17209', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 9, 'created': '2021-02-04 17:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/3561d360b72777a435c242b2244290a9723804d9', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 10, 'created': '2021-02-05 11:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c1fbff01415ccddc2130528e05faca69ad6a1aef', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}, {'number': 11, 'created': '2021-02-05 12:01:53.000000000', 'files': ['doc/source/installation/testing_connectivity.rst', 'doc/source/devref/kuryr_kubernetes_design.rst', 'doc/source/devref/service_support.rst'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1d8afc722d1839ee91c65fa2c21df29402b689bf', 'message': 'Update documentation for svc and ep annotation to KuryrLoadBalancer\n\nChange-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba\n'}]",38,765197,1d8afc722d1839ee91c65fa2c21df29402b689bf,40,4,11,30963,,,0,"Update documentation for svc and ep annotation to KuryrLoadBalancer

Change-Id: Ia4c60d4bb8f3e4c232ef0d83d32f9e0bba3815ba
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/97/765197/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/kuryr_kubernetes_design.rst', 'doc/source/devref/service_support.rst']",2,072af5de3aac87cfa431e6802f5c186d0a34ff0c,Docume_crd,"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Three Kubernetes Event Handlers are added to the Controller pipeline. - ServiceHandler manages KubernetesService creation and modification events. Based on the service spec and metadata details, it creates KuryrLoadBalancer CRD or it updates the CRD, more specifically the spec part of the CRD with details to be used for translation to LBaaSv2 model, such as tenant-id, subnet-id, ip address and security groups. - EndpointsHandler is responsible for adding endpoints subsets to the CRD. If endpoint is created as first, this handle is responsible for creation of KuryrLoadBalancer CRD. - KuryrLoadBalancerHandler manages Kubernetes endpoints events, after KuryrLoadBalancer CRD is successfully created and filled with spec datas. LoadBalancer, LoadBalancerListener, LoadBalancerPool and LoadBalancerPool members to reflect and keep in sync with the Kubernetes service. The KuryrLoadBalancer CRD, status part, is updated with the Kubernetes Endpoints object which keeps details of Neutron resources. These Handlers use Project, Subnet and SecurityGroup service drivers to get","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Two Kubernetes Event Handlers are added to the Controller pipeline. - LBaaSSpecHandler manages Kubernetes Service creation and modification events. Based on the service spec and metadata details, it annotates the service endpoints entity with details to be used for translation to LBaaSv2 model, such as tenant-id, subnet-id, ip address and security groups. The rationale for setting annotation both on Service and Endpoints resources is to avoid concurrency issues, by delegating all Service translation operations to Endpoints (LoadBalancer) handler. To avoid conflicting annotations, K8s Services's resourceVersion is used for Service and Endpoints while handling Services events. - LoadBalancerHandler manages Kubernetes endpoints events. It manages LoadBalancer, LoadBalancerListener, LoadBalancerPool and LoadBalancerPool members to reflect and keep in sync with the Kubernetes service. It keeps details of Neutron resources by annotating the Kubernetes Endpoints object. Both Handlers use Project, Subnet and SecurityGroup service drivers to get",28,27
openstack%2Fpuppet-nova~stable%2Ftrain~I468ecf06ac6e0853fbb296c011f20d63e38f6922,openstack/puppet-nova,stable/train,I468ecf06ac6e0853fbb296c011f20d63e38f6922,Fix libvirt version discovery for CentOS Stream,MERGED,2021-02-01 09:43:04.000000000,2021-02-05 12:38:48.000000000,2021-02-05 12:38:48.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 13861}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 31068}]","[{'number': 1, 'created': '2021-02-01 09:43:04.000000000', 'files': ['manifests/compute/libvirt/version.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c8507e9207a56d364aa2e62b29c57e60a6206e83', 'message': ""Fix libvirt version discovery for CentOS Stream\n\nCentOS Stream is Rolling-release distro that tracks just ahead of\nRed Hat Enterprise Linux (RHEL) development [1]. While not recommended\nin RDO, it's used to find potential issues before they are found in\nofficial CentOS 8.\n\nCentOS Stream is reported by facter as '8' with no minor version,\nbreaking the logic to discover the libvirtd version. This patch is\nsetting the version of libvirtd to 5.6 for all CdentOS 8 releases,\nincluding Stream, as 8.0 is no longer supported.\n\n[1] https://www.centos.org/centos-stream/\n\nChange-Id: I468ecf06ac6e0853fbb296c011f20d63e38f6922\n(cherry picked from commit b6294ce7a27379444ec9a447a51a6a1f83e9069f)\n""}]",0,773329,c8507e9207a56d364aa2e62b29c57e60a6206e83,9,6,1,16312,,,0,"Fix libvirt version discovery for CentOS Stream

CentOS Stream is Rolling-release distro that tracks just ahead of
Red Hat Enterprise Linux (RHEL) development [1]. While not recommended
in RDO, it's used to find potential issues before they are found in
official CentOS 8.

CentOS Stream is reported by facter as '8' with no minor version,
breaking the logic to discover the libvirtd version. This patch is
setting the version of libvirtd to 5.6 for all CdentOS 8 releases,
including Stream, as 8.0 is no longer supported.

[1] https://www.centos.org/centos-stream/

Change-Id: I468ecf06ac6e0853fbb296c011f20d63e38f6922
(cherry picked from commit b6294ce7a27379444ec9a447a51a6a1f83e9069f)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/29/773329/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/compute/libvirt/version.pp'],1,c8507e9207a56d364aa2e62b29c57e60a6206e83,c8s," if versioncmp($facts['os']['release']['full'], '8') >= 0 {"," if versioncmp($facts['os']['release']['full'], '8.1') >= 0 {",1,1
openstack%2Fpuppet-nova~stable%2Fussuri~I468ecf06ac6e0853fbb296c011f20d63e38f6922,openstack/puppet-nova,stable/ussuri,I468ecf06ac6e0853fbb296c011f20d63e38f6922,Fix libvirt version discovery for CentOS Stream,MERGED,2021-02-01 09:42:41.000000000,2021-02-05 12:38:45.000000000,2021-02-05 12:38:45.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 13861}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 31068}]","[{'number': 1, 'created': '2021-02-01 09:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1f29b7fbb07a4b7c48ef1db9c4e0dba77fa716ee', 'message': ""Fix libvirt version discovery for CentOS Stream\n\nCentOS Stream is Rolling-release distro that tracks just ahead of\nRed Hat Enterprise Linux (RHEL) development [1]. While not recommended\nin RDO, it's used to find potential issues before they are found in\nofficial CentOS 8.\n\nCentOS Stream is reported by facter as '8' with no minor version,\nbreaking the logic to discover the libvirtd version. This patch is\nsetting the version of libvirtd to 5.6 for all CdentOS 8 releases,\nincluding Stream, as 8.0 is no longer supported.\n\n[1] https://www.centos.org/centos-stream/\n\nChange-Id: I468ecf06ac6e0853fbb296c011f20d63e38f6922\n(cherry picked from commit b6294ce7a27379444ec9a447a51a6a1f83e9069f)\n""}, {'number': 2, 'created': '2021-02-01 16:08:23.000000000', 'files': ['spec/classes/nova_compute_libvirt_spec.rb', 'manifests/compute/libvirt/version.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6397e5c2260ac960aa9d219d76bc2fd55446d7c0', 'message': ""Fix libvirt version discovery for CentOS Stream\n\nCentOS Stream is Rolling-release distro that tracks just ahead of\nRed Hat Enterprise Linux (RHEL) development [1]. While not recommended\nin RDO, it's used to find potential issues before they are found in\nofficial CentOS 8.\n\nCentOS Stream is reported by facter as '8' with no minor version,\nbreaking the logic to discover the libvirtd version. This patch is\nsetting the version of libvirtd to 5.6 for all CdentOS 8 releases,\nincluding Stream, as 8.0 is no longer supported.\n\n[1] https://www.centos.org/centos-stream/\n\n(cherry picked from commit b6294ce7a27379444ec9a447a51a6a1f83e9069f)\n\n(suash) Do not test nova::migration::libvirt in 2 places\n\nCurrently behavior of the nova::migration::libvirt class is tested in\nnova_migration_livirt_spec.rb, thus we don't need to test the same in\nnova_compute_libvirt_spec.rb.\n\nThis patch also remove a redundant test case.\n\n(cherry picked from commit 2b046eeec6e064c7189d13e699e92cce0ef386b9)\n\nChange-Id: I468ecf06ac6e0853fbb296c011f20d63e38f6922\n""}]",0,773328,6397e5c2260ac960aa9d219d76bc2fd55446d7c0,18,6,2,16312,,,0,"Fix libvirt version discovery for CentOS Stream

CentOS Stream is Rolling-release distro that tracks just ahead of
Red Hat Enterprise Linux (RHEL) development [1]. While not recommended
in RDO, it's used to find potential issues before they are found in
official CentOS 8.

CentOS Stream is reported by facter as '8' with no minor version,
breaking the logic to discover the libvirtd version. This patch is
setting the version of libvirtd to 5.6 for all CdentOS 8 releases,
including Stream, as 8.0 is no longer supported.

[1] https://www.centos.org/centos-stream/

(cherry picked from commit b6294ce7a27379444ec9a447a51a6a1f83e9069f)

(suash) Do not test nova::migration::libvirt in 2 places

Currently behavior of the nova::migration::libvirt class is tested in
nova_migration_livirt_spec.rb, thus we don't need to test the same in
nova_compute_libvirt_spec.rb.

This patch also remove a redundant test case.

(cherry picked from commit 2b046eeec6e064c7189d13e699e92cce0ef386b9)

Change-Id: I468ecf06ac6e0853fbb296c011f20d63e38f6922
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/28/773328/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/compute/libvirt/version.pp'],1,1f29b7fbb07a4b7c48ef1db9c4e0dba77fa716ee,c8s," if versioncmp($facts['os']['release']['full'], '8') >= 0 {"," if versioncmp($facts['os']['release']['full'], '8.1') >= 0 {",1,1
openstack%2Fopenstack-ansible-os_zun~stable%2Fussuri~Ie674947ba6673a92e53f85de2cc8acdae5788f8f,openstack/openstack-ansible-os_zun,stable/ussuri,Ie674947ba6673a92e53f85de2cc8acdae5788f8f,Update zun role to match current requirements,MERGED,2021-01-20 08:43:48.000000000,2021-02-05 12:26:19.000000000,2021-02-05 12:20:50.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-20 08:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/ef687afeb7700a055f4cf9ba2f21992abf4b46ff', 'message': 'Update zun role to match current requirements\n\nBrings together a set of existing patches and attempts to address\npermissions issues with the kuryr-libnetwork plugin.\n\nDefaults are chosen to match the requirements of the tempest tests\n\nChange-Id: Ie674947ba6673a92e53f85de2cc8acdae5788f8f\nDepends-On: https://review.opendev.org/767469\n(cherry picked from commit 6d6a4beb285d4ba4cc5d4896779dc4bb541ab5b4)\n'}, {'number': 2, 'created': '2021-01-20 08:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/fe9af8e096a7d57007aa1546fea2b38c25e71f23', 'message': 'Update zun role to match current requirements\n\nBrings together a set of existing patches and attempts to address\npermissions issues with the kuryr-libnetwork plugin.\n\nDefaults are chosen to match the requirements of the tempest tests\n\nChange-Id: Ie674947ba6673a92e53f85de2cc8acdae5788f8f\nDepends-On: https://review.opendev.org/767469\n(cherry picked from commit 6d6a4beb285d4ba4cc5d4896779dc4bb541ab5b4)\n'}, {'number': 3, 'created': '2021-01-28 21:16:20.000000000', 'files': ['templates/sudoers.j2', 'templates/zun.conf.j2', 'tasks/zun_pre_flight.yml', 'templates/rootwrap.conf.j2', 'tasks/zun_compute.yml', 'vars/redhat.yml', 'vars/debian.yml', 'zuul.d/project.yaml', 'tasks/zun_post_install.yml', 'defaults/main.yml', 'tasks/zun_pre_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/bc6079ebe96b39b376bd347170b01bb51b4f068f', 'message': 'Update zun role to match current requirements\n\nBrings together a set of existing patches and attempts to address\npermissions issues with the kuryr-libnetwork plugin.\n\nDefaults are chosen to match the requirements of the tempest tests\n\nChange-Id: Ie674947ba6673a92e53f85de2cc8acdae5788f8f\nDepends-On: https://review.opendev.org/767469\nDepends-On: https://review.opendev.org/771608\n(cherry picked from commit 6d6a4beb285d4ba4cc5d4896779dc4bb541ab5b4)\n'}]",0,771547,bc6079ebe96b39b376bd347170b01bb51b4f068f,25,3,3,28619,,,0,"Update zun role to match current requirements

Brings together a set of existing patches and attempts to address
permissions issues with the kuryr-libnetwork plugin.

Defaults are chosen to match the requirements of the tempest tests

Change-Id: Ie674947ba6673a92e53f85de2cc8acdae5788f8f
Depends-On: https://review.opendev.org/767469
Depends-On: https://review.opendev.org/771608
(cherry picked from commit 6d6a4beb285d4ba4cc5d4896779dc4bb541ab5b4)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/47/771547/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/sudoers.j2', 'templates/zun.conf.j2', 'tasks/zun_compute.yml', 'tasks/zun_pre_flight.yml', 'templates/rootwrap.conf.j2', 'vars/redhat.yml', 'vars/debian.yml', 'zuul.d/project.yaml', 'tasks/zun_post_install.yml', 'defaults/main.yml', 'tasks/zun_pre_install.yml']",11,ef687afeb7700a055f4cf9ba2f21992abf4b46ff,zun-permissions-stable/ussuri," - { path: ""{{ zun_system_home_folder }}/volumes"" }",,97,15
openstack%2Fcharm-designate-bind~stable%2F20.05~Ib1954ec01d78518da064b0912b91643c153d543e,openstack/charm-designate-bind,stable/20.05,Ib1954ec01d78518da064b0912b91643c153d543e,Update files used to seed new bind units,ABANDONED,2020-06-04 12:52:14.000000000,2021-02-05 11:18:45.000000000,,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-04 12:52:14.000000000', 'files': ['src/lib/charm/openstack/designate_bind.py', 'unit_tests/test_lib_charm_openstack_designate_bind.py'], 'web_link': 'https://opendev.org/openstack/charm-designate-bind/commit/e64fc638ed9eeabe5332cec4d8fc4670c9cff20a', 'message': 'Update files used to seed new bind units\n\nIt looks like the focal version of named is compiled with lmdb\nsupport where as the bionic version is not. This means that on\nFocal+ zone information is stored in a nzd file rather than\nnzf. This change ensure that nzd files are also used to seed new\nunits.\n\nChange-Id: Ib1954ec01d78518da064b0912b91643c153d543e\nCloses-Bug: #1881532\n(cherry picked from commit 02f667ac166dc8d6e1eeb8b0d130b6259abc01d2)\n'}]",0,733600,e64fc638ed9eeabe5332cec4d8fc4670c9cff20a,7,3,1,12549,,,0,"Update files used to seed new bind units

It looks like the focal version of named is compiled with lmdb
support where as the bionic version is not. This means that on
Focal+ zone information is stored in a nzd file rather than
nzf. This change ensure that nzd files are also used to seed new
units.

Change-Id: Ib1954ec01d78518da064b0912b91643c153d543e
Closes-Bug: #1881532
(cherry picked from commit 02f667ac166dc8d6e1eeb8b0d130b6259abc01d2)
",git fetch https://review.opendev.org/openstack/charm-designate-bind refs/changes/00/733600/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/designate_bind.py', 'unit_tests/test_lib_charm_openstack_designate_bind.py']",2,e64fc638ed9eeabe5332cec4d8fc4670c9cff20a,bug/1881532-stable/20.05," '/var/cache/bind/*nzf': ['nsffile'], '/var/cache/bind/*nzd': ['nsdfile']} 'nsffile', 'nsdfile'], cwd='/var/cache/bind')"," '/var/cache/bind/*nzf': ['nsffile']} 'nsffile'], cwd='/var/cache/bind')",4,3
openstack%2Ftripleo-heat-templates~master~I860e99af585aff6d1f5490930c364f091df81e56,openstack/tripleo-heat-templates,master,I860e99af585aff6d1f5490930c364f091df81e56,Disable swift on undercloud by default,MERGED,2021-01-29 03:16:00.000000000,2021-02-05 11:16:19.000000000,2021-02-05 11:16:19.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}, {'_account_id': 28223}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-01-29 03:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8f7f3841d8a376d7eca3bee05c7662d9bd0f98e1', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 2, 'created': '2021-01-29 08:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eea166b7d71f3660d514bc9242ae919be2cfe249', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 3, 'created': '2021-02-01 05:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aef8c4894129e852f06675c58a83236fe59c3ac8', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 4, 'created': '2021-02-01 14:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/20c85133787ac6a0500922215c36abccc611c98c', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nAlso changes ironic image_download_source and glance to not\nuse swift for deployments that still use nova for node\nprovisioning.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 5, 'created': '2021-02-02 02:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/11bf407e2a08adb3167e2ad8732ddc388f761069', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart/+/773560\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 6, 'created': '2021-02-02 08:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/83c7d855a9c7675900301adb5bb2428541eaffaf', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 7, 'created': '2021-02-03 02:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/19cd521e64efb5ed77e0f86da2f4f2e4d1c106fa', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}, {'number': 8, 'created': '2021-02-04 09:45:44.000000000', 'files': ['environments/undercloud.yaml', 'environments/undercloud-enable-swift.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b3f4111c9ebb6ebd572b734a46b1d58e2875bd55', 'message': 'Disable swift on undercloud by default\n\nThis changes to disable swift by default on the undercloud.\nAdds a new environment if there is a requirement to enable\nit.\n\nDepends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/\nChange-Id: I860e99af585aff6d1f5490930c364f091df81e56\n'}]",0,772967,b3f4111c9ebb6ebd572b734a46b1d58e2875bd55,52,8,8,8833,,,0,"Disable swift on undercloud by default

This changes to disable swift by default on the undercloud.
Adds a new environment if there is a requirement to enable
it.

Depends-On: https://review.opendev.org/c/openstack/python-tripleoclient/+/772827/
Change-Id: I860e99af585aff6d1f5490930c364f091df81e56
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/772967/8 && git format-patch -1 --stdout FETCH_HEAD,"['environments/undercloud.yaml', 'environments/undercloud-enable-swift.yaml']",2,8f7f3841d8a376d7eca3bee05c7662d9bd0f98e1,env_merging,parameter_defaults: SwiftCorsAllowedOrigin: '*' SwiftReplicas: 1 SwiftWorkers: 2 SwiftAccountWorkers: 2 SwiftContainerWorkers: 2 SwiftObjectWorkers: 2 resource_registry: OS::TripleO::Services::SwiftProxy: ../deployment/swift/swift-proxy-container-puppet.yaml OS::TripleO::Services::SwiftStorage: ../deployment/swift/swift-storage-container-puppet.yaml OS::TripleO::Services::SwiftRingBuilder: ../deployment/swift/swift-ringbuilder-container-puppet.yaml ,,15,6
openstack%2Fneutron~master~Ie66356428d7c1ab0d9d721d9710f915e90747c99,openstack/neutron,master,Ie66356428d7c1ab0d9d721d9710f915e90747c99,Add DBDuplicateEntry exception catch code to object update method,ABANDONED,2021-01-21 09:37:32.000000000,2021-02-05 10:34:00.000000000,,"[{'_account_id': 1131}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-21 09:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/824c98a0671d7b399e788f919f9fd25129ad618e', 'message': 'Add DBDuplicateEntry exception catch code to object update method\n\nCloses-Bug: #1912596\nChange-Id: Ie66356428d7c1ab0d9d721d9710f915e90747c99\n'}, {'number': 2, 'created': '2021-01-31 05:18:27.000000000', 'files': ['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/objects/base.py', 'neutron/tests/unit/extensions/test_l3_conntrack_helper.py', 'neutron/tests/unit/objects/test_base.py', 'neutron/services/conntrack_helper/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/01761092f7017993544c8eab7de0eee533cad043', 'message': ""Add DBDuplicateEntry exception catch code to object update method\n\nIn some case, the update action may also cause DBDuplicateEntry\nexception. For example: update floating ip port forwarding or\nupdate router conntrack helper. This patch add common catch code\nfor neutron object's update method.\n\nAdditionally, add some extension unit tests for rotuer conntrack\nhelper plugin.\n\nCloses-Bug: #1912596\nChange-Id: Ie66356428d7c1ab0d9d721d9710f915e90747c99\n""}]",4,771776,01761092f7017993544c8eab7de0eee533cad043,14,3,2,28329,,,0,"Add DBDuplicateEntry exception catch code to object update method

In some case, the update action may also cause DBDuplicateEntry
exception. For example: update floating ip port forwarding or
update router conntrack helper. This patch add common catch code
for neutron object's update method.

Additionally, add some extension unit tests for rotuer conntrack
helper plugin.

Closes-Bug: #1912596
Change-Id: Ie66356428d7c1ab0d9d721d9710f915e90747c99
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/771776/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_floating_ip_port_forwarding.py', 'neutron/objects/base.py', 'neutron/tests/unit/objects/test_base.py']",3,824c98a0671d7b399e788f919f9fd25129ad618e,bug/1912596," def test_update_duplicates(self): with mock.patch.object(obj_db_api, 'update_object', side_effect=obj_exc.DBDuplicateEntry): obj = self._test_class(self.context, **self.obj_fields[0]) with mock.patch.object(obj, '_validate_changed_fields'): self.assertRaises(o_exc.NeutronDbObjectDuplicateEntry, obj.update) ",,92,5
openstack%2Fkayobe~stable%2Ftrain~I487633546bbd3a65ed2858d0b5b6df715224a9ee,openstack/kayobe,stable/train,I487633546bbd3a65ed2858d0b5b6df715224a9ee,CI: overcloud upgrade fixes for Train,MERGED,2021-02-02 11:00:51.000000000,2021-02-05 10:31:30.000000000,2021-02-05 10:29:36.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 11:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/673a4e8f4ecf9869944152cce15fef34762feb61', 'message': ""CI: prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 2, 'created': '2021-02-02 13:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/c2fd2e055c954266b366a2ab3522df7ad7448598', 'message': ""CI: prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 3, 'created': '2021-02-03 09:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/94062009de91732be99e780fa671e9e564b1e9bf', 'message': ""CI: prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 4, 'created': '2021-02-03 14:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/019a9ce39d2aa9b11df4dee28b56a80a5397b4c0', 'message': ""CI: overcloud upgrade fixes\n\n1. prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\n2. add dummy1 port for overcloud upgrade job (Train only)\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 5, 'created': '2021-02-03 16:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/7140c2b3e0055459f901a7cbb86d5b1f1adf6bfc', 'message': ""CI: overcloud upgrade fixes\n\n1. prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\n2. add dummy1 port for overcloud upgrade job (Train only)\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 6, 'created': '2021-02-04 08:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/28bfd146c24f08d2a4be39938f901374becfe4c5', 'message': ""CI: overcloud upgrade fixes\n\n1. prune docker images after upgrade (Train CentOS 7 only)\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nPrune old images to free up links.\n\n2. add dummy1 port for overcloud upgrade job (Train only)\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 7, 'created': '2021-02-04 13:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/d39ca96918229a9358c9594740c39bda30cdd09d', 'message': ""CI: overcloud upgrade fixes for Train\n\n1. Use overlay2 storage driver\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links. This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nUse overlay2 storage driver instead.\n\n2. Add dummy1 port for overcloud upgrade job\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 8, 'created': '2021-02-04 13:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/1d19a3b5b4c81dd0bdcedcadec5e151a6b4deb7b', 'message': ""[DNM] CI: overcloud upgrade fixes for Train\n\n1. Use overlay2 storage driver\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links. This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nUse overlay2 storage driver instead.\n\n2. Add dummy1 port for overcloud upgrade job\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\n""}, {'number': 9, 'created': '2021-02-04 17:53:28.000000000', 'files': ['playbooks/kayobe-overcloud-upgrade-base/overrides.yml.j2', 'playbooks/kayobe-overcloud-upgrade-base/pre.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/564af0aba3b89a951d770b21c706783ec8dba1f4', 'message': ""CI: overcloud upgrade fixes for Train\n\n1. Use overlay2 storage driver\n\nSometimes with the overlayfs (v1) driver we can hit the following error\non upgrade jobs: Unknown error message: failed to register layer: link\n<path1> <path2>: too many links. This happens when many images share a\nbase image, we can hit the file system's hard link limit.\n\nUse overlay2 storage driver instead.\n\n2. Add dummy1 port for overcloud upgrade job\n\nAdapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an\novercloud upgrade job for Ussuri, including this dummy port.\n\nChange-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee\nCo-Authored-By: Pierre Riteau <pierre@stackhpc.com>\n""}]",1,773635,564af0aba3b89a951d770b21c706783ec8dba1f4,34,4,9,14826,,,0,"CI: overcloud upgrade fixes for Train

1. Use overlay2 storage driver

Sometimes with the overlayfs (v1) driver we can hit the following error
on upgrade jobs: Unknown error message: failed to register layer: link
<path1> <path2>: too many links. This happens when many images share a
base image, we can hit the file system's hard link limit.

Use overlay2 storage driver instead.

2. Add dummy1 port for overcloud upgrade job

Adapted from I0e88683f775769c1a80879685b0e7a2983599b08, which added an
overcloud upgrade job for Ussuri, including this dummy port.

Change-Id: I487633546bbd3a65ed2858d0b5b6df715224a9ee
Co-Authored-By: Pierre Riteau <pierre@stackhpc.com>
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/35/773635/9 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/kayobe-overcloud-upgrade-base/run.yml'],1,673a4e8f4ecf9869944152cce15fef34762feb61,," # NOTE(mgoddard): Sometimes with the overlayfs (v1) driver we can hit # the following error on upgrade jobs: # Unknown error message: failed to register layer: link <path1> # <path2>: too many links # This happens when many images share a base image, we can hit the file # system's hard link limit. - name: Prune images from previous release shell: cmd: >- source {{ kayobe_src_dir }}/dev/environment-setup.sh && kayobe overcloud host command run --command ""docker image prune -af"" --become when: ansible_distribution_major_version | int == 7 ",,14,0
openstack%2Ffreezer~master~Iccd20901384ccee82dbb1e57dc6dddf211cbbcd0,openstack/freezer,master,Iccd20901384ccee82dbb1e57dc6dddf211cbbcd0,add test_scheduledstate_start for unit test,MERGED,2021-02-05 08:44:07.000000000,2021-02-05 10:09:58.000000000,2021-02-05 10:08:19.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 08:44:07.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/97984c71d69ba4e05632c920fa62c1e392650a20', 'message': 'add test_scheduledstate_start for unit test\n\nChange-Id: Iccd20901384ccee82dbb1e57dc6dddf211cbbcd0\n'}]",0,774206,97984c71d69ba4e05632c920fa62c1e392650a20,7,2,1,21387,,,0,"add test_scheduledstate_start for unit test

Change-Id: Iccd20901384ccee82dbb1e57dc6dddf211cbbcd0
",git fetch https://review.opendev.org/openstack/freezer refs/changes/06/774206/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,97984c71d69ba4e05632c920fa62c1e392650a20,improveUTC2," def test_scheduledstate_abort(self): result = scheduler_job.ScheduledState.abort(self.job, self.jobdoc) self.assertEqual(result, '') def test_scheduledstate_start(self): result = scheduler_job.ScheduledState.start(self.job, self.jobdoc) self.assertEqual(result, '')",,8,0
openstack%2Fmagnum~stable%2Fussuri~Ifd57405d72ed6c1406bc9cecca3a412507bb8a02,openstack/magnum,stable/ussuri,Ifd57405d72ed6c1406bc9cecca3a412507bb8a02,Drop lower constraints testing,MERGED,2021-02-02 11:56:00.000000000,2021-02-05 10:00:59.000000000,2021-02-05 09:55:54.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2021-02-02 11:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9ca4423a54f950d30985d6580abfc7265e1a43fb', 'message': 'Drop lower constraints testing\n\nProjects like oslo are dropping lower constraints\ntesting. There is also discussion to drop it until\nwe find a proper setup. For details, please follow\nthe ML thread. TC will have updates soon.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2021-January/019679.html\n\nstory: 2008482\ntask: 41565\n\nChange-Id: Ifd57405d72ed6c1406bc9cecca3a412507bb8a02\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n(cherry picked from commit 97c6bdad476b05e2691f3e9c57c9d53997c5f207)\n'}, {'number': 2, 'created': '2021-02-02 11:56:46.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/2e6ebc0a59bc8e3d36c161a3934811863796d0b1', 'message': 'Drop lower constraints testing\n\nProjects like oslo are dropping lower constraints\ntesting. There is also discussion to drop it until\nwe find a proper setup. For details, please follow\nthe ML thread. TC will have updates soon.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2021-January/019679.html\n\nstory: 2008482\ntask: 41565\n\nChange-Id: Ifd57405d72ed6c1406bc9cecca3a412507bb8a02\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n(cherry picked from commit 97c6bdad476b05e2691f3e9c57c9d53997c5f207)\n'}]",0,773594,2e6ebc0a59bc8e3d36c161a3934811863796d0b1,14,4,2,28022,,,0,"Drop lower constraints testing

Projects like oslo are dropping lower constraints
testing. There is also discussion to drop it until
we find a proper setup. For details, please follow
the ML thread. TC will have updates soon.

http://lists.openstack.org/pipermail/openstack-discuss/2021-January/019679.html

story: 2008482
task: 41565

Change-Id: Ifd57405d72ed6c1406bc9cecca3a412507bb8a02
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
(cherry picked from commit 97c6bdad476b05e2691f3e9c57c9d53997c5f207)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/94/773594/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,9ca4423a54f950d30985d6580abfc7265e1a43fb,drop_lc,"<<<<<<< HEAD (22053b Merge ""Update default values for docker nofile and vm.max_ma)======= - openstack-python3-victoria-jobs >>>>>>> CHANGE (97c6bd Drop lower constraints testing)",,4,0
openstack%2Fneutron-lib~master~I6b57f7ce6d411be388c63b87f2c75f2de703cc97,openstack/neutron-lib,master,I6b57f7ce6d411be388c63b87f2c75f2de703cc97,Add qos rule validation for network,MERGED,2021-02-04 13:27:35.000000000,2021-02-05 09:27:24.000000000,2021-02-05 09:26:08.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 13:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/ce74632492f485bdf3c51eaa2d8e91c69cf9957f', 'message': 'Add qos rule validation for network\n\nMinimum bandwidth QoS rule is only applicable for the network\nwhich is backed by physical networks.\nWhen updating network policy on network without port\nwill raise exception.\n\nPartial-Bug: #1913180\nChange-Id: I6b57f7ce6d411be388c63b87f2c75f2de703cc97\n'}, {'number': 2, 'created': '2021-02-04 13:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/c0c4f5cc65243052313a6404e88da202d6d4a81f', 'message': 'Add qos rule validation for network\n\nMinimum bandwidth QoS rule is only applicable for the network\nwhich is backed by physical networks.\nWhen updating network policy on network without port\nwill raise exception.\n\nPartial-Bug: #1913180\nChange-Id: I6b57f7ce6d411be388c63b87f2c75f2de703cc97\n'}, {'number': 3, 'created': '2021-02-04 14:16:39.000000000', 'files': ['neutron_lib/exceptions/qos.py', 'neutron_lib/services/qos/base.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/2dabcc5cf7d68bf2a4640f07d5e170aa8b911390', 'message': 'Add qos rule validation for network\n\nMinimum bandwidth QoS rule is only applicable for the network\nwhich is backed by physical networks.\nWhen updating network policy on network without port\nwill raise exception.\n\nPartial-Bug: #1913180\nChange-Id: I6b57f7ce6d411be388c63b87f2c75f2de703cc97\n'}]",5,774083,2dabcc5cf7d68bf2a4640f07d5e170aa8b911390,16,3,3,32667,,,0,"Add qos rule validation for network

Minimum bandwidth QoS rule is only applicable for the network
which is backed by physical networks.
When updating network policy on network without port
will raise exception.

Partial-Bug: #1913180
Change-Id: I6b57f7ce6d411be388c63b87f2c75f2de703cc97
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/83/774083/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/exceptions/qos.py', 'neutron_lib/services/qos/base.py']",2,ce74632492f485bdf3c51eaa2d8e91c69cf9957f,bug/1913180," def validate_rule_for_network(self, context, rule, network_id): """"""Return True/False for valid/invalid. This is only meant to be used when a rule is compatible with some networks but not with others (depending on network properties). Returns True by default for backwards compatibility. """""" return True",,16,0
openstack%2Fnova~master~Ibe6aff4edeb32208bc9865e9216a7432caddab2b,openstack/nova,master,Ibe6aff4edeb32208bc9865e9216a7432caddab2b,hyperv: Configures chassis asset tags for VMs.,MERGED,2020-09-18 16:12:06.000000000,2021-02-05 09:14:34.000000000,2021-02-05 01:37:55.000000000,"[{'_account_id': 782}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-18 16:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0f9c65a4150ef8dc13220eb8a42febc5689720af', 'message': 'hyperv: Configures chassis asset tags for VMs.\n\nThe Msvm_VirtualSystemSettingData object associated with a VM has a\nfield named ""ChassisAssetTag"". The value set in this field is reflected\nin Linux VMs in /sys/class/dmi/id/chassis-asset-tag. This value is\nchecked by cloud-init in order to figure out if it is currently running\ninside an OpenStack VM.\n\nThe verification above has been introduced in cloud-init [1] in order to\navoid costly metadata probes that aren\'t needed in non-OpenStack VMs.\n\nSetting the ChassisAssetTag will allow us to pass these checks. The\nvalue we are setting is similar to what libvirt is setting in the\nLibvirtConfigGuestSysinfo.\n\n[1] https://github.com/canonical/cloud-init/commit/1efa8a0a030794cec68197100f31a856d0d264ab\n\nPartially-Fixes: #1895976\n\nChange-Id: Ibe6aff4edeb32208bc9865e9216a7432caddab2b\nDepends-On: 33e6c07dab4b46442bf0fbb838d59516112899b9\n'}, {'number': 2, 'created': '2020-09-21 11:57:36.000000000', 'files': ['nova/tests/unit/virt/hyperv/test_vmops.py', 'nova/virt/hyperv/vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/48123d63211a2446ddaf12f8ef692e3c67f09c7d', 'message': 'hyperv: Configures chassis asset tags for VMs.\n\nThe Msvm_VirtualSystemSettingData object associated with a VM has a\nfield named ""ChassisAssetTag"". The value set in this field is reflected\nin Linux VMs in /sys/class/dmi/id/chassis-asset-tag. This value is\nchecked by cloud-init in order to figure out if it is currently running\ninside an OpenStack VM.\n\nThe verification above has been introduced in cloud-init [1] in order to\navoid costly metadata probes that aren\'t needed in non-OpenStack VMs.\n\nSetting the ChassisAssetTag will allow us to pass these checks. The\nvalue we are setting is similar to what libvirt is setting in the\nLibvirtConfigGuestSysinfo.\n\n[1] https://github.com/canonical/cloud-init/commit/1efa8a0a030794cec68197100f31a856d0d264ab\n\nPartially-Fixes: #1895976\n\nChange-Id: Ibe6aff4edeb32208bc9865e9216a7432caddab2b\nDepends-On: 33e6c07dab4b46442bf0fbb838d59516112899b9\n'}]",1,752723,48123d63211a2446ddaf12f8ef692e3c67f09c7d,84,13,2,8213,,,0,"hyperv: Configures chassis asset tags for VMs.

The Msvm_VirtualSystemSettingData object associated with a VM has a
field named ""ChassisAssetTag"". The value set in this field is reflected
in Linux VMs in /sys/class/dmi/id/chassis-asset-tag. This value is
checked by cloud-init in order to figure out if it is currently running
inside an OpenStack VM.

The verification above has been introduced in cloud-init [1] in order to
avoid costly metadata probes that aren't needed in non-OpenStack VMs.

Setting the ChassisAssetTag will allow us to pass these checks. The
value we are setting is similar to what libvirt is setting in the
LibvirtConfigGuestSysinfo.

[1] https://github.com/canonical/cloud-init/commit/1efa8a0a030794cec68197100f31a856d0d264ab

Partially-Fixes: #1895976

Change-Id: Ibe6aff4edeb32208bc9865e9216a7432caddab2b
Depends-On: 33e6c07dab4b46442bf0fbb838d59516112899b9
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/752723/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/hyperv/test_vmops.py', 'nova/virt/hyperv/vmops.py']",2,0f9c65a4150ef8dc13220eb8a42febc5689720af,,from nova import version host_shutdown_action=host_shutdown_action chassis_asset_tag=version.product_string()), host_shutdown_action=host_shutdown_action),7,2
openstack%2Fcharm-mysql-router~master~I0ea751aa4015ad6e569d9c3e9f8364cf36801c18,openstack/charm-mysql-router,master,I0ea751aa4015ad6e569d9c3e9f8364cf36801c18,Use report host on bootstrap,MERGED,2021-02-04 21:05:15.000000000,2021-02-05 09:08:03.000000000,2021-02-05 09:08:03.000000000,"[{'_account_id': 8992}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 21:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/745a589adba09d19f2410e9610fae7d987529286', 'message': 'Use report host on bootstrap\n\nLP Bug #1914649 saw an edge case where --report-host was necessary for\nmysql-router bootstrap. Adding it to cover this edge case.\n\nChange-Id: I0ea751aa4015ad6e569d9c3e9f8364cf36801c18\nCloses-Bug: #1914649\n'}, {'number': 2, 'created': '2021-02-04 21:11:10.000000000', 'files': ['src/lib/charm/openstack/mysql_router.py', 'unit_tests/test_lib_charm_openstack_mysql_router.py'], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/7c8acbc18fae896bd5340ddea8eaa2a070620ba6', 'message': 'Use report host on bootstrap\n\nLP Bug #1914649 saw an edge case where --report-host was necessary for\nmysql-router bootstrap. Adding it to cover this edge case.\n\nChange-Id: I0ea751aa4015ad6e569d9c3e9f8364cf36801c18\nCloses-Bug: #1914649\n'}]",0,774160,7c8acbc18fae896bd5340ddea8eaa2a070620ba6,12,5,2,20805,,,0,"Use report host on bootstrap

LP Bug #1914649 saw an edge case where --report-host was necessary for
mysql-router bootstrap. Adding it to cover this edge case.

Change-Id: I0ea751aa4015ad6e569d9c3e9f8364cf36801c18
Closes-Bug: #1914649
",git fetch https://review.opendev.org/openstack/charm-mysql-router refs/changes/60/774160/2 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/mysql_router.py'],1,745a589adba09d19f2410e9610fae7d987529286,bug/1914649," ""--report-host"", self.db_router_address,",,1,0
openstack%2Frequirements~master~Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37,openstack/requirements,master,Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37,Add python-cyborgclient in openstack/requirements.,MERGED,2021-01-18 10:09:45.000000000,2021-02-05 09:03:38.000000000,2021-02-05 09:01:59.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-18 10:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a339ddaa0a5881e4176a9505fcff49fdbc6ad976', 'message': 'Add python-cyborgclient in openstack/requirements.\n\nChange-Id: Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37\n'}, {'number': 2, 'created': '2021-01-18 10:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/b60521a30f20a9831c90b045e7e816cbab364eba', 'message': 'Add python-cyborgclient in openstack/requirements.\n\nWe have implemented our OpenStack client plugin and would like to\nget it added to the global-requirements list.  This is to facilitate\ntesting and documentation generation, etc.\n\n[Q] Is the library actively maintained?\n[A] Yes.\n\n[Q] Is the library good code?\n[A] Yes. We think so.\n\n[Q] Is the library python 3 compatible?\n[A] Yes.\n\n[Q] Is the library license compatible?\n[A] Yes. Apache 2.0\n\n[Q] Is the library already packaged in the distros we target\n    (Ubuntu latest / Fedora latest)?\n[A] Yes.\n\n[Q] Is the function of this library already covered by other\n    libraries in global-requirements.txt?\n[A] No.\n\nChange-Id: Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37\n'}, {'number': 3, 'created': '2021-02-05 05:46:33.000000000', 'files': ['global-requirements.txt', 'projects.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cc40d6ef13888e86ed36c70058350cf20eeda1fc', 'message': 'Add python-cyborgclient in openstack/requirements.\n\nWe have implemented our OpenStack client plugin and would like to\nget it added to the global-requirements list.  This is to facilitate\ntesting and documentation generation, etc.\n\n[Q] Is the library actively maintained?\n[A] Yes.\n\n[Q] Is the library good code?\n[A] Yes. We think so.\n\n[Q] Is the library python 3 compatible?\n[A] Yes.\n\n[Q] Is the library license compatible?\n[A] Yes. Apache 2.0\n\n[Q] Is the library already packaged in the distros we target\n    (Ubuntu latest / Fedora latest)?\n[A] Yes.\n\n[Q] Is the function of this library already covered by other\n    libraries in global-requirements.txt?\n[A] No.\n\nChange-Id: Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37\n'}]",0,771179,cc40d6ef13888e86ed36c70058350cf20eeda1fc,15,3,3,25738,,,0,"Add python-cyborgclient in openstack/requirements.

We have implemented our OpenStack client plugin and would like to
get it added to the global-requirements list.  This is to facilitate
testing and documentation generation, etc.

[Q] Is the library actively maintained?
[A] Yes.

[Q] Is the library good code?
[A] Yes. We think so.

[Q] Is the library python 3 compatible?
[A] Yes.

[Q] Is the library license compatible?
[A] Yes. Apache 2.0

[Q] Is the library already packaged in the distros we target
    (Ubuntu latest / Fedora latest)?
[A] Yes.

[Q] Is the function of this library already covered by other
    libraries in global-requirements.txt?
[A] No.

Change-Id: Ied2a885c46a07c48d3f04c8d0d492c8acf7c4e37
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/771179/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'projects.txt', 'upper-constraints.txt']",3,a339ddaa0a5881e4176a9505fcff49fdbc6ad976,,python-cyborgclient===1.2.1,,3,0
openstack%2Ftripleo-ansible~master~I0048fec8c1e19bd20b1edcd23f2490456fe1cd12,openstack/tripleo-ansible,master,I0048fec8c1e19bd20b1edcd23f2490456fe1cd12,Make server group quota unlimited for Octavia,MERGED,2021-02-01 09:51:22.000000000,2021-02-05 08:49:36.000000000,2021-02-05 08:49:36.000000000,"[{'_account_id': 6681}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29244}]","[{'number': 1, 'created': '2021-02-01 09:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/16ce99b2ee3b1a468c00cae0c2a6779249bc1267', 'message': 'Increase service project server-group-members,server-groups quotas when deploying octavia\n\nOctavia currently launches HA load balancer VMs in the services tenant\nwhich has very low quotas by default. This patch increases the values\nthrough the API for the services project to permit lots of load\nbalancers.\n\nCloses-Bug: #1769896\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}, {'number': 2, 'created': '2021-02-01 09:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/eebd85fba347fc87e94c4cf150a1fa6619774cbf', 'message': 'Increase service project server-group-members,server-groups quotas when deploying octavia\n\nOctavia currently launches HA load balancer VMs in the services tenant\nwhich has very low quotas by default. This patch increases the values\nthrough the API for the services project to permit lots of load\nbalancers.\n\nCloses-Bug: #1914018\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}, {'number': 3, 'created': '2021-02-01 10:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/89f88b7148265f068de44303c601b2e723fda51f', 'message': 'Make server group quota unlimited for Octavia\n\nOctavia currently launches HA load balancer VMs in the services tenant\nwhich has very low quotas by default. This patch increases the values\nthrough the API for the services project to permit lots of load\nbalancers.\n\nCloses-Bug: #1914018\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}, {'number': 4, 'created': '2021-02-01 10:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9491c202a509ed270071b32010091b07d7fd5448', 'message': 'Make server group quota unlimited for Octavia\n\nWhen a user creates a HA load balancer in Octavia, Octavia creates server\ngroups as part of the load balancer resources. However because the default\nquotas related to server group are very low and we have all load balancer\nresources in the common service project, users can create very limited\nnumber of HA load balancers by default.\n \nThis patch disables the quota limits of the server-group-members and\nserver-groups of the service project, so that HA load balancer creation\nis not blocked by these quotas.\n\nCloses-Bug: #1914018\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}, {'number': 5, 'created': '2021-02-01 10:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/bd77db9cce399893b588be2d28686b5b304ac96a', 'message': 'Make server group quota unlimited for Octavia\n\n\nWhen a user creates a HA load balancer in Octavia, Octavia creates\nserver groups as part of the load balancer resources. However because\nthe default quotas related to server group are very low and we have all\nload balancer resources in the common service project, users can create\nvery limited number of HA load balancers by default.\n \nThis patch disables the quota limits of the server-group-members and\nserver-groups of the service project, so that HA load balancer creation\nis not blocked by these quotas.\n\nCloses-Bug: #1914018\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}, {'number': 6, 'created': '2021-02-01 10:51:58.000000000', 'files': ['tripleo_ansible/roles/octavia_overcloud_config/tasks/quotas.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/06470bc4d64c9e832d06a2e54ae6a3363a720008', 'message': 'Make server group quota unlimited for Octavia\n\nWhen a user creates a HA load balancer in Octavia, Octavia creates\nserver groups as part of the load balancer resources. However because\nthe default quotas related to server group are very low and we have all\nload balancer resources in the common service project, users can create\nvery limited number of HA load balancers by default.\n\nThis patch disables the quota limits of the server-group-members and\nserver-groups of the service project, so that HA load balancer creation\nis not blocked by these quotas.\n\nCloses-Bug: #1914018\nChange-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12\n'}]",6,773338,06470bc4d64c9e832d06a2e54ae6a3363a720008,19,6,6,33061,,,0,"Make server group quota unlimited for Octavia

When a user creates a HA load balancer in Octavia, Octavia creates
server groups as part of the load balancer resources. However because
the default quotas related to server group are very low and we have all
load balancer resources in the common service project, users can create
very limited number of HA load balancers by default.

This patch disables the quota limits of the server-group-members and
server-groups of the service project, so that HA load balancer creation
is not blocked by these quotas.

Closes-Bug: #1914018
Change-Id: I0048fec8c1e19bd20b1edcd23f2490456fe1cd12
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/38/773338/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/octavia_overcloud_config/tasks/quotas.yml'],1,16ce99b2ee3b1a468c00cae0c2a6779249bc1267,bug/1914018, openstack quota set --cores -1 --ram -1 --ports -1 --instances -1 --secgroups -1 --secgroup-rules -1 --server-group-members -1 --server-groups -1 {{ auth_project_name }}, openstack quota set --cores -1 --ram -1 --ports -1 --instances -1 --secgroups -1 --secgroup-rules -1 {{ auth_project_name }},1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,openstack/tripleo-heat-templates,stable/train,I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues,MERGED,2021-02-01 14:58:55.000000000,2021-02-05 08:46:39.000000000,2021-02-05 08:44:18.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-02-01 14:58:55.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/431cfb979a31f00d7a5c548e466d1b6d343bb434', 'message': 'Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues\n\nAdd NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in\nnova.conf of the compute. Default 0 corresponds to not set meaning the\nlegacy limits based on the reported kernel major version will be used.\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/773267\nChange-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f\n(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)\n(cherry picked from commit ace2eb097ed221eb5110df9d470306234a6b93ef)\n(cherry picked from commit e21b9f8dd0ac758aca1f0a808bfda0b335290a3b)\n'}]",0,773408,431cfb979a31f00d7a5c548e466d1b6d343bb434,15,6,1,17216,,,0,"Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues

Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in
nova.conf of the compute. Default 0 corresponds to not set meaning the
legacy limits based on the reported kernel major version will be used.

Conflicts:
  deployment/nova/nova-compute-container-puppet.yaml

Depends-On: https://review.opendev.org/c/openstack/puppet-nova/+/773267
Change-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f
(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)
(cherry picked from commit ace2eb097ed221eb5110df9d470306234a6b93ef)
(cherry picked from commit e21b9f8dd0ac758aca1f0a808bfda0b335290a3b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/773408/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml']",2,431cfb979a31f00d7a5c548e466d1b6d343bb434,1917460-t,--- features: - | Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in nova.conf of the compute. Default 0 corresponds to not set meaning the legacy limits based on the reported kernel major version will be used. ,,29,0
openstack%2Fpython-tripleoclient~master~I2ab141d676088042260c6456b59f22b2ba474e68,openstack/python-tripleoclient,master,I2ab141d676088042260c6456b59f22b2ba474e68,Quote $@ in ansible-playbook-command.sh,MERGED,2021-01-27 22:31:03.000000000,2021-02-05 08:46:35.000000000,2021-02-05 08:44:41.000000000,"[{'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-27 22:31:03.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0b872060ee1fcc1fb5088163d727464bd703ef5b', 'message': 'Quote $@ in ansible-playbook-command.sh\n\n$@ should be quoted within the generated ansible-playbook-command.sh\nshell script, so that if any of the additional args contain quotes\nthemselves they will be handled appropriately.\n\nChange-Id: I2ab141d676088042260c6456b59f22b2ba474e68\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}]",0,772782,0b872060ee1fcc1fb5088163d727464bd703ef5b,8,3,1,7144,,,0,"Quote $@ in ansible-playbook-command.sh

$@ should be quoted within the generated ansible-playbook-command.sh
shell script, so that if any of the additional args contain quotes
themselves they will be handled appropriately.

Change-Id: I2ab141d676088042260c6456b59f22b2ba474e68
Signed-off-by: James Slagle <jslagle@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/82/772782/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,0b872060ee1fcc1fb5088163d727464bd703ef5b,," f.write('{} ""$@""\n'.format(' '.join(runner_config.command)))", f.write('{} $@\n'.format(' '.join(runner_config.command))),1,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~I269607d43f45f65efcbce33dd776e7eb4f475311,openstack/tripleo-heat-templates,stable/rocky,I269607d43f45f65efcbce33dd776e7eb4f475311,Use Ceph-NFS for Manila in scenario004,MERGED,2021-02-04 16:11:35.000000000,2021-02-05 08:45:17.000000000,2021-02-05 08:45:17.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2021-02-04 16:11:35.000000000', 'files': ['roles/Standalone.yaml', 'ci/environments/scenario004-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/adca6772c4012c999288a89b0e440ecfc0b65512', 'message': 'Use Ceph-NFS for Manila in scenario004\n\nCephFS gatewayed by NFS is more generally suitable for multi-tenant\nOpenStack deployments than native CephFS since the latter requires\nthat VMs belonging to regular members of Keystone projects be exposed\nto the Ceph infrastructure and run client software with capabilities\nthat are not appropriate for untrusted cloud tenants.\n\nChange-Id: I269607d43f45f65efcbce33dd776e7eb4f475311\n(cherry picked from commit 63c5a94f83a6d8d9f9cc3e342265002e2e708d81)\n(cherry picked from commit 7c2933d3b47d203fa012a6667e61d8377e503a18)\n(cherry picked from commit d9414af719142bfa7a619c2d72dd3ebd4360f1a7)\n(cherry picked from commit e038ecd2e8433c3927e3d921703c4c897965fecc)\n(cherry picked from commit 051a367ae3b9c10a64a717c988be71003d0262df)\n'}]",0,774099,adca6772c4012c999288a89b0e440ecfc0b65512,9,6,1,9003,,,0,"Use Ceph-NFS for Manila in scenario004

CephFS gatewayed by NFS is more generally suitable for multi-tenant
OpenStack deployments than native CephFS since the latter requires
that VMs belonging to regular members of Keystone projects be exposed
to the Ceph infrastructure and run client software with capabilities
that are not appropriate for untrusted cloud tenants.

Change-Id: I269607d43f45f65efcbce33dd776e7eb4f475311
(cherry picked from commit 63c5a94f83a6d8d9f9cc3e342265002e2e708d81)
(cherry picked from commit 7c2933d3b47d203fa012a6667e61d8377e503a18)
(cherry picked from commit d9414af719142bfa7a619c2d72dd3ebd4360f1a7)
(cherry picked from commit e038ecd2e8433c3927e3d921703c4c897965fecc)
(cherry picked from commit 051a367ae3b9c10a64a717c988be71003d0262df)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/774099/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario004-standalone.yaml', 'roles/Standalone.yaml']",2,adca6772c4012c999288a89b0e440ecfc0b65512,, - StorageNFS - OS::TripleO::Services::CephNfs,,108,0
openstack%2Fpython-tripleoclient~master~I4ac0c2aaf8b6a8f4a9b5e5f40fa68929be32ee38,openstack/python-tripleoclient,master,I4ac0c2aaf8b6a8f4a9b5e5f40fa68929be32ee38,Write ansible-playbook-command.sh to workdir not playbook_dir,MERGED,2021-01-27 22:45:59.000000000,2021-02-05 08:44:55.000000000,2021-02-05 08:44:55.000000000,"[{'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-27 22:45:59.000000000', 'files': ['tripleoclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8b3fa1bfd7cc6ee27676cfaf7aab6f03ce6408ae', 'message': 'Write ansible-playbook-command.sh to workdir not playbook_dir\n\nThe reproducer command, ansible-playbook-command.sh, should not be\nwritten to playbook_dir, as that directory may not always be writeable.\nIt is in fact commonly set to /usr/share/ansible/tripleo-playbooks,\nwhich is not writeable by a non-privileged user.\n\nInstead, write the command to workdir, which is either the\nconfig-download directory, or the directory setup for use by ansible\nrunner.\n\nChange-Id: I4ac0c2aaf8b6a8f4a9b5e5f40fa68929be32ee38\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}]",0,772783,8b3fa1bfd7cc6ee27676cfaf7aab6f03ce6408ae,7,3,1,7144,,,0,"Write ansible-playbook-command.sh to workdir not playbook_dir

The reproducer command, ansible-playbook-command.sh, should not be
written to playbook_dir, as that directory may not always be writeable.
It is in fact commonly set to /usr/share/ansible/tripleo-playbooks,
which is not writeable by a non-privileged user.

Instead, write the command to workdir, which is either the
config-download directory, or the directory setup for use by ansible
runner.

Change-Id: I4ac0c2aaf8b6a8f4a9b5e5f40fa68929be32ee38
Signed-off-by: James Slagle <jslagle@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/83/772783/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/utils.py'],1,8b3fa1bfd7cc6ee27676cfaf7aab6f03ce6408ae,," workdir,"," playbook_dir,",1,1
openstack%2Ffreezer~master~I75b4025cb207bb0aa59c4325819add1be45cf08e,openstack/freezer,master,I75b4025cb207bb0aa59c4325819add1be45cf08e,add test_scheduledstate_stop for unit test,MERGED,2021-02-05 05:57:06.000000000,2021-02-05 08:39:39.000000000,2021-02-05 08:38:17.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 05:57:06.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/0ea6b00494cdb19826c0d4124970340dc67ce7a4', 'message': 'add test_scheduledstate_stop for unit test\n\nChange-Id: I75b4025cb207bb0aa59c4325819add1be45cf08e\n'}]",0,774194,0ea6b00494cdb19826c0d4124970340dc67ce7a4,7,2,1,21387,,,0,"add test_scheduledstate_stop for unit test

Change-Id: I75b4025cb207bb0aa59c4325819add1be45cf08e
",git fetch https://review.opendev.org/openstack/freezer refs/changes/94/774194/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,0ea6b00494cdb19826c0d4124970340dc67ce7a4,improveUTC1," def test_stopstate_remove(self): result = scheduler_job.StopState.remove(self.job) self.assertEqual(result, '') def test_scheduledstate_stop(self): result = scheduler_job.ScheduledState.stop(self.job, self.jobdoc) self.assertEqual(result, 'stop')",,8,0
openstack%2Fneutron-specs~master~I0427339489140457a2b56911cbabe74082c751c8,openstack/neutron-specs,master,I0427339489140457a2b56911cbabe74082c751c8,Add spec for Distributed DHCP,MERGED,2020-12-28 02:44:40.000000000,2021-02-05 08:30:16.000000000,2021-02-05 08:28:47.000000000,"[{'_account_id': 5948}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-28 02:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/34b8bb4fb0acc073da861e2bfc2d875359cd3806', 'message': 'Add spec for Distributed DHCP\n\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\nCloses-Bug: #1900934\n'}, {'number': 2, 'created': '2020-12-28 08:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e389b6fbc801283c5aa637c1b723090e4f5f1a81', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 3, 'created': '2020-12-30 08:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/33228f81d31c2bcbbd03e5d48ed6f4cdd93bb644', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 4, 'created': '2021-01-05 03:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c3b4e64de68aeb93da11f82c3166648bfb5dce68', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 5, 'created': '2021-01-11 16:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/441e04d4fc3acaf45ae90747ec9c87fdee748857', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 6, 'created': '2021-01-27 08:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/886b8fd661d31c5b7e3ffb4893891fb98fa5e405', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 7, 'created': '2021-01-27 08:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/541b231a6eec931ede3ab8067359832f4b1499e1', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 8, 'created': '2021-01-27 10:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6d787599fe78df939fa7fe67baac4b24f3267c64', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 9, 'created': '2021-02-01 06:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b15e34bb27060ac38b034f0ee1a171897bdc8bf7', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 10, 'created': '2021-02-01 11:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f6e31437031df3161abdac899ab80f6c066f9d2f', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 11, 'created': '2021-02-03 10:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/df01540b0f9ba4e625651f41091f59a385c509b3', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 12, 'created': '2021-02-03 10:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4681e55f2eaead71329bb9fb672955c629197d08', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 13, 'created': '2021-02-04 10:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5e0960e9fa03850a509326c1278588fefe259e66', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}, {'number': 14, 'created': '2021-02-04 11:04:41.000000000', 'files': ['specs/wallaby/distributed_dhcp.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3f645640d9311a1e353d901fdd54156653559ac0', 'message': 'Add spec for Distributed DHCP\n\nCloses-Bug: #1900934\nChange-Id: I0427339489140457a2b56911cbabe74082c751c8\n'}]",128,768588,3f645640d9311a1e353d901fdd54156653559ac0,74,4,14,9531,,,0,"Add spec for Distributed DHCP

Closes-Bug: #1900934
Change-Id: I0427339489140457a2b56911cbabe74082c751c8
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/88/768588/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/distributed_dhcp.rst'],1,34b8bb4fb0acc073da861e2bfc2d875359cd3806,bp/distributed-dhcp-for-ml2-ovs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================ Distributed DHCP ================ RFE: https://bugs.launchpad.net/neutron/+bug/1900934 Neutron DHCP agents and the scheduled network instances are relatively simple in function. But the configuration is complex, and it depends on external process (dnsmasq) and namespace. When the user's demand is merely unique, for example, they only need the DHCP response during the virtual machine booting process, then the existing DHCP agent and its configuration procedure for network and port make things complicated. This spec describes how to implement a DHCP extension for Neutron openvswitch agent to achive a simple and efficient solution for virtual machine DHCP function by leveraging the openflow with openvswitch. Problem Description =================== Response the DHCP request is the main function for the scheduled network instance of DHCP agent. Except this other functions attached to it, like isolated metadata and DNS lookup, are not popular. And there are alternatives for these extended functions, such as config drive for metadata and designate for DNS. Then, the use frequency of the DHCP agent and its scheduling instance are relatively low. And we have more problems for large scale clusters: * The scheduled network instance of DHCP port increase consume L2 agent's capacity and performance. * The DHCP provisioning block sometimes cause virtual machine booting failure. * Full sync in unknown reason cause the message Queue, neutron-server and DB in high load. * DVR local router creation for the scheduled DHCP port in default config option. * Down a DHCP node cause long time recovery of it has tons of scheduled network instance And it is hard to find the balance between ``how many DHCP agents should the deployment have`` and ``how many resources could the agent handle``. Too few DHCP agent will finally make each one agent have a huge mount of resources. Too many DHCP agent will increase maintenance pressure for the operators. There is a trick is to schedule one network to all DHCP agent on all compute nodes. Firstly, this may work for tiny deployment with extremely few resources. for large-scale deployment, it is basically impossible. Because there will be the tens of thousands of Networks in neutron, this will directly lead to a surge of resource pressure on each node, the result is basically unable to operate, virtual machine startup failure and unable to obtain IP and so on. Proposed Change =============== A new extension of neutron openvswitch agent will be added to achieve the ``Distributed DHCP``. Note: Linux bridge mechanism driver will not be considered, because this new extension will rely on the openflow protocol and principle which is not possible for Linux bridge. Solution Proposed ----------------- As we know neutron openvswitch agent has the entire information of the ports which are pluged to the ovs bridge (If the port information was not synced by the ovs-agent, there is a simple cache pull mechanism which will fill the information). So we can assume the neutron openvswitch agent is a local SDN controller which will try to response the VM's DHCP request. The basical data pipeline can be described as this: :: +---------+ +---------------------+ +-------+ DHCP Request | | packet-in | +----------------+ | | VM +---------------> Flows +----------------> | os-ken app | | | <---------------+ <----------------+ | | | +-------+ DHCP Response | | packet-out | | DHCP Responder | | | | | +----------------+ | | br-int | | OVS-agent | +---------+ +---------------------+ After this we will have: * Higher level availability, DHCP requests are directly processed in the computing nodes, it is completely distributed. * No DHCP agent and its scheduling mechanism anymore * No extra external process for DHCP anymore * The (neutron openvswith) agent downtime will no longer affect the address acquisition and virtual machine startup in other nodes. * Virtual machine startup will no longer be affected by port's DHCP configuration, which reduces the probability of VM spawning failure. * DHCP request and reponse for VM will achieve a high success rate. Server side changes +++++++++++++++++++ None OpenvSwitch Agent side changes ++++++++++++++++++++++++++++++ For neutron openvswitch agent, we will add a new agent extension will will process the basical flow installation for each port's DHCP. There will be two basic flows which will direct DHCPv4 and DHCPv6 to independent tables. ``table 77`` is for DHCPv4, ``table 78`` is for DHCPv6. The flows are: :: table=60, priority=101,udp,nw_dst=255.255.255.255,tp_src=68,tp_dst=67 actions=resubmit(,77) table=60, priority=101,udp6,ipv6_dst=ff02::1:2,tp_src=546,tp_dst=547 actions=resubmit(,78) For table 77, each DHCP request will be checked to verify the source mac and in_port in order to avoid the DHCP spoofing. If the DHCP request is matched, then submit it to the controller, aka the Neutron openvswitch agent. Any unmatched packets will be dropped. One example for a VM's port is: :: table=77, priority=100,udp,in_port=""tapcc4f2da4-c5"",dl_src=fa:16:3e:46:58:fe,tp_src=68,tp_dst=67 actions=CONTROLLER:0 table=77, priority=0 actions=drop For table 78, DHCPv6 match and drop flows structure are basically same to DHCPv4: :: table=78, priority=100,udp6,in_port=""tapcc4f2da4-c5"",dl_src=fa:16:3e:46:58:fe,tp_src=546,tp_dst=547 actions=CONTROLLER:0 table=78, priority=0 actions=drop For the new extension of openvswitch agent, it will add a local ``packet_in_handler`` which will do the following work: 1. Listen on the EventOFPPacketIn event 2. Verify each packet to be DHCPv4 or DHCPv6 3. According to the openflow inport number to retrieve the port's information 4. Assemble the DHCP(v4/v6) response and ``packet_out`` to ``in_port``. Potential configurations ++++++++++++++++++++++++ 1. Add config option to disable traditional network DHCP forever. 2. Add config option to disable DHCP privisioning block. 3. Add config option for DHCP protocol, such as lease time, for openvswitch agent. The neutron basic workflow -------------------------- 1. User create VM in a network 2. Nova plug the VM's NIC port to ovs-bridge 3. Ovs-agent process the port and install the DHCP related flows 4. L2 provisioning block released (No DHCP provisioning block) 5. VM booting and send DHCP request out 6. Match the flows and ``packet_in`` to ovs-agent 7. Ovs-agent directly send DHCP(v4/v6) response to VM's port 8. VM booting success Data Model Impact ----------------- None REST API Impact --------------- None Implementation ============== Assignee(s) ----------- * LIU Yulong <i@liuyulong.me> Work Items ---------- * Create agent extension. * Testing. * Documentation. Dependencies ============ None Testing ======= Functionality ------------- In namespace starts fake VM port, and then send DHCP request out. Verify the IP address configuration. References ========== None ",,213,0
openstack%2Fcompute-hyperv~master~I726e426a7274d7c9c6a878afddd23a20ce222a33,openstack/compute-hyperv,master,I726e426a7274d7c9c6a878afddd23a20ce222a33,rbd volume support,MERGED,2020-04-08 11:38:14.000000000,2021-02-05 08:18:39.000000000,2021-02-05 08:18:39.000000000,"[{'_account_id': 8213}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-04-08 11:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/8a893df175dabf9ec41edb9dcb86f9f77b8c5f3c', 'message': 'wip: rbd volume support\n\nThe next Ceph release will support attaching RBD images to Windows\nhosts as well as Hyper-V VMs.\n\nThis patch updates the Hyper-V driver so that it may be able to\nconsume those images.\n\nChange-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33\nTODO: handle attachment persistence.\n'}, {'number': 2, 'created': '2020-11-20 12:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/68612e16835abdb78cf20c1fd7bc022eb301c597', 'message': 'rbd volume support\n\nThe next Ceph release will support attaching RBD images to Windows\nhosts as well as Hyper-V VMs [1].\n\nThis patch updates the Hyper-V driver so that it may be able to\nconsume RBD volumes.\n\nos-brick patch: I56bf09cbd40679eefa5e378c9b36383de89e980c\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nChange-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33\n'}, {'number': 3, 'created': '2020-11-20 13:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/d4037020242a535c6bd928fa97be23cd04792d59', 'message': 'rbd volume support\n\nThe next Ceph release will support attaching RBD images to Windows\nhosts as well as Hyper-V VMs [1].\n\nThis patch updates the Hyper-V driver so that it may be able to\nconsume RBD volumes.\n\nos-brick patch: I56bf09cbd40679eefa5e378c9b36383de89e980c\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nChange-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33\n'}, {'number': 4, 'created': '2020-11-20 14:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/6b080f14f775dc1e442fed4f49afe25cf8a0b336', 'message': 'rbd volume support\n\nCeph 16 (Pacific) will support attaching RBD images to Windows\nhosts as well as Hyper-V VMs [1].\n\nThis patch updates the Hyper-V driver so that it may be able to\nconsume RBD volumes.\n\nos-brick patch: I56bf09cbd40679eefa5e378c9b36383de89e980c\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nChange-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33\n'}, {'number': 5, 'created': '2020-11-20 15:01:46.000000000', 'files': ['doc/source/configuration/index.rst', 'compute_hyperv/nova/cluster/volumeops.py', 'compute_hyperv/nova/volumeops.py', 'releasenotes/notes/rbd-support-9bb0037f69249785.yaml', 'doc/source/install/prerequisites.rst', 'compute_hyperv/nova/constants.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/81c7cf6c404c98b559ba48974c0cecba682ad396', 'message': 'rbd volume support\n\nCeph 16 (Pacific) will support attaching RBD images to Windows\nhosts as well as Hyper-V VMs [1].\n\nThis patch updates the Hyper-V driver so that it may be able to\nconsume RBD volumes.\n\nos-brick patch: I56bf09cbd40679eefa5e378c9b36383de89e980c\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint rbd-volumes\n\nChange-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33\n'}]",0,718399,81c7cf6c404c98b559ba48974c0cecba682ad396,18,2,5,8543,,,0,"rbd volume support

Ceph 16 (Pacific) will support attaching RBD images to Windows
hosts as well as Hyper-V VMs [1].

This patch updates the Hyper-V driver so that it may be able to
consume RBD volumes.

os-brick patch: I56bf09cbd40679eefa5e378c9b36383de89e980c

[1] https://github.com/ceph/ceph/pull/33750

Implements: blueprint rbd-volumes

Change-Id: I726e426a7274d7c9c6a878afddd23a20ce222a33
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/99/718399/4 && git format-patch -1 --stdout FETCH_HEAD,"['compute_hyperv/nova/cluster/volumeops.py', 'compute_hyperv/nova/volumeops.py', 'compute_hyperv/nova/constants.py']",3,8a893df175dabf9ec41edb9dcb86f9f77b8c5f3c,,STORAGE_PROTOCOL_RBD = 'rbd',,12,3
openstack%2Fsushy-tools~master~I5d5e526cedbdd70ea8ee8eaa8fe847baa72fc275,openstack/sushy-tools,master,I5d5e526cedbdd70ea8ee8eaa8fe847baa72fc275,Move some test requirements to tox.ini,MERGED,2021-01-22 08:49:09.000000000,2021-02-05 07:59:26.000000000,2021-02-05 07:57:39.000000000,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11292}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-22 08:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/41f514424d9d792783d7100fc95cd091651da3da', 'message': 'Move some test requirements to tox.ini\n\nSimplify requirements management.\n\nAlso increase minversion of tox to support inline comments [1]\n\nhttps://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17\n\nChange-Id: I5d5e526cedbdd70ea8ee8eaa8fe847baa72fc275\n'}, {'number': 2, 'created': '2021-01-25 09:16:24.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/0f7fc92a8ac4137b1883687707409d3dd7f90618', 'message': 'Move some test requirements to tox.ini\n\nSimplify requirements management.\n\nAlso increase minversion of tox to support inline comments [1]\n\nhttps://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17\n\nChange-Id: I5d5e526cedbdd70ea8ee8eaa8fe847baa72fc275\n'}]",0,771945,0f7fc92a8ac4137b1883687707409d3dd7f90618,13,4,2,23851,,,0,"Move some test requirements to tox.ini

Simplify requirements management.

Also increase minversion of tox to support inline comments [1]

https://tox.readthedocs.io/en/latest/changelog.html#v3-9-0-2019-04-17

Change-Id: I5d5e526cedbdd70ea8ee8eaa8fe847baa72fc275
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/45/771945/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,41f514424d9d792783d7100fc95cd091651da3da,tox-min-version-parse-comments,"minversion = 3.9.0deps = hacking>=3.1.0,<4.0.0 # Apache-2.0 flake8-import-order>=0.17.1 # LGPLv3 pycodestyle>=2.0.0,<2.7.0 # MITdeps = coverage!=4.4,>=4.0 # Apache-2.0",minversion = 3.2.1,7,6
openstack%2Fcompute-hyperv~master~I9e5f202bc66eae39dcb7c6b3247012b584a8a618,openstack/compute-hyperv,master,I9e5f202bc66eae39dcb7c6b3247012b584a8a618,Bump eventlet requirement,MERGED,2021-02-05 07:32:38.000000000,2021-02-05 07:51:06.000000000,2021-02-05 07:51:06.000000000,"[{'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 07:32:38.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/07c0f8b3c0c1c1ecce7c9fa64c0008e0bea554ed', 'message': ""Bump eventlet requirement\n\nNova has raised the eventlet minimum requirement to 0.26.1, which\nbreaks our lower constraints job.\n\nWe're going to use the same constraint.\n\nChange-Id: I9e5f202bc66eae39dcb7c6b3247012b584a8a618\n""}]",0,774200,07c0f8b3c0c1c1ecce7c9fa64c0008e0bea554ed,6,2,1,8543,,,0,"Bump eventlet requirement

Nova has raised the eventlet minimum requirement to 0.26.1, which
breaks our lower constraints job.

We're going to use the same constraint.

Change-Id: I9e5f202bc66eae39dcb7c6b3247012b584a8a618
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/00/774200/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,07c0f8b3c0c1c1ecce7c9fa64c0008e0bea554ed,,eventlet==0.26.1,eventlet==0.22.0,2,2
openstack%2Frequirements~master~I3eaa71b05031d516078ad1736caac34f1e3046bb,openstack/requirements,master,I3eaa71b05031d516078ad1736caac34f1e3046bb,update constraint for oslo.messaging to new release 12.7.0,MERGED,2021-02-04 18:13:18.000000000,2021-02-05 07:37:57.000000000,2021-02-05 05:42:54.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-04 18:13:18.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2f8d6b267e929e46e0f531da9273fe7f17c93176', 'message': 'update constraint for oslo.messaging to new release 12.7.0\n\nmeta: version: 12.7.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Commit: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I12a51cd877b28d42bfb3c735ac0744cbcb514250\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I3eaa71b05031d516078ad1736caac34f1e3046bb\n'}]",0,774139,2f8d6b267e929e46e0f531da9273fe7f17c93176,12,3,1,11131,,,0,"update constraint for oslo.messaging to new release 12.7.0

meta: version: 12.7.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Hervé Beraud <hberaud@redhat.com>
meta: release:Commit: Hervé Beraud <hberaud@redhat.com>
meta: release:Change-Id: I12a51cd877b28d42bfb3c735ac0744cbcb514250
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I3eaa71b05031d516078ad1736caac34f1e3046bb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/39/774139/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2f8d6b267e929e46e0f531da9273fe7f17c93176,new-release,oslo.messaging===12.7.0,oslo.messaging===12.6.1,1,1
openstack%2Fkeystone~master~I3b219bde569c5a8001aec0c243027b6881254304,openstack/keystone,master,I3b219bde569c5a8001aec0c243027b6881254304,Use enforce_new_defaults when setting up keystone protection tests,MERGED,2020-10-29 18:31:12.000000000,2021-02-05 06:47:39.000000000,2021-02-05 06:45:20.000000000,"[{'_account_id': 8482}, {'_account_id': 9954}, {'_account_id': 16465}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-29 18:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/74e77f73a3612c58e000a36c017aaaf4c4e1bcac', 'message': 'Use enforce_new_defaults when setting up tempest\n\nThe `keystone.conf [oslo_policy] enforce_new_defaults` option is meant\nto help deployments that want to opt into the new policy enforcement\nmodel (with scope checking) but without having to generate override\nfiles. This is the case for devstack and tempest.\n\nWe can use this to bypass generating a policy file with just the new\npolicies for tempest testing.\n\nChange-Id: I3b219bde569c5a8001aec0c243027b6881254304\n'}, {'number': 2, 'created': '2020-10-29 18:33:50.000000000', 'files': ['devstack/lib/scope.sh'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5d2f716e4be69e31cc48e326cb024aa18c83bbe9', 'message': 'Use enforce_new_defaults when setting up keystone protection tests\n\nThe `keystone.conf [oslo_policy] enforce_new_defaults` option is meant\nto help deployments that want to opt into the new policy enforcement\nmodel (with scope checking) but without having to generate override\nfiles. This is the case for devstack and tempest.\n\nWe can use this to bypass generating a policy file with just the new\npolicies for tempest testing.\n\nChange-Id: I3b219bde569c5a8001aec0c243027b6881254304\n'}]",0,760441,5d2f716e4be69e31cc48e326cb024aa18c83bbe9,15,5,2,5046,,,0,"Use enforce_new_defaults when setting up keystone protection tests

The `keystone.conf [oslo_policy] enforce_new_defaults` option is meant
to help deployments that want to opt into the new policy enforcement
model (with scope checking) but without having to generate override
files. This is the case for devstack and tempest.

We can use this to bypass generating a policy file with just the new
policies for tempest testing.

Change-Id: I3b219bde569c5a8001aec0c243027b6881254304
",git fetch https://review.opendev.org/openstack/keystone refs/changes/41/760441/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/scope.sh'],1,74e77f73a3612c58e000a36c017aaaf4c4e1bcac,functional-protection-tests, iniset $KEYSTONE_CONF oslo_policy enforce_new_defaults true, oslopolicy-policy-generator --namespace keystone > /etc/keystone/policy.yaml,1,1
openstack%2Frequirements~master~I661c200364b1ddf101b192d15061c847f6b73d86,openstack/requirements,master,I661c200364b1ddf101b192d15061c847f6b73d86,Updated from generate-constraints,ABANDONED,2021-02-05 06:30:52.000000000,2021-02-05 06:31:47.000000000,,[],"[{'number': 1, 'created': '2021-02-05 06:30:52.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8fbe7e5dbfd3e1f04cacd16d8ccf8e8be4de5e37', 'message': 'Updated from generate-constraints\n\nChange-Id: I661c200364b1ddf101b192d15061c847f6b73d86\n'}]",0,774196,8fbe7e5dbfd3e1f04cacd16d8ccf8e8be4de5e37,2,0,1,11131,,,0,"Updated from generate-constraints

Change-Id: I661c200364b1ddf101b192d15061c847f6b73d86
",git fetch https://review.opendev.org/openstack/requirements refs/changes/96/774196/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,8fbe7e5dbfd3e1f04cacd16d8ccf8e8be4de5e37,openstack/requirements/constraints,netmiko===3.3.3croniter===1.0.6pymongo===3.11.3pyghmi===1.5.22SQLAlchemy===1.3.23google-auth===1.25.0eventlet===0.30.1mock===4.0.3pylxd===2.3.0Jinja2===2.11.3boto3===1.17.2pifpaf===3.1.5cfn-lint===0.44.6pika===1.2.0uhashring===2.0botocore===1.20.2Django===2.2.18cmd2===1.5.0dulwich===0.20.18oslo.db===8.5.0oslo.policy===3.6.1hvac===0.10.7pkg-resources===0.0.0diskimage-builder===3.7.0alembic===1.5.4fasteners===0.16virtualenv===20.4.2 sshpubkeys===3.3.1pytz===2021.1,netmiko===3.3.2croniter===1.0.5pymongo===3.11.2pyghmi===1.5.21SQLAlchemy===1.3.22google-auth===1.24.0eventlet===0.30.0mock===3.0.5pylxd===2.2.11Jinja2===2.11.2boto3===1.16.63pifpaf===3.1.4cfn-lint===0.44.5pika===1.1.0uhashring===1.2botocore===1.19.63Django===2.2.17cmd2===1.4.0dulwich===0.20.15oslo.db===8.4.0oslo.policy===3.6.0hvac===0.10.6diskimage-builder===3.6.0alembic===1.5.3fasteners===0.14.1virtualenv===20.2.1 sshpubkeys===3.3.0pytz===2020.5setuptools===52.0.0,29,29
openstack%2Fopenstack-tempest-skiplist~master~I0dd08585c4449a0c9c2e7ef44cbb45cb9f4f17e6,openstack/openstack-tempest-skiplist,master,I0dd08585c4449a0c9c2e7ef44cbb45cb9f4f17e6,Adding TrafficOperationsScenarioTest to skip list master,MERGED,2021-02-04 12:52:13.000000000,2021-02-05 06:15:25.000000000,2021-02-04 13:15:31.000000000,"[{'_account_id': 8367}, {'_account_id': 9592}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 29775}]","[{'number': 1, 'created': '2021-02-04 12:52:13.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/7daacdd38e1f2443965b9218be823d3c3e64805e', 'message': ""Adding TrafficOperationsScenarioTest to skip list master\n\nThe test was removed recently because the ssh timeout issue was fixed,\nhowever, now it's failing to begin traffic on ports 60092 and 8085.\n\nRelated-Bug: #1914600\nChange-Id: I0dd08585c4449a0c9c2e7ef44cbb45cb9f4f17e6\n""}]",0,774079,7daacdd38e1f2443965b9218be823d3c3e64805e,14,5,1,8367,,,0,"Adding TrafficOperationsScenarioTest to skip list master

The test was removed recently because the ssh timeout issue was fixed,
however, now it's failing to begin traffic on ports 60092 and 8085.

Related-Bug: #1914600
Change-Id: I0dd08585c4449a0c9c2e7ef44cbb45cb9f4f17e6
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/79/774079/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,7daacdd38e1f2443965b9218be823d3c3e64805e,bug/1914600, - name: 'master' reason: 'port 60092/8085 did not begin passing traffic within the timeout period' lp: 'https://bugs.launchpad.net/tripleo/+bug/1914600',,3,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ice5e1cfbc158eb6705988706c8625bedb80d7de2,openstack/tripleo-heat-templates,stable/train,Ice5e1cfbc158eb6705988706c8625bedb80d7de2,Deprecate environments/dcn-hci.yaml for dcn-storage.yaml,MERGED,2021-02-03 20:52:32.000000000,2021-02-05 06:05:52.000000000,2021-02-05 06:02:02.000000000,"[{'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-02-03 20:52:32.000000000', 'files': ['releasenotes/notes/dcn-hci-storage-rename-0b1c17dd50f4cc9a.yaml', 'environments/dcn-hci.yaml', 'sample-env-generator/dcn.yaml', 'environments/dcn-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23014772070fa14e78007362d7093f2843a19fb9', 'message': 'Deprecate environments/dcn-hci.yaml for dcn-storage.yaml\n\nRename the file in the environments directory so that it\nreflects its expanded scope. This file is used when\ndeploying storage with DCN sites regardless of if those\nsites use HCI. We are now supporting non-HCI DCN sites\nwith storage so the old name is confusing.\n\nOld name : dcn-hci.yaml\nNew name : dcn-storage.yaml\n\ndcn-hci.yaml is depreacated but will remain in the environments\ndirectory for backwards compatibility. dcn-hci.yaml will be\nremoved during the X cycle.\n\nChange-Id: Ice5e1cfbc158eb6705988706c8625bedb80d7de2\n(cherry picked from commit d4ae25e2fd53d1af59fa57947843474cf5c2887a)\n(cherry picked from commit 8d0638ecac61681c54b657c02bf140401a416b3a)\n'}]",0,773957,23014772070fa14e78007362d7093f2843a19fb9,16,3,1,18002,,,0,"Deprecate environments/dcn-hci.yaml for dcn-storage.yaml

Rename the file in the environments directory so that it
reflects its expanded scope. This file is used when
deploying storage with DCN sites regardless of if those
sites use HCI. We are now supporting non-HCI DCN sites
with storage so the old name is confusing.

Old name : dcn-hci.yaml
New name : dcn-storage.yaml

dcn-hci.yaml is depreacated but will remain in the environments
directory for backwards compatibility. dcn-hci.yaml will be
removed during the X cycle.

Change-Id: Ice5e1cfbc158eb6705988706c8625bedb80d7de2
(cherry picked from commit d4ae25e2fd53d1af59fa57947843474cf5c2887a)
(cherry picked from commit 8d0638ecac61681c54b657c02bf140401a416b3a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/57/773957/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/dcn-hci-storage-rename-0b1c17dd50f4cc9a.yaml', 'environments/dcn-hci.yaml', 'sample-env-generator/dcn.yaml', 'environments/dcn-storage.yaml']",4,23014772070fa14e78007362d7093f2843a19fb9,dcn-storage-stable/victoria-stable/ussuri-stable/train,"# ******************************************************************* # This file was created automatically by the sample environment # generator. Developers should use `tox -e genconfig` to update it. # Users are recommended to make changes to a copy of the file instead # of the original, if any customizations are needed. # ******************************************************************* # title: Distributed Compute Node with storage # description: | # Environment file for deploying a remote site of distributed compute # nodes (DCN) in a separate stack (multi-stack) deployment with storage; # either HCI or with separate storage nodes. It should be used in # combination with environments/ceph-ansible/ceph-ansible.yaml. parameter_defaults: # When running Cinder A/A, whether to connect to Etcd via the local IP for the Etcd network. If set to true, the ip on the local node will be used. If set to false, the VIP on the Etcd network will be used instead. Defaults to false. # Type: boolean CinderEtcdLocalConnect: True # The Cinder service's storage availability zone. # Type: string CinderStorageAvailabilityZone: dcn # The cluster name used for deploying the cinder-volume service in an active-active (A/A) configuration. This configuration requires the Cinder backend drivers support A/A, and the cinder-volume service not be managed by pacemaker. If these criteria are not met then the cluster name must be left blank. # Type: string CinderVolumeCluster: dcn # Enable Glance Image Cache # Type: boolean GlanceCacheEnabled: False # The upper limit on cache size, in bytes, after which the cache-pruner cleans up the image cache. # Type: number GlanceImageCacheMaxSize: 10737418240 # Manage the network and related resources (subnets and segments) with either create, update, or delete operations (depending on the stack operation). Does not apply to ports which will always be managed as needed. Defaults to true. For multi-stack use cases where the network related resources have already been managed by a separate stack, this parameter can be set to false. # Type: boolean ManageNetworks: False # The availability zone where new Nova compute nodes will be added. If the zone does not already exist, it will be created. If left unset, it will default to the value of the stack name. # Type: string NovaComputeAvailabilityZone: '' # Whether instances can attach cinder volumes from a different availability zone. # Type: boolean NovaCrossAZAttach: False # Refuse to boot an instance if it would require downloading from glance and uploading to ceph instead of a COW clone. # Type: boolean NovaDisableImageDownloadToRbd: True resource_registry: OS::TripleO::Network::Ports::OVNDBsVipPort: ../network/ports/noop.yaml OS::TripleO::Network::Ports::RedisVipPort: ../network/ports/noop.yaml OS::TripleO::Services::CinderVolumeEdge: ../deployment/cinder/cinder-volume-container-puppet.yaml OS::TripleO::Services::Etcd: ../deployment/etcd/etcd-container-puppet.yaml OS::TripleO::Services::GlanceApiEdge: ../deployment/glance/glance-api-edge-container-puppet.yaml OS::TripleO::Services::HAproxyEdge: ../deployment/haproxy/haproxy-edge-container-puppet.yaml OS::TripleO::Services::NovaAZConfig: ../deployment/nova/nova-az-config.yaml ",,74,5
openstack%2Ftripleo-quickstart-extras~master~I8ae3f956b8ddf485f423403faa5b1fcc46409d8b,openstack/tripleo-quickstart-extras,master,I8ae3f956b8ddf485f423403faa5b1fcc46409d8b,Add ironic_network_interface opts undercloud.conf.j2,MERGED,2020-10-23 14:25:52.000000000,2021-02-05 06:02:37.000000000,2021-02-05 06:02:37.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-10-23 14:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/673a527987d84bfb559ad05cccf6af2de949b27e', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 2, 'created': '2020-10-29 11:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6c0c9ae0b0ea6966f175bf12e84547a133ad1e9c', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 3, 'created': '2020-11-09 12:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0d9d5ff4623b820cea9164a78244242d962e7fdc', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 4, 'created': '2020-11-14 00:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/909539f2aedaca321943db50f5cac8dbcf1d59fe', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 5, 'created': '2020-11-20 00:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/de67531cba0a590bdb74c68b6c15925701371a52', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 6, 'created': '2020-12-18 05:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/98befcd37c74cfa55263ea625e460f3b87ab5df6', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 7, 'created': '2021-01-07 07:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/074f2016427604b431646e6f3ec5bf9197f8f1f8', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}, {'number': 8, 'created': '2021-01-13 09:49:22.000000000', 'files': ['roles/undercloud-deploy/templates/undercloud.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/654484103e7cf5262e639d9091dd48a43493d5ed', 'message': 'Add ironic_network_interface opts undercloud.conf.j2\n\nAdds options:\n  ironic_default_network_interface\n  ironic_enabled_network_interfaces\n\nChange-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b\n'}]",0,759433,654484103e7cf5262e639d9091dd48a43493d5ed,53,7,8,24245,,,0,"Add ironic_network_interface opts undercloud.conf.j2

Adds options:
  ironic_default_network_interface
  ironic_enabled_network_interfaces

Change-Id: I8ae3f956b8ddf485f423403faa5b1fcc46409d8b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/33/759433/5 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud-deploy/templates/undercloud.conf.j2'],1,673a527987d84bfb559ad05cccf6af2de949b27e,ironic_network_interfaces,# Ironic network interface implementation to use by default. (string # value) # Possible values: # flat - Use one flat provider network. # neutron - Ironic interacts with Neutron to enable other network # types and advanced networking features. {% if undercloud_ironic_default_network_interface is defined %} ironic_default_network_interface = {{ undercloud_ironic_default_network_interface }} {% else %} #ironic_default_network_interface = flat {% endif %} # Enabled ironic network interface implementations. Each hardware type # must have at least one valid implementation enabled. (list value) {% if undercloud_ironic_enabled_network_interfaces is defined %} ironic_enabled_network_interfaces = {{ undercloud_ironic_enabled_network_interfaces }} {% else %} #ironic_enabled_network_interfaces = flat {% endif %} ,,20,0
openstack%2Ftripleo-validations~stable%2Ftrain~I73d2de81dfd0eba89aaee195f6f0d18adb9d364a,openstack/tripleo-validations,stable/train,I73d2de81dfd0eba89aaee195f6f0d18adb9d364a,Remove useless __init__.py file in library,MERGED,2021-01-21 11:26:45.000000000,2021-02-05 06:02:33.000000000,2021-02-05 06:02:33.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2021-01-21 11:26:45.000000000', 'files': ['library/__init__.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/8274f9c5681d5cc0b99d9d58b3159b69ad1f98a1', 'message': 'Remove useless __init__.py file in library\n\nSigned-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>\nChange-Id: I73d2de81dfd0eba89aaee195f6f0d18adb9d364a\n(cherry picked from commit 949cc1c18ea7c166b999fd0375f61b62f7e02340)\n(cherry picked from commit 3866628db31da0b2fb6d2a05a58422d283beee80)\n(cherry picked from commit 14bbbbce81916c55f983e87be736eec03e040d6f)\n'}]",0,771797,8274f9c5681d5cc0b99d9d58b3159b69ad1f98a1,14,7,1,11491,,,0,"Remove useless __init__.py file in library

Signed-off-by: Gael Chamoulaud (Strider) <gchamoul@redhat.com>
Change-Id: I73d2de81dfd0eba89aaee195f6f0d18adb9d364a
(cherry picked from commit 949cc1c18ea7c166b999fd0375f61b62f7e02340)
(cherry picked from commit 3866628db31da0b2fb6d2a05a58422d283beee80)
(cherry picked from commit 14bbbbce81916c55f983e87be736eec03e040d6f)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/97/771797/1 && git format-patch -1 --stdout FETCH_HEAD,['library/__init__.py'],1,8274f9c5681d5cc0b99d9d58b3159b69ad1f98a1,__init__dot_py-stable/train,,,0,0
openstack%2Ftripleo-quickstart-extras~master~I477644b085bd77407884bce25947be159bfc5c31,openstack/tripleo-quickstart-extras,master,I477644b085bd77407884bce25947be159bfc5c31,add validations playbook for VF component testing,MERGED,2020-09-30 19:47:57.000000000,2021-02-05 06:00:56.000000000,2021-02-05 06:00:56.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 11491}, {'_account_id': 16515}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}]","[{'number': 1, 'created': '2020-09-30 19:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/56c15d69aec0a134fafbf7cef9060ef15cb5adc6', 'message': 'add validations playbook for VF component testing\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 2, 'created': '2020-10-01 13:19:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3fa58ddaa41b030f27f2c291798f58eec261d443', 'message': 'add validations playbook for VF component testing\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 3, 'created': '2020-10-01 13:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/62161cc155e6fe5aa65d5406ada136f262b6fd2d', 'message': 'add validations playbook for VF component testing\n\nDepends-On: https://review.opendev.org/#/c/755311/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 4, 'created': '2020-10-02 12:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/edab004785ec08e29674af5d38893f2d5d3de046', 'message': 'add validations playbook for VF component testing\n\nDepends-On: https://review.opendev.org/#/c/755311/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 5, 'created': '2020-10-02 12:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2a572c030902353f317f3fe5c76d7d6e20975061', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755311/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 6, 'created': '2020-10-02 13:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/393c37bbdf83ca058906131f0a899ca3ce79fe8e', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755311/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 7, 'created': '2020-10-04 20:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7fcbbdfb1c69f153c20e2f030f1c1347a1568ea0', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755311/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 8, 'created': '2020-10-05 05:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8439a515a20035da6e2c9d252c5eeb294e0ec2ef', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755311/\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 9, 'created': '2020-10-05 12:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/46099cee01f8c6bd342e1f102aade49ecfdfab8d', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755311/\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 10, 'created': '2020-10-06 14:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a4a6b2e7b4af82a306c79cc7edc340122eb7831e', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/756328/\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 11, 'created': '2020-11-18 10:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f2a6cb9eabd81bf3067ad02eea99faa51156cdde', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 12, 'created': '2020-11-18 11:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/692470a00b1b0c07fdfdfd97ce8459f9a7bf1571', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 13, 'created': '2020-11-18 11:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7d77c8cc1cc1a20b25990c7ff27b373c5ba63779', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 14, 'created': '2020-12-03 17:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ea67053348c415d39b7765087df5ee830944cd9a', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 15, 'created': '2020-12-04 12:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/71dc2307c2cfb634cc3626e2a4afa94814944fa4', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 16, 'created': '2020-12-04 13:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/fe2b4e003433761effa72da9fdd2c332f7cb1ef1', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 17, 'created': '2020-12-06 20:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a2b415a74dd34f8fa465bbdf810efcb12ca586fc', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 18, 'created': '2020-12-07 17:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5e07c906ec9d2ec7f052cf90a1dc42a6805ab9be', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 19, 'created': '2020-12-07 21:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1983fcb3379c63e643a7b8b2cfe923acd8312c69', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 20, 'created': '2020-12-07 22:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c41c0523d67a9ab40075d72396525af323ec996e', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 21, 'created': '2020-12-08 11:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/47b2d14d58909093852dcf2254555a578f7581b2', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 22, 'created': '2020-12-08 13:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7a0f86aef392e2716ed776be0da6d16097b16f14', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 23, 'created': '2020-12-09 07:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ccaad8583ed4eeaa50e572bd0c25be99edaf4702', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 24, 'created': '2020-12-09 20:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/74c532e4170fa1dabfac70e83178ea9670c03e32', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nDepends-On: https://review.opendev.org/#/c/756328/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 25, 'created': '2021-01-04 10:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e0ee6e8da062bb8a9a81696832ddfd0085925e77', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 26, 'created': '2021-01-04 10:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e72a21179a97d96d0ed8920646e235d4dd7cbe59', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 27, 'created': '2021-01-11 14:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/66a6920265b3e20d0895bd02d3627736924943fc', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 28, 'created': '2021-01-11 17:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3603613a2971acde403097dd0866cfef23a16723', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 29, 'created': '2021-01-12 09:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/10c585622176337ef10cf34e46f2be61f0714f26', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/#/c/755390/\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 30, 'created': '2021-01-12 12:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/de254af0ade106b5bed8b0a658411e0d29a93350', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 31, 'created': '2021-01-13 07:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2fb10265d22ad14516143bc63c04742dc5401196', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-validations/+/770503\nDepends-On: https://review.opendev.org/c/openstack/tripleo-validations/+/770504\nDepends-On: https://review.opendev.org/c/openstack/tripleo-validations/+/770505\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 32, 'created': '2021-01-22 13:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8298cdc875d63db5c1786224fa26bae221f20507', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 33, 'created': '2021-01-25 14:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/338835f06c3566d164d3ba99aeac664af29c945d', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}, {'number': 34, 'created': '2021-02-04 09:09:46.000000000', 'files': ['playbooks/multinode-overcloud.yml', 'roles/tripleo-validations/meta/main.yml', 'playbooks/multinode-standalone.yml', 'roles/tripleo-validations/tasks/config.yml', 'roles/tripleo-validations/defaults/main.yml', 'playbooks/baremetal-full-overcloud.yml', 'roles/tripleo-validations/templates/run-preintro-validations-negative-tests.sh.j2', 'roles/tripleo-validations/README.md', 'playbooks/multinode-undercloud.yml', 'playbooks/quickstart-extras-overcloud-prep.yml', 'playbooks/multinode-overcloud-prep.yml', 'roles/tripleo-validations/templates/run-predep-validations-negative-tests.sh.j2', 'playbooks/baremetal-full-overcloud-prep.yml', 'playbooks/quickstart-extras-overcloud.yml', 'playbooks/validations.yml', 'playbooks/baremetal-full-undercloud.yml', 'roles/tripleo-validations/templates/run-tripleo-validations.sh.j2', 'roles/tripleo-validations/tasks/main.yml', 'roles/tripleo-validations/templates/run-postdep-validations-negative-tests.sh.j2', 'playbooks/multinode-multiple-overcloud.yml', 'playbooks/tripleo-validations.yml', 'playbooks/quickstart-extras-undercloud.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9fdfaa1250cd9ab6cba8592bf8c271014ed54cfe', 'message': 'add validations playbook for VF component testing\n\n* Removed legacy tripleo-validations role. The new roles will be\n  stored in tripleo-validations repo itself\n* Removed legacy playbooks tripleo-validations\n* Update multinode-undercloud playbook\n* Add validations playbook\n\nChange-Id: I477644b085bd77407884bce25947be159bfc5c31\n'}]",9,755382,9fdfaa1250cd9ab6cba8592bf8c271014ed54cfe,129,8,34,16515,,,0,"add validations playbook for VF component testing

* Removed legacy tripleo-validations role. The new roles will be
  stored in tripleo-validations repo itself
* Removed legacy playbooks tripleo-validations
* Update multinode-undercloud playbook
* Add validations playbook

Change-Id: I477644b085bd77407884bce25947be159bfc5c31
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/82/755382/11 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/validations.yml'],1,56c15d69aec0a134fafbf7cef9060ef15cb5adc6,ci/validation,--- - name Execute pre undercloud validations hosts: undercloud gather_facts: true tags: - component-validation roles: - validations ,,8,0
openstack%2Frequirements~master~I52189c3792a5302531aa3b3e744a77f34682585d,openstack/requirements,master,I52189c3792a5302531aa3b3e744a77f34682585d,update constraint for oslo.policy to new release 3.6.1,ABANDONED,2021-02-02 17:39:34.000000000,2021-02-05 05:53:23.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-02 17:39:34.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/24712d38d91e3599b0e1c03ca6c3d30a20315fc0', 'message': 'update constraint for oslo.policy to new release 3.6.1\n\nmeta: version: 3.6.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Slawek Kaplonski <skaplons@redhat.com>\nmeta: release:Commit: Slawek Kaplonski <skaplons@redhat.com>\nmeta: release:Change-Id: Ic312679976481e3082f3523e2c0058b02dd77bf8\nmeta: release:Code-Review+1: Lance Bragstad <lbragstad@redhat.com>\nmeta: release:Code-Review+1: Ghanshyam <gmann@ghanshyammann.com>\nmeta: release:Code-Review+1: Oleg Bondarev <oleg.bondarev@huawei.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I52189c3792a5302531aa3b3e744a77f34682585d\n'}]",0,773779,24712d38d91e3599b0e1c03ca6c3d30a20315fc0,12,3,1,11131,,,0,"update constraint for oslo.policy to new release 3.6.1

meta: version: 3.6.1
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Slawek Kaplonski <skaplons@redhat.com>
meta: release:Commit: Slawek Kaplonski <skaplons@redhat.com>
meta: release:Change-Id: Ic312679976481e3082f3523e2c0058b02dd77bf8
meta: release:Code-Review+1: Lance Bragstad <lbragstad@redhat.com>
meta: release:Code-Review+1: Ghanshyam <gmann@ghanshyammann.com>
meta: release:Code-Review+1: Oleg Bondarev <oleg.bondarev@huawei.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I52189c3792a5302531aa3b3e744a77f34682585d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/773779/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,24712d38d91e3599b0e1c03ca6c3d30a20315fc0,new-release,oslo.policy===3.6.1,oslo.policy===3.6.0,1,1
openstack%2Fkeystone~master~I42f0abc2ddf8c53239d5098d5f32b667314b942d,openstack/keystone,master,I42f0abc2ddf8c53239d5098d5f32b667314b942d,Ignore oslo.db deprecating sqlalchemy-migrate warning,MERGED,2020-10-31 00:36:49.000000000,2021-02-05 05:44:39.000000000,2021-02-05 05:43:03.000000000,"[{'_account_id': 5046}, {'_account_id': 16465}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-31 00:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9877c0434d83753102e9f89005660537ac687211', 'message': 'Ignore oslo.db deprecating sqlalchemy-migrate warning\n\nIn I59335b4f318bae2e29ab139cdea089a4d6e14305, oslo.db\nis now emitting deprecation warnings for SQLAlchemy-migrate\nfunctions.  This breaks Keystone tests which raise on\nDeprecationWarning, so add to the filters.\n\nChange-Id: I42f0abc2ddf8c53239d5098d5f32b667314b942d\n'}, {'number': 2, 'created': '2021-01-26 17:34:17.000000000', 'files': ['keystone/tests/unit/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/11cfc38df1d3f24e8f1b19f58372f6b8386270d9', 'message': 'Ignore oslo.db deprecating sqlalchemy-migrate warning\n\nIn I59335b4f318bae2e29ab139cdea089a4d6e14305, oslo.db\nis now emitting deprecation warnings for SQLAlchemy-migrate\nfunctions.  This breaks Keystone tests which raise on\nDeprecationWarning, so add to the filters.\n\nChange-Id: I42f0abc2ddf8c53239d5098d5f32b667314b942d\n'}]",2,760678,11cfc38df1d3f24e8f1b19f58372f6b8386270d9,16,4,2,11816,,,0,"Ignore oslo.db deprecating sqlalchemy-migrate warning

In I59335b4f318bae2e29ab139cdea089a4d6e14305, oslo.db
is now emitting deprecation warnings for SQLAlchemy-migrate
functions.  This breaks Keystone tests which raise on
DeprecationWarning, so add to the filters.

Change-Id: I42f0abc2ddf8c53239d5098d5f32b667314b942d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/78/760678/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/core.py'],1,9877c0434d83753102e9f89005660537ac687211,ignore_oslodb_warning," warnings.filterwarnings( 'ignore', category=DeprecationWarning, message=r""Using function/method 'db_version\(\)' is deprecated"")",,4,0
openstack%2Fnova~stable%2Fussuri~Ica180165184b319651d22fe77e076af036228860,openstack/nova,stable/ussuri,Ica180165184b319651d22fe77e076af036228860,Set instance host and drop migration under lock,MERGED,2021-01-14 09:56:31.000000000,2021-02-05 05:43:58.000000000,2021-02-05 05:42:16.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-14 09:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06f74d26295f7308d7f7022d8dd7dd222ee85ae3', 'message': 'Set instance host and drop migration under lock\n\nThe _update_available_resources periodic makes resource allocation\nadjustments while holding the COMPUTE_RESOURCE_SEMAPHORE based on the\nlist of instances assigned to this host of the resource tracker and\nbased on the migrations where the source or the target host is the host\nof the resource tracker. So if the instance.host or the migration\ncontext changes without holding the COMPUTE_RESOURCE_SEMAPHORE while\nthe _update_available_resources task is running there there will be data\ninconsistency in the resource tracker.\n\nThis patch makes sure that during evacuation the instance.host and the\nmigration context is changed while holding the semaphore.\n\nConflicts:\n      nova/tests/unit/compute/test_compute_mgr.py due to\n  I147bf4d95e6d86ff1f967a8ce37260730f21d236 is not in stable/ussuri\n\nChange-Id: Ica180165184b319651d22fe77e076af036228860\nCloses-Bug: #1896463\n(cherry picked from commit 7675964af81472f3dd57db952d704539e61a3e6e)\n(cherry picked from commit 3ecc098d28addd8f3e1da16b29940f4337209e62)\n'}, {'number': 2, 'created': '2021-01-29 16:29:52.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1896463.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3b497ad7d41bc84ec50124c4d55f4138c4878751', 'message': 'Set instance host and drop migration under lock\n\nThe _update_available_resources periodic makes resource allocation\nadjustments while holding the COMPUTE_RESOURCE_SEMAPHORE based on the\nlist of instances assigned to this host of the resource tracker and\nbased on the migrations where the source or the target host is the host\nof the resource tracker. So if the instance.host or the migration\ncontext changes without holding the COMPUTE_RESOURCE_SEMAPHORE while\nthe _update_available_resources task is running there there will be data\ninconsistency in the resource tracker.\n\nThis patch makes sure that during evacuation the instance.host and the\nmigration context is changed while holding the semaphore.\n\nConflicts:\n      nova/tests/unit/compute/test_compute_mgr.py due to\n  I147bf4d95e6d86ff1f967a8ce37260730f21d236 is not in stable/ussuri\n\nChange-Id: Ica180165184b319651d22fe77e076af036228860\nCloses-Bug: #1896463\n(cherry picked from commit 7675964af81472f3dd57db952d704539e61a3e6e)\n(cherry picked from commit 3ecc098d28addd8f3e1da16b29940f4337209e62)\n'}]",0,770769,3b497ad7d41bc84ec50124c4d55f4138c4878751,23,3,2,9708,,,0,"Set instance host and drop migration under lock

The _update_available_resources periodic makes resource allocation
adjustments while holding the COMPUTE_RESOURCE_SEMAPHORE based on the
list of instances assigned to this host of the resource tracker and
based on the migrations where the source or the target host is the host
of the resource tracker. So if the instance.host or the migration
context changes without holding the COMPUTE_RESOURCE_SEMAPHORE while
the _update_available_resources task is running there there will be data
inconsistency in the resource tracker.

This patch makes sure that during evacuation the instance.host and the
migration context is changed while holding the semaphore.

Conflicts:
      nova/tests/unit/compute/test_compute_mgr.py due to
  I147bf4d95e6d86ff1f967a8ce37260730f21d236 is not in stable/ussuri

Change-Id: Ica180165184b319651d22fe77e076af036228860
Closes-Bug: #1896463
(cherry picked from commit 7675964af81472f3dd57db952d704539e61a3e6e)
(cherry picked from commit 3ecc098d28addd8f3e1da16b29940f4337209e62)
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/770769/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1896463.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py']",4,06f74d26295f7308d7f7022d8dd7dd222ee85ae3,bug/1896463," @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE, fair=True) def finish_evacuation(self, instance, node, migration): instance.apply_migration_context() # NOTE (ndipanov): This save will now update the host and node # attributes making sure that next RT pass is consistent since # it will be based on the instance and not the migration DB # entry. instance.host = self.host instance.node = node instance.save() instance.drop_migration_context() # NOTE (ndipanov): Mark the migration as done only after we # mark the instance as belonging to this host. if migration: migration.status = 'done' migration.save()",,40,37
openstack%2Fpuppet-horizon~stable%2Fqueens~I121a4ad2070cfef173c572a3d25788abbbf16989,openstack/puppet-horizon,stable/queens,I121a4ad2070cfef173c572a3d25788abbbf16989,"update ""DROPDOWN_MAX_ITEMS"" horizon parameter as a variable",MERGED,2020-04-24 16:20:12.000000000,2021-02-05 05:09:26.000000000,2021-02-05 05:08:22.000000000,"[{'_account_id': 3153}, {'_account_id': 8648}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 22420}]","[{'number': 1, 'created': '2020-04-24 16:20:12.000000000', 'files': ['releasenotes/notes/add-dropdown_max_items-38ea8e64152d76e5.yaml', 'templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/83b6d1b325f2223c1f096b4da022ce4ec944b2d3', 'message': 'update ""DROPDOWN_MAX_ITEMS"" horizon parameter as a variable\n\n""DROPDOWN_MAX_ITEMS"" horizon parameter was hardcoded in a ruby\ntemplate. Hence, it was not possible to manage it using heat.\nThis fix will allow user to manage ""DROPDOWN_MAX_ITEMS"" from\nheat template.\n\nChange-Id: I121a4ad2070cfef173c572a3d25788abbbf16989\nCloses-Bug: #1813786\n(cherry picked from commit 004142d577a1388244b19b2869797a4653b46bed)\n'}]",0,722930,83b6d1b325f2223c1f096b4da022ce4ec944b2d3,16,6,1,8648,,,0,"update ""DROPDOWN_MAX_ITEMS"" horizon parameter as a variable

""DROPDOWN_MAX_ITEMS"" horizon parameter was hardcoded in a ruby
template. Hence, it was not possible to manage it using heat.
This fix will allow user to manage ""DROPDOWN_MAX_ITEMS"" from
heat template.

Change-Id: I121a4ad2070cfef173c572a3d25788abbbf16989
Closes-Bug: #1813786
(cherry picked from commit 004142d577a1388244b19b2869797a4653b46bed)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/30/722930/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-dropdown_max_items-38ea8e64152d76e5.yaml', 'templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",4,83b6d1b325f2223c1f096b4da022ce4ec944b2d3,queens/bug1813786," 'DROPDOWN_MAX_ITEMS = 30', :dropdown_max_items => 123, 'DROPDOWN_MAX_ITEMS = 123',",,15,1
openstack%2Fneutron~master~I5b5cf563f0c3d6ea352303f76323177cffc57c6e,openstack/neutron,master,I5b5cf563f0c3d6ea352303f76323177cffc57c6e,Fix losses of ovs flows when ovs is restarted,MERGED,2021-01-29 18:26:23.000000000,2021-02-05 04:49:51.000000000,2021-02-05 01:58:11.000000000,"[{'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-29 18:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40f97111cc13a64cda2f41d1b2c6b7a57505b435', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager wehn OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n'}, {'number': 2, 'created': '2021-02-02 13:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/75460e5716af8b7eeb8e9a4d76e29464900d8bd7', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n'}, {'number': 3, 'created': '2021-02-02 13:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e40a6c74a43aa1574641d1283dc26f564c91c3c', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n'}, {'number': 4, 'created': '2021-02-03 14:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee80a7e420ef44ab24f402ebea27126d7d3eacd6', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n'}, {'number': 5, 'created': '2021-02-03 14:27:39.000000000', 'files': ['neutron/agent/linux/openvswitch_firewall/firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/412160b97fc398f105c3f7386b928eeec2d9e60a', 'message': 'Fix losses of ovs flows when ovs is restarted\n\nReinitialize conj_ip_manager when OVS is restarted.\n\nCloses-Bug: #1912651\nChange-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e\n'}]",3,773165,412160b97fc398f105c3f7386b928eeec2d9e60a,53,5,5,13095,,,0,"Fix losses of ovs flows when ovs is restarted

Reinitialize conj_ip_manager when OVS is restarted.

Closes-Bug: #1912651
Change-Id: I5b5cf563f0c3d6ea352303f76323177cffc57c6e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/773165/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/openvswitch_firewall/firewall.py'],1,40f97111cc13a64cda2f41d1b2c6b7a57505b435,bug-1912651, self.conj_ip_manager = ConjIPFlowManager(self),,1,0
openstack%2Ffreezer~master~I850f92470380de21b91406eda28ca01339b61d43,openstack/freezer,master,I850f92470380de21b91406eda28ca01339b61d43,add test_stopstate_abort for unit test,MERGED,2021-02-05 03:07:13.000000000,2021-02-05 04:23:08.000000000,2021-02-05 04:21:58.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 03:07:13.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/50885c1041c5ad4fa304d84dc009ba91c8801545', 'message': 'add test_stopstate_abort for unit test\n\nChange-Id: I850f92470380de21b91406eda28ca01339b61d43\n'}]",0,774188,50885c1041c5ad4fa304d84dc009ba91c8801545,7,2,1,21387,,,0,"add test_stopstate_abort for unit test

Change-Id: I850f92470380de21b91406eda28ca01339b61d43
",git fetch https://review.opendev.org/openstack/freezer refs/changes/88/774188/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,50885c1041c5ad4fa304d84dc009ba91c8801545,improveUTC," def test_stopstate_abort(self): result = scheduler_job.StopState.abort(self.job, self.jobdoc) self.assertEqual(result, '') def test_stopstate_start(self): result = scheduler_job.StopState.start(self.job, self.jobdoc) self.assertEqual(result, '')",,8,0
openstack%2Ftempest~master~I78076ebb0fc955662b5ee3f67938f9fc939882d3,openstack/tempest,master,I78076ebb0fc955662b5ee3f67938f9fc939882d3,Make _log_console_output non-private,MERGED,2021-01-29 12:48:09.000000000,2021-02-05 04:14:53.000000000,2021-02-05 04:12:33.000000000,"[{'_account_id': 5689}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 9592}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-01-29 12:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/53a5b4898785d073fa1e8780835242f58709fd01', 'message': 'Need to make certain apis non-private\n\n_log_console_output() is currently private\nwhich is not necessarily required to be private\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}, {'number': 2, 'created': '2021-02-03 10:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9df8653e54d77ef20d61e9ed8e7a681fc6814d8c', 'message': 'Make _log_console_output non-private\n\n_log_console_output is made public by this commit as\nthe tempest.scenario.manager interface is meant to be\nconsumed by tempest plugins.\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}, {'number': 3, 'created': '2021-02-03 12:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d2cc7d90b77ab3a2175e513b8d426c646039970f', 'message': 'Make _log_console_output non-private\n\n_log_console_output is made public by this commit as\nthe tempest.scenario.manager interface is meant to be\nconsumed by tempest plugins.\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}, {'number': 4, 'created': '2021-02-03 22:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/050a787d5b1e0cd1033990f306773e83075914e1', 'message': 'Make _log_console_output non-private\n\n_log_console_output is made public by this commit as\nthe tempest.scenario.manager interface is meant to be\nconsumed by tempest plugins.\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}, {'number': 5, 'created': '2021-02-04 07:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/392a4cc1e1d0d48aa980a8967a68d55130a07f7a', 'message': 'Make _log_console_output non-private\n\n_log_console_output is made public by this commit as\nthe tempest.scenario.manager interface is meant to be\nconsumed by tempest plugins.\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}, {'number': 6, 'created': '2021-02-04 16:39:05.000000000', 'files': ['releasenotes/notes/log_console_output-dae6b8740b5a5821.yaml', 'tempest/scenario/manager.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_security_groups_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1b0cddc90df0d0736e1d7ae63feef3b801ffdbe1', 'message': 'Make _log_console_output non-private\n\n_log_console_output is made public by this commit as\nthe tempest.scenario.manager interface is meant to be\nconsumed by tempest plugins.\n\nImplements: blueprint tempest-scenario-manager-stable\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3\n'}]",7,773019,1b0cddc90df0d0736e1d7ae63feef3b801ffdbe1,31,7,6,30742,,,0,"Make _log_console_output non-private

_log_console_output is made public by this commit as
the tempest.scenario.manager interface is meant to be
consumed by tempest plugins.

Implements: blueprint tempest-scenario-manager-stable
Signed-off by: Soniya Vyas<svyas@redhat.com>

Change-Id: I78076ebb0fc955662b5ee3f67938f9fc939882d3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/19/773019/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_security_groups_basic_ops.py']",3,53a5b4898785d073fa1e8780835242f58709fd01,bp/tempest-scenario-manager-stable," self.log_console_output(servers=tenant.servers, client=client) if tenant.access_point is not None: self.log_console_output("," self._log_console_output(servers=tenant.servers, client=client) if tenant.access_point is not None: self._log_console_output(",5,5
openstack%2Fos-brick~master~Ied220a5a5cb61afb3e76d5e61594bf38bffa89cc,openstack/os-brick,master,Ied220a5a5cb61afb3e76d5e61594bf38bffa89cc,fcsan: fix a potential racing when resizing,ABANDONED,2021-02-05 00:50:15.000000000,2021-02-05 03:11:40.000000000,,[],"[{'number': 1, 'created': '2021-02-05 00:50:15.000000000', 'files': ['os_brick/initiator/connectors/fibre_channel.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/85da7dc3e551f33876d27ccee816574d9364edc6', 'message': 'fcsan: fix a potential racing when resizing\n\nmultipathd reconfigure might re-introduce previous flushed\ndevices which might cause dangling dm on host\n\nChange-Id: Ied220a5a5cb61afb3e76d5e61594bf38bffa89cc\nRelated-Bug: #1914671\n'}]",0,774180,85da7dc3e551f33876d27ccee816574d9364edc6,3,0,1,29071,,,0,"fcsan: fix a potential racing when resizing

multipathd reconfigure might re-introduce previous flushed
devices which might cause dangling dm on host

Change-Id: Ied220a5a5cb61afb3e76d5e61594bf38bffa89cc
Related-Bug: #1914671
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/80/774180/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/initiator/connectors/fibre_channel.py'],1,85da7dc3e551f33876d27ccee816574d9364edc6,bug/1914671, flushed = False flushed = True # avoid a potential racing with `multipathd reconfigure` # only flush if it has been flushed before if mpath_path and flushed: mpath_path = self._linuxscsi.find_multipath_device_path(wwn) if mpath_path: self._linuxscsi.flush_multipath_device(mpath_path) ,,9,0
openstack%2Ffreezer~master~I1abb4eca21a19ee810cf3017116eaf446b94af8b,openstack/freezer,master,I1abb4eca21a19ee810cf3017116eaf446b94af8b,add test_stopstate_stop for unit test,MERGED,2021-02-05 01:48:14.000000000,2021-02-05 02:56:37.000000000,2021-02-05 02:55:08.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 01:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e6977054469261df149a1736ba9782aa5b2b4678', 'message': 'add test_terminate_subprocess1 for unit test\n\nChange-Id: I1abb4eca21a19ee810cf3017116eaf446b94af8b\n'}, {'number': 2, 'created': '2021-02-05 01:51:28.000000000', 'files': ['freezer/tests/unit/scheduler/test_scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/04023a00920e000c7d598677214454494b037575', 'message': 'add test_stopstate_stop for unit test\n\nChange-Id: I1abb4eca21a19ee810cf3017116eaf446b94af8b\n'}]",0,774183,04023a00920e000c7d598677214454494b037575,8,2,2,21387,,,0,"add test_stopstate_stop for unit test

Change-Id: I1abb4eca21a19ee810cf3017116eaf446b94af8b
",git fetch https://review.opendev.org/openstack/freezer refs/changes/83/774183/2 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_scheduler_job.py'],1,e6977054469261df149a1736ba9782aa5b2b4678,,"from unittest import mock class TestSchedulerJob1(unittest.TestCase): def setUp(self): self.scheduler = mock.MagicMock() self.job_schedule = {""event"": ""start"", ""status"": ""start"", ""schedule_day"": ""1""} self.jobdoc = {""job_id"": ""test"", ""job_schedule"": self.job_schedule} self.job = scheduler_job.Job(self.scheduler, None, self.jobdoc) def test_stopstate_stop(self): result = scheduler_job.StopState.stop(self.job, self.jobdoc) self.assertEqual(result, '')",,14,0
openstack%2Fpuppet-openstack-integration~stable%2Fqueens~I06f40a32038bd9b76d174ef2b9c3635c7a25350f,openstack/puppet-openstack-integration,stable/queens,I06f40a32038bd9b76d174ef2b9c3635c7a25350f,Make puppet-openstack-beaker-xenial non-voting,MERGED,2021-02-02 14:32:19.000000000,2021-02-05 02:52:46.000000000,2021-02-05 02:52:46.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 14:32:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8ee9d6a6e35a121bef62e9a559e647595deed626', 'message': 'Make puppet-openstack-beaker-xenial non-voting\n\nThis change makes the broken job non-voting to unblock backports to\nqueens. We have integration tests and beaker tests for CentOS so basic\nfunctionality is tested by the other jobs.\n\nChange-Id: I06f40a32038bd9b76d174ef2b9c3635c7a25350f\n'}]",0,773693,8ee9d6a6e35a121bef62e9a559e647595deed626,7,6,1,9816,,,0,"Make puppet-openstack-beaker-xenial non-voting

This change makes the broken job non-voting to unblock backports to
queens. We have integration tests and beaker tests for CentOS so basic
functionality is tested by the other jobs.

Change-Id: I06f40a32038bd9b76d174ef2b9c3635c7a25350f
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/93/773693/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,8ee9d6a6e35a121bef62e9a559e647595deed626,xenial-beaker-nonvoting, voting: false,,1,0
openstack%2Frequirements~master~I95f27566440c659d6504da156bdaed69836c3a91,openstack/requirements,master,I95f27566440c659d6504da156bdaed69836c3a91,update constraint for sushy to new release 3.6.1,MERGED,2021-02-04 12:08:01.000000000,2021-02-05 02:47:27.000000000,2021-02-05 02:45:17.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-04 12:08:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2b4c67254e2175d2e7b9cf0114f11fbc690606ea', 'message': 'update constraint for sushy to new release 3.6.1\n\nmeta: version: 3.6.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Bill Dodd <billdodd@gmail.com>\nmeta: release:Commit: Bill Dodd <billdodd@gmail.com>\nmeta: release:Change-Id: I3a9da98c363fc9322d6f13ce600be1ebfd5b7ed6\nmeta: release:Code-Review+1: Dmitry Tantsur <dtantsur@protonmail.com>\nmeta: release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I95f27566440c659d6504da156bdaed69836c3a91\n'}]",0,774074,2b4c67254e2175d2e7b9cf0114f11fbc690606ea,12,3,1,11131,,,0,"update constraint for sushy to new release 3.6.1

meta: version: 3.6.1
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Bill Dodd <billdodd@gmail.com>
meta: release:Commit: Bill Dodd <billdodd@gmail.com>
meta: release:Change-Id: I3a9da98c363fc9322d6f13ce600be1ebfd5b7ed6
meta: release:Code-Review+1: Dmitry Tantsur <dtantsur@protonmail.com>
meta: release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I95f27566440c659d6504da156bdaed69836c3a91
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/774074/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2b4c67254e2175d2e7b9cf0114f11fbc690606ea,new-release,sushy===3.6.1,sushy===3.6.0,1,1
openstack%2Fswift~master~I3315f349e5b965cecadc78af9e1c66c3f3bcfe83,openstack/swift,master,I3315f349e5b965cecadc78af9e1c66c3f3bcfe83,Do not delete root_path on ContainerBroker.delete_db,MERGED,2021-02-03 05:44:15.000000000,2021-02-05 02:47:17.000000000,2021-02-05 02:45:20.000000000,"[{'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 05:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bad6ab686c7fd0cbab8cf70f5583a56b695677be', 'message': ""Do not delete root_path on ContainerBroker.delete_db\n\nWhen a shard is deleted all the sysmeta is deleted along with it. But\nthis is problematic as we support dealing with misplaced objects in deleted\nshards. Which is required.\n\nCurrently, when we deal with misplaced objects in shard a broker marked as\ndeleted we push the objects into a handoff broker and set this brokers\nroot_path attribute from the deleted shard. Unfortunately, root_path\nis itself stored in sysmeta, which has been removed. So instead it falls\nback to using it's own account and container in the root_path.\nThis in turn gets pushed to the shard responsible for the misplaced\nobjects and because these objects are pushed by replication the\nroot_path meta has a newer timestamp, replacing the shards pointer to\nthe root.\n\nAs a consequence listings all still works because it's root driven, but\nthe shard will never pull the latest shard range details from the _real_\nroot container during audits.\n\nThis patch contains a probe test that demonstrates this issue and also\nfixes it my making 'X-Container-Sysmeta-Shard-Quoted-Root' and\n'X-Container-Sysmeta-Shard-Root' whitelisted from being cleared on\ndelete. Meaning a deleted shard retains it's knowledge of root so\nit can correctly deal with misplaced objects.\n\nChange-Id: I3315f349e5b965cecadc78af9e1c66c3f3bcfe83\n""}, {'number': 2, 'created': '2021-02-04 02:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6b3e6a8afe51e9ec919f85507ba032d50b410e5c', 'message': ""Do not delete root_path on ContainerBroker.delete_db\n\nWhen a shard is deleted all the sysmeta is deleted along with it. But\nthis is problematic as we support dealing with misplaced objects in deleted\nshards. Which is required.\n\nCurrently, when we deal with misplaced objects in shard a broker marked as\ndeleted we push the objects into a handoff broker and set this brokers\nroot_path attribute from the deleted shard. Unfortunately, root_path\nis itself stored in sysmeta, which has been removed. So instead it falls\nback to using it's own account and container in the root_path.\nThis in turn gets pushed to the shard responsible for the misplaced\nobjects and because these objects are pushed by replication the\nroot_path meta has a newer timestamp, replacing the shards pointer to\nthe root.\n\nAs a consequence listings all still works because it's root driven, but\nthe shard will never pull the latest shard range details from the _real_\nroot container during audits.\n\nThis patch contains a probe test that demonstrates this issue and also\nfixes it my making 'X-Container-Sysmeta-Shard-Quoted-Root' and\n'X-Container-Sysmeta-Shard-Root' whitelisted from being cleared on\ndelete. Meaning a deleted shard retains it's knowledge of root so\nit can correctly deal with misplaced objects.\n\nChange-Id: I3315f349e5b965cecadc78af9e1c66c3f3bcfe83\n""}, {'number': 3, 'created': '2021-02-04 10:36:03.000000000', 'files': ['swift/common/db.py', 'test/probe/test_sharder.py', 'test/unit/common/test_db.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/6c62c8d07254fc28f6d3e1cc8a3837a16b02e57d', 'message': ""Do not delete root_path on ContainerBroker.delete_db\n\nWhen a shard is deleted all the sysmeta is deleted along with it. But\nthis is problematic as we support dealing with misplaced objects in\ndeleted shards. Which is required.\n\nCurrently, when we deal with misplaced objects in a shard broker\nmarked as deleted we push the objects into a handoff broker and set\nthis broker's root_path attribute from the deleted shard.\nUnfortunately, root_path is itself stored in sysmeta, which has been\nremoved. So the deleted broker falls back to using its own account and\ncontainer in the root_path.  This in turn gets pushed to the shard\nresponsible for the misplaced objects and because these objects are\npushed by replication the root_path meta has a newer timestamp,\nreplacing the shard's pointer to the root.\n\nAs a consequence listings all still works because it's root driven,\nbut the shard will never pull the latest shard range details from the\n_real_ root container during audits.\n\nThis patch contains a probe test that demonstrates this issue and also\nfixes it by making 'X-Container-Sysmeta-Shard-Quoted-Root' and\n'X-Container-Sysmeta-Shard-Root' whitelisted from being cleared on\ndelete. Meaning a deleted shard retains it's knowledge of root so it\ncan correctly deal with misplaced objects.\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I3315f349e5b965cecadc78af9e1c66c3f3bcfe83\n""}]",25,773832,6c62c8d07254fc28f6d3e1cc8a3837a16b02e57d,19,3,3,7233,,,0,"Do not delete root_path on ContainerBroker.delete_db

When a shard is deleted all the sysmeta is deleted along with it. But
this is problematic as we support dealing with misplaced objects in
deleted shards. Which is required.

Currently, when we deal with misplaced objects in a shard broker
marked as deleted we push the objects into a handoff broker and set
this broker's root_path attribute from the deleted shard.
Unfortunately, root_path is itself stored in sysmeta, which has been
removed. So the deleted broker falls back to using its own account and
container in the root_path.  This in turn gets pushed to the shard
responsible for the misplaced objects and because these objects are
pushed by replication the root_path meta has a newer timestamp,
replacing the shard's pointer to the root.

As a consequence listings all still works because it's root driven,
but the shard will never pull the latest shard range details from the
_real_ root container during audits.

This patch contains a probe test that demonstrates this issue and also
fixes it by making 'X-Container-Sysmeta-Shard-Quoted-Root' and
'X-Container-Sysmeta-Shard-Root' whitelisted from being cleared on
delete. Meaning a deleted shard retains it's knowledge of root so it
can correctly deal with misplaced objects.

Co-Authored-By: Alistair Coles <alistairncoles@gmail.com>
Change-Id: I3315f349e5b965cecadc78af9e1c66c3f3bcfe83
",git fetch https://review.opendev.org/openstack/swift refs/changes/32/773832/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/db.py', 'test/probe/test_sharder.py', 'test/unit/container/test_backend.py', 'swift/container/backend.py']",4,bad6ab686c7fd0cbab8cf70f5583a56b695677be,delete_db_keeps_root_path," delete_meta_whitelist = ['X-Container-Sysmeta-Shard-Quoted-Root', 'X-Container-Sysmeta-Shard-Root']",,128,0
openstack%2Fkeystone~master~Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b,openstack/keystone,master,Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b,[goal] Deprecate the JSON formatted policy file,MERGED,2020-11-25 20:35:48.000000000,2021-02-05 02:01:04.000000000,2021-02-05 01:58:21.000000000,"[{'_account_id': 5046}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 20:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/599db5cfa57376c421f34112d7d22bd9fd5484c1', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 2, 'created': '2020-11-26 00:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/472558d36f38870de9a2a90d945cdf0b66891a9d', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 3, 'created': '2020-11-26 19:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7e142fec37b46577a24d65efd145c62d017abb15', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 4, 'created': '2020-11-27 02:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d7a7b7d83f3360afb6ed6dc0358ff2cce21944a', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 5, 'created': '2020-11-27 04:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a6398b20ec4158d87cf8289c1bd2faf42abb3c4e', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 6, 'created': '2020-12-12 22:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bcc8bbd4864389950c76f6f571768c7bdc40d311', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 7, 'created': '2020-12-12 23:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e4b03e11b09e344bfecc2b1214e377b2f613cb63', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 8, 'created': '2021-01-14 22:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9284aa015281c56e9da0481a9283ab06cc0a573c', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}, {'number': 9, 'created': '2021-02-01 17:36:29.000000000', 'files': ['doc/source/admin/upgrading.rst', 'keystone/conf/__init__.py', 'keystone/tests/unit/test_policy.py', 'keystone/tests/unit/test_v3.py', 'doc/source/admin/identity-concepts.rst', 'lower-constraints.txt', 'doc/source/admin/cli-manage-projects-users-and-roles.rst', 'releasenotes/notes/deprecate-json-formatted-policy-file-95f6307f88358f58.yaml', 'keystone/common/rbac_enforcer/enforcer.py', 'doc/source/getting-started/policy_mapping.rst', 'requirements.txt', 'doc/source/configuration/policy.rst', 'keystone/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/256160b849e49d819f6abd492a99989dec285ae7', 'message': ""[goal] Deprecate the JSON formatted policy file\n\nAs per the community goal of migrating the policy file\nthe format from JSON to YAML[1], we need to do two things:\n\n1. Change the default value of '[oslo_policy] policy_file''\nconfig option from 'policy.json' to 'policy.yaml' with\nupgrade checks.\n\n2. Deprecate the JSON formatted policy file on the project side\nvia warning in doc and releasenotes.\n\nAlso replace policy.json to policy.yaml ref from doc and tests.\n\n[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html\n\nChange-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b\n""}]",0,764240,256160b849e49d819f6abd492a99989dec285ae7,37,3,9,8556,,,0,"[goal] Deprecate the JSON formatted policy file

As per the community goal of migrating the policy file
the format from JSON to YAML[1], we need to do two things:

1. Change the default value of '[oslo_policy] policy_file''
config option from 'policy.json' to 'policy.yaml' with
upgrade checks.

2. Deprecate the JSON formatted policy file on the project side
via warning in doc and releasenotes.

Also replace policy.json to policy.yaml ref from doc and tests.

[1]https://governance.openstack.org/tc/goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.html

Change-Id: Ic65d2fd6ce7215b4a47a6fb41b9cbf991f27773b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/764240/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/upgrading.rst', 'keystone/conf/__init__.py', 'keystone/tests/unit/test_policy.py', 'keystone/tests/unit/test_v3.py', 'doc/source/admin/identity-concepts.rst', 'lower-constraints.txt', 'doc/source/admin/cli-manage-projects-users-and-roles.rst', 'releasenotes/notes/deprecate-json-formatted-policy-file-95f6307f88358f58.yaml', 'keystone/common/rbac_enforcer/enforcer.py', 'doc/source/getting-started/policy_mapping.rst', 'requirements.txt', 'doc/source/configuration/policy.rst', 'keystone/cmd/status.py']",13,599db5cfa57376c421f34112d7d22bd9fd5484c1,policy-json-to-yaml,"from oslo_upgradecheck import common_checks (_('Policy File JSON to YAML Migration'), (common_checks.check_policy_json, {'conf': CONF})),",,69,19
openstack%2Fnova~stable%2Fussuri~Id91d2e817ef6bd21124bb840bdb098054e9753b8,openstack/nova,stable/ussuri,Id91d2e817ef6bd21124bb840bdb098054e9753b8,Reproduce bug 1907522 in functional test,MERGED,2021-02-03 15:41:00.000000000,2021-02-05 02:00:43.000000000,2021-02-05 01:58:48.000000000,"[{'_account_id': 4690}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 15:41:00.000000000', 'files': ['nova/tests/functional/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f67627b44c298159206abe86335dd9cf26f15191', 'message': 'Reproduce bug 1907522 in functional test\n\nCross cell resize does not support neutron ports with resource request\nas nova fails to send a proper port binding to neutron. This causes the\nmigration to fail. However we should simply not allow the migration to\ngo cross cell if the server has such ports.\n\nThis patch adds a functional test to reproduce the problem\n\nOn the stable branches Ie15ec8299ae52ae8f5334d591ed3944e9585cf71 was\nnever done and therefore bug 1907511 visible first during the\nreproduction (this bug does not exists on master due to the above\nlinked change). But if 1907511 has fixed then 1907522 would be visible.\nOur incoming bugfix solves fixes both bug at the same time. This means\nthat the backport is not clean, the reproduction test changed to assert\nbug 1907511 instead of bug 1907522\n\nChange-Id: Id91d2e817ef6bd21124bb840bdb098054e9753b8\nRelated-Bug: #1907522\nRelated-Bug: #1907511\n(cherry picked from commit f96ade2726c4ff91690064e9ae228fa12e618540)\n(cherry picked from commit 7366e3c375532f5c4320d8f811106688b1f50813)\n'}]",0,773930,f67627b44c298159206abe86335dd9cf26f15191,13,4,1,9708,,,0,"Reproduce bug 1907522 in functional test

Cross cell resize does not support neutron ports with resource request
as nova fails to send a proper port binding to neutron. This causes the
migration to fail. However we should simply not allow the migration to
go cross cell if the server has such ports.

This patch adds a functional test to reproduce the problem

On the stable branches Ie15ec8299ae52ae8f5334d591ed3944e9585cf71 was
never done and therefore bug 1907511 visible first during the
reproduction (this bug does not exists on master due to the above
linked change). But if 1907511 has fixed then 1907522 would be visible.
Our incoming bugfix solves fixes both bug at the same time. This means
that the backport is not clean, the reproduction test changed to assert
bug 1907511 instead of bug 1907522

Change-Id: Id91d2e817ef6bd21124bb840bdb098054e9753b8
Related-Bug: #1907522
Related-Bug: #1907511
(cherry picked from commit f96ade2726c4ff91690064e9ae228fa12e618540)
(cherry picked from commit 7366e3c375532f5c4320d8f811106688b1f50813)
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/773930/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/test_servers.py', 'nova/compute/api.py']",2,f67627b44c298159206abe86335dd9cf26f15191,bug/1907522, # TODO(gibi): do not allow cross cell migration if the instance has # neutron ports with resource request. See bug 1907522.,,111,0
openstack%2Ffreezer~master~Ibf1b42c7c41aacb4f5d5cb8d2699cb069436f230,openstack/freezer,master,Ibf1b42c7c41aacb4f5d5cb8d2699cb069436f230,add test_terminate_subprocess1 for unit test,MERGED,2021-02-05 00:23:28.000000000,2021-02-05 01:38:28.000000000,2021-02-05 01:36:50.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-05 00:23:28.000000000', 'files': ['freezer/tests/unit/scheduler/test_utils.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/6e0bed59269f1ee6a978b5a6d8299024d8c48f10', 'message': 'add test_terminate_subprocess1 for unit test\n\nChange-Id: Ibf1b42c7c41aacb4f5d5cb8d2699cb069436f230\n'}]",0,774177,6e0bed59269f1ee6a978b5a6d8299024d8c48f10,7,2,1,21387,,,0,"add test_terminate_subprocess1 for unit test

Change-Id: Ibf1b42c7c41aacb4f5d5cb8d2699cb069436f230
",git fetch https://review.opendev.org/openstack/freezer refs/changes/77/774177/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/tests/unit/scheduler/test_utils.py'],1,6e0bed59269f1ee6a978b5a6d8299024d8c48f10,unittest1," @patch('os.kill') @patch('psutil.Process') def test_terminate_subprocess1(self, mock_process, mock_oskill): mock_pro = mock.MagicMock() mock_pro.name.startswith.return_value = False mock_process.return_value = mock_pro result = utils.terminate_subprocess(35, 'test') self.assertIsNone(result) mock_pro.name.startswith.return_value = True mock_oskill.side_effect = Exception(""error"") result = utils.terminate_subprocess(35, 'test') self.assertIsNone(result) ",,13,0
openstack%2Ftripleo-ansible~stable%2Ftrain~Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f,openstack/tripleo-ansible,stable/train,Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f,Add tripleo_multipathd role,MERGED,2020-12-01 18:51:29.000000000,2021-02-05 01:38:13.000000000,2021-02-05 01:34:16.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 18:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d5969a1dfd1e938ce296cbe793e2a4f98eed827f', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 2, 'created': '2020-12-01 21:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ed9cca247d991f2ea4316cfdd59ffdecea84d8ef', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 3, 'created': '2020-12-08 18:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e3daa7587e101ddec4012bcc4ed1779157d34831', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 4, 'created': '2020-12-09 04:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8ab4e0da50ea666888d34ff881f905e876ec0963', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 5, 'created': '2020-12-10 19:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b58a9220a89779dbcc0bb151c6d4acf48dd89a95', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train): Fixed molecule configs and files.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 6, 'created': '2020-12-18 17:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b312836163235492fb4531b86ce6edd18bb01b5c', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train): Fixed molecule configs and files.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 7, 'created': '2020-12-18 20:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/92b3f2a166374c6ed7ddb040ef0c1b9c6f2a2c01', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train): Fixed molecule configs and files.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 8, 'created': '2020-12-18 20:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/514b0cdd1ec50cd482096576291c463b66e0fe63', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train): Fixed molecule configs and files.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 9, 'created': '2021-01-26 16:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e5137ac20587657c050271b8dc8b6ee5961fb8c4', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 10, 'created': '2021-01-26 17:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/80a606e53f85e97cae7747781f6d6c06f0c62c59', 'message': ""Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo's OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nstable/train:\n- Use tripleo-module-load role instead of tripleo_module_load\n- Fix additional lint errors\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n""}, {'number': 11, 'created': '2021-01-27 18:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2a215bab1566cef89c22e91afe1d1cc3182f9de3', 'message': 'Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo\'s OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train):\n- Use tripleo-module-load role instead of tripleo_module_load\n- Rename molecule/converge.yml to molecule/playbook.yml\n- Specify the verifier use ansible-lint (flake8 is an ""unallowed value"")\n- Fix additional lint errors\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n'}, {'number': 12, 'created': '2021-01-28 14:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/5c6be8b81943260860efa425b37592700e8887f8', 'message': 'Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo\'s OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train):\n- Use tripleo-module-load role instead of tripleo_module_load\n- Add molecule/playbook.yml by copying converge.yaml (for autodoc)\n- Specify the verifier use ansible-lint (flake8 is an ""unallowed value"")\n- Fix additional lint errors\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n'}, {'number': 13, 'created': '2021-01-28 19:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/90f4a3b30e9aa353e73b5ff38ea871ca02aac8af', 'message': 'Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo\'s OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train):\n- Use tripleo-module-load role instead of tripleo_module_load\n- Add molecule/playbook.yml by copying converge.yaml (for autodoc)\n- Specify the verifier use ansible-lint (flake8 is an ""unallowed value"")\n- Fix additional lint errors\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n'}, {'number': 14, 'created': '2021-02-01 14:49:25.000000000', 'files': ['tripleo_ansible/roles/tripleo_multipathd/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/meta/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/tasks/configure.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/Dockerfile', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/Dockerfile', 'doc/source/roles/role-tripleo_multipathd.rst', 'zuul.d/molecule.yaml', 'tripleo_ansible/roles/tripleo_multipathd/defaults/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/custom_multipath.conf', 'tripleo_ansible/roles/tripleo_multipathd/tasks/host_prep.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/playbook.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/playbook.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/tasks/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/files/multipath.conf', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/playbook.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/preexisting_multipath.conf', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/Dockerfile'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/18868f4e3978a7befe22fe97083d02169c1409e9', 'message': 'Add tripleo_multipathd role\n\nA new tripleo_multipathd role is responsible for preparing and\nconfiguring an overcloud node to run multipathd in a container.\n- Host prep tasks ensure any existing multipathd service is disabled\n  on the host.\n- /etc/multipath.conf configuration is controlled via ansible variables\n  supplied by tripleo\'s OS::TripleO::Services::Multipathd service.\n- The multipathd container is restarted whenever the configuration\n  changes.\n\nNOTE(stable/train):\n- Use tripleo-module-load role instead of tripleo_module_load\n- Add molecule/playbook.yml by copying converge.yaml (for autodoc)\n- Use canned preexisting_multipath.conf\n- Specify the verifier use ansible-lint (flake8 is an ""unallowed value"")\n- Fix additional lint errors\n\nChange-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\n(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)\n(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)\n'}]",0,764993,18868f4e3978a7befe22fe97083d02169c1409e9,55,4,14,21129,,,0,"Add tripleo_multipathd role

A new tripleo_multipathd role is responsible for preparing and
configuring an overcloud node to run multipathd in a container.
- Host prep tasks ensure any existing multipathd service is disabled
  on the host.
- /etc/multipath.conf configuration is controlled via ansible variables
  supplied by tripleo's OS::TripleO::Services::Multipathd service.
- The multipathd container is restarted whenever the configuration
  changes.

NOTE(stable/train):
- Use tripleo-module-load role instead of tripleo_module_load
- Add molecule/playbook.yml by copying converge.yaml (for autodoc)
- Use canned preexisting_multipath.conf
- Specify the verifier use ansible-lint (flake8 is an ""unallowed value"")
- Fix additional lint errors

Change-Id: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f
(cherry picked from commit 1af2cde366e42ab8509b4cd2a77a3e8058e175df)
(cherry picked from commit db6541dfb5b6eac4f80a7b8d6e72a1da6f744793)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/93/764993/6 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_multipathd/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/meta/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/tasks/configure.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/Dockerfile', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/Dockerfile', 'doc/source/roles/role-tripleo_multipathd.rst', 'zuul.d/molecule.yaml', 'tripleo_ansible/roles/tripleo_multipathd/defaults/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/custom_multipath.conf', 'tripleo_ansible/roles/tripleo_multipathd/tasks/host_prep.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/default/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/converge.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/molecule.yml', 'tripleo_ansible/roles/tripleo_multipathd/tasks/main.yml', 'tripleo_ansible/roles/tripleo_multipathd/files/multipath.conf', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/verify.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/preexisting_config/prepare.yml', 'tripleo_ansible/roles/tripleo_multipathd/molecule/custom_config/Dockerfile']",24,d5969a1dfd1e938ce296cbe793e2a4f98eed827f,multipath-v2,"# Molecule managed # Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. {% if item.registry is defined %} FROM {{ item.registry.url }}/{{ item.image }} {% else %} FROM {{ item.image }} {% endif %} RUN if [ $(command -v apt-get) ]; then apt-get update && apt-get install -y python sudo bash ca-certificates && apt-get clean; \ elif [ $(command -v dnf) ]; then dnf makecache && dnf --assumeyes install sudo python*-devel python*-dnf bash {{ item.pkg_extras | default('') }} && dnf clean all; \ elif [ $(command -v yum) ]; then yum makecache fast && yum install -y python sudo yum-plugin-ovl python-setuptools bash {{ item.pkg_extras | default('') }} && sed -i 's/plugins=0/plugins=1/g' /etc/yum.conf && yum clean all; \ elif [ $(command -v zypper) ]; then zypper refresh && zypper install -y python sudo bash python-xml {{ item.pkg_extras | default('') }} && zypper clean -a; \ elif [ $(command -v apk) ]; then apk update && apk add --no-cache python sudo bash ca-certificates {{ item.pkg_extras | default('') }}; \ elif [ $(command -v xbps-install) ]; then xbps-install -Syu && xbps-install -y python sudo bash ca-certificates {{ item.pkg_extras | default('') }} && xbps-remove -O; fi {% for pkg in item.easy_install | default([]) %} # install pip for centos where there is no python-pip rpm in default repos RUN easy_install {{ pkg }} {% endfor %} CMD [""sh"", ""-c"", ""while true; do sleep 10000; done""] ",,876,0
openstack%2Frequirements~stable%2Ftrain~I8718c40cdb95258ea7553ac70c1fd632daf408b7,openstack/requirements,stable/train,I8718c40cdb95258ea7553ac70c1fd632daf408b7,update constraint for horizon to new release 16.2.1,MERGED,2021-02-04 10:58:19.000000000,2021-02-05 01:23:45.000000000,2021-02-05 01:23:45.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-04 10:58:19.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/62467c0570ebca99dfaff2f94bdbe0306a7ba070', 'message': 'update constraint for horizon to new release 16.2.1\n\nmeta: version: 16.2.1\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: Ia2c366658bdd79ec976f90d3fb79fb8362e225d1\nmeta: release:Code-Review+1: Vishal Manchanda <manchandavishal143@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I8718c40cdb95258ea7553ac70c1fd632daf408b7\n'}]",0,774064,62467c0570ebca99dfaff2f94bdbe0306a7ba070,7,3,1,11131,,,0,"update constraint for horizon to new release 16.2.1

meta: version: 16.2.1
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: Ia2c366658bdd79ec976f90d3fb79fb8362e225d1
meta: release:Code-Review+1: Vishal Manchanda <manchandavishal143@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I8718c40cdb95258ea7553ac70c1fd632daf408b7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/64/774064/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,62467c0570ebca99dfaff2f94bdbe0306a7ba070,new-release,horizon===16.2.1,horizon===16.2.0,1,1
openstack%2Frequirements~stable%2Ftrain~Icb8a17764e56c71be8f5681905e5d3ab3889f84f,openstack/requirements,stable/train,Icb8a17764e56c71be8f5681905e5d3ab3889f84f,update constraint for neutron to new release 15.3.2,MERGED,2021-02-04 11:14:40.000000000,2021-02-05 01:23:41.000000000,2021-02-05 01:23:41.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2021-02-04 11:14:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c188a5b2ba678a992e8f9bb717f95819c78af8b2', 'message': 'update constraint for neutron to new release 15.3.2\n\nmeta: version: 15.3.2\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: I393fa514bcac898f05fba6ffedaefdf99bac7249\nmeta: release:Code-Review+1: Thomas Bachman <bachman@noironetworks.com>\nmeta: release:Code-Review+1: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Code-Review+1: Bernard Cafarelli <bcafarel@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Icb8a17764e56c71be8f5681905e5d3ab3889f84f\n'}]",0,774066,c188a5b2ba678a992e8f9bb717f95819c78af8b2,7,3,1,11131,,,0,"update constraint for neutron to new release 15.3.2

meta: version: 15.3.2
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: I393fa514bcac898f05fba6ffedaefdf99bac7249
meta: release:Code-Review+1: Thomas Bachman <bachman@noironetworks.com>
meta: release:Code-Review+1: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Code-Review+1: Bernard Cafarelli <bcafarel@redhat.com>
meta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Icb8a17764e56c71be8f5681905e5d3ab3889f84f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/66/774066/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c188a5b2ba678a992e8f9bb717f95819c78af8b2,new-release,neutron===15.3.2,neutron===15.3.1,1,1
openstack%2Fhorizon~master~I11d804ae71e57119565d53e4a0a54a609e7139d2,openstack/horizon,master,I11d804ae71e57119565d53e4a0a54a609e7139d2,Allow specifying mtu during creating network,ABANDONED,2020-04-17 02:41:14.000000000,2021-02-05 00:35:15.000000000,,"[{'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-04-17 02:41:14.000000000', 'files': ['openstack_dashboard/dashboards/admin/networks/forms.py', 'openstack_dashboard/dashboards/admin/networks/workflows.py', 'openstack_dashboard/dashboards/project/networks/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0d6b8bdb141112c0726e6d91d8fc3f4b1a2ec50e', 'message': 'Allow specifying mtu during creating network\n\nAllow choosing an mtu during creating network.\n\nChange-Id: I11d804ae71e57119565d53e4a0a54a609e7139d2\n'}]",0,720630,0d6b8bdb141112c0726e6d91d8fc3f4b1a2ec50e,5,3,1,29071,,,0,"Allow specifying mtu during creating network

Allow choosing an mtu during creating network.

Change-Id: I11d804ae71e57119565d53e4a0a54a609e7139d2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/720630/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/networks/forms.py', 'openstack_dashboard/dashboards/admin/networks/workflows.py', 'openstack_dashboard/dashboards/project/networks/workflows.py']",3,0d6b8bdb141112c0726e6d91d8fc3f4b1a2ec50e,add_mtu," mtu = forms.IntegerField( label='mtu', required=False, ) ""mtu"", ""az_hints"") if 'mtu' in data and data['mtu']: params['mtu'] = data['mtu']"," ""az_hints"")",13,2
openstack%2Fnova~stable%2Ftrain~I48f57082edaef3ec4722bd31ce29a90b94d32523,openstack/nova,stable/train,I48f57082edaef3ec4722bd31ce29a90b94d32523,Use cell targeted context to query BDMs for metadata,MERGED,2021-01-19 14:55:43.000000000,2021-02-05 00:14:55.000000000,2021-02-05 00:12:22.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-19 14:55:43.000000000', 'files': ['nova/tests/unit/test_metadata.py', 'nova/api/metadata/base.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4839d41fc0c084fe56106c879c468f1553e8e780', 'message': 'Use cell targeted context to query BDMs for metadata\n\nThe metadata service supports a multicell deployment in a configuration\nwhere the nova-api service implements the metadata API. In this case the\nmetadata query needs to be cell targeted. This was partly implemented\nalready. The instance itself is queried from the cell DB properly.\nHowever the BDM data used the non targeted context resulting in an empty\nBDM returned by the metadata service.\n\nFunctional reproduction test is not added as I did not find a way to\nhave a cell setup in the functional test that reproduce the problem. I\nreproduced the bug and tested the fix in a devstack.\n\nChange-Id: I48f57082edaef3ec4722bd31ce29a90b94d32523\nCloses-Bug: #1881944\n(cherry picked from commit 1390eecf8dec4c3b022a9b1e259a908197566738)\n(cherry picked from commit 9a5b6249d65c96e387a9eb0ecdefcc2057c21869)\n(cherry picked from commit c727cfc36c9d352102e04b9c94bebc7e25a1ab97)\n'}]",0,771407,4839d41fc0c084fe56106c879c468f1553e8e780,16,3,1,9708,,,0,"Use cell targeted context to query BDMs for metadata

The metadata service supports a multicell deployment in a configuration
where the nova-api service implements the metadata API. In this case the
metadata query needs to be cell targeted. This was partly implemented
already. The instance itself is queried from the cell DB properly.
However the BDM data used the non targeted context resulting in an empty
BDM returned by the metadata service.

Functional reproduction test is not added as I did not find a way to
have a cell setup in the functional test that reproduce the problem. I
reproduced the bug and tested the fix in a devstack.

Change-Id: I48f57082edaef3ec4722bd31ce29a90b94d32523
Closes-Bug: #1881944
(cherry picked from commit 1390eecf8dec4c3b022a9b1e259a908197566738)
(cherry picked from commit 9a5b6249d65c96e387a9eb0ecdefcc2057c21869)
(cherry picked from commit c727cfc36c9d352102e04b9c94bebc7e25a1ab97)
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/771407/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_metadata.py', 'nova/api/metadata/base.py']",2,4839d41fc0c084fe56106c879c468f1553e8e780,bug/1881944, # NOTE(gibi): this is not a cell targeted context even if we are called # in a situation when the instance is in a different cell than the # metadata service itself. self.mappings = _format_instance_mapping(instance) def _format_instance_mapping(instance): bdms = instance.get_bdms()," self.mappings = _format_instance_mapping(ctxt, instance) def _format_instance_mapping(ctxt, instance): bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( ctxt, instance.uuid)",17,11
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,openstack/tripleo-heat-templates,stable/victoria,I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues,MERGED,2021-02-01 14:51:01.000000000,2021-02-04 23:58:37.000000000,2021-02-04 23:56:46.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-02-01 14:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee5c65a2098eb614954842eceb7bd1b88fdf7214', 'message': 'Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues\n\nAdd NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in\nnova.conf of the compute. Default 0 corresponds to not set meaning the\nlegacy limits based on the reported kernel major version will be used.\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nDepends-On: Ieaa29b51257f5ea3a5e4d6c678140fd9ae052d88\nChange-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f\n(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)\n'}, {'number': 2, 'created': '2021-02-01 14:51:57.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ace2eb097ed221eb5110df9d470306234a6b93ef', 'message': 'Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues\n\nAdd NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in\nnova.conf of the compute. Default 0 corresponds to not set meaning the\nlegacy limits based on the reported kernel major version will be used.\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/772805\nChange-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f\n(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)\n'}]",0,773404,ace2eb097ed221eb5110df9d470306234a6b93ef,10,6,2,17216,,,0,"Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues

Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in
nova.conf of the compute. Default 0 corresponds to not set meaning the
legacy limits based on the reported kernel major version will be used.

Conflicts:
  deployment/nova/nova-compute-container-puppet.yaml

Depends-On: https://review.opendev.org/c/openstack/puppet-nova/+/772805
Change-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f
(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/773404/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml']",2,ee5c65a2098eb614954842eceb7bd1b88fdf7214,1917460-v,--- features: - | Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in nova.conf of the compute. Default 0 corresponds to not set meaning the legacy limits based on the reported kernel major version will be used. ,,30,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,openstack/tripleo-heat-templates,stable/ussuri,I353e8ca2676bbdceb056f8b2b084bc5102f52c1f,Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues,MERGED,2021-02-01 14:55:01.000000000,2021-02-04 23:58:29.000000000,2021-02-04 23:56:54.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2021-02-01 14:55:01.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e21b9f8dd0ac758aca1f0a808bfda0b335290a3b', 'message': 'Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues\n\nAdd NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in\nnova.conf of the compute. Default 0 corresponds to not set meaning the\nlegacy limits based on the reported kernel major version will be used.\n\nConflicts:\n  deployment/nova/nova-compute-container-puppet.yaml\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-nova/+/773266\nChange-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f\n(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)\n(cherry picked from commit ace2eb097ed221eb5110df9d470306234a6b93ef)\n'}]",0,773406,e21b9f8dd0ac758aca1f0a808bfda0b335290a3b,9,6,1,17216,,,0,"Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues

Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in
nova.conf of the compute. Default 0 corresponds to not set meaning the
legacy limits based on the reported kernel major version will be used.

Conflicts:
  deployment/nova/nova-compute-container-puppet.yaml

Depends-On: https://review.opendev.org/c/openstack/puppet-nova/+/773266
Change-Id: I353e8ca2676bbdceb056f8b2b084bc5102f52c1f
(cherry picked from commit 67a5a788971c1e2475cd260d91149b7d3d3a2012)
(cherry picked from commit ace2eb097ed221eb5110df9d470306234a6b93ef)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/773406/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_libvirt_max_queues-8024fc63105bd25d.yaml']",2,e21b9f8dd0ac758aca1f0a808bfda0b335290a3b,1917460-u,--- features: - | Add NovaLibvirtMaxQueues role parameter to set [libvirt]/max_queues in nova.conf of the compute. Default 0 corresponds to not set meaning the legacy limits based on the reported kernel major version will be used. ,,30,0
openstack%2Fcharm-neutron-openvswitch~master~I06db4d2165a58c99e01f2cea3d771363a3ed3062,openstack/charm-neutron-openvswitch,master,I06db4d2165a58c99e01f2cea3d771363a3ed3062,Set the memlock rlimit to infinity for containers,ABANDONED,2020-12-04 08:21:58.000000000,2021-02-04 23:50:19.000000000,,"[{'_account_id': 8992}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-04 08:21:58.000000000', 'files': ['lxd-profile.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/78b5aa79eb091314ee25ab94b3ffe5e39cdda49a', 'message': 'Set the memlock rlimit to infinity for containers\n\nAn issue with starting ovs-vswitchd in an unprivileged LXD container was\nencountered on a machine with a large amount of cores:\n\n* ovs-vswitchd started via ovs-ctl configures memory locking for all\nmemory allocations by calling mlockall(MCL_CURRENT | MCL_FUTURE);\n* there are 2 generic threads per process + 1 pthread per core\nstarted by ovs-vswitchd;\n* each thread needs around 1.5 MiB of RSS in an idle state;\n* Memory locking configured that way affects mmap(2), sbrk(2) system\ncalls and any malloc(3) calls done in any threads of the ovs-vswitchd\nprocess;\n* Any memory allocations (when pages actually get dirty) count toward\nRLIMIT_MEMLOCK;\n* RLIMIT_MEMLOCK is only ignored for processes that have CAP_IPC_LOCK\nin the initial user namespace which is not the case for unprivileged\ncontainer root users;\n* Resource limits are preserved across forks/clones and execs:\nprocess creation in the kernel uses a common code path which preserves\nrlimits stored in the signal_struct and upon exec the limits are\nkept as well. Therefore, when LXD uses clone(2) to create a container\ninit process, resource limits are inherited from LXD;\n* rlimits can be per-process, per-uid or mixed. RLIMIT_MEMLOCK is mixed\nand uses per-process accounting for non-SHM memory and per-UID\naccounting for SHM memory;\n* rlimits are not hierarchical and are not set via cgroups;\n* Before systemd 237-3ubuntu10.43 on Bionic, the default RLIMIT_MEMLOCK\nvalue was set to 16 MiB. An upstream patch applied with\n237-3ubuntu10.43 bumped it to 64 MiB (LP: #1830746);\n* this is not enough for ovs-vswitchd with a large amount of threads.\n\nThis change sets the RLIMIT_MEMLOCK value to unlimited in the LXD\nprofile shipped with the charm. If we ever apply memory limits via a\nLXD profile, those will limit the amount of RAM a container can allocate\nand lock.\n\nChange-Id: I06db4d2165a58c99e01f2cea3d771363a3ed3062\nCloses-Bug: #1906280\n'}]",0,765493,78b5aa79eb091314ee25ab94b3ffe5e39cdda49a,13,4,1,24824,,,0,"Set the memlock rlimit to infinity for containers

An issue with starting ovs-vswitchd in an unprivileged LXD container was
encountered on a machine with a large amount of cores:

* ovs-vswitchd started via ovs-ctl configures memory locking for all
memory allocations by calling mlockall(MCL_CURRENT | MCL_FUTURE);
* there are 2 generic threads per process + 1 pthread per core
started by ovs-vswitchd;
* each thread needs around 1.5 MiB of RSS in an idle state;
* Memory locking configured that way affects mmap(2), sbrk(2) system
calls and any malloc(3) calls done in any threads of the ovs-vswitchd
process;
* Any memory allocations (when pages actually get dirty) count toward
RLIMIT_MEMLOCK;
* RLIMIT_MEMLOCK is only ignored for processes that have CAP_IPC_LOCK
in the initial user namespace which is not the case for unprivileged
container root users;
* Resource limits are preserved across forks/clones and execs:
process creation in the kernel uses a common code path which preserves
rlimits stored in the signal_struct and upon exec the limits are
kept as well. Therefore, when LXD uses clone(2) to create a container
init process, resource limits are inherited from LXD;
* rlimits can be per-process, per-uid or mixed. RLIMIT_MEMLOCK is mixed
and uses per-process accounting for non-SHM memory and per-UID
accounting for SHM memory;
* rlimits are not hierarchical and are not set via cgroups;
* Before systemd 237-3ubuntu10.43 on Bionic, the default RLIMIT_MEMLOCK
value was set to 16 MiB. An upstream patch applied with
237-3ubuntu10.43 bumped it to 64 MiB (LP: #1830746);
* this is not enough for ovs-vswitchd with a large amount of threads.

This change sets the RLIMIT_MEMLOCK value to unlimited in the LXD
profile shipped with the charm. If we ever apply memory limits via a
LXD profile, those will limit the amount of RAM a container can allocate
and lock.

Change-Id: I06db4d2165a58c99e01f2cea3d771363a3ed3062
Closes-Bug: #1906280
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/93/765493/1 && git format-patch -1 --stdout FETCH_HEAD,['lxd-profile.yaml'],1,78b5aa79eb091314ee25ab94b3ffe5e39cdda49a,bug/1830746, limits.kernel.memlock: unlimited,,1,0
openstack%2Fcharm-hacluster~stable%2F20.10~Ie88982fe987b742082a978ff2488693d0154123b,openstack/charm-hacluster,stable/20.10,Ie88982fe987b742082a978ff2488693d0154123b,Increase default TimeoutStopSec value,ABANDONED,2021-01-05 15:31:47.000000000,2021-02-04 23:48:40.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-05 15:31:47.000000000', 'files': ['hooks/hooks.py', 'config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/8ed1254418a9e57c1664775ac41d6d35dbe58723', 'message': 'Increase default TimeoutStopSec value\n\nThe charm installs systemd overrides of the TimeoutStopSec and\nTimeoutStartSec parameters for the corosync and pacemaker services.\nThe default timeout stop parameter is changed to 60s, which is a\nsignificant change from the package level default of 30 minutes. The\npacemaker systemd default is 30 minutes to allow time for resources\nto safely move off the node before shutting down. It can take some\ntime for services to migrate away under a variety of circumstances (node\nusage, the resource, etc).\n\nThis change increases the timeout to 10 minutes by default, which should\nprevent things like unattended-upgrades from causing outages due\nservices not starting because systemd timed out (and an instance was\nalready running).\n\nChange-Id: Ie88982fe987b742082a978ff2488693d0154123b\nCloses-Bug: #1903745\n(cherry picked from commit 9645aefdec0c43588ddcc4bb8b846d4a694e632c)\n'}]",0,769384,8ed1254418a9e57c1664775ac41d6d35dbe58723,4,2,1,8992,,,0,"Increase default TimeoutStopSec value

The charm installs systemd overrides of the TimeoutStopSec and
TimeoutStartSec parameters for the corosync and pacemaker services.
The default timeout stop parameter is changed to 60s, which is a
significant change from the package level default of 30 minutes. The
pacemaker systemd default is 30 minutes to allow time for resources
to safely move off the node before shutting down. It can take some
time for services to migrate away under a variety of circumstances (node
usage, the resource, etc).

This change increases the timeout to 10 minutes by default, which should
prevent things like unattended-upgrades from causing outages due
services not starting because systemd timed out (and an instance was
already running).

Change-Id: Ie88982fe987b742082a978ff2488693d0154123b
Closes-Bug: #1903745
(cherry picked from commit 9645aefdec0c43588ddcc4bb8b846d4a694e632c)
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/84/769384/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'config.yaml']",2,8ed1254418a9e57c1664775ac41d6d35dbe58723,bug/1903745, default: 600 seconds. The default value will cause systemd to timeout a service stop after 10 minutes. This should provide for sufficient time for resources to migrate away from the current node as part of the stop sequence in most cases. Set value to -1 turn off timeout for the services., default: 60 seconds. Set value to -1 turn off timeout for the services.,7,2
openstack%2Fnova~stable%2Ftrain~I29d6f4a78c0206385a550967ce244794e71cef6d,openstack/nova,stable/train,I29d6f4a78c0206385a550967ce244794e71cef6d,Move revert resize under semaphore,NEW,2020-09-11 17:20:55.000000000,2021-02-04 23:47:22.000000000,,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-11 17:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13787c36d5d93b38b6a8835de46057078fec2eea', 'message': 'Move revert resize under semaphore\n\nAs discussed in change I26b050c402f5721fc490126e9becb643af9279b4, the\nresource tracker\'s periodic task is reliant on the status of migrations\nto determine whether to include usage from these migrations in the\ntotal, and races between setting the migration status and decrementing\nresource usage via \'drop_move_claim\' can result in incorrect usage.\nThat change tackled the confirm resize operation. This one changes the\nrevert resize operation, and is a little trickier due to kinks in how\nboth the same-cell and cross-cell resize revert operations work.\n\nFor same-cell resize revert, the \'ComputeManager.revert_resize\'\nfunction, running on the destination host, sets the migration status to\n\'reverted\' before dropping the move claim. This exposes the same race\nthat we previously saw with the confirm resize operation. It then calls\nback to \'ComputeManager.finish_revert_resize\' on the source host to boot\nup the instance itself. This is kind of weird, because, even ignoring\nthe race, we\'re marking the migration as \'reverted\' before we\'ve done\nany of the necessary work on the source host.\n\nThe cross-cell resize revert splits dropping of the move claim and\nsetting of the migration status between the source and destination host\ntasks. Specifically, we do cleanup on the destination and drop the move\nclaim first, via \'ComputeManager.revert_snapshot_based_resize_at_dest\'\nbefore resuming the instance and setting the migration status on the\nsource via\n\'ComputeManager.finish_revert_snapshot_based_resize_at_source\'. This\nwould appear to avoid the weird quirk of same-cell migration, however,\nin typical weird cross-cell fashion, these are actually different\ninstances and different migration records.\n\nThe solution is once again to move the setting of the migration status\nand the dropping of the claim under \'COMPUTE_RESOURCE_SEMAPHORE\'. This\nintroduces the weird setting of migration status before completion to\nthe cross-cell resize case and perpetuates it in the same-cell case, but\nthis seems like a suitable compromise to avoid attempts to do things\nlike unplugging already unplugged PCI devices or unpinning already\nunpinned CPUs. From an end-user perspective, instance state changes are\nwhat really matter and once a revert is completed on the destination\nhost and the instance has been marked as having returned to the source\nhost, hard reboots can help us resolve any remaining issues.\n\nConflicts:\n  nova/compute/manager.py\n  nova/compute/resource_tracker.py\n  nova/tests/unit/compute/test_compute_mgr.py\n\nNOTE(stephenfin): The bulk of the conflicts are due to the absence of\nvarious cross-cell resize related patches. The only exception is the\nconflict in \'nova/compute/resource_tracker.py\', which is due to the\nabsence of change Ia5e521e0f0c7a78b5ace5de9f343e84d872553f9 (""Use fair\nlocks in resource tracker"") which we can\'t backport since it requires a\nfeature only found in newer versions of \'oslo.concurrency\' and mandates\na lower constraint bump.\n\nChange-Id: I29d6f4a78c0206385a550967ce244794e71cef6d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nCloses-Bug: #1879878\n(cherry picked from commit dc9c7a5ebf11253f86127238d33dff7401465155)\n(cherry picked from commit 79a467e1cfa05b1c281e592e69549716c11892e5)\n'}, {'number': 2, 'created': '2020-09-14 10:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c394d79b3ead53e7c7fae0665c579ab5b06b11e', 'message': 'Move revert resize under semaphore\n\nAs discussed in change I26b050c402f5721fc490126e9becb643af9279b4, the\nresource tracker\'s periodic task is reliant on the status of migrations\nto determine whether to include usage from these migrations in the\ntotal, and races between setting the migration status and decrementing\nresource usage via \'drop_move_claim\' can result in incorrect usage.\nThat change tackled the confirm resize operation. This one changes the\nrevert resize operation, and is a little trickier due to kinks in how\nboth the same-cell and cross-cell resize revert operations work.\n\nFor same-cell resize revert, the \'ComputeManager.revert_resize\'\nfunction, running on the destination host, sets the migration status to\n\'reverted\' before dropping the move claim. This exposes the same race\nthat we previously saw with the confirm resize operation. It then calls\nback to \'ComputeManager.finish_revert_resize\' on the source host to boot\nup the instance itself. This is kind of weird, because, even ignoring\nthe race, we\'re marking the migration as \'reverted\' before we\'ve done\nany of the necessary work on the source host.\n\nThe cross-cell resize revert splits dropping of the move claim and\nsetting of the migration status between the source and destination host\ntasks. Specifically, we do cleanup on the destination and drop the move\nclaim first, via \'ComputeManager.revert_snapshot_based_resize_at_dest\'\nbefore resuming the instance and setting the migration status on the\nsource via\n\'ComputeManager.finish_revert_snapshot_based_resize_at_source\'. This\nwould appear to avoid the weird quirk of same-cell migration, however,\nin typical weird cross-cell fashion, these are actually different\ninstances and different migration records.\n\nThe solution is once again to move the setting of the migration status\nand the dropping of the claim under \'COMPUTE_RESOURCE_SEMAPHORE\'. This\nintroduces the weird setting of migration status before completion to\nthe cross-cell resize case and perpetuates it in the same-cell case, but\nthis seems like a suitable compromise to avoid attempts to do things\nlike unplugging already unplugged PCI devices or unpinning already\nunpinned CPUs. From an end-user perspective, instance state changes are\nwhat really matter and once a revert is completed on the destination\nhost and the instance has been marked as having returned to the source\nhost, hard reboots can help us resolve any remaining issues.\n\nConflicts:\n  nova/compute/manager.py\n  nova/compute/resource_tracker.py\n  nova/tests/unit/compute/test_compute_mgr.py\n\nNOTE(stephenfin): The bulk of the conflicts are due to the absence of\nvarious cross-cell resize related patches. The only exception is the\nconflict in \'nova/compute/resource_tracker.py\', which is due to the\nabsence of change Ia5e521e0f0c7a78b5ace5de9f343e84d872553f9 (""Use fair\nlocks in resource tracker"") which we can\'t backport since it requires a\nfeature only found in newer versions of \'oslo.concurrency\' and mandates\na lower constraint bump.\n\nChange-Id: I29d6f4a78c0206385a550967ce244794e71cef6d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nCloses-Bug: #1879878\n(cherry picked from commit dc9c7a5ebf11253f86127238d33dff7401465155)\n(cherry picked from commit 79a467e1cfa05b1c281e592e69549716c11892e5)\n'}, {'number': 3, 'created': '2021-02-04 17:13:23.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/functional/regressions/test_bug_1879878.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/66184692cca3239ea750d258e5659e149d56526d', 'message': 'Move revert resize under semaphore\n\nAs discussed in change I26b050c402f5721fc490126e9becb643af9279b4, the\nresource tracker\'s periodic task is reliant on the status of migrations\nto determine whether to include usage from these migrations in the\ntotal, and races between setting the migration status and decrementing\nresource usage via \'drop_move_claim\' can result in incorrect usage.\nThat change tackled the confirm resize operation. This one changes the\nrevert resize operation, and is a little trickier due to kinks in how\nboth the same-cell and cross-cell resize revert operations work.\n\nFor same-cell resize revert, the \'ComputeManager.revert_resize\'\nfunction, running on the destination host, sets the migration status to\n\'reverted\' before dropping the move claim. This exposes the same race\nthat we previously saw with the confirm resize operation. It then calls\nback to \'ComputeManager.finish_revert_resize\' on the source host to boot\nup the instance itself. This is kind of weird, because, even ignoring\nthe race, we\'re marking the migration as \'reverted\' before we\'ve done\nany of the necessary work on the source host.\n\nThe cross-cell resize revert splits dropping of the move claim and\nsetting of the migration status between the source and destination host\ntasks. Specifically, we do cleanup on the destination and drop the move\nclaim first, via \'ComputeManager.revert_snapshot_based_resize_at_dest\'\nbefore resuming the instance and setting the migration status on the\nsource via\n\'ComputeManager.finish_revert_snapshot_based_resize_at_source\'. This\nwould appear to avoid the weird quirk of same-cell migration, however,\nin typical weird cross-cell fashion, these are actually different\ninstances and different migration records.\n\nThe solution is once again to move the setting of the migration status\nand the dropping of the claim under \'COMPUTE_RESOURCE_SEMAPHORE\'. This\nintroduces the weird setting of migration status before completion to\nthe cross-cell resize case and perpetuates it in the same-cell case, but\nthis seems like a suitable compromise to avoid attempts to do things\nlike unplugging already unplugged PCI devices or unpinning already\nunpinned CPUs. From an end-user perspective, instance state changes are\nwhat really matter and once a revert is completed on the destination\nhost and the instance has been marked as having returned to the source\nhost, hard reboots can help us resolve any remaining issues.\n\nConflicts:\n  nova/compute/manager.py\n  nova/compute/resource_tracker.py\n  nova/tests/unit/compute/test_compute_mgr.py\n\nNOTE(stephenfin): The bulk of the conflicts are due to the absence of\nvarious cross-cell resize related patches. The only exception is the\nconflict in \'nova/compute/resource_tracker.py\', which is due to the\nabsence of change Ia5e521e0f0c7a78b5ace5de9f343e84d872553f9 (""Use fair\nlocks in resource tracker"") which we can\'t backport since it requires a\nfeature only found in newer versions of \'oslo.concurrency\' and mandates\na lower constraint bump.\n\nChange-Id: I29d6f4a78c0206385a550967ce244794e71cef6d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nCloses-Bug: #1879878\n(cherry picked from commit dc9c7a5ebf11253f86127238d33dff7401465155)\n(cherry picked from commit 79a467e1cfa05b1c281e592e69549716c11892e5)\n'}]",0,751369,66184692cca3239ea750d258e5659e149d56526d,24,7,3,15334,,,0,"Move revert resize under semaphore

As discussed in change I26b050c402f5721fc490126e9becb643af9279b4, the
resource tracker's periodic task is reliant on the status of migrations
to determine whether to include usage from these migrations in the
total, and races between setting the migration status and decrementing
resource usage via 'drop_move_claim' can result in incorrect usage.
That change tackled the confirm resize operation. This one changes the
revert resize operation, and is a little trickier due to kinks in how
both the same-cell and cross-cell resize revert operations work.

For same-cell resize revert, the 'ComputeManager.revert_resize'
function, running on the destination host, sets the migration status to
'reverted' before dropping the move claim. This exposes the same race
that we previously saw with the confirm resize operation. It then calls
back to 'ComputeManager.finish_revert_resize' on the source host to boot
up the instance itself. This is kind of weird, because, even ignoring
the race, we're marking the migration as 'reverted' before we've done
any of the necessary work on the source host.

The cross-cell resize revert splits dropping of the move claim and
setting of the migration status between the source and destination host
tasks. Specifically, we do cleanup on the destination and drop the move
claim first, via 'ComputeManager.revert_snapshot_based_resize_at_dest'
before resuming the instance and setting the migration status on the
source via
'ComputeManager.finish_revert_snapshot_based_resize_at_source'. This
would appear to avoid the weird quirk of same-cell migration, however,
in typical weird cross-cell fashion, these are actually different
instances and different migration records.

The solution is once again to move the setting of the migration status
and the dropping of the claim under 'COMPUTE_RESOURCE_SEMAPHORE'. This
introduces the weird setting of migration status before completion to
the cross-cell resize case and perpetuates it in the same-cell case, but
this seems like a suitable compromise to avoid attempts to do things
like unplugging already unplugged PCI devices or unpinning already
unpinned CPUs. From an end-user perspective, instance state changes are
what really matter and once a revert is completed on the destination
host and the instance has been marked as having returned to the source
host, hard reboots can help us resolve any remaining issues.

Conflicts:
  nova/compute/manager.py
  nova/compute/resource_tracker.py
  nova/tests/unit/compute/test_compute_mgr.py

NOTE(stephenfin): The bulk of the conflicts are due to the absence of
various cross-cell resize related patches. The only exception is the
conflict in 'nova/compute/resource_tracker.py', which is due to the
absence of change Ia5e521e0f0c7a78b5ace5de9f343e84d872553f9 (""Use fair
locks in resource tracker"") which we can't backport since it requires a
feature only found in newer versions of 'oslo.concurrency' and mandates
a lower constraint bump.

Change-Id: I29d6f4a78c0206385a550967ce244794e71cef6d
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Closes-Bug: #1879878
(cherry picked from commit dc9c7a5ebf11253f86127238d33dff7401465155)
(cherry picked from commit 79a467e1cfa05b1c281e592e69549716c11892e5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/751369/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/functional/regressions/test_bug_1879878.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py']",7,13787c36d5d93b38b6a8835de46057078fec2eea,bug/1879878," def drop_move_claim_at_dest(self, context, instance, migration): """"""Drop a move claim after reverting a resize or cold migration."""""" # NOTE(stephenfin): This runs on the destination, before we return to # the source and resume the instance there. As such, the migration # isn't really really reverted yet, but this status is what we use to # indicate that we no longer needs to account for usage on this host migration.status = 'reverted' migration.save() self._drop_move_claim( context, instance, migration.dest_node, instance.new_flavor, prefix='new_') instance.revert_migration_context() instance.save(expected_task_state=[task_states.RESIZE_REVERTING]) @utils.synchronized(COMPUTE_RESOURCE_SEMAPHORE)",,63,45
openstack%2Fopenstack-helm-infra~master~I4f7913967185dd52d4301c218450cfad9d0e2b2b,openstack/openstack-helm-infra,master,I4f7913967185dd52d4301c218450cfad9d0e2b2b,[CEPH] Uplift from Nautilus to Octopus release,MERGED,2021-01-06 17:41:47.000000000,2021-02-04 23:35:22.000000000,2021-02-04 23:33:34.000000000,"[{'_account_id': 18511}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 28372}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}]","[{'number': 1, 'created': '2021-01-06 17:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9f67ec19532027132cc52f03498a1b82d0cc025a', 'message': '[CEPH] uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 2, 'created': '2021-01-06 18:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/69ec683f45f5b66beeab9cc48e91dba95ab1b690', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 3, 'created': '2021-01-06 21:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2e7529f5907681f9cab0c4dcc4039a9e739f5b08', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 4, 'created': '2021-01-08 16:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8e5ce59253cf66a074c9c545a71a6c68c5a91302', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 5, 'created': '2021-01-08 16:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/af09da53fabcacae8144cbdab48d4b2aae66f744', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 6, 'created': '2021-01-08 20:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/499945be561c49a6f33f832b8539dcec7b3b9847', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 7, 'created': '2021-01-08 21:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ff54a1b088db0744c94ba1b1518b35a390814c5', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 8, 'created': '2021-01-08 21:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e4885754f6e0fcd9595a64a8791b08b7ad09fc91', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 9, 'created': '2021-01-08 22:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6077452b4c26b0fc6f3bdb1e2763151df6fe7bde', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 10, 'created': '2021-01-11 18:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2cdc6529b8625fa102a227ba1ed64746558da4fc', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 11, 'created': '2021-01-11 18:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b8207ac2f7eb920470805f5b13146fcdf5ade8d', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 12, 'created': '2021-01-13 16:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f7103643815476c6f92ee2706c3aca2e0d570e5b', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 13, 'created': '2021-01-13 16:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e3c373f7fa6010b6bedf86427f0b5c10d934de75', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 14, 'created': '2021-01-13 17:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7aca5d7fc20df69a1982ee40639f3721e4b81f1b', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 15, 'created': '2021-01-13 20:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/574019424f4ae364d23f16a8c63344f749a939e1', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 16, 'created': '2021-01-14 14:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7e5f7091ee8485883f7cfd4b8a230a1e14673928', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 17, 'created': '2021-01-14 16:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/58a631a058d7dc833258171d851cce2fe94d79c0', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 18, 'created': '2021-01-19 23:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fac05aa5790255f0828c44fbf3c48f1c36f59d27', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 19, 'created': '2021-01-20 15:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/828171e85acd69e1baf9eb1107dd507f389fd2df', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 20, 'created': '2021-01-25 21:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9e99bfa0b4552564f7dc0e2c9a5e7834c8fbc453', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 21, 'created': '2021-01-26 15:56:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a85939e5eebc74f205a503c06f2cfe3ef50ec475', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 22, 'created': '2021-02-02 16:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e187522c7655591ef172b6566bcd005a073e4980', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 23, 'created': '2021-02-02 20:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2e5638e5f89ed557b491b483306b0112781b0459', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 24, 'created': '2021-02-02 21:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6111fe54e82fc4597fe36ecd90b04d6d703beadd', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 25, 'created': '2021-02-03 16:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/aa8328a226bd9d7ac418286666867690473cbee5', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 26, 'created': '2021-02-03 17:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ef2f3998ed0a083ff5e3d6475dc8457b9a722b2', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 27, 'created': '2021-02-03 17:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8f7b20c7cac97c65ae7bc1e728b06bd17e57a92c', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 28, 'created': '2021-02-03 18:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a2c5cd22883c39afccbe84f6def7b869e11d8af8', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 29, 'created': '2021-02-03 19:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a655fa16e56a6e3d51739a73172195647c6db646', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}, {'number': 30, 'created': '2021-02-03 22:34:53.000000000', 'files': ['ceph-mon/templates/bin/moncheck/_start.sh.tpl', 'ceph-osd/templates/bin/osd/ceph-disk/_common.sh.tpl', 'ceph-client/templates/bin/pool/_init.sh.tpl', 'ceph-osd/values.yaml', 'ceph-rgw/Chart.yaml', 'ceph-client/Chart.yaml', 'ceph-client/templates/bin/mgr/_start.sh.tpl', 'ceph-client/values.yaml', 'ceph-mon/templates/bin/keys/_bootstrap-keyring-manager.sh.tpl', 'ceph-provisioners/Chart.yaml', 'ceph-rgw/values.yaml', 'tools/deployment/osh-infra-logging/020-ceph.sh', 'ceph-osd/templates/bin/_helm-tests.sh.tpl', 'ceph-client/templates/bin/utils/_checkPGs.sh.tpl', 'ceph-client/templates/bin/_helm-tests.sh.tpl', 'ceph-client/templates/bin/utils/_checkPGs.py.tpl', 'ceph-mon/templates/bin/keys/_storage-keyring-manager.sh.tpl', 'ceph-osd/templates/bin/osd/ceph-volume/_common.sh.tpl', 'ceph-provisioners/values.yaml', 'ceph-osd/templates/bin/_post-apply.sh.tpl', 'ceph-mon/Chart.yaml', 'ceph-osd/Chart.yaml', 'ceph-mon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/da289c78cb8500525d5445e5cc2e0c4a113a7d21', 'message': '[CEPH] Uplift from Nautilus to Octopus release\n\nThis is to uplift ceph charts from 14.X release to 15.X\n\nChange-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b\n'}]",44,769572,da289c78cb8500525d5445e5cc2e0c4a113a7d21,90,8,30,28372,,,0,"[CEPH] Uplift from Nautilus to Octopus release

This is to uplift ceph charts from 14.X release to 15.X

Change-Id: I4f7913967185dd52d4301c218450cfad9d0e2b2b
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/72/769572/24 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-provisioners/values.yaml', 'ceph-osd/values.yaml', 'ceph-rgw/values.yaml', 'ceph-mon/values.yaml']",4,9f67ec19532027132cc52f03498a1b82d0cc025a,change-769572-17, ceph_bootstrap: 'docker.io/openstackhelm/ceph-daemon:ubuntu_bionic-20210106' ceph_config_helper: 'docker.io/openstackhelm/ceph-config-helper:ubuntu_bionic-20210106' ceph_mon: 'docker.io/openstackhelm/ceph-daemon:ubuntu_bionic-20210106' ceph_mon_check: 'docker.io/openstackhelm/ceph-config-helper:ubuntu_bionic-20210106', ceph_bootstrap: 'docker.io/openstackhelm/ceph-daemon:ubuntu_bionic-20200521' ceph_config_helper: 'docker.io/openstackhelm/ceph-config-helper:ubuntu_bionic-20200521' ceph_mon: 'docker.io/openstackhelm/ceph-daemon:ubuntu_bionic-20200521' ceph_mon_check: 'docker.io/openstackhelm/ceph-config-helper:ubuntu_bionic-20200521',15,15
openstack%2Fopenstack-helm-infra~master~I380a55b93e7aabb606e713c21d71a383fef78b3f,openstack/openstack-helm-infra,master,I380a55b93e7aabb606e713c21d71a383fef78b3f,Elasticsearch: Make templates job more generic,MERGED,2021-02-03 18:10:23.000000000,2021-02-04 23:24:34.000000000,2021-02-04 23:22:40.000000000,"[{'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 30582}, {'_account_id': 32090}]","[{'number': 1, 'created': '2021-02-03 18:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5743b78a14ddf8bb25b90cc219d41a29ed35531a', 'message': 'Elasticsearch: Make templates job more generic\n\nThis change updates the logic in our create-elasticsearch-templates\njob to support creation of a variety of different API endpoints.\n\nChange-Id: I380a55b93e7aabb606e713c21d71a383fef78b3f\n'}, {'number': 2, 'created': '2021-02-03 18:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4be88d260adcf4cd85b14e91149c863abf804336', 'message': 'Elasticsearch: Make templates job more generic\n\nThis change updates the logic in our create-elasticsearch-templates\njob to support creation of a variety of different API objects.\n\nChange-Id: I380a55b93e7aabb606e713c21d71a383fef78b3f\n'}, {'number': 3, 'created': '2021-02-03 20:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d9b8e87d734fe8527c3fe47f731ee2ab4e64dbb1', 'message': 'Elasticsearch: Make templates job more generic\n\nThis change updates the logic in our create-elasticsearch-templates\njob to support creation of a variety of different API objects.\n\nChange-Id: I380a55b93e7aabb606e713c21d71a383fef78b3f\n'}, {'number': 4, 'created': '2021-02-03 22:40:25.000000000', 'files': ['elasticsearch/templates/bin/_create_template.sh.tpl', 'elasticsearch/templates/configmap-etc-templates.yaml', 'elasticsearch/templates/job-elasticsearch-template.yaml', 'elasticsearch/templates/bin/_helm-tests.sh.tpl', 'elasticsearch/values.yaml', 'elasticsearch/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0ab71ae35cae80457c8ed9e8f33d8ba35a5ca537', 'message': 'Elasticsearch: Make templates job more generic\n\nThis change updates the logic in our create-elasticsearch-templates\njob to support creation of a variety of different API objects.\n\nChange-Id: I380a55b93e7aabb606e713c21d71a383fef78b3f\n'}]",5,773977,0ab71ae35cae80457c8ed9e8f33d8ba35a5ca537,17,5,4,30777,,,0,"Elasticsearch: Make templates job more generic

This change updates the logic in our create-elasticsearch-templates
job to support creation of a variety of different API objects.

Change-Id: I380a55b93e7aabb606e713c21d71a383fef78b3f
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/77/773977/1 && git format-patch -1 --stdout FETCH_HEAD,"['elasticsearch/templates/bin/_create_template.sh.tpl', 'elasticsearch/templates/configmap-etc-templates.yaml', 'elasticsearch/templates/job-elasticsearch-template.yaml', 'elasticsearch/templates/bin/_helm-tests.sh.tpl', 'elasticsearch/values.yaml']",5,5743b78a14ddf8bb25b90cc219d41a29ed35531a,," helm_tests: docker.io/openstackhelm/elasticsearch-s3:latest-7_6_2 elasticsearch_templates: docker.io/openstackhelm/elasticsearch-s3:latest-7_6_2 api_objects: - endpoint: _template/fluent body: index_patterns: ""logstash-*"" settings: index: number_of_shards: 1 mappings: properties: kubernetes: properties: container_name: type: keyword index: false docker_id: type: keyword index: false host: type: keyword index: false namespace_name: type: keyword index: false pod_id: type: keyword index: false pod_name: type: keyword index: false - endpoint: _ilm/policy/delete_all_indexes body: policy: phases: delete: min_age: 14d actions: delete: {} - endpoint: _slm/policy/non-security-snapshots body: schedule: ""0 30 1 * * ?"" name: ""<non-security-logs-snapshot-{now/d}>"" repository: logstash_snapshots config: indices: [""^(.*calico-|.*ceph-|.*jenkins-|.*journal-|.*kernel_syslog-|.*kubernetes-|.*libvirt-|.*logstash-|.*openvswitch-|.*utility_access-).*$""] ignore_unavailable: true include_global_state: false wait_for_completion: true max_wait: 64800 wait_interval: 30 ignore_empty_list: true continue_if_exception: true disable_action: false retention: expire_after: 29d - endpoint: _slm/policy/security-snapshots body: schedule: ""0 30 1 * * ?"" name: ""<security-logs-snapshot-{now/d}>"" repository: logstash_snapshots config: indices: [""^(.*airship-|.*audit_tsee-|.*auth-|.*flows-|.*lma-|.*openstack-).*$""] ignore_unavailable: true include_global_state: false wait_for_completion: true max_wait: 18000 wait_interval: 30 ignore_empty_list: true continue_if_exception: true disable_action: false retention: expire_after: 179d"," helm_tests: docker.io/openstackhelm/heat:newton-ubuntu_xenial elasticsearch_templates: docker.io/openstackhelm/heat:newton templates: fluent: index_patterns: ""logstash-*"" settings: index: number_of_shards: 1 mappings: properties: kubernetes: properties: container_name: type: keyword index: false docker_id: type: keyword index: false host: type: keyword index: false namespace_name: type: keyword index: false pod_id: type: keyword index: false pod_name: type: keyword index: false snapshot_policies: non-security-snapshots: schedule: ""0 30 1 * * ?"" name: ""<non-security-logs-snapshot-{now/d}>"" repository: logstash_snapshots config: indices: [""^(.*calico-|.*ceph-|.*jenkins-|.*journal-|.*kernel_syslog-|.*kubernetes-|.*libvirt-|.*logstash-|.*openvswitch-|.*utility_access-).*$""] ignore_unavailable: true include_global_state: false wait_for_completion: true max_wait: 64800 wait_interval: 30 ignore_empty_list: true continue_if_exception: true disable_action: false retention: expire_after: 29d security-snapshots: schedule: ""0 30 1 * * ?"" name: ""<security-logs-snapshot-{now/d}>"" repository: logstash_snapshots config: indices: [""^(.*airship-|.*audit_tsee-|.*auth-|.*flows-|.*lma-|.*openstack-).*$""] ignore_unavailable: true include_global_state: false wait_for_completion: true max_wait: 18000 wait_interval: 30 ignore_empty_list: true continue_if_exception: true disable_action: false retention: expire_after: 179d index_policies: delete_all_indexes: policy: phases: delete: min_age: 14d actions: delete: {}",84,176
openstack%2Fcharm-mysql-innodb-cluster~master~I5abc14d8c6793a18fe5a95c66e9f0a3c5d46d5fe,openstack/charm-mysql-innodb-cluster,master,I5abc14d8c6793a18fe5a95c66e9f0a3c5d46d5fe,Rebuild to use charm-tools pre 2.8 release,MERGED,2021-02-02 17:10:27.000000000,2021-02-04 22:59:24.000000000,2021-02-04 22:59:24.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 17:10:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/e84d86289072dbb57cb7275fe4c3be7c1e759f05', 'message': 'Rebuild to use charm-tools pre 2.8 release\n\nReverting to an earlier version of charm-tools to\nresolve some building issues seen with latest 2.8.2\nversion.\n\nChange-Id: I5abc14d8c6793a18fe5a95c66e9f0a3c5d46d5fe\n'}]",0,773755,e84d86289072dbb57cb7275fe4c3be7c1e759f05,10,3,1,20870,,,0,"Rebuild to use charm-tools pre 2.8 release

Reverting to an earlier version of charm-tools to
resolve some building issues seen with latest 2.8.2
version.

Change-Id: I5abc14d8c6793a18fe5a95c66e9f0a3c5d46d5fe
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/55/773755/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e84d86289072dbb57cb7275fe4c3be7c1e759f05,sync-for-21-01,"charm-tools>=2.4.4,<2.8",charm-tools>=2.4.4,1,1
openstack%2Fnova~stable%2Ftrain~Ifd19f636f58ae353d912bde57cba2cd0a29a9baa,openstack/nova,stable/train,Ifd19f636f58ae353d912bde57cba2cd0a29a9baa,Fix a hacking test,MERGED,2020-12-19 08:20:51.000000000,2021-02-04 22:57:53.000000000,2021-02-04 22:55:41.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2020-12-19 08:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12f824585990eeea809c05850af81225d981f840', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n(cherry picked from commit f4d62e1a0b77f9611a3be8427adafd96caf24bb1)\n(cherry picked from commit 7562e64dee54a36162c3c181214aa269068f1712)\n'}, {'number': 2, 'created': '2021-01-09 08:56:04.000000000', 'files': ['nova/tests/unit/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6cc7e9aacf8d66a6a881ed698f36bb9e4443c0d', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n(cherry picked from commit f4d62e1a0b77f9611a3be8427adafd96caf24bb1)\n(cherry picked from commit 7562e64dee54a36162c3c181214aa269068f1712)\n'}]",0,767793,b6cc7e9aacf8d66a6a881ed698f36bb9e4443c0d,14,4,2,7634,,,0,"Fix a hacking test

In test_useless_assertion,
the useless_assertion method should be checked instead of
nonexistent_assertion_methods_and_attributes.

Change-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)
(cherry picked from commit f4d62e1a0b77f9611a3be8427adafd96caf24bb1)
(cherry picked from commit 7562e64dee54a36162c3c181214aa269068f1712)
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/767793/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_hacking.py'],1,12f824585990eeea809c05850af81225d981f840,fix_hacking_test-stable/train," code, checks.useless_assertion,"," code, checks.nonexistent_assertion_methods_and_attributes,",1,1
openstack%2Fnova~stable%2Fussuri~Ib1e3798992696cf5f271b20bc731b8b766d173ac,openstack/nova,stable/ussuri,Ib1e3798992696cf5f271b20bc731b8b766d173ac,[doc]: Fix glance image_metadata link,MERGED,2020-11-09 18:20:15.000000000,2021-02-04 22:44:27.000000000,2021-02-04 22:40:32.000000000,"[{'_account_id': 4690}, {'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-11-09 18:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a689a411f6c6a202d158151187a5f210c393c7b7', 'message': '[doc]: Fix glance image_metadata link\n\nChange-Id: Ib1e3798992696cf5f271b20bc731b8b766d173ac\nCloses-Bug: #1900731\n(cherry picked from commit f5a68826c7820f571de5bb02c8a516ab89ec641b)\n(cherry picked from commit a919cc0cbd7d0929befec4de957ff203be366ae4)\n'}, {'number': 2, 'created': '2020-11-11 08:46:04.000000000', 'files': ['doc/source/admin/configuration/hypervisor-xen-libvirt.rst', 'doc/source/admin/huge-pages.rst', 'doc/source/admin/cpu-topologies.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/97330d65e173e97c600b4ab9206cd2dd4499e95a', 'message': '[doc]: Fix glance image_metadata link\n\nChange-Id: Ib1e3798992696cf5f271b20bc731b8b766d173ac\nCloses-Bug: #1900731\n(cherry picked from commit f5a68826c7820f571de5bb02c8a516ab89ec641b)\n(cherry picked from commit a919cc0cbd7d0929befec4de957ff203be366ae4)\n'}]",0,761977,97330d65e173e97c600b4ab9206cd2dd4499e95a,14,6,2,17685,,,0,"[doc]: Fix glance image_metadata link

Change-Id: Ib1e3798992696cf5f271b20bc731b8b766d173ac
Closes-Bug: #1900731
(cherry picked from commit f5a68826c7820f571de5bb02c8a516ab89ec641b)
(cherry picked from commit a919cc0cbd7d0929befec4de957ff203be366ae4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/761977/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/configuration/hypervisor-xen-libvirt.rst', 'doc/source/admin/huge-pages.rst', 'doc/source/admin/cpu-topologies.rst']",3,a689a411f6c6a202d158151187a5f210c393c7b7,bug/1900731,.. _`Image metadata`: https://docs.openstack.org/image-guide/introduction.html#image-metadata,.. _`Image metadata`: https://docs.openstack.org/image-guide/image-metadata.html,3,3
openstack%2Fneutron~master~Iad52edda8c737585ff2fca59c032be38ba673d57,openstack/neutron,master,Iad52edda8c737585ff2fca59c032be38ba673d57,Use constants from neutron-lib,MERGED,2021-02-02 13:16:22.000000000,2021-02-04 22:42:55.000000000,2021-02-04 22:39:12.000000000,"[{'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-02 13:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea4408fb32006e39f0641f2bb28e644bc3bb7604', 'message': 'Use constants from neutron-lib\n\nConstants were released in neutron-lib 2.8.0\n\nChange-Id: Iad52edda8c737585ff2fca59c032be38ba673d57\n'}, {'number': 2, 'created': '2021-02-04 06:33:49.000000000', 'files': ['neutron/services/qos/qos_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ffeb0d623975071acfa406b0bf54cfd780ee3a7', 'message': 'Use constants from neutron-lib\n\nConstants were released in neutron-lib 2.8.0\n\nChange-Id: Iad52edda8c737585ff2fca59c032be38ba673d57\n'}]",0,773683,6ffeb0d623975071acfa406b0bf54cfd780ee3a7,35,4,2,32667,,,0,"Use constants from neutron-lib

Constants were released in neutron-lib 2.8.0

Change-Id: Iad52edda8c737585ff2fca59c032be38ba673d57
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/773683/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/qos/qos_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/services/trunk/plugin.py']",3,ea4408fb32006e39f0641f2bb28e644bc3bb7604,fix_todo, @resource_extend.extends([port_def.COLLECTION_NAME_BULK]), # TODO(obondarev): use neutron_lib constant @resource_extend.extends(['ports_bulk']),4,6
openstack%2Fnova~stable%2Fussuri~Ie15ec8299ae52ae8f5334d591ed3944e9585cf71,openstack/nova,stable/ussuri,Ie15ec8299ae52ae8f5334d591ed3944e9585cf71,Warn when starting services with older than N-1 computes,MERGED,2021-01-14 09:25:14.000000000,2021-02-04 22:42:52.000000000,2021-02-04 22:39:27.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-14 09:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bfdd7f5920f533159ed4225063e65032392fe21', 'message': ""Warn when starting services with older than N-1 computes\n\nNova services only support computes that are not older than\nthe previous major release. This patch introduces a check in the\nservice startup that warns at staring the service if too old computes\nare detected.\n\nThis is a partial backport from master. As we agreed on the Wallaby PTG\n[1] we would like to backport the check but we don't want to make it a\nhard failure of the service startup as that felt too harsh for a stable\nbranch. So this patch changes the behavior from hard failure to emitting\na warning in the log.\n\nThis commit also contains two bugfixes from master squashed into it to\navoid merging broken code:\n\n* Improve error handling during service level check\n  Change-Id: I89cdf3852266ed93a2ac7cd6261fe269932026ac\n  cherry picked from commit 3b44275868e08992a36e9163f533d689f27a0119\n\n* Restore retrying the RPC connection to conductor\n  Change-Id: Iad0ba1a02868eebc2f43b1ac843fcc5096cd5c47\n  cherry picked from commit 433bee58bc8d7d65edb6a0805021e51972e6bed6\n\n[1] https://etherpad.opendev.org/p/nova-wallaby-ptg\n\nCloses-Bug: #1903545\nRelated-Bug: #1871482\nCloses-Bug: #1904181\n\nChange-Id: Ie15ec8299ae52ae8f5334d591ed3944e9585cf71\n(cherry picked from commit aa7c6f87699ec1340bd446a7d47e1453847a637f)\n(cherry picked from commit 0c5ca351e27ca74610478d8af9777de0db5c0acc)\n""}, {'number': 2, 'created': '2021-01-29 16:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ab833ab7e646b95d3fad6b871a0959b7d0a129e', 'message': ""Warn when starting services with older than N-1 computes\n\nNova services only support computes that are not older than\nthe previous major release. This patch introduces a check in the\nservice startup that warns at staring the service if too old computes\nare detected.\n\nThis is a partial backport from master. As we agreed on the Wallaby PTG\n[1] we would like to backport the check but we don't want to make it a\nhard failure of the service startup as that felt too harsh for a stable\nbranch. So this patch changes the behavior from hard failure to emitting\na warning in the log.\n\nThis commit also contains two bugfixes from master squashed into it to\navoid merging broken code:\n\n* Improve error handling during service level check\n  Change-Id: I89cdf3852266ed93a2ac7cd6261fe269932026ac\n  cherry picked from commit 3b44275868e08992a36e9163f533d689f27a0119\n\n* Restore retrying the RPC connection to conductor\n  Change-Id: Iad0ba1a02868eebc2f43b1ac843fcc5096cd5c47\n  cherry picked from commit 433bee58bc8d7d65edb6a0805021e51972e6bed6\n\nstable/ussuri specific change:\n* need to use six.text_type() instead of str() as we still support\n  python2.7\n\n[1] https://etherpad.opendev.org/p/nova-wallaby-ptg\n\nCloses-Bug: #1903545\nRelated-Bug: #1871482\nCloses-Bug: #1904181\n\nChange-Id: Ie15ec8299ae52ae8f5334d591ed3944e9585cf71\n(cherry picked from commit aa7c6f87699ec1340bd446a7d47e1453847a637f)\n(cherry picked from commit 0c5ca351e27ca74610478d8af9777de0db5c0acc)\n""}, {'number': 3, 'created': '2021-02-01 16:11:32.000000000', 'files': ['releasenotes/notes/warn-when-services-started-with-old-compute-fc80b4ff58a2aaea.yaml', 'nova/api/openstack/wsgi_app.py', 'nova/objects/service.py', 'nova/tests/unit/api/openstack/test_requestlog.py', 'nova/tests/unit/test_utils.py', 'nova/tests/unit/test_fixtures.py', 'nova/tests/functional/test_service.py', 'nova/service.py', 'nova/tests/unit/test_service.py', 'nova/exception.py', 'doc/source/contributor/ptl-guide.rst', 'nova/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75bac345d5d579591f6f7f047f0c8f68b4e89002', 'message': ""Warn when starting services with older than N-1 computes\n\nNova services only support computes that are not older than\nthe previous major release. This patch introduces a check in the\nservice startup that warns at staring the service if too old computes\nare detected.\n\nThis is a partial backport from master. As we agreed on the Wallaby PTG\n[1] we would like to backport the check but we don't want to make it a\nhard failure of the service startup as that felt too harsh for a stable\nbranch. So this patch changes the behavior from hard failure to emitting\na warning in the log.\n\nThis commit also contains two bugfixes from master squashed into it to\navoid merging broken code:\n\n* Improve error handling during service level check\n  Change-Id: I89cdf3852266ed93a2ac7cd6261fe269932026ac\n  cherry picked from commit 3b44275868e08992a36e9163f533d689f27a0119\n\n* Restore retrying the RPC connection to conductor\n  Change-Id: Iad0ba1a02868eebc2f43b1ac843fcc5096cd5c47\n  cherry picked from commit 433bee58bc8d7d65edb6a0805021e51972e6bed6\n\nstable/ussuri specific change:\n* need to use six.text_type() instead of str() as we still support\n  python2.7\n\n[1] https://etherpad.opendev.org/p/nova-wallaby-ptg\n\nCloses-Bug: #1903545\nRelated-Bug: #1871482\nCloses-Bug: #1904181\n\nChange-Id: Ie15ec8299ae52ae8f5334d591ed3944e9585cf71\n(cherry picked from commit aa7c6f87699ec1340bd446a7d47e1453847a637f)\n(cherry picked from commit 0c5ca351e27ca74610478d8af9777de0db5c0acc)\n""}]",3,770764,75bac345d5d579591f6f7f047f0c8f68b4e89002,21,3,3,9708,,,0,"Warn when starting services with older than N-1 computes

Nova services only support computes that are not older than
the previous major release. This patch introduces a check in the
service startup that warns at staring the service if too old computes
are detected.

This is a partial backport from master. As we agreed on the Wallaby PTG
[1] we would like to backport the check but we don't want to make it a
hard failure of the service startup as that felt too harsh for a stable
branch. So this patch changes the behavior from hard failure to emitting
a warning in the log.

This commit also contains two bugfixes from master squashed into it to
avoid merging broken code:

* Improve error handling during service level check
  Change-Id: I89cdf3852266ed93a2ac7cd6261fe269932026ac
  cherry picked from commit 3b44275868e08992a36e9163f533d689f27a0119

* Restore retrying the RPC connection to conductor
  Change-Id: Iad0ba1a02868eebc2f43b1ac843fcc5096cd5c47
  cherry picked from commit 433bee58bc8d7d65edb6a0805021e51972e6bed6

stable/ussuri specific change:
* need to use six.text_type() instead of str() as we still support
  python2.7

[1] https://etherpad.opendev.org/p/nova-wallaby-ptg

Closes-Bug: #1903545
Related-Bug: #1871482
Closes-Bug: #1904181

Change-Id: Ie15ec8299ae52ae8f5334d591ed3944e9585cf71
(cherry picked from commit aa7c6f87699ec1340bd446a7d47e1453847a637f)
(cherry picked from commit 0c5ca351e27ca74610478d8af9777de0db5c0acc)
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/770764/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/warn-when-services-started-with-old-compute-fc80b4ff58a2aaea.yaml', 'nova/api/openstack/wsgi_app.py', 'nova/objects/service.py', 'nova/tests/unit/api/openstack/test_requestlog.py', 'nova/tests/unit/test_utils.py', 'nova/tests/unit/test_fixtures.py', 'nova/tests/functional/test_service.py', 'nova/service.py', 'nova/tests/unit/test_service.py', 'nova/exception.py', 'doc/source/contributor/ptl-guide.rst', 'nova/utils.py']",12,8bfdd7f5920f533159ed4225063e65032392fe21,bug/1904181," def raise_if_old_compute(): # to avoid circular imports from nova import context as nova_context from nova.objects import service ctxt = nova_context.get_admin_context() if CONF.api_database.connection is not None: scope = 'system' try: current_service_version = service.get_minimum_version_all_cells( ctxt, ['nova-compute']) except exception.DBNotAllowed: # This most likely means we are in a nova-compute service # which is configured with a connection to the API database. # We should not be attempting to ""get out"" of our cell to # look at the minimum versions of nova-compute services in other # cells, so DBNotAllowed was raised. Leave a warning message # and fall back to only querying computes in our cell. LOG.warning( 'This service is configured for access to the API database ' 'but is not allowed to directly access the database. You ' 'should run this service without the ' '[api_database]/connection config option. The service version ' 'check will only query the local cell.') scope = 'cell' current_service_version = service.Service.get_minimum_version( ctxt, 'nova-compute') else: scope = 'cell' # We in a cell so target our query to the current cell only current_service_version = service.Service.get_minimum_version( ctxt, 'nova-compute') if current_service_version == 0: # 0 means no compute in the system, # probably a fresh install before the computes are registered return oldest_supported_service_level = service.SERVICE_VERSION_ALIASES[ service.OLDEST_SUPPORTED_SERVICE_VERSION] if current_service_version < oldest_supported_service_level: raise exception.TooOldComputeService( oldest_supported_version=service.OLDEST_SUPPORTED_SERVICE_VERSION, scope=scope, min_service_level=current_service_version, oldest_supported_service=oldest_supported_service_level)",,242,1
openstack%2Fnova~stable%2Fussuri~Id0577bceed9808b52da4acc352cf9c204f6c8861,openstack/nova,stable/ussuri,Id0577bceed9808b52da4acc352cf9c204f6c8861,Reproduce bug 1896463 in func env,MERGED,2021-01-14 09:56:31.000000000,2021-02-04 22:39:54.000000000,2021-02-04 22:39:54.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-14 09:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46227e2702f3b6e9743ba63861a745a3df77d5e2', 'message': 'Reproduce bug 1896463 in func env\n\nThere is a race condition between the rebuild and the\n_update_available_resource periodic task on the compute. This patch adds\na reproducer functional test. Unfortunately it needs some injected sleep\nto make the race happen in a stable way. This is suboptimal but only\nadds 3 seconds of slowness to the test execution.\n\nChange-Id: Id0577bceed9808b52da4acc352cf9c204f6c8861\nRelated-Bug: #1896463\n(cherry picked from commit 3f348602ae4a40c52c7135b2cb48deaa6052c488)\n(cherry picked from commit d768cdbb88d0b0b3ca38623c4bb26d5eabdf1596)\n'}, {'number': 2, 'created': '2021-01-29 16:28:27.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1896463.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/02114a9d7f2e8b62d3a7091ca3fde251dfffa860', 'message': 'Reproduce bug 1896463 in func env\n\nThere is a race condition between the rebuild and the\n_update_available_resource periodic task on the compute. This patch adds\na reproducer functional test. Unfortunately it needs some injected sleep\nto make the race happen in a stable way. This is suboptimal but only\nadds 3 seconds of slowness to the test execution.\n\nstable/ussuri specific changes:\n\n* GlanceFixture does not exist as\n  I6daea47988181dfa6dde3d9c42004c0ecf6ae87a is not in ussuri\n\n* MigrationList.get_in_progress_and_error was added in\n  I422a907056543f9bf95acbffdd2658438febf801 which is not in ussuri\n\nChange-Id: Id0577bceed9808b52da4acc352cf9c204f6c8861\nRelated-Bug: #1896463\n(cherry picked from commit 3f348602ae4a40c52c7135b2cb48deaa6052c488)\n(cherry picked from commit d768cdbb88d0b0b3ca38623c4bb26d5eabdf1596)\n'}]",0,770768,02114a9d7f2e8b62d3a7091ca3fde251dfffa860,15,3,2,9708,,,0,"Reproduce bug 1896463 in func env

There is a race condition between the rebuild and the
_update_available_resource periodic task on the compute. This patch adds
a reproducer functional test. Unfortunately it needs some injected sleep
to make the race happen in a stable way. This is suboptimal but only
adds 3 seconds of slowness to the test execution.

stable/ussuri specific changes:

* GlanceFixture does not exist as
  I6daea47988181dfa6dde3d9c42004c0ecf6ae87a is not in ussuri

* MigrationList.get_in_progress_and_error was added in
  I422a907056543f9bf95acbffdd2658438febf801 which is not in ussuri

Change-Id: Id0577bceed9808b52da4acc352cf9c204f6c8861
Related-Bug: #1896463
(cherry picked from commit 3f348602ae4a40c52c7135b2cb48deaa6052c488)
(cherry picked from commit d768cdbb88d0b0b3ca38623c4bb26d5eabdf1596)
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/770768/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1896463.py'],1,46227e2702f3b6e9743ba63861a745a3df77d5e2,bug/1896463,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import copy import fixtures import time from oslo_config import cfg from nova import context from nova import objects from nova import test from nova.tests import fixtures as nova_fixtures from nova.tests.functional import fixtures as func_fixtures from nova.tests.functional import integrated_helpers from nova import utils from nova.virt import fake CONF = cfg.CONF class TestEvacuateResourceTrackerRace( test.TestCase, integrated_helpers.InstanceHelperMixin, ): """"""Demonstrate bug #1896463. Trigger a race condition between an almost finished evacuation that is dropping the migration context, and the _update_available_resource() periodic task that already loaded the instance list but haven't loaded the migration list yet. The result is that the PCI allocation made by the evacuation is deleted by the overlapping periodic task run and the instance will not have PCI allocation after the evacuation. """""" def setUp(self): super().setUp() self.neutron = self.useFixture(nova_fixtures.NeutronFixture(self)) self.glance = self.useFixture(nova_fixtures.GlanceFixture(self)) self.placement = self.useFixture(func_fixtures.PlacementFixture()).api self.api_fixture = self.useFixture(nova_fixtures.OSAPIFixture( api_version='v2.1')) self.admin_api = self.api_fixture.admin_api self.admin_api.microversion = 'latest' self.api = self.admin_api self.start_service('conductor') self.start_service('scheduler') self.flags(compute_driver='fake.FakeDriverWithPciResources') self.useFixture( fake.FakeDriverWithPciResources. FakeDriverWithPciResourcesConfigFixture()) self.compute1 = self._start_compute('host1') self.compute1_id = self._get_compute_node_id_by_host('host1') self.compute1_service_id = self.admin_api.get_services( host='host1', binary='nova-compute')[0]['id'] self.compute2 = self._start_compute('host2') self.compute2_id = self._get_compute_node_id_by_host('host2') self.compute2_service_id = self.admin_api.get_services( host='host2', binary='nova-compute')[0]['id'] # add extra ports and the related network to the neutron fixture # specifically for these tests. It cannot be added globally in the # fixture init as it adds a second network that makes auto allocation # based test to fail due to ambiguous networks. self.neutron._ports[self.neutron.sriov_port['id']] = \ copy.deepcopy(self.neutron.sriov_port) self.neutron._networks[ self.neutron.network_2['id']] = self.neutron.network_2 self.neutron._subnets[ self.neutron.subnet_2['id']] = self.neutron.subnet_2 self.ctxt = context.get_admin_context() def _get_compute_node_id_by_host(self, host): # we specifically need the integer id of the node not the UUID so we # need to use the old microversion with utils.temporary_mutation(self.admin_api, microversion='2.52'): hypers = self.admin_api.api_get( 'os-hypervisors').body['hypervisors'] for hyper in hypers: if hyper['hypervisor_hostname'] == host: return hyper['id'] self.fail('Hypervisor with hostname=%s not found' % host) def _assert_pci_device_allocated( self, instance_uuid, compute_node_id, num=1): """"""Assert that a given number of PCI devices are allocated to the instance on the given host. """""" devices = objects.PciDeviceList.get_by_instance_uuid( self.ctxt, instance_uuid) devices_on_host = [dev for dev in devices if dev.compute_node_id == compute_node_id] self.assertEqual(num, len(devices_on_host)) def test_evacuate_races_with_update_available_resource(self): # Create a server with a direct port to have PCI allocation server = self._create_server( name='test-server-for-bug-1896463', networks=[{'port': self.neutron.sriov_port['id']}], host='host1' ) self._assert_pci_device_allocated(server['id'], self.compute1_id) self._assert_pci_device_allocated( server['id'], self.compute2_id, num=0) # stop and force down the compute the instance is on to allow # evacuation self.compute1.stop() self.admin_api.put_service( self.compute1_service_id, {'forced_down': 'true'}) # Inject some sleeps both in the Instance.drop_migration_context and # the MigrationList.get_in_progress_and_error code to make them # overlap. # We want to create the following execution scenario: # 1) The evacuation makes a move claim on the dest including the PCI # claim. This means there is a migration context. But the evacuation # is not complete yet so the instance.host does not point to the # dest host. # 2) The dest resource tracker starts an _update_available_resource() # periodic task and this task loads the list of instances on its # host from the DB. Our instance is not in this list due to #1. # 3) The evacuation finishes, the instance.host is set to the dest host # and the migration context is deleted. # 4) The periodic task now loads the list of in-progress migration from # the DB to check for incoming our outgoing migrations. However due # to #3 our instance is not in this list either. # 5) The periodic task cleans up every lingering PCI claim that is not # connected to any instance collected above from the instance list # and from the migration list. As our instance is not in either of # the lists, the resource tracker cleans up the PCI allocation for # the already finished evacuation of our instance. # # Unfortunately we cannot reproduce the above situation without sleeps. # We need that the evac starts first then the periodic starts, but not # finishes, then evac finishes, then periodic finishes. If I trigger # and run the whole periodic in a wrapper of drop_migration_context # then I could not reproduce the situation described at #4). In general # it is not # # evac # | # | # | periodic # | | # | | # | x # | # | # x # # but # # evac # | # | # | periodic # | | # | | # | | # x | # | # x # # what is needed need. # # Starting the periodic from the test in a separate thread at # drop_migration_context() might work but that is an extra complexity # in the test code. Also it might need a sleep still to make the # reproduction stable but only one sleep instead of two. orig_drop = objects.Instance.drop_migration_context def slow_drop(*args, **kwargs): time.sleep(1) return orig_drop(*args, **kwargs) self.useFixture( fixtures.MockPatch( 'nova.objects.instance.Instance.drop_migration_context', new=slow_drop)) orig_get_mig = objects.MigrationList.get_in_progress_and_error def slow_get_mig(*args, **kwargs): time.sleep(2) return orig_get_mig(*args, **kwargs) self.useFixture( fixtures.MockPatch( 'nova.objects.migration.MigrationList.' 'get_in_progress_and_error', new=slow_get_mig)) self.admin_api.post_server_action(server['id'], {'evacuate': {}}) # we trigger the _update_available_resource periodic to overlap with # the already started evacuation self._run_periodics() self._wait_for_server_parameter( server, {'OS-EXT-SRV-ATTR:host': 'host2', 'status': 'ACTIVE'}) self._assert_pci_device_allocated(server['id'], self.compute1_id) # This is bug #1896463 as the PCI allocation was deleted by the racing # _update_available_resource periodic task. self._assert_pci_device_allocated( server['id'], self.compute2_id, num=0) # FIXME(gibi): When this bug is fixed (or if you remove the sleeps # above to avoid the race condition) then we expect that the PCI # allocation exists on the destination host too. # self._assert_pci_device_allocated(server['id'], self.compute2_id) ",,231,0
openstack%2Ftripleo-common~stable%2Fvictoria~Iba06dc0f8afe9bc6a8820742c656dca5bf75df15,openstack/tripleo-common,stable/victoria,Iba06dc0f8afe9bc6a8820742c656dca5bf75df15,Fix placement endpoint check when endpoints are not set,MERGED,2021-02-02 10:25:22.000000000,2021-02-04 21:28:48.000000000,2021-02-04 21:26:47.000000000,"[{'_account_id': 6816}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2021-02-02 10:25:22.000000000', 'files': ['tripleo_common/tests/utils/test_plan.py', 'tripleo_common/utils/plan.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3b3c9fc0fb29cab93cbca7390958e1e4caa733a0', 'message': ""Fix placement endpoint check when endpoints are not set\n\nWhen endpoint are not set in the heat resource, None is returned, not an empty\ndict. The check then raises a 'NoneType' is not iterable exception.\n\nFix the logic to handle None and update the unit test.\n\nCloses-bug: #1913416\nChange-Id: Iba06dc0f8afe9bc6a8820742c656dca5bf75df15\n(cherry picked from commit 86d0e65a2905f46eca05cbf4070f97feaa392463)\n""}]",0,773590,3b3c9fc0fb29cab93cbca7390958e1e4caa733a0,12,8,1,26343,,,0,"Fix placement endpoint check when endpoints are not set

When endpoint are not set in the heat resource, None is returned, not an empty
dict. The check then raises a 'NoneType' is not iterable exception.

Fix the logic to handle None and update the unit test.

Closes-bug: #1913416
Change-Id: Iba06dc0f8afe9bc6a8820742c656dca5bf75df15
(cherry picked from commit 86d0e65a2905f46eca05cbf4070f97feaa392463)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/90/773590/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/utils/test_plan.py', 'tripleo_common/utils/plan.py']",2,3b3c9fc0fb29cab93cbca7390958e1e4caa733a0,," placement_extracted = False endpoints = endpoint_res.attributes.get('endpoint_map', None) placement_extracted = endpoints and 'PlacementPublic' in endpoints except heat_exc.HTTPNotFound: pass"," endpoints = endpoint_res.attributes.get('endpoint_map', {}) placement_extracted = 'PlacementPublic' in endpoints except heat_exc.HTTPNotFound: placement_extracted = False",5,4
openstack%2Fos-net-config~stable%2Fussuri~I17d19715a1f7c231630416d6fea06fe9afe44e9b,openstack/os-net-config,stable/ussuri,I17d19715a1f7c231630416d6fea06fe9afe44e9b,Exclude DPDK mapped VF device even if not present,MERGED,2021-01-25 04:21:42.000000000,2021-02-04 21:28:35.000000000,2021-02-04 21:26:23.000000000,"[{'_account_id': 11166}, {'_account_id': 12398}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-01-25 04:21:42.000000000', 'files': ['os_net_config/utils.py', 'os_net_config/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/fa0fd2e3540cf32d4e559d95f23a2ae5111ac5b7', 'message': 'Exclude DPDK mapped VF device even if not present\n\nAs part of FFU from queens to train, os-net-config\nwill run after the RHEL update. At this point, DPDK\nmapping file will have VF if it has been used as\npart of NIC partitioning feature, but the physically\nthe VF will not be present as it is yet to be created.\nDuring the active nic list creation (before creating\nVFs), DPDK mapped VF will be used as regular nic,\nwhich results in wrong nic numbering.\n\nThis patch excludes the VFs by checking the device\ntype in the sriov_config.yaml mapping file, so that\nthe nic numbering will be kept same.\n\nChange-Id: I17d19715a1f7c231630416d6fea06fe9afe44e9b\n(cherry picked from commit 4f2ebfd6bd90e5247dc2bddf67146e713919a437)\n'}]",0,772221,fa0fd2e3540cf32d4e559d95f23a2ae5111ac5b7,9,5,1,18575,,,0,"Exclude DPDK mapped VF device even if not present

As part of FFU from queens to train, os-net-config
will run after the RHEL update. At this point, DPDK
mapping file will have VF if it has been used as
part of NIC partitioning feature, but the physically
the VF will not be present as it is yet to be created.
During the active nic list creation (before creating
VFs), DPDK mapped VF will be used as regular nic,
which results in wrong nic numbering.

This patch excludes the VFs by checking the device
type in the sriov_config.yaml mapping file, so that
the nic numbering will be kept same.

Change-Id: I17d19715a1f7c231630416d6fea06fe9afe44e9b
(cherry picked from commit 4f2ebfd6bd90e5247dc2bddf67146e713919a437)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/21/772221/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/utils.py', 'os_net_config/tests/test_utils.py']",2,fa0fd2e3540cf32d4e559d95f23a2ae5111ac5b7,avoid_dpdk_sriov_vf-stable/victoria-stable/ussuri," def test_ordered_active_nics_with_dpdk_mapping_of_vf(self): tmpdir = tempfile.mkdtemp() self.stub_out('os_net_config.utils._SYS_CLASS_NET', tmpdir) tmp_pci_dir = tempfile.mkdtemp() self.stub_out('os_net_config.utils._SYS_BUS_PCI_DEV', tmp_pci_dir) physfn_path = utils._SYS_BUS_PCI_DEV + '/0000:05:01.1/physfn' os.makedirs(physfn_path) def test_is_available_nic(interface_name, check_active): return True self.stub_out('os_net_config.utils._is_available_nic', test_is_available_nic) utils._update_dpdk_map('eth2_0', '0000:06:01.1', 'AA:02:03:04:05:FE', 'vfio-pci') utils.update_sriov_vf_map('eth2', 0, 'eth2_0') nics = utils.ordered_active_nics() self.assertEqual(len(nics), 0) shutil.rmtree(tmpdir) shutil.rmtree(tmp_pci_dir) ",,33,1
openstack%2Ftripleo-common~stable%2Ftrain~Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f,openstack/tripleo-common,stable/train,Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f,Use the new IPA-builder element for installing python-hardware,MERGED,2021-01-29 14:53:54.000000000,2021-02-04 21:28:31.000000000,2021-02-04 21:26:43.000000000,"[{'_account_id': 8449}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-29 14:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/54cc18553a89432b00003714d32aa8fe175c2870', 'message': 'Use the new IPA-builder element for installing python-hardware\n\nChange-Id: Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f\nDepends-On: https://review.opendev.org/#/c/753966/\n(cherry picked from commit be437cb1e341c437ddd8d6901ce107982bb808df)\n'}, {'number': 2, 'created': '2021-02-02 05:58:01.000000000', 'files': ['image-yaml/overcloud-images.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2ec51ff8bd63247dc5f1c380cdacf5e8e8f869e3', 'message': ""Use the new IPA-builder element for installing python-hardware\n\nAlso use quotes for DIB_EPEL_DISABLED as without that it fails\nin python2, in ussuri+ releases it's not needed as those are\npython3 only.\n  \n\nChange-Id: Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f\nDepends-On: https://review.opendev.org/#/c/753966/\n(cherry picked from commit be437cb1e341c437ddd8d6901ce107982bb808df)\n""}]",2,773010,2ec51ff8bd63247dc5f1c380cdacf5e8e8f869e3,20,5,2,13861,,,0,"Use the new IPA-builder element for installing python-hardware

Also use quotes for DIB_EPEL_DISABLED as without that it fails
in python2, in ussuri+ releases it's not needed as those are
python3 only.
  

Change-Id: Id75c11e5b7c4f3bf73c962bc7e46f5a6021efc5f
Depends-On: https://review.opendev.org/#/c/753966/
(cherry picked from commit be437cb1e341c437ddd8d6901ce107982bb808df)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/10/773010/1 && git format-patch -1 --stdout FETCH_HEAD,['image-yaml/overcloud-images.yaml'],1,54cc18553a89432b00003714d32aa8fe175c2870,extra-hardware-stable/ussuri-stable/train, - extra-hardware DIB_EPEL_DISABLED: 1, packages: - python-hardware-detect,2,2
openstack%2Fos-net-config~stable%2Ftrain~I17d19715a1f7c231630416d6fea06fe9afe44e9b,openstack/os-net-config,stable/train,I17d19715a1f7c231630416d6fea06fe9afe44e9b,Exclude DPDK mapped VF device even if not present,MERGED,2021-01-25 04:21:57.000000000,2021-02-04 21:28:20.000000000,2021-02-04 21:26:26.000000000,"[{'_account_id': 11166}, {'_account_id': 12398}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-01-25 04:21:57.000000000', 'files': ['os_net_config/utils.py', 'os_net_config/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/3c733272f56bdb7324a3476fe635ec3ddea8a3cf', 'message': 'Exclude DPDK mapped VF device even if not present\n\nAs part of FFU from queens to train, os-net-config\nwill run after the RHEL update. At this point, DPDK\nmapping file will have VF if it has been used as\npart of NIC partitioning feature, but the physically\nthe VF will not be present as it is yet to be created.\nDuring the active nic list creation (before creating\nVFs), DPDK mapped VF will be used as regular nic,\nwhich results in wrong nic numbering.\n\nThis patch excludes the VFs by checking the device\ntype in the sriov_config.yaml mapping file, so that\nthe nic numbering will be kept same.\n\nChange-Id: I17d19715a1f7c231630416d6fea06fe9afe44e9b\n(cherry picked from commit 4f2ebfd6bd90e5247dc2bddf67146e713919a437)\n'}]",0,772222,3c733272f56bdb7324a3476fe635ec3ddea8a3cf,8,5,1,18575,,,0,"Exclude DPDK mapped VF device even if not present

As part of FFU from queens to train, os-net-config
will run after the RHEL update. At this point, DPDK
mapping file will have VF if it has been used as
part of NIC partitioning feature, but the physically
the VF will not be present as it is yet to be created.
During the active nic list creation (before creating
VFs), DPDK mapped VF will be used as regular nic,
which results in wrong nic numbering.

This patch excludes the VFs by checking the device
type in the sriov_config.yaml mapping file, so that
the nic numbering will be kept same.

Change-Id: I17d19715a1f7c231630416d6fea06fe9afe44e9b
(cherry picked from commit 4f2ebfd6bd90e5247dc2bddf67146e713919a437)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/22/772222/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/utils.py', 'os_net_config/tests/test_utils.py']",2,3c733272f56bdb7324a3476fe635ec3ddea8a3cf,avoid_dpdk_sriov_vf-stable/victoria-stable/ussuri-stable/train," def test_ordered_active_nics_with_dpdk_mapping_of_vf(self): tmpdir = tempfile.mkdtemp() self.stub_out('os_net_config.utils._SYS_CLASS_NET', tmpdir) tmp_pci_dir = tempfile.mkdtemp() self.stub_out('os_net_config.utils._SYS_BUS_PCI_DEV', tmp_pci_dir) physfn_path = utils._SYS_BUS_PCI_DEV + '/0000:05:01.1/physfn' os.makedirs(physfn_path) def test_is_available_nic(interface_name, check_active): return True self.stub_out('os_net_config.utils._is_available_nic', test_is_available_nic) utils._update_dpdk_map('eth2_0', '0000:06:01.1', 'AA:02:03:04:05:FE', 'vfio-pci') utils.update_sriov_vf_map('eth2', 0, 'eth2_0') nics = utils.ordered_active_nics() self.assertEqual(len(nics), 0) shutil.rmtree(tmpdir) shutil.rmtree(tmp_pci_dir) ",,33,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,openstack/tripleo-heat-templates,stable/train,I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""",MERGED,2021-01-12 11:00:24.000000000,2021-02-04 21:26:17.000000000,2021-02-04 21:26:17.000000000,"[{'_account_id': 7144}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-01-12 11:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4fb331b152aabf04503465a62cca442788ba3fda', 'message': 'Revert ""Reset sriov_numvfs to 0 before leapp upgrade""\n\nThis reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.\n\nReason for revert: Work is in progress to get the issue fixed in leapp itself via PR https://github.com/oamg/leapp-repository/pull/631\n\nChange-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c\n'}, {'number': 2, 'created': '2021-01-12 11:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d06427ca68792756f5bf859fbf44749c4741c5e9', 'message': 'Revert ""Reset sriov_numvfs to 0 before leapp upgrade""\n\nThis reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.\n\nReason for revert: Work is in progress to get the\nissue fixed in leapp itself via\nPR https://github.com/oamg/leapp-repository/pull/631\n\nChange-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c\n'}, {'number': 3, 'created': '2021-02-01 13:20:37.000000000', 'files': ['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c68c4428dddb08d5a26e8183cef40fd78b7cd21', 'message': 'Revert ""Reset sriov_numvfs to 0 before leapp upgrade""\n\nThis reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.\n\nReason for revert: The patch was introduced as a workaround\nto fix the leapp issue reproduced in v0.10.0 which throws\nexception when the interface is not found. But with the\nrecent version of the leapp package, the issue is not\nreproducible. The leapp upgrade completes succesfully\neven with VFs present. Though the actual leapp commit which\nfixed the issue not traced, the issue is no more present.\nThis workaround can be removed from TripleO, so that\nnic paritioning FFU can be supported.\n\nThis revert is required for nic paritioning FFU, because\nresetting the VFs will hang, when one of the VF is bound\nto the vfio-pci (DPDK) driver.\n\nChange-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c\n(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)\n(cherry picked from commit 81a18403304f6f7dbb1a58be68875cc809ad28c4)\n'}]",0,770184,0c68c4428dddb08d5a26e8183cef40fd78b7cd21,15,7,3,18575,,,0,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""

This reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.

Reason for revert: The patch was introduced as a workaround
to fix the leapp issue reproduced in v0.10.0 which throws
exception when the interface is not found. But with the
recent version of the leapp package, the issue is not
reproducible. The leapp upgrade completes succesfully
even with VFs present. Though the actual leapp commit which
fixed the issue not traced, the issue is no more present.
This workaround can be removed from TripleO, so that
nic paritioning FFU can be supported.

This revert is required for nic paritioning FFU, because
resetting the VFs will hang, when one of the VF is bound
to the vfio-pci (DPDK) driver.

Change-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c
(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)
(cherry picked from commit 81a18403304f6f7dbb1a58be68875cc809ad28c4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/770184/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'],1,4fb331b152aabf04503465a62cca442788ba3fda,,"<<<<<<< HEAD (65ac38 Merge ""Adding key_size option on the certificate creation"" i)======= upgrade_tasks: [] >>>>>>> CHANGE (65b0b3 Revert ""Reset sriov_numvfs to 0 before leapp upgrade"")",,4,0
openstack%2Fneutron-tempest-plugin~master~I45629e89ca357306c3fad607647eb30baedfec04,openstack/neutron-tempest-plugin,master,I45629e89ca357306c3fad607647eb30baedfec04,Delete router test - API scenario,MERGED,2020-11-17 18:40:24.000000000,2021-02-04 21:03:04.000000000,2021-02-04 21:03:04.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18894}, {'_account_id': 19118}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28609}, {'_account_id': 29088}, {'_account_id': 29350}, {'_account_id': 31450}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-11-17 18:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/7c224f755d2003840457559fefd4fc0bfb8aa6c0', 'message': 'Delete router. End to End scenario.\n\nTest scenario:\n1) Create: network, subnet, port and router (External Gateway)\n2) Create the VM with FIP and check connectivity\n3) Try to delete router prior to VM/port delete (should fail)\n4) Delete router after removing all associated resources (PASS)\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 2, 'created': '2020-12-18 18:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f0d2eb286d6d80ce6e0a02d3294c6f8e07e4053a', 'message': 'Delete router. End to End scenario.\n\nTest scenario:\n1) Create: network, subnet, port and router (External Gateway)\n2) Create the VM with FIP and check connectivity\n3) Try to delete router prior to VM/port delete (should fail)\n4) Delete router after removing all associated resources (PASS)\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 3, 'created': '2020-12-19 17:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/807fd6ed853a8d0edcc4038754b02b4178662eb7', 'message': 'Delete router. End to End scenario.\n\nTest scenario:\n1) Create: network, subnet, port and router (External Gateway)\n2) Create the VM with FIP and check connectivity\n3) Try to delete router prior to VM/port delete (should fail)\n4) Delete router after removing all associated resources (PASS)\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 4, 'created': '2021-01-26 16:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/93291757eeeaae1b616d40517819ebd5ca5dac95', 'message': 'Delete router: ""End to End scenario""\n\nTest scenario:\n1) Create the VM with FIP and check connectivity\n2) Try to delete router prior to VM/port delete (should fail)\n3) Delete router after removing all associated resources (PASS)\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 5, 'created': '2021-01-27 09:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/be1744e9f26a96ab2d22617c0a738e1e74d05e16', 'message': 'Delete router: ""End to End scenario""\n\nTest scenario:\n1) Create the VM with FIP and check connectivity\n2) Try to delete router prior to VM/port delete (should fail)\n3) Delete router after removing all associated resources (PASS)\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 6, 'created': '2021-01-31 11:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/0b15f60e5e0bd173744fd96610baf70bf9172756', 'message': 'Delete router API scenario test\n\nTest scenario:\n1) Associate port with FIP to the router\n2) Try to delete router, should FAIL\n3) Delete port\n4) Delete router\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 7, 'created': '2021-01-31 13:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/def2e68cff2047c620606313d4fb5311f4cfffac', 'message': 'Delete router API scenario test\n\nTest scenario:\n1) Associate port with FIP to the router\n2) Try to delete router, should FAIL\n3) Delete port\n4) Delete router\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 8, 'created': '2021-02-01 10:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/149fe2d564c0bcf232f4d74555c9c82e4a018712', 'message': 'Delete router test - API scenario\n\nTest scenario:\n1) Associate port with FIP to the router\n2) Try to delete router - Error is raised\n3) Delete port and router - should PASS\n\nNote: this patch removes ""old test"" in:\nneutron_tempest_plugin/api/test_routers_negative.py L:44\nbecause this test is actually removes router when it has no dependencies\nand it\'s not about the ""Error"" validation only.\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}, {'number': 9, 'created': '2021-02-03 17:03:33.000000000', 'files': ['neutron_tempest_plugin/api/test_routers_negative.py', 'neutron_tempest_plugin/api/test_routers.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/b667ac366ca85618bf83f4ba0cebdc33b6bd3215', 'message': 'Delete router test - API scenario\n\nTest tries to delete router, up untill the last is finally deleted.\n""Conflict Errors"" are covered for each router\'s ""in use"" port.\n\nNote: this patch removes ""old test"" in:\nneutron_tempest_plugin/api/test_routers_negative.py L:44\nbecause this test is actually removes router when it has no dependencies\nand it\'s not about the ""Error"" validation only.\n\nChange-Id: I45629e89ca357306c3fad607647eb30baedfec04\n'}]",29,763072,b667ac366ca85618bf83f4ba0cebdc33b6bd3215,56,12,9,28609,,,0,"Delete router test - API scenario

Test tries to delete router, up untill the last is finally deleted.
""Conflict Errors"" are covered for each router's ""in use"" port.

Note: this patch removes ""old test"" in:
neutron_tempest_plugin/api/test_routers_negative.py L:44
because this test is actually removes router when it has no dependencies
and it's not about the ""Error"" validation only.

Change-Id: I45629e89ca357306c3fad607647eb30baedfec04
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/72/763072/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_routers.py'],1,7c224f755d2003840457559fefd4fc0bfb8aa6c0,router_delete,"# Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import waiters from tempest.lib.common.utils import data_utils from tempest.lib import decorators from tempest.lib import exceptions as lib_exc from neutron_tempest_plugin import config from neutron_tempest_plugin.scenario import base from neutron_tempest_plugin.scenario import constants as const CONF = config.CONF class RoutersTest(base.BaseTempestTestCase): credentials = ['primary'] @classmethod def resource_setup(cls): super(RoutersTest, cls).resource_setup() # setup basic topology for servers we can log into it cls.router = cls.create_router_by_client() cls.keypair = cls.create_keypair() cls.secgroup = cls.create_security_group( name=data_utils.rand_name(""test_port_secgroup"")) cls.create_loginable_secgroup_rule( secgroup_id=cls.secgroup['id']) cls.create_pingable_secgroup_rule( secgroup_id=cls.secgroup['id']) cls.network = cls.create_network() cls.subnet = cls.create_subnet(cls.network) cls.create_router_interface(cls.router['id'], cls.subnet['id']) cls.port = cls.create_port(cls.network, name=data_utils.rand_name(""port""), security_groups=[cls.secgroup['id']]) @decorators.idempotent_id('5b766a72-28d7-11eb-8253-74e5f9e2a801') def test_delete_router(self): # This test cannot run in parallel with other tests in this script. # That is why we cannot use all ""common"" resources created in # resource_setup. router_kwargs = { 'router_name': data_utils.rand_name('router_to_delete')} router = self.create_router_by_client(**router_kwargs) network = self.create_network() subnet = self.create_subnet(network) self.create_router_interface(router['id'], subnet['id']) port = self.create_port( network, name=data_utils.rand_name(""port""), security_groups=[self.secgroup['id']]) # Create the VM with FIP and check connectivity. server_args = { 'flavor_ref': CONF.compute.flavor_ref, 'image_ref': CONF.compute.image_ref, 'key_name': self.keypair['name'], 'networks': [{'port': port['id']}] } server = self.create_server(**server_args) waiters.wait_for_server_status( self.os_primary.servers_client, server['server']['id'], const.SERVER_STATUS_ACTIVE) fip = self.create_floatingip(port=port) self.check_connectivity(fip['floating_ip_address'], CONF.validation.image_ssh_user, self.keypair['private_key']) # Try to delete router, should fail self.assertRaises(lib_exc.Conflict, self.delete_router, router) # Delete the VM and try to delete router, should fail. self.os_primary.servers_client.delete_server(server['server']['id']) self.assertRaises(lib_exc.Conflict, self.delete_router, router) # Delete port associated with router and try to delete # router, should PASS self.client.delete_port(port['id']) self.delete_router(router) ",,86,0
openstack%2Fpython-tripleoclient~master~Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5,openstack/python-tripleoclient,master,Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5,Disable swift on undercloud,MERGED,2021-01-28 03:57:35.000000000,2021-02-04 20:51:09.000000000,2021-02-04 20:48:55.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-28 03:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6f8a1fa58e6527542cb4022e03b829de5901d8f3', 'message': ""WIP Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772826\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 2, 'created': '2021-01-28 04:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a298d3342bd46d174ed3dc488078b840eb6c912d', 'message': ""WIP Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772826\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 3, 'created': '2021-01-28 06:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/37e558f061132aa4e370defda90986bfcb8fb5ac', 'message': ""WIP Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772826\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 4, 'created': '2021-01-28 12:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/11e26de674dcd3bb0ac79a3d0c59e40759928248', 'message': ""WIP Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 5, 'created': '2021-01-29 03:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/42d850fccf55b4580dab5910177949164c48d4bb', 'message': ""Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift. Not sure if those are required.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 6, 'created': '2021-01-29 03:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bdaaded988b58f4f4ebe92a8c45ead45ab5f310b', 'message': ""Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift. Not sure if those are required.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 7, 'created': '2021-02-01 04:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/cf5c582a54f15abfd589d958f072b62b876489e0', 'message': ""Disable swift on undercloud\n\nWe still need to do something about the export commands\n'overcloud export' and 'cell export' which export data\nto swift. Not sure if those are required.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n""}, {'number': 8, 'created': '2021-02-01 05:26:00.000000000', 'files': ['tripleoclient/config/undercloud.py', 'tripleoclient/tests/config/test_config_undercloud.py', 'tripleoclient/tests/v1/undercloud/test_install_upgrade.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/876b24b55d0f57786dac78d244899c998aa3e87e', 'message': 'Disable swift on undercloud\n\nThis disables swift on the undercloud.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870\nChange-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5\n'}]",0,772827,876b24b55d0f57786dac78d244899c998aa3e87e,47,6,8,8833,,,0,"Disable swift on undercloud

This disables swift on the undercloud.

Depends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/772870
Change-Id: Ib6c895a3263df6accdc75dd52fe2b10f12d6a7e5
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/27/772827/6 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/overcloud_deploy.py'],1,6f8a1fa58e6527542cb4022e03b829de5901d8f3,env_merging," None, self.orchestration_client, env, stack, None, stack_name)"," self.object_client = self.clients.tripleoclient.object_store self.object_client, self.orchestration_client, env, stack, self.object_client, stack_name) # TODO(sbaker) Remove this call when it is no longer necessary # to write to a swift object",2,5
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,openstack/tripleo-heat-templates,stable/ussuri,I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""",MERGED,2021-02-01 13:15:08.000000000,2021-02-04 20:49:22.000000000,2021-02-04 20:49:22.000000000,"[{'_account_id': 7144}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-01 13:15:08.000000000', 'files': ['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81a18403304f6f7dbb1a58be68875cc809ad28c4', 'message': 'Revert ""Reset sriov_numvfs to 0 before leapp upgrade""\n\nThis reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.\n\nReason for revert: The patch was introduced as a workaround\nto fix the leapp issue reproduced in v0.10.0 which throws\nexception when the interface is not found. But with the\nrecent version of the leapp package, the issue is not\nreproducible. The leapp upgrade completes succesfully\neven with VFs present. Though the actual leapp commit which\nfixed the issue not traced, the issue is no more present.\nThis workaround can be removed from TripleO, so that\nnic paritioning FFU can be supported.\n\nThis revert is required for nic paritioning FFU, because\nresetting the VFs will hang, when one of the VF is bound\nto the vfio-pci (DPDK) driver.\n\nChange-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c\n(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)\n'}]",0,773211,81a18403304f6f7dbb1a58be68875cc809ad28c4,7,6,1,18575,,,0,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""

This reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.

Reason for revert: The patch was introduced as a workaround
to fix the leapp issue reproduced in v0.10.0 which throws
exception when the interface is not found. But with the
recent version of the leapp package, the issue is not
reproducible. The leapp upgrade completes succesfully
even with VFs present. Though the actual leapp commit which
fixed the issue not traced, the issue is no more present.
This workaround can be removed from TripleO, so that
nic paritioning FFU can be supported.

This revert is required for nic paritioning FFU, because
resetting the VFs will hang, when one of the VF is bound
to the vfio-pci (DPDK) driver.

Change-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c
(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/11/773211/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'],1,81a18403304f6f7dbb1a58be68875cc809ad28c4,ffu16_remove_sriov_devs-stable/victoria-stable/ussuri, upgrade_tasks: []," upgrade_tasks: - name: upgrade prepare for leapp to remove extra sriov vfs tags: - never - system_upgrade - system_upgrade_prepare when: - step|int == 3 - upgrade_leapp_enabled block: - name: reset all vfs as leapp will look for all interfaces on reboot shell: | for item in $(find /sys/class/net/ -type l); do DEVPATH=""$item/device/sriov_numvfs"" if [ -f $DEVPATH ]; then NUM_VFS=$(cat $DEVPATH) if [[ $NUM_VFS != 0 ]]; then echo 0 >$DEVPATH fi fi done - name: remove sriov_config service for leapp upgrade file: path: ""/etc/systemd/system/sriov_config.service"" state: absent register: sriov_config_remove_result - name: reload systemd daemon after removing sriov_config service systemd: daemon-reload: yes when: sriov_config_remove_result['changed']",1,30
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,openstack/tripleo-heat-templates,stable/victoria,I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""",MERGED,2021-02-01 13:14:48.000000000,2021-02-04 20:49:00.000000000,2021-02-04 20:49:00.000000000,"[{'_account_id': 7144}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2021-02-01 13:14:48.000000000', 'files': ['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ae7ab696d8d8968d6c506c0f97dcc2f11f16ce0a', 'message': 'Revert ""Reset sriov_numvfs to 0 before leapp upgrade""\n\nThis reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.\n\nReason for revert: The patch was introduced as a workaround\nto fix the leapp issue reproduced in v0.10.0 which throws\nexception when the interface is not found. But with the\nrecent version of the leapp package, the issue is not\nreproducible. The leapp upgrade completes succesfully\neven with VFs present. Though the actual leapp commit which\nfixed the issue not traced, the issue is no more present.\nThis workaround can be removed from TripleO, so that\nnic paritioning FFU can be supported.\n\nThis revert is required for nic paritioning FFU, because\nresetting the VFs will hang, when one of the VF is bound\nto the vfio-pci (DPDK) driver.\n\nChange-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c\n(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)\n'}]",0,773210,ae7ab696d8d8968d6c506c0f97dcc2f11f16ce0a,13,6,1,18575,,,0,"Revert ""Reset sriov_numvfs to 0 before leapp upgrade""

This reverts commit b3ec034649e0d18de78fcfe5f903cfe9a0a18a6a.

Reason for revert: The patch was introduced as a workaround
to fix the leapp issue reproduced in v0.10.0 which throws
exception when the interface is not found. But with the
recent version of the leapp package, the issue is not
reproducible. The leapp upgrade completes succesfully
even with VFs present. Though the actual leapp commit which
fixed the issue not traced, the issue is no more present.
This workaround can be removed from TripleO, so that
nic paritioning FFU can be supported.

This revert is required for nic paritioning FFU, because
resetting the VFs will hang, when one of the VF is bound
to the vfio-pci (DPDK) driver.

Change-Id: I5ab1d2925989fc3da62e6045e56a7bd017c8ec4c
(cherry picked from commit c4d75bc147d0e5fe56b9445d23f0a1ea7a34b141)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/10/773210/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/neutron/neutron-sriov-agent-container-puppet.yaml'],1,ae7ab696d8d8968d6c506c0f97dcc2f11f16ce0a,ffu16_remove_sriov_devs-stable/victoria, upgrade_tasks: []," upgrade_tasks: - name: upgrade prepare for leapp to remove extra sriov vfs tags: - never - system_upgrade - system_upgrade_prepare when: - step|int == 3 - upgrade_leapp_enabled block: - name: reset all vfs as leapp will look for all interfaces on reboot shell: | for item in $(find /sys/class/net/ -type l); do DEVPATH=""$item/device/sriov_numvfs"" if [ -f $DEVPATH ]; then NUM_VFS=$(cat $DEVPATH) if [[ $NUM_VFS != 0 ]]; then echo 0 >$DEVPATH fi fi done - name: remove sriov_config service for leapp upgrade file: path: ""/etc/systemd/system/sriov_config.service"" state: absent register: sriov_config_remove_result - name: reload systemd daemon after removing sriov_config service systemd: daemon-reload: yes when: sriov_config_remove_result['changed']",1,30
openstack%2Fnova~master~I30a040d549f48d53cab2c59c00bb269f821ace88,openstack/nova,master,I30a040d549f48d53cab2c59c00bb269f821ace88,functional: Add tests for mixed CPU policy,MERGED,2020-10-02 17:17:08.000000000,2021-02-04 20:46:30.000000000,2021-02-04 20:44:10.000000000,"[{'_account_id': 5754}, {'_account_id': 7634}, {'_account_id': 8864}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-10-02 17:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/104665ea83aae12dfb3c23babbd620c9103d290c', 'message': 'functional: Add tests for mixed CPU policy\n\nI\'m not sure why these weren\'t included in the series, but they help\nprove out what this is doing.\n\nThis highlights a small bug in the code, whereby the topology object\nassociated with the instance doesn\'t have the correct number of CPUs.\nThis doesn\'t seem to have any adverse effects since I am able to create\nan instance without the ""fix"" and the XML looks correct, but we correct\nit here nonetheless.\n\nSome tests are renamed now that we\'re testing more than one ""legacy""\npolicy.\n\nPart of blueprint use-pcpu-and-vcpu-in-one-instance\n\nChange-Id: I30a040d549f48d53cab2c59c00bb269f821ace88\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2020-10-05 13:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93ac51d2f90daf87680ac54e60cbd1d741afbacb', 'message': 'functional: Add tests for mixed CPU policy\n\nI\'m not sure why these weren\'t included in the series, but they help\nprove out what this is doing.\n\nThis highlights a small ""bug"" in the code, whereby the topology object\nassociated with the instance\'s NUMA cell doesn\'t have the correct number\nof CPUs. This has no adverse effects since that attribute isn\'t actually\nused except to indicate a minimum thread count necessary for the cell,\nbut it is wrong as we fix it all the same.\n\nSome tests are renamed now that we\'re testing more than one ""legacy""\npolicy.\n\nPart of blueprint use-pcpu-and-vcpu-in-one-instance\n\nChange-Id: I30a040d549f48d53cab2c59c00bb269f821ace88\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2020-10-06 09:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24abe0f57cd4d38dfdca0fbe15ebcb9d4ec510a0', 'message': 'functional: Add tests for mixed CPU policy\n\nI\'m not sure why these weren\'t included in the series, but they help\nprove out what this is doing.\n\nThis highlights a small ""bug"" in the code, whereby the topology object\nassociated with the instance\'s NUMA cell doesn\'t have the correct number\nof CPUs. This has no adverse effects since that attribute isn\'t actually\nused except to indicate a minimum thread count necessary for the cell,\nbut it is wrong as we fix it all the same.\n\nSome tests are renamed now that we\'re testing more than one ""legacy""\npolicy.\n\nPart of blueprint use-pcpu-and-vcpu-in-one-instance\n\nChange-Id: I30a040d549f48d53cab2c59c00bb269f821ace88\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 4, 'created': '2020-10-12 09:40:21.000000000', 'files': ['nova/virt/hardware.py', 'nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/583e85622bf9d7e2fdf2a8cf5157bbd1ec5f8b2b', 'message': 'functional: Add tests for mixed CPU policy\n\nI\'m not sure why these weren\'t included in the series, but they help\nprove out what this is doing.\n\nThis highlights a small ""bug"" in the code, whereby the topology object\nassociated with the instance\'s NUMA cell doesn\'t have the correct number\nof CPUs. This has no adverse effects since that attribute isn\'t actually\nused except to indicate a minimum thread count necessary for the cell,\nbut it is wrong as we fix it all the same.\n\nSome tests are renamed now that we\'re testing more than one ""legacy""\npolicy.\n\nPart of blueprint use-pcpu-and-vcpu-in-one-instance\n\nChange-Id: I30a040d549f48d53cab2c59c00bb269f821ace88\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",14,755852,583e85622bf9d7e2fdf2a8cf5157bbd1ec5f8b2b,50,16,4,15334,,,0,"functional: Add tests for mixed CPU policy

I'm not sure why these weren't included in the series, but they help
prove out what this is doing.

This highlights a small ""bug"" in the code, whereby the topology object
associated with the instance's NUMA cell doesn't have the correct number
of CPUs. This has no adverse effects since that attribute isn't actually
used except to indicate a minimum thread count necessary for the cell,
but it is wrong as we fix it all the same.

Some tests are renamed now that we're testing more than one ""legacy""
policy.

Part of blueprint use-pcpu-and-vcpu-in-one-instance

Change-Id: I30a040d549f48d53cab2c59c00bb269f821ace88
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/755852/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/hardware.py', 'nova/tests/functional/libvirt/test_numa_servers.py']",2,104665ea83aae12dfb3c23babbd620c9103d290c,bug/1898272," expected_core_usages = ( expected_usage.get('VCPU', 0) + expected_usage.get('PCPU', 0) ) def test_create_server_with_dedicated_policy(self): """"""Create a server using the 'hw:cpu_policy=dedicated' extra spec. def test_create_server_with_mixed_policy(self): """"""Create a server using the 'hw:cpu_policy=mixed' extra spec. This should pass and result in a guest NUMA topology with a mixture of pinned and unpinned CPUs. """""" # configure the flags so we 2 shared, 2 dedicated CPUs on one node and # 1 shared and 3 dedicated on the other; the guest will request the # latter so it should always land on the second NUMA node self.flags( cpu_dedicated_set='2-3,5-7', cpu_shared_set='0,1,4', group='compute') self.flags(vcpu_pin_set=None) host_info = fakelibvirt.HostInfo( cpu_nodes=2, cpu_sockets=1, cpu_cores=4, cpu_threads=1, kB_mem=15740000) self.start_compute(host_info=host_info, hostname='compute1') # sanity check the created host topology object; this is really just a # test of the fakelibvirt module host_numa = objects.NUMATopology.obj_from_db_obj( objects.ComputeNode.get_by_nodename( self.ctxt, 'compute1', ).numa_topology ) self.assertEqual(2, len(host_numa.cells)) self.assertEqual({0, 1}, host_numa.cells[0].cpuset) self.assertEqual({2, 3}, host_numa.cells[0].pcpuset) self.assertEqual({4}, host_numa.cells[1].cpuset) self.assertEqual({5, 6, 7}, host_numa.cells[1].pcpuset) # create a flavor with 1 shared and 3 dedicated CPUs so that we can # validate that both come from the same host NUMA node extra_spec = { 'hw:cpu_policy': 'mixed', 'hw:cpu_dedicated_mask': '^0', } flavor_id = self._create_flavor(vcpu=4, extra_spec=extra_spec) expected_usage = { 'DISK_GB': 20, 'MEMORY_MB': 2048, 'PCPU': 3, 'VCPU': 1, } server = self._run_build_test(flavor_id, expected_usage=expected_usage) # sanity check the instance topology inst = objects.Instance.get_by_uuid(self.ctxt, server['id']) self.assertEqual(1, len(inst.numa_topology.cells)) self.assertEqual(4, inst.numa_topology.cells[0].cpu_topology.cores) self.assertEqual({0}, inst.numa_topology.cells[0].cpuset) self.assertEqual({1, 2, 3}, inst.numa_topology.cells[0].pcpuset) self.assertEqual( {5, 6, 7}, set(inst.numa_topology.cells[0].cpu_pinning.values()), ) def test_create_server_with_dedicated_policy_old_configuration(self): def test_create_server_with_dedicated_policy_fails(self): def test_create_server_with_dedicated_policy_quota_fails(self):"," expected_core_usages = expected_usage.get( 'VCPU', expected_usage.get('PCPU', 0)) def test_create_server_with_legacy_pinning_policy(self): """"""Create a server using the legacy 'hw:cpu_policy' extra spec. def test_create_server_with_legacy_pinning_policy_old_configuration(self): def test_create_server_with_legacy_pinning_policy_fails(self): def test_create_server_with_legacy_pinning_policy_quota_fails(self):",68,10
openstack%2Ftripleo-heat-templates~master~Icc8a9e2c80660b0dcc29a75183550917667d030c,openstack/tripleo-heat-templates,master,Icc8a9e2c80660b0dcc29a75183550917667d030c,Don't use swift backend for introspection data,MERGED,2021-01-28 12:08:34.000000000,2021-02-04 20:27:26.000000000,2021-02-04 20:25:44.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2021-01-28 12:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/741d8ea3c03cd319abb42e194f3f3980eb42b39d', 'message': ""Don't use swift backend for introspection data\n\nAs we plan to remove swift from undercloud we probably\nhave to change this to not store introspection data.\nWe may change to database if we want to store and\nthat would have an upgrade impact.\n\nChange-Id: Icc8a9e2c80660b0dcc29a75183550917667d030c\n""}, {'number': 2, 'created': '2021-01-28 16:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26b6e9a8f20a73075c1c9ea131ae7c72a5866517', 'message': ""Don't use swift backend for introspection data\n\nThis adds a new tht parameter to set introspection\ndata storage backend.\n\nAs we plan to remove swift from undercloud, we change\nthis to database for it.\n\nChange-Id: Icc8a9e2c80660b0dcc29a75183550917667d030c\n""}, {'number': 3, 'created': '2021-02-01 05:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/983928d32ae7904a90acb9f99e1bb97a53f290f7', 'message': ""Don't use swift backend for introspection data\n\nThis adds a new tht parameter to set introspection\ndata storage backend.\n\nAs we plan to remove swift from undercloud, we change\nthis to database for it.\n\nChange-Id: Icc8a9e2c80660b0dcc29a75183550917667d030c\n""}, {'number': 4, 'created': '2021-02-04 09:45:44.000000000', 'files': ['deployment/ironic/ironic-inspector-container-puppet.yaml', 'environments/undercloud.yaml', 'releasenotes/notes/add-IronicInspectorStorageBackend-parameter-9dd87e751b576007.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c35df2f7c3e117e02ed0577b08ed03da43504ce3', 'message': ""Don't use swift backend for introspection data\n\nThis adds a new tht parameter to set introspection\ndata storage backend.\n\nAs we plan to remove swift from undercloud, we change\nthis to database for it.\n\nChange-Id: Icc8a9e2c80660b0dcc29a75183550917667d030c\n""}]",9,772870,c35df2f7c3e117e02ed0577b08ed03da43504ce3,37,7,4,8833,,,0,"Don't use swift backend for introspection data

This adds a new tht parameter to set introspection
data storage backend.

As we plan to remove swift from undercloud, we change
this to database for it.

Change-Id: Icc8a9e2c80660b0dcc29a75183550917667d030c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/70/772870/4 && git format-patch -1 --stdout FETCH_HEAD,['environments/undercloud.yaml'],1,741d8ea3c03cd319abb42e194f3f3980eb42b39d,env_merging, IronicInspectorUseSwift: false,,1,0
openstack%2Ftripleo-upgrade~stable%2Fussuri~Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,openstack/tripleo-upgrade,stable/ussuri,Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,[live-migration] Count all hosts from all tenants for migration timeout,MERGED,2021-02-04 09:59:48.000000000,2021-02-04 20:25:40.000000000,2021-02-04 20:25:40.000000000,"[{'_account_id': 11166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 09:59:48.000000000', 'files': ['templates/node_upgrade_pre.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/427260995c45f194f41fc73711533a97743a056a', 'message': '[live-migration] Count all hosts from all tenants for migration timeout\n\nChange-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9\n(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)\n'}]",0,773960,427260995c45f194f41fc73711533a97743a056a,6,2,1,6816,,,0,"[live-migration] Count all hosts from all tenants for migration timeout

Change-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9
(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/60/773960/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/node_upgrade_pre.sh.j2'],1,427260995c45f194f41fc73711533a97743a056a,,"INSTANCE_COUNT=$(openstack server list --all --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')","INSTANCE_COUNT=$(openstack server list --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')",1,1
openstack%2Fnetworking-ovn~stable%2Ftrain~Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e,openstack/networking-ovn,stable/train,Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e,Remove testing OVS/OVN master branch in Train,MERGED,2019-11-28 14:17:44.000000000,2021-02-04 19:30:08.000000000,2021-02-04 19:23:46.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-11-28 14:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/73e0241e8f61ffb3cdd138b31b4e58e148fbba74', 'message': 'Remove testing OVS/OVN master branch in Train\n\nThere is no need to run Train against OVS master as it is supposed to be\nrunning with 2.12 version.\n\nChange-Id: Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e\n'}, {'number': 2, 'created': '2020-03-05 16:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/538b9ffa5de6588fc85b78cdada08f9db62e6d1a', 'message': 'Remove testing OVS/OVN master branch in Train\n\nThere is no need to run Train against OVS master as it is supposed to be\nrunning with 2.12 version.\n\nChange-Id: Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e\n'}, {'number': 3, 'created': '2020-05-04 08:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7da682ad10cbd4ec5b909ab5a02dc49e05f5c713', 'message': 'Remove testing OVS/OVN master branch in Train\n\nThere is no need to run Train against OVS master as it is supposed to be\nrunning with 2.12 version.\n\nChange-Id: Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e\n'}, {'number': 4, 'created': '2021-02-03 09:30:25.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/networking-ovn-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/d8961110523a605837d5d70b1b6b6b83992d1f62', 'message': 'Remove testing OVS/OVN master branch in Train\n\nThere is no need to run Train against OVS master as it is supposed to be\nrunning with 2.12 version.\n\nChange-Id: Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e\n'}]",6,696581,d8961110523a605837d5d70b1b6b6b83992d1f62,33,6,4,8655,,,0,"Remove testing OVS/OVN master branch in Train

There is no need to run Train against OVS master as it is supposed to be
running with 2.12 version.

Change-Id: Ic2bc8c8fa2facd340283c3b69dd7b8fb3b364f3e
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/81/696581/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/networking-ovn-jobs.yaml'],1,73e0241e8f61ffb3cdd138b31b4e58e148fbba74,change-696581-3,, name: networking-ovn-tempest-dsvm-ovs-master description: Job testing for devstack/tempest testing networking-ovn with OVN master branch parent: networking-ovn-base vars: devstack_localrc: OVN_BRANCH: master - job: name: networking-ovn-tempest-dsvm-ovs-master-fedora description: Job testing for devstack/tempest testing networking-ovn with OVN master branch and Fedora parent: networking-ovn-tempest-dsvm-ovs-master nodeset: devstack-single-node-fedora-latest - job:,0,14
openstack%2Fnova~master~Ie49ea0c0d3729001dd40cde5ee9455af3f4e8ec6,openstack/nova,master,Ie49ea0c0d3729001dd40cde5ee9455af3f4e8ec6,Fix invalid argument formatting in exception messages,MERGED,2020-11-20 07:16:47.000000000,2021-02-04 19:21:35.000000000,2021-02-04 19:14:46.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-20 07:16:47.000000000', 'files': ['nova/tests/unit/virt/disk/vfs/fakeguestfs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/67454b307b31d4695ffab44c02dea876ed15f67e', 'message': 'Fix invalid argument formatting in exception messages\n\nThis is to fix the invalid argument formaating in exception messages.\n\nChange-Id: Ie49ea0c0d3729001dd40cde5ee9455af3f4e8ec6\n'}]",1,763511,67454b307b31d4695ffab44c02dea876ed15f67e,15,10,1,20190,,,0,"Fix invalid argument formatting in exception messages

This is to fix the invalid argument formaating in exception messages.

Change-Id: Ie49ea0c0d3729001dd40cde5ee9455af3f4e8ec6
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/763511/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/disk/vfs/fakeguestfs.py'],1,67454b307b31d4695ffab44c02dea876ed15f67e,exception_message," raise RuntimeError(""%s: No such file or directory"" % file) raise RuntimeError(""Node not found %s"" % cfgpath) raise RuntimeError(""Unknown path %s"" % cfgpath)"," raise RuntimeError(""%s: No such file or directory"", file) raise RuntimeError(""Node not found %s"", cfgpath) raise RuntimeError(""Unknown path %s"", cfgpath)",3,3
openstack%2Ffreezer-web-ui~master~I2e7c0f1e9fd40ef0f7d4345d191ece57d673c9fb,openstack/freezer-web-ui,master,I2e7c0f1e9fd40ef0f7d4345d191ece57d673c9fb,remove unicode from code,NEW,2021-01-07 06:52:40.000000000,2021-02-04 19:21:20.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-01-07 06:52:40.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/696787eef1a672fecf87e7a35236bfe86914799a', 'message': 'remove unicode from code\n\nChange-Id: I2e7c0f1e9fd40ef0f7d4345d191ece57d673c9fb\n'}]",0,769670,696787eef1a672fecf87e7a35236bfe86914799a,4,2,1,32921,,,0,"remove unicode from code

Change-Id: I2e7c0f1e9fd40ef0f7d4345d191ece57d673c9fb
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/70/769670/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,696787eef1a672fecf87e7a35236bfe86914799a,,"project = 'freezer-web-ui' copyright = '2016, OpenStack' ('index', 'freezer-web-ui.tex', 'freezer-web-ui Documentation', 'OpenStack', 'manual'), ('index', 'freezer-web-ui', 'freezer-web-ui Documentation', ['OpenStack'], 1) ('index', 'freezer-web-ui', 'freezer-web-ui Documentation', 'OpenStack', 'freezer-web-ui', 'One line description of project.',","project = u'freezer-web-ui' copyright = u'2016, OpenStack' ('index', 'freezer-web-ui.tex', u'freezer-web-ui Documentation', u'OpenStack', 'manual'), ('index', 'freezer-web-ui', u'freezer-web-ui Documentation', [u'OpenStack'], 1) ('index', 'freezer-web-ui', u'freezer-web-ui Documentation', u'OpenStack', 'freezer-web-ui', 'One line description of project.',",8,8
openstack%2Fos-brick~master~I56bf09cbd40679eefa5e378c9b36383de89e980c,openstack/os-brick,master,I56bf09cbd40679eefa5e378c9b36383de89e980c,rbd Windows support,MERGED,2020-04-08 11:39:46.000000000,2021-02-04 19:14:15.000000000,2021-02-04 19:12:26.000000000,"[{'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 8543}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27710}]","[{'number': 1, 'created': '2020-04-08 11:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/62b452ab2091521de262d362bb9a53bbaf6144e7', 'message': 'WIP: rbd Windows support\n\nThe next Ceph release is going to support mounting RBD images on\nWindows.\n\nThis change provides a simplified RBD connector for Windows.\n\nThere are a few differences compared to the Linux version:\n* the Ceph python bindings are not available on Windows yet, so we\'ll\n  always do a local mount. Besides, Hyper-V cannot use librbd, so\n  we\'ll need to do a local mount anyway.\n* the device names aren\'t handled in the same way. On Windows,\n  disk names such as ""\\\\.\\PhysicalDrive1"" are provided by the OS and\n  cannot be explicitly requsted. The WNBD driver allows us to pass\n  arbitrary unique identifiers that are also used when disconnecting\n  devices. To keep things simple, we\'ll just use the volume id.\n* we\'re trying to reduce the number of exec calls to a minimum\n  since this operation is particularly expensive on Windows.\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 2, 'created': '2020-05-28 11:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/4f4c3a187e4a132cc4bd6a774dc1a90d51565f16', 'message': 'WIP: rbd Windows support\n\nThe next Ceph release is going to support mounting RBD images on\nWindows.\n\nThis change provides a simplified RBD connector for Windows.\n\nThere are a few differences compared to the Linux version:\n* the Ceph python bindings are not available on Windows yet, so we\'ll\n  always do a local mount. Besides, Hyper-V cannot use librbd, so\n  we\'ll need to do a local mount anyway.\n* the device names aren\'t handled in the same way. On Windows,\n  disk names such as ""\\\\.\\PhysicalDrive1"" are provided by the OS and\n  cannot be explicitly requsted. The WNBD driver allows us to pass\n  arbitrary unique identifiers that are also used when disconnecting\n  devices. To keep things simple, we\'ll just use the volume id.\n* we\'re trying to reduce the number of exec calls to a minimum\n  since this operation is particularly expensive on Windows.\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 3, 'created': '2020-11-20 10:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/32ff7265d864d7fee6901d7cff571c0d3a12b6a4', 'message': 'WIP: rbd Windows support\n\nThe next Ceph release is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nThe WIP tag will be removed after the unit tests are added.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 4, 'created': '2020-11-20 12:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/9892c720fe0f15eafb9fff4b5b1dcfcfb3405845', 'message': 'rbd Windows support\n\nThe next Ceph release is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 5, 'created': '2020-11-21 21:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6d7c2614af251315f9e17352c11fa1543c8a7c76', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 6, 'created': '2020-11-22 06:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/0da347250700d78f72e190f835295cf72aace48d', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 7, 'created': '2020-12-03 10:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/ced4a960d910bb211559e80fd8a645bce5b21263', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors. At the same time, we\'re going\nto include the RBD version in the connector properties dict, which\nwill allow performing version checks on the Cinder driver side.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 8, 'created': '2020-12-03 12:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/3da6e928c2ae6273551a3c2a7dccebe426edce12', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors. At the same time, we\'re going\nto include the RBD version in the connector properties dict, which\nwill allow performing version checks on the Cinder driver side.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 9, 'created': '2020-12-03 14:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/57214b035804da636cb5c3f9ad40cfba2967e232', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors. At the same time, we\'re going\nto include the RBD version in the connector properties dict, which\nwill allow performing version checks on the Cinder driver side.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 10, 'created': '2020-12-07 10:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/be37d4c24188fd236c3cc2ae83a52070038e7b61', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 11, 'created': '2020-12-07 10:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/82d9ca955529099d0fbe235c8b6584146d201506', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 12, 'created': '2020-12-07 10:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/ff1a7ac1fc0d49d48808d228422359e3115a5c91', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 13, 'created': '2020-12-07 10:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/b108e7d0d4553417e350cf1613d2d235e318f02a', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 14, 'created': '2020-12-07 14:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/69a197281ec3fd6175ab44d1db305de062aca72d', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nOnce the Python bindings are ported to Windows, we might consider\nmerging the two connectors or at least providing some common helpers\nto avoid code duplication.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 15, 'created': '2020-12-07 14:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/48260e3e7356ac59c919604653a80506c2f5b609', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors. At the same time, we\'re going\nto include the RBD version in the connector properties dict, which\nwill allow performing version checks on the Cinder driver side.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 16, 'created': '2020-12-09 15:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cd7eb8d1260ec3843e4301cabb1193f6ed1a5fae', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}, {'number': 17, 'created': '2020-12-16 13:24:08.000000000', 'files': ['os_brick/tests/initiator/connectors/test_rbd.py', 'os_brick/initiator/connectors/base_rbd.py', 'os_brick/tests/initiator/test_connector.py', 'os_brick/initiator/windows/rbd.py', 'os_brick/tests/windows/test_rbd.py', 'os_brick/initiator/connector.py', 'releasenotes/notes/rbd-windows-support-ef6e8184842409dd.yaml', 'os_brick/initiator/connectors/rbd.py', 'os_brick/initiator/windows/base.py', 'os_brick/tests/initiator/connectors/test_base_rbd.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8d849e5fea2b00482eba91eeb8c5b7956313c170', 'message': 'rbd Windows support\n\nCeph 16 (Pacific) is going to support mounting RBD images on\nWindows[1].\n\nThis change provides a simplified RBD connector for Windows.\n\nThe Windows RBD connector is very similar to the Linux one.\nThere are a few main differences though:\n  * the Ceph python bindings are not available on Windows yet, so\n    we\'ll always do a local mount. Besides, Hyper-V cannot use\n    librbd directly, so we\'ll need a local mount anyway.\n  * The device names aren\'t handled in the same way. On Windows,\n    disk names such as ""\\\\.\\PhysicalDrive1"" are provided by\n    the OS and cannot be explicitly requsted.\n  * under high load, the disk might not become available immediately,\n    we\'re adding a few checks when mapping the image.\n  * rbd-wnbd provides a ""show"" command, which we\'re going to use\n    in order to retrieve mounted disk paths\n  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully\n    disconnecting volume. By default, WNBD waits for the Windows\n    storage PnP stack before removing the attachment (e.g. waiting for\n    open handles, unflushed data, pending IO, etc).\n\nWe\'re adding a mixin class meant to avoid duplicating code between\nthe Linux and Windows RBD connectors.\n\nIntegration testing will be covered by the existing Windows CI.\n\n[1] https://github.com/ceph/ceph/pull/33750\n\nImplements: blueprint os-brick-windows-rbd\n\nChange-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c\n'}]",42,718403,8d849e5fea2b00482eba91eeb8c5b7956313c170,156,11,17,8543,,,0,"rbd Windows support

Ceph 16 (Pacific) is going to support mounting RBD images on
Windows[1].

This change provides a simplified RBD connector for Windows.

The Windows RBD connector is very similar to the Linux one.
There are a few main differences though:
  * the Ceph python bindings are not available on Windows yet, so
    we'll always do a local mount. Besides, Hyper-V cannot use
    librbd directly, so we'll need a local mount anyway.
  * The device names aren't handled in the same way. On Windows,
    disk names such as ""\\.\PhysicalDrive1"" are provided by
    the OS and cannot be explicitly requsted.
  * under high load, the disk might not become available immediately,
    we're adding a few checks when mapping the image.
  * rbd-wnbd provides a ""show"" command, which we're going to use
    in order to retrieve mounted disk paths
  * rbd-wnbd provides a ""hard-disconnect"" option, used when forcefully
    disconnecting volume. By default, WNBD waits for the Windows
    storage PnP stack before removing the attachment (e.g. waiting for
    open handles, unflushed data, pending IO, etc).

We're adding a mixin class meant to avoid duplicating code between
the Linux and Windows RBD connectors.

Integration testing will be covered by the existing Windows CI.

[1] https://github.com/ceph/ceph/pull/33750

Implements: blueprint os-brick-windows-rbd

Change-Id: I56bf09cbd40679eefa5e378c9b36383de89e980c
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/03/718403/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/initiator/windows/rbd.py', 'os_brick/initiator/connector.py', 'os_brick/initiator/windows/base.py']",3,62b452ab2091521de262d362bb9a53bbaf6144e7,rbd,from oslo_concurrency import processutils as putils kwargs['executor'] = kwargs.get('executor') or putils.execute,,210,0
openstack%2Fhorizon~master~I0a01de9e503ba1550cfd011229e76cc633b371d3,openstack/horizon,master,I0a01de9e503ba1550cfd011229e76cc633b371d3,[DNR] Test integration job with latest geckodriver release,ABANDONED,2021-02-01 09:09:06.000000000,2021-02-04 18:59:17.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-02-01 09:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e12212e3e80c8d9258fb0aab1ae43515db1baa5a', 'message': '[DNR] Test integration job with latest geckodriver release\n\nChange-Id: I0a01de9e503ba1550cfd011229e76cc633b371d3\n'}, {'number': 2, 'created': '2021-02-01 09:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a2c6e6b751f8b22aa52c3372bda9d9d31dd90b42', 'message': '[DNR] Test integration job with latest geckodriver release\n\nChange-Id: I0a01de9e503ba1550cfd011229e76cc633b371d3\n'}, {'number': 3, 'created': '2021-02-01 18:30:46.000000000', 'files': ['roles/setup-selenium-tests/defaults/main.yaml', 'openstack_dashboard/test/integration_tests/regions/menus.py', '.zuul.d/project.yaml', 'horizon/test/chromedriver.py', 'openstack_dashboard/test/integration_tests/helpers.py', 'horizon/test/webdriver.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/09a73c5feded92ff86d80c17ce8f1ae7e7c40f8b', 'message': '[DNR] Test integration job with latest geckodriver release\n\nChange-Id: I0a01de9e503ba1550cfd011229e76cc633b371d3\n'}]",2,773315,09a73c5feded92ff86d80c17ce8f1ae7e7c40f8b,10,2,3,29313,,,0,"[DNR] Test integration job with latest geckodriver release

Change-Id: I0a01de9e503ba1550cfd011229e76cc633b371d3
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/773315/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/setup-selenium-tests/defaults/main.yaml', '.zuul.d/project.yaml']",2,e12212e3e80c8d9258fb0aab1ae43515db1baa5a,, #- check-requirements #- horizon-cross-jobs #- horizon-nodejs10-jobs #- horizon-non-primary-django-jobs #- openstack-lower-constraints-jobs #- openstack-python3-wallaby-jobs #- periodic-stable-jobs #- publish-openstack-docs-pti #- release-notes-jobs-python3 #- horizon-selenium-headless #- horizon-dsvm-tempest-plugin #- horizon-tox-bandit-baseline #- horizon-tempest-plugin-ipv6, - check-requirements - horizon-cross-jobs - horizon-nodejs10-jobs - horizon-non-primary-django-jobs - openstack-lower-constraints-jobs - openstack-python3-wallaby-jobs - periodic-stable-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 - horizon-selenium-headless - horizon-dsvm-tempest-plugin - horizon-tox-bandit-baseline - horizon-tempest-plugin-ipv6,14,14
openstack%2Ffreezer-dr~master~If817a0d8d2dcc6aa6f6652a0586af51eef860aa0,openstack/freezer-dr,master,If817a0d8d2dcc6aa6f6652a0586af51eef860aa0,remove unicode from code,NEW,2021-01-07 06:42:27.000000000,2021-02-04 18:58:24.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2021-01-07 06:42:27.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/c3121bee0ab43559a6d358278863351dc2c536c9', 'message': 'remove unicode from code\n\nChange-Id: If817a0d8d2dcc6aa6f6652a0586af51eef860aa0\n'}]",0,769668,c3121bee0ab43559a6d358278863351dc2c536c9,3,2,1,32921,,,0,"remove unicode from code

Change-Id: If817a0d8d2dcc6aa6f6652a0586af51eef860aa0
",git fetch https://review.opendev.org/openstack/freezer-dr refs/changes/68/769668/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,c3121bee0ab43559a6d358278863351dc2c536c9,,"project = 'Freezer' copyright = '2016, OpenStack' ('index', 'Freezerdr.tex', 'Freezer DR Documentation', 'OpenStack', 'manual'), ('index', 'freezer-dr', 'Freezer DR Documentation', ['OpenStack'], 1) ('index', 'Freezer DR', 'Freezer Disaster Recovery Documentation', 'OpenStack', 'Freezer Disaster Recovery', 'One line description of project.',","project = u'Freezer' copyright = u'2016, OpenStack' ('index', 'Freezerdr.tex', u'Freezer DR Documentation', u'OpenStack', 'manual'), ('index', 'freezer-dr', u'Freezer DR Documentation', [u'OpenStack'], 1) ('index', 'Freezer DR', u'Freezer Disaster Recovery Documentation', u'OpenStack', 'Freezer Disaster Recovery', 'One line description of project.',",8,8
openstack%2Fopenstack-ansible~stable%2Fussuri~Ifd514580702cd99912c3193272b790a04760ae07,openstack/openstack-ansible,stable/ussuri,Ifd514580702cd99912c3193272b790a04760ae07,Ensure kuryr repo is available within CI images,MERGED,2021-01-21 13:05:27.000000000,2021-02-04 18:40:06.000000000,2021-02-04 18:32:52.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2021-01-21 13:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7842d28d4d179bc952b33beaec593e20cde456a5', 'message': 'Ensure kuryr repo is available within CI images\n\nThis needs to be included explicitly for use by the Zun role\nuntil kuryr-libnetwork explicitly depends upon a version of\nkuryr lib which includes the patch from\nhttps://review.opendev.org/c/openstack/kuryr/+/764908\n\nDepends-On: https://review.opendev.org/765839\nDepends-On: https://review.opendev.org/766030\nChange-Id: Ifd514580702cd99912c3193272b790a04760ae07\n(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)\n'}, {'number': 2, 'created': '2021-01-21 13:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/05802b37904246e1a5d40f6bc5457623b3d4eec6', 'message': 'Ensure kuryr repo is available within CI images\n\nThis needs to be included explicitly for use by the Zun role\nuntil kuryr-libnetwork explicitly depends upon a version of\nkuryr lib which includes the patch from\nhttps://review.opendev.org/c/openstack/kuryr/+/764908\n\nDepends-On: https://review.opendev.org/765839\nDepends-On: https://review.opendev.org/766030\nChange-Id: Ifd514580702cd99912c3193272b790a04760ae07\n(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)\n'}, {'number': 3, 'created': '2021-01-21 13:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a9664d4ef6e9d1e5097183cc6900d618e0014b28', 'message': 'Ensure kuryr repo is available within CI images\n\nThis needs to be included explicitly for use by the Zun role\nuntil kuryr-libnetwork explicitly depends upon a version of\nkuryr lib which includes the patch from\nhttps://review.opendev.org/c/openstack/kuryr/+/764908\n\nDepends-On: https://review.opendev.org/765839\nDepends-On: https://review.opendev.org/766030\nChange-Id: Ifd514580702cd99912c3193272b790a04760ae07\n(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)\n'}, {'number': 4, 'created': '2021-01-28 20:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/12e092c7ac80ff933f1aeea07aebb30f37dda5f0', 'message': 'Ensure kuryr repo is available within CI images\n\nThis needs to be included explicitly for use by the Zun role\nuntil kuryr-libnetwork explicitly depends upon a version of\nkuryr lib which includes the patch from\nhttps://review.opendev.org/c/openstack/kuryr/+/764908\n\nDepends-On: https://review.opendev.org/765839\nDepends-On: https://review.opendev.org/766030\nChange-Id: Ifd514580702cd99912c3193272b790a04760ae07\n(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)\n'}, {'number': 5, 'created': '2021-02-01 13:08:18.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'tests/roles/bootstrap-host/templates/user_variables_zun.yml.j2', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/90087a9926710eb2066adf706be962e503902f89', 'message': 'Ensure kuryr repo is available within CI images\n\nThis needs to be included explicitly for use by the Zun role\nuntil kuryr-libnetwork explicitly depends upon a version of\nkuryr lib which includes the patch from\nhttps://review.opendev.org/c/openstack/kuryr/+/764908\n\nDepends-On: https://review.opendev.org/765839\nDepends-On: https://review.opendev.org/766030\nChange-Id: Ifd514580702cd99912c3193272b790a04760ae07\n(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)\n'}]",0,771608,90087a9926710eb2066adf706be962e503902f89,32,3,5,28619,,,0,"Ensure kuryr repo is available within CI images

This needs to be included explicitly for use by the Zun role
until kuryr-libnetwork explicitly depends upon a version of
kuryr lib which includes the patch from
https://review.opendev.org/c/openstack/kuryr/+/764908

Depends-On: https://review.opendev.org/765839
Depends-On: https://review.opendev.org/766030
Change-Id: Ifd514580702cd99912c3193272b790a04760ae07
(cherry picked from commit 627a04482f73f5bacc07bbad7d0ba3bb45f8e717)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/08/771608/5 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'zuul.d/jobs.yaml']",2,7842d28d4d179bc952b33beaec593e20cde456a5,,<<<<<<< HEAD (e383e9 Bump SHAs for stable/ussuri) ======= - name: openstack/zun - name: openstack/kuryr-libnetwork - name: openstack/kuryr >>>>>>> CHANGE (627a04 Ensure kuryr repo is available within CI images),,17,1
openstack%2Fproject-config~master~Ic6ae3c5406fc0efd7fff1875459dfab85b4f702c,openstack/project-config,master,Ic6ae3c5406fc0efd7fff1875459dfab85b4f702c,zuul-worker: remove additional install of apt-transport-https,MERGED,2020-04-01 23:14:27.000000000,2021-02-04 18:31:43.000000000,2021-02-04 18:20:14.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-04-01 23:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7c44671e3adf2056e1282100b8bc59b153d033f4', 'message': 'zuul-worker: remove additional install of apt-transport-https\n\nThis is installed for the base images in the dependent change\n\nDepends-On: https://review.opendev.org/716788\nChange-Id: Ic6ae3c5406fc0efd7fff1875459dfab85b4f702c\n'}, {'number': 2, 'created': '2020-04-03 14:20:26.000000000', 'files': ['nodepool/elements/zuul-worker/pkg-map', 'nodepool/elements/zuul-worker/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2ef9b25101fe9fd1edc09dc8363625edf534bf06', 'message': 'zuul-worker: remove additional install of apt-transport-https\n\nThis is installed for the base images in the dependent change\n\nDepends-On: https://review.opendev.org/716788\nChange-Id: Ic6ae3c5406fc0efd7fff1875459dfab85b4f702c\n'}]",0,716789,2ef9b25101fe9fd1edc09dc8363625edf534bf06,14,6,2,7118,,,0,"zuul-worker: remove additional install of apt-transport-https

This is installed for the base images in the dependent change

Depends-On: https://review.opendev.org/716788
Change-Id: Ic6ae3c5406fc0efd7fff1875459dfab85b4f702c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/89/716789/2 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/zuul-worker/package-installs.yaml', 'nodepool/elements/zuul-worker/pkg-map']",2,7c44671e3adf2056e1282100b8bc59b153d033f4,fedora-31-patch1,,"{ ""family"": { ""debian"": { ""apt-transport-https"": ""apt-transport-https"", } }, ""default"": { ""apt-transport-https"": """", } } ",0,12
openstack%2Fmagnum~master~Idf04b5e0a1be3ef6637a675271174acd6652ae9f,openstack/magnum,master,Idf04b5e0a1be3ef6637a675271174acd6652ae9f,Update docs for cluster resource,MERGED,2021-01-21 06:24:36.000000000,2021-02-04 17:59:54.000000000,2021-02-04 17:56:57.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2021-01-21 06:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a0aec4de1e1fec8ed5623913fe03b1dc07e81124', 'message': 'Update docs for cluster resource\n\n+ Ensure floating_ip_enabled included\n+ Ensure master_lb_enabled included\n\nChange-Id: Idf04b5e0a1be3ef6637a675271174acd6652ae9f\n'}, {'number': 2, 'created': '2021-01-21 07:00:05.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/clusters.inc'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9b8f155543029d822f92930b5aa233b97683368f', 'message': 'Update docs for cluster resource\n\n+ Ensure floating_ip_enabled included\n+ Ensure master_lb_enabled included\n\nChange-Id: Idf04b5e0a1be3ef6637a675271174acd6652ae9f\n'}]",0,771751,9b8f155543029d822f92930b5aa233b97683368f,10,3,2,30447,,,0,"Update docs for cluster resource

+ Ensure floating_ip_enabled included
+ Ensure master_lb_enabled included

Change-Id: Idf04b5e0a1be3ef6637a675271174acd6652ae9f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/51/771751/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/clusters.inc']",2,a0aec4de1e1fec8ed5623913fe03b1dc07e81124,fix/update-create-cluster-docs, - master_lb_enabled: master_lb_enabled_cluster - floating_ip_enabled: floating_ip_enabled_cluster - master_lb_enabled: master_lb_enabled_cluster,,15,0
openstack%2Fpython-magnumclient~stable%2Fvictoria~I4c06648e4e9f2c5b7110ce6d6fb82fe44f105cb2,openstack/python-magnumclient,stable/victoria,I4c06648e4e9f2c5b7110ce6d6fb82fe44f105cb2,Update .gitreview for stable/victoria,MERGED,2020-09-09 16:04:47.000000000,2021-02-04 17:58:46.000000000,2021-02-04 17:57:25.000000000,"[{'_account_id': 8064}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28182}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-09-09 16:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/b94f95e270a714f3d30b075e14f6de3c1d80e1c5', 'message': 'Update .gitreview for stable/victoria\n\nChange-Id: I4c06648e4e9f2c5b7110ce6d6fb82fe44f105cb2\n'}, {'number': 2, 'created': '2021-02-04 17:07:32.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/d16026a3243d406803ae2b6465bb8ab7ed5a652d', 'message': 'Update .gitreview for stable/victoria\n\nChange-Id: I4c06648e4e9f2c5b7110ce6d6fb82fe44f105cb2\n'}]",0,750705,d16026a3243d406803ae2b6465bb8ab7ed5a652d,16,5,2,22816,,,0,"Update .gitreview for stable/victoria

Change-Id: I4c06648e4e9f2c5b7110ce6d6fb82fe44f105cb2
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/05/750705/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,b94f95e270a714f3d30b075e14f6de3c1d80e1c5,create-victoria,defaultbranch=stable/victoria,,1,0
openstack%2Freleases~master~I12a51cd877b28d42bfb3c735ac0744cbcb514250,openstack/releases,master,I12a51cd877b28d42bfb3c735ac0744cbcb514250,Release oslo.messaging 12.7.0,MERGED,2021-02-03 14:18:57.000000000,2021-02-04 17:49:11.000000000,2021-02-04 17:49:11.000000000,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-03 14:18:57.000000000', 'files': ['deliverables/wallaby/oslo.messaging.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f646caf2b71721e99b4dcae5f5c8b3c6f7ed0f5a', 'message': 'Release oslo.messaging 12.7.0\n\nAn option have been deprecated [1] release a new version to officialize it\n\n[1] https://opendev.org/openstack/oslo.messaging/commit/2b89d97888c9b6cd8b4f23e5ae7ce3103d5f9e5b\n\nChange-Id: I12a51cd877b28d42bfb3c735ac0744cbcb514250\n'}]",0,773895,f646caf2b71721e99b4dcae5f5c8b3c6f7ed0f5a,8,2,1,28522,,,0,"Release oslo.messaging 12.7.0

An option have been deprecated [1] release a new version to officialize it

[1] https://opendev.org/openstack/oslo.messaging/commit/2b89d97888c9b6cd8b4f23e5ae7ce3103d5f9e5b

Change-Id: I12a51cd877b28d42bfb3c735ac0744cbcb514250
",git fetch https://review.opendev.org/openstack/releases refs/changes/95/773895/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/oslo.messaging.yaml'],1,f646caf2b71721e99b4dcae5f5c8b3c6f7ed0f5a,oslo.messaging-depreacte-mandatory-flag, - version: 12.7.0 projects: - repo: openstack/oslo.messaging hash: e18553f5058ef6fd1200ac76e1f8e548afb1c043,,4,0
openstack%2Foslo.policy~master~If104b6d41503e7c0c4dbfae9f4d1fa9a74b0f96e,openstack/oslo.policy,master,If104b6d41503e7c0c4dbfae9f4d1fa9a74b0f96e,TODO,ABANDONED,2021-02-04 17:33:14.000000000,2021-02-04 17:34:29.000000000,,[],"[{'number': 1, 'created': '2021-02-04 17:33:14.000000000', 'files': ['oslo_policy/tests/test_policy.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/05d61dfaad8ca6ab600286f3d10e10b798109ff4', 'message': 'TODO\n\nChange-Id: If104b6d41503e7c0c4dbfae9f4d1fa9a74b0f96e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,774111,05d61dfaad8ca6ab600286f3d10e10b798109ff4,2,0,1,15334,,,0,"TODO

Change-Id: If104b6d41503e7c0c4dbfae9f4d1fa9a74b0f96e
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/11/774111/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_policy/tests/test_policy.py'],1,05d61dfaad8ca6ab600286f3d10e10b798109ff4,bug/1914095," def test_deprecation_logic_is_only_performed_once(self): deprecated_rule = policy.DeprecatedRule( name='member_api', check_str='role:member', ) old_base_rule = policy.RuleDefault( name='member_api', check_str='role:member', description='Unscoped member-level access', deprecated_for_removal=True, deprecated_reason='Scoping FTW', deprecated_since='W', ) new_base_rule = policy.RuleDefault( name='admin_api', check_str='role:admin', description='Unscoped admin-level access', deprecated_rule=deprecated_rule, deprecated_reason='reasons', deprecated_since='W', ) create_rule = policy.DocumentedRuleDefault( name='servers:create', check_str='rule:admin_api', description='Create a server.', operations=[{'path': '/v1/bars', 'method': 'POST'}], ) rules = [old_base_rule, new_base_rule, create_rule] print('!!! loading !!!') policy_json = jsonutils.dumps({ 'servers:create': 'rule:member_api', }) self.create_config_file('policy.json', policy_json) enforcer = policy.Enforcer(self.conf) enforcer.register_defaults(rules) enforcer.load_rules() ctx = context.RequestContext(roles=['member']) self.assertTrue(enforcer.enforce('servers:create', {}, ctx)) print('!!! reloading !!!') self.create_config_file('policy.json', '') enforcer.load_rules() ctx = context.RequestContext(roles=['member']) self.assertTrue(enforcer.enforce('servers:create', {}, ctx)) ",,51,0
openstack%2Ftripleo-common~master~Ibbdf63ec372e8496d094f45f2eaef49f9a79d464,openstack/tripleo-common,master,Ibbdf63ec372e8496d094f45f2eaef49f9a79d464,Frr image support,MERGED,2020-11-17 21:07:06.000000000,2021-02-04 17:17:41.000000000,2021-02-04 17:14:51.000000000,"[{'_account_id': 6469}, {'_account_id': 6926}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-17 21:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8523e68deea8bed9ac5d86d12b65429e99c98c5d', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 2, 'created': '2020-11-18 08:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c5504d5ffa5f2320280d2f05aac3f35d1b9b9484', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 3, 'created': '2020-11-18 11:45:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/773ae5da98e92d6b11c211f84fba7f842c18fadb', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 4, 'created': '2020-11-18 13:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6f4b67079a9866e1bae0d7a9650692a851903d0a', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 5, 'created': '2020-11-18 14:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3988647993c447e3a58db53a3a23f4909a21500f', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 6, 'created': '2020-11-18 15:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c3fe009a74269978ad5c0fde620eb47230f3ed72', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 7, 'created': '2020-11-19 09:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/461afae6645ee8a9c54470a00a5ca657b084c035', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 8, 'created': '2020-11-19 09:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/db816a1fd72af924084b52b6d55663fc23fdd88b', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 9, 'created': '2020-11-25 21:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/783b72a58b7e3161af65d2d600a65cbfcf97fb97', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 10, 'created': '2020-12-02 22:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/89d36d39854e37baee63f17fb7dd1eb11866a473', 'message': 'DNR/DNM Frr support\n\ntesting\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}, {'number': 11, 'created': '2021-02-03 07:43:24.000000000', 'files': ['healthcheck/frr', 'container-images/tripleo_containers.yaml.j2', 'container-images/tcib/base/frr/frr.yaml', 'container-images/kolla/base/uid_gid_manage.sh', 'container-images/tripleo_containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/380a12c88923f977a7ed9c5896e6996b0cd9a4b8', 'message': 'Frr image support\n\nThis adds support for the Frr container image. Frr can be found at\nhttps://github.com/FRRouting/frr/ and is an implementation of a suite\nof different routing protocols.\n\nChange-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464\n'}]",3,763087,380a12c88923f977a7ed9c5896e6996b0cd9a4b8,44,7,11,20172,,,0,"Frr image support

This adds support for the Frr container image. Frr can be found at
https://github.com/FRRouting/frr/ and is an implementation of a suite
of different routing protocols.

Change-Id: Ibbdf63ec372e8496d094f45f2eaef49f9a79d464
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/87/763087/7 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/frr/frr.yaml'],1,8523e68deea8bed9ac5d86d12b65429e99c98c5d,bgpsupport,tcib_actions: - run: bash /usr/local/bin/uid_gid_manage {{ tcib_user }} - run: dnf install -y {{ tcib_packages['common'] | join(' ') }} && dnf clean all && rm -rf /var/cache/dnf - run: ln -s /usr/share/openstack-tripleo-common/healthcheck/frr /openstack/healthcheck && chmod a+rx /openstack/healthcheck tcib_packages: common: - frr tcib_user: frr ,,8,0
openstack%2Fopenstack-tempest-skiplist~master~I5733e7682292e64d8756c4e8ecf1718812e9591e,openstack/openstack-tempest-skiplist,master,I5733e7682292e64d8756c4e8ecf1718812e9591e,Update TrafficOperationsScenarioTest to be skipped only on periodic,MERGED,2021-02-04 16:33:23.000000000,2021-02-04 17:10:40.000000000,2021-02-04 17:08:08.000000000,"[{'_account_id': 6681}, {'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 16:33:23.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/5cfe9aa68908a47665d7da05c43e039c21936fee', 'message': 'Update TrafficOperationsScenarioTest to be skipped only on periodic\n\nThis patch update the previous patch that adds the\nTrafficOperationsScenarioTest on skiplist to be executed only on the ovn\njob, since this patch is also being executed successfully in other jobs.\n\nRelated-Bug: #1914600\nChange-Id: I5733e7682292e64d8756c4e8ecf1718812e9591e\n'}]",0,774102,5cfe9aa68908a47665d7da05c43e039c21936fee,8,3,1,8367,,,0,"Update TrafficOperationsScenarioTest to be skipped only on periodic

This patch update the previous patch that adds the
TrafficOperationsScenarioTest on skiplist to be executed only on the ovn
job, since this patch is also being executed successfully in other jobs.

Related-Bug: #1914600
Change-Id: I5733e7682292e64d8756c4e8ecf1718812e9591e
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/02/774102/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,5cfe9aa68908a47665d7da05c43e039c21936fee,1914600/2, jobs: - periodic-tripleo-ci-centos-8-scenario010-ovn-provider-standalone-master, jobs: [],2,1
openstack%2Ftripleo-upgrade~stable%2Ftrain~Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,openstack/tripleo-upgrade,stable/train,Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9,[live-migration] Count all hosts from all tenants for migration timeout,MERGED,2021-02-04 10:00:12.000000000,2021-02-04 17:05:04.000000000,2021-02-04 17:05:04.000000000,"[{'_account_id': 11166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-02-04 10:00:12.000000000', 'files': ['templates/node_upgrade_pre.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/6bcc6b2b9cbb520e5839aac6a4625504ed8d06a9', 'message': '[live-migration] Count all hosts from all tenants for migration timeout\n\nChange-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9\n(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)\n'}]",0,773961,6bcc6b2b9cbb520e5839aac6a4625504ed8d06a9,6,2,1,6816,,,0,"[live-migration] Count all hosts from all tenants for migration timeout

Change-Id: Ifef1b4201b6959e2a8d30ec5ae6ef31a0e4871d9
(cherry picked from commit b9882bec2b57fe2ea4a37dff2d9074eea3bfea51)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/61/773961/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/node_upgrade_pre.sh.j2'],1,6bcc6b2b9cbb520e5839aac6a4625504ed8d06a9,,"INSTANCE_COUNT=$(openstack server list --all --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')","INSTANCE_COUNT=$(openstack server list --host ${HOST} -f json | jq -r -c '[.[] | select(.Status | contains(""ACTIVE"") or contains(""PAUSED"") or contains(""MIGRATING""))] | length')",1,1
openstack%2Fcharm-mysql-router~master~I1e66aca79df83b41072bb5df2cfb1708c8259cb4,openstack/charm-mysql-router,master,I1e66aca79df83b41072bb5df2cfb1708c8259cb4,Set client_ssl_mode,MERGED,2021-02-03 22:14:49.000000000,2021-02-04 17:04:34.000000000,2021-02-04 17:04:34.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2021-02-03 22:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/c70cfcc1fb894306a54c365b10b7e5bd9a8b3b15', 'message': ""Set client_ssl_mode\n\nWhen vault certificates are being used and passed to the mysql-router\nvia the db-router relation use client_ssl_mode = PASSTHROUGH. This\nmaintains the < 8.0.23 behavior terminating TLS at the\nmysql-innodb-cluster nodes.\n\nIf not using vault certificates from the db-router relation use\nclient_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts\nwith self-signed certificates. This covers TLS for the deployment\nprocess.\n\nIf ssl_ca is unset on the db-router relation, unset it on the shared-db\nrelation to guarantee the requestor uses the correct communication\nmethod.\n\nCloses Bug: #1914299\n\nChange-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4\n""}, {'number': 2, 'created': '2021-02-04 00:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/c96de64e4d304971bf9dd17ac9adfbd11acc7f0b', 'message': ""Set client_ssl_mode\n\nWhen vault certificates are being used and passed to the mysql-router\nvia the db-router relation use client_ssl_mode = PASSTHROUGH. This\nmaintains the < 8.0.23 behavior terminating TLS at the\nmysql-innodb-cluster nodes.\n\nIf not using vault certificates from the db-router relation use\nclient_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts\nwith self-signed certificates. This covers TLS for the deployment\nprocess.\n\nIf ssl_ca is unset on the db-router relation, unset it on the shared-db\nrelation to guarantee the requestor uses the correct communication\nmethod.\n\nCloses Bug: #1914299\n\nChange-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4\n""}, {'number': 3, 'created': '2021-02-04 09:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/2020f81d0c8beb7674a462e9a58b06d3afaee6e4', 'message': ""Set client_ssl_mode\n\nWhen vault certificates are being used and passed to the mysql-router\nvia the db-router relation use client_ssl_mode = PASSTHROUGH. This\nmaintains the < 8.0.23 behavior terminating TLS at the\nmysql-innodb-cluster nodes.\n\nIf not using vault certificates from the db-router relation use\nclient_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts\nwith self-signed certificates. This covers TLS for the deployment\nprocess.\n\nIf ssl_ca is unset on the db-router relation, unset it on the shared-db\nrelation to guarantee the requestor uses the correct communication\nmethod.\n\nCloses Bug: #1914299\n\nChange-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4\n""}, {'number': 4, 'created': '2021-02-04 09:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/8eca10d0bf236b9e49971cf5b731d8ae526664ee', 'message': ""Set client_ssl_mode\n\nWhen vault certificates are being used and passed to the mysql-router\nvia the db-router relation use client_ssl_mode = PASSTHROUGH. This\nmaintains the < 8.0.23 behavior terminating TLS at the\nmysql-innodb-cluster nodes.\n\nIf not using vault certificates from the db-router relation use\nclient_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts\nwith self-signed certificates. This covers TLS for the deployment\nprocess.\n\nIf ssl_ca is unset on the db-router relation, unset it on the shared-db\nrelation to guarantee the requestor uses the correct communication\nmethod.\n\nCloses-Bug: #1914299\nChange-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n""}, {'number': 5, 'created': '2021-02-04 09:38:58.000000000', 'files': ['src/lib/charm/openstack/mysql_router.py', 'src/tests/bundles/focal.yaml', 'unit_tests/test_lib_charm_openstack_mysql_router.py', 'src/tests/tests.yaml', 'src/tests/bundles/groovy.yaml'], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/5245a1592a0d67c03ad070ff0d634951a3bdd070', 'message': ""Set client_ssl_mode\n\nWhen vault certificates are being used and passed to the mysql-router\nvia the db-router relation use client_ssl_mode = PASSTHROUGH. This\nmaintains the < 8.0.23 behavior terminating TLS at the\nmysql-innodb-cluster nodes.\n\nIf not using vault certificates from the db-router relation use\nclient_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts\nwith self-signed certificates. This covers TLS for the deployment\nprocess.\n\nIf ssl_ca is unset on the db-router relation, unset it on the shared-db\nrelation to guarantee the requestor uses the correct communication\nmethod.\n\nCloses-Bug: #1914299\nChange-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n""}]",1,774008,5245a1592a0d67c03ad070ff0d634951a3bdd070,25,5,5,20805,,,0,"Set client_ssl_mode

When vault certificates are being used and passed to the mysql-router
via the db-router relation use client_ssl_mode = PASSTHROUGH. This
maintains the < 8.0.23 behavior terminating TLS at the
mysql-innodb-cluster nodes.

If not using vault certificates from the db-router relation use
client_ssl_mode = PREFERRED, 8.0.23's new behavior. This TLS encrypts
with self-signed certificates. This covers TLS for the deployment
process.

If ssl_ca is unset on the db-router relation, unset it on the shared-db
relation to guarantee the requestor uses the correct communication
method.

Closes-Bug: #1914299
Change-Id: I1e66aca79df83b41072bb5df2cfb1708c8259cb4
Co-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-mysql-router refs/changes/08/774008/4 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/mysql_router.py', 'src/tests/bundles/focal.yaml', 'src/tests/tests.yaml']",3,c70cfcc1fb894306a54c365b10b7e5bd9a8b3b15,bug/1914299,- zaza.openstack.charm_tests.vault.setup.auto_initialize,,73,8
openstack%2Fkolla-ansible~master~I96d7cb11935798bf5bce9443e274d69b0a1cf583,openstack/kolla-ansible,master,I96d7cb11935798bf5bce9443e274d69b0a1cf583,[WIP] Test Masakari for Ubuntu binary,ABANDONED,2020-12-22 20:25:10.000000000,2021-02-04 17:04:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-22 20:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7a4ef53bf63daa814372d3c36e2969ae8e073071', 'message': '[WIP] Test Masakari for Ubuntu binary\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/768255\nChange-Id: I96d7cb11935798bf5bce9443e274d69b0a1cf583\n'}, {'number': 2, 'created': '2020-12-23 12:41:34.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e6cef4f34076d6a5c381c40bb1e6d24a5fa5532b', 'message': '[WIP] Test Masakari for Ubuntu binary\n\nDepends-On: https://review.opendev.org/c/openstack/kolla/+/768255\nChange-Id: I96d7cb11935798bf5bce9443e274d69b0a1cf583\n'}]",0,768276,e6cef4f34076d6a5c381c40bb1e6d24a5fa5532b,11,1,2,30491,,,0,"[WIP] Test Masakari for Ubuntu binary

Depends-On: https://review.opendev.org/c/openstack/kolla/+/768255
Change-Id: I96d7cb11935798bf5bce9443e274d69b0a1cf583
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/76/768276/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,7a4ef53bf63daa814372d3c36e2969ae8e073071,ubuntu-binary-masakari, name: kolla-ansible-ubuntu-binary-masakari parent: kolla-ansible-masakari-base nodeset: kolla-ansible-focal vars: base_distro: ubuntu install_type: binary - job:,,47,38
